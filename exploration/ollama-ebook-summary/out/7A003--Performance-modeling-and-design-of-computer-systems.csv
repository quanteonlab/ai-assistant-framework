filename,title,text,len
01-Contents.pdf,01-Contents,"Contents\nPreface xvii\nAcknowledgments xxiii\nI Introduction to Queueing\n1 Motivating Examples of the Power of Analytical Modeling 3\n1.1 What Is Queueing Theory? 3\n1.2 Examples of the Power of Queueing Theory 5\n2 Queueing Theory Terminology 13\n2.1 Where We Are Heading 13\n2.2 The Single-Server Network 13\n2.3 Classiﬁcation of Queueing Networks 16\n2.4 Open Networks 16\n2.5 More Metrics: Throughput and Utilization 17\n2.6 Closed Networks 20\n2.6.1 Interactive (Terminal-Driven) Systems 21\n2.6.2 Batch Systems 22\n2.6.3 Throughput in a Closed System 23\n2.7 Differences between Closed and Open Networks 24\n2.7.1 A Question on Modeling 25\n2.8 Related Readings 25\n2.9 Exercises 26\nII Necessary Probability Background\n3 Probability Review 31\n3.1 Sample Space and Events 31\n3.2 Probability Deﬁned on Events 32\n3.3 Conditional Probabilities on Events 33\n3.4 Independent Events and Conditionally Independent Events 34\n3.5 Law of Total Probability 35\n3.6 Bayes Law 36\n3.7 Discrete versus Continuous Random Variables 37\n3.8 Probabilities and Densities 38\n3.8.1 Discrete: Probability Mass Function 38\n3.8.2 Continuous: Probability Density Function 41\n3.9 Expectation and Variance 44\n3.10 Joint Probabilities and Independence 47\nvii\nviii contents\n3.11 Conditional Probabilities and Expectations 49\n3.12 Probabilities and Expectations via Conditioning 53\n3.13 Linearity of Expectation 54\n3.14 Normal Distribution 57\n3.14.1 Linear Transformation Property 58\n3.14.2 Central Limit Theorem 61\n3.15 Sum of a Random Number of Random Variables 62\n3.16 Exercises 64\n4 Generating Random Variables for Simulation 70\n4.1 Inverse-Transform Method 70\n4.1.1 The Continuous Case 70\n4.1.2 The Discrete Case 72\n4.2 Accept-Reject Method 72\n4.2.1 Discrete Case 73\n4.2.2 Continuous Case 75\n4.2.3 Some Harder Problems 77\n4.3 Readings 78\n4.4 Exercises 78\n5 Sample Paths, Convergence, and Averages 79\n5.1 Convergence 79\n5.2 Strong and Weak Laws of Large Numbers 83\n5.3 Time Average versus Ensemble Average 84\n5.3.1 Motivation 85\n5.3.2 Deﬁnition 86\n5.3.3 Interpretation 86\n5.3.4 Equivalence 88\n5.3.5 Simulation 90\n5.3.6 Average Time in System 90\n5.4 Related Readings 91\n5.5 Exercise 91\nIII The Predictive Power of Simple Operational Laws: “What-If”\nQuestions and Answers\n6 Little’s Law and Other Operational Laws 95\n6.1 Little’s Law for Open Systems 95\n6.2 Intuitions 96\n6.3 Little’s Law for Closed Systems 96\n6.4 Proof of Little’s Law for Open Systems 97\n6.4.1 Statement via Time Averages 97\n6.4.2 Proof 98\n6.4.3 Corollaries 100\n6.5 Proof of Little’s Law for Closed Systems 101\n6.5.1 Statement via Time Averages 101\n6.5.2 Proof 102\n6.6 Generalized Little’s Law 102\ncontents ix\n6.7 Examples Applying Little’s Law 103\n6.8 More Operational Laws: The Forced Flow Law 106\n6.9 Combining Operational Laws 107\n6.10 Device Demands 110\n6.11 Readings and Further Topics Related to Little’s Law 111\n6.12 Exercises 111\n7 Modiﬁcation Analysis: “What-If” for Closed Systems 114\n7.1 Review 114\n7.2 Asymptotic Bounds for Closed Systems 115\n7.3 Modiﬁcation Analysis for Closed Systems 118\n7.4 More Modiﬁcation Analysis Examples 119\n7.5 Comparison of Closed and Open Networks 122\n7.6 Readings 122\n7.7 Exercises 122\nIV From Markov Chains to Simple Queues\n8 Discrete-Time Markov Chains 129\n8.1 Discrete-Time versus Continuous-Time Markov Chains 130\n8.2 Deﬁnition of a DTMC 130\n8.3 Examples of Finite-State DTMCs 131\n8.3.1 Repair Facility Problem 131\n8.3.2 Umbrella Problem 132\n8.3.3 Program Analysis Problem 132\n8.4 Powers of P:n-Step Transition Probabilities 133\n8.5 Stationary Equations 135\n8.6 The Stationary Distribution Equals the Limiting Distribution 136\n8.7 Examples of Solving Stationary Equations 138\n8.7.1 Repair Facility Problem with Cost 138\n8.7.2 Umbrella Problem 139\n8.8 Inﬁnite-State DTMCs 139\n8.9 Inﬁnite-State Stationarity Result 140\n8.10 Solving Stationary Equations in Inﬁnite-State DTMCs 142\n8.11 Exercises 145\n9 Ergodicity Theory 148\n9.1 Ergodicity Questions 148\n9.2 Finite-State DTMCs 149\n9.2.1 Existence of the Limiting Distribution 149\n9.2.2 Mean Time between Visits to a State 153\n9.2.3 Time Averages 155\n9.3 Inﬁnite-State Markov Chains 155\n9.3.1 Recurrent versus Transient 156\n9.3.2 Inﬁnite Random Walk Example 160\n9.3.3 Positive Recurrent versus Null Recurrent 162\n9.4 Ergodic Theorem of Markov Chains 164\nx contents\n9.5 Time Averages 166\n9.6 Limiting Probabilities Interpreted as Rates 168\n9.7 Time-Reversibility Theorem 170\n9.8 When Chains Are Periodic or Not Irreducible 171\n9.8.1 Periodic Chains 171\n9.8.2 Chains that Are Not Irreducible 177\n9.9 Conclusion 177\n9.10 Proof of Ergodic Theorem of Markov Chains∗178\n9.11 Exercises 183\n10 Real-World Examples: Google, Aloha, and Harder Chains∗190\n10.1 Google’s PageRank Algorithm 190\n10.1.1 Google’s DTMC Algorithm 190\n10.1.2 Problems with Real Web Graphs 192\n10.1.3 Google’s Solution to Dead Ends and Spider Traps 194\n10.1.4 Evaluation of the PageRank Algorithm 195\n10.1.5 Practical Implementation Considerations 195\n10.2 Aloha Protocol Analysis 195\n10.2.1 The Slotted Aloha Protocol 196\n10.2.2 The Aloha Markov Chain 196\n10.2.3 Properties of the Aloha Markov Chain 198\n10.2.4 Improving the Aloha Protocol 199\n10.3 Generating Functions for Harder Markov Chains 200\n10.3.1 The z-Transform 201\n10.3.2 Solving the Chain 201\n10.4 Readings and Summary 203\n10.5 Exercises 204\n11 Exponential Distribution and the Poisson Process 206\n11.1 Deﬁnition of the Exponential Distribution 206\n11.2 Memoryless Property of the Exponential 207\n11.3 Relating Exponential to Geometric via δ-Steps 209\n11.4 More Properties of the Exponential 211\n11.5 The Celebrated Poisson Process 213\n11.6 Merging Independent Poisson Processes 218\n11.7 Poisson Splitting 218\n11.8 Uniformity 221\n11.9 Exercises 222\n12 Transition to Continuous-Time Markov Chains 225\n12.1 Deﬁning CTMCs 225\n12.2 Solving CTMCs 229\n12.3 Generalization and Interpretation 232\n12.3.1 Interpreting the Balance Equations for the CTMC 234\n12.3.2 Summary Theorem for CTMCs 234\n12.4 Exercises 234\ncontents xi\n13 M/M/1 and PASTA 236\n13.1 The M/M/1 Queue 236\n13.2 Examples Using an M/M/1 Queue 239\n13.3 PASTA 242\n13.4 Further Reading 245\n13.5 Exercises 245\nV Server Farms and Networks: Multi-server, Multi-queue Systems\n14 Server Farms: M/M/k and M/M/k/k 253\n14.1 Time-Reversibility for CTMCs 253\n14.2 M/M/k/k Loss System 255\n14.3 M/M/k 258\n14.4 Comparison of Three Server Organizations 263\n14.5 Readings 264\n14.6 Exercises 264\n15 Capacity Provisioning for Server Farms 269\n15.1 What Does Load Really Mean in an M/M/k? 269\n15.2 The M/M/∞ 271\n15.2.1 Analysis of the M/M/ ∞ 271\n15.2.2 A First Cut at a Capacity Provisioning Rule for the M/M/k 272\n15.3 Square-Root Stafﬁng 274\n15.4 Readings 276\n15.5 Exercises 276\n16 Time-Reversibility and Burke’s Theorem 282\n16.1 More Examples of Finite-State CTMC s 282\n16.1.1 Networks with Finite Buffer Space 282\n16.1.2 Batch System with M/M/2 I/O 284\n16.2 The Reverse Chain 285\n16.3 Burke’s Theorem 288\n16.4 An Alternative (Partial) Proof of Burke’s Theorem 290\n16.5 Application: Tandem Servers 291\n16.6 General Acyclic Networks with Probabilistic Routing 293\n16.7 Readings 294\n16.8 Exercises 294\n17 Networks of Queues and Jackson Product Form 297\n17.1 Jackson Network Deﬁnition 297\n17.2 The Arrival Process into Each Server 298\n17.3 Solving the Jackson Network 300\n17.4 The Local Balance Approach 301\n17.5 Readings 306\n17.6 Exercises 306\n18 Classed Network of Queues 311\n18.1 Overview 311\n18.2 Motivation for Classed Networks 311\nxii contents\n18.3 Notation and Modeling for Classed Jackson Networks 314\n18.4 A Single-Server Classed Network 315\n18.5 Product Form Theorems 317\n18.6 Examples Using Classed Networks 322\n18.6.1 Connection-Oriented ATM Network Example 322\n18.6.2 Distribution of Job Classes Example 325\n18.6.3 CPU-Bound and I/O-Bound Jobs Example 326\n18.7 Readings 329\n18.8 Exercises 329\n19 Closed Networks of Queues 331\n19.1 Motivation 331\n19.2 Product-Form Solution 333\n19.2.1 Local Balance Equations for Closed Networks 333\n19.2.2 Example of Deriving Limiting Probabilities 335\n19.3 Mean Value Analysis (MV A) 337\n19.3.1 The Arrival Theorem 338\n19.3.2 Iterative Derivation of Mean Response Time 340\n19.3.3 An MV A Example 341\n19.4 Readings 343\n19.5 Exercises 343\nVI Real-World Workloads: High Variability and Heavy Tails\n20 Tales of Tails: A Case Study of Real-World Workloads 349\n20.1 Grad School Tales ...Process Migration 349\n20.2 UNIX Process Lifetime Measurements 350\n20.3 Properties of the Pareto Distribution 352\n20.4 The Bounded Pareto Distribution 353\n20.5 Heavy Tails 354\n20.6 The Beneﬁts of Active Process Migration 354\n20.7 Pareto Distributions Are Everywhere 355\n20.8 Exercises 357\n21 Phase-Type Distributions and Matrix-Analytic Methods 359\n21.1 Representing General Distributions by Exponentials 359\n21.2 Markov Chain Modeling of PH Workloads 364\n21.3 The Matrix-Analytic Method 366\n21.4 Analysis of Time-Varying Load 367\n21.4.1 High-Level Ideas 367\n21.4.2 The Generator Matrix, Q 368\n21.4.3 Solving for R 370\n21.4.4 Finding /vectorπ0 371\n21.4.5 Performance Metrics 372\n21.5 More Complex Chains 372\n21.6 Readings and Further Remarks 376\n21.7 Exercises 376\ncontents xiii\n22 Networks with Time-Sharing (PS) Servers (BCMP) 380\n22.1 Review of Product-Form Networks 380\n22.2 BCMP Result 380\n22.2.1 Networks with FCFS Servers 381\n22.2.2 Networks with PS Servers 382\n22.3 M/M/1/PS 384\n22.4 M/Cox/1/PS 385\n22.5 Tandem Network of M/G/1/PS Servers 391\n22.6 Network of PS Servers with Probabilistic Routing 393\n22.7 Readings 394\n22.8 Exercises 394\n23 The M/G/1 Queue and the Inspection Paradox 395\n23.1 The Inspection Paradox 395\n23.2 The M/G/1 Queue and Its Analysis 396\n23.3 Renewal-Reward Theory 399\n23.4 Applying Renewal-Reward to Get Expected Excess 400\n23.5 Back to the Inspection Paradox 402\n23.6 Back to the M/G/1 Queue 403\n23.7 Exercises 405\n24 Task Assignment Policies for Server Farms 408\n24.1 Task Assignment for FCFS Server Farms 410\n24.2 Task Assignment for PS Server Farms 419\n24.3 Optimal Server Farm Design 424\n24.4 Readings and Further Follow-Up 428\n24.5 Exercises 430\n25 Transform Analysis 433\n25.1 Deﬁnitions of Transforms and Some Examples 433\n25.2 Getting Moments from Transforms: Peeling the Onion 436\n25.3 Linearity of Transforms 439\n25.4 Conditioning 441\n25.5 Distribution of Response Time in an M/M/1 443\n25.6 Combining Laplace and z-Transforms 444\n25.7 More Results on Transforms 445\n25.8 Readings 446\n25.9 Exercises 446\n26 M/G/1 Transform Analysis 450\n26.1 The z-Transform of the Number in System 450\n26.2 The Laplace Transform of Time in System 454\n26.3 Readings 456\n26.4 Exercises 456\n27 Power Optimization Application 457\n27.1 The Power Optimization Problem 457\n27.2 Busy Period Analysis of M/G/1 459\n27.3 M/G/1 with Setup Cost 462\nxiv contents\n27.4 Comparing ON/IDLE versus ON/OFF 465\n27.5 Readings 467\n27.6 Exercises 467\nVII Smart Scheduling in the M/G/1\n28 Performance Metrics 473\n28.1 Traditional Metrics 473\n28.2 Commonly Used Metrics for Single Queues 474\n28.3 Today’s Trendy Metrics 474\n28.4 Starvation/Fairness Metrics 475\n28.5 Deriving Performance Metrics 476\n28.6 Readings 477\n29 Scheduling: Non-Preemptive, Non-Size-Based Policies 478\n29.1 FCFS, LCFS, and RANDOM 478\n29.2 Readings 481\n29.3 Exercises 481\n30 Scheduling: Preemptive, Non-Size-Based Policies 482\n30.1 Processor-Sharing (PS) 482\n30.1.1 Motivation behind PS 482\n30.1.2 Ages of Jobs in the M/G/1/PS System 483\n30.1.3 Response Time as a Function of Job Size 484\n30.1.4 Intuition for PS Results 487\n30.1.5 Implications of PS Results for Understanding FCFS 487\n30.2 Preemptive-LCFS 488\n30.3 FB Scheduling 490\n30.4 Readings 495\n30.5 Exercises 496\n31 Scheduling: Non-Preemptive, Size-Based Policies 499\n31.1 Priority Queueing 499\n31.2 Non-Preemptive Priority 501\n31.3 Shortest-Job-First (SJF) 504\n31.4 The Problem with Non-Preemptive Policies 506\n31.5 Exercises 507\n32 Scheduling: Preemptive, Size-Based Policies 508\n32.1 Motivation 508\n32.2 Preemptive Priority Queueing 508\n32.3 Preemptive-Shortest-Job-First (PSJF) 512\n32.4 Transform Analysis of PSJF 514\n32.5 Exercises 516\n33 Scheduling: SRPT and Fairness 518\n33.1 Shortest-Remaining-Processing-Time (SRPT) 518\n33.2 Precise Derivation of SRPT Waiting Time∗521\ncontents xv\n33.3 Comparisons with Other Policies 523\n33.3.1 Comparison with PSJF 523\n33.3.2 SRPT versus FB 523\n33.3.3 Comparison of All Scheduling Policies 524\n33.4 Fairness of SRPT 525\n33.5 Readings 529\nBibliography 531\nIndex 541",12695
02-Preface.pdf,02-Preface,,0
03-The ad hoc World of Computer System Design.pdf,03-The ad hoc World of Computer System Design,,0
04-Outline of the Book.pdf,04-Outline of the Book,"Preface\nThe ad hoc World of Computer System Design\nThe design of computer systems is often viewed very much as an art rather than a\nscience. Decisions about which scheduling policy to use, how many servers to run,what speed to operate each server at, and the like are often based on intuitions rather\nthan mathematically derived formulas. Speciﬁc policies built into kernels are often\nriddled with secret “voodoo constants,”\n1which have no explanation but seem to “work\nwell” under some benchmarked workloads. Computer systems students are often told\ntoﬁrst build the system and then make changes to the policies to improve system\nperformance, rather than ﬁrst creating a formal model and design of the system on\npaper to ensure the system meets performance goals.\nEven when trying to evaluate the performance of an existing computer system, students\nare encouraged to simulate the system and spend many days running their simulation\nunder different workloads waiting to see what happens. Given that the search space of\npossible workloads and input parameters is often huge, vast numbers of simulationsare needed to properly cover the space. Despite this fact, mathematical models of thesystem are rarely created, and we rarely characterize workloads stochastically. There isno formal analysis of the parameter space under which the computer system is likely toperform well versus that under which it is likely to perform poorly. It is no wonder thatcomputer systems students are left feeling that the whole process of system evaluationand design is very ad hoc. As an example, consider the trial-and-error approach to\nupdating resource scheduling in the many versions of the Linux kernel.\nAnalytical Modeling for Computer Systems\nBut it does not have to be this way! These same systems designers could mathematically\nmodel the system, stochastically characterize the workloads and performance goals,and then analytically derive the performance of the system as a function of workload\nand input parameters. The ﬁelds of analytical modeling andstochastic processes have\nexisted for close to a century, and they can be used to save systems designers huge\nnumbers of hours in trial and error while improving performance. Analytical modelingcan also be used in conjunction with simulation to help guide the simulation, reducingthe number of cases that need to be explored.\n1The term “voodoo constants” was coined by Prof. John Ousterhout during his lectures at the University of\nCalifornia, Berkeley.\nxvii\nxviii preface\nUnfortunately, of the hundreds of books written on stochastic processes, almost none\ndeal with computer systems. The examples in those books and the material covered areoriented toward operations research areas such as manufacturing systems, or human\noperators answering calls in a call center, or some assembly-line system with differentpriority jobs.\nIn many ways the analysis used in designing manufacturing systems is not all that\ndifferent from computer systems. There are many parallels between a human operatorand a computer server: There are faster human operators and slower ones (just ascomputer servers); the human servers sometimes get sick (just as computer serverssometimes break down); when not needed, human operators can be sent home to savemoney (just as computer servers can be turned off to save power); there is a startupoverhead to bringing back a human operator (just as there is a warmup cost to turningon a computer server); and the list goes on.\nHowever, there are also many differences between manufacturing systems and com-\nputer systems. To start, computer systems workloads have been shown to have ex-tremely high variability in job sizes (service requirements), with squared coefﬁcientsof variation upward of 100. This is very different from the low-variability service timescharacteristic of job sizes in manufacturing workloads. This difference in variabilitycan result in performance differences of orders of magnitude. Second, computer work-loads are typically preemptible, and time-sharing (Processor-Sharing) of the CPU isextremely common. By contrast, most manufacturing workloads are non-preemptive(ﬁrst-come-ﬁrst-serve service order is the most common). Thus most books on stochas-tic processes and queueing omit chapters on Processor-Sharing or more advanced pre-emptive policies like Shortest-Remaining-Processing-Time, which are very much atthe heart of computer systems. Processor-Sharing is particularly relevant when analyz-ing server farms, which, in the case of computer systems, are typically composed ofProcessor-Sharing servers, not First-Come-First-Served ones. It is also relevant in anycomputing application involving bandwidth being shared between users, which typi-\ncally happens in a processor-sharing style, not ﬁrst-come-ﬁrst-serve order. Performance\nmetrics may also be different for computer systems as compared with manufacturingsystems (e.g., power usage, an important metric for computer systems, is not mentionedin stochastic processes books). Closed-loop architectures, in which new jobs are notcreated until existing jobs complete, and where the performance goal is to maximizethroughput, are very common in computer systems, but are often left out of queueingbooks. Finally, the particular types of interactions that occur in disks, networking pro-tocols, databases, memory controllers, and other computer systems are very differentfrom what has been analyzed in traditional queueing books.\nThe Goal of This Book\nMany times I have walked into a fellow computer scientist’s ofﬁce and was pleased toﬁnd a queueing book on his shelf. Unfortunately, when questioned, my colleague wasquick to answer that he never uses the book because “The world doesn’t look like anM/M/1 queue, and I can’t understand anything past that chapter.” The problem is that\npreface xix\nthe queueing theory books are not “friendly” to computer scientists. The applications\nare not computer-oriented, and the assumptions used are often unrealistic for computersystems. Furthermore, these books are abstruse and often impenetrable by anyone whohas not studied graduate-level mathematics. In some sense this is hard to avoid: If onewants to do more than provide readers with formulas to “plug into,” then one has toteach them to derive their own formulas, and this requires learning a good deal of math.\nFortunately, as one of my favorite authors, Sheldon Ross, has shown, it ispossible to\nteach a lot of stochastic analysis in a fun and simple way that does not require ﬁrst\ntaking classes in measure theory and real analysis.\nMy motive in writing this book is to improve the design of computer systems by intro-\nducing computer scientists to the powerful world of queueing-theoretic modeling andanalysis. Personally, I have found queueing-theoretic analysis to be extremely valuablein much of my research including: designing routing protocols for networks, designingbetter scheduling algorithms for web servers and database management systems, diskscheduling, memory-bank allocation, supercomputing resource scheduling, and powermanagement and capacity provisioning in data centers. Content-wise, I have two goalsfor the book. First, I want to provide enough applications from computer systems tomake the book relevant and interesting to computer scientists. Toward this end, almost\nhalf the chapters of the book are “application” chapters. Second, I want to make the\nbook mathematically rich enough to give readers the ability to actually develop new\nqueueing analysis , not just apply existing analysis. As computer systems and their\nworkloads continue to evolve and become more complex, it is unrealistic to assumethat they can be modeled with known queueing frameworks and analyses. As a designerof computer systems myself, I am constantly ﬁnding that I have to invent new queueingconcepts to model aspects of computer systems.\nHow This Book Came to Be\nIn 1998, as a postdoc at MIT, I developed and taught a new computer science class,which I called “Performance Analysis and Design of Computer Systems.” The classhad the following description:\nIn designing computer systems one is usually constrained by certain performance\ngoals (e.g., low response time or high throughput or low energy). On the other hand,\none often has many choices: One fast disk, or two slow ones? What speed CPU will\nsufﬁce? Should we invest our money in more buffer space or a faster processor?How should jobs be scheduled by the processor? Does it pay to migrate active jobs?\nWhich routing policy will work best? Should one balance load among servers? How\ncan we best combat high-variability workloads? Often answers to these questions arecounterintuitive. Ideally, one would like to have answers to these questions before\ninvesting the time and money to build a system. This class will introduce students\nto analytic stochastic modeling, which allows system designers to answer questionssuch as those above.\nSince then, I have further developed the class via 10 more iterations taught within\nthe School of Computer Science at Carnegie Mellon, where I taught versions of the\nxx preface\nclass to both PhD students and advanced undergraduates in the areas of computer\nscience, engineering, mathematics, and operations research. In 2002, the OperationsManagement department within the Tepper School of Business at Carnegie Mellon\nmade the class a qualiﬁer requirement for all operations management students.\nAs other faculty, including my own former PhD students, adopted my lecture notes in\nteaching their own classes, I was frequently asked to turn the notes into a book. This is“version 1” of that book.\nOutline of the Book\nThis book is written in a question/answer style, which mimics the Socratic style that\nI use in teaching. I believe that a class “lecture” should ideally be a long sequenceof bite-sized questions, which students can easily provide answers to and which lead\nstudents to the right intuitions. In reading this book, it is extremely important to try\nto answer each question without looking at the answer that follows the question. The\nquestions are written to remind the reader to “think” rather than just “read,” and toremind the teacher to ask questions rather than just state facts.\nThere are exercises at the end of each chapter. The exercises are an integral part of the\nbook and should not be skipped. Many exercises are used to illustrate the applicationof the theory to problems in computer systems design, typically with the purpose ofilluminating a key insight. All exercises are related to the material covered in thechapter, with early exercises being straightforward applications of the material andlater exercises exploring extensions of the material involving greater difﬁculty.\nThe book is divided into seven parts, which mostly build on each other.\nPart Iintroduces queueing theory and provides motivating examples from computer\nsystems design that can be answered using basic queueing analysis. Basic queueing\nterminology is introduced including closed and open queueing models and performance\nmetrics.\nPart IIis a probability refresher. To make this book self-contained, we have included\nin these chapters all the probability that will be needed throughout the rest of the book.\nThis includes a summary of common discrete and continuous random variables, theirmoments, and conditional expectations and probabilities. Also included is some mate-rial on generating random variables for simulation. Finally we end with a discussion ofsample paths, convergence of sequences of random variables, and time averages versus\nensemble averages.\nPart IIIis about operational laws, or “back of the envelope” analysis. These are\nvery simple laws that hold for all well-behaved queueing systems. In particular, they\ndo not require that any assumptions be made about the arrival process or workload(like Poisson arrivals or Exponential service times). These laws allow us to quicklyreason at a high level (averages only) about system behavior and make design decisionsregarding what modiﬁcations will have the biggest performance impact. Applicationsto high-level computer system design are provided throughout.\npreface xxi\nPart IVis about Markov chains and their application toward stochastic analysis of\ncomputer systems. Markov chains allow a much more detailed analysis of systems\nby representing the full space of possible states that the system can be in. Whereas\nthe operational laws in Part IIIoften allow us to answer questions about the overall\nmean number of jobs in a system, Markov chains allow us to derive the probability\nof exactly ijobs being queued at server jof a multi-server system. Part IVincludes\nboth discrete-time and continuous-time Markov chains. Applications include Google’s\nPageRank algorithm, the Aloha (Ethernet) networking protocol, and an analysis of\ndropping probabilities in ﬁnite-buffer routers.\nPart Vdevelops the Markov chain theory introduced in Part IVto allow the analysis of\nmore complex networks, including server farms. We analyze networks of queues with\ncomplex routing rules, where jobs can be associated with a “class” that determines\ntheir route through the network (these are known as BCMP networks). Part Valso\nderives theorems on capacity provisioning of server farms, such as the “square-rootstafﬁng rule,” which determines the minimum number of servers needed to providecertain delay guarantees.\nThe fact that Parts IVandVare based on Markov chains necessitates that certain\n“Markovian” (memoryless) assumptions are made in the analysis. In particular, it is\nassumed that the service requirements (sizes) of jobs follow an Exponential distribu-tion and that the times between job arrivals are also Exponentially distributed. Manyapplications are reasonably well modeled via these Exponential assumptions, allowingus to use Markov analysis to get good insights into system performance. However,in some cases, it is important to capture the high-variability job size distributions orcorrelations present in the empirical workloads.\nPart VIintroduces techniques that allow us to replace these Exponential distributions\nwith high-variability distributions. Phase-type distributions are introduced, which allow\nus to model virtually any general distribution by a mixture of Exponentials , leverag-\ning our understanding of Exponential distributions and Markov chains from Parts IV\nandV. Matrix-analytic techniques are then developed to analyze systems with phase-\ntype workloads in both the arrival process and service process. The M/G/1 queueis introduced, and notions such as the Inspection Paradox are discussed. Real-world\nworkloads are described including heavy-tailed distributions. Transform techniquesare also introduced that facilitate working with general distributions. Finally, eventhe service order at the queues is generalized from simple ﬁrst-come-ﬁrst-served ser-vice order to time-sharing (Processor-Sharing) service order, which is more commonin computer systems. Applications abound: Resource allocation (task assignment) inserver farms with high-variability job sizes is studied extensively, both for server farmswith non-preemptive workloads and for web server farms with time-sharing servers.\nPower management policies for single servers and for data centers are also studied.\nPart VII, the ﬁnal part of the book, is devoted to scheduling. Smart scheduling is\nextremely important in computer systems, because it can dramatically improve system\nperformance without requiring the purchase of any new hardware. Scheduling is at theheart of operating systems, bandwidth allocation in networks, disks, databases, memoryhierarchies, and the like. Much of the research being done in the computer systems\nxxii preface\narea today involves the design and adoption of new scheduling policies. Scheduling can\nbe counterintuitive, however, and the analysis of even basic scheduling policies is farfrom simple. Scheduling policies are typically evaluated via simulation. In introducing\nthe reader to analytical techniques for evaluating scheduling policies, our hope is that\nmore such policies might be evaluated via analysis.\nWe expect readers to mostly work through the chapters in order, with the following\nexceptions: First, any chapter or section marked with a star (*) can be skipped without\ndisturbing the ﬂow. Second, the chapter on transforms, Chapter 25, is purposely moved\nto the end, so that most of the book does not depend on knowing transform analysis.However, because learning transform analysis takes some time, we recommend thatany teacher who plans to cover transforms introduce the topic a little at a time, startingearly in the course. To facilitate this, we have included a large number of exercises atthe end of Chapter 25that do not require material in later chapters and can be assigned\nearlier in the course to give students practice manipulating transforms.\nFinally, we urge readers to please check the following websites for new errors/software:\nhttp://www.cs.cmu.edu/\n∼harchol/PerformanceModeling/errata.html\nhttp://www.cs.cmu.edu/ ∼harchol/PerformanceModeling/software.html\nPlease send any additional errors to harchol@cs.cmu.edu.",17306
05-Acknowledgments.pdf,05-Acknowledgments,"Acknowledgments\nWriting a book, I quickly realized, is very different from writing a research paper, even\na very long one. Book writing actually bears much more similarity to teaching a class.That is why I would like to start by thanking the three people who most inﬂuenced myteaching. Manuel Blum, my PhD advisor, taught me the art of creating a lecture outof a series of bite-sized questions. Dick Karp taught me that you can cover an almostinﬁnite amount of material in just one lecture if you spend enough time in advancesimplifying that material into its cleanest form. Sheldon Ross inspired me by the depthof his knowledge in stochastic processes (a knowledge so deep that he never oncelooked at his notes while teaching) and by the sheer clarity and elegance of both hislectures and his many beautifully written books.\nI would also like to thank Carnegie Mellon University, and the School of Computer\nScience at Carnegie Mellon, which has at its core the theme of interdisciplinary re-search, particularly the mixing of theoretical and applied research. CMU has been theperfect environment for me to develop the analytical techniques in this book, all inthe context of solving hard applied problems in computer systems design. CMU hasalso provided me with a never-ending stream of gifted students, who have inspiredmany of the exercises and discussions in this book. Much of this book came from theresearch of my own PhD students, including Sherwin Doroudi, Anshul Gandhi, VarunGupta, Yoongu Kim, David McWherter, Takayuki Osogami, Bianca Schroeder, AdamWierman, and Timothy Zhu. In addition, Mark Crovella, Mike Kozuch, and particu-\nlarly Alan Scheller-Wolf, all longtime collaborators of mine, have inspired much of\nmy thinking via their uncanny intuitions and insights.\nA great many people have proofread parts of this book or tested out the book and\nprovided me with useful feedback. These include Sem Borst, Doug Down, ErhunOzkan, Katsunobu Sasanuma, Alan Scheller-Wolf, Thrasyvoulos Spyropoulos, JarodWang, and Zachary Young. I would also like to thank my editors, Diana Gillooly andLauren Cowles from Cambridge University Press, who were very quick to answer myendless questions, and who greatly improved the presentation of this book. Finally, I amvery grateful to Miso Kim, my illustrator, a PhD student at the Carnegie Mellon Schoolof Design, who spent hundreds of hours designing all the fun ﬁgures in the book.\nOn a more personal note, I would like to thank my mother, Irit Harchol, for making\nmy priorities her priorities, allowing me to maximize my achievements. I did not knowwhat this meant until I had a child of my own. Lastly, I would like to thank myhusband, Andrew Young. He won me over by reading all my online lecture notes anddoing every homework problem – this was his way of asking me for a ﬁrst date. Hisability to understand it all without attending any lectures made me believe that mylecture notes might actually “work” as a book. His willingness to sit by my side everynight for many months gave me the motivation to make it happen.\nxxiii",3087
06-Part I Introduction to Queueing.pdf,06-Part I Introduction to Queueing,"PART I\nIntroduction to Queueing\nPartIserves as an introduction to analytical modeling.\nWe begin in Chapter 1with a number of paradoxical examples that come up in the\ndesign of computer systems, showing off the power of analytical modeling in making\ndesign decisions.\nChapter 2introduces the reader to basic queueing theory terminology and notation\nthat is used throughout the rest of the book. Readers are introduced to both open and\nclosed queueing networks and to standard performance metrics, such as response time,throughput, and the number of jobs in the system.\n1",578
07-Chapter 1 Motivating Examples of the Power of Analytical Modeling.pdf,07-Chapter 1 Motivating Examples of the Power of Analytical Modeling,,0
08-1.1 What Is Queueing Theory.pdf,08-1.1 What Is Queueing Theory,"CHAPTER 1\nMotivating Examples of the\nPower of Analytical Modeling\n1.1 What Is Queueing Theory?\nQueueing theory is the theory behind what happens when you have lots of jobs,\nscarce resources, and subsequently long queues and delays. It is literally the “theoryof queues”: what makes queues appear and how to make them go away.\nImagine a computer system, say a web server, where there is only one job. The job\narrives, it uses certain resources (some CPU, some I/O), and then it departs. Given thejob’s resource requirements, it is very easy to predict exactly when the job will depart.There is no delay because there are no queues. If every job indeed got to run on its own\ncomputer, there would be no need for queueing theory. Unfortunately, that is rarely thecase.\nArrivin g customersServer\nFigure 1.1. Illustration of a queue, in which customers wait to be served, and a server. The\npicture shows one customer being served at the server and ﬁve others waiting in the queue.\nQueueing theory applies anywhere that queues come up (see Figure 1.1). We all have\nhad the experience of waiting in line at the bank, wondering why there are not more\ntellers, or waiting in line at the supermarket, wondering why the express lane is for 8\nitems or less rather than 15 items or less, or whether it might be best to actually have two\nexpress lanes, one for 8 items or less and the other for 15 items or less. Queues are also\nat the heart of any computer system. Your CPU uses a time-sharing scheduler to servea queue of jobs waiting for CPU time. A computer disk serves a queue of jobs waitingto read or write blocks. A router in a network serves a queue of packets waiting to be\nrouted. The router queue is a ﬁnite capacity queue, in which packets are dropped whendemand exceeds the buffer space. Memory banks serve queues of threads requestingmemory blocks. Databases sometimes have lock queues, where transactions wait toacquire the lock on a record. Server farms consist of many servers, each with its own\nqueue of jobs. The list of examples goes on and on.\nThe goals of a queueing theorist are twofold. The ﬁrst is predicting the system perfor-\nmance. Typically this means predicting mean delay or delay variability or the proba-\nbility that delay exceeds some Service Level Agreement (SLA). However, it can alsomean predicting the number of jobs that will be queueing or the mean number of servers\n3\n4 motivating examples of the power of analytical modeling\nbeing utilized (e.g., total power needs), or any other such metric. Although prediction\nis important, an even more important goal is ﬁnding a superior system design to im-\nprove performance. Commonly this takes the form of capacity planning, where one\ndetermines which additional resources to buy to meet delay goals (e.g., is it better tobuy a faster disk or a faster CPU, or to add a second slow disk). Many times, however,\nwithout buying any additional resources at all, one can improve performance just bydeploying a smarter scheduling policy or different routing policy to reduce delays.Given the importance of smart scheduling in computer systems, all of Part VIIof this\nbook is devoted to understanding scheduling policies.\nQueueing theory is built on a much broader area of mathematics called stochastic\nmodeling and analysis. Stochastic modeling represents the service demands of jobs and\nthe interarrival times of jobs as random variables. For example, the CPU requirementsof UNIX processes might be modeled using a Pareto distribution [ 84], whereas the\narrival process of jobs at a busy web server might be well modeled by a Poisson\nprocess with Exponentially distributed interarrival times. Stochastic models can alsobe used to model dependencies between jobs, as well as anything else that can berepresented as a random variable.\nAlthough it is generally possible to come up with a stochastic model that adequately\nrepresents the jobs or customers in a system and its service dynamics, these stochasticmodels are not always analytically tractable with respect to solving for performance.As we discuss in Part IV,Markovian assumptions , such as assuming Exponentially\ndistributed service demands or a Poisson arrival process, greatly simplify the analysis;\nhence much of the existing queueing literature relies on such Markovian assumptions.In many cases these are a reasonable approximation. For example, the arrival process ofbook orders on Amazon might be reasonably well approximated by a Poisson process,\ngiven that there are many independent users, each independently submitting requests\nat a low rate (although this all breaks down when a new Harry Potter book comesout). However, in some cases Markovian assumptions are very far from reality; forexample, in the case in which service demands of jobs are highly variable or arecorrelated.\nWhile many queueing texts downplay the Markovian assumptions being made, this\nbook does just the opposite. Much of my own research is devoted to demonstrating theimpact of workload assumptions on correctly predicting system performance. I havefound many cases where making simplifying assumptions about the workload can lead\nto very inaccurate performance results and poor system designs. In my own research,\nI therefore put great emphasis on integrating measured workload distributions into theanalysis. Rather than trying to hide the assumptions being made, this book highlights\nall assumptions about workloads. We will discuss speciﬁcally whether the workloadmodels are accurate and how our model assumptions affect performance and design,as well as look for more accurate workload models. In my opinion, a major reasonwhy computer scientists are so slow to adopt queueing theory is that the standardMarkovian assumptions often do not ﬁt. However, there are often ways to work aroundthese assumptions, many of which are shown in this book, such as using phase-typedistributions and matrix-analytic methods, introduced in Chapter 21.",5994
09-1.2 Examples of the Power of Queueing Theory.pdf,09-1.2 Examples of the Power of Queueing Theory,"1.2examples of the power of queueing theory 5\n1.2 Examples of the Power of Queueing Theory\nThe remainder of this chapter is devoted to showing some concrete examples of the\npower of queueing theory. Do notexpect to understand everything in the examples. The\nexamples are developed in much greater detail later in the book. Terms like “Poisson\nprocess” that you may not be familiar with are also explained later in the book. Theseexamples are just here to highlight the types of lessons covered in this book.\nAs stated earlier, one use of queueing theory is as a predictive tool , allowing one to\npredict the performance of a given system. For example, one might be analyzing a\nnetwork, with certain bandwidths, where different classes of packets arrive at certainrates and follow certain routes throughout the network simultaneously. Then queueingtheory can be used to compute quantities such as the mean time that packets spendwaiting at a particular router\ni, the distribution on the queue buildup at router i, or the\nmean overall time to get from router ito router jin the network.\nWe now turn to the usefulness of queueing theory as a design tool in choosing the\nbest system design to minimize response time. The examples that follow illustrate that\nsystem design is often a counterintuitive process.\nDesign Example 1 – Doubling Arrival Rate\nConsider a system consisting of a single CPU that serves a queue of jobs in First-Come-\nFirst-Served (FCFS) order, as illustrated in Figure 1.2. The jobs arrive according to some\nrandom process with some average arrival rate, say λ=3 jobs per second. Each job\nhas some CPU service requirement, drawn independently from some distribution of job\nservice requirements (we can assume any distribution on the job service requirements\nfor this example). Let’s say that the average service rate is μ=5jobs per second (i.e.,\neach job on average requires 1/5of a second of service). Note that the system is not\nin overload ( 3<5). LetE[T]denote the mean response time of this system, where\nresponse time is the time from when a job arrives until it completes service, a.k.a.\nsojourn time.\n λ = 3FCFS C PU\nµ = 5If λ 2λ, \nby how m uch \nshould µ  increase ? \nFigure 1.2. A system with a single CPU that serves jobs in FCFS order.\nQuestion: Your boss tells you that starting tomorrow the arrival rate will double. You\nare told to buy a faster CPU to ensure that jobs experience the same mean response\ntime,E[T]. That is, customers should not notice the effect of the increased arrival\nrate. By how much should you increase the CPU speed? (a) Double the CPU speed;(b) More than double the CPU speed; (c) Less than double the CPU speed.\nAnswer: (c) Less than double.\n6 motivating examples of the power of analytical modeling\nQuestion: Why not (a)?\nAnswer: It turns out that doubling CPU speed together with doubling the arrival\nrate will generally result in cutting the mean response time in half! We prove this in\nChapter 13. Therefore, the CPU speed does not need to double.\nQuestion: Can you immediately see a rough argument for this result that does not\ninvolve any queueing theory formulas? What happens if we double the service rate and\ndouble the arrival rate?\nAnswer: Imagine that there are two types of time: Federation time and Klingon time.\nKlingon seconds are faster than Federation seconds. In fact, each Klingon second is\nequivalent to a half-second in Federation time. Now, suppose that in the Federation,there is a CPU serving jobs. Jobs arrive with rate\nλjobs per second and are served at\nsome rate μjobs per second. The Klingons steal the system specs and reengineer the\nsame system in the Klingon world. In the Klingon system, the arrival rate is λjobs\nper Klingon second, and the service rate is μjobs per Klingon second. Note that both\nsystems have the same mean response time, E[T], except that the Klingon system\nresponse time is measured in Klingon seconds, while the Federation system response\ntime is measured in Federation seconds. Consider now that Captain Kirk is observingboth the Federation system and the Klingon reengineered system. From his perspective,the Klingon system has twice the arrival rate and twice the service rate; however, the\nmean response time in the Klingon system has been halved (because Klingon secondsare half-seconds in Federation time).\nQuestion: Suppose the CPU employs time-sharing service order (known as Processor-\nSharing, or PS for short), instead of FCFS. Does the answer change?\nAnswer: No. The same basic argument still works.\nDesign Example 2 – Sometimes “Improvements” Do Nothing\nConsider the batch system shown in Figure 1.3. There are always\nN=6 jobs in this\nsystem (this is called the multiprogramming level). As soon as a job completes service,\na new job is started (this is called a “closed” system). Each job must go through the“service facility.” At the service facility, with probability\n1/2the job goes to server 1,\nand with probability 1/2it goes to server 2. Server 1 services jobs at an average rate\nof 1 job every 3 seconds. Server 2 also services jobs at an average rate of 1 job every 3\nseconds. The distribution on the service times of the jobs is irrelevant for this problem.\nResponse time is deﬁned as usual as the time from when a job ﬁrst arrives at the service\nfacility (at the fork) until it completes service.\nN = 6 jobs\n½\n½µ=⅓ Server 1\nServer 2\nµ=⅓ \nFigure 1.3. A closed batch system.\n1.2examples of the power of queueing theory 7\nQuestion: You replace server 1 with a server that is twice as fast (the new server\nservices jobs at an average rate of 2 jobs every 3 seconds). Does this “improvement”\naffect the average response time in the system? Does it affect the throughput? (Assume\nthat the routing probabilities remain constant at 1/2and1/2.)\nAnswer: Not really. Both the average response time and throughput are hardly affected.\nThis is explained in Chapter 7.\nQuestion: Suppose that the system had a higher multiprogramming level, N. Does the\nanswer change?\nAnswer: No. The already negligible effect on response time and throughput goes to\nzero as Nincreases.\nQuestion: Suppose the system had a lower value of N. Does the answer change?\nAnswer: Yes. If Nis sufﬁciently low, then the “improvement” helps. Consider, for\nexample, the case N=1.\nQuestion: Suppose the system is changed into an open system, rather than a closed\nsystem, as shown in Figure 1.4, where arrival times are independent of service com-\npletions. Now does the “improvement” reduce mean response time?\nAnswer: Absolutely!\n½\n½µ=⅓ Server 1\nServer 2\nµ=⅓ \nFigure 1.4. An open system.\nDesign Example 3 – One Machine or Many?\nYou are given a choice between one fast CPU of speed s,o rnslow CPUs each of speed\ns/n (see Figure 1.5). Your goal is to minimize mean response time. To start, assume\nthat jobs are non-preemptible (i.e., each job must be run to completion).\nversusµ = 1\nµ = 1\nµ = 4\nµ = 1\nµ = 1\nFigure 1.5. Which is better for minimizing mean response time: many slow servers or one\nfast server?\n8 motivating examples of the power of analytical modeling\nQuestion: Which is the better choice: one fast machine or many slow ones?\nHint: Suppose that I tell you that the answer is, “It depends on the workload.” What\naspects of the workload do you think the answer depends on?\nAnswer: It turns out that the answer depends on the variability of the job size distribu-\ntion, as well as on the system load.\nQuestion: Which system do you prefer when job size variability is high?\nAnswer: When job size variability is high, we prefer many slow servers because we\ndo not want short jobs getting stuck behind long ones.\nQuestion: Which system do you prefer when load is low?\nAnswer: When load is low, not all servers will be utilized, so it seems better to go with\none fast server.These observations are revisited many times throughout the book.\nQuestion: Now suppose we ask the same question, but jobs are preemptible ; that is,\nthey can be stopped and restarted where they left off. When do we prefer many slow\nmachines as compared to a single fast machine?\nAnswer: If your jobs are preemptible, you could always use a single fast machine\nto simulate the effect of\nnslow machines. Hence a single fast machine is at least as\ngood.\nThe question of many slow servers versus a few fast ones has huge applicability in a\nwide range of areas, because anything can be viewed as a resource, including CPU,\npower, and bandwidth.\nFor an example involving power management in data centers, consider the problem\nfrom [ 69] where you have a ﬁxed power budget Pand a server farm consisting of\nnservers. You have to decide how much power to allocate to each server, so as\nto minimize overall mean response time for jobs arriving at the server farm. There\nis a function that speciﬁes the relationship between the power allocated to a server\nand the speed (frequency) at which it runs – generally, the more power you allocate\nto a server, the faster it runs (the higher its frequency), subject to some maximumpossible frequency and some minimum power level needed just to turn the server on.To answer the question of how to allocate power, you need to think about whetheryou prefer many slow servers (allocate just a little power to every server) or a few fast\nones (distribute all the power among a small number of servers). In [ 69], queueing\ntheory is used to optimally answer this question under a wide variety of parametersettings.\nAs another example, if bandwidth is the resource, we can ask when it pays to partition\nbandwidth into smaller chunks and when it is better not to. The problem is alsointeresting when performance is combined with price. For example, it is often cheaper(ﬁnancially) to purchase many slow servers than a few fast servers. Yet in some cases,many slow servers can consume more total power than a few fast ones. All of thesefactors can further inﬂuence the choice of architecture.\n1.2examples of the power of queueing theory 9\nDesign Example 4 – Task Assignment in a Server Farm\nConsider a server farm with a central dispatcher and several hosts. Each arriving job is\nimmediately dispatched to one of the hosts for processing. Figure 1.6illustrates such\na system.\nHost 1\nHost 2\nHost 3Dispatcher \n(Load Balancer)Arrivals\nFigure 1.6. A distributed server system with a central dispatcher.\nServer farms like this are found everywhere. Web server farms typically deploy a\nfront-end dispatcher like Cisco’s Local Director or IBM’s Network Dispatcher. Super-computing sites might use LoadLeveler or some other dispatcher to balance load and\nassign jobs to hosts.\nFor the moment, let’s assume that all the hosts are identical (homogeneous) and that\nall jobs only use a single resource. Let’s also assume that once jobs are assigned to ahost, they are processed there in FCFS order and are non-preemptible.\nThere are many possible task assignment policies that can be used for dispatching jobs\nto hosts. Here are a few:\nRandom: Each job ﬂips a fair coin to determine where it is routed.\nRound-Robin: The\nith job goes to host imodn, where nis the number of hosts,\nand hosts are numbered 0,1,...,n−1.\nShortest-Queue: Each job goes to the host with the fewest number of jobs.\nSize-Interval-Task-Assignment (SITA): “Short” jobs go to the ﬁrst host, “medium”\njobs go to the second host, “long” jobs go to the third host, etc., for some deﬁnition\nof “short,” “medium,” and “long.”\nLeast-Work-Left (LWL): Each job goes to the host with the least total remaining\nwork, where the “work” at a host is the sum of the sizes of jobs there.\nCentral-Queue: Rather than have a queue at each host, jobs are pooled at one central\nqueue. When a host is done working on a job, it grabs the ﬁrst job in the central\nqueue to work on.\nQuestion: Which of these task assignment policies yields the lowest mean response\ntime?\n10 motivating examples of the power of analytical modeling\nAnswer: Given the ubiquity of server farms, it is surprising how little is known about\nthis question. If job size variability is low, then the LWL policy is best. If job size\nvariability is high, then it is important to keep short jobs from getting stuck behind long\nones, so a SITA-like policy, which affords short jobs isolation from long ones, can be\nfar better. In fact, for a long time it was believed that SITA is always better than LWLwhen job size variability is high. However, it was recently discovered (see [ 90]) that\nSITA can be far worse than LWL even under job size variability tending to inﬁnity. Itturns out that other properties of the workload, including load and fractional moments\nof the job size distribution, matter as well.\nQuestion: For the previous question, how important was it to know the size of jobs?\nFor example, how does LWL, which requires knowing job size, compare with Central-\nQueue, which does not?\nAnswer: Actually, most task assignment policies do not require knowing the size of\njobs. For example, it can be proven by induction that LWL is equivalent to Central-\nQueue. Even policies like SITA, which by deﬁnition are based on knowing the job size,can be well approximated by other policies that do not require knowing the job size;see [82].\nQuestion: Now consider a different model, in which jobs are preemptible. Speciﬁcally,\nsuppose that the servers are Processor-Sharing (PS) servers, which time-share amongall the jobs at the server, rather than serving them in FCFS order. Which task assignmentpolicy is preferable now? Is the answer the same as that for FCFS servers?\nAnswer: The task assignment policies that are best for FCFS servers are often a\ndisaster under PS servers. For PS servers, the Shortest-Queue policy is near optimal\n([79]), whereas that policy is pretty bad for FCFS servers if job size variability is high.\nThere are many open questions with respect to task assignment policies. The case of\nserver farms with PS servers, for example, has received almost no attention, and eventhe case of FCFS servers is still only partly understood. There are also many othertask assignment policies that have not been mentioned. For example, cycle stealing\n(taking advantage of a free host to process jobs in some other queue) can be combinedwith many existing task assignment policies to create improved policies. There are alsoother metrics to consider, like minimizing the variance of response time, rather thanmean response time, or maximizing fairness. Finally, task assignment can become evenmore complex, and more important, when the workload changes over time.\nTask assignment is analyzed in great detail in Chapter 24, after we have had a chance\nto study empirical workloads.\nDesign Example 5 – Scheduling Policies\nSuppose you have a single server. Jobs arrive according to a Poisson process. Assume\nanything you like about the distribution of job sizes. The following are some possible\nservice orders (scheduling orders) for serving jobs:\nFirst-Come-First-Served (FCFS): When the server completes a job, it starts working\non the job that arrived earliest.\n1.2examples of the power of queueing theory 11\nNon-Preemptive Last-Come-First-Served (LCFS): When the server completes a\njob, it starts working on the job that arrived last.\nRandom: When the server completes a job, it starts working on a random job.\nQuestion: Which of these non-preemptive service orders will result in the lowest mean\nresponse time?\nAnswer: Believe it or not, they all have the same mean response time.\nQuestion: Suppose we change the non-preemptive LCFS policy to a Preemptive-LCFS\npolicy (PLCFS), which works as follows: Whenever a new arrival enters the system,\nit immediately preempts the job in service. How does the mean response time of thispolicy compare with the others?\nAnswer: It depends on the variability of the job size distribution. If the job size\ndistribution is at least moderately variable, then PLCFS will be a huge improvement.\nIf the job size distribution is hardly variable (basically constant), then PLCFS policywill be up to a factor of 2 worse.\nWe study many counterintuitive scheduling theory results toward the very end of the\nbook, in Chapters 28through 33.\nMore Design Examples\nThere are many more questions in computer systems design that lend themselves to a\nqueueing-theoretic solution.\nOne example is the notion of a setup cost . It turns out that it can take both signiﬁcant time\nand power to turn ona server that is off. In designing an efﬁcient power management\npolicy, we often want to leave servers off(to save power), but then we have to pay the\nsetup cost to get them back on when jobs arrive. Given performance goals, both with\nrespect to response time and power usage, an important question is whether it pays toturn a server off. If so, one can then ask exactly how many servers should be left on.These questions are discussed in Chapters 15and27.\nThere are also questions involving optimal scheduling when jobs have priorities (e.g.,certain users have paid more for their jobs to have priority over other users’ jobs, orsome jobs are inherently more vital than others). Again, queueing theory is very usefulin designing the right priority scheme to maximize the value of the work completed.\nFigure 1.7. Example of a difﬁcult problem: The M/G/2 queue consists of a single queue and\ntwo servers. When a server completes a job, it starts working on the job at the head of the\nqueue. Job sizes follow a general distribution, G.\n12 motivating examples of the power of analytical modeling\nHowever, queueing theory (and more generally analytical modeling) is notcurrently\nall-powerful! There are lots of very simple problems that we can at best only analyze\napproximately. As an example, consider the simple two-server network shown in\nFigure 1.7, where job sizes come from a general distribution. No one knows how to\nderive mean response time for this network. Approximations exist, but they are quite\npoor, particularly when job size variability gets high [ 76]. We mention many such open\nproblems in this book, and we encourage readers to attempt to solve these!",18230
10-Chapter 2 Queueing Theory Terminology.pdf,10-Chapter 2 Queueing Theory Terminology,,0
11-2.1 Where We Are Heading.pdf,11-2.1 Where We Are Heading,,0
12-2.2 The Single-Server Network.pdf,12-2.2 The Single-Server Network,"CHAPTER 2\nQueueing Theory Terminology\n2.1 Where We Are Heading\nQueueing theory is the study of queueing behavior in networks and systems. Figure 2.1\nshows the solution process.\nReal-world system\nwith question:\n“Should we buy a faster\ndisk or a faster CPU?”\nTranslate backResultQueueing \nnetworkModel as\nAnalyze!\nFigure 2.1. Solution process.\nIn Chapter 1, we looked at examples of the power of queueing theory as a design tool.\nIn this chapter, we start from scratch and deﬁne the terminology used in queueing\ntheory.\n2.2 The Single-Server Network\nAqueueing network is made up of servers .\nThe simplest example of a queueing network is the single-server network , as shown\nin Figure 2.2. The discussion in this section is limited to the single-server network with\nFirst-Come-First-Served (FCFS) service order. You can think of the server as being a\nCPU.\nArrivin g jobs\nλ = 3FCFS\n= 4\nFigure 2.2. Single-server network.\n13\n14 queueing theory terminology\nThere are several parameters associated with the single-server network:\nService Order This is the order in which jobs will be served by the server. Unless\notherwise stated, assume First-Come-First-Served (FCFS).\nAverage Arrival Rate This is the average rate, λ, at which jobs arrive to the server\n(e.g.,λ=3jobs/sec).\nMean Interarrival Time This is the average time between successive job arrivals\n(e.g.,1/λ=1\n3sec).\nService Requirement, Size The “size” of a job is typically denoted by the random\nvariable S. This is the time it would take the job to run on this server if there were\nno other jobs around (no queueing). In a queueing model, the size (a.k.a. service\nrequirement) is typically associated with the server (e.g., this job will take 5seconds\non this server).\nMean Service Time This is the expected value of S, namely the average time required\nto service a job on this CPU, where “service” does not include queueing time. InFigure 2.2,\nE[S]=1\n4sec.\nAverage Service Rate This is the average rate, μ, at which jobs are served (e.g.,\nμ=4jobs/sec =1\nE[S]).\nObserve that this way of speaking is different from the way we normally talk about\nservers in conversation. For example, nowhere have we mentioned the absolute speed\nof the CPU; rather we have only deﬁned the CPU’s speed in terms of the set of jobsthat it is working on.\nIn normal conversation, we might say something like the following:\nrThe average arrival rate of jobs is 3 jobs per second.\nrJobs have different service requirements, but the average number of cycles re-\nquired by a job is 5,000 cycles per job.\nrThe CPU speed is 20,000 cycles per second.\nThat is, an average of 15,000 cycles of work arrive at the CPU each second, and theCPU can process 20,000 cycles of work a second.\nIn the queueing-theoretic way of talking, we would never mention the word “cycle.”\nInstead, we would simply say\nrThe average arrival rate of jobs is 3 jobs per second.\nrThe average rate at which the CPU can service jobs is 4 jobs per second.\nThis second way of speaking suppresses some of the detail and thus makes the problem\na little easier to think about. You should feel comfortable going back and forth between\nthe two.\nWe consider these common performance metrics in the context of a single-server\nsystem:\nResponse Time, Turnaround Time, Time in System, or Sojourn Time ( T)We\ndeﬁne a job’s response time by T=tdepart−tarrive, where tdepart is the time when the\n2.2the single-server network 15\njob leaves the system, and tarriveis the time when the job arrived to the system. We\nare interested in E[T], the mean response time; Var(T), the variance in response\ntime; and the tail behavior of T,P{T>t}.\nWaiting Time or Delay ( TQ)This is the time that the job spends in the queue, not\nbeing served. It is also called the “time in queue” or the “wasted time.” Notice that\nE[T]=E[TQ]+E[S]. Under FCFS service order, waiting time can be deﬁned as\nthe time from when a job arrives to the system until it ﬁrst receives service.\nNumber of Jobs in the System ( N)This includes those jobs in the queue, plus the\none being served (if any).\nNumber of Jobs in Queue ( NQ)This denotes only the number of jobs waiting (in\nqueue).\nThere are some immediate observations that we can make about the single-server\nnetwork. First, observe that as λ, the mean arrival rate, increases, all the performance\nmetrics mentioned earlier increase (get worse). Also, as μ, the mean service rate,\nincreases, all the performance metrics mentioned earlier decrease (improve).\nWe require that λ≤μ(we always assume λ<μ ).\nQuestion: Ifλ>μ what happens?\nAnswer: Ifλ>μ the queue length goes to inﬁnity over time.\nQuestion: Can you provide the intuition?\nAnswer: Consider a large time t. Then, if N(t)is the number of jobs in the system\nat time t, andA(t)(respectively, D(t)) denotes the number of arrivals (respectively,\ndepartures) by time t, then we have:\nE[N(t)] =E[A(t)]−E[D(t)]≥λt−μt=t(λ−μ).\n(The inequality comes from the fact that the expected number of departures by time t\nis actually smaller than μt, because the server is not always busy). Now observe that if\nλ>μ , thent(λ−μ)→∞ ,a st→∞ .\nThroughout the book we assume λ<μ , which is needed for stability (keeping queue\nsizes from growing unboundedly). Situations where λ≥μare touched on in Chapter 9.\nQuestion: Given the previous stability condition ( λ<μ ), suppose that the interarrival\ndistribution and the service time distribution are Deterministic (i.e., both are constants).\nWhat is TQ? What is T?\nAnswer: TQ=0, andT=S.\nTherefore queueing (waiting) results from variability in service time and/or interarrival\ntime distributions. Here is an example of how variability leads to queues: Let’s discretize\ntime. Suppose at each time step, an arrival occurs with probability p=1/6. Suppose at\neach time step, a departure occurs with probability q=1/3. Then there is a non-zero\nprobability that the queue will build up (temporarily) if several arrivals occur without\na departure.",6022
13-2.3 Classification of Queueing Networks.pdf,13-2.3 Classification of Queueing Networks,,0
14-2.5 More Metrics Throughput and Utilization.pdf,14-2.5 More Metrics Throughput and Utilization,"16 queueing theory terminology\n2.3 Classiﬁcation of Queueing Networks\nQueueing networks can be classiﬁed into two categories: open networks andclosed\nnetworks . Stochastic processes books (e.g., [ 149,150]) usually limit their discussion\nto open networks. By contrast, the systems performance analysis books (e.g., [ 117,\n125]) almost exclusively discuss closed networks. Open networks are introduced in\nSection 2.4. Closed networks are introduced in Section 2.6.\n2.4 Open Networks\nAn open queueing network has external arrivals and departures. Four examples of open\nnetworks are illustrated in this section.\nExample: The Single-Server System\nThis was shown in Figure 2.2.\nExample: Network of Queues with Probabilistic RoutingThis is shown in Figure 2.3. Here server\nireceives external arrivals (“outside arrivals”)\nwith rate ri.S e r v e r ialso receives internal arrivals from some of the other servers. A\npacket that ﬁnishes service at server iis next routed to server jwith probability pij.\nWe can even allow the probabilities to depend on the “class” of the packet, so that not\nall packets have to follow the same routing scheme.\nServer 1\nµ1µ2\nServer 3Server 2\nµ3r2\nr3r1p12p2,out\np1,outp23\np31p13\nFigure 2.3. Network of queues with probabilistic routing.\nApplication: In modeling packet ﬂows in the Internet, for example, one could make\nthe class of the packet (and hence its route) depend on its source and destination IP\naddresses. In modeling delays, each wire might be replaced by a server that would beused to model the wire latency. The goal might be to predict mean round-trip times forpackets on a particular route, given the presence of the other packets. We solve this\nproblem in Chapter 18.\n2.5more metrics: throughput and utilization 17\nExample: Network of Queues with Non-Probabilistic Routing\nThis is shown in Figure 2.4. Here all jobs follow a predetermined route: CPU to disk 1\nto disk 2 to disk 1 to disk 2 to disk 1 and out.\nArrivin g\nJobs ( λ)CPU Disk 1\nDisk 22X aro und\n(Disk 1,2,1,2,1)\nFigure 2.4. Network of queues with non-probabilistic routing.\nExample: Finite Buffer\nAn example of a single-server network with ﬁnite buffer is shown in Figure 2.5.A n y\narrival that ﬁnds no room is dropped.\nλCPU\nSpace for 9 jobs\nplus 1 in serviceµCPU\nFigure 2.5. Single-server network with ﬁnite buffer capacity.\n2.5 More Metrics: Throughput and Utilization\nWe have already seen four performance metrics: E[N],E[T],E[NQ], andE[TQ].\nAlthough these were applied to a single-server system, they can also be used to describe\nperformance in a multi-server, multi-queue system. For example, E[T]would denote\nthe mean time a job spends in the whole system, including all time spent in variousqueues and time spent receiving service at various servers, whereas\nE[TQ]refers to just\nthe mean time the job “wasted” waiting in various queues. If we want to refer to just the\nith queue in such a system, we typically write E[Ni]to denote the expected number\nof jobs both queueing and in service at server i, andE[Ti]to denote the expected time\na job spends queueing and in service at server i.\nNow we introduce two new performance metrics: throughput and utilization. Through-\nput is arguably the performance metric most used in conversation. Everyone wantshigher throughput! Let’s see why.\nQuestion: How does maximizing throughput relate to minimizing response time? For\nexample, in Figure 2.6, which system has higher throughput?\n18 queueing theory terminology\nversusµ=⅓ λ = \n= λ = \nFigure 2.6. Comparing throughput of two systems.\nAnswer: We will see soon.\nLet’s start by deﬁning utilization.Device Utilization (\nρi)is the fraction of time device iis busy . Note our current\ndeﬁnition of utilization applies only to a single device (server). When the device isimplied, we simply write\nρ(omitting the subscript).\nSuppose we watch a device ifor a long period of time. Let τdenote the length of the\nobservation period. Let Bdenote the total time during the observation period that the\ndevice is non-idle (busy). Then\nρi=B\nτ.\nDevice Throughput ( Xi)is the rate of completions at device i(e.g., jobs/sec). The\nthroughput (X)of the system is the rate of job completions in the system.\nLetCdenote the total number of jobs completed at device iduring time τ. Then\nXi=C\nτ.\nSo how does Xirelate to ρi? Well,\nC\nτ=/parenleftbiggC\nB/parenrightbigg\n·B\nτ.\nQuestion: So what isC\nB?\nAnswer: Well,B\nC=E[S].S oC\nB=1\nE[S]=μi.\nSo we have\nXi=μi·ρi.\nHere is another way to derive this expression by conditioning:\nXi=Mean rate of completion at server i\n=E[Rate of completion at server i|server iis busy ]·P{server iis busy}\n+E[Rate of completion at server i|server iis idle]·P{server iis idle}\n=μi·P{server iis busy}+0\n=μi·ρi\n2.5more metrics: throughput and utilization 19\nOr, equivalently,\nρi=Xi·E[S].\nThis latter formulation has a name: the Utilization Law .\nExample: Single-Server Network: What Is the Throughput?\nIn Figure 2.7we have a single-server system.\n=⅓ λ = FCFS\nFigure 2.7. Single-server model.\nQuestion: What is X?\nAnswer: X=ρ·μ. But what is ρ? In Chapter 6, we will prove that ρ=λ\nμ. For now\nhere is a hand-wavy but intuitive way to see this, but nota proof!!\nρ=Fraction of time server is busy\n=Average service time required by a job\nAverage time between arrivals\n=1/μ\n1/λ\n=λ\nμ.\nSo, this leaves us with\nX=ρ·μ=λ\nμ·μ=λ.\nSo the throughput does not depend on the service rate whatsoever!In particular, in the example shown in Figure 2.6, repeated again in Figure 2.8, both\nsystems have the same throughput of\n1/6jobs/sec. In the case of the faster processor,\nthe response time drops and the queue length drops, but Xdoes not change. Therefore\nlower response time is notrelated to higher throughput.\nversus=⅓ λ = \n= λ = \nFigure 2.8. Same model, but different values of μ. Throughput, X, is the same in both.\nQuestion: Explain why Xdoes not change.\nAnswer: No matter how high we make μ, the completion rate is still bounded by the\narrival rate: “rate in =rate out.” Changing μaffects the maximum possible X,b u t",6130
15-2.6 Closed Networks.pdf,15-2.6 Closed Networks,"20 queueing theory terminology\nnot the actual X. Note that because we assume a stable system, then, for large t, the\nnumber of arrivals during tis approximately the number of completions during t.\nExample: Probabilistic Network of Queues: What is the Throughput?\nFor Figure 2.3,ridenotes the average outside arrival rate into server i, andμidenotes\nthe average service rate at server i.\nQuestion: What is the system throughput, X, in Figure 2.3?\nAnswer: X=/summationtext\niri.\nQuestion: What is the throughput at server i,Xi?\nAnswer: Letλidenote the total arrival rate into server i. Then Xi=λi. But to get λi\nwe need to solve these simultaneous equations:\nλi=ri+/summationdisplay\njλjPji (2.1)\nQuestion: How are the ri’s constrained in these equations?\nAnswer: For the network to reach “equilibrium” (ﬂow into server = ﬂow out of server),\nwe must have λi<μ i,∀i, and this constrains the ri’s (see Exercise 2.1).\nExample: Network of Queues with Non-Probabilistic Routing:\nWhat is the Throughput?\nQuestion: What is Xin Figure 2.4?\nAnswer: X=λ.\nQuestion: What are XDisk1 andXDisk2?\nAnswer: XDisk1=3λandXDisk2=2λ.\nExample: Finite Buffer: What is the Throughput?\nFor Figure 2.5, the outside arrival rate is λand the service rate is μ.\nQuestion: What is X?\nAnswer: X=ρμ. But we need stochastic analysis to determine ρbecause it is no\nlonger simply λ/μ. Observe that X<λ because some arrivals get dropped.\n2.6 Closed Networks\nClosed queueing networks have no external arrivals or departures. They can be classiﬁed\ninto two categories as shown in Figure 2.9.\nClosed networks\nInteractive\n(terminal-driven)Batch system\nFigure 2.9. Closed network categories.\n2.6closed networks 21\n2.6.1 Interactive (Terminal-Driven) Systems\nAn example of an interactive (terminal-driven) system is shown in Figure 2.10.T e r -\nminals represent users who each send a job to the “central subsystem” and then wait\nfor a response. The central subsystem is a network of queues. A user cannot submit\nher next job before her previous job returns. Thus, the number of jobs in the system is\nﬁxed (equal to the number of terminals). This number is sometimes called the load or\nMPL (multiprogramming level), not to be confused with device utilization.\nCentral s ubsystemN user terminals\ntuo ni\nFigure 2.10. Interactive system.\nThere is a think time ,Z, which is a random variable representing the time at each\nterminal between receiving the result of one job and sending out the next job. Note\nthat the number of jobs in the central subsystem is at most the number of terminals,\nbecause some users might be in the “thinking” state.\nAn example of an interactive system such as the one shown in Figure 2.10 is a data-\nentry application. Nusers each sit at terminals ﬁlling out the entries on their screens.\nSeveral ﬁelds of the screen must be ﬁlled out, and then the whole screen is submitted\nto the central subsystem for appropriate processing and database update. A new screen\ncannot be ﬁlled out until the previous update is performed. The “think time,” Z, is the\ntime to key data to the screen.\nAn individual user (terminal) oscillates between the think state and the submitted state\nas shown in Figure 2.11.\nThink state Think state Think state\nSubmitted state\nin o utSubmitted state\nFigure 2.11. The user alternates between thinking and waiting for the submitted job to return.\n22 queueing theory terminology\nQuestion: How would you deﬁne the response time for the interactive system?\nAnswer: Response time is the time it takes a job to go between “in” and “out” in\nFigures 2.10 and 2.11. We denote the average time to get from “in” to “out” by\nE[Response Time ]orE[R]to differentiate it from E[T], which is deﬁned as\nE[T]=E[R]+E[Z]\nImportant: Although “response time” in open systems is denoted by the random\nvariable (r.v.) T, for closed interactive systems, we refer to Tas the system time (or\n“time in system”) and reserve the r.v. Rforresponse time .\nGoal: The goal in an interactive system is to ﬁnd a way to allow as many users\nas possible to get onto the system at once, so they can all get their work done,\nwhile keeping E[R]low enough. Note that interactive systems are very different\nfrom open systems in that a small change in Nhas a profound effect on the system\nbehavior.\nThe typical questions asked by systems designers are:\nrGiven the original system, how high can I make Nwhile keeping E[R]below\nsome threshold? That is, how does E[R]rise with N?\nrAssume a ﬁxed multiprogramming level, N. Given that we can make changes\nto the central subsystem (i.e., make certain devices faster), which changes will\nimprove E[R]the most?\nQuestion: Say we are modeling performance at a website. Would you model the\nwebsite as a closed interactive system or an open system?\nAnswer: The jury is still out. There are research papers of both types. On the one hand,\nonce a user clicks on a link (submits a job), he typically waits to receive the result\nbefore clicking on another link. Thus users behave as if the website is a closed system.On the other hand, a website may have a huge number of users, each of whom is very\ntransient in his or her use of the website. In this respect, the website might behave morelike an open system.\nSchroeder et al. [ 165] proposes the idea of a “partly-open” system. Here users arrive\nfrom outside as in an open system, but make\nkrequests to the system when they arrive,\nwhere each request can only be made when the previous request completes (as in a\nclosed system).\n2.6.2 Batch Systems\nAn example of a batch system is shown in Figure 2.12. A batch system looks like an\ninteractive system with a think time of zero. However, the goals are somewhat differentfor batch systems. In a batch system, typically one is running many jobs overnight. As\nsoon as one job completes, another one is started. So there are always\nNjobs in the\ncentral subsystem. The MPL is usually predetermined and ﬁxed. For example the MPL\nmight be the number of jobs that ﬁt into memory.\n2.6closed networks 23\nCentral s ubsystemN user terminals\nFigure 2.12. Batch system.\nGoal: For a batch system, the goal is to obtain high throughput , so that as many jobs\nas possible are completed overnight.\nThe typical question asked by systems designers is, “How can we improve the central\nsubsystem so as to maximize throughput?”\nNote that we are typically constrained by some ﬁxed maximum MPL (because only so\nmany jobs ﬁt into memory or for some other reason). Thus the only method we have\nfor increasing throughput is changing the central subsystem, either by changing therouting or by speeding up some device. Observe that in the batch system we are notconcerned with response times because the jobs are running overnight.\nQuestion: What does\nXmean in a closed system?\nAnswer: Xis the number of jobs crossing “out” per second. Note that “in” = “out” for\nthe batch system.\n2.6.3 Throughput in a Closed System\nLet’s look at some examples.\nExample: Single Server\nFigure 2.13 shows a closed network consisting of a single server.\nMPL = N\nµ\nFigure 2.13. Single-server closed network.\nQuestion: What is the throughput, X, in Figure 2.13?\nAnswer: X=μ.\nObserve that this is very different from the case of the open network where throughput\nwas independent of service rate!",7353
16-2.9 Exercises.pdf,16-2.9 Exercises,"24 queueing theory terminology\nQuestion: What is the mean response time, E[R], in Figure 2.13?\nAnswer: For a closed batch system, E[R]=E[T], namely the response time and\ntime in system are the same. For Figure 2.13,E[T]=N/μ , because every “arrival”\nwaits behind N−1jobs and then runs.\nNote that XandE[R]are inversely related!\nExample: Tandem Servers\nNow consider the example of a more complicated closed network, as shown in Fig-\nure2.14.\nMPL = N\nµ2 µ1\nFigure 2.14. Tandem servers closed network.\nQuestion: What is the throughput?\nAnswer: We would like to say X=m i n ( μ1,μ2)...\nQuestion: Why is this previous answer not necessarily correct?\nAnswer: The previous answer is correct if we know that the slower server is always\nbusy, but that is not necessarily the case. Imagine N=1. Then it is certainly not the\ncase that the slower server is always busy.\nQuestion: OK, but what happens when N=2. Now it appears that there is always at\nleast one job at the slow server, doesn’t it?\nAnswer: Nope, the slower server is still not always busy. What we’re missing here is\nthe fact that sometimes the slow server is faster than the fast server – because these\nservice rates are just averages! So do we in fact need to take the job size distributioninto account to get the exact answer? Does the job size distribution really affect the\nanswer very much?\nWe will answer these questions soon enough ...F o rn o w , let’s sum up the differences\nbetween the behavior of open and closed networks and why we need to consider both.\n2.7 Differences between Closed and Open Networks\nOpen Systems\nrThroughput, X, is independent of the μi’s\nrXis not affected by doubling the μi’s.\nrThroughput and response time are notrelated.\n2.8related readings 25\nClosed Systems\nrXdepends on μi’s.\nrIf we double all the μi’s while holding Nconstant, then Xchanges.\nrIn fact we see in Chapter 6that for closed systems,\nHigher throughput ⇐⇒ Lower avg. response time .\n2.7.1 A Question on Modeling\nHere is a ﬁnal question: A few years ago I got a call from some folks at IBM. They\nwere trying to model their blade server as a single-server queue. They knew the arrival\nrate into the server, λ, in jobs/sec. However they were wondering how to get E[S], the\nmean job size.\nQuestion: How do you obtain E[S]in practice for your single-server system?\nAnswer: At ﬁrst glance, you might reason that because E[S]is the mean time required\nfor a job in isolation, you should just send a single job into the system and measure\nits response time, repeating that experiment a hundred times to get an average. This\nmakes sense in theory, but does not work well in practice, because cache conditions\nand other factors are very different for the scenario of just a single job compared withthe case when the system has been loaded for some time.\nA better approach is to recall that\nE[S]=1\nμ, so it sufﬁces to think about the service\nrate of the server in jobs/second. To get μ, assuming an open system, we can make λ\nhigher and higher, which will increase the completion rate, until the completion rate\nlevels off at some value, which will be rate μ.\nAn even better idea is to put our server into a closed system, with zero think time. This\nway the server is guaranteed to always be occupied with work. Now, if we measure thecompletion rate at the server (jobs completing per second), then that will give us\nμfor\nthe server. E[S]is then the reciprocal of μ.\n2.8 Related Readings\nEspecially helpful in understanding closed queueing networks are Lazowska (pp. 58–\n59) [ 117] and Menasc ´e (pp. 84–87) [ 125]. Both of these are wonderful books.\nThere is surprisingly very little known in the literature on how closed systems compare\nto open systems. For example, consider a closed interactive single-server system withload\nρ, versus the corresponding open system with load ρ. How do these compare to\neach other with respect to their mean response time? How does variability in service\ntime affect closed systems versus open ones? These questions and many others are\nconsidered in [ 186] and [ 24], as well as in Exercises 7.2,7.5,13.7, and 13.8. Another\nquestion is how the scheduling policy (service order) at the server affects closed systems\nversus open systems. This question was not really discussed until 2006 [ 165]. For a\n26 queueing theory terminology\nmore recent discussion of the open versus closed topic, we recommend the book by\nY. C . Ta y [ 173].\nIn this chapter, we have mentioned several times that ensuring that the arrival rate is\nless than the service rate ( λ<μ )i snecessary for stability. This condition will also be\nsufﬁcient to ensure stability of the networks we consider in this book. However, it is\nnot generally a sufﬁcient condition for stability in more complex queueing networks.\nTo understand why, we recommend the papers of Maury Bramson (see [ 29]).\n2.9 Exercises\n2.1 Maximum Outside Arrival Rate\nFor the network-of-queues with probabilistic routing given in Figure 2.3, sup-\npose that each server serves at an average rate of 10 jobs/sec; that is, μi=1 0 ,∀i.\nSuppose that r2=r3=1. Suppose that p12=p2,out=0.8,p23=p13=0.2,\np1,out=0, andp31=1. What is the maximum allowable value of r1to keep\nthis system stable?\n2.2 Slowdown\n(a) Jobs arrive at a server that services them in FCFS order:\nFCFS\nThe average arrival rate is λ=1\n2job/sec. The job sizes (service times) are\nindependently and identically distributed according to random variable S\nwhere\nS=/braceleftbigg\n1with probability 3/4\n2otherwise.\nYou have measured the mean response time: E[T]=29\n12.\nBased on this information, compute the mean slowdown, E[Slowdown ],\nwhere the slowdown of job jis deﬁned as Slowdown (j)=T(j)\nS(j), where\nT(j)is the response time of job jandS(j)is the size of job j.\n(b) If the service order in part (a) had been Shortest-Job-First (SJF), would the\nsame technique have worked for computing mean slowdown?\n2.3 Scheduling Orders\n(a) For a single-server CPU, where jobs arrive according to some process,\nlet SRPT denote the preemptive scheduling policy that always serves the\njob with the currently Shortest-Remaining-Processing-Time (assume one\nknows this information). It is claimed that for any arrival sequence , con-\nsisting of the arrival time and size of every job, SRPT scheduling mini-\nmizes mean response time over that arrival sequence. Prove or disprove thisclaim.\n2.9exercises 27\n(b) The slowdown of a job is deﬁned as the job’s response time divided by\nits service requirement. (i) Mean slowdown is thought by many to be amore important performance metric than mean response time. Why do youthink this is? (ii) It seems intuitive that the SRPT scheduling policy shouldminimize mean slowdown. Prove or disprove this hypothesis.",6815
17-Part II Necessary Probability Background.pdf,17-Part II Necessary Probability Background,"PART II\nNecessary Probability\nBackground\nProbability is an important part of analytical modeling. Part IIprovides all the prob-\nability that we will need throughout this book. Chapter 3provides a quick review of\nundergraduate probability. Chapter 4reviews two methods for generating random vari-\nables, which will be important in simulating queues. Finally, Chapter 5discusses more\nadvanced topics, like sample paths, convergence of sequences of random variables,\nand different types of averages, such as time averages and ensemble averages. Theseconcepts are important and are referred to throughout the book; however they are alsodifﬁcult, and it is reasonable that a reader might want to skim Chapter 5during a ﬁrst\nreading and return to the chapter for a more in-depth reading after covering Markovchains in Chapters 8and9.\n29",840
18-Chapter 3 Probability Review.pdf,18-Chapter 3 Probability Review,,0
19-3.8 Probabilities and Densities.pdf,19-3.8 Probabilities and Densities,"CHAPTER 3\nProbability Review\nIn this book, we assume a knowledge of undergraduate probability, including both\ndiscrete and continuous random variables. The ﬁrst three chapters (about 180 pages)of Sheldon Ross’s book, Introduction to Probability Models [150], provide excellent\ncoverage of these topics, and we encourage readers to look there. In this chapter we\nprovide a brief review of the speciﬁc probabilistic concepts that we will need in thisbook, by way of some simple illustrative examples. We start with a discussion ofprobability on events and then move on to random variables. Working through theseexamples, plus the exercises at the end of this chapter, should sufﬁce as a review of\nundergraduate probability for the purposes of this book.\n3.1 Sample Space and Events\nProbability is typically deﬁned in terms of some experiment . The sample space ,Ω,\nof the experiment is the set of all possible outcomes of the experiment.\nDeﬁnition 3.1 Anevent ,E, is any subset of the sample space, Ω.\nFor example, in an experiment where two dice are rolled, each outcome (a.k.a. sample\npoint) is denoted by the pair (i,j), where iis the ﬁrst roll and jis the second roll.\nThere are 36 sample points. We can consider the event\nE={(1,3)or(2,2)or(3,1)}\nthat the sum of the dice rolls is 4.\nIn general, the sample space may be discrete , meaning that the number of outcomes is\nﬁnite, or at least countably inﬁnite, or continuous , meaning that the number of outcomes\nis uncountable.One can talk of unions and intersections of events, because they are also sets (e.g.,\nE∪F,E∩F, andEC, where EandFare events and EC, the complement of E,\ndenotes the set of points in Ωbut not in E).\nQuestion: For the dice-rolling experiment, consider events E1andE2deﬁned on Ωin\nFigure 3.1. Do you think that E1andE2are independent?\nAnswer: No, they are not independent. We get to this later when we deﬁne indepen-\ndence. We say instead that E1andE2are mutually exclusive.\n31\n32 probability review\n(1,1)      (1,2)      (1,3)      (1,4)      (1,5)      (1,6)   \n(2,1)      (2,2)      (2,3)      (2,4)      (2,5)      (2,6)   (3,1)      (3,2)      (3,3)      (3,4)      (3,5)      (3,6)   \n(4,1)      (4,2)      (4,3)      (4,4)      (4,5)      (4,6)   \n(5,1)      (5,2)      (5,3)      (5,4)      (5,5)      (5,6)   \n(6,1)      (6,2)      (6,3)      (6,4)      (6,5)      (6,6)   Ω =E2 E1\nFigure 3.1. Illustration of two events in sample space Ω.\nDeﬁnition 3.2 IfE1∩E2=∅, thenE1andE2aremutually exclusive .\nDeﬁnition 3.3 IfE1,E2,...,Enare events such that Ei∩Ej=∅,∀i, j, and such\nthat/uniontextn\ni=1Ei=F, then we say that events E1,E2,...,Enpartition setF.\n3.2 Probability Deﬁned on Events\nProbability is deﬁned on events.\nP{E}=probability of event Eoccurring.\nWe can think of each sample point as having some probability of occurring, and the\nprobability that event Eoccurs is the sum of the probabilities of the sample points\ninE. For example, in the two-dice example, each sample point (an ordered pair of\nnumbers) occurs with a probability of1\n36.\nImportantly the probability of Ω, where Ωis the sample space, is deﬁned to be 1.\nDeﬁnition 3.4 The probability of the union of two events is deﬁned as follows:\nP{E∪F}=P{E}+P{F}−P{E∩F}\nThis should make sense if we think of events as sets as shown in Figure 3.2. Observe\nthat the subtraction of the P{E∩F}term is necessary so that those sample points\nare not counted twice.\n= Sample poin tEF\nFigure 3.2. Venn diagram.\n3.3conditional probabilities on events 33\nTheorem 3.5 P{E∪F}≤P{E}+P{F}.\nProof This follows immediately from Deﬁnition 3.4.\nQuestion: When is Theorem 3.5an equality?\nAnswer: When EandFare mutually exclusive.\nQuestion: Suppose your experiment involves throwing a dart, which is equally likely\nto land anywhere in the interval [0,1]. What is the probability that the dart lands at\nexactly 0.3?\nAnswer: The probability of landing at exactly 0.3is deﬁned to be 0. To see this,\nsuppose that the probability were strictly greater than 0, say/epsilon1>0. Then the probability\nof landing at 0.5would also be /epsilon1, as would the probability of landing at any rational\npoint. But these different landing outcomes are mutually exclusive events, so their\nprobabilities add. Thus the probability of landing in the interval [0,1]would be greater\nthan1, which is not allowed, because P{Ω}=1. While the probability of landing\nat exactly 0.3is deﬁned to be 0, the probability of landing in the interval [0,0.3]is\ndeﬁned to be 0.3.\n3.3 Conditional Probabilities on Events\nDeﬁnition 3.6 The conditional probability of event Egiven event Fis written as\nP{E|F}and is given by the following, where we assume P{F}>0:\nP{E|F}=P{E∩F}\nP{F}(3.1)\nP{E|F}should be thought of as the probability that event Eoccurs, given that we\nhave narrowed our sample space to points in F. To see this, consider Figure 3.3, where\nP{E}=8\n42andP{F}=10\n42.\nEΩ\nF\nFigure 3.3. Sample space with 42 sample points.\nIf we imagine that we narrow our space to the 10 points in F, then the probability of\nbeing in set E, given we are in set F, should be 2out of 10. Indeed,\nP{E|F}=2\n10=2\n42\n10\n42=P{E∩F}\nP{F}.\n34 probability review\nExample: Table 3.1shows my sandwich choices each day. We deﬁne the “ﬁrst half of\nthe week” to be Monday through Wednesday (inclusive), and the “second half of the\nweek” to be Thursday through Sunday (inclusive).\nTable 3.1. My sandwich choices\nMon Tue Wed Thu Fri Sat Sun\nJelly Cheese Turkey Cheese Turkey Cheese None\nQuestion: What is P{Cheese|Second half of week }?\nAnswer: This is asking for the fraction of days in the second half of the week when\nI eat a cheese sandwich. The answer is clearly 2out of 4,o r2\n4. Alternatively, we can\nuse ( 3.1) as follows:\nP{Cheese|Second half of week }=P{Cheese &Second half}\nP{Second half}=2\n7\n4\n7=2\n4.\n3.4 Independent Events and Conditionally Independent Events\nDeﬁnition 3.7 Events EandFareindependent if\nP{E∩F}=P{E}·P{F}.\nQuestion: IfEandFare independent, what is P{E|F}?\nAnswer: Assuming P{F}>0,w eh a v e\nP{E|F}=P{E∩F}\nP{F}indpt=P{E}·P{F}\nP{F}=P{E}.\nThat is, P{E}is not affected by whether Fis true or not.\nQuestion: Can two mutually exclusive (non-null) events ever be independent?\nAnswer: No. In this case, P{E|F}=0/negationslash=P{E}.\nQuestion: Suppose one is rolling two dice. Which of these pairs of events are inde-\npendent?\n1.E1=“First roll is 6” and E2=“Second roll is 6”\n2.E1=“Sum of the rolls is 7” and E2=“Second roll is 4”\nAnswer: They are both independent!\nQuestion: Suppose we had deﬁned: E1=“Sum of the rolls is 8” and E2=“Second\nroll is 4.” Are they independent now?\nAnswer: No.\nA different notion of independence that comes up frequently in problems (see for\nexample, Exercise 3.20) is that of conditional independence.\n3.5law of total probability 35\nDeﬁnition 3.8 Two events EandFare said to be conditionally independent given\neventG, where P{G}>0,i f\nP{E∩F|G}=P{E|G}·P{F|G}.\nIndependence does not imply conditional independence and vice versa.\n3.5 Law of Total Probability\nObserve that the set Ecan be expressed as\nE=(E∩F)∪/parenleftbig\nE∩FC/parenrightbig\n.\nThat is, Eis the union of the set E∩Fand the set E∩FC, because any point in E\nis either also in For also notinF.\nNow observe that E∩FandE∩FCare mutually exclusive. Thus,\nP{E}=P{E∩F}+P/braceleftbig\nE∩FC/bracerightbig\n=P{E|F}P{F}+P/braceleftbig\nE|FC/bracerightbig\nP/braceleftbig\nFC/bracerightbig\nwhereP{FC}=1−P{F}.\nTheorem 3.9 is a generalization.\nTheorem 3.9 (Law of Total Probability) LetF1,F2,...,F npartition the state\nspaceΩ. Then,\nP{E}=n/summationdisplay\ni=1P{E∩Fi}\n=n/summationdisplay\ni=1P{E|Fi}·P{Fi}.\nProof\nE=n/uniondisplay\ni=1(E∩Fi).\nNow, because the events E∩Fi,i=1,...,n , are mutually exclusive, we have that\nP{E}=n/summationdisplay\ni=1P{E∩Fi}=n/summationdisplay\ni=1P{E|Fi}·P{Fi}.\nQuestion: Suppose we are interested in the probability that a certain type of transaction\nfails. We know that if there is a caching failure, then the transaction will fail withprobability\n5/6. We also know that if there is a network failure then the transaction\nwill fail with probability 1/4. Suppose that the network fails with probability 1/100,\n36 probability review\nand the cache fails with probability 1/100. Is this enough to tell us the probability that\nthe transaction will fail?\nAnswer: It is tempting to write\n(WRONG)\nP{transaction fails }=P{transaction fails |caching failure }·1\n100\n+P{transaction fails |network failure }·1\n100\n=5\n6·1\n100+1\n4·1\n100.\nQuestion: What is wrong with that solution?\nAnswer: The two events we conditioned on – a network failure and a caching failure –\ndo not necessarily partition the space. The sum of the probabilities of these events isclearly\n<1. Furthermore, there may be a non-zero probability that both failures occur.\nOne needs to be very careful that the events are both (i) mutually exclusive and (ii)\nsum to the whole sample space.\n3.6 Bayes Law\nSometimes, one needs to know P{F|E}, but all one knows is the reverse direction:\nP{E|F}. Is it possible to get P{F|E}fromP{E|F}? It turns out that it is,\nassuming that we also know P{E}andP{F}.\nTheorem 3.10 (Bayes Law)\nP{F|E}=P{E|F}·P{F}\nP{E}\nProof\nP{F|E}=P{E∩F}\nP{E}=P{E|F}·P{F}\nP{E}\nThe Law of Total Probability can be combined with Bayes Law as follows:\nLetF1,F2,...,F npartition Ω. Then we can write: P{E}=/summationtextn\nj=1P{E|Fj}·\nP{Fj}. This yields the following:\nTheorem 3.11 (Extended Bayes Law) LetF1,F2,...,F npartition Ω. Then\nP{F|E}=P{E|F}·P{F}\nP{E}=P{E|F}·P{F}/summationtextn\nj=1P{E|Fj}P{Fj}\n3.7discrete versus continuous random variables 37\nExample: A test is used to diagnose a rare disease. The test is only 95% accurate,\nmeaning that, in a person who has the disease it will report “positive” with probability\n95% (and negative otherwise), and in a person who does not have the disease, it will\nreport “negative” with probability 95% (and positive otherwise). Suppose that 1 in\n10,000 children get the disease.\nQuestion: A mom brings in her child to be tested. Given that the test comes back\npositive, how worried should the mom be?\nAnswer:\nP{Child has disease |Test positive}\n=P{Test Positive|Disease}·P{Disease}\nP{Test positive|Disease}·P{Disease}+P{Test positive|Healthy}·P{Healthy}\n=0.95·1\n10000\n0.95·1\n10000+0.05·9999\n10000\n=0.0019\nThus the probability that the child has the disease is only about 2 out of 1,000.\n3.7 Discrete versus Continuous Random Variables\nConsider an experiment, such as rolling two dice. Suppose that we are interested in\nthe sum of the two rolls. That sum could range anywhere from 2to12, with each of\nthese events having a different probability. A random variable, X, associated with this\nexperiment, is a way to represent the value of the experiment (in this case the sum ofthe rolls). Speciﬁcally, when we write\nX, it is understood that Xhas many instances,\nranging from 2to12and that different instances occur with different probabilities (e.g.,\nP{X=3}=2\n36).\nDeﬁnition 3.12 Arandom variable (r.v.) is a real-valued function of the outcome\nof an experiment.\nDeﬁnition 3.13 Adiscrete random variable can take on at most a countably inﬁnite\nnumber of possible values, whereas a continuous random variable can take on an\nuncountable set of possible values.\nQuestion: Which of these random variables is discrete and which is continuous?\n1.The sum of the rolls of two dice\n2.The number of arrivals at a website by time t\n3.The time until the next arrival at a website\n4.The CPU requirement of an HTTP request\n38 probability review\nAnswer: The ﬁrst of these can take on only a ﬁnite number of values – those between\n2 and 12 – so it clearly is a discrete r.v. The number of arrivals at a website can takeon the values:\n0,1,2,3,... namely a countable set; hence this is discrete as well.\nTime, in general, is modeled as a continuous quantity, even though there is a non-zerogranularity in our ability to measure time via a computer. Thus quantities three andfour above are continuous r.v.’s.\nWe use capital letters to denote random variables. For example, we might deﬁne\nXto\nbe a random variable equal to the sum of two dice. Then,\nP{X=7}=P{(1,6)or(2,5)or(3,4),..., or(6,1)}=1\n6.\nImportant: Because the “outcome of the experiment” is just an event, all the theorems\nthat we learned about events apply to random variables as well. In particular, the\nLaw of Total Probability holds. For example, if Ndenotes the number of arrivals at a\nwebsite by time t, thenN>10is an event. We can then use conditioning on events to\nget\nP{N>10}=P{N>10|weekday}·5\n7+P{N>10|weekend}·2\n7.\nAll of this will become more concrete once we study examples of common random\nvariables next.\n3.8 Probabilities and Densities\n3.8.1 Discrete: Probability Mass Function\nDiscrete random variables take on a countable number of values, each with some\nprobability.\nDeﬁnition 3.14 LetXbe a discrete r.v. Then the probability mass function (p.m.f.) ,\npX(·)ofX, is deﬁned as follows:\npX(a)=P{X=a},where/summationdisplay\nxpX(x)=1\nThe cumulative distribution function ofXis deﬁned as\nFX(a)=P{X≤a}=/summationdisplay\nx≤apX(x).\nWe also write\nFX(a)=P{X>a}=/summationdisplay\nx>apX(x)=1−FX(a).\nCommon discrete distributions include the Bernoulli, the Binomial, the Geometric, and\nthe Poisson, all of which are discussed next.\nBernoulli( p)represents the result of a single coin ﬂip, where the coin has probability\npof coming up heads (we map this event to the value 1) and 1−pof coming up tails\n3.8probabilities and densities 39\n(we map this event to the value 0). If Xis a r.v. drawn from the Bernoulli (p)distribution,\nthen we write: X∼Bernoulli (p)and deﬁne Xas follows:\nX=/braceleftbigg\n1w/ prob p\n0otherwise\nThe p.m.f. of r.v. Xis deﬁned as follows:\npX(1) = p\npX(0) = 1−p\nThe p.m.f. is depicted in Figure 3.4.\n00.20.40.60.81\n1–pp\n1 0\nFigure 3.4. Probability mass function of Bernoulli (p)distribution, with p=0.76.\nBinomial( n, p )builds on Bernoulli (p). Given a coin with probability pof coming\nup heads (success), we ﬂip the coin ntimes (these are independent ﬂips). If X∼\nBinomial (n,p), then Xrepresents the number of heads (successes) when ﬂipping a\nBernoulli (p)coinntimes. Observe that Xcan take on discrete values: 0,1,2,...,n .\nThe p.m.f. of r.v. Xis deﬁned as follows:\npX(i)=P{X=i}\n=/parenleftbiggn\ni/parenrightbigg\npi(1−p)n−i,where i=0,1,2,...,n\nThe p.m.f. is shown in Figure 3.5.\n00.20.40.60.81\n4 3 2 1 0\nFigure 3.5. Probability mass function of the Binomial (n,p)distribution, with n=4andp=0.3.\nGeometric( p)also builds on Bernoulli (p). Again we have a coin with probability pof\ncoming up heads (success). We now ﬂip it until we get a success; these are independent\ntrials, each Bernoulli (p).I fX∼Geometric (p), thenXrepresents the number of ﬂips\nuntil we get a success.\n40 probability review\nThe p.m.f. of r.v. Xis deﬁned as follows:\npX(i)=P{X=i}=( 1−p)i−1p,where i=1,2,3,...\nThe p.m.f. is shown in Figure 3.6.\n1\n0.8\n0.6\n0.4\n0.2\n0\n56 4 3 2 1\nFigure 3.6. Probability mass function of the Geometric (p)distribution, with p=0.5.\nQuestion: Let’s review. Suppose you have a room of ndisks. Each disk independently\ndies with probability peach year. How are the following quantities distributed?\n1.The number of disks that die in the ﬁrst year\n2.The number of years until a particular disk dies\n3.The state of a particular disk after one year\nAnswer: The distributions are: 1. Binomial (n,p), 2. Geometric (p), 3. Bernoulli (p).\nPoisson( λ)is another discrete distribution that is very common in computer systems\nanalysis. We deﬁne Poisson (λ)via its p.m.f. Although the p.m.f. does not appear\nto have any meaning at present, we will show many interesting properties of this\ndistribution in Chapter 11. The Poisson distribution occurs naturally when looking\nat a mixture of a very large number of independent sources, each with a very small\nindividual probability. It can therefore be a reasonable approximation for the numberof arrivals to a website or a router per unit time.\nIf\nX∼Poisson (λ), then\npX(i)=e−λλi\ni!,where i=0,1,2,...\nThe p.m.f. for the Poisson (λ)distribution is shown in Figure 3.7.\n00.20.40.60.81\n5 4 3 2 1 0\nFigure 3.7. Probability mass function of the Poisson (λ)distribution with λ=2.\n3.8probabilities and densities 41\nYou may have noticed that the Poisson distribution does not look all that different from\nthe Binomial distribution. It turns out, as shown in Exercise 3.12, that if nis large and\npis small, then Binomial (n,p)is actually very close to Poisson (np).\n3.8.2 Continuous: Probability Density Function\nContinuous r.v.’s take on an uncountable number of values. The range of a continuous\nr.v. can be thought of as an interval or collection of intervals on the real line. Theprobability that a continuous r.v.,\nX, is equal to any particular value is zero. We deﬁne\nprobability for a continuous r.v. in terms of a density function.\nDeﬁnition 3.15 The probability density function (p.d.f.) of a continuous r.v. Xis\na non-negative function fX(·)where\nP{a≤X≤b}=/integraldisplayb\nafX(x)dx and where/integraldisplay∞\n−∞fX(x)dx=1.\nDeﬁnition 3.15 is illustrated in Figure 3.8.\nfX(x)\nThis area represents \nthe probability that 5 < X < 6\n6 5\nFigure 3.8. Area under the curve represents the probability that r.v. Xis between 5and6,\nnamely/integraltext6\n5fX(x)dx.\nQuestion: DoesfX(x)have to be <1for all x?\nAnswer: No,fX(x)/negationslash=P{X=x}.\nTo interpret the density function, f(·), think of\nfX(x)dx.=P{x≤X≤x+dx}.\nQuestion: Which of these are valid p.d.f.’s?\nfX(x)=/braceleftbigg\n.5x−.5if0<x< 1\n0 otherwise\nfX(x)=/braceleftbigg\n2x−2if0<x< 1\n0 otherwise\nfX(x)=/braceleftbigg\nx−2if1<x<∞\n0 otherwise\nAnswer: Only the ﬁrst and third p.d.f.’s integrate to 1, so only they are valid.\n42 probability review\nDeﬁnition 3.16 The cumulative distribution function (c.d.f.) of a continuous r.v.\nXis the function F(·)deﬁned by\nFX(a)=P{−∞ <X≤a}=/integraldisplaya\n−∞fX(x)dx.\nWe also write:\nF(a)=1−FX(a)=P{X>a}.\nQuestion: We know how to get FX(x)fromfX(x). How do we get fX(x)from\nFX(x)?\nAnswer: By the Fundamental Theorem of Calculus,\nfX(x)=d\ndx/integraldisplayx\n−∞f(t)dt=d\ndxFX(x).\nThere are many common continuous distributions. Below we brieﬂy deﬁne just a few:\nthe Uniform, Exponential, and the Pareto distributions.\nUniform( a,b), often written U(a, b), models the fact that any interval of length δ\nbetween aandbis equally likely. Speciﬁcally, if X∼U(a, b), then\nfX(x)=⎧\n⎨\n⎩1\nb−aifa≤x≤b\n0 otherwise.\nQuestion: ForX∼U(a, b), what is FX(x)?\nAnswer:\nFX(x)=/integraldisplayx\na1\nb−adx=x−a\nb−a\nFigure 3.9depicts fX(x)andFX(x)graphically.\nbx x a 01\nFX(x)\nfX(x)1\nb − a\nb a\nFigure 3.9. The p.d.f., f(x), and c.d.f., F(x), functions for Uniform (a,b). The shaded region\nin the left graph has an area equal to the height of the darkened segment in the right graph.\nExp(λ)denotes the Exponential distribution, whose probability density function drops\noff exponentially. We say that a random variable Xis distributed Exponentially with\n3.8probabilities and densities 43\nrateλ, written X∼Exp(λ),i f\nfX(x)=/braceleftbiggλe−λxx≥0\n0 x<0.\nThe graph of the p.d.f. is shown in Figure 3.10. The c.d.f., FX(x)=P{X≤x},i s\ngiven by\nFX(x)=/integraldisplayx\n−∞f(y)dy=/braceleftbigg1−e−λxx≥0\n0 x<0.\nFX(x)=1−FX(x)=e−λx,x≥0\nλ\nλe−λ\nλe−2λ\nλe−3λ\nx\n4fX(x)\n0 12 3\nFigure 3.10. Exponential probability density function.\nObserve that both fX(x)andF(x)drop off by a constant factor, e−λ, with each unit\nincrease of x. This fact will be important in proving the “memoryless” property of the\nExponential distribution, described in Chapter 11.\nPareto( α)is a distribution with a power-law tail, meaning that its density decays\nas a polynomial in 1/xrather than exponentially, as in Exp( λ). The parameter αis\noften referred to as the “tail parameter.” It is generally assumed that 0<α< 2.A s\nwe see later, this range of αgives the Pareto inﬁnite variance (variance is deﬁned in\nSection 3.9). IfX∼Pareto(α), then\nfX(x)=/braceleftBigg\nαx−α−1x≥1\n0 otherwise.\nFX(x)=1−x−α.\nFX(x)=x−α.\nAlthough the Pareto distribution has a ski-slope shape, like that of the Exponential, its\ntail decreases much more slowly (compare F(x)for the two distributions). The Pareto",20429
20-3.9 Expectation and Variance.pdf,20-3.9 Expectation and Variance,"44 probability review\ndistribution is said to have a “heavy tail” or a “fat tail,” where a lower αcorresponds\nto a fatter tail. This is all covered in Chapter 20.\nAn important continuous distribution that we have not mentioned is the Normal ,\na.k.a. Gaussian, distribution. The discussion of the Normal distribution requires ﬁrst\nunderstanding expectation and variance, so we defer it until Section 3.14.\n3.9 Expectation and Variance\nThemean of a distribution, also known as its expectation , follows immediately from the\nprobability mass function (or density function, in the case of continuous distributions)\nfor the distribution. For r.v. X, we write E[X]to denote its mean. This is deﬁned in\nthe following table.\nDiscrete case Continuous case\nE[X]=/summationtext\nxx·pX(x) E[X]=/integraltext∞\n−∞x·fX(x)dx\nFor the case of a discrete r.v., X, its expectation can be viewed as a sum of the possible\noutcomes, each weighted by its probability.\nE[X]=/summationdisplay\nxxP{X=x}\nTo see this, consider the following example.\nExample: Average Cost of Lunch\nWhat is the average cost of my lunch?\nMonday Tuesday Wednesday Thursday Friday Saturday Sunday\n$7 $7 $5 $5 $5 $0 $2\nAvg=7+7+5+5+5+0+2\n7\n|||\nE[Cost]=2\n7(7) +3\n7(5) +1\n7(2) +1\n7(0)\nEach possible value – 7,5,2, and0– is weighted by its probability.\nQuestion: IfX∼Bernoulli (p), what is E[X]?\nAnswer: E[X]=0·(1−p)+1·(p)=p.\nQuestion: Suppose a coin has probability1\n3of coming up heads. In expectation, how\nmany times do I need to toss the coin to get a head?\n3.9expectation and variance 45\nAnswer: This is simply E[X], where X∼Geometric (p), with p=1\n3. Assuming\nX∼Geometric (p),w eh a v e\nE[X]=∞/summationdisplay\nn=1n(1−p)n−1p\n=p·∞/summationdisplay\nn=1n·qn−1where q=( 1−p)\n=p·∞/summationdisplay\nn=1d\ndq(qn)\n=p·d\ndq∞/summationdisplay\nn=1qn\n=p·d\ndq/parenleftbiggq\n1−q/parenrightbigg\n=p\n(1−q)2\n=1\np.\nSo when p=1\n3, the expected number of ﬂips is 3.\nQuestion: IfX∼Poisson (λ), what is E[X]?\nAnswer:\nE[X]=∞/summationdisplay\ni=0ie−λλi\ni!\n=∞/summationdisplay\ni=1ie−λλi\ni!\n=λe−λ∞/summationdisplay\ni=1λi−1\n(i−1)!\n=λe−λ∞/summationdisplay\nk=0λk\nk!\n=λe−λeλ\n=λ.\nQuestion: IfX∼Exp(λ), what is E[X]?\nAnswer:\nE[X]=/integraldisplay∞\n−∞xfX(x)dx=/integraldisplay∞\n0xλe−λxdx=1\nλ(integration by parts) .\n46 probability review\nObserve that whereas the λparameter for the Poisson distribution is also its mean, for\nthe Exponential distribution, the λparameter is the reciprocal of the mean. We will\nrefer to λas the “rate” of the Exponential. For example, if the time until the next arrival\nis Exponentially distributed with rate 3arrivals per second, then the expected time until\nthe next arrival is1\n3seconds.\nWe can also think about higher moments of a random variable X. Theith moment of\nr.v.X, denoted by E[Xi], is deﬁned as follows:\nDiscrete case Continuous case\nE[Xi]=/summationtext\nxxi·pX(x) E[Xi]=/integraltext∞\n−∞xi·fX(x)dx\nMore generally, we can talk about the expectation of a function g(·)of a random\nvariable X. This is deﬁned as follows for a discrete r.v. X:\nE[g(X)] =/summationdisplay\nxg(x)·pX(x)\nand as follows for a continuous r.v. X:\nE[g(X)] =/integraldisplay∞\n−∞g(x)fX(x)dx\nQuestion: Suppose Xis deﬁned as follows:\nX=⎧\n⎪⎨\n⎪⎩0w/ prob. 0.2\n1w/ prob. 0.5\n2w/ prob. 0.3\nWhat is E[X]and what is E[2X2+3 ]?\nAnswer:\nE[X]=( 0 ) ( .2) + (1)( .5) + (2)( .3).\nE/bracketleftbig\n2X2+3/bracketrightbig\n=/parenleftbig\n2·02+3/parenrightbig\n(.2) +/parenleftbig\n2·12+3/parenrightbig\n(.5) +/parenleftbig\n2·22+3/parenrightbig\n(.3).\nYou may have noticed that E[2X2+3 ]=2 E[X2]+3 . This is no coincidence and\nis due to Linearity of Expectation to be discussed in Section 3.13.\nDeﬁnition 3.17 The variance o far . v . X, written as Var(X), is the expected\nsquared difference of Xfrom its mean (i.e., the square of how much we expect X\nto differ from its mean, E[X]). This is deﬁned as follows:\nVar(X)=E/bracketleftBig\n(X−E[X])2/bracketrightBig\nand can be equivalently expressed as follows:\nVar(X)=E[X2]−(E[X])2\n(The derivation of why these expressions are equivalent will be obvious after we\ncover Linearity of Expectation in Section 3.13.)",4194
21-3.10 Joint Probabilities and Independence.pdf,21-3.10 Joint Probabilities and Independence,"3.10 joint probabilities and independence 47\nQuestion: IfX∼Bernoulli (p), what is Var(X)?\nAnswer:\nE[X]=p\nVar(X)=E/bracketleftbig\n(X−p)2/bracketrightbig\n=p(1−p)2+( 1−p)(0−p)2=p(1−p)\nQuestion: What is the variance of X∼Uniform (a, b)?\nAnswer:\nE[X]=/integraldisplayb\nax1\nb−adx=1\nb−a·(b2−a2)\n2=a+b\n2\nVar(X)=E/bracketleftBigg/parenleftbigg\nX−a+b\n2/parenrightbigg2/bracketrightBigg\n=/integraldisplayb\na/parenleftbigg\nX−a+b\n2/parenrightbigg2\n·1\nb−adx=(b−a)2\n12\nTable 3.2shows the p.m.f. (or p.d.f.) and the mean and variance for many common\ndistributions.\nTable 3.2. Discrete and continuous distributions\nDistribution p.m.f. pX(x) Mean Variance\nBernoulli (p) pX(0) = 1 −p;pX(1) = pp p (1−p)\nBinomial (n,p) pX(x)=/parenleftbign\nx/parenrightbig\npx(1−p)n−x, np np (1−p)\nx=0,1,...,n\nGeometric (p) pX(x)=( 1 −p)x−1p,x=1,2,...1\np1−p\np2\nPoisson( λ) pX(x)=e−λ·λx\nx!,x=0,1,2,... λ λ\nDistribution p.d.f. fX(x) Mean Variance\nExp(λ) fX(x)=λe−λx 1\nλ1\nλ2\nUniform (a,b) fX(x)=1\nb−a,i fa≤x≤bb+a\n2(b−a)2\n12\nPareto( α),0<α< 2fX(x)=αx−α−1,i fx>1/braceleftbigg∞ ifα≤1\nα\nα−1ifα>1∞\nNormal( μ,σ2) fX(x)=1√\n2πσe−1\n2(x−μ\nσ)2\n, μσ2\n−∞<x< ∞\n3.10 Joint Probabilities and Independence\nWe are often interested in probability statements concerning two or more r.v.’s simulta-\nneously. For example, we might want to know the probability that two disks will bothcrash within some time interval. The behavior of the two disks might be correlated or\nnot. As another example, computer systems performance is often measured in terms\nof the energy-delay product [ 68], namely the product of the energy used by the system\nand the delay experienced by users. Energy and delay typically are correlated with each\nother, and one can imagine a joint distribution between these two random variables. Inthis section and the next, we present the deﬁnitions needed to formally express theseideas.\n48 probability review\nDeﬁnition 3.18 The joint probability mass function between discrete r.v.’s Xand\nYis deﬁned by\npX,Y(x, y)=P{X=x&Y=y}.\nThis is typically written as P{X=x, Y=y}. Similarly, fX,Y(x, y)represents\nthejoint probability density function between continuous r.v.’s XandY, where\n/integraldisplayd\nc/integraldisplayb\nafX,Y(x, y)dxdy=P{a<X<b &c<Y <d}\nQuestion: What is the relationship between fX(x)andfX,Y(x, y)?\nAnswer: Applying the Law of Total Probability, we have\nfX(x)=/integraldisplay∞\n−∞fX,Y(x, y)dyand fY(y)=/integraldisplay∞\n−∞fX,Y(x, y)dx.\nLikewise,\npX(x)=/summationdisplay\nypX,Y(x, y)a n d pY(y)=/summationdisplay\nxpX,Y(x, y).\nSimilarly to the way we deﬁned two events EandFas being independent, we can\nlikewise deﬁne two r.v.’s as being independent.\nDeﬁnition 3.19 We say that discrete r.v.’s XandYareindependent , written\nX⊥Y,i f\npX,Y(x, y)=pX(x)·pY(y).\nLikewise, we say that continuous r.v.’s XandYare independent if\nfX,Y(x, y)=fX(x)·fY(y),∀x, y.\nTheorem 3.20 IfX⊥Y, thenE[XY]=E[X]·E[Y].\nProof\nE[XY]=/summationdisplay\nx/summationdisplay\nyxy·P{X=x, Y=y}\n=/summationdisplay\nx/summationdisplay\nyxy·P{X=x}P{Y=y}(by deﬁnition of ⊥)\n=/summationdisplay\nxxP{X=x}·/summationdisplay\nyyP{Y=y}\n=E[X]E[Y]\nThe same argument works for continuous r.v.’s.",3204
22-3.11 Conditional Probabilities and Expectations.pdf,22-3.11 Conditional Probabilities and Expectations,"3.11 conditional probabilities and expectations 49\nThe same proof shows that if X⊥Y, then\nE[g(X)f(Y)] =E[g(X)]·E[f(Y)]\nfor arbitrary functions gandf.\nQuestion: IfE[XY]=E[X]E[Y], does that imply that X⊥Y?\nAnswer: No, see Exercise 3.10.\n3.11 Conditional Probabilities and Expectations\nJust as we studied conditional probabilities of events – that is, the probability that one\nevent occurs, given that another has occurred – we can also extend this to conditionalprobabilities in random variables. We start with the discrete case and then move on to\nthe continuous case. The following example will help motivate the idea.\nExample: Hair Color\nSuppose we divide the people in the class into Blondes (color value 1), Red-heads\n(color value 2), Brunettes (color value 3), and Black-haired people (color value 4).Let’s say that\n5students are Blondes, 2are Red-heads, 17are Brunettes, and 14\nare Black-haired. Let Xbe a random variable whose value is hair color. Then the\nprobability mass function for Xlooks like this:\npX(1) =P{Blonde}=5/38\npX(2) =P{Red}=2/38\npX(3) =P{Brown}=1 7/38\npX(4) =P{Black}=1 4/38\nNow let’s say that a person has light-colored hair if the hair color is either Blonde or\nRed. Let’s say that a person has dark-colored hair if the hair color is either Brown or\nBlack. Let Adenote the event that a person’s hair color is light.\nP{A}=7/38 andP/braceleftbig\nAC/bracerightbig\n=3 1/38\nDeﬁnition 3.21 LetXbe a discrete r.v. with p.m.f. pX(·)deﬁned over a countable\nspace. Let Abe an event. Then pX|A(·)is the conditional p.m.f. ofXgiven event\nA. We deﬁne\npX|A(x)=P{X=x|A}=P{(X=x)∩A}\nP{A}.\nMore formally, if Ωdenotes the sample space and ωrepresents a sample point in\nthe sample space, and {ω:X(ω)=x}is the set of sample points that result in X\nhaving value x, then\npX|A(x)=P{X=x|A}=P{{ω:X(ω)=x}∩A}\nP{A}.\n50 probability review\nA conditional probability thus involves narrowing down the probability space. For\nexample,\npX|A(Blonde )=P{(X=Blonde )∩A}\nP{A}=5\n38\n7\n38=5\n7.\nLikewise pX|A(Red)=2/7.\nAs another example,\npX|A(Brown )=P{(X=Brown )∩A}\nP{A}=0\n7\n38=0.\nLikewise pX|A(Black)=0 .\nQuestion: If we sum pX|A(x)over all x, what do we get?\nAnswer:\n/summationdisplay\nxpX|A(x)=/summationdisplay\nxP{(X=x)∩A}\nP{A}=P{A}\nP{A}=1.\nThuspX|A(x)is a valid p.m.f.\nDeﬁnition 3.22 For a discrete r.v. X, the conditional expectation of Xgiven event\nAis as follows:\nE[X|A]=/summationdisplay\nxxpX|A(x)=/summationdisplay\nxx·P{(X=x)∩A}\nP{A}\nQuestion: For our example, viewing Blonde as having value 1and Red-haired as\nhaving value 2, what is E[X|A]?\nAnswer:\nE[X|A]=1·5\n7+2·2\n7=9\n7.\nWe can also consider the case where the event, A, is an instance of a random variable.\nFor example, Amight be the event Y=y. It is then common to write the conditional\np.m.f. of Xgiven the event Y=yas\npX|Y(x|y)=P{X=x|Y=y}=P{X=x&Y=y}\nP{Y=y}=pX,Y(x, y)\npY(y),\nand\nE[X|Y=y]=/summationdisplay\nxx·pX|Y(x|y).\nExample of Conditioning on Random Variables\nTwo discrete random variables XandYtaking the values {0,1,2}have a joint\nprobability mass function given by Table 3.3.\n3.11 conditional probabilities and expectations 51\nTable 3.3. Joint probability mass\nfunction, pX,Y(x, y)\nY=2 01\n61\n8\nY=11\n81\n61\n8\nY=01\n61\n80\nX=0 X=1 X=2\nQuestion: Compute the conditional expectation E[X|Y=2 ] .\nAnswer:\nE[X|Y=2 ]=/summationdisplay\nxx·pX|Y(x|2)\n=/summationdisplay\nxx·P{X=x|Y=2}\n=0·P{X=0& Y=2}\nP{Y=2}+1·P{X=1& Y=2}\nP{Y=2}\n+2·P{X=2& Y=2}\nP{Y=2}\n=1·1\n6\n7\n24+2·1\n8\n7\n24=10\n7.\nFor a continuous, real-valued, r.v. X, the conditional p.d.f. of Xgiven event Ais\nanalogous to that for the discrete case, except that Ais now a subset of the real line,\nwhere we deﬁne P{X∈A}to be the probability that Xhas value within the subset A.\nDeﬁnition 3.23 LetXbe a continuous r.v. with p.d.f. fX(·)deﬁned over the reals.\nLetAbe a subset of the real line with P{X∈A}>0. Then fX|A(·)is the\nconditional p.d.f. ofXgiven event A. We deﬁne\nfX|A(x)=/braceleftBiggfX(x)\nP{X∈A}ifx∈A\n0 otherwise.\nAs with the discrete case, the conditional p.d.f. is zero outside the conditioning set A.\nWithin A, the conditional p.d.f. has exactly the same shape as the unconditional one,\nexcept that it is scaled by the constant factor1\nP{X∈A}, so that fX|A(x)integrates to 1.\nDeﬁnition 3.24 LetXbe a continuous r.v. with p.d.f. fX(·)deﬁned over the reals.\nLetAbe a subset of the real line with P{X∈A}>0. The conditional expectation\nofXgivenA, written E[X|A], is deﬁned by\nE[X|A]=/integraldisplay∞\n−∞xfX|A(x)dx=/integraldisplay\nAxfX|A(x)dx=1\nP{X∈A}/integraldisplay\nAxfX(x)dx.\n52 probability review\nExample: Pittsburgh Supercomputing Center\nThe Pittsburgh Supercomputing Center (PSC) runs large parallel jobs for scientists\nfrom all over the country. To charge users appropriately, jobs are grouped into differentbins based on the number of CPU hours they require, each with a different price.Suppose that job durations are Exponentially distributed with mean 1,000 processor-\nhours. Further suppose that all jobs requiring less than 500 processor-hours are sent to\nbin 1, and all remaining jobs are sent to bin 2.\nQuestion: Consider the following questions:\n(a)What is\nP{Job is sent to bin 1 }?\n(b)What is P{Job duration <200|job is sent to bin 1 }?\n(c)What is the conditional density of the duration X,fX|Y(t), where Yis the\nevent that the job is sent to bin 1?\n(d)What is E[Job duration |job is in bin 1 ]?\nAnswer: Start by recalling that for X∼Exp/parenleftbig1\n1000/parenrightbig\nwe have\nfX(t)=/braceleftBigg\n1\n1000e−t\n1000 ift>0\n0 otherwise.\nFX(t)=P{X≤t}=1−e−1\n1000t.\nThen:\n(a)FX(500) = 1−e−500\n1000=1−e−1\n2≈0.39\n(b)FX(200)\nFX(500)=1−e−1\n5\n1−e−1\n2≈0.46\n(c)\nfX|Y(t)=⎧\n⎨\n⎩fX(t)\nF(500)=1\n1000e−t\n1000\n1−e−1\n2ift<500\n0 otherwise\n(d)\nE[Job duration |job in bin 1 ]=/integraldisplay∞\n−∞tfX|Y(t)dt\n=/integraldisplay500\n0t1\n1000e−t\n1000\n1−e−1\n2dt≈229\nQuestion: Why is the expected size of jobs in bin 1 less than 250?\nAnswer: Consider the shape of the Exponential p.d.f. Now truncate it at 500, and scale\neverything by a constant needed to make it integrate to 1. There is still more weight onthe smaller values, so the expected value is less than the midpoint.\nQuestion: How would the answer to question (d) change if the job durations were\ndistributed Uniform\n(0,2000) , still with mean 1,000?\nAnswer: Logically, given that the job is in bin 1 and the distribution is uniform, we\nshould ﬁnd that the expected job duration is 250 hours. Here is an algebraic argument:\nE[Job duration |job in bin 1 ]=/integraldisplay∞\n−∞tfX|Y(t)dt=/integraldisplay500\n0t1\n2000\n500\n2000dt= 250",6680
23-3.13 Linearity of Expectation.pdf,23-3.13 Linearity of Expectation,"3.12 probabilities and expectations via conditioning 53\n3.12 Probabilities and Expectations via Conditioning\nRecall from the Law of Total Probability that, if F1,...,F npartition the sample space\nΩ, then\nP{E}=n/summationdisplay\ni=1P{E|Fi}P{Fi}.\nThis extends to random variables, because “ X=k” is an event.\nTheLaw of Total Probability for Discrete Random Variables says\nP{X=k}=/summationdisplay\nyP{X=k|Y=y}P{Y=y}\n(A similar statement can be made for continuous random variables.)\nThis is a huge tool! It allows us to break a problem into a number of simpler problems.\nThe trick, as usual, is knowing what to condition on.\nExample: Which Exponential Happens First?\nDeriveP{X1<X 2}where X1⊥X2andX1∼Exp(λ1)andX2∼Exp(λ2).\nQuestion: What do you condition on?\nAnswer: We choose to condition on the value of X2, where we use f2(·)to denote the\np.d.f. for X2:\nP{X1<X 2}=/integraldisplay∞\n−∞P{X1<X 2|X2=k}·f2(k)dk\n=/integraldisplay∞\n0P{X1<k}·λ2e−λ2kdk\n=/integraldisplay∞\n0/parenleftbig\n1−e−λ1k/parenrightbig/parenleftbig\nλ2e−λ2k/parenrightbig\ndk\n=λ1\nλ1+λ2\nTheorem 3.25 For discrete random variables,\nE[X]=/summationdisplay\nyE[X|Y=y]P{Y=y}.\nSimilarly for continuous random variables,\nE[X]=/integraldisplay\nE[X|Y=y]fY(y)dy.\n54 probability review\nProof We present the proof for the discrete case:\nE[X]=/summationdisplay\nxxP{X=x}\n=/summationdisplay\nxx/summationdisplay\nyP{X=x|Y=y}P{Y=y}\n=/summationdisplay\nx/summationdisplay\nyxP{X=x|Y=y}P{Y=y}\n=/summationdisplay\ny/summationdisplay\nxxP{X=x|Y=y}P{Y=y}\n=/summationdisplay\nyP{Y=y}/summationdisplay\nxxP{X=x|Y=y}\n=/summationdisplay\nyP{Y=y}E[X|Y=y]\nThis proof generalizes to\nE[g(X)] =/summationdisplay\nyE[g(X)|Y=y]P{Y=y},\nwhich is very important when we need to compute the variance of Xor higher\nmoments.\nExample: Geometric\nSuppose we want to use conditioning to easily compute the mean of the Geometric\ndistribution with parameter p. That is, we seek E[N], where Nis the number of ﬂips\nrequired to get the ﬁrst head.\nQuestion: What do we condition on?\nAnswer: We condition on the value of the ﬁrst ﬂip, Y, as follows:\nE[N]=E[N|Y=1 ]P{Y=1}+E[N|Y=0 ]P{Y=0}\n=1p+( 1+ E[N])(1−p)\npE[N]=p+( 1−p)\nE[N]=1\np\nNote how much simpler this derivation is than our original derivation of the mean of a\nGeometric!\n3.13 Linearity of Expectation\nThe following is one of the most powerful theorems of probability.\n3.13 linearity of expectation 55\nTheorem 3.26 (Linearity of Expectation) For random variables XandY,\nE[X+Y]=E[X]+E[Y].\nQuestion: Does Theorem 3.26 require X⊥Y?\nAnswer: No! Recall that we doneed independence for simplifying E[XY], but not\nforE[X+Y].\nProof Here is a proof in the case where XandYare continuous. The discrete case\nis similar: Just replace fX,Y(x, y)withpX,Y(x, y).\nE[X+Y]\n=/integraldisplay∞\ny=−∞/integraldisplay∞\nx=−∞(x+y)fX,Y(x, y)dxdy\n=/integraldisplay∞\ny=−∞/integraldisplay∞\nx=−∞xfX,Y(x, y)dxdy+/integraldisplay∞\ny=−∞/integraldisplay∞\nx=−∞yfX,Y(x, y)dxdy\n=/integraldisplay∞\nx=−∞/integraldisplay∞\ny=−∞xfX,Y(x, y)dydx+/integraldisplay∞\ny=−∞/integraldisplay∞\nx=−∞yfX,Y(x, y)dxdy\n=/integraldisplay∞\nx=−∞x/integraldisplay∞\ny=−∞fX,Y(x, y)dydx+/integraldisplay∞\ny=−∞y/integraldisplay∞\nx=−∞fX,Y(x, y)dxdy\n=/integraldisplay∞\nx=−∞xfX(x)dx+/integraldisplay∞\ny=−∞yfY(y)dy\n=E[X]+E[Y]\nThis identity can simplify many proofs. Consider the following example:\nExample: Binomial\nX∼Binomial (n,p). What is E[X]?\nQuestion: If we simply use the deﬁnition of the Binomial, what expression do we have\nforE[X]?\nAnswer: E[X]=/summationtextn\ni=0i/parenleftbign\ni/parenrightbig\npi(1−p)n−i. This expression appears daunting.\nQuestion: Can we think of Binomial (n,p)as a sum of random variables?\nAnswer: Let\nX=number of successes in ntrials=X1+X2+···+Xn\n56 probability review\nwhere\nXi=/braceleftbigg\n1if trial iis successful\n0otherwise\nE[Xi]=p.\nThen\nE[X]=E[X1]+E[X2]+···+E[Xn]=nE[Xi]=np.\nThis result should make sense, because ncoin ﬂips, each with probability pof coming\nup heads, should result in an average of npheads.\nTheXi’s above are called indicator random variables because they take on values\n0or1. In the previous example, the Xi’s were i.i.d. (independent and identically\ndistributed). However, even if the trials were not independent, we would have\nE[X]=E[X1]+···+E[Xn].\nThe following example makes this clear.\nExample: Hats\nAt a party, npeople throw their hats into the middle of a circle. Each closes his or her\neyes and picks a random hat. Let Xdenote the number of people who get back their\nown hat. Our goal is to determine E[X].\nQuestion: How can we express Xas a sum of indicator random variables?\nAnswer: X=I1+I2+···+In, where\nIi=/braceleftbigg\n1if theith person gets their own hat\n0otherwise.\nObserve that although the Ii’s have the same distribution (by symmetry), they are not\nindependent of each other! Nevertheless, we can still use Linearity of Expectation tosay\nE[X]=E[I1]+E[I2]+···+E[In]\n=nE[Ii]\n=n/parenleftbigg1\nn·1+n−1\nn·0/parenrightbigg\n=1.\nObserve that Linearity of Expectation can also be used to show that\nE/bracketleftbig\nX2+Y2/bracketrightbig\n=E/bracketleftbig\nX2/bracketrightbig\n+E/bracketleftbig\nY2/bracketrightbig\n.\nNonetheless this does not imply that Linearity of Expectation holds for variance. For\nthat, we require an independence assumption, as in the following theorem.\nTheorem 3.27 LetXandYbe random variables where X⊥Y. Then\nVar(X+Y)=Var(X)+Var(Y).",5470
24-3.14 Normal Distribution.pdf,24-3.14 Normal Distribution,"3.14 normal distribution 57\nProof\nVar(X+Y)=E/bracketleftBig\n(X+Y)2/bracketrightBig\n−(E[(X+Y)])2\n=E/bracketleftbig\nX2/bracketrightbig\n+E/bracketleftbig\nY2/bracketrightbig\n+2E[XY]\n−(E[X])2−(E[Y])2−2E[X]E[Y]\n=Var(X)+Var(Y)\n+2E[XY]−2E[X]E[Y]/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\nequals 0 if X ⊥Y\n3.14 Normal Distribution\nA very important and ubiquitous continuous distribution is the Normal distribution.\nDeﬁnition 3.28 A continuous r.v. Xis said to be Normal (μ,σ2)o r Gaussian (μ,\nσ2) if it has p.d.f. fX(x)of the form\nfX(x)=1√\n2πσe−1\n2(x−μ\nσ)2\n,−∞<x<∞\nwhere σ>0. The parameter μis called the mean , and the parameter σis called the\nstandard deviation .\nDeﬁnition 3.29 AN o r m a l (0,1)r.v.Yis said to be a standard Normal . Its c.d.f. is\ndenoted by\nΦ(y)=FY(y)=P{Y≤y}=1√\n2π/integraldisplayy\n−∞e−t2/2dt.\nThe Normal (μ, σ2)p.d.f. has a “bell” shape and is clearly symmetric around μ,a s\nshown in Figure 3.11. The fact that fX(x)in Deﬁnition 3.28 is actually a density\nfunction can be seen by integrating it via a change into polar coordinates (trust me, you\ndo not want to see the gory details [ 176]).\n2π1\n-1 1 2 3fX(x)\nx\nFigure 3.11. Normal (1,1)p.d.f.\n58 probability review\nTheorem 3.30 LetX∼Normal (μ, σ2), thenE[X]=μandVar(X)=σ2.\nProof Because fX(x)is symmetric around μ, it is obvious that E[X]=μ.\nVar(X)=/integraldisplay∞\n−∞(x−μ)2fX(x)dx\n=1√\n2πσ/integraldisplay∞\n−∞(x−μ)2e−1\n2((x−μ)/σ)2dx\n=σ2\n√\n2π/integraldisplay∞\n−∞y2e−y2/2dy by change of variables y=(x−μ)/σand\ndx=σdy\n=σ2\n√\n2π/integraldisplay∞\n−∞y·/parenleftBig\nye−y2/2/parenrightBig\ndy\n=σ2\n√\n2π/parenleftBig\n−ye−y2/2/parenrightBig/bracketrightBig∞\n−∞+σ2\n√\n2π/integraldisplay∞\n−∞e−y2/2dy by integration by parts\n=σ2\n√\n2π/integraldisplay∞\n−∞e−y2/2dy\n=σ2\nThe last line was obtained by using the fact that\n1√\n2π/integraldisplay∞\n−∞e−y2/2dy=1\nbecause the integrand is the density function of the standard Normal.\n3.14.1 Linear Transformation Property\nThe Normal distribution has a very particular property known as the “Linear Transfor-\nmation Property,” which says that if Xis a Normal r.v., and you take a linear function\nofX, then that new r.v. will also be distributed as a Normal. Note that this property is\nnottrue for other distributions that we have seen, such as the Exponential.\nTheorem 3.31 (Linear Transformation Property) LetX∼Normal (μ, σ2).L e t\nY=aX+b, where a>0andbare scalars. Then Y∼Normal (aμ+b, a2σ2).\nProof It is easy to show that E[Y]=aE[X]+b=aμ+band Var(Y)=\na2Var(X)=a2σ2. All that remains is to show that fY(y)is Normally distributed. We\nrelate the c.d.f. of Yto the c.d.f. of Xas follows:\nFY(y)=P{Y≤y}=P{aX+b≤y}=P/braceleftbigg\nX≤y−b\na/bracerightbigg\n=FX/parenleftbiggy−b\na/parenrightbigg\n3.14 normal distribution 59\nWe now differentiate both sides with respect to y:\nd\ndyFY(y)=d\ndy/integraldisplayy\n−∞fY(t)dt=fY(y)\nd\ndyFX/parenleftbiggy−b\na/parenrightbigg\n=d\ndy/integraldisplayy−b\na\n−∞fX(t)dt=fX/parenleftbiggy−b\na/parenrightbigg\n·d\ndy/parenleftbiggy−b\na/parenrightbigg\n=fX/parenleftbiggy−b\na/parenrightbigg\n·1\na\nThus we have shown that\nfY(y)=1\nafX/parenleftbiggy−b\na/parenrightbigg\n.\nEvaluating this, we have\nfY(y)=1\nafX/parenleftbiggy−b\na/parenrightbigg\n=1\na√\n2πσe−(y−b\na−μ)2/2σ2\n=1√\n2π(aσ)e−(y−b−aμ)2/2a2σ2\n=1√\n2π(aσ)e−(y−(b+aμ))2/2a2σ2.\nSofY(y)is a Normal p.d.f. with mean aμ+band variance a2σ2.\nUnfortunately, we do not know how to integrate the density of the Normal from 0toy\nsymbolically. To compute the c.d.f. of a Normal distribution, we must therefore use a\ntable of numerically integrated results for Φ(y), such as that given in [ 200].1A subset\nof the table is given next for reference:\ny 0.5 1.0 1.5 2.0 2.5 3.0\nΦ(y)0.6915 0.8413 0.9332 0.9772 0.9938 0.9987\nQuestion: Looking at the table you see, for example, that Φ(1) = 0 .8413 . What\ndoes this tell us about the probability that the standard Normal is within one standard\ndeviation of its mean?\n1In practice no one ever goes to the table anymore, because there are approximations that allow you to compute\nthe values in the table to within seven decimal places; see for example [ 131].\n60 probability review\nAnswer: We are given that P{Y<1}=0.84. We want to know P{−1<Y < 1}.\nP{−1<Y < 1}=P{Y<1}−P{Y<−1}\n=P{Y<1}−P{Y>1}(by symmetry)\n=P{Y<1}−(1−P{Y<1})\n=2P{Y<1}−1\n= 2Φ(1)−1\n.=2·0.84−1\n=0.68\nSo with probability 68%, we are within one standard deviation of the mean.\nLikewise, we can use the same argument to show that with probability 95%, we are\nwithin two standard deviations of the mean, and with probability 99.7%, we are withinthree standard deviations of the mean, etc.\nQuestion: The previous results were expressed for a standard Normal. What if we do\nnot have a standard Normal?\nAnswer: We can convert a non-standard Normal into a standard Normal using the\nLinear Transformation Property. Here is how it works:\nX∼Normal (μ, σ2)⇐⇒Y=X−μ\nσ∼Normal (0,1)\nSo\nP{X<k}=P/braceleftbiggX−μ\nσ<k−μ\nσ/bracerightbigg\n=P/braceleftbigg\nY<k−μ\nσ/bracerightbigg\n=Φ/parenleftbiggk−μ\nσ/parenrightbigg\n.\nTheorem 3.32 IfX∼Normal (μ, σ2), then the probability that Xdeviates from\nits mean by less than kstandard deviations is the same as the probability that the\nstandard Normal deviates from its mean by less than k.\nProof LetY∼Normal (0,1). Then,\nP{−kσ < X−μ<k σ}=P/braceleftbigg\n−k<X−μ\nσ<k/bracerightbigg\n=P{−k<Y <k}\nTheorem 3.32 illustrates why it is often easier to think in terms of standard deviations\nthan in absolute values.\nQuestion: Proponents of IQ testing will tell you that human intelligence (IQ) has been\nshown to be Normally distributed with mean 100 and standard deviation 15. Whatfraction of people have an IQ greater than 130 (“the gifted cutoff”)?\nAnswer: We are looking for the fraction of people whose IQ is more than two standard\ndeviations above the mean. This is the same as the probability that the standard Normal\n3.14 normal distribution 61\nexceeds its mean by more than two standard deviations, which is 1−Φ(2) = 0 .023.\nThus only about 2% of people have an IQ above 130.\n3.14.2 Central Limit Theorem\nConsider sampling the heights of all the individuals in the state and taking that average.\nThe Central Limit Theorem (CLT), which we deﬁne soon, says that this average willtend to be Normally distributed. This would be true even if we took the average of\na large number of i.i.d. random variables, where the random variables come from a\ndistribution that is decidedly non-Normal, say a Uniform distribution. It is this propertythat makes the Normal distribution so important!\nWe now state this more formally. Let\nX1,X2,X3,...,X nbe independent and identi-\ncally distributed r.v.’s with some mean μand variance σ2. Note: We are notassuming\nthat these are Normally distributed r.v.’s. In fact we are not even assuming that they are\nnecessarily continuous r.v.’s – they may be discrete r.v.’s.\nLet\nSn=X1+X2+···+Xn. (3.2)\nQuestion: What are the mean and standard deviation of Sn?\nAnswer: E[Sn]=nμandVar(Sn)=nσ2. Thus the standard deviation is σ√n.\nLet\nZn=Sn−nμ\nσ√n.\nQuestion: What are the mean and standard deviation of Zn?\nAnswer: Znhas mean 0and standard deviation 1.\nTheorem 3.33 (Central Limit Theorem (CLT)) LetX1,X2,...,X nbe a se-\nquence of i.i.d. r.v. ’s with common mean μand variance σ2, and deﬁne\nZn=X1+···+Xn−nμ\nσ√n.\nThen the c.d.f. of Znconverges to the standard normal c.d.f.; that is,\nlim\nn→∞P{Zn≤z}=Φ (z)=1√\n2π/integraldisplayz\n−∞e−x2/2dx\nfor every z.\nProof Our proof makes use of transforms, so we defer the proof of CLT to Chap-\nter25, Exercise 25.15 .",7674
25-3.15 Sum of a Random Number of Random Variables.pdf,25-3.15 Sum of a Random Number of Random Variables,"62 probability review\nQuestion: What is the distribution of Snin (3.2)?\nAnswer: By the Linear Transformation Property, Sn∼Normal (nμ, nσ2).\nThe Central Limit Theorem is extremely general and explains many natural phenomena\nthat result in Normal distributions. The fact that CLT applies to any sum of i.i.d.\nr.v.’s allows us to prove that the Binomial (n,p)distribution, which is a sum of i.i.d.\nBernoulli (p)r.v.’s, converges to a Normal distribution when nis high. When we study\nthe Poisson distribution in more depth in Chapter 11, we will see that the Poisson (λ)\ndistribution can also be viewed as a sum of i.i.d. r.v.’s; hence the Poisson (λ)distribution\nis also well approximated by a Normal distribution with mean λand variance λ.\nWe now illustrate the use of the Normal distribution in approximating the distribution\nof a complicated sum.\nExample: Normal Approximation of a Sum\nImagine that we are trying to transmit a signal. During the transmission, there are a\nhundred sources independently making low noise. Each source produces an amount ofnoise that is Uniformly distributed between\na=−1andb=1. If the total amount of\nnoise is greater than 10or less than −10, then it corrupts the signal. However, if the\nabsolute value of the total amount of noise is under 10, then it is not a problem.\nQuestion: What is the approximate probability that the absolute value of the total\namount of noise from the 100 signals is less than 10?\nAnswer: LetXibe the noise from source i. Observe that μXi=0. Observe that\nσ2\nXi=(b−a)2\n12=1\n3andσXi=1√\n3. LetS100=X1+X2+···+X100.\nP{−10<S 100<10}=P/braceleftBigg\n−10/radicalbig\n100/3<S100−0/radicalbig\n100/3<10/radicalbig\n100/3/bracerightBigg\n≈2Φ/parenleftbigg10√\n33.33/parenrightbigg\n−1\n=2 ( 0.9572)−1\n=0.9144\nHence the approximate probability of the signal getting corrupted is less than 10%. In\npractice, this approximation is excellent.\n3.15 Sum of a Random Number of Random Variables\nIn many applications one often needs to add up a number of i.i.d. random variables,where the number of these variables is itself a random variable. Speciﬁcally, we are\ntalking about the quantity\nSin the following expression. Let X1,X2,X3,... be i.i.d.\nrandom variables. Let\nS=N/summationdisplay\ni=1Xi,N⊥Xi\nwhere Nis a non-negative, integer-valued random variable.\n3.15 sum of a random number of random variables 63\nWe now review how to derive quantities like E[S]andE[S2], which we will need\nthroughout the book.\nQuestion: Why can’t we directly apply Linearity of Expectation?\nAnswer: Linearity equations only apply when Nis a constant.\nQuestion: Does this give you any ideas?\nAnswer: Let’s condition on the value of N, and then apply Linearity of Expectation.\nE[S]=E/bracketleftBiggN/summationdisplay\ni=1Xi/bracketrightBigg\n=/summationdisplay\nnE/bracketleftBiggN/summationdisplay\ni=1Xi/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleN=n/bracketrightBigg\n·P{N=n}\n=/summationdisplay\nnE/bracketleftBiggn/summationdisplay\ni=1Xi/bracketrightBigg\n·P{N=n}\n=/summationdisplay\nnnE[X]·P{N=n}\n=E[X]·E[N] (3.3)\nQuestion: Can we use the same trick to get E[S2]?\nAnswer: The difﬁculty with conditioning on Nis that we end up with a big sum that\nwe need to square, and it is not obvious how to do that. Consider the following:\nE/bracketleftbig\nS2/bracketrightbig\n=/summationdisplay\nnE/bracketleftbig\nS2|N=n/bracketrightbig\n·P{N=n}\n=/summationdisplay\nnE⎡\n⎣/parenleftBiggn/summationdisplay\ni=1Xi/parenrightBigg2⎤⎦·P{N=n}\nA better idea is to ﬁrst derive Var(S|N=n)and then use that to get E[S2|N=n].\nObserve that, by Theorem 3.27,\nVar(S|N=n)=nVar(X).\nObserve also that\nnVar(X)=Var(S|N=n)=E/bracketleftbig\nS2|N=n/bracketrightbig\n−(E[S|N=n])2\n=E/bracketleftbig\nS2|N=n/bracketrightbig\n−(nE[X])2.\nFrom the previous expression, we have that\nE/bracketleftbig\nS2|N=n/bracketrightbig\n=nVar(X)+n2(E[X])2.",3919
26-3.16 Exercises.pdf,26-3.16 Exercises,"64 probability review\nIt follows that\nE/bracketleftbig\nS2/bracketrightbig\n=/summationdisplay\nnE/bracketleftbig\nS2|N=n/bracketrightbig\n·P{N=n}\n=/summationdisplay\nn/parenleftBig\nnVar(X)+n2(E[X])2/parenrightBig\nP{N=n}\n=E[N]Var(X)+E/bracketleftbig\nN2/bracketrightbig\n(E[X])2.\nFurthermore,\nVar(S)=E/bracketleftbig\nS2/bracketrightbig\n−(E[S])2\n=E[N]Var(X)+E/bracketleftbig\nN2/bracketrightbig\n(E[X])2−(E[N]E[X])2\n=E[N]Var(X)+Var(N)(E[X])2.\nWe have proven Theorem 3.34:\nTheorem 3.34 LetX1,X2,X3,... be i.i.d. random variables. Let\nS=N/summationdisplay\ni=1Xi,N⊥Xi.\nThen\nE[S]=E[N]E[X],\nE/bracketleftbig\nS2/bracketrightbig\n=E[N]Var(X)+E/bracketleftbig\nN2/bracketrightbig\n(E[X])2,\nVar(S)=E[N]Var(X)+Var(N)(E[X])2.\nThe variance trick was pretty cool. You may be wondering how we would get the\nthird moment, E[S3], if we ever needed it, given that the variance trick will not work\nthere. The answer is to use transform analysis (generating functions), which will easilyprovide any moment of\nS. This topic is covered in Chapter 25.\n3.16 Exercises\n3.1 Expectation Brainteaser\nA friend told me that during his ﬁrst year in school he was never in a classwith less than 90 students. He said that almost all of his friends had the same\nexperience. The dean, however, insists that the mean freshman class size is 30\nstudents. How can this be? Explain with a simple numerical example what isgoing on.\n3.2 Nerdy Ned\nNerdy Ned asks out a new girl every day. With probability\n1\n100the girl says\n“yes,” and with probability99\n100the girl says “no.” What is the probability that it\ntakes Ned more than 100 days to get a girlfriend?\n3.3 Variance\nUse Linearity of Expectation to prove that Var(X)=E[X2]−E[X]2.\n3.16 exercises 65\n3.4 Chain Rule for Conditioning\nLetE1,E2,...,E nbenevents, each with positive probability. Prove that\nP/braceleftBiggn/intersectiondisplay\ni=1Ei/bracerightBigg\n=P{E1}·P{E2|E1}·P{E3|E1∩E2}···P/braceleftBigg\nEn|n−1/intersectiondisplay\ni=1Ei/bracerightBigg\n.\n3.5 Assessing Risk\nQueueville Airlines knows that on average 5% of the people making ﬂight\nreservations do not show up. (They model this information by assuming that each\nperson independently does not show up with probability of 5%.) Consequently,\ntheir policy is to sell 52 tickets for a ﬂight that can only hold 50 passengers.What is the probability that there will be a seat available for every passengerwho shows up?\n3.6 Practice with Conditional Expectation\nFor the joint p.m.f. in Table 3.3, compute\nE[X|Y/negationslash=1 ] .\n3.7 How Does Variance Scale?\nConsider the following two random variables:\nX=⎧\n⎪⎨\n⎪⎩3w/prob1\n3\n2w/prob1\n3\n1w/prob1\n3Y=⎧\n⎪⎨\n⎪⎩30 w/prob1\n3\n20 w/prob1\n3\n10 w/prob1\n3\n(a)Yis a scaled version of X.D oXandYhave the same variance?\n(b) Intuitively, if we think of Xas representing measurements in seconds, and\nYas representing measurements in tenths of seconds, then we would like to\nfeel that XandYhave the same variance. A common metric in computer\nsystems is the squared coefﬁcient of variation, where the squared coefﬁcient\nof variation of Xis written as C2\nXand is deﬁned as C2\nX=Var(X)\nE[X]2. This can\nbe viewed as a normalized variance. How do C2\nXandC2\nYcompare?\n3.8 Understanding Variance and Risk\nLetcbe an integer where c>1. We are given cindependent instances of the\nr.v.X: call these X1,X2,...,X c.\n(a) Which has lower variance: Var(X1+X2+···+Xc)orVar(cX)?C o m -\npute each of these.\n(b) The selling point of mutual funds is that they are less risky than buying a\nsingle stock. Explain this statement.\n3.9 Identities\nLetAandBbe independent random variables. Prove or disprove the following\nstatement:\nE[A/B]=E[A]/E[B]\n3.10 Expectation of Product\nProve or disprove the following claim: If\nE[XY]=E[X]·E[Y],\nthenXandYare independent r.v.’s.\n66 probability review\n3.11 Variance of the Binomial\nLetX∼Binomial (n,p). Use Theorem 3.27 to easily derive Var(X).\n3.12 Poisson Approximation to Binomial\nProve that the Binomial (n,p)distribution is well approximated by the\nPoisson (np)distribution when nis large and pis small. [Hint: Start with\nthe probability mass function for the Binomial (n,p)distribution. Set p=λ/n.\nExpand out all the terms. Take limits and show you get a Poisson (λ)distribution,\nwhere λ=np.]\n3.13 Probability Bounds\nYou are told that the average ﬁle size in a database is 6K.\n(a) Explain why it follows (from the deﬁnition of expectation) that fewer than\nhalf of the ﬁles can have size >12K.\n(b) You are now given the additional information that the minimum ﬁle size is\n3K. Derive a tighter upper bound on the percentage of ﬁles that have size\n>12K.\n3.14 Quality of Service\nA company pays a ﬁne if the time to process a request exceeds 7 seconds.\nProcessing a request consists of two tasks: (a) retrieving the ﬁle – which takessome time\nXthat is Exponentially distributed with mean 5, and (b) parsing\nthe ﬁle – which takes some time Ythat is independent of Xand is distributed\nUniform (1,3), with mean 2. Given that the mean time to process a request is\nclearly 7seconds, the company views the ﬁne as unfair, because it will have to\npay the ﬁne on half its requests. Is this right? What is the actual fraction of time\nthat the ﬁne will have to be paid, and how much does this differ from 1/2?\n3.15 Positive Correlation\nWe say that events AandBarepositively correlated if\nP{A|B}>P{A}. (3.4)\nProve or disprove that ( 3.4) implies\nP{B|A}>P{B}. (3.5)\n3.16 Covariance\nThecovariance of any two random variables XandY, denoted by cov (X,Y),\nis deﬁned by\ncov(X,Y)=E[(X−E[X])(Y−E[Y])].\n(a) Prove that cov (X,Y)=E[XY]−E[X]E[Y].\n(b) IfX⊥Y, what can we say about cov (X,Y)?\n(c) Let XandYbe indicator random variables, where\nX=/braceleftbigg\n1if event Aoccurs\n0o.w.\n3.16 exercises 67\nand\nY=/braceleftbigg\n1if event Boccurs\n0o.w..\nProve that if events AandBare positively correlated (see Exercise 3.15),\nthen cov (X,Y)>0, whereas if AandBare negatively correlated, then\ncov(X,Y)<0.Note: This notion can be extended to general random\nvariables XandY, not just indicator random variables.\n3.17 Normal Approximation\nBill Gater invites 1,000 friends to a dinner. Each is asked to make a contribution.\nThe contributions are i.i.d. Poisson-distributed random variables with mean\n$1,000 each. Bill hopes to raise $1,000,000.\nYour job is to compute the probability that Bill raises <$999,000.\n(a) Compute this using the Normal approximation from this chapter.\n(b) Now write an exact expression for this probability, and then use your calcu-\nlator or a small program to evaluate the expression.\n3.18 Joint Distributions\nYour TAs, Eric and Timmy, have agreed to meet between 2 and 3 pm to design\nthe next homework. They are rather busy and are not quite sure when they canarrive, so assume that each of their arrival times is independent and uniformly\ndistributed over the hour. Each agrees to wait 15 minutes for the other TA, afterwhich he will leave. What is the probability that Eric and Timmy will be ableto meet?\n3.19 Bayesian Reasoning for Weather Prediction\nIn the hope of having a dry outdoor wedding, John and Mary decide to getmarried in the desert, where the average number of rainy days per year is\n10.\nUnfortunately, the weather forecaster is predicting rain for tomorrow, the day of\nJohn and Mary’s wedding. Suppose that the weather forecaster is not perfectly\naccurate: If it rains the next day, 90% of the time the forecaster predicts rain. If\nit is dry the next day, 10% of the time the forecaster still (incorrectly) predicts\nrain. Given this information, what is the probability that it will rain during John\nand Mary’s wedding?\n3.20 Bayesian Reasoning for Health Care Testing\nA pharmaceutical company has developed a potential vaccine against the H1N1\nﬂu virus. Before any testing of the vaccine, the developers assume that with\nprobability 0.5their vaccine will be effective and with probability 0.5it will\nbe ineffective. The developers do an initial laboratory test on the vaccine. This\ninitial lab test is only partially indicative of the effectiveness of the vaccine,\nwith an accuracy of 0.6. Speciﬁcally, if the vaccine is effective, then this labo-\nratory test will return “success” with probability 0.6, whereas if the vaccine is\nineffective, then this laboratory test will return “failure” with probability 0.6.\n(a) What is the probability that the laboratory test returns “success”?\n(b) What is the probability that the vaccine is effective, given that the laboratory\ntest returned “success”?\n68 probability review\n(c) The developers decide to add a second experiment (this one on human\nbeings) that is more indicative than the original lab test and has an accuracy\nof0.8. Speciﬁcally, if the vaccine is effective, then the human being test\nwill return “success” with probability 0.8. If the vaccine is ineffective, then\nthe human being test will return “failure” with probability 0.8. What is the\nprobability that the vaccine is effective, given that both the lab test andthe human being test came up “success”? How useful was it to add this\nadditional test? Assume that the two tests (human test and lab test) are\nconditionally independent on the vaccine being effective or ineffective.\n3.21 Dating Costs: Deriving Expectation and Variance via Conditioning\nA man, in search of a wife, tries two approaches: generous and cheapskate.\nWhen the man tries the generous approach, he ends up spending $1,000 on his\ndate, who will, eventually, with probability\n0.95break up with him, but with\nprobability 0.05marry him. When the man tries the cheapskate approach, he\nspends $50 on his date, who will eventually break up with him. So far in his life,\nthe man has only experienced failure, so he cannot tell which approach works\nbetter. He therefore decides to choose an approach (generous or cheapskate) at\nrandom.(a) Assuming the man starts searching today, what is his expected cost to ﬁnd\na wife?\n(b) Compute the variance on the amount of money the man ends up spending\nto ﬁnd a wife.\n3.22 Variance of the Geometric\nLet\nX∼Geometric (p). Prove that Var(X)=1−p\np2. [Hint: Use conditioning.]\n3.23 Good Chips versus Lemons\nA chip supplier produces 95% good chips and 5% lemons. The good chips failwith probability\n0.0001 each day. The lemons fail with probability 0.01each\nday. You buy a random chip. Let Tbe the time until your chip fails. Compute\nE[T]andVar(T).\n3.24 Alternative Deﬁnition of Expectation2\n(a) Let X: non-negative, discrete, integer-valued random variable. Prove\nE[X]=∞/summationdisplay\nx=0P{X>x}\n(b) Let X: non-negative, continuous random variable. Prove\nE[X]=/integraldisplay∞\nx=0P{X>x}dx\n(c) Let X: non-negative, continuous random variable. Does this quantity have\na nicer name?/integraldisplay∞\nx=0xP{X>x}dx\n2Warning: The result of this exercise will be invoked throughout the book.\n3.16 exercises 69\n3.25 Expectation via Conditioning\nStacy’s fault-tolerant system only crashes if there are k=1 0 consecutive fail-\nures. If every minute a failure occurs independently with probability p=1\n10,\nwhat is the expected number of minutes until Stacy’s system crashes. (Expressgenerally in terms of\nkandp.) [Hint: Write a recurrence relation.]\n3.26 Napster – Brought to You by the RIAA\nAs a present for my brother, I decided to create a collection of all the songsfrom his favorite band. I needed to download the band’s 50 songs. Unfortunately,\nwhenever I typed in the band name, I was sent a random song from the band.\nLet\nDdenote the number of downloads required to get all 50 songs.\n(a) What is E[D]? Give a closed-form approximation.\n(b) What is Var(D)? (No need for closed-form here.)\n3.27 Fractional Moments\nGiven the ugliness of the Normal distribution, I am happy to say that it nevercomes up in my research . . . until a few days ago! Here’s the story: I had a\nrandom variable\nX∼Exp(1)and I needed to compute E/bracketleftbig\nX1\n2/bracketrightbig\n. Figure out\nwhy I needed a Normal distribution to do this and what answer I ﬁnally got.Here are some hints: Start by applying integration by parts. Then make theright change of variables. If you do it right, the standard Normal should popout. Remember that the Exponential ranges from 0 to\n∞, whereas the Normal\nranges from −∞ to∞.",12368
27-Chapter 4 Generating Random Variables for Simulation.pdf,27-Chapter 4 Generating Random Variables for Simulation,,0
28-4.1 Inverse-Transform Method.pdf,28-4.1 Inverse-Transform Method,"CHAPTER 4\nGenerating Random Variables\nfor Simulation\nIn Chapter 3we reviewed the most common discrete and continuous random variables.\nThis chapter shows how we can use the density function or cumulative distribution\nfunction for a distribution to generate instances of that distribution. For example, wemight have a system in which the interarrival times of jobs are well modeled by anExponential distribution and the job sizes (service requirements) are well modeled\nby a Normal distribution. To simulate the system, we need to be able to generateinstances of Exponential and Normal random variables. This chapter reviews the twobasic methods used in generating random variables. Both these methods assume thatwe already have a generator of Uniform(0,1) random variables, as is provided by mostoperating systems.\n1,2\n4.1 Inverse-Transform Method\nThis method assumes that (i) we know the c.d.f. (cumulative distribution function),\nFX(x)=P{X≤x}, of the random variable Xthat we are trying to generate, and\n(ii) that this distribution is easily invertible, namely that we can get xfromFX(x).\n4.1.1 The Continuous Case\nIdea: We would like to map each instance of a uniform r.v. generated by our operating\nsystem – that is, u∈U(0,1)–t os o m e x, which is an instance of the random variable\nX, where Xhas c.d.f. FX. We assume WLOG that Xranges from 0to∞. Let’s\nsuppose there is some mapping that takes each uand assigns it a unique x. Such a\nmapping is illustrated by g−1(·)in Figure 4.1.\nQuestion: Can you ﬁgure out what the mapping g−1(·)in Figure 4.1should be?\nHint: Think about what property we want for our output. What should be the probability\nof outputting a value between 0andx?\nAnswer: A value in (0,x)should be output with probability FX(x).\nQuestion: What is the actual probability that g−1(·)outputs a value in (0,x)?\n1Actually, most operating systems provide a random integer between 1 and N=232−1. This is easy to convert\ninto a Uniform(0,1) by just dividing by N.\n2One cannot always trust the random number generator provided by one’s operating system. It is worth reading\nthe literature to understand how to best “seed” the random number generator and what guarantees it provides.See for example, [ 31].\n70\n4.1inverse-transform method 71\nXgU(0,1)\n01\nu\nx\nFigure 4.1. Illustration of mapping g(·).\nAnswer: Because g−1(·)only maps values in (0,u)to values in (0,x), the probability\nof outputting a value in (0,x)is the probability that the uniform instance is in (0,u).\nQuestion: And what is the probability that the uniform instance is in (0,u)?\nAnswer: u.\nSo we want that\nu=P{0<U<u}=P{0<X<x}=FX(x).\nThat is, we want\nu=FX(x)or equivalently x=F−1\nX(u). (4.1)\nQuestion: So what was the g(·)function in Figure 4.1?\nAnswer: g(·)=F(·), the cumulative distribution function.\nInverse-Transform Method to generate r.v. X :\n1.Generate u∈U(0,1).\n2.Return X=F−1\nX(u).\nExample: Generate X∼Exp(λ)\nFor the Exp (λ)distribution,\nF(x)=1−e−λx.\nSo by ( 4.1) we want\nx=F−1(u)\n=⇒F(x)=u\n=⇒1−e−λx=u\n=⇒−λx= ln(1−u)\n=⇒x=−1\nλln(1−u).\nGiven u∈U(0,1), setting x=−1\nλln(1−u)produces an instance of X∼Exp(λ).",3150
29-4.2 Accept-Reject Method.pdf,29-4.2 Accept-Reject Method,"72 generating random variables for simulation\n4.1.2 The Discrete Case\nThe discrete case follows the same basic idea as the continuous case (see Figure 4.2).\nThis time, we want to generate a discrete r.v. Xsuch that\nX=⎧\n⎪⎪⎨\n⎪⎪⎩x0with prob p0\nx1with prob p1\n...\nxkwith prob pk.\nU(0,1)\n0X1\nx0x1 x2 x3p0p1p2p3\nFigure 4.2. Generating a discrete random variable with 4 values.\nSolution:\n1.Arrange x0,...,x ks.t.x0<x 1<...<x k.\n2.Generate u∈U(0,1).\n3.If0<u≤p0, then output x0.\nIfp0<u≤p0+p1, then output x1.\nIfp0+p1<u≤p0+p1+p2, then output x2.\nIf/summationtext/lscript−1\ni=0pi<u≤/summationtext/lscript\ni=0pi, then output x/lscript, where 0≤/lscript≤k.\nNotice that again our g(·)function is FX(·), the cumulative distribution function.\nThis sounds easy enough, but it is not always practical. If Xcan take on many values,\nthen we have to compute many partial sums:/summationtext/lscript\ni=0pifor all 0≤/lscript≤k. For this\nmethod to be practical, we therefore need closed-form expressions for/summationtext/lscripti=0pifor all\n/lscript. Equivalently, we need a closed form for FX(x)=P{X≤x}for any x. Then we\ncould do the same thing as in the continuous case, as in ( 4.1): generate u∈U(0,1),\nand return x=F−1\nX(u). Thus, as in the continuous case, we need to both have a\nclosed-form expression for the cumulative distribution function and also know how to\ninvert this function.\n4.2 Accept-Reject Method\nThe Inverse-Transform method required knowing the cumulative distribution function,\nFX(·). However, there are many cases where we do not know the c.d.f., FX(·), but only\nknow the p.d.f., fX(·). For example, suppose we want to generate a random variable\nfrom the Normal distribution, whose c.d.f. is not known. We thus need a new method.\n4.2accept-reject method 73\nThe Accept-Reject method involves generating instances of the desired random vari-\nable, but throwing away (rejecting) some of the generated instances until the desiredp.d.f (or p.m.f.) is met. It is easiest to explain the method for the case of a discrete r.v.ﬁrst.\n4.2.1 Discrete Case\nThe Accept-Reject method requires the following structure:\nGiven : Efﬁcient method for generating random variable Qwith probability mass\nfunction{qj,j:discrete}, where qj=P{Q=j}.\nOutput : Random variable Pwith probability mass function {pj,j:discrete}, where\npj=P{P=j}.\nRequirement : For all j, we must have qj>0⇐⇒pj>0. That is, PandQtake on\nthe same set of values.\nExample: Suppose we want to generate\nP=⎧\n⎨\n⎩1with prob p1=0.36\n2with prob p2=0.24\n3with prob p3=0.40.\nWe know how to generate\nQ=⎧\n⎨\n⎩1with prob q1=0.33\n2with prob q2=0.33\n3with prob q3=0.33.\nAny ideas? We are looking for a method where we generate an instance of Q, and then\nwe either choose to accept the value or reject it. If we accept it, that becomes the valueof\nP.\nIdea #1: Suppose we generate an instance jofQand accept it with probability pj?\nQuestion: What are the disadvantages to this approach?\nAnswer: The obvious disadvantage is the time needed to output a value of P. Suppose\nthe number of possible values is n, andnis high. Then qj=1\nn, and most pj’s will\nbe very low – certainly it could be the case that all pj’s are approximately1\nnbut not\nexactly. In this case, the time needed to output a value is on the order of n.\nAnother disadvantage of Idea #1 is that in general Qmay not have a uniform distribu-\ntion, so we need to normalize the acceptance probabilities.\nIdea #2: Suppose we generate an instance jof Q and accept it with probabilitypj\nqj?\nThat is, with probabilitypj\nqj, we return P=j, and with probability 1−pj\nqj,w eﬂ i p\nagain.\n74 generating random variables for simulation\nQuestion: What is the intuition behind Idea #2?\nAnswer: Suppose Qis not uniform, and Qhas an especially low probability of\ngenerating j. Then we will make up for that by having a higher than pjprobability of\naccepting jwhen it is generated.\nQuestion: What is wrong with Idea #2?\nAnswer: It requires that pj≤qj,∀j, which cannot be true if P/negationslash=Q.\nBut we can work with Idea #2. We just need a normalizing constant. Let cbe a constant\nsuch that\npj\nqj≤c,∀js.t.pj>0.\nObserve c>1.\nAccept-Reject Algorithm to generate discrete r.v. P :\n1.Find r.v. Qs.t.qj>0⇔pj>0.\n2.Generate an instance of Q, and call it j.\n3.Generate r.v. U∈(0,1).\n4.IfU<pj\ncqj, return P=jand stop; else return to step 2.\nWe will now prove that the Accept-Reject algorithm does in fact result in a Pwith the\nappropriate distribution.\nWe want to prove that\nP{Pends up being set to j(as opposed to some other value) }=pj.\nNow observe that\nP{Pends up being set to j}=Fraction of time jis generated and accepted\nFraction of time any value is accepted.\nFraction of time jis generated and accepted\n=P{jis generated }·P{jis accepted given jis generated }\n=qj·pj\ncqj=pj\nc.\nFraction of time any value is accepted\n=/summationdisplay\njFraction of time jis generated and is accepted\n=/summationdisplay\njpj\nc=1\nc.\n4.2accept-reject method 75\nSo,\nP{Pends up being set to j}=pj\nc\n1\nc=pj\nas desired.\nQuestion: On average, how many values of Qare generated before one is accepted?\nAnswer: c. (The fraction of time any value is accepted is1\nc.)\nIn our example,\nc=m a x/parenleftbigg0.36\n0.33,0.24\n0.33,0.40\n0.33/parenrightbigg\n=1.2.\nThus we only need 1.2iterations on average.\n4.2.2 Continuous Case\nThe Accept-Reject method works the same way for continuous random variables,\nexcept that we now use probability density functions, rather than probability mass\nfunctions.\nGiven: We know how to generate Ywith probability density function fY(t).\nGoal: To generate Xwith p.d.f. fX(t).\nRequirement: For all t,\nfY(t)>0⇐⇒fX(t)>0.\nAccept-Reject Algorithm to generate continuous r.v. X:\n1.Find continuous r.v. Ys.t.fY(t)>0⇔fX(t)>0. Letcbe a constant\nsuch that\nfX(t)\nfY(t)≤c,∀ts.t.fX(t)>0.\n2.Generate an instance tofY.\n3.With probabilityfX(t)\nc·fY(t), return X=t(i.e. “accept t” and stop). Else reject\ntand return to step 2.\nSimple Example\nSuppose we want to generate a r.v. Xwith p.d.f.:\nfX(t)=2 0 t(1−t)3,0<t< 1\nIf you plot this function, it looks like Figure 4.3. Observe that Xhas positive p.d.f.\nonly in the interval (0,1). Thus we want to choose a Ythat is easy to generate and\nalso has positive p.d.f. only in (0,1).\n76 generating random variables for simulation\nt\n00.511.522.5\n0.2 0.4 0.6 0.8 1\nFigure 4.3. Plot of fX(t).\nQuestion: Any ideas for what fY(t)should be?\nAnswer: Consider simply fY(t)=1 , where 0<t< 1.\nQuestion: Suppose we now apply the Accept-Reject method. What will cbe?\nAnswer: cshould not be too bad – just over 2 based on the plot. To determine c\nprecisely, we want to determine\nmax\nt/braceleftbiggfX(t)\nfY(t)/bracerightbigg\n=m a x\nt/braceleftbig\n20t(1−t)3/bracerightbig\n.\nTaking the derivative with respect to t, and setting it equal to zero, we have\nd\ndt(20t(1−t)3)=0⇔t=1\n4.\nSo the maximum value is obtained when t=1\n4:\nfX/parenleftbig1\n4/parenrightbig\nfY/parenleftbig1\n4/parenrightbig=2 0/parenleftbigg1\n4/parenrightbigg/parenleftbigg3\n4/parenrightbigg3\n=135\n64=c. (4.2)\nObserve how easy it was to make a good guess for fY(t)just by looking at the plot of\nfX(t).\nExample: Generating Normal Random Variable\nFor the previous example we could have used the Inverse-Transform method. Now let’s\ntry an example where we cannot apply the Inverse-Transform method.\nGoal: Generate N∼Normal (0,1).\nIdea: It will be enough to generate X=|N|and then multiply Nby−1with proba-\nbility0.5.\nSo how do we generate such an X? A plot of Xis shown in Figure 4.4. LetfX(t)be\nthe p.d.f of X:\nfX(t)=2√\n2πe−t2\n2,0<t<∞\n4.2accept-reject method 77\n00.20.40.60.81\n2468 1 0fX(t)\nfY(t)\nt\nFigure 4.4. Solid line shows fX(t). Dashed line shows proposed fY(t).\nQuestion: The idea is now to think of a random variable Ythat we know how to\ngenerate, such that fY(t)(the p.d.f. of Y)ﬁ t sfX(t)reasonably well. Can you think of\nsuch a Y?\nAnswer: LetY∼Exp(1).\nfY(t)=e−t,0<t<∞\nObserve that fX(t)is not too much higher than fY(t), according to Figure 4.4.\nQuestion: How many iterations are needed on average?\nAnswer: We need to determine c.\nfX(t)\nfY(t)=2√\n2πe−t2\n2+t=/radicalbigg\n2\nπet−t2\n2\nSo, the maximum value occurs when t−t2\n2is maximized.\n0=d\ndt/parenleftbigg\nt−t2\n2/parenrightbigg\n=1−t⇒t=1\nSo,\nc=fX(1)\nfY(1)=/radicalbigg\n2e\nπ≈1.3.\nThus we only need 1.3iterations on average!\n4.2.3 Some Harder Problems\nConsider a Poisson r.v. with mean λ.\npi=P{X=i}=e−λλi\ni!\nObserve that there are an inﬁnite number of pi’s. There is no closed form for F(i)=\nP{X≤i}so the Inverse-Transform method will not work.\nIt looks like we should be able to apply the Accept-Reject method, but it is hard to ﬁnd\nthe right distribution to match up to (for more discussion see [ 116], p. 503).",8861
30-4.3 Readings.pdf,30-4.3 Readings,,0
31-Chapter 5 Sample Paths Convergence and Averages.pdf,31-Chapter 5 Sample Paths Convergence and Averages,"78 generating random variables for simulation\nIn Chapter 11, we see that the Poisson distribution can be viewed as counting the\nnumber of instances of an Exponentially distributed random variable that occur by a\nﬁxed time. This gives us another way of generating Poisson random variables – by\ngenerating many instances of an Exponential random variable.\n4.3 Readings\nA lot more is known about simulating random variables than we have described in this\nchapter. Some particularly well-written texts are [ 148] (see Chs. 4 and 5) and [ 116] (see\nCh. 8).\n4.4 Exercises\n4.1 Generating Random Variables for Simulation (from [ 148]).\nGive an algorithm for generating a r.v. having the following density function\nf(x) = 30( x2−2x3+x4),where 0≤x≤1.\n4.2 Inverse-Transform Method\nExplain how to generate values from a continuous distribution with densityfunction\nf(t)=5\n4t−2, where 1<t< 5,givenu∈U(0,1).\n4.3 Simulation of M/M/1\nThis problem asks you to simulate a single M/M/1 queue. Do not worry; you\ndo not need to know what this notation means – everything you need to know\nis explained in this problem. Use any programming language you like.\nThe job sizes are distributed according to Exp (μ), where μ=1. The interarrival\ntimes between jobs are i.i.d. according to Exp (λ).\nConsider three cases: λ=0.5,λ=0.7, andλ=0.9. Your goal is to measure\nthe mean response time E[T]for each load level (each value of λ). Do this by\naveraging independent samples.\nLet one “run” of the simulator consist of running the system from the empty\nstate for 2,000 arrivals, and then record the response time experienced by ar-\nrival number 2,001. Perform n= 200 (independent) runs, each of which will\ngenerate one “sample,” and then determine the mean of the n= 200 samples.",1776
32-5.1 Convergence.pdf,32-5.1 Convergence,"CHAPTER 5\nSample Paths, Convergence,\nand Averages\nIf you are a theoretician, you probably are already starting to get uncomfortable with\nthe way we use the word “average” without carefully deﬁning it and, in particular,with the way we deﬁne the load\nρby seemingly dividing two averages ( ρ=1/μ\n1/λ=λ\nμ).\nEverything we have said is correct, but we would like to prove this, rather than just\nassuming it. This chapter sets up the groundwork to allow us to make such claims about\naverages.\nBefore we can talk about averages, we ﬁrst need to discuss convergence of random\nvariables. In this chapter, we deﬁne the convergence of random variables and statesome limit theorems. We then deﬁne two types of averages: ensemble averages and\ntime averages. These are needed for the next chapter on Little’s Law, which will allow\nus to formally relate mean response time to the mean number of jobs in the system and\nto properly deﬁne the load,\nρ.\nThis chapter is more theoretically oriented and abstract than the rest of this book. It\nis not necessary for the reader to follow everything in this chapter to understand laterchapters. A reader might wish to skim the chapter to pick up the basic terminology and\nthen come back later for a more in-depth reading.\nAlthough this chapter is somewhat formal, we are still just grazing the surface of this\nmaterial. If you really want to understand the concepts in depth, we recommend readinga measure-theory book such as Halmos’s book [ 80].\n5.1 Convergence\nRecall from high school the standard deﬁnition of convergence of a sequence of\nnumbers:\nDeﬁnition 5.1 A sequence {an:n=1,2,...}converges to basn→∞ , written\nan−→b,asn→∞\nor equivalently,\nlim\nn→∞an=b\nif∀/epsilon1>0,∃n0(/epsilon1), such that∀n>n 0(/epsilon1),w eh a v e|an−b|</epsilon1.\n79\n80 sample paths, convergence, and averages\nThis is very easy to think about because the ai’s are constants. It says that a sequence\nconverges to bif, for any given “degree of convergence,” /epsilon1, one can ﬁnd some index\npoint in the sequence (call that point n0(/epsilon1)) such that, beyond that point, all elements\nof the sequence are within /epsilon1ofb.\nWe now need a similar deﬁnition for random variables. The point to remember is that\na random variable becomes a constant for each possible outcome of an experiment .\nWe refer to the outcome of the experiment as a sample path . For example, consider a\nrandom variable, Z, equal to the larger of two rolls of a die. Given a particular sample\npath,ω=( 4,6), we know that the value of Zis exactly 6.\nAs another example, consider a sequence of random variables: {Yn:n=1,2,...},\nwhere Yndenotes the average of the ﬁrst ncoin ﬂips. Here again, these are all variables.\nNow consider a sample path ,ω, consisting of an inﬁnite sequence of coin ﬂips (e.g.\nω= 01101001011 ...). If we evaluate the sequence of random variables on ω,w e\nhave a sequence of constants: {Yn(ω):n=1,2,...}={0,1\n2,2\n3,1\n2,3\n5,...}.\nDeﬁnition 5.2 The sequence of random variables {Yn:n=1,2,...}converges\nalmost surely toμ, written\nYna.s.−→μ,asn→∞\nor equivalently, the sequence converges with probability 1 , written\nYn−→μ,asn→∞ w.p.1\nif\n∀k>0,P/braceleftBig\nlim\nn→∞|Yn−μ|>k/bracerightBig\n=0.\nTheP{...}in the previous expression is over the set of sample paths. More precisely\nwe might write\n∀k>0,P/braceleftBig\nω: lim\nn→∞|Yn(ω)−μ|>k/bracerightBig\n=0\n(although no one actually writes this).\nTo understand Deﬁnition 5.2, consider the sequence of random variables, {Yn:n=\n1,2,...}, evaluated on a particular sample path, ω0, yielding the sequence of constants,\n{Yn(ω0):n=1,2,...}. Now look at the limit of this sequence of constants and ask\nwhether it deviates from μby more than k. We say that the sample path ω0behaves well\nif the sequence of constants, {Yn(ω0):n=1,2,...}, converges to μ(meaning it is\nwithin kofμfor all k>0asn→∞ ) and that it behaves badly otherwise. Likewise,\nthe sample path ω1behaves well if the sequence of constants, {Yn(ω1):n=1,2,...},\nconverges to μ.\nQuestion: What does P{ω: lim n→∞|Yn(ω)−μ|>k}represent?\n5.1convergence 81\nAnswer: This represents the mass (probability) of sample paths that behave badly in\nthat, for each such bad sample path, ω, the limit of the sequence {Yn(ω):n=1,2,...}\nis notμor does not exist.\nAlmost sure convergence occurs when, on almost all sample paths, the sequence of\nrandom variables will, after some point, start behaving well and continue behavingwell from that point on. That is, almost all sample paths\nωhave the property that the\nsequence{Yn(ω):n=1,2,...}converges to μ. The mass comprising sample paths\nthat do not have this property has probability zero – meaning, there may be some\nsample paths that do not have this property, but these paths have a total “mass” of zero.\nFigure 5.1shows an illustration of almost sure convergence.\nY(ω2)Y(ω1)\nY(ω3)\nY(ω4)nµ\nFigure 5.1. Illustration of the concept of almost sure convergence. The dotted line indicates μ.\nY(ω1)is shorthand for the sequence of constants: {Yn(ω1):n=1,2,...}. All four sample\npaths shown, after some point, behave well – meaning that the sequence of constants, created\nby evaluating {Yn:n=1,2,...}on that sample path, converges to μ.\nQuestion: In the case where Ynrepresents the average of the ﬁrst ncoin ﬂips, what do\nwe expect the sequence {Yn(ω):n=1,2,...}to converge to?\nAnswer: Assuming a fair coin,1\n2.\nQuestion: Why can’t we say that this convergence holds for all sample paths?\nAnswer: There are always some sample paths, such as the coin ﬂips 1111..., that do\nnot average to1\n2no matter how far out we look. Luckily the total measure made up by\nsuch sample paths is zero.\nQuestion: How many badly behaving sample paths are there? A ﬁnite number? Count-\nably many? Uncountably many?\nAnswer: Actually there are uncountably many such bad paths, each occurring with\nprobability zero and summing to a measure of zero.\nQuestion: How can we determine that there are uncountably many bad paths?\nAnswer: Let’s refer to the sequence 110 as a “red car” and to the sequence 101 as a\n“blue car.” Now any sequence made up of red and blue cars is clearly bad (because it\nhas twice as many 1’s as 0’s). However, there are an uncountable number of possiblesequences of red and blue cars, because there are an uncountable number of binarysequences (by Cantor’s diagonalization argument).\n82 sample paths, convergence, and averages\nWe now present another deﬁnition of convergence of random variables that is sometimes\nused.\nDeﬁnition 5.3 The sequence of random variables {Yn:n=1,2,...}converges\nin probability toμ, written\nYnP−→μ,asn→∞\nif\n∀k>0,lim\nn→∞P{|Yn−μ|>k}=0.\nTheP{...}in Deﬁnition 5.3is over the set of possible sample paths, ω. More precisely\nwe might write\n∀k>0,lim\nn→∞P{ω:|Yn(ω)−μ|>k}=0 (5.1)\n(although no one actually writes this).\nTo understand Deﬁnition 5.3, again consider the sequence of random variables, {Yn:\nn=1,2,...}, evaluated on a particular sample path, ω0. This time, however, look only\nat thenth constant in the resulting sequence of constants, Yn(ω0). If that nth constant,\nYn(ω0), deviates from μby more than k, we say that the sample path ω0behaves\nbadly for Yn. Let’s repeat the experiment for a different sample path, ω1. Consider the\nsequence{Yn(ω1):n=1,2,...}. Again look only at the nth constant, Yn(ω1), and\nask whether Yn(ω1)deviates from μby more than k. If so, then the sample path ω1\nbehaves badly for Yn.\nQuestion: What does P{ω:|Yn(ω)−μ|>k}represent?\nAnswer: The probability comprising sample paths that behave badly for the nth r.v.,\nYn. This is a number between 0and1.\nQuestion: What does P{ω:|Yn+1(ω)−μ|>k}represent?\nAnswer: The probability comprising sample paths that behave badly for the n+1th\nr.v.,Yn+1.\nNote that YnandYn+1may behave badly on different sample paths. We are only\ninterested in the mass (probability) of sample paths that are bad for Yn, the mass that\nare bad for Yn+1, the mass of those that are bad for Yn+2, etc.\nQuestion: What is limn→∞P{ω:|Yn(ω)−μ|>k}?\nAnswer: This is the limit of a sequence of probabilities: the probability comprising\nsample paths that are bad for Yn, the probability comprising sample paths that are bad\nforYn+1, the probability comprising sample paths that are bad for Yn+2, etc. If this\nlimit,limn→∞P{ω:|Yn(ω)−μ|>k}, exists and is zero for all k>0, then we say\nthat the sequence of random variables {Yn:n=1,2,...}converges in probability\ntoμ.",8498
33-5.3 Time Average versus Ensemble Average.pdf,33-5.3 Time Average versus Ensemble Average,"5.2strong and weak laws of large numbers 83\nQuestion: Given the deﬁnition of a limit of a sequence of constants, how could we\nexpand the deﬁnition of convergence in probability to replace the limit in there?\nAnswer:\n∀k>0,∀/epsilon1>0,∃n0(/epsilon1)s.t.∀n>n 0(/epsilon1),|P{ω:|Yn(ω)−μ|>k}|</epsilon1 .\nQuestion: Which is stronger: almost sure convergence or convergence in probability?\nAnswer: Almost sure convergence implies convergence in probability. Here is the\nintuition: Given almost sure convergence, we know that (almost) all sample paths\neventually do the right thing, each from some n0(ω)point onward. Thus, looking out\nat higher and higher n, we see that the number of sample paths behaving badly past\nthat point gets smaller and smaller. From this it seems intuitive that the mass of sample\npaths behaving badly gets smaller and smaller as we look at further out values of n.\nNote that this is only intuition, because the total number of sample paths also grows\nwithn. Thus it is hard to immediately claim that the probability comprising paths\nbehaving badly decreases for all nvalues.\nQuestion: Explain how a sequence {Yn}might converge in probability but notalmost\nsurely.\nAnswer: Even if{Yn}converges in probability, it could still be the case that nosample\npath has the property that from some point onward it behaves well. For example, each\nsample path may have occasional spikes; however, these spikes get further and furtherapart for large\nn. Thus for no sample path ωdoes{Yn(ω):n=1,2,...}converge.\nHowever, for any ﬁxed nthe fraction of sample paths ωunder which Yn(ω)is far from\nμis small – and gets smaller as we increase n. This is illustrated in Figure 5.2.\nY(ω2)Y(ω1)\nY(ω3)nµ\nFigure 5.2. Illustration of the convergence in probability without almost sure convergence.\nAgain, the dotted line indicates μ.\n5.2 Strong and Weak Laws of Large Numbers\nTheorem 5.4 (Weak Law of Large Numbers) LetX1,X2,X3,... be i.i.d. ran-\ndom variables with mean E[X].L e t\nSn=n/summationdisplay\ni=1Xiand Yn=Sn\nn.\n84 sample paths, convergence, and averages\nThen\nYnP−→E[X],asn→∞.\nThis is read as “ Ynconverges in probability to E[X], ” which is shorthand for the\nfollowing:\n∀k>0,lim\nn→∞P{|Yn−E[X]|>k}=0.\nTheorem 5.5 (Strong Law of Large Numbers) LetX1,X2,X3,... be i.i.d.\nrandom variables with mean E[X].L e t\nSn=n/summationdisplay\ni=1Xiand Yn=Sn\nn.\nThen\nYna.s.−→E[X],asn→∞.\nThis is read as “ Ynconverges almost surely to E[X]”o r“Ynconverges to E[X]\nwith probability 1, ” which is shorthand for the following:\n∀k>0,P/braceleftBig\nlim\nn→∞|Yn−E[X]|≥k/bracerightBig\n=0.\nQuestion: Going back to the example where the Xi’s are all 0/1random variables\nwith mean1\n2, what is the Strong Law of Large Numbers saying?\nAnswer: Each sample path is an inﬁnite sequence of coin ﬂips. The Strong Law says\nthat for “almost every” sample path, if we average the coin ﬂips far out enough along\nthe path, we will get convergence to1\n2from that point onward. As we have discussed,\neven if there are uncountably many bad paths that do not behave this way, the mass\ncomprising those paths is zero, when compared to all the well-behaved sample paths.\nThe proof of the Weak Law of Large Numbers is derived in Exercise 5.1. The proof\nof the Strong Law is much more involved (as are many proofs regarding almost all\nsample paths). There are several different proofs; one of the simpler versions is givenin Ross [ 149], pp. 56–58.\n5.3 Time Average versus Ensemble Average\nYou may think that the concept of an “average” is quite clear. However, in stochastic\nprocesses there are multiple types of averages. Two of these types are the time average\nand the ensemble average .\nTo keep this discussion from becoming too abstract, we will repeatedly return to the\nfollowing simple example: a single FCFS queue in which at every second a new job isadded to the queue with probability\npand at every second the job in service (if there\n5.3time average versus ensemble average 85\nis one) is completed with probability q, where q>p . LetN(v)=number of jobs in\nthe system at time v.\n5.3.1 Motivation\nOnce upon a time there were two students in my class, Tim and Enzo (see Figure 5.3).\nTim was very tall and long, and he looked very much like a time-line. Enzo was more\n2-dimensional looking (if they both look a little like robots, remember that this is a\ncomputer science department). Both Tim and Enzo were trying to simulate their FCFS\nqueue to determine the average number of jobs in the system.\nTim\nEnzo\nFigure 5.3. Tim and Enzo.\nTim, who saw the world as a time-line, generated onevery long sequence of coin ﬂips\n(a single process), which he used to simulate the queue over a very, very long period\nof time, as shown in Figure 5.4. During the running of this queue, Tim logged the\nnumber of jobs in the system each second, obtaining a million samples. Then he took\nthe average over all the million samples in his log to get the “average number of jobs.”\nEnzo took a more 2-dimensional approach. Instead of averaging over one long simula-\ntion of length 1,000,000, he generated 1,000 shorter simulations, each of length 1,000.\nFor each simulation, he would wait until his simulation had run for t=1,000seconds,\nand then he would sample the queue at exactly time t, obtaining onevalue for N(t),\nthe number of jobs at time t. Enzo then restarted the experiment from scratch (with a\noznE miT\nFigure 5.4. Tim and Enzo’s different simulation approaches.\n86 sample paths, convergence, and averages\nnew random seed) and again simulated the queue until time t, when he sampled the\nnumber of jobs, obtaining one more value. Enzo continued to restart his experiment\na thousand times. Each time, he would run his simulation until time tand obtain one\nmore sample for the number of jobs. After obtaining a thousand samples, he averaged\nthese to get the “average number of jobs.”\nQuestion: Who is “right”? Tim or Enzo?\nAnswer: We will soon see . . .\n5.3.2 Deﬁnition\nDeﬁnition 5.6\nNTime Avg= lim\nt→∞/integraltextt\n0N(v)dv\nt.\nDeﬁnition 5.7\nNEnsemble= lim\nt→∞E[N(t)] =∞/summationdisplay\ni=0ipi\nwhere\npi= lim\nt→∞P{N(t)=i}\n=mass of sample paths with value iat time t.\n5.3.3 Interpretation\nWhen we talk about a time average we implicitly have in mind a particular sample path\nωover which we are taking the time average. Thus a more precise deﬁnition might be\nas follows:\nDeﬁnition 5.8\nNTime Avg(ω) = lim\nt→∞/integraltextt\n0N(v,ω)dv\nt,\nwhere N(v,ω)represents the number of jobs in the system at time vunder sample\npathω.\nThus the time average, NTime Avg, is deﬁned by observing a single sample path over\na long period of time, t, as shown in Figure 5.5. During this long period of time, we\nmonitor the number of jobs in the system, and then we take the average over time.\nThe important point here is that we are looking at a single process – one sequence of\n5.3time average versus ensemble average 87\ncoin ﬂips ,ω. Consider the example of the single server. The queue might start empty\n(N(0,ω)=0 ). Then at time 1, there might be an arrival but no departure ( N(1,ω)=\n1). At time 2, there might again be an arrival but no departure ( N(2,ω)=2 ). At time\n3, there might again be an arrival but no departure ( N(3,ω)=3 ). Now at time 4, there\nmight be no arrival and a departure ( N(4,ω)=2 ), etc. The average number of jobs\nin the system by time 4 for this process is ( 0+1+2+3+2 ) /5=8/5. We could\ncontinue looking at this process up to time tfor some huge time tin the future and ask\nwhat is the average number of jobs in the system for this process by time t.I ftis really\nlarge, we hope that the average number of jobs in the system for this sample path, ω,\nconverges. We then call this limit the time average number of jobs in the system along\nsample path ω.\ntime νN(ν,ω)\nFigure 5.5. Time average for sample path ω.\nYet the time average number may seem suspicious because we are only looking at a\nsingle sequence of coin ﬂips. Perhaps this was a particularly unusual sequence?\nThe ensemble average, NEnsemble, is what we more typically mean when we talk about\nthe average number of jobs in the system, E[N]. This represents the expected number\nof jobs in the system when the system is in steady state. ( Note: the term “steady state”\nwill only be formally deﬁned when we get to Markov chains. For now consider steady\nstate to be some point in time where the effects of the initial starting state are longgone.) The ensemble average takes into account all possible sequences of coin ﬂips\n– all sample paths, as shown in Figure 5.6. Consider again the example of the single\nserver. Again the system might start empty (\nN(0) = 0 ). Considering all possible events\nduring the ﬁrst time step, we see that at time 1 there is some probability that the system\nis still empty and there is some probability that the system contains one job. Thus we\ncan compute E[N(1)], the expected number of jobs at time 1. Now at time 2, again\nconsidering all possible sequences of coin ﬂips and their likelihoods, we can again\nsee that there is some probability that the system is empty, some probability that the\nsystem contains 1 job, and some probability that the system contains 2 jobs. We can\nthus compute E[N(2)], the expected number of jobs in the system at time 2. Likewise,\nfor any time twe can compute E[N(t)]. If we choose tlarge enough ( t→∞ ), under\ntypical conditions there will be some limiting probability that the system contains 0\njobs,p0, and some limiting probability that the system contains 1 job, p1, and some\nlimiting probability that the system contains 2 jobs, p2, and some limiting probability\nthat the system contains ijobs, for any i,pi. The expectation of these,/summationtext∞\ni=0ipi,i s\nexactly what we mean by NEnsemble.\n88 sample paths, convergence, and averages\ntime\ntY(ω2)Y(ω1)\nY(ω3)\nY(ω4)\nFigure 5.6. Ensemble average.\nQuestion: Which type of average is Tim? Which type is Enzo?\nAnswer: Tim is measuring a time average, whereas Enzo is measuring the ensemble\naverage.\nRemark: As a practical matter, both Tim and Enzo need to be concerned about initial\nconditions, but in different ways. Enzo needs to be sure his initial conditions have\nattenuated sufﬁciently before his measurement point, whereas Tim needs to make sure\nthe portion of his simulation that is affected by initial conditions is sufﬁciently small.\n5.3.4 Equivalence\nHow does NTime Avgcompare with NEnsemble?\nTheorem 5.9 For an “ergodic” system (see Deﬁnition 5.10), the ensemble average\nexists and, with probability 1,\nNTime Avg=NEnsemble.\nThat is, for (almost) all sample paths, the time average along that sample path\nconverges to the ensemble average.\nThis theorem is discussed in greater detail and proven in Chapter 9. The intuition,\nhowever, is very simple. To explain the intuition, we ﬁrst need to explain the term\n“ergodic.”\nQuestion: First, do you have any intuition about what conditions might be required to\nmake the time average equal to the ensemble average?\nDeﬁnition 5.10 Anergodic system is one that is positive recurrent, aperiodic, and\nirreducible.\n5.3time average versus ensemble average 89\nThese terms are all deﬁned precisely in Chapter 9, but we explain the ideas now. We\nstart with irreducibility . Irreducibility says that a process should be able to get from\nany state to any other state (think of the state as the number of jobs in the system). This\nis important for ensuring that the choice of initial state does not matter.\nThepositive recurrent property is the most important condition with respect to under-\nstanding the equivalence between the time average and the ensemble average: Given\nan irreducible system, in which we can get to any state, the system is positive recurrent\nif for any state i, the state is revisited inﬁnitely often, and the mean time between visits\nto state i(renewals) is ﬁnite. Furthermore, every time that we visit state ithe system\nwill probabilistically restart itself.\nQuestion: Give an example of what it means for the process to probabilistically restart\nitself.Answer: Every time that the system empties (\n0jobs), the process starts anew in state\n0. We call this a “restart.” In a positive recurrent system, the system empties inﬁnitely\noften. This includes all systems that we will study.Consider our example of a queue, where a new job is created at each time step with\nprobability\npand a job is removed with probability q>p . We start out with zero jobs\nin the system. We now start ﬂipping coins, and the number of jobs in the system goes\nup and down. At some point, the number of jobs in the system returns to zero. At this\npoint, we can imagine the same statistical process starting over again. And the nexttime the number of jobs in the system returns to zero, it will start over again. Thus a\nsingle long run of the system (Tim’s view) actually appears to be an inﬁnite number ofstatistically independent runs (Enzo’s view).\nThe aperiodicity condition is important in making sure that the ensemble average\nexists. Aperiodicity refers to the fact that the system state (number of jobs in the\nsystem) should not be tied in some particular way to the time step; for example, itshould not be the case that the system is always in state\n0for even time steps and state 1\nfor odd time steps; otherwise, the particular tthat Enzo picked for stopping the system\nmight sway his result.\nQuestion: Explain intuitively why an ergodic system should have the property that the\ntime average equals the ensemble average.\nAnswer: Consider the time average over a single long run of the system as shown in\nFigure 5.7. This run can be thought of as a chain of many independent but statistically\nidentical runs, each called a “renewal.” Let X1represent the time average over just\nRestart Restart Restart Restart Restart\nFigure 5.7. Single process restarting itself.\n90 sample paths, convergence, and averages\nthe ﬁrst renewal, let X2represent the time average over just the second renewal, etc.\nThen the overall time average is the average of X1,X2,.... But these are i.i.d. So,\nby the Strong Law of Large Numbers (SLLN), the average of these converges withprobability 1 to the expected time average over a single renewal, where the expectation\nis an ensemble average (taken over all sample paths).\n5.3.5 Simulation\nWhat does all this say about how we do simulation? Tim’s method of sampling a\nsingle process over a very long period of time and averaging those samples results in\nNTime Avg. Enzo’s method of generating many independent processes and taking their\naverage at some far-out time tyields NEnsemble. If these yield the same result, should\nwe go for the easier method?\nQuestion: The ensemble average seems more costly to compute, because we need new\nrandom seeds. Why bother with the ensemble average if it comes out to the same thing\nas the time average?\nAnswer: The main reason is that the ensemble average can be obtained in parallel,\nby running simulations on different cores or different machines. Another reason forusing the ensemble average is that the independent data points allow us to generateconﬁdence intervals, which allow us to bound the deviation in our result.\nQuestion: Why in both the deﬁnitions of ensemble average and time average is it so\nimportant that the system be run for a “long” time?\nAnswer: We want to get to the point where the initial state has no effect: We want to\nreach “steady state.” This will all become more clear when we get to Markov chain\ntheory.\n5.3.6 Average Time in System\nSo far, we have talked about the average number of jobs in the system. We can also\ndeﬁne two versions of the average time in system as follows:\nTTime Avg= lim\nt→∞/summationtextA(t)\ni=1Ti\nA(t),\nwhere Tiis the time in system of the ith arrival and A(t)is the number of arrivals by\ntimet. Again the time average is assumed to be associated with a single sample path.\nTEnsemble= lim\ni→∞E[Ti],\nwhereE[Ti]is the average time in system of the ith job, where the average is taken\nover all sample paths.",16168
34-5.4 Related Readings.pdf,34-5.4 Related Readings,,0
35-5.5 Exercise.pdf,35-5.5 Exercise,"5.5exercise 91\n5.4 Related Readings\nThe following books provide more detail on the information covered in this chapter:\nKarlin and Taylor (pp. 474–89) [ 105], and Gross and Harris (pp. 38–45) [ 75].\n5.5 Exercise\n5.1 Weak Law of Large Numbers\nLetX1,X2,X3, ..., b e i . i . d . r andom variables with ﬁnite mean E[X]and\nﬁnite variance σ2. Your goal is to prove the Weak Law of Large Numbers:\n∀/epsilon1,lim\nn→∞P/braceleftbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingleS\nn\nn−E[X]/vextendsingle/vextendsingle/vextendsingle/vextendsingle>/epsilon1/bracerightbigg\n=0\nwhere Sn=/summationtextn\ni=1Xi.\n(a) Start out by proving Markov’s Inequality, which says: If Xis non-negative\nthen\nP{X>t}≤E[X]\nt,∀t>0.\n(b) Now use Markov’s Inequality to prove Chebyshev’s Inequality, which says:\nLetYbe a random variable with ﬁnite mean E[Y]and ﬁnite variance σ2\nY.\nThen\nP{|Y−E[Y]|≥t}≤σ2\nY\nt2.\n(c) Finally use Chebyshev’s Inequality to prove the Weak Law of Large\nNumbers.",989
36-Part III The Predictive Power of Simple Operational Laws What-If Questions and Answers.pdf,36-Part III The Predictive Power of Simple Operational Laws What-If Questions and Answers,"PART III\nThe Predictive Power of\nSimple Operational\nLaws: “What-If”\nQuestions and Answers\nPart IIIis about operational laws. Operational laws are very powerful because they\napply to any system or part of a system. They are both simple and exact. A very\nimportant feature of operational laws is that they are “distribution independent.” This\nmeans, for example, that the laws do not depend on the distribution of the job service\nrequirements (job sizes), just on their mean. Likewise the results do not depend on thedistribution of the job interarrival times, just on the mean arrival rate. The fact that theresults do not require the Markovian assumptions that we will see in Part IV, coupled\nwith the fact that using operational laws is so easy, makes these laws very popular with\nsystem builders.\nThe most important operational law that we will study is Little’s Law, which relates\nthe mean number of jobs in any system to the mean response time experienced byarrivals to that system. We will study Little’s Law and several other operational lawsin Chapter 6.\nIn Chapter 7we will see how to put together several operational laws to prove asymp-\ntotic bounds on system behavior (speciﬁcally, mean response time and throughput)for closed systems. Asymptotic bounds will be proven both in the limit as the multi-programming level approaches inﬁnity and in the limit as the multiprogramming levelapproaches 1. These asymptotic bounds will be very useful in allowing us to answer“what-if” questions of the form, “Is it preferable to increase the speed of the CPU bya factor of 2, or to increase the speed of the I/O device by a factor of 3, or does neitherreally make a difference?”\n93",1698
37-Chapter 6 Littles Law and Other Operational Laws.pdf,37-Chapter 6 Littles Law and Other Operational Laws,,0
38-6.2 Intuitions.pdf,38-6.2 Intuitions,"CHAPTER 6\nLittle’s Law and Other\nOperational Laws\nLittle’s Law is probably the single most famous queueing theory result. It states that\nthe average number of jobs in the system is equal to the product of the average arrivalrate into the system and the average time a job spends in the system. It also holds whenthe system consists of just the “queues” in the system. Little’s Law applies to both openand closed systems, and we explain it in both cases.\n6.1 Little’s Law for Open Systems\nLet’s ﬁrst consider open systems, as shown in Figure 6.1.\nTheorem 6.1 (Little’s Law for Open Systems) For any ergodic1open system we\nhave that\nE[N]=λE[T]\nwhereE[N]is the expected number of jobs in the system, λis the average arrival\nrate into the system, and E[T]is the mean time jobs spend in the system.\nArrivals (rate λ) Depart ures Any system\nTime in system, T\nFigure 6.1. Setup for Little’s Law.\nIt is important to note that Little’s Law makes no assumptions about the arrival process,\nthe service time distributions at the servers, the network topology, the service order, oranything!\nAt this point it may be hard to appreciate Little’s Law. Its usefulness stems from the\nfact that when we study Markov chains, we see many techniques for computing\nE[N].\nApplying Little’s Law will then immediately yield E[T].\n1The term ergodic was deﬁned brieﬂy in Section 5.3. In Section 6.4we elaborate on its purpose in Theorems 6.1\nand6.2.\n95",1447
39-6.4 Proof of Littles Law for Open Systems.pdf,39-6.4 Proof of Littles Law for Open Systems,"96 little’s law and other operational laws\n6.2 Intuitions\nThis section contains some intuitions to help you remember Little’s Law. They are not\nproofs! We will prove Little’s Law in Section 6.4.\nIt should seem intuitive that E[T]andE[N]are proportional. Consider the example\nof a fast-food restaurant [ 18]. It gets people out fast (low E[T]) and also does not\nrequire much waiting room (low E[N]). By contrast, a slow-service restaurant gets\npeople out slowly (high E[T]) and therefore needs a lot more seating room ( E[N]).\nThusE[T]should be directly proportional to E[N].\nHere is the way I always remember Little’s Law (intuition only): Think about a single\nFCFS queue, as shown in Figure 6.2. A customer arrives and sees E[N]jobs in the\nsystem. The expected time for each customer to complete is 1/λ(not1/μ), because\nthe average rate of completions is λ(see Section 2.5). Hence the expected time until\nthe customer leaves is E[T]≈1\nλ·E[N].\nFCFS\nRate λ\nFigure 6.2. Little’s Law applied to a single server.\n6.3 Little’s Law for Closed Systems\nIn a closed system, E[N]is ﬁxed at N, the multiprogramming level. Thus, for a closed\nsystem, the statement of Little’s Law is as follows:\nTheorem 6.2 (Little’s Law for Closed Systems) Given any ergodic closed system,\nN=X·E[T],\nwhere Nis a constant equal to the multiprogramming level, Xis the throughput\n(i.e., the rate of completions for the system), and E[T]is the mean time jobs spend\nin the system.\nFigure 6.3shows a batch system and an interactive (terminal-driven) system. Note\nthat for the interactive system (right), the time in system, T, is the time to go from\n“out” to “out,” whereas response time, R, is the time from “in” to “out.” Speciﬁcally,\nfor a closed interactive system , we deﬁne E[T]=E[R]+E[Z], where E[Z]is the\naverage think time, E[T]is the average time in system, and E[R]is the average\nresponse time. The notation is a little overloaded, in that for open systems and closedbatch systems, we refer to\nE[T]as mean response time, whereas for closed interactive\nsystems E[T]represents the mean time in system and E[R]is the mean response\ntime, since response time does not include thinking.\n6.4proof of little’s law for open systems 97\nSubsystemN jobs\nN jobs\nSubsystemin o ut in o ut\nFigure 6.3. Closed systems: A batch system (left) and an interactive system (right).\nRecall from Chapter 2that, for an open system , throughput and mean response time are\nuncorrelated. By contrast, Little’s Law tells us that, for a closed system, XandE[T]\nare inversely related, as are XandE[R].Thus in a closed system, improving response\ntime results in improved throughput and vice versa.\n6.4 Proof of Little’s Law for Open Systems\nWe are now ready to prove Little’s Law. This section focuses on open systems (see\nFigure 6.4). The next section concentrates on closed systems.\nArrivin g jobs Departin g jobs\nAny system\nFigure 6.4. Open system.\n6.4.1 Statement via Time Averages\nTheorem 6.3is a statement of Little’s Law as you will see it in the literature. As you see,\nLittle’s Law is actually stated as a relationship between time averages (see Section 5.3).\nLet\nλ= lim\nt→∞A(t)\ntandX= lim\nt→∞C(t)\nt,\nwhere A(t)is the number of arrivals by time tandC(t)is the number of system\ncompletions (departures) by time t. Observe that it is typically the case that λ=X\n(one could have λ>X if some arrivals get dropped, or if some jobs get stuck and\nnever complete for some reason).\n98 little’s law and other operational laws\nTheorem 6.3 (Little’s Law for Open Systems Restated) Given any system where\nNTime Avg,TTime Avg,λ, andXexist and where λ=X, then\nNTime Avg=λ·TTime Avg.\nObserve that Little’s Law is stated as an equality between time averages , not ensemble\naverages . Little’s Law says that the time-average number in system for sample path\nωis equal to λtimes the time-average time in system for that sample path. However,\nwe know that if we assume that the system is also ergodic , then the time average\nconverges to the ensemble average with probability 1; namely, on almost every sample\npath, the time average on that sample path will be equal to the ensemble average over\nall paths (see Section 5.3). Thus, assuming ergodicity, we can apply Little’s Law in an\nensemble-average sense, which we will do.\nConsider the requirements in Theorem 6.3. They are all subsumed by the assumption\nthat the system is ergodic , for if the system is ergodic then the above limits all exist\nand furthermore the average arrival rate and completion rate are equal, because the\nsystem empties inﬁnitely often. Furthermore, if we assume that the system is ergodic,then the time average is equal to the ensemble (or “true”) average. Thus it is sufﬁcientto require that the system is ergodic for Little’s Law, as stated in Theorem 6.1,t o\nhold.\n6.4.2 Proof\nProof (Theorem 6.3)LetTidenote the time that the ith arrival to the system spends\nin the system, as shown in Figure 6.5. Now, for any time t, consider the area, A,\ncontained within all the rectangles in Figure 6.5, up to time t(this includes most of the\nrectangle labeled T5). We ﬁrst view this area, A, by summing horizontally and then,\nequivalently, view it again by summing vertically.\nT6\nT4\nT3\nT2\nttime\nArrival\n1st jobDepart ure\n1st jobT1T5\nFigure 6.5. Graph of arrivals in an open system.\n6.4proof of little’s law for open systems 99\nThe horizontal view consists of summing up the Ti’s as follows: We observe that\n/summationdisplay\ni∈C(t)Ti≤A≤/summationdisplay\ni∈A(t)Ti\nwhere/summationtext\ni∈C(t)Tidenotes the sum of the time in system of those jobs that have\ncompleted by time t, and/summationtext\ni∈A(t)Tidenotes the sum of the time in system of those\njobs that have arrived by time t.\nThe vertical view of Aadds up the number of jobs in system at any moment in time,\nN(s), where sranges from 0tot. Thus,\nA=/integraldisplayt\n0N(s)ds.\nCombining these two views, we have\n/summationdisplay\ni∈C(t)Ti≤/integraldisplayt\n0N(s)ds≤/summationdisplay\ni∈A(t)Ti.\nDividing by tthroughout, we get\n/summationtext\ni∈C(t)Ti\nt≤/integraltextt\n0N(s)ds\nt≤/summationtext\ni∈A(t)Ti\nt\nor, equivalently,\n/summationtext\ni∈C(t)Ti\nC(t)·C(t)\nt≤/integraltextt\n0N(s)ds\nt≤/summationtext\ni∈A(t)Ti\nA(t)·A(t)\nt.\nTaking limits as t→∞ ,\nlimt→∞/summationtext\ni∈C(t)Ti\nC(t)·lim\nt→∞C(t)\nt≤NTime Avg≤lim\nt→∞/summationtext\ni∈A(t)Ti\nA(t)·lim\nt→∞A(t)\nt\n⇒TTime Avg·X≤NTime Avg≤TTime Avg·λ.\nYet we are given that Xandλare equal. Therefore,\nNTime Avg=λ·TTime Avg.\nQuestion: Are we assuming FCFS service order in this argument?\nAnswer: No, this argument does not depend on service order. Observe that the second\narrival departs after the third arrival departs.\nQuestion: Are we assuming anywhere that this is a single-server system?\nAnswer: No, this argument holds for any system.\n100 little’s law and other operational laws\n6.4.3 Corollaries\nCorollary 6.4 (Little’s Law for Time in Queue) Given any system where\nNTime Avg\nQ ,TTime AvgQ,λ, andXexist and where λ=X, then\nNTime Avg\nQ =λ·TTime AvgQ,\nwhere NQrepresents the number of jobs in queue in the system and TQrepresents\nthe time jobs spend in queues.\nQuestion: How would you prove Corollary 6.4?\nAnswer: Same proof as for Theorem 6.3, except that now instead of drawing Ti,w e\ndrawTQ(i), namely the time the ith arrival to the system spends in queues (wasted\ntime). Note that TQ(i)may not be a solid rectangle. It may be made up of several\nrectangles because the ith job might be in queue for a while, then in service, then\nwaiting in some other queue, then in service, again, etc.\nCorollary 6.5 (Utilization Law) Consider a single device iwith average arrival\nrateλijobs/sec and average service rate μijobs/sec, where λi<μ i.L e tρidenote\nthe long-run fraction of time that the device is busy. Then\nρi=λi\nμi.\nWe refer to ρias the “device utilization” or “device load.” Observe that, given ergodicity,\nρirepresents both the long-run fraction of time that device iis busy and also the limiting\nprobability (ensemble average) that device iis busy.\nQuestion: Do you see how to use Little’s Law to prove this corollary? What should\nwe deﬁne the “system” to be?\nProof Let the “system” consist of just the service facility without the associated\nqueue, as shown in the shaded box of Figure 6.6. Now the number of jobs in the\n“system” is always just 0 or 1.\nDepart uresDevice i\nThe “system ”Arrival rate λi i\nFigure 6.6. Using Little’s Law to prove the Utilization Law.\nQuestion: What is the expected number of jobs in the system as we have deﬁned it?\nAnswer: The number of jobs in the system is 1when the device is busy (this happens\nwith probability ρi) and is 0when the device is idle (this happens with probability",8798
40-6.7 Examples Applying Littles Law.pdf,40-6.7 Examples Applying Littles Law,"6.5proof of little’s law for closed systems 101\n1−ρi). Hence the expected number of jobs in the system is ρi. So, applying Little’s\nLaw, we have\nρi=Expected number jobs in service facility for device i\n=(Arrival rate into service facility) ·(Mean time in service facility)\n=λi·E[Service time at device i]\n=λi·1\nμi.\nWe often express the Utilization Law as\nρi=λiE[Si]=XiE[Si]\nwhere ρi,λi,Xi, andE[Si]are the load, average arrival rate, average throughput, and\naverage service requirement at device i, respectively.\nQuestion: Suppose we are only interested in “red” jobs, where “red” denotes some\ntype of jobs. Can we apply Little’s Law to just “red” jobs? Prove it.\nAnswer: Yes.\nE[Number of red jobs in system ]=λred·E[Time spent in system by red jobs ]\nThe proof is exactly the same as before, but only the Ti’s corresponding to the red jobs\nare included in Figure 6.5.\n6.5 Proof of Little’s Law for Closed Systems\n6.5.1 Statement via Time Averages\nAs in the previous section, we begin with a restatement of Little’s Law for closed\nsystems. As before we deﬁne\nX= lim\nt→∞C(t)\nt\nwhere C(t)is the number of system completions by time t.\nThis time, however, there are no exogenous arrivals. We thus deﬁne\nλ= lim\nt→∞A(t)\nt\nwhere A(t)is the number of jobs that are generated by time t.\nTheorem 6.6 (Little’s Law for Closed Systems Restated) Given any closed\nsystem (either interactive or batch) with multiprogramming level Nand given that\nTTime AvgandXexist and that λ=X, then\nN=X·TTime Avg.\n102 little’s law and other operational laws\n6.5.2 Proof\nIt is important to note that Tin Theorem 6.6corresponds to the total time in system,\nnamely the time to go from “out” to “out” in Figure 6.3, which includes both response\ntime (R) and think time ( Z). Thus, as soon as one Ticompletes, another immediately\nstarts, as shown in Figure 6.7.\nT1T4T5T7T2T3 T8 T11\nT10\nT12 T9T6\nttimeN = 3\nFigure 6.7. Graph of job system times in closed system with N=3.\nProof Figure 6.7shows the time in system for arrivals. Observe that a new job cannot\narrive until one departs. Thus there are always Njobs in the system. At any time t, the\narea made up by all rectangles up to time tisNt, which can be bounded above and\nbelow as follows:\n/summationdisplay\ni∈C(t)Ti≤N·t≤/summationdisplay\ni∈A(t)Ti\n⇒/summationtext\ni∈C(t)Ti\nt≤N≤/summationtext\ni∈A(t)Ti\nt\n⇒/summationtext\ni∈C(t)Ti\nC(t)·C(t)\nt≤N≤/summationtext\ni∈A(t)Ti\nA(t)·A(t)\nt\nTaking limits as t→∞ ,\nlim\nt→∞/summationtext\ni∈C(t)Ti\nC(t)·lim\nt→∞C(t)\nt≤N≤lim\nt→∞/summationtext\ni∈A(t)Ti\nA(t)·lim\nt→∞A(t)\nt\n⇒TTime Avg·X≤N≤λ·TTime Avg.\nButXandλare equal. Therefore\nN=X·TTime Avg.\n6.6 Generalized Little’s Law\nNote that the relationships presented so far have all been between the mean time\nin system, E[T], and the mean number of jobs in system, E[N]. You might be\nwondering if Little’s Law can be generalized to relate higher moments as well, such as a\nrelationship between E[T2]andE[N2]. Some research papers have been successful at\nproving relationships between higher moments under certain very restrictive conditions,\n6.7examples applying little’s law 103\ngenerally requiring that jobs leave in the order that they arrive, as in a single FCFS\nqueue, see [ 33,19]. Although we later derive a relationship between the higher moments\nofTandNfor a single-server M/G/1 queue (see Chapter 26), it is typically very difﬁcult\nto get higher moments of Tfor more general multi-queue systems.\n6.7 Examples Applying Little’s Law\nThe versatility of Little’s Law lies in two properties: First, Little’s Law is distribution\nindependent. This means that it depends only on mean quantities (e.g., the mean\ninterarrival time or the mean service time), not on whether the service times are\nExponentially distributed or Uniformly distributed, nor on whether the arrival process\nis Poisson or something else. Second, Little’s Law applies to any system or piece of a\nsystem , as we demonstrate in the following examples.\nExample 1: Refer to Figure 6.8\nWe have an interactive system with N=1 0 users, as shown in Figure 6.8. We are told\nthat the expected think time is E[Z]=5 seconds and that the expected response time\nisE[R]=1 5 seconds. Note that the response time is the time it takes a job to get from\n“in” to “out” in Figure 6.8.\nSubsystemN = 10 users\ntuo ni\nFigure 6.8. An interactive system.\nQuestion: What is the throughput, X, of the system?\nAnswer: Using Little’s Law for closed systems, we have\nN=X·E[T]=X(E[Z]+E[R])\n⇒X=N\nE[R]+E[Z]=10\n5+1 5=0.5jobs/sec .\nThe application of Little’s Law to closed systems is often referred to as the Response\nTime Law for Closed Systems :\nE[R]=N\nX−E[Z]\n104 little’s law and other operational laws\nExample 2: Refer to Figure 6.9\nN = 10\nCPUDisk 1\nDisk 2\nDisk 3\nFigure 6.9. A more complex interactive system.\nWe are given the system in Figure 6.9and the following information:\nrThe throughput of disk 3 is 40 requests/sec ( Xdisk3=4 0 ).\nrThe service time of an average request at disk 3 is 0.0225 sec ( E[Sdisk3]=.0225 ).\nrThe average number of jobs in the system consisting of disk 3 and its queue is 4\n(E[Ndisk3]=4 ).\nQuestion: What is the utilization of disk 3?\nAnswer:\nρdisk3=Xdisk3·E[Sdisk3]=4 0·(0.0225) = 90% .\nQuestion: What is the mean time spent queueing at disk 3?\nAnswer: LetTdisk3denote the time spent queueing plus serving at disk 3. Let Tdisk3\nQ\ndenote the time spent queueing at disk 3. Then,\nE[Tdisk3]=E[Ndisk3]\nXdisk3=4\n40=.1sec.\nE/bracketleftbig\nTdisk3\nQ/bracketrightbig\n=E[Tdisk3]−E[Sdisk3]=0.1sec−0.0225 sec=0.0775 sec.\nQuestion: FindE[Number of requests queued at disk 3 ].\nAnswer:\nE/bracketleftbig\nNdisk3\nQ/bracketrightbig\n=E[Ndisk3]−E[Number requests serving at disk 3 ]\n=E[Ndisk3]−ρdisk3\n=4−0.9\n=3.1requests .\n6.7examples applying little’s law 105\nAlternatively, we could have obtained this same answer from\nE/bracketleftbig\nNdisk3\nQ/bracketrightbig\n=E/bracketleftbig\nTdisk3\nQ/bracketrightbig\n·Xdisk3=0.775·40 = 3 .1requests .\nNext we are told that\nrE[Number of ready users (not thinking) ]=7.5.\nrNumber of terminals Nis 10.\nrE[Think time ]=E[Z]=5 sec.\nQuestion: What is the system throughput?\nAnswer: Looking at the whole system, we have\nX=N\nE[R]+E[Z]=10\nE[R]+5\nbut we do not know E[R]. Looking only at the non-thinking part of the system, we\nhave\nE[R]=E[Nnot-thinking ]\nX=7.5\nX\nbut we do not know X. Solving these two equations simultaneously yields X=.5\nrequests per second and E[R]is 15 seconds.\nQuestion: Is there a way to get system throughput using only one equation?\nAnswer: Yes, we could instead apply Little’s Law to the thinking region only. The\nthroughput of the thinking region is still X, and the mean time spent in the thinking\nregion is E[Z]. Hence,\nE[Nthinking]=X·E[Z]\n2.5=X·5\nX=0.5.\nExample 3: Refer to Figure 6.10\nµ = 4 λ= 3\nFigure 6.10. A ﬁnite buffer.\nFigure 6.10 shows a single FCFS queue with a capacity limitation of 7 jobs (there is\nroom for 1 job to serve and buffer space for 6 more waiting jobs). Arrivals that ﬁnd a\nfull buffer are dropped.\nQuestion: What does Little’s Law look like for this system?\nAnswer: The problem is that λ/negationslash=Xas required by Little’s Law. However,\ntheeffective arrival rate , meaning the rate of those jobs that get through, is",7346
41-6.9 Combining Operational Laws.pdf,41-6.9 Combining Operational Laws,"106 little’s law and other operational laws\nλ(1−P{7 jobs in system }), which is equal to the completion rate, as required. So\nE[N]=λ·(1−P{7 jobs in system })·E[T].\n6.8 More Operational Laws: The Forced Flow Law\nTheForced Flow Law relates system throughput to the throughput of an individual\ndevice as follows:\nXi=E[Vi]·X\nwhere Xdenotes the system throughput, Xidenotes the throughput at device i, and\nVidenotes the number of visits to device iper job.\nViis often referred to as the visit ratio for device i(see Figure 6.11).\nout\nJobs\nini\nVi visits per jobDevice i\nSystem\nFigure 6.11. A single device within a larger system. (In a closed system the “in” and “out”\narrows would be connected.)\nThe Forced Flow Law should seem intuitive: For every system completion, there are\non average E[Vi]completions at device i. Hence the rate of completions at device iis\nE[Vi]times the rate of system completions.2\n2A more formal argument would go like this: Consider Figure 6.11. Suppose we observe the system for some\nlarge observation period t.L e tC(t)denote the number of system completions during time tand let Ci(t)\ndenote the number of completions at device iduring time t.L e tV(j)\nibe the number of visits that the jth job\nentering the system makes to device i. Then,\nCi(t)≈/summationdisplay\nj∈C(t)V(j)\ni\nCi(t)\nt≈/summationtext\nj∈C(t)V(j)\ni\nt\nCi(t)\nt≈/summationtext\nj∈C(t)V(j)\ni\nC(t)·C(t)\nt\nlim\nt→∞Ci(t)\nt≈lim\nt→∞/summationtext\nj∈C(t)V(j)\ni\nC(t)·lim\nt→∞C(t)\nt\nXi=E[Vi]·X.\nNote that approximation signs are used here because C(t)actually provides a lower bound on the sum, whereas\nA(t)would provide an upper bound. To be precise, we should use both the upper and lower bounds, but this\nbecomes irrelevant once we take the limit as t→∞ .\n6.9combining operational laws 107\nExample of Forced Flow Law\nQuestion: Suppose we are given the network shown in Figure 6.12. What are the visit\nratios? That is, what are E[Va],E[Vb], andE[Vcpu]?\nDisk a\nDisk bCPUN = 10\nFigure 6.12. Calculating the visit ratios.\nAnswer: Although it may seem obvious for this example, let’s work it out formally\nbecause later exercises may be more complicated.\nLooking at the ﬁgure, we see\nCa=Ccpu·80/181\nCb=Ccpu·100/181\nC=Ccpu·1/181\nCcpu=Ca+Cb+C.\nDividing through by C(the number of system completions) yields the visit ratios. So\nwe get\nE[Va]=E[Vcpu]·80/181\nE[Vb]=E[Vcpu]·100/181\n1=E[Vcpu]·1/181\nE[Vcpu]=E[Va]+E[Vb]+1.\nSolving this system of simultaneous equations yields\nE[Vcpu] = 181\nE[Va]=8 0\nE[Vb] = 100 .\n6.9 Combining Operational Laws\nSimple Example\nSuppose we have an interactive system with the following characteristics:\nr25 terminals ( N=2 5 )\nr18 seconds average think time ( E[Z]=1 8 )\nr20 visits to a speciﬁc disk per interaction on average ( E[Vdisk]=2 0 )\n108 little’s law and other operational laws\nr30% utilization of that disk ( ρdisk=.3)\nr0.025 sec average service time per visit to that disk ( E[Sdisk]=.025)\nThat is all the information we have. We are not told anything else about the rest of the\nsystem.\nQuestion: What is the mean response time, E[R]?\nAnswer:\n1.E[R]=N\nX−E[Z], but we still need X.\n2.X=Xdisk\nE[Vdisk], but we still need Xdisk.\n3.Xdisk=ρdisk\nE[Sdisk], both of which we know.\nWorking backward, we calculate\nXdisk=ρdisk\nE[Sdisk]=1 2 requests/sec\n⇒X=Xdisk\nE[Vdisk]=.6interactions/sec\n⇒E[R]=N\nX−E[Z]=2 3 .7sec.\nHarder Example\nThis is a case study taken from Lazowska et al., p. 49 [ 117]. We are told the following\ninformation only:\nrIt is an interactive system.\nrThe central subsystem consists of a CPU and three disks.\nrSwapping may occur between interactions, causing a user to lose her memory\npartition. Thus a request sometimes has to queue up in the memory queue to get\nback its memory partition before entering the central subsystem, but sometimes\ncan skip this queue.\nFigure 6.13 is a sketch of what the system looks like based on this information. Observe\nthat some jobs have to wait in the “get memory queue,” whereas others already have the\nprerequisite memory allocated and can skip over this part and go directly to the central\nsubsystem. We are not given information as to the fraction of jobs that go each way.\nHere are the measurements that were collected about this system:\nrnumber of time-sharing users ( N=2 3 )\nraverage think time per user ( E[Z]=2 1 seconds)\nrsystem throughput ( X=0.45interactions per second)\nraverage number of requests trying to get memory ( E[Ngetting memory ]=1 1 .65)\nraverage number of visits to the CPU per interaction ( E[Vcpu]=3 )\nraverage service demand per visit to the CPU ( E[Scpu]=.21seconds)\n6.9combining operational laws 109\nDisk a\nDisk b\nDisk cCPU\nGet memory q ueue\nCentral s ubsystem\nFigure 6.13. A system with a memory queue.\nQuestion: What is the average amount of time that elapses between getting a memory\npartition and completing the interaction?\nAnswer: This question asks us for the expected time that jobs spend in the central\nsubsystem. There are several ways to answer it. Here is one:\nE[Time in central subsystem ]=E[Response Time ]−E[Time to get memory ]\nIt is true that not every job has to go get memory, but you can think of E[Time to\nget memory ]as the expected time to go from the point right before the split in the\nﬁgure to right after the join in the ﬁgure.\nNow by the Response Time Law,\nE[Response Time ]=N\nX−E[Z]=23\n0.45−21 = 30 .11sec.\nFurthermore,\nE[Time to get memory ]=E[Number getting memory ]\nX=11.65\n0.45=2 5.88sec.\nThus,\nE[Time in central subsystem ]=E[Response Time ]−E[Time to get memory ]\n=3 0.11−25.88\n=4.23sec.\nQuestion: What is the CPU utilization?\nAnswer:\nρcpu=Xcpu·E[Scpu]=X·E[Vcpu]·E[Scpu]=0.45·3·0.21 = 0 .28.",5757
42-6.11 Readings and Further Topics Related to Littles Law.pdf,42-6.11 Readings and Further Topics Related to Littles Law,"110 little’s law and other operational laws\n6.10 Device Demands\nWe end with one ﬁnal law, called the Bottleneck Law. This law is very important in\nanswering “what-if” type questions about systems, which come up in the next chapter.\nDeﬁne Dito be the total service demand on device ifor all visits of a single job (i.e.,\na single interaction). That is,\nDi=Vi/summationdisplay\nj=1S(j)\ni,\nwhere S(j)\niis the service time required by the jth visit of the job to server i.\nWe immediately see by ( 3.3) that\nE[Di]=E[Vi]·E[Si],\nprovided that Viand the S(j)\ni’s are independent. That is, we are assuming that the\nnumber of visits a job makes to device iis not affected by its service demand at the\ndevice.\nWe will soon discuss the importance of these Di’s. First, let’s observe how easy Di\ntypically is to measure. Suppose we had to measure the Vi’s. This would be hard,\nbecause we would have to keep track of a particular job and count its visits to device\ni. If device iis time-shared among jobs, it would be even harder. Luckily, we do not\nhave to do this!Question: How would you determine\nE[Di]in practice?\nAnswer: Consider a long observation period. Observe that\nE[Di]=Bi\nC,\nwhere Biis the busy time at device ifor the duration of our observation period and\nCis the number of system completions during this observation period. These are very\neasy measurements to get.\nThe importance of E[Di]lies in the following law, which we call the Bottleneck Law :\nρi=X·E[Di]\nQuestion: Can you explain the Bottleneck Law intuitively?\nAnswer: Xis the jobs/sec arriving into the whole system. Each of those outside arrivals\ninto the system contributes E[Di]seconds of work for device i. So device iis busy for\nX·E[Di]seconds out of every second (e.g., device imight be busy for half a second\nout of every second). Thus X·E[Di]represents the utilization of device i.\nHere is a proof of the Bottleneck Law:\nρi=Xi·E[Si]=X·E[Vi]·E[Si]=X·E[Di].",1959
43-6.12 Exercises.pdf,43-6.12 Exercises,"6.12 exercises 111\nExample\nAs a simple example, consider a system with an outside arrival rate of 3 jobs/second.\nSuppose that each job, on average, visits the disk 10 times. Suppose that each visitto the disk takes\n0.01second on average. Then, the per-job demand on the disk is\n.1seconds, and the utilization of the disk is .3.\n6.11 Readings and Further Topics Related to Little’s Law\nLittle’s Law was invented by J.D.C. Little in 1961, [ 121]. The following books are\nuseful in providing examples of the application of Little’s Law and other operational\nlaws, as explained in this chapter and Chapter 7: Jain (pp. 547–67) [ 104], Lazowska\net al. (pp. 40–95) [ 117], Bertsekas & Gallager (pp. 152–57) [ 18], and Menasc ´ee ta l .\n(pp. 84–89) [ 125].\nThe proof of Little’s Law can be generalized to allow for more general notions of the\ntime in system, T, and the number in system, N. One of the generalizations is known\nin the literature as H=λG, where Htakes the place of NandGtakes the place of\nT. TheH=λGlaw and its further generalizations are described in great detail in a\ngem of a book by El-Taha and Stidham [ 51], Ch. 6. Another generalization is the Rate\nConservation Law (RCL); see [ 126,103,167,183].\nFinally, as mentioned earlier, there have been many attempts to prove relationships\nbetween higher moments of TandN. The Distributional Little’s Law holds only\nunder certain very restrictive conditions, generally requiring that jobs leave in the order\nthat they arrive, as in a single FCFS queue. Some relevant references are [ 33,19].\nExercises 26.4 and26.5 derive the Distributional Little’s Law for an M/G/1 FCFS\nqueue and illustrate its application to more complex systems.\n6.12 Exercises\n6.1 Professors and Students\nA professor practices the following strategy with respect to taking on newPh.D. students. On even-numbered years, she takes on 2 new students. On odd-\nnumbered years, she takes on 1 new student. Assuming the average time to\ngraduate is 6 years, how many students on average will the professor have?Prove your answer using an operational law.\n6.2 Simpliﬁed Power Usage in Server Farms\nGiven that power is expensive, it is common practice to leave servers on only\nwhen they are being used and to turn them off whenever they are not in use.Assume that the following power-aware algorithm is used: When a job arrives,it instantly turns on a fresh server (assume zero setup cost). When the jobcompletes service, it instantly turns off that server. Assume that there is alwaysa server available for every job (i.e., there is no queueing). Your goal is to derive\nthe time-average rate at which power is used in our system. Assume that when\na server is on, it consumes power at a rate of\nP= 240 watts. Assume λ=1 0\n112 little’s law and other operational laws\njobs arrive per second and that the service requirement of jobs is Uniformly\ndistributed ranging from 1second to 9seconds.\n(Note: This is a highly simpliﬁed model. We will study much more complex\nmodels in Chapter 27.)\n6.3 Measurements Gone Wrong\nAfter spending months carefully building his closed batch data storage system,David comes to see his advisor with the following description and measure-\nments: The MPL for the system is ﬁxed at\n19jobs. David explains that 90% of\njobs ﬁnd the data they need in the cache, and hence their expected response time\nis only 1second. However, 10% end up having to go to the database, where their\nexpected response time is 10seconds. David’s advisor asks one question: “How\nmany jobs do you see on average at the database?” When David answers “5,”\nhis advisor says he needs to go back to the drawing board. What went wrong?\n6.4 More Practice Manipulating Operational Laws\nFor the interactive system in Figure 6.14, suppose that we are given the following\ninformation:\nmean user think time =5 seconds\nexpected service time at device i=.01 seconds\nutilization of device i=.3\nutilization of CPU =.5\nexpected number of visits to device iper visit to CPU =10\nexpected number of jobs in the central subsystem (the cloud shape) =20\nexpected total time in system (including think time) per job =50 seconds.\nHow many jobs are there in the queue portion of the CPU on average, E/bracketleftbig\nNcpu\nQ/bracketrightbig\n?\nCPU½½\nDevice i\nFigure 6.14. Figure for Exercise 6.4.\n6.5 Little’s Law for Closed Systems\nRecall that the Response Time Law for a closed interactive system says that\nE[R]=N\nX−E[Z].\nThus it seems possible that E[R]might be negative! Prove that this can never\nhappen. (If you are clever, your proof can be only two lines.)\n6.12 exercises 113\n6.6 Little’s Law for Mean Slowdown\nRecall that Little’s Law relates the mean response time to the mean number of\njobs in any ergodic system. It is interesting to ask whether a similar law can be\nproven that relates mean slowdown to the mean number of jobs in the system.\nWe do not have an answer. However, you should be able to derive the followingbound in the case of a single FCFS queue :\nE[Slowdown ]≤E[N]\nλ·E/bracketleftbigg1\nS/bracketrightbigg\nwhere Srepresents job size, Nrepresents the number of jobs in the system, and\nλis the average arrival rate into the queue.\n6.7 More on SRPT\nThe SRPT scheduling policy is important because it minimizes mean response\ntime. In Exercise 2.3, we saw that SRPT does notminimize mean slowdown.\nRunting suggests that the problem with SRPT is that it picks jobs with the\nshortest remaining time, whereas to minimize mean slowdown we want tochoose jobs that have both short remaining time and also small original size.\nRunting proposes that we use the RS algorithm , which computes the product of\na job’s current remaining size (\nR) and its (original) size ( S), and then runs that\njob whose product ( RS) is smallest. Is Runting right?\n(a) Explain the intuition behind the RS algorithm for minimizing mean slow-\ndown.\n(b) Prove or disprove that the RS algorithm minimizes mean slowdown on every\narrival sequence. If it minimizes mean slowdown, provide a proof. If it does\nnot minimize mean slowdown, provide a counterexample.\nRS is also known as SPTP and is analyzed in [ 100].",6185
44-Chapter 7 Modification Analysis What-If for Closed Systems.pdf,44-Chapter 7 Modification Analysis What-If for Closed Systems,,0
45-7.2 Asymptotic Bounds for Closed Systems.pdf,45-7.2 Asymptotic Bounds for Closed Systems,"CHAPTER 7\nModiﬁcation Analysis:\n“What-If” for Closed Systems\nIn the last chapter we learned about several operational laws. Operational laws are laws\nthat hold independently of any assumptions about the distribution of arrivals or thedistribution of service times (job sizes). They are extremely useful and simple to apply.Operational laws may be applied to open and closed systems, although they often aremost powerful when applied to closed systems.\nIn this chapter we do the following:\n1.We use our operational laws to prove some very cool asymptotic bounds for\nclosed systems. Note: These asymptotic bounds apply only toclosed systems.\n2.We use our newly developed asymptotic bounds to do modiﬁcation analysis on\nclosed systems. In modiﬁcation analysis we ask “what-if” questions about whichdesign changes will result in performance improvements for the closed system.\n3.Finally, we return to the question of how closed systems differ from open systems.\nAfter this chapter, you can don a suit and call yourself a systems consultant :-)\n7.1 Review\nSo far we have seen several operational laws. They all follow immediately from the\nderivation of Little’s Law.\nLittle’s Law for an Open System This holds for anyergodic open system and states\nthat\nE[N]=λ·E[T],\nwhere λis the average outside arrival rate into the system, also equal to the (average)\nthroughput rate of the system, X.H e r eE[N]is the expected number of jobs in the\nsystem, and E[T]is the expected time a job spends in the system.\nWe saw several variations on this law, including\nE[NQ]=λ·E[TQ],\nwhich relates the number of jobs that are waiting (in queues) to the mean time jobs\nspend waiting, and\nE[Nred]=λred·E[Tred],\nwhich applies Little’s Law to just the “red-colored” jobs.\n114\n7.2asymptotic bounds for closed systems 115\nLittle’s Law for a Closed Batch System (Zero Think Time) This holds for any\nergodic closed batch system and states that\nN=X·E[T],\nwhere Nis the multiprogramming level of the system.\nResponse Time Law for Closed Interactive Systems This law holds for any ergodic\nclosed interactive (terminal-driven) system and states that\nE[R]=N\nX−E[Z],\nwhere Nis the multiprogramming level (number of users), Xis the throughput,\nE[Z]denotes the mean time spent thinking, and E[R]is the expected response\ntime.\nUtilization Law This applies to a single server iand states that\nρi=λi\nμi=λiE[Si],\nwhere ρiis the utilization of the server, λiis the average arrival rate into the server\n(this is also the server’s throughput rate, Xi), and μi=1\nE[Si]is the mean service\nrate at the server.\nForced Flow Law This law relates system throughput to the throughput of an in-\ndividual device i:\nXi=E[Vi]·X,\nwhere Xdenotes the system throughput, Xidenotes the throughput at device i, and\nE[Vi]denotes the expected number of visits to device iper job.\nBottleneck Law This law involves Di, the total service demand on device ifor all\nvisits of a single job. Over a long observation period T,Di=Bi/C, where Biis\nthe total time during Tthat device iis busy and Cis the total number of system\ncompletions during time T. The Bottleneck Law states that\nρi=X·E[Di].\n7.2 Asymptotic Bounds for Closed Systems\nWe will now see that, by knowing the Di’s alone, we are able to both:\n1.Estimate XandE[R]as a function of the multiprogramming level, N(this\nsection).\n2.Determine which changes to the system will be worthwhile and which will not\n(next section).\nLetmbe the number of devices in our system. Let\nD=m/summationdisplay\ni=1E[Di]\n116 modiﬁcation analysis: “what-if” for closed systems\nand let\nDmax=m a x\ni{E[Di]}.\nWe will assume an interactive system ( E[Z]/negationslash=0). One can always set E[Z]=0 to\nget a batch system.\nTheorem 7.1 For any closed interactive system with Nterminals,\nX≤min/parenleftbiggN\nD+E[Z],1\nDmax/parenrightbigg\n.\nE[R]≥max(D,N·Dmax−E[Z]).\nImportantly, the ﬁrst term in each clause (N\nD+E[Z]orD)is an asymptote for small\nN, and the second term (1\nDmaxorN·Dmax−E[Z])is an asymptote for large N.\nProof First, we derive the large Nasymptotes:\n1. ∀i, X·E[Di]=ρi≤1\n⇒∀i,X≤1/E[Di]\n⇒X≤1/D max. (7.1)\nForlargeN, theDmaxserver is always busy ( ρmax≈1), soX=1/D max. Thus\n1/D maxis an asymptote for large N.\n2. E[R]=N/X−E[Z]≥N·Dmax−E[Z],\nwhere the inequality comes from (7.1) and thus forms a tight bound for large N.\nNext, we derive the small Nasymptotes:\n1.LetE[R(N)]denote the mean response time when the multiprogramming level\nisN. Then,\nE[R(N)]≥E[R(1)] = D1, (7.2)\nwhere the above expression is a tight asymptote for low N(when there is no\ncongestion).\nQuestion: Why is E[R(1)] = D? Are we saying all devices must be visited by\nevery job?\nAnswer: No, We are not saying that all devices must be visited by every job, but\nthat an average job has an expected amount of time at each device because some\nfraction of all jobs go to each device.\n1For all the systems that we will look at, E[R(1)] = D. However, one can imagine some systems where\nE[R(1)]/negationslash=D. For example, suppose that a job can utilize two devices at the same exact time. Then E[R(1)]\nmight be less than D=/summationtext\nDi. In this case, we want to make sure that we use E[R(1)], in Theorem 7.1,\nnotD.\n7.2asymptotic bounds for closed systems 117\n2.\nX=N\nE[R]+E[Z]\n≤N\nD+E[Z],\nwhere the inequality comes from ( 7.2) and thus forms a tight bound for small N.\nThe power of this theorem lies in the fact that the bounds are asymptotes . That is, for\nlargeNor small N, the curve comes very close to touching these lines.\nIt is possible to get even tighter estimates (upper and lower bound on XandE[R]\nby using the Balanced Bounds technique, described in Lazowska et al.’s book [ 117]\n(Section 5.4).\nA Simple Example of Bounds\nLet’s examine a system like the one in Figure 7.1. Suppose\nrE[Z]=1 8\nrE[DCPU]=5 sec\nrE[Ddisk a]=4 sec\nrE[Ddisk b]=3 sec\nCentral s ubsystemtuo niCPUDisk a\nDisk b\nFigure 7.1. Closed system example.\nOur goal is to determine XandE[R]as a function of the multiprogramming level N.\nFrom this information, we see that\nrD=5+4+3=1 2 seconds\nrDmax=5 (the CPU is the bottleneck device)\nThusX≤min{N/30,1/5}, andE[R]≥max{12,5N−18}. This is illustrated in\nFigures 7.2(a) and 7.2(b), which give us a good estimate of the performance of the\nsystem as a function of N. Observe that the point at which the asymptotes cross is\ndenoted by N∗.",6421
46-7.4 More Modification Analysis Examples.pdf,46-7.4 More Modification Analysis Examples,"118 modiﬁcation analysis: “what-if” for closed systems\nN.05.1.15.2Xslope = 1/( D+Z)\n1/Dmax\nactual curve\n0 5 10 15 20 25\nN* = 6\n(a) X versus N (b) E [R] versus NN75100\n50\n25\n0 5 10 15 20 25\nN* = 6slope = DmaxE[R]\nFigure 7.2. Performance as a function of multiprogramming level, N.\n7.3 Modiﬁcation Analysis for Closed Systems\nWe start with some motivation for where we are going.\nA Simple, but Counterintuitive Example\nConsider the very simple closed network shown in Figure 7.3(a). Let’s suppose that N\nis high for this system. In this network both servers have service rate μ=1/3.N o w\nconsider the “improvement” to the system shown in Figure 7.3(b), where one of the\nservers has been replaced with a faster server of service rate μ=1/2.\nN: high\n½\n½µ=⅓ \nµ=⅓ \n(a) OriginalN: high\n½½µ=½\nµ=⅓ \n(b) “Improved”\nFigure 7.3. A simple system and the “improved” system.\nQuestion: How much does the throughput improve in going from Figure 7.3(a) to\nFigure 7.3(b)? How much does the mean response time improve?\nAnswer: Neither throughput nor mean response time changes! This is because we\nare only looking at the high Nregime, which is dominated by Dmax, andDmaxhas\nnot changed. Yes, this is counterintuitive. We examine this result more carefully in\nExercise 7.2.\nFor now, let’s continue with our discussion . . .\nImportant Observations\nLooking at the asymptotic bounds, we make the following observations:\n7.4more modiﬁcation analysis examples 119\nrThe knee of the XandE[R]curves occurs at some point N, which we denote\nbyN∗, where N∗=D+E[Z]\nDmax.\nQuestion: What does N∗represent?\nAnswer: N∗represents the point beyond which there must be some queueing in\nthe system ( E[R]>D ).\nrFor ﬁxed N>N∗, to get more throughput, one must decrease Dmax. To get\nlower response time, one must similarly decrease Dmax. Other changes will be\nlargely ineffective.\nrTo expand on the previous item, let us suppose we decrease some other Di,\nlikeDnext tomax. What happens? The heavy load asymptote in both XandE[R]\ndoes not change, so performance for N/greatermuchN∗does not change. Performance for\nN/lessmuchN∗will improve a little because Dwill drop. For the graph of Xversus\nN, when Ddecreases, the light-load asymptote will get a little steeper (better).\nFor the graph of E[R]versus N, when Ddecreases, the light-load asymptote\nwill get a little lower (better).\nQuestion: What happens if E[Z]goes to zero (the batch case)?\nAnswer: N∗decreases, meaning that the domination of Dmaxoccurs with fewer jobs\nin the system.\nSummary: To summarize, the device corresponding to Dmaxis the bottleneck\ndevice . The bottleneck device is the key limiting factor to improving system per-\nformance. Improving other devices will have little effect. The ﬁrst step in improving\nsystem performance is to identify the bottleneck device.\n7.4 More Modiﬁcation Analysis Examples\nSimple Example\nRefer to the system in Figure 7.4, with N=2 0 , andE[Z]=5 . Now consider the\nfollowing two systems:\nN = 10\nCPU Disk\nFigure 7.4. Simple closed system.\n1. System A looks like Figure 7.4withDcpu=4.6andDdisk=4.0.\n2. System B looks like Figure 7.4withDcpu=4.9andDdisk=1.9(a slightly\nslower CPU and a much faster disk).\n120 modiﬁcation analysis: “what-if” for closed systems\nQuestion: Which system has higher throughput?\nAnswer: N∗\nA=D+E[Z]\nDmax=13.6\n4.6<3andN∗\nB=11.8\n4.9<3.S oN/greatermuchN∗for both sys-\ntems. Thus System Awins, because it has a lower Dmax.\nHarder Example\nThe following measurements were obtained for an interactive system2:\nrT= 650 seconds (the length of the observation interval)\nrBcpu= 400 seconds\nrBslowdisk = 100 seconds\nrBfastdisk= 600 seconds\nrC=Ccpu= 200 jobs\nrCslowdisk =2,000jobs\nrCfastdisk=2 0,000jobs\nrE[Z]=1 5 seconds\nrN=2 0 users\nThe above are typically easy-to-measure quantities.\nIn this example, we examine four possible improvements (modiﬁcations) – hence the\nname “modiﬁcation analysis.”\n1. Faster CPU: Replace the CPU with one that is twice as fast.\n2. Balancing slow and fast disks: Shift some ﬁles from the fast disk to the slow\ndisk, balancing their demand.\n3. Second fast disk: Buy a second fast disk to handle half the load of the busier\nexisting fast disk.\n4. Balancing among three disks plus faster CPU: Make all three improvements\ntogether: Buy a second fast disk, balance the load across all three disks, and also\nreplace the CPU with a faster one.\nTo evaluate these modiﬁcations, we need to derive the following quantities. Note that\nwe sometimes drop the expectation symbols around a random variable when it isobvious that they are implied.\nrDcpu=Bcpu/C= 400 sec/200jobs=2.0sec/job\nrDslowdisk =Bslowdisk/C= 100 sec/200jobs=0.5sec/job\nrDfastdisk=Bfastdisk/C= 600 sec/200jobs=3.0sec/job\nrE[Vcpu]=Ccpu/C= 200 visits/200jobs=1visit/job\nrE[Vslowdisk]=Cslowdisk/C=2,000visits/200job=1 0 visits/job\nrE[Vfastdisk]=Cfastdisk/C=2 0 ,000visits/200job= 100 visits/job\nrE[Scpu]=Bcpu/C cpu= 400 sec/200visits=2.0sec/visit\nrE[Sslowdisk]=Bslowdisk/C slowdisk = 100 sec/2,000visits=.05sec/visit\nrE[Sfastdisk]=Bfastdisk/C fastdisk= 600 sec/20,000visits=.03sec/visit\n2Just as most fairy tales start with “once upon a time,” most performance analysis problems begin with “the\nfollowing measurements were obtained.”\n7.4more modiﬁcation analysis examples 121\nNow let’s examine the four possible modiﬁcations:\n1. Faster CPU: Originally, Dmax=3sec/job, D=5.5,N∗=20.5\n3≈7/lessmuchN.\nDcpu→1sec/job does not change Dmax=3sec/job. Notice that N∗hardly changes\nat all. The fast disk is the bottleneck. We can never get more than 1job done every\n3seconds on average.\n2. Balancing slow and fast disks: Shift some ﬁles from the fast disk to the slow disk,\nbalancing their demand. To do this we need that\nVslow+Vfast= 110 as originally\nbutSslow·Vslow=Sfast·Vfastbecause we are balancing the demand.\nSolving this system of linear equations yields the new demands Dslow=Dfast=\n2.06.N o w , Dmax=2.06sec/job, although Dincreases slightly because some ﬁles\nhave been moved from the fast disk to the slow disk.\n3. Second fast disk: We keep Dslow=0.5, the same as before. However, we buy a\nsecond fast disk to handle half the load of the original fast disk. So now\nDfast1=Dfast2=1.5sec/job .\nThus our new Dmaxis 2.0 sec/job (the CPU becomes the bottleneck).\n4. Balancing among three disks plus faster CPU: We now make the CPU faster and\nbalance load across all three disks, so\nVslow+Vfast1+Vfast2= 110 .\nSslow·Vslow=Sfast1·Vfast1=Sfast2·Vfast2.\nSolving these simultaneous equations yields: Ddisk1=Ddisk2=Ddisk3=1.27.S o\nDmax=1.27, since we cut Dcputo 1 already.\nA graph of the results is shown in Figure 7.5. Assuming Nis not too small, we conclude\nthe following:\nrChange 1 is insigniﬁcant.\nrChanges 2 and 3 are about the same, which is interesting because change 2 was\nachieved without any hardware expense.\nrChange 4 yields the most dramatic improvement.\n234\n1X\nN1 23 4E[R]\nN\nFigure 7.5. Throughput and response time versus N, showing the effects of four possible\nimprovements from the harder example, where the improvements are labeled 1, 2, 3, and 4.",7155
47-7.5 Comparison of Closed and Open Networks.pdf,47-7.5 Comparison of Closed and Open Networks,,0
48-7.6 Readings.pdf,48-7.6 Readings,,0
49-7.7 Exercises.pdf,49-7.7 Exercises,"122 modiﬁcation analysis: “what-if” for closed systems\nConcluding Remarks\nThe salient features of modiﬁcation analysis are that (i) it is easy and computation-\nally feasible; (ii) it does not rely on any assumptions about the distribution of theservice time, the interarrival time, or the scheduling order used for serving jobs; and\n(iii) although it only yields bounds, if\nNis sufﬁciently far from N∗these bounds are\nall we need to analyze proposed changes.\n7.5 Comparison of Closed and Open Networks\nThe asymptotic bounds in this chapter were for closed networks.\nQuestion: Why don’t they make sense for open networks?\nAnswer: Because they are not asymptotic bounds in the open case. For open networks,\nit is still true that X≤1/D max. For example, if jobs require 3seconds of service on\naverage, there is no way that we can complete more than 1 job every 3 seconds on\naverage. However, we already know that X=λ,s o1/D maxis an upper bound on X,\nbut not necessarily a tight upper bound. Thus, our corresponding bound on E[R]for\nlargeNis also not tight.\nHowever, the lessons of this chapter will still be true in the open network case if the\noutside arrival rate is high enough that Xis close to 1/D max: Alleviate the bottleneck\ndevice!\nAs an interesting example of the difference between closed and open networks, consider\nFigure 7.3. In the closed network shown, it did not help to speed up only one of the\ntwo devices (under probabilistic routing). However, consider the same network now in\nthe form of an open network. The mean response time, E[T], will certainly improve\nby speeding up just one of the two devices.\n7.6 Readings\nA few years ago, one of the smart, industrious students studying this material in my\nclass, Eno Thereska, decided that operational laws might actually be important forreal computer systems design (unimaginable!). So he got together with another smart\nstudent who had also taken the class, Dushyanth Narayanan, and they wrote a paper\n[175] on self-predicting storage systems. This led to a series of papers, all dealing\nwith predictions possible via operational laws, and eventually to Eno’s Ph.D. thesis on\nhow operational laws can be applied to storage performance prediction [ 174]. Eno and\nDushyanth continue to leverage operational laws today.\nThat’s it! Time to throw on that suit and go make some money!\n7.7 Exercises\n7.1 Outside Arrival Rates – Open Networks\nConsider an open network consisting of two devices. Packets arrive to device 1\nfrom outside with rate r1jobs/sec. Packets arrive to device 2 from outside with\n7.7exercises 123\nrater2=1 0 jobs/sec. Assume 30% of the packets completing service at device\n1 will next queue up at device 2 (the rest leave the system). Assume 50% of the\npackets completing service at device 2 will next queue up at device 1 (the rest\nleave the system). The mean service time at device 1 is E[S1]=.1sec. The\nmean service time at device 2 is E[S2]=.05sec.\n(a) In this network, how high can we make r1?\n(b) When r1is maximized, what is the utilization of device 2?\n7.2 Open versus Closed\nConsider the system in Figure 7.6. Suppose that server 2 is replaced by one\nexactly twice as fast.\nServer 1\nServer 2N = 6\n½\n½µ=⅓ \nµ=\nFigure 7.6. The system prior to improvement.\n(a) Does this replacement result in signiﬁcant improvement in the mean re-\nsponse time of the network? Explain via operational laws.\n(b) Explain your answer to (a) by showing a time-line of where the jobs are at\neach step, both before and after the replacement. To do this you will need\nto make the problem deterministic, so you should assume that the servicetime at each server is a constant and that jobs alternately go to server\n1\nand2. This is not meant to be a proof, just an explanation of what is going\non. Make sure that you extend your time-line long enough that the average\nresponse time becomes clear.\n(c) Given that the replacement has been made, is there any further modiﬁcation\nyou would propose to improve the mean response time in the closed system\nthat does not involve spending more money? By how much would yourmodiﬁcation improve performance?\n(d) If the above system were an open system, would the replacement improve\nthe mean response time? Prove your answer. ( Note: we do not expect you\nto know how to determine mean response time in an open system yet, but\nyou can still come up with a proof.)\n7.3 Modiﬁcation Analysis\nMarty is running his database as a closed interactive system with\nN=5 0 users.\nEach user submits a screenful of data to the database (her “job”) to process,\nwaits until she gets back an answer from the system, spends E[Z]=1 0 seconds\nentering a new screenful of data (think time), and then submits that new job tothe database. This process repeats ad inﬁnitum.\n124 modiﬁcation analysis: “what-if” for closed systems\nMarty realizes that his system’s CPU utilization and his disk utilization are both\nhigh. He considers two modiﬁcations to his database to increase throughput.The ﬁrst is to buy a second CPU (new CPUs on the market run at twice the\nspeed of old ones) and divide the CPU load among the old CPU and the new\none according to some optimal split. The second is to buy a second disk (newdisks on the market run at three times the speed of old ones) and divide the disk\nload among the old disk and the new one according to some optimal split.\nYou obtain the following measurements of Marty’s original system:\nrC= 100 (number of jobs that completed during the observation period)\nrCCPU= 300 (number of completions at the CPU during observation)\nrCdisk= 400 (number of completions at the disk during observation)\nrBCPU= 600 sec (time that the CPU was busy during observation)\nrBdisk=1,200sec (time that the disk was busy during observation)\nYour job is to answer two questions:\n1. Assuming that the new disk and new CPU are equally priced, which should\nMarty buy to increase throughput?\n2. Assuming that he chooses to buy the new disk (CPU), how should he opti-\nmally split requests between the old disk (CPU) and the new one? Work this\nout for whichever device you chose.\n7.4 More Practice with Modiﬁcation Analysis – from [ 117]\nConsider an interactive system with a CPU and two disks. The following mea-\nsurement data was obtained by observing the system:\nrobservation interval =17 minutes\nrmean think time =12 seconds\nrnumber of complete transactions during observation interval =1,600\nrnumber of completions at CPU =1,600\nrnumber of fast disk accesses =32,000\nrnumber of slow disk accesses =12,000\nrCPU busy time =1,080 seconds\nrfast disk busy time =400 seconds\nrslow disk busy time =600 seconds\n(a) Give asymptotic bounds on throughput and response time as a function of\nthe number of terminals.\n(b) Now consider the following modiﬁcations to the system:\n1. Move all ﬁles to the fast disk.\n2. Replace the slow disk by a second fast disk.3. Increase the CPU speed by 50% (with the original disks).4. Increase the CPU speed by 50% and balance the disk load across the two\nfast disks.\nFor each of these four modiﬁcations, compute and graph the effects on the\noriginal system. Explain in words the effect when the multiprogramming\nlevel,\nN, is small and when Nis large.\n7.7exercises 125\n7.5 Proportional Power – based on [ 69]\nIn the world of power distribution, one reasonable approximation is that the\npower that is allocated to a machine is proportional to the speed at which that\nmachine can run. In this problem we assume that, if a machine is allocated\npower w, then that machine processes jobs at speed wjobs/sec.\nConsider a closed batch system with two servers and Nusers, where Nis\nassumed to be high. Assume that each job, with probability p, is routed to server\n1 for processing and, with probability 1−p, is routed to server 2. It may help\nto look at Figure 7.6here.\nYou are given a total power budget W, which you need to distribute between\nthe two machines. You can choose any way of dividing the power budget W\nbetween the two machines, and you can also choose any value you want for p,\nthe routing probability.\n(a) What choice for dividing Wand for picking pwill maximize the throughput\nof your system?\n(b) Suppose that Nwas small. Would your answer still be the same? If so,\nexplain why. If not, derive the optimal strategy.\n7.6 Minimizing Mean Slowdown\nIn Exercise 6.7, we saw that the RS algorithm does not minimize mean slowdown\non every arrival sequence. We have also seen that the SRPT algorithm does\nnot minimize mean slowdown. In this problem either ﬁnd an algorithm thatminimizes mean slowdown or prove that no online algorithm can minimize\nmean slowdown on every arrival sequence (an online algorithm is one that does\nnot know future arrivals).",8802
50-Part IV From Markov Chainsto Simple Queues.pdf,50-Part IV From Markov Chainsto Simple Queues,"PART IV\nFrom Markov Chains\nto Simple Queues\nPart IVintroduces both discrete-time Markov chains (referred to as DTMCs) and\ncontinuous-time Markov chains (referred to as CTMCs). These allow us to model\nsystems in much greater detail and to answer distributional questions, such as “What is\nthe probability that there are kjobs queued at server i?” Markov chains are extremely\npowerful. However, only certain problems can be modeled via Markov chains. These\nare problems that exhibit the Markovian property, which allows the future behavior to\nbe independent of all past behavior.\nChapter 8introduces DTMCs and the Markovian property. We purposely defer the\nmore theoretical issues surrounding ergodicity, including the existence of a limiting\ndistribution and the equivalence between time averages and ensemble averages, toChapter 9. Less theoretically inclined readers may wish to skim Chapter 9during a\nﬁrst reading. Chapter 10considers some real-world examples of DTMCs in computing\ntoday, including Google’s PageRank algorithm and the Aloha (Ethernet) protocol. Thischapter also considers more complex DTMCs that occur naturally and how generatingfunctions can be used to solve them.\nNext we transition to CTMCs. Chapter 11discusses the Markovian property of the\nExponential distribution and the Poisson process, which make these very applicable\nto CTMCs. Chapter 12shows an easy way to translate all that we learned for DTMCs\nto CTMCs. Chapter 13applies CTMC theory to analyzing the M/M/1 single-server\nqueue and also covers the PASTA property.\nCTMCs will be used extensively in Part Vto analyze multi-server systems.\n127",1645
51-8.1 Discrete-Time versus Continuous-Time Markov Chains.pdf,51-8.1 Discrete-Time versus Continuous-Time Markov Chains,"CHAPTER 8\nDiscrete-Time Markov Chains\nLet’s review what we already know how to do at this point.\nClosed Systems\nFor closed systems, we can approximate and bound the values of throughput, X,\nand the expected response time, E[R]. The approximations we have developed are\nindependent of the distribution of service times of the jobs, but require that the system\nisclosed . When the multiprogramming level, N, is much higher than N∗,w eh a v ea\ntight bound on XandE[R]. Also, when N=1, we have a tight bound. However, for\nintermediate values of N, we can only approximate XandE[R].\nOpen Systems\nFor open systems, we cannot do very much at all yet. Consider even a single queue.\nIf we knew E[N], then we could calculate E[T], but we do not yet know how to\ncompute E[N].\nMarkov chain analysis is a tool for deriving the above performance metrics and in fact\nderiving a lot more. It will enable us to determine not only the mean number of jobs,\nE[Ni], at server iof a queueing network, but also the full distribution of the number\nof jobs at the server.\nAll the chapters in Parts IVandVwill exploit the power of Markov chain analysis.\nIt is important, however, to keep in mind that not all systems can readily be modeled\nusing Markov chains. We will see that, in queueing networks where the service timesat a server are Exponentially distributed and the interarrival times of jobs are also\nExponentially distributed, the system can often be exactly modeled by a Markov chain.This is true because the Exponential distribution has the Markovian property (a.k.a.memoryless property), meaning that the remaining time until a service completes ora new job arrives is independent of how long we have waited so far. Properties of theExponential distribution are covered in Chapter 11. The same holds for Geometrically\ndistributed interarrival times and service times, where jobs arrive or complete with\nsome ﬁxed probability at each time step, independent of the past. All of this will\nbecome more clear after we deﬁne discrete-time Markov chains in this chapter.\nBy contrast, other workload distributions do not have the Markovian property, and\nthus are harder to model via a Markov chain. In many cases, however, even these non-Markovian workloads can be approximated by mixtures of Exponential distributions,\nand hence still lend themselves to Markov chain analysis, as explained in Chapter 21.\n129",2415
52-8.3 Examples of Finite-State DTMCs.pdf,52-8.3 Examples of Finite-State DTMCs,"130 discrete-time markov chains\nMarkov chains are extremely powerful and are used to model problems in computer\nscience, statistics, physics, biology, operations research, and business – you nameit! They are used extensively in machine learning, computer science theory, and inall areas of computer system modeling (analysis of networking protocols, memorymanagement protocols, server performance, capacity provisioning, disk protocols, etc.).Markov chains are also very common in operations research, including supply-chainmanagement and inventory management.\nAs we study Markov chains, be on the lookout for Markov chains in your own work\nand the world around you. They are everywhere!\n8.1 Discrete-Time versus Continuous-Time Markov Chains\nWe now cover Markov chains in depth, starting with Discrete-Time Markov Chains(DTMCs). In a DTMC, the world is broken up into synchronized time steps. An event(arrival or departure) can only occur at the end of a time step. This property makesDTMCs a little odd for modeling computer systems. However, there are many other\nproblems that are well modeled by DTMCs.\nIn Continuous-Time Markov Chains (CTMCs) events can happen at any moment in\ntime. This makes CTMCs convenient for modeling systems.\nNote: Solving Markov chains typically requires solving large systems of simultaneous\nequations. We therefore recommend that readers take the time to familiarize themselveswith the three M’s: Matlab, Mathematica, and Maple. The latter two are particularlyuseful in that they allow symbolic computation.\n8.2 Deﬁnition of a DTMC\nAstochastic process is simply a sequence of random variables.\nDeﬁnition 8.1 ADTMC (discrete-time Markov chain) is a stochastic process\n{Xn,n=0,1,2,...}, where Xndenotes the state at (discrete) time step nand\nsuch that,∀n≥0,∀i, j, and∀i0,...,i n−1,\nP{Xn+1=j|Xn=i, Xn−1=in−1,...,X 0=i0}=P{Xn+1=j|Xn=i}\n=Pij(by stationarity) ,\nwhere Pijis independent of the time step and of past history.\nThe ﬁrst equality in the deﬁnition of a DTMC indicates the application of the Markovian\nproperty.\nDeﬁnition 8.2 The Markovian Property states that the conditional distribution of\nany future state Xn+1, given past states X0,X1,...,Xn−1, and given the present\nstateXn, is independent of past states and depends only on the present state Xn.\n8.3examples of finite-state dtmcs 131\nThe second equality in the deﬁnition of a DTMC follows from the “stationary” property,\nwhich indicates that the transition probability is independent of time.\nDeﬁnition 8.3 The transition probability matrix associated with any DTMC is a\nmatrix, P, whose (i, j)th entry, Pij, represents the probability of moving to state j\non the next transition, given that the current state is i.\nObserve that the transition probability matrix, P, might have inﬁnite order, if there are\ninﬁnitely many states. Also observe that by deﬁnition,/summationtext\njPij=1,∀i, because, given\nthat the DTMC is in state i, it must next transition to some state j.\nWe begin this chapter by focusing on DTMCs with a ﬁnite number of states ,M.\nLater in the chapter, we generalize to DTMCs with an inﬁnite number of states.\nIn this chapter, we do notdiscuss issues of ergodicity. Speciﬁcally, we do not dwell on\nquestions of the existence of limiting probabilities. We simply assume that there exists\nsome limiting probability of being in each state of the chain (to be deﬁned soon), andwe defer all discussion of the existence of these limits to Chapter 9.\n8.3 Examples of Finite-State DTMCs\nWe start with a few examples of some simple Markov chains to illustrate the key\nconcepts. More involved and interesting examples are saved for the exercises.\n8.3.1 Repair Facility Problem\nA machine is either working or in the repair center. If it is working today, then there isa 95% chance that it will be working tomorrow. If it is in the repair center today, thenthere is a 40% chance that it will be working tomorrow. We are interested in questionslike “what fraction of time does my machine spend in the repair shop?”\nQuestion: Describe the DTMC for the repair facility problem.\nAnswer: There are two states, “Working” and “Broken,” where “Broken” denotes that\nthe machine is in repair. The transition probability matrix is\nP=/bracketleftbiggWB\nW0.95 0.05\nB0.40 0.60/bracketrightbigg\n.\nThe Markov chain diagram is shown in Figure 8.1.\n0.6 0.950.05\n0.4W orkin g Broken\nFigure 8.1. Markov chain for repair facility problem.\n132 discrete-time markov chains\nQuestion: Now suppose that after the machine remains broken for 4 days, the machine\nis replaced with a new machine. How does the DTMC diagram change?\nAnswer: The revised DTMC is shown in Figure 8.2.\n0.05\n0.40.4\n0.410.6\n0 0.95Broken\nDay 1W orkin g 00.6 0.6\nBroken\nDay 2Broken\nDay 4Broken\nDay 3\nFigure 8.2. Markov chain for repair facility problem with 4-day limit.\n8.3.2 Umbrella Problem\nAn absent-minded professor has two umbrellas that she uses when commuting from\nhome to ofﬁce and back. If it rains and an umbrella is available in her location, shetakes it. If it is not raining, she always forgets to take an umbrella. Suppose that it rains\nwith probability\npeach time she commutes, independently of prior commutes. Our\neventual goal is to determine the fraction of commutes during which the professor gets\nwet.1\nQuestion: What is the state space?\nHint: You can model this with three states!\nAnswer: The states track the number of umbrellas available at the current location,\nregardless of what this current location is. The DTMC is shown in Figure 8.3.\nThe transition probability matrix is P=⎡\n⎣00 1\n01−pp\n1−pp 0⎤\n⎦.\np 1–p1.0\n1–pp\nFigure 8.3. DTMC for umbrella problem.\n8.3.3 Program Analysis Problem\nA program has three types of instructions: CPU instructions (C), Memory instructions\n(M), and User interaction instructions (U). In analyzing the program, we note that\n1The umbrella example is borrowed from Bertsekas & Gallager [ 18].",5981
53-8.4 Powers of P n-Step Transition Probabilities.pdf,53-8.4 Powers of P n-Step Transition Probabilities,"8.4powers of P:n-step transition probabilities 133\na C instruction with probability 0.7is followed by another C instruction, but with\nprobability 0.2is followed by an M instruction and with probability 0.1is followed\nby a U instruction. We also note that an M instruction with probability 0.1is followed\nby another M instruction, but with probability 0.8is followed by a C instruction,\nand with probability 0.1is followed by a U instruction. Finally, a U instruction, with\nprobability 0.9is followed by a C instruction, and with probability 0.1is followed by\nan M instruction.\nIn the exercises for this chapter and the next, we answer questions like, “What is the\nfraction of C instructions?” and “What is the mean length of the instruction sequencebetween consecutive M instructions?” For now, we simply note that the program canbe represented as a Markov chain with the transition probability matrix,\nP:\nP=⎡\n⎣CMU\nC0.70.20.1\nM0.80.10.1\nU0.90.10⎤\n⎦\n8.4 Powers of P:n-Step Transition Probabilities\nLetPn=P·P···P, multiplied ntimes. We will use the notation Pn\nijto denote\n(Pn)ij.\nQuestion: What does Pn\nijrepresent?\nAnswer: To answer this, we ﬁrst consider two examples.\nUmbrella Problem\nConsider the umbrella problem from before where the chance of rain on any given day\nisp=0.4. We then have\nP=⎡\n⎣001\n00.60.4\n0.60.40⎤\n⎦,P5=⎡\n⎣.06.30.64\n.18.38.44\n.38.44.18⎤\n⎦,P30=⎡\n⎣.230.385.385\n.230.385.385\n.230.385.385⎤\n⎦.\nObserve that all the rows become the same ! Note also that, for all the above powers,\neach row sums to 1.\nRepair Facility Problem\nNow, consider again the simple repair facility problem, with general transition proba-\nbility matrix P:\nP=/bracketleftbigg\n1−aa\nb1−b/bracketrightbigg\n,0<a< 1,0<b< 1\n134 discrete-time markov chains\nYou should be able to prove by induction that\nPn=/bracketleftBiggb+a(1−a−b)n\na+ba−a(1−a−b)n\na+b\nb−b(1−a−b)n\na+ba+b(1−a−b)n\na+b/bracketrightBigg\n.\nlim\nn→∞Pn=/bracketleftBiggb\na+ba\na+b\nb\na+ba\na+b/bracketrightBigg\n.\nQuestion: Again, all rows are the same. Why? What is the meaning of the row?\nHint: Consider a DTMC in state i. Suppose we want to know the probability that it\nwill be in state jtwo steps from now. To go from state ito state jin two steps, the\nDTMC must have passed through some state kafter the ﬁrst step. Below we condition\non this intermediate state k:\nFor an M-state DTMC, as shown in Figure 8.4,\nP2\nij=M−1/summationdisplay\nk=0Pik·Pkj\n=Probability that after 2 steps we will be in state j, given that\nwe are in state inow.\nij\nPij =2\nFigure 8.4. P2\nij.\nLikewise, the n-wise product can be viewed as\nPn\nij=M−1/summationdisplay\nk=0Pn−1\nikPkj\n=Probability of being in state jinnsteps, given we are in state inow.\nLimiting Probabilities\nWe now move on to looking at the limit. Consider the (i, j)th entry of the power matrix\nPnfor large n:\nlim\nn→∞Pn\nij=/parenleftBig\nlim\nn→∞Pn/parenrightBig\nij\nThis quantity represents the limiting probability of being in state jinﬁnitely far into\nthe future, given that we started in state i.\nQuestion: So what is the limiting probability of having 0umbrellas?\nAnswer: According to P30, it is 0.23.",3180
54-8.6 The Stationary Distribution Equals the Limiting Distribution.pdf,54-8.6 The Stationary Distribution Equals the Limiting Distribution,"8.5stationary equations 135\nQuestion: The fact that the rows of limn→∞Pnare all the same is interesting because\nit says what?\nAnswer: It says that the starting state ( i) does not matter.\nDeﬁnition 8.4 Let\nπj= lim\nn→∞Pn\nij.\nπjrepresents the limiting probability that the chain is in state j(independent of the\nstarting state i). For an M-state DTMC, with states 0,1,...,M−1,\n/vectorπ=(π0,π1,...,π M−1),whereM−1/summationdisplay\ni=0πi=1\nrepresents the limiting distribution of being in each state.\nImportant Note: As deﬁned, πjis a limit. Yet it is not at all obvious that the limit πj\nexists! It is also not obvious that /vectorπrepresents a distribution (i.e.,/summationtext\niπi=1), although\nthis latter part turns out to be easy to see (Exercise 8.2). For the rest of this chapter,\nwe assume that the limiting probabilities exist. In Chapter 9we look at the existence\nquestion in detail.\nQuestion: So what is the limiting probability that the professor gets wet?\nAnswer: The professor gets wet if both (i) the state is 0, that is there are zero umbrellas\nin the current location; and (ii) it is raining. So the limiting probability that the professor\ngets wet on any given day is π0·p=( 0.23)(0.4) =.092.\nQuestion: Can you see why the limiting probability of having 1 umbrella is equal to\nthe limiting probability of having 2 umbrellas?\nAnswer: This is a little tricky. Notice that if we are only looking at the DTMC from the\nperspective of 1 versus 2 umbrellas, then the chain becomes symmetric. The collapsed\nchain is shown in Figure 8.5.\n1–p 1–pp\np\nFigure 8.5. Compressed umbrella problem.\n8.5 Stationary Equations\nQuestion: Based only on what we have learned so far, how do we determine πj=\nlimn→∞Pn\nij?\nAnswer: We take the transition probability matrix Pand raise it to the nth power for\nsome large nand look at the jth column, any row.\n136 discrete-time markov chains\nQuestion: Multiplying Pby itself many times sounds quite onerous. Also, it seems\none might need to perform a very large number of multiplications if the Markov chain\nis large. Is there a more efﬁcient way?\nAnswer: Yes, by solving stationary equations, given in Deﬁnition 8.5.\nDeﬁnition 8.5 A probability distribution /vectorπ=(π0,π1,...,π M−1)is said to be\nstationary for the Markov chain if\n/vectorπ·P=/vectorπandM−1/summationdisplay\ni=0πi=1.\nThese equations are referred to as the stationary equations . Deﬁnition 8.5says that /vectorπ\nis stationary if\nM−1/summationdisplay\ni=0πiPij=πj,∀jandM−1/summationdisplay\ni=0πi=1. (8.1)\nQuestion: What does the left-hand-side (LHS) of the ﬁrst equation in ( 8.1) represent?\nAnswer: The LHS represents the probability of being in state jone transition from\nnow, given that the current probability distribution on the states is /vectorπ. So equation ( 8.1)\nsays that if we start out distributed according to /vectorπ, then one step later our probability\nof being in each state will still follow distribution /vectorπ. Thus from then on we will always\nhave the same probability distribution on the states. Hence we call the distribution\n“stationary.”\n8.6 The Stationary Distribution Equals the Limiting Distribution\nThe following theorem relates the limiting distribution to the stationary distribution for\na ﬁnite-state DTMC. Speciﬁcally, the theorem says that for a ﬁnite-state DTMC, thestationary distribution obtained by solving ( 8.1) is unique and represents the limiting\nprobabilities of being in each state, assuming these limiting probabilities exist.\nTheorem 8.6 (Stationary distribution =Limiting distribution) Given a ﬁnite-\nstate DTMC with Mstates, let\nπj= lim\nn→∞Pn\nij>0\nbe the limiting probability of being in state jand let\n/vectorπ=(π0,π1,...,π M−1),whereM−1/summationdisplay\ni=0πi=1\nbe the limiting distribution. Assuming that the limiting distribution exists, then /vectorπis\nalso a stationary distribution and no other stationary distribution exists.\n8.6the stationary distribution equals the limiting distribution 137\nProof We will prove two things about the limiting distribution /vectorπ.\n1.We will prove that {πj,j=0,1,2,...,M−1}is a stationary distribution.\nHence at least one stationary distribution exists.\n2.We will prove that any stationary distribution must be equal to the limiting\ndistribution.\nThroughout, {πj,j=0,1,2,...,M−1}is used to refer to the limiting distribution.\nPart 1: Proof that {πj,j=0,1,2,...,M−1}is a stationary distribution:\nπj= lim\nn→∞Pn+1\nij= lim\nn→∞M−1/summationdisplay\nk=0Pn\nik·Pkj=M−1/summationdisplay\nk=0lim\nn→∞Pn\nikPkj=M−1/summationdisplay\nk=0πkPkj\nHence /vectorπsatisﬁes the stationary equations.\nPart 2: Proof that any stationary distribution must equal the limiting distribution:\nLet/vectorπ/primebe any stationary probability distribution. As usual, /vectorπrepresents the limiting\nprobability distribution. We will prove that /vectorπ/prime=/vectorπ, and speciﬁcally that π/prime\nj=πj.\nLet’s assume that we start at time 0with distribution /vectorπ/prime. Then\nπ/prime\nj=P{X0=j}=P{Xn=j}because /vectorπ/primeis stationary.\nSo\nπ/prime\nj=P{Xn=j},∀n\n=M−1/summationdisplay\ni=0P{Xn=j|X0=i}·P{X0=i},∀n\n=M−1/summationdisplay\ni=0Pn\nijπ/prime\ni,∀n.\nSo\nπ/prime\nj= lim\nn→∞π/prime\nj= lim\nn→∞M−1/summationdisplay\ni=0Pn\nijπ/prime\ni=M−1/summationdisplay\ni=0lim\nn→∞Pn\nijπ/prime\ni=M−1/summationdisplay\ni=0πjπ/prime\ni=πjM−1/summationdisplay\ni=0π/prime\ni=πj.\nNote that we were allowed to pull the limit into the summation sign in both parts\nbecause we had ﬁnite sums ( Mis ﬁnite).\nOne more thing: In the literature you often see the phrase “Consider a stationary Markov\nchain,” or “Consider the following Markov chain in steady state ...”\nDeﬁnition 8.7 A Markov chain for which the limiting probabilities exist is said to\nbestationary or in steady state if the initial state is chosen according to the stationary\nprobabilities.",5915
55-8.9 Infinite-State Stationarity Result.pdf,55-8.9 Infinite-State Stationarity Result,"138 discrete-time markov chains\nSummary: Finding the Limiting Probabilities in a Finite-State DTMC :\nBy Theorem 8.6, given the limiting distribution {πj,j=0,1,2,...,M−1}\nexists, we can obtain it by solving the stationary equations\n/vectorπ·P=/vectorπ andM−1/summationdisplay\ni=0πi=1\nwhere /vectorπ=(π0,π1,...,π M−1).\n8.7 Examples of Solving Stationary Equations\n8.7.1 Repair Facility Problem with Cost\nConsider again the repair facility problem represented by the ﬁnite-state DTMC shown\nhere:\n0.6 0.950.05\n0.4W orkin g Broken\nWe are interested in the following type of question.\nQuestion: The help desk is trying to ﬁgure out how much to charge me for maintaining\nmy machine. They ﬁgure that it costs them $300 every day that my machine is in repair.\nWhat will my annual repair bill be?\nTo answer this question, we ﬁrst derive the limiting distribution /vectorπ=(πW,πB)for this\nchain. We solve the stationary equations to get /vectorπas follows:\n/vectorπ=/vectorπ·P,whereP=/parenleftbigg\n.95.05\n.4.6/parenrightbigg\nπW+πB=1\nThis translates to the following equations:\nπW=πW·.95 +πB·.4\nπB=πW·.05 +πB·.6\nπW+πB=1\nQuestion: What do you notice about the ﬁrst two equations above?\nAnswer: They are identical! In general, if /vectorπ=/vectorπ·Presults in Mequations, only\nM−1of these will be linearly independent. Fortunately, the last equation above (the\n8.8inﬁnite-state dtmcs 139\nnormalization condition) is there to help us out. Solving, we get πW=8\n9andπB=1\n9.\nBy Theorem 8.6, the stationary distribution also represents the limiting probability\ndistribution. Thus my machine is broken 1 out of every 9 days on average. The expected\ndaily cost is1\n9·300 = $33.33 (with an annual cost of more than $12,000).\n8.7.2 Umbrella Problem\nConsider again the umbrella problem with probability pof rain each day. Before,\nwe raised the transition probability matrix Pto the nth power to get the limiting\nprobabilities, in the case where p=0.4. Now let’s use the stationary equations to\nobtain the limiting probabilities for general p.\np 1–p1.0\n1–pp\nWe solve the following stationary equations to get the limiting probabilities:\nπ0=π2·(1−p)\nπ1=π1·(1−p)+π2·p\nπ2=π0·1+π1·p\nπ0+π1+π2=1\nTheir solution is\nπ0=1−p\n3−p.π 1=1\n3−p.π 2=1\n3−p.\nQuestion: Suppose the probability of rain is p=0.6. What fraction of days does the\nprofessor get soaked?\nAnswer: The professor gets wet if she has zero umbrellas and it is raining: π0·p=\n0.4\n2.4·0.6=0.1. Not too bad!\n8.8 Inﬁnite-State DTMCs\nSo far we have only talked about ﬁnite -state DTMCs with Mstates. Now we move on\nto inﬁnite-state DTMCs. For a Markov chain with an inﬁnite number of states, one can\nstill imagine a transition probability matrix, P, although the matrix has inﬁnite order.\nWe denote the limiting probability distribution on the states by\n/vectorπ=(π0,π1,π2,...)where πj= lim\nn→∞Pn\nij and∞/summationdisplay\nj=0πj=1.\n140 discrete-time markov chains\nInﬁnite-state Markov chains are common in modeling systems where the number of\ncustomers or jobs is unbounded, and thus the state space is unbounded.\n8.9 Inﬁnite-State Stationarity Result\nWe have seen that for a ﬁnite-state DTMC, if the limiting distribution exists, then thelimiting distribution and stationary distribution are equivalent (Theorem 8.6). The same\nresult holds for inﬁnite-state DTMCs.\nTheorem 8.8 (Stationary distribution =Limiting distribution) Given an\ninﬁnite-state DTMC, let\nπj= lim\nn→∞Pn\nij>0\nbe the limiting probability of being in state jand let\n/vectorπ=(π0,π1,π2,...)where∞/summationdisplay\ni=0πi=1\nbe the limiting distribution. Assuming that the limiting distribution exists, then /vectorπis\nalso a stationary distribution and no other stationary distribution exists.\nProof We will prove two things about this limiting distribution, assuming it exists.\n1.We will prove that {πj,j=0,1,2,...}is a stationary distribution. Hence at\nleast one stationary distribution exists.\n2.We will prove that any stationary distribution must be equal to the limiting\ndistribution.\nPart 1: Proof that {πj,j=0,1,2,...}is a stationary distribution:\nπj= lim\nn→∞Pn+1\nij= lim\nn→∞∞/summationdisplay\nk=0Pn\nik·Pkj (8.2)\nQuestion: If we could interchange the limit and sum at this point, what would we know\naboutπj?\nAnswer: We would know that πjis a stationary distribution – we would be done with\nPart 1.\nUnfortunately, we cannot in general interchange the limit and sum when the sum is\ninﬁnite. So what we need to do in these types of proofs is convert the inﬁnite sum to aﬁnite sum, make the switch, and then convert back to an inﬁnite sum\n...carefully.\nπj= lim\nn→∞Pn+1\nij\n= lim\nn→∞∞/summationdisplay\nk=0Pn\nikPkj\n8.9inﬁnite-state stationarity result 141\n≥lim\nn→∞M/summationdisplay\nk=0Pn\nikPkj,∀M\n=M/summationdisplay\nk=0lim\nn→∞Pn\nikPkj,∀M\n=M/summationdisplay\nk=0πkPkj,∀M\nSo\n∀M, π j≥M/summationdisplay\nk=0πkPkj\n⇒πj≥lim\nM→∞M/summationdisplay\nk=0πkPkj\n⇒πj≥∞/summationdisplay\nk=0πkPkj.\nWe are almost there. We would like to prove that the above inequality is actually an\nequality. Suppose, by contradiction, ∃lsuch that\nπl>∞/summationdisplay\nk=0πkPkl.\nLet’s consider/summationtext∞\nj=0πj:\n∞/summationdisplay\nj=0πj>∞/summationdisplay\nj=0/parenleftBigg∞/summationdisplay\nk=0πkPkj/parenrightBigg\n=∞/summationdisplay\nk=0∞/summationdisplay\nj=0πkPkj=∞/summationdisplay\nk=0πk·1=1\nYet this says that the sum of the limiting probabilities is strictly greater than 1, which\nis impossible and hence a contradiction. So we have shown that\nπj=∞/summationdisplay\nk=0πkPkj. (8.3)\nPart 2: Proof that any stationary distribution must equal the limiting distribution:\nLet/vectorπ/primebe any stationary probability distribution. As usual, /vectorπrepresents the limiting\nprobability distribution. Our goal is to prove that π/prime\nj=πj,∀j.\nLet’s assume that we start at time 0with distribution /vectorπ/prime. Then\nπ/prime\nj=P{X0=j}=P{Xn=j}because π/prime\njis stationary.",5992
56-8.10 Solving Stationary Equations in Infinite-State DTMCs.pdf,56-8.10 Solving Stationary Equations in Infinite-State DTMCs,"142 discrete-time markov chains\nSo\nπ/prime\nj=P{Xn=j}\n=∞/summationdisplay\ni=0P{Xn=j|X0=i}·P{X0=i}\n=∞/summationdisplay\ni=0Pn\nijπ/prime\ni\n=M/summationdisplay\ni=0Pn\nijπ/prime\ni+∞/summationdisplay\ni=M+1Pn\nijπ/prime\ni(for any integer M).\nObserving that 0≤Pn\nij≤1, we now apply the sandwich theorem to the above equa-\ntion, which will allow us to prove that π/prime\njis bounded above and below by πj.\nM/summationdisplay\ni=0Pn\nijπ/prime\ni≤π/prime\nj≤M/summationdisplay\ni=0Pn\nijπ/prime\ni+∞/summationdisplay\ni=M+1π/prime\ni\nlim\nn→∞M/summationdisplay\ni=0Pn\nijπ/prime\ni≤lim\nn→∞π/prime\nj≤lim\nn→∞M/summationdisplay\ni=0Pn\nijπ/prime\ni+ lim\nn→∞∞/summationdisplay\ni=M+1π/prime\ni\nM/summationdisplay\ni=0πjπ/prime\ni≤π/prime\nj≤M/summationdisplay\ni=0πjπ/prime\ni+∞/summationdisplay\ni=M+1π/prime\ni\nπjM/summationdisplay\ni=0π/prime\ni≤π/prime\nj≤πjM/summationdisplay\ni=0π/prime\ni+∞/summationdisplay\ni=M+1π/prime\ni\nlim\nM→∞πjM/summationdisplay\ni=0π/prime\ni≤lim\nM→∞π/prime\nj≤lim\nM→∞πjM/summationdisplay\ni=0π/prime\ni+ lim\nM→∞∞/summationdisplay\ni=M+1π/prime\ni\nπj≤π/prime\nj≤πj\nThus we have shown that π/prime\nj=πjas desired.\n8.10 Solving Stationary Equations in Inﬁnite-State DTMCs\nWe have seen that to obtain the limiting probability distribution /vectorπ, assuming that it\nexists, we only need to solve the stationary equations. Yet there are an inﬁnite number\nof stationary equations! Let’s see how we solve them.\nConsider the example of an unbounded queue (see Figure 8.6). Imagine jobs (or\ncustomers) arriving at a server. These jobs queue up at the server. The server works on\n8.10 solving stationary equations in inﬁnite-state dtmcs 143\nthe job at the head of the queue, and when it ﬁnishes that job, it moves on to the next\njob. This server never drops jobs, but just allows them to queue.\nFigure 8.6. Illustration of a server with unbounded buffer.\nSuppose at every time step, with probability p=1\n40one job arrives, and independently,\nwith probability q=1\n30one job departs. Note that during a time step, we might have\nboth an arrival and a transmission, or neither.\nWe will be interested in answering questions like, what is the average number of jobs\nin the system?\nTo answer this question, we model the problem as a DTMC with an inﬁnite number of\nstates: 0,1,2,..., representing the number of jobs at the router. Let r=p(1−q)=\n29\n1200ands=q(1−p)=39\n1200, where r<s . Figure 8.7shows the Markov chain for\nour problem.\n0r\nsr\nsr\ns1−r−s 1−r−s 1−r−s\n00 1 2 1−r 3\nFigure 8.7. DTMC for a server with unbounded queue.\nHere the transition probability matrix is inﬁnite!\nP=⎛\n⎜⎜⎜⎜⎜⎝1−rr 00 ...\ns1−r−sr 0 ...\n0 s 1−r−s r ...\n00 s 1−r−s ...\n...............⎞\n⎟⎟⎟⎟⎟⎠\nThe stationary equations look like this:\nπ0=π0(1−r)+π1s\nπ1=π0r+π1(1−r−s)+π2s\nπ2=π1r+π2(1−r−s)+π3s\nπ3=π2r+π3(1−r−s)+π4s\n...\nπ0+π1+π2+π3+···=1\n144 discrete-time markov chains\nQuestion: How are we going to solve this inﬁnite number of equations?\nHint: Observe that the ﬁrst equation can be rewritten as\nπ1=r\nsπ0.\nCan you use this to express π2in terms of π0?\nAnswer: If we substitute the above expression for π1into the second stationary equa-\ntion, we can express π2in terms of π0as well:\nπ2=/parenleftBigr\ns/parenrightBig2\nπ0\nWe can now substitute the expression for π2into the third stationary equation, to\nexpress π3in terms of π0as well:\nπ3=/parenleftBigr\ns/parenrightBig3\nπ0\nWe can now make a general “guess”:\nπi=/parenleftBigr\ns/parenrightBigi\nπ0\nQuestion: How do we verify that this guess is correct?\nAnswer: To verify your guess, you need to show that it satisﬁes the stationary equations:\nπi=πi−1r+πi(1−r−s)+πi+1s\n/parenleftBigr\ns/parenrightBigi\nπ0=/parenleftBigr\ns/parenrightBigi−1\nπ0r+/parenleftBigr\ns/parenrightBigi\nπ0(1−r−s)+/parenleftBigr\ns/parenrightBigi+1\nπ0s√\nQuestion: OK, but we still do not know π0. How can we determine π0?\nAnswer: To determine π0, we make use of the fact that/summationtext\niπi=1.\nThis says that\nπ0·/parenleftbigg\n1+r\ns+/parenleftBigr\ns/parenrightBig2\n+/parenleftBigr\ns/parenrightBig3\n+···/parenrightbigg\n=1\nπ0·/parenleftbigg1\n1−r\ns/parenrightbigg\n=1\nπ0=1−r\ns.\nSo\nπi=/parenleftBigr\ns/parenrightBigi\n·/parenleftBig\n1−r\ns/parenrightBig\n.",4277
57-8.11 Exercises.pdf,57-8.11 Exercises,"8.11 exercises 145\nQuestion: What is the average number of jobs at the server?\nAnswer: LetNdenote the number of jobs at the server. Then\nE[N]=π0·0+π1·1+π2·2+π3·3+...\nQuestion: Can we get a closed-form expression for E[N]?\nAnswer: Yes! It will help to deﬁne\nρ=r\ns\nfor shorthand. Then πi=ρi(1−ρ).\nE[N]=1ρ(1−ρ)+2ρ2(1−ρ)+3ρ3(1−ρ)+...\n=( 1−ρ)ρ/parenleftbig\n1+2ρ+3ρ2+4ρ3+.../parenrightbig\n=( 1−ρ)ρd\ndρ/parenleftbig\n1+ρ+ρ2+ρ3+ρ4+.../parenrightbig\n=( 1−ρ)ρd\ndρ/parenleftbigg1\n1−ρ/parenrightbigg\n=( 1−ρ)ρ·1\n(1−ρ)2\n=ρ\n1−ρ(8.4)\nWow! That is a really simple formula. We will see this again . . .\nFor our example ρ=29\n39andE[N]=2.9. So on average there are about 3jobs in the\nsystem.\n8.11 Exercises\n8.1 Solving for Limiting Distribution\nConsider the program analysis problem from Section 8.3.3 . Determine the\nlimiting distribution, (πC,πM,πU), by solving the stationary equations.\n8.2 Powers of Transition Matrix\nGiven any ﬁnite-state transition matrix, P, prove that for any integer n,Pn\nmaintains the property that each row sums to 1.\n8.3 Doubly Stochastic Matrix\nA doubly stochastic matrix is one in which the entries in each row sum up to\n1 and the entries in each column sum up to 1. Suppose you have a ﬁnite-stateMarkov chain whose limiting probabilities exist and whose transition matrix is\ndoubly stochastic. What can you prove about the stationary distribution of thisMarkov chain?\n146 discrete-time markov chains\n8.4 Gambling Game\nDafna starts out with zero dollars. Every day she gains a dollar with prob-\nability p, stays put with probability s, or loses all her money (goes broke)\nwith probability b, where p+s+b=1. Dafna plays the game forever. Use a\nDTMC to determine the stationary probability that Dafna has idollars. What\nhappens to your solution when s=0? What is Dafna’s long-run expected\nmoney?\n8.5 Randomized Chess\nIn chess, a rook can move either horizonally within its row (left or right) or\nvertically within its column (up or down) any number of squares. In an 8×8\nchess board, imagine a rook that starts at the lower left corner of a chess board.\nAt each move, a bored child decides to move the rook to a random legal location(assume that the “move” cannot involve staying still). Let\nTdenote the time\nuntil the rook ﬁrst lands in the upper right corner of the board. Compute E[T]\nandVar(T).\n8.6 Threshold Queue\nWe deﬁne a threshold queue with parameter Tas follows: When the number\nof jobs is <T, then the number of jobs decreases by 1 with probability 0.4\nand increases by 1 with probability 0.6at each time step. However, when the\nnumber of jobs increases to >T, then the reverse is true, and the number of\njobs increases by 1 with probability 0.4and decreases by 1 with probability 0.6\nat each time step, as shown in Figure 8.8.\n0.4\n0.60.4 0.4\n0.6 0.6q0.6\n0.40.60.2\n0.40 0.4 4 2 3 1 q0.6\n0.40 0.4 05\nFigure 8.8. Markov chain for threshold queue with T=3.\n(a) Assume that the limiting probabilities exist. Use the stationary equations to\nderive the limiting probability distribution as a function of T, for arbitrary\nthreshold T.\n(b) Compute the mean number of jobs, E[N], in a threshold queue as a function\nofT.\n(c) What happens to E[N]whenT=0? Does this answer make sense?\n8.7 Naval Battle Analysis\nIn the game Axis & Allies, the outcome of a two-sided naval battle is decided\nby repeated rolling of dice. Until all ships on at least one side are destroyed,\neach side rolls one (six-sided) die for each of its existing ships. The die rollsdetermine casualties inﬂicted on the opponent; these casualties are removedfrom play and cannot ﬁre (roll) in subsequent rounds. There are two types ofships: battleships and destroyers. For a battleship, a die roll of four or lower is\nscored as a “hit.” For a destroyer, a die roll of three or lower is scored as a “hit.”\n8.11 exercises 147\nIt takes two hits (not necessarily in the same round) to destroy a battleship and\nonly one hit to destroy a destroyer (side note: battleships are twice as expensiveas destroyers). The defender gets to decide to which ship to allocate the hit; weassume the defender chooses intelligently. If two destroyers engage a battleshipin a naval battle, what is the probability that the destroyers win? How about thebattleship? [Hint: You will need to raise a matrix to a large power.]",4355
58-Chapter 9 Ergodicity Theory.pdf,58-Chapter 9 Ergodicity Theory,,0
59-9.2 Finite-State DTMCs.pdf,59-9.2 Finite-State DTMCs,"CHAPTER 9\nErgodicity Theory\n9.1 Ergodicity Questions\nAt this point, in our discussion of DTMCs, we have deﬁned the notion of a limiting\nprobability of being in state j:\nπj= lim\nn→∞(Pn)ij,\ntypically written πj= lim n→∞Pn\nij, where the limiting distribution is\n/vectorπ=(π0,π1,π2,π3,...)with∞/summationdisplay\ni=0πi=1.\nWe have also deﬁned the notion of a stationary distribution ,/vectorπ, as a distribution that\nsatisﬁes\n/vectorπ·P=/vectorπ and∞/summationdisplay\ni=0πi=1\nor, equivalently,\nπj=∞/summationdisplay\ni=0πiPij and∞/summationdisplay\ni=0πi=1.\nWe also proved two theorems (Theorem 8.6for ﬁnite-state chains and Theorem 8.8\nfor inﬁnite-state chains) that said that, assuming the limiting distribution exists, then\nthe limiting distribution is a stationary distribution and no other stationary distribution\nexists. These theorems are key because they allow us to simply solve the stationaryequations to get the limiting distribution.\nQuestion: Is\nπj= lim n→∞Pn\nija time average or an ensemble average?\nAnswer: Ensemble. When we raise matrix Pto thenth power, we are averaging over\nall sample paths of length n(i.e., all possible choices for the ﬁrst hop, 2nd hop, 3rd\nhop, etc.). πjis deﬁned to be the limiting probability of being in state j. By contrast,\nwe can deﬁne pjto be the time-average fraction of time spent in state j, averaged over\none inﬁnitely long sample path.\nIn the previous chapter we looked at how to ﬁnd πj, assuming it exists. However, we\ndid not spend much time on questions like the following:\n1.Under what conditions does the limiting distribution exist?\n2.How does the limiting probability of being in state j,πj, compare with the\nlong-run time-average fraction of time spent in state j,pj?\n148\n9.2finite-state dtmcs 149\n3.What can we say about the mean time between visits to state j, and how is this\nrelated to πj?\nThis entire chapter is devoted to these and other theoretical questions, all related to\nthe notion of ergodicity (you can look ahead to Deﬁnition 9.24, where ergodicity is\ndeﬁned). We end with a brief discussion of time-reversibility, which gives a faster\nmethod for computing limiting probabilities in the case of certain Markov chains.\nUnsurprisingly, most of the questions just presented are simpler to think about in the\ncontext of a ﬁnite-state Markov chain. Hence, we start in Section 9.2by discussing\nthese issues for a ﬁnite-state chain. After that, we move on to inﬁnite-state chains.\nThis is a highly theoretical chapter. The reader may wish to forgo the proofs during a\nﬁrst reading and return later for a more in-depth reading.\n9.2 Finite-State DTMCs\n9.2.1 Existence of the Limiting Distribution\nWe dive right into the question of existence of the limiting distribution, with a few\nexamples.\nQuestion: What is an example of a valid two-state transition matrix for which πjdoes\nnot exist?Answer:\nP=/bracketleftbigg\n01\n10/bracketrightbigg\nThe problem is that this chain is periodic ; speciﬁcally, a given state is only visited every\nother time step. Observe that πj= lim n→∞Pn\njjdoes not exist, although limn→∞P(2n)\njj\ndoes exist.\nQuestion: What is the time average, pj, for the above chain?\nAnswer: The above chain is a valid DTMC, so there has to be some fraction of time\nspent in each state. In this case, the time averages are obvious: p0=1\n2=p1.\nQuestion: Does this chain have a stationary distribution?\nAnswer: Yes, the stationary distribution does exist. To see this, let’s set up the stationary\nequations /vectorπ·P=/vectorπ:\nπ0=π1\nπ1=π0\nπ0+π1=1\nSolving these, we get /vectorπ=(1\n2,1\n2)=(p1,p2).\nExamples like this one illustrate why we need to pay attention to the conditions under\nwhich all these kinds of averages agree. Let’s consider another example.\n150 ergodicity theory\nQuestion: Does the following transition matrix have limiting probabilities?\nP=⎡\n⎢⎢⎣001 /21/2\n10 0 0\n01 0 001 0 0⎤\n⎥⎥⎦\nAnswer: No, this too is periodic – it is just a little harder to see.\nDeﬁnition 9.1 The period of state jis the greatest common divisor (GCD) of the\nset of integers n, such that Pn\njj>0. A state is aperiodic if it has period 1. A chain\nis said to be aperiodic if all of its states are aperiodic.\nSo aperiodicity is clearly necessary for the limiting probabilities to exist. However in\nan aperiodic Markov chain, it could still turn out that the limiting probabilities depend\non the start state, whereas we want πj= lim n→∞Pn\nijto be the same for all i.\nIf we also want the limiting probabilities to be independent of the start state, we need\none more condition, known as irreducibility , which says that from any state one can\nget to any other state.\nDeﬁnition 9.2 Statejisaccessible from state iifPn\nij>0for some n>0. States\niandjcommunicate ifiis accessible from jand vice versa.\nDeﬁnition 9.3 A Markov chain is irreducible if all its states communicate with\neach other.\nQuestion: Why is irreducibility needed for the limiting probabilities to be independent\nof the start state?\nAnswer: Without irreducibility, one might, for example, have the situation where the\nMarkov chain consists of two disconnected components – thus the limiting probabilities\nwould depend on which component contains the start state.\nQuestion: What is a simple transition matrix that is notirreducible?\nAnswer: The identity matrix.\nQuestion: Do you think that aperiodicity and irreducibility are enough to guarantee\nthe existence of the limiting distribution?\nAnswer: As we see in Theorem 9.4, for a ﬁnite-state DTMC, aperiodicity and ir-\nreducibility are all that is needed to ensure that the limiting probabilities exist, are\npositive, sum to 1, and are independent of the starting state. This is very convenient,because it is often easy to argue that a DTMC is aperiodic and irreducible.\nTheorem 9.4 Given an aperiodic, irreducible, ﬁnite-state DTMC with transition\nmatrixP,a sn→∞ ,Pn→L, where Lis a limiting matrix all of whose rows are\nthe same vector, /vectorπ. The vector /vectorπhas all positive components, summing to 1.\n9.2finite-state dtmcs 151\nProof We are trying to show that Pnconverges to a matrix where all rows are\nthe same. Speciﬁcally, we are trying to show that, for any j, thejth column of Pn\nconverges to a vector of all constants.\nLet/vectorerepresent the column vector of the same dimension as P, whose jth component\nis1and whose remaining components are all 0. That is\n/vectore=⎛\n⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝0\n...\n0\n10\n...\n0⎞\n⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠.\nWe are trying to show that\nPn·/vectore\nconverges to a vector all of whose components are the same.\nThe idea is to view Pn/vectore=P(...(P(P(P/vectore)))).\nConsider the innermost product P/vectore. Because Pis a matrix of probabilities, where each\nrow sums to 1, the effect of multiplying /vectorebyPis to replace each component of /vectoreby\na value that is a weighted average of all the components. In particular, the effect is\nto bring all the components of /vectorecloser together. That is, the difference between the\nmaximum component and the minimum component should decrease.\nHere is an example of the effect of successive multiplications by P:\nP/vectore=⎛\n⎜⎝1\n21\n31\n6\n1\n31\n31\n3\n1\n43\n40⎞\n⎟⎠·⎛\n⎝0\n10⎞\n⎠=⎛\n⎜⎝1\n3\n1\n33\n4⎞\n⎟⎠\nP(P/vectore)=⎛\n⎜⎝1\n21\n31\n6\n1\n31\n31\n3\n1\n43\n40⎞\n⎟⎠·⎛\n⎜⎝1\n3\n1\n33\n4⎞\n⎟⎠=⎛\n⎝.40\n.47\n.33⎞\n⎠\nLetMndenote the maximum component of Pn/vectoreand let mndenote the minimum\ncomponent of Pn/vectore.\nWe now claim that\nMn−mn≤(1−2s)(Mn−1−mn−1) (9.1)\nwhere sis the smallest element in P.\nTo see why ( 9.1) is true, consider the vector /vectory=Pn−1/vectore. By our deﬁnition, the maxi-\nmum component of /vectoryisMn−1and the minimum is mn−1. Now, if we multiply /vectorybyP\n152 ergodicity theory\n(obtaining P/vectory=Pn/vectore), we are replacing each component of /vectoryby a weighted average\nof all the components of /vectory.\nQuestion: What is an upper bound on the largest possible component in P·/vectory?\nAnswer: The largest possible weighted average is obtained if all but one of the elements\nof/vectoryareMn−1, with the remaining one being mn−1, where mn−1is weighted by the\nsmallest value, s. An upper bound on the largest possible component of P·/vectoryis\ns·mn−1+( 1−s)·Mn−1.\nQuestion: What is a lower bound on the smallest possible component in P·/vectory?\nAnswer: In the smallest weighted average, all but one of the elements of /vectoryaremn−1,\nwith the remaining one being Mn−1, where Mn−1is weighted by the smallest value,\ns. Thus a lower bound on the smallest possible component of P·/vectoryis\n(1−s)·mn−1+s·Mn−1.\nThus an upper bound on the greatest difference between the components in P/vectoryis\ns·mn−1+( 1−s)·Mn−1−(1−s)·mn−1−s·Mn−1\n=( 1−2s)(Mn−1−mn−1).\nThis proves our claim in ( 9.1). Finally, because s≤1\n2(when M≥2), we see that the\ndifference between the maximum and minimum elements of Pn/vectorecontinues to decrease\nas we continue to multiply by P, until eventually all elements are the same.\nThe proof would now be complete except for a small hole . . .\nQuestion: Can you see the hole?\nAnswer: Ifs=0, then the above argument does not result in convergence, because\n(1−2s)=1 .\nQuestion: How can this be ﬁxed?\nHint: Even if Pcontains some zero elements, what do we know about Pnfor high\nenough n, given that Pis aperiodic and irreducible?\nAnswer: Because Pis aperiodic and irreducible, there exists some n0such that,\n∀n≥n0,Pnhas all positive elements. This follows from the Euclidean number\nproperty. [Here is a sketch: For any (j,j)entry, by aperiodicity, there are some powers\nxandysuch that PxandPyhave a positive (j,j)entry, where GCD(x, y)=1 .\nHence, by the Euclidean number property, ∃n0(j,j)s.t.,∀n≥n0(j,j),ncan be\nexpressed as a linear combination of xandywith non-negative coefﬁcients; hence,\n∀n≥n0(j,j), there is a path of length nfromjtoj, and thus the (j,j)th entry of Pn\nis positive. Now repeat this argument for all (j,j)pairs (there are only a ﬁnite number).\nFinally, consider two arbitrary states iandj, where i/negationslash=j. By irreducibility there is\nsomexs.t. there is a path from itojof length x. However, since we also know that\n9.2finite-state dtmcs 153\n∀n≥n0(i, i)there is a path of length nfromitoi, it follows that ∀n≥n0(i, i)+x\nthere is a path of length nfromitoj. Deﬁne n0(i, j)=n0(i,i)+x. Finally, deﬁne\nn0to be the maximum of all n0(i, j)values, over all iandj. Now, for all n≥n0,Pn\nhas all positive elements.]\nTo complete the proof, we now deﬁne P/prime=Pn0. Then\nPn/vectore=(Pn0)n/n 0=(P/prime)n/n 0.\nNow repeat the argument in ( 9.1), except that the decrease by a factor of (1−2s)<1\noccurs only every n0multiplications of P. However, because n/n 0→∞ asn→∞ ,\nwe still have an inﬁnite number of these decreases, meaning that\n(P/prime)n/n 0→L,asn→∞.\nTo ﬁnish off the proof of the theorem, we note that by Exercise 8.2, all powers of P\nhave the property that the components of each row sum to 1. Furthermore, because\nPn0has all positive elements, and because multiplying by Ponly creates weighted\naverages, then P·Pn0still has all positive elements and so forth as we continue to\nmultiply by P. Hence the limiting matrix Lwill still have all positive elements and\nwill have the property that the components of each row sum to 1.\nSummary : We have proven that for any aperiodic, irreducible, ﬁnite-state Markov\nchain, the limiting probabilities exist.\n9.2.2 Mean Time between Visits to a State\nConsider the mean time between visits to state j. It seems that this quantity should be\nrelated to the limiting probability of being in state j. Let’s see how.\nConsider an irreducible ﬁnite-state Markov chain with Mstates and transition\nmatrixP.\nDeﬁnition 9.5 Letmijdenote the expected number of time steps needed to ﬁrst get\nto state j, given we are currently at state i. Likewise, let mjjdenote the expected\nnumber of steps between visits to state j.\nIn Exercise 9.16, we will prove from ﬁrst principles that mjjis ﬁnite. Theorem 9.6\nrelates mjjtoπj.\nTheorem 9.6 For an irreducible, aperiodic ﬁnite-state Markov chain with transi-\ntion matrix P,\nmjj=1\nπj\nwhere mjjis the mean time between visits to state jandπj= lim n→∞(Pn)ij.\n154 ergodicity theory\nProof By conditioning on the ﬁrst step, we have\nmij=Pij·1+/summationdisplay\nk/negationslash=jPik(1 +mkj)\n=1+/summationdisplay\nk/negationslash=jPikmkj (9.2)\nLikewise\nmjj=Pjj·1+/summationdisplay\nk/negationslash=jPjk(1 +mkj)\n=1+/summationdisplay\nk/negationslash=jPjkmkj (9.3)\nLet’s express ( 9.2) and ( 9.3) using matrix notation. All the matrices in this proof are\nof the same order as P, namely M×M. Imagine a matrix Mwhose (i,j)th entry\nismij. For purposes of the proof, it will be convenient to express Mas a sum of two\nmatrices M=D+N,whereDis a matrix whose entries are all zero, except for its\ndiagonal entries: djj=mjj, andNis a matrix whose diagonal entries are all zero,\nbut where Nij=mij,∀i/negationslash=j. Finally, let Ebe a matrix with allentries 1. Then by\n(9.2) and ( 9.3), we can write1\nM=E+PN. (9.4)\nRewriting ( 9.4), we have\nN+D=E+PN.\n(I−P)·N=E−D.\nLet/vectorπdenote the limiting probability distribution. We know that /vectorπexists because we\nhave aperiodicity and irreducibility. Multiplying both sides by /vectorπ,w eh a v e\n/vectorπ·(I−P)·N=/vectorπ(E−D). (9.5)\nQuestion: What do we know about the left-hand side of ( 9.5)?\nHint: Remember that /vectorπis also a stationary distribution.\nAnswer:\n/vectorπP=/vectorπ\n⇒/vectorπ(I−P)=/vector0\n⇒/vectorπ(I−P)N=/vector0\n1To see this, observe that by ( 9.4),\n∀i/negationslash=j, m ij=1+/summationdisplay\nkPikNkj=1+/summationdisplay\nk/negationslash=jPikNkj=1+/summationdisplay\nk/negationslash=jPikmkj which matches ( 9.2).\nmjj=1+/summationdisplay\nkPjkNkj=1+/summationdisplay\nk/negationslash=jPjkNkj=1+/summationdisplay\nk/negationslash=jPjkmkj which matches ( 9.3).",13927
60-9.3 Infinite-State Markov Chains.pdf,60-9.3 Infinite-State Markov Chains,"9.3inﬁnite-state markov chains 155\nThus, we have from ( 9.5)\n/vector0=/vectorπ(E−D)\n⇒/vectorπE=/vectorπD\n⇒(1,1,...,1) = ( π0m00,π1m11,...,π M−1mM−1,M−1)\n⇒πimii=1,∀i.\n9.2.3 Time Averages\nSo far, we have seen that, for a ﬁnite-state Markov chain, the limiting distribution,\n/vectorπ=(π0,π1,...,π M−1), when it exists, is equal to the unique stationary distribution.\nWe have also seen that πj=1\nmjj, where mjjis the mean time (number of steps)\nbetween visits to state j. We now consider pj, the fraction of time that the Markov\nchain spends in state j, along a given sample path.\nQuestion: What would you guess is the relationship between πjandpj, assuming that\nthe limiting distribution exists?\nAnswer: It seems pretty natural to believe that πj=pj. We prove this formally later in\nTheorem 9.28, where we show that pj=1\nmjjwith probability 1(i.e., for almost every\nsample path). Because we also know that πj=1\nmjj, it follows that, with probability 1,\npj=πj.\nThe formal argument requires renewal theory, which is described in Section 9.5.H o w -\never, intuitively, it should make sense that if the average time between visits to state j\nismjj, then, during a long period of time t, we visit state japproximately x=t\nmjj\ntimes. Hence the proportion of time spent in state jduring time tisx\nt=t\nmjj·1\nt\n=1\nmjj.\n9.3 Inﬁnite-State Markov Chains\nWe now turn to inﬁnite-state Markov chains. These are far more difﬁcult to reason\nabout than ﬁnite-state Markov chains, and it will take some time to even develop theterminology we need to discuss them.\nConsider the three inﬁnite-state DTMCs shown in Figure 9.1.\nQuestion: Which of these chains are aperiodic and irreducible?\nAnswer: All of them.\nQuestion: Forﬁnite-state DTMCs that are aperiodic and irreducible, does a limiting\ndistribution always exist?\nAnswer: Yes, by Theorem 9.4.\nQuestion: Does a limiting distribution exist for all the chains in Figure 9.1?\nAnswer: We will see that a limiting distribution exists only for the ﬁrst chain. For\nthe ﬁrst chain, there is a well-deﬁned limiting probability of being in each state, and\n156 ergodicity theory\n3 1 2 0.6\n0.5 0.5 0.5\n0.1 0.1 0.10.50.4 0.4 0.4 0.4\n4\n3 1 2 0.5\n0.4 0.4 0.4\n0.1 0.1 0.10.40.5 0.5 0.5 0.5\n4\n3 1 2 0.50.5 0.5 0.5 0.5\n0.5 0.5 0.5 0.54\nFigure 9.1. Examples of positive recurrent, transient, and null-recurrent chains (looking from\ntop to bottom).\nthese probabilities sum to 1. For the other two chains, we will show that the limiting\nprobability of being in each state is 0, and the limiting probabilities do not sum to 1;\nhence there does not exist a limiting distribution. The ﬁrst chain has a property called\n“positive recurrent.” The second chain is what we call “transient,” and the third chain\nis “null recurrent.” We explain all these terms in this chapter and how they relate to the\nexistence of limiting distributions.\nQuestion: Intuitively, what is the problem with the second and third chains in Fig-\nure9.1?\nAnswer: The second chain can be viewed as an ocean, where the shore is at state\n1. There is a drift away from shore. Given this drift, it is not obvious that we keep\nreturning back to shore. There could be some point after which we never return to the\nshore. This same argument holds for any state kthat we call the “shore.” In the case of\nthe third chain, it seems that we should return to each state, but it is not obvious howlong it will take to return. If the time between visits to a state is inﬁnite, then it seems\nthat the limiting probability of being in the state should be zero.\n9.3.1 Recurrent versus Transient\nDeﬁnition 9.7 fj=probability that a chain starting in state jever returns to state\nj.\nDeﬁnition 9.8 A state jis either recurrent or transient:\nrIffj=1, thenjis arecurrent state.\nrIffj<1, thenjis atransient state.\n9.3inﬁnite-state markov chains 157\nQuestion: What is the distribution of the number of visits to a transient state j?\nAnswer: Every time we visit state jwe have probability 1−fjof never visit-\ning it again. Hence the number of visits is distributed Geometrically with mean\n1/(1−fj).\nTheorem 9.9 With probability 1, the number of visits to a recurrent state is\ninﬁnite. With probability 1, the number of visits to a transient state is ﬁnite.\nProof If a state jis recurrent, then starting in state j, with probability 1we will visit\njagain. Thus, repeating this argument, we see that with probability 1statejwill be\nvisited an inﬁnite number of times. In contrast, if state jis transient, then every time\nwe visit state j, there is some probability ( 1−fj) that we will never again visit j.\nThus, with probability 1statejwill be visited a ﬁnite number of times.\nTheorem 9.10\nE[# visits to state iinssteps|start in state i]=s/summationdisplay\nn=0Pn\nii (9.6)\nE[Total # visits to state i|start in state i]=∞/summationdisplay\nn=0Pn\nii (9.7)\nProof E[Number visits to state iinssteps|X0=i]\n=E/bracketleftBiggs/summationdisplay\nn=0In|X0=i/bracketrightBigg\n,where In=/braceleftbigg\n1ifXn=i\n0o.w.\n=s/summationdisplay\nn=0E[In|X0=i]\n=s/summationdisplay\nn=0P{Xn=i|X0=i}\n=s/summationdisplay\nn=0Pn\nii\nThe above proves ( 9.6). To get ( 9.7), we take the limit as s→∞ .\nSo, combining Theorems 9.9and9.10, we have the following theorem.2\nTheorem 9.11 If state iis recurrent, then/summationtext∞\nn=0Pn\nii=∞.\nIf state iis transient, then/summationtext∞n=0Pn\nii<∞.\n2Theorem 9.11 is an application of the Borel-Cantelli lemma [ 57].\n158 ergodicity theory\nTheorem 9.12 If state iis recurrent and icommunicates with j,(i←→j), then\njis recurrent.\nWe start with the intuition for Theorem 9.12. Consider Figure 9.2. We know that we\ncome back to iinﬁnitely many times. By the deﬁnition of “communicates,” every time\nwe are in i, we have some probability of taking the road to j, and once we are in\nj, we have some probability of taking the road to i. So, for every visit to i, there’s\nsome non-zero probability that we’ll also visit j. Therefore the number of visits to jis\nproportional to the number of visits to i. Because the number of visits to iis inﬁnite,\nso is the number of visits to j.\nAlways come backRoad to j\nRoad to ij i\nFigure 9.2. Proof of Theorem 9.12.\nNow for the formal proof.\nProof We know that icommunicates with j. Thus, there exists an msuch that\nPm\nji>0and there exists nsuch that Pn\nij>0.\nNow\nPm+s+n\njj≥Pm\njiPs\niiPn\nij. (9.8)\nThe right-hand side of ( 9.8) represents only some of the ways to go from jtojin\nm+n+ssteps, whereas the left-hand side represents all the ways. Summing both\nsides of ( 9.8) overs,w eh a v e\n/summationdisplay\nsPm+s+n\njj≥/summationdisplay\nsPm\njiPs\niiPn\nij=Pm\njiPn\nij/summationdisplay\nsPs\nii=∞,\nwhere the last step is due to the fact that state iis recurrent.\nSo\n∞/summationdisplay\nt=0Pt\njj≥∞/summationdisplay\nt=m+nPt\njj=∞/summationdisplay\ns=0Pm+n+s\njj =∞.\nTherefore state jis recurrent.\nTheorem 9.13 If state iis transient and icommunicates with j,(i←→j), then j\nis transient.\n9.3inﬁnite-state markov chains 159\nProof This follows directly from the previous Theorem 9.12. Suppose by contradic-\ntion that state jis recurrent. Then because jandicommunicate, iis recurrent as well,\nwhich is a contradiction to the assumption.\nWe have thus seen that in an irreducible Markov chain, either all states are transient,\nor all are recurrent.\nTheorem 9.14 For a transient Markov chain,\nlim\nn→∞Pn\nij=0,∀j.\nProof As we have seen, in a transient Markov chain there is some point after which\nwe never visit state jagain. So the probability of being in state jafternsteps is zero\nasn→∞ . This holds for every state j.\nTheorem 9.15 If for a Markov chain\nπj= lim\nn→∞Pn\nij=0,∀j,\nthen\n∞/summationdisplay\nj=0πj=0\nso the limiting distribution does not exist.\nProof This follows because we are adding a countable number of 0’s, which\nequals 0.\nCorollary 9.16 For a transient Markov chain the limiting distribution does not\nexist.\nProof This follows immediately from Theorems 9.14 and9.15.\nIn situations where the limiting probabilities are all 0, it seems hard to imagine that a\nstationary distribution exists. Theorem 9.17 states that, in agreement with our intuition,\nno stationary distribution exists.\nTheorem 9.17 Given an aperiodic, irreducible chain. Suppose that the limiting\nprobabilities are all zero. That is, πj= lim n→∞Pn\nij=0,∀j. Then the stationary\ndistribution does not exist.\nProof This proof follows very closely the structure of the proof of Theorem 8.8.\nLet/vectorπ/primebe any stationary probability distribution. As usual, /vectorπrepresents the limiting\nprobability distribution. We are given that πj= lim n→∞Pn\nij=0,∀j.\nOur goal is to prove that π/prime\nj=0,∀j. Observe that\nπ/prime\nj=P{X0=j}=P{Xn=j}because π/prime\njis stationary.\n160 ergodicity theory\nSo\nπ/prime\nj=P{Xn=j}\n=∞/summationdisplay\ni=0P{Xn=j|X0=i}·P{X0=i}\n=∞/summationdisplay\ni=0Pn\nijπ/prime\ni\n=M/summationdisplay\ni=0Pn\nijπ/prime\ni+∞/summationdisplay\ni=M+1Pn\nijπ/prime\ni(for any integer M).\nWe now prove that π/prime\njis bounded above by 0. By the previous equation,\nπ/prime\nj≤M/summationdisplay\ni=0Pn\nijπ/prime\ni+∞/summationdisplay\ni=M+1π/prime\ni\nlim\nn→∞π/prime\nj≤lim\nn→∞M/summationdisplay\ni=0Pn\nijπ/prime\ni+ lim\nn→∞∞/summationdisplay\ni=M+1π/prime\ni\nπ/prime\nj≤M/summationdisplay\ni=0πjπ/prime\ni+∞/summationdisplay\ni=M+1π/prime\ni\nπ/prime\nj≤0+∞/summationdisplay\ni=M+1π/prime\ni\nNow taking the limit as M→∞ , the ﬁnal summation becomes zero, so π/prime\nj≤0as\ndesired.\n9.3.2 Inﬁnite Random Walk Example\nConsider the random walk shown in Figure 9.3, where at each step a gambler either\ngains a dollar (with probability p) or loses a dollar (with probability q=1−p).\npppppp\nqqqqqq0 0–1 0 1 –2 2\nFigure 9.3. Random walk.\nBecause all states communicate, it follows from Theorems 9.12 and9.13 that either\nall states are transient or all are recurrent. Hence to determine whether the chain is\nrecurrent or transient, it sufﬁces to look at state 0.\nTo determine whether state 0is transient or recurrent, we invoke Theorem 9.11. Let\nV=∞/summationdisplay\nn=1Pn\n00\n9.3inﬁnite-state markov chains 161\ndenote the expected number of visits to state 0.I fVis ﬁnite, then state 0is transient.\nOtherwise it is recurrent.\nSince one cannot get from 0to0in an odd number of steps, it follows that\nV=∞/summationdisplay\nn=1P2n\n00=∞/summationdisplay\nn=1/parenleftbigg\n2n\nn/parenrightbigg\npnqn(9.9)\nWe now simplify this equation using Lavrov’s lemma.\nLemma 9.18 (due to Misha Lavrov) Forn≥1,\n4n\n2n+1</parenleftbigg\n2n\nn/parenrightbigg\n<4n(9.10)\nProof By simple binomial expansion,\n2n/summationdisplay\nk=0/parenleftbigg\n2n\nk/parenrightbigg\n=( 1+1 )2n=22n=4n\nSince/parenleftBig2n\nn/parenrightBig\nis the largest term in the sum, it follows that it is bigger than the average\nterm,4n/(2n+1 ) . However it is also smaller than the total sum, 4n.\nSubstituting ( 9.10) into ( 9.9), we get that\n∞/summationdisplay\nn=14n\n2n+1pnqn<V <∞/summationdisplay\nn=14npnqn(9.11)\nIf we substitute p=q=1\n2into the left-hand side of ( 9.11), we get that\nV>∞/summationdisplay\nn=14n\n2n+1·1\n4n=∞/summationdisplay\nn=11\n2n+1=∞ (9.12)\nIf instead we assume p/negationslash=qand consider the right-hand side of ( 9.11), we get that\nV<∞/summationdisplay\nn=1(4pq)n<∞ (since 4pq <1) (9.13)\nThus by ( 9.12) and ( 9.13) we see that V=/summationtext∞\nn=1Pn\n00is inﬁnite if and only if p=1\n2.\nSo the chain is recurrent if and only if p=1\n2.\nWe have thus proven Theorem 9.19.\nTheorem 9.19 The random walk shown in Figure 9.3is recurrent only when p=1\n2\nand is transient otherwise.\n162 ergodicity theory\nQuestion: Recall that we deﬁned f0as the probability that the chain ever returns to\nstate0. What do we know about f0for the random walk example?\nAnswer: We know that when p=1\n2, we should have f0=1. However, when p/negationslash=1\n2,\nit should be the case that f0<1.\nLemma 9.20 For the random walk shown in Figure 9.3, in the case where the\nchain is transient with rightward drift ( p>q ), we have that f0=2q<1.\nProof This follows by conditioning. Let fijdenote the probability that we ever get\nto state jgiven that we start in state i. Thus, f00=f0. Then f0=qf−1,0+pf1,0.\nWe will argue two things:\n1.f−1,0=1\n2.f1,0=q\np\nTogether these result in\nf0=qf−1,0+pf1,0=q+p·q\np=2q.\nThatf−1,0=1 should be clear from the fact that the chain has a rightward drift, so\neventually we must get to state 0. It can also be seen by conditioning on the ﬁrst step\nas follows:\nf−1,0=qf−2,0+p=q(f−1,0)2+p\nand observing that f−1,0=1is a solution to the above equation, because q+p=1.\nThe fact that f1,0=q/pcan be seen by conditioning on the ﬁrst step as follows:\nf1,0=q·1+p·f2,0=q+p·(f1,0)2\nand observing that f1,0=q/pis a solution to the above equation, because q+p=1.\n9.3.3 Positive Recurrent versus Null Recurrent\nQuestion: Is knowing that a chain is aperiodic, irreducible, and recurrent enough to\nguarantee the existence of the limiting distribution?\nAnswer: No. What is required is “positive recurrence.”\nDeﬁnition 9.21 Recurrent Markov chains fall into two types: positive recurrent\nandnull recurrent . In a positive-recurrent MC, the mean time between recurrences\n(returning to same state) is ﬁnite. In a null-recurrent MC, the mean time between\nrecurrences is inﬁnite.\nThe following theorem is proven in Exercise 9.16.\nTheorem 9.22 If state iis positive recurrent and i←→j, then jis positive\nrecurrent. If state iis null recurrent and i←→j, thenjis null recurrent.\n9.3inﬁnite-state markov chains 163\nNull-recurrent chains seem like an oxymoron: For a null-recurrent state j, the mean\ntime between visits to state jis∞, and yet state jis visited an inﬁnite number of times.\nAn example of a null-recurrent chain is the random walk shown in Figure 9.3with\np=1\n2. In the previous example we proved that this chain is recurrent. We now\nshow that the mean time between visits to state 0is inﬁnite. Hence state 0is null\nrecurrent, and, since all states communicate, by Theorem 9.22 all states are null\nrecurrent.\nTheorem 9.23 For the symmetric random walk shown in Figure 9.3withp=1\n2,\nthe mean number of time steps between visits to state 0is inﬁnite.\nProof The theorem can be proven in several ways. We present a very short argument\nhere, but illustrate two more proofs in Exercises 9.11 and9.13.3We use the notation\nmi,jto denote the mean number of time steps until we visit state j, given that we are\ncurrently at state i. Our goal is to prove that m00is inﬁnite.\nWe present a proof by contradiction. Assume that m00is ﬁnite. Then it follows that\nm1,0must be ﬁnite as well. This follows from the fact that\nm00=1\n2m1,0+1\n2m−1,0+1.\nHence we cannot have m1,0being inﬁnity.\nNow that we know that m1,0is ﬁnite, we compute it by conditioning on the next state\nm1,0=1+1\n2·0+1\n2m2,0. (9.14)\nNow observe that\nm2,0=2m1,0 (9.15)\nbecause the mean time to go from 2 to 0 is the mean time to go from 2 to 1 plus the\nmean time to go from 1 to 0; and m2,1=m1,0because the chain is location-invariant.\nHence ( 9.14) reduces to\nm1,0=1+1\n2·0+1\n2m2,0\n=1+1\n2·2m1,0(by9.15)\nm1,0=1+ m1,0.\nHowever, this contradicts the fact that m1,0is ﬁnite.\n3The proof here is due to a student in my class, Ameya Velingker.",15355
61-9.4 Ergodic Theorem of Markov Chains.pdf,61-9.4 Ergodic Theorem of Markov Chains,"164 ergodicity theory\n9.4 Ergodic Theorem of Markov Chains\nDeﬁnition 9.24 Anergodic DTMC is one that has all three desirable properties:\naperiodicity, irreducibility, and positive recurrence.4\nRemark: For a ﬁnite-state DTMC, positive recurrence is a consequence of irreducibil-\nity. This fact is proven in Exercise 9.16. Hence, for ﬁnite-state chains, aperiodicity and\nirreducibility sufﬁce for ergodicity.\nThe Ergodic Theorem of Markov Chains (Theorem 9.25) tells us that for any ergodic\nDTMC, the limiting probabilities exist and are positive. Furthermore, for any state i,\nthe limiting probability of being in state iis equal to the reciprocal of the mean time\nbetween visits to state i.\nThe Ergodic Theorem of Markov Chains is saying the same thing that we saw in\nTheorems 9.4and 9.6. However, those theorems were restricted to ﬁnite -state chains.\nThe fact that we now allow for inﬁnite-state chains makes the proof much more\ntechnical, and thus we defer the proof to Section 9.10.\nTheorem 9.25 (Ergodic Theorem of Markov Chains) Given a recurrent, aperi-\nodic, irreducible DTMC, πj= lim n→∞Pn\nijexists and\nπj=1\nmjj,∀j.\nFor a positive recurrent, aperiodic, irreducible DTMC, πj>0,∀j.\nProof Deferred to Section 9.10.\nQuestion: The second sentence in Theorem 9.25 follows immediately from the ﬁrst\none. Why is this?\nAnswer: For a positive-recurrent chain, mjjis ﬁnite, so1\nmjj>0.\nRemark: It may not seem obvious that the πj’s as deﬁned by Theorem 9.25 actually\nsum up to 1, when mjjis ﬁnite. This fact will be proven shortly in Corollary 9.30.\nLet us now consider what Theorem 9.25 says about a null-recurrent Markov\nchain.\n4Note that in some books, ergodicity is deﬁned as the equivalence of the ensemble- and and time-average proba-\nbilities, where the three properties of aperiodicity, irreducibility, and positive recurrence are then consequences\nof this equivalence.\n9.4ergodic theorem of markov chains 165\nTheorem 9.26 For an aperiodic, null-recurrent Markov chain, the limiting prob-\nabilities are all zero and the limiting distribution and stationary distribution do not\nexist.\nProof For a null-recurrent chain, the mean time between visits to each state is inﬁnite\n(mii=∞). Hence, by Theorem 9.25, all the limiting probabilities are zero. Thus, by\nTheorem 9.15, a limiting distribution does not exist, and by Theorem 9.17, neither does\nthe stationary distribution.\nWe now state a single theorem that summarizes all that we have seen so far regardinglimiting distributions and stationary distributions.\nTheorem 9.27 (Summary Theorem) An irreducible, aperiodic DTMC belongs to\noneof the following two classes:\nEither\n(i)All the states are transient, or all are null recurrent. In this case πj=\nlimn→∞Pn\nij=0,∀j, and there does NOT exist a stationary distribution.\nor\n(ii)All states are positive recurrent. Then the limiting distribution /vectorπ=\n(π0,π1,π2,...)exists, and there is a positive probability of being in each\nstate. Here\nπj= lim\nn→∞Pn\nij>0,∀i\nis the limiting probability of being in state j. In this case /vectorπis a stationary\ndistribution, and no other stationary distribution exists. Also, πjis equal to\n1\nmjj, where mjjis the mean number of steps between visits to state j.\nProof We know by Theorems 9.22 and9.13 that transience, null recurrence, and\npositive recurrence are class properties, meaning that in an irreducible Markov chain\nall the states are of the same one type.\nIf all states are transient, then by Theorem 9.14 all the limiting probabilities are zero,\nand by Theorem 9.15, these limiting probabilities add up to 0, so no limiting distribution\nexists.\nIf all states are null recurrent, then by Theorem 9.26 all the limiting probabilities are\nzero, and again by Theorem 9.15, no limiting distribution exists.\nWhenever the limiting probabilities are all zero, it follows by Theorem 9.17 that the\nstationary probabilities are all zero as well, so no stationary distribution exists.\nIf all states are positive recurrent, then by Theorem 9.25, the limiting probabilities are\nall positive and equal to1\nmjj, and by Corollary 9.30 (coming up soon) they sum to 1,\nso the limiting distribution exists. Furthermore, by Theorems 8.6and8.8, the limiting\ndistribution is also equal to the unique stationary distribution.",4324
62-9.5 Time Averages.pdf,62-9.5 Time Averages,"166 ergodicity theory\nImportant Remark :What is nice about this summary theorem is that it tells us\nthat we never have to actually determine whether our DTMC is positive recurrent.\nIt sufﬁces to simply check for irreducibility and aperiodicity and then solve thestationary equations. If these stationary equations yield a distribution, then thatdistribution is also the limiting probability distribution.\nSo life is good when our DTMC is irreducible and aperiodic. One question that youmight be wondering about is what happens when our DTMC is either not irreducibleor is periodic. Can we still solve the stationary equations? If the solution still exists,what does it represent? Section 9.8answers these questions. We see, for example, that\nfor periodic chains, when the solution to the stationary equations exists, it does not\nrepresent the limiting distribution, but rather it represents the long-run time-averagefraction of time spent in each state. Time averages are the topic of our nextsection.\n9.5 Time Averages\nQuestion: Recall that πj= lim n→∞Pn\nijis an ensemble average. How might we deﬁne\npj, the time-average fraction of time spent in state j(i.e., the “long-run” proportion of\ntime spent in state j)?\nAnswer: LetNj(t)be the number of times that the Markov chain enters state jby\ntimet(ttransitions). The time-average fraction of time that the Markov chain spends\nin state jis then\npj= lim\nt→∞Nj(t)\nt=Time-average fraction of time in state j.\nObserve that pjis actually deﬁned as an average over a single sample path, ω.W h a t\nwe would like to say is (i) that this average converges with probability 1 (meaning\nit converges along “almost” all the sample paths), (ii) that it always converges to thesame quantity, and (iii) that this quantity is positive. Theorem 9.28 tells us that when\nthe chain is positive recurrent and irreducible, all these good things happen.\nTheorem 9.28 For a positive recurrent, irreducible Markov chain, with probabil-\nity1,\npj= lim\nt→∞Nj(t)\nt=1\nmjj>0,\nwhere mjjis the (ensemble) mean number of time steps between visits to state j.\nImportantly, the existence of pjdoes notrequire aperiodicity.\nBefore we prove Theorem 9.28, let’s discuss some of its consequences.\n9.5time averages 167\nQuestion: Where have we seen the term1\nmjjbefore?\nAnswer: This is the same expression that was equal to the limiting probability πj; see\nTheorem 9.27(ii). This observation leads to Corollary 9.29.\nCorollary 9.29 For an ergodic DTMC, with probability 1,\npj=πj=1\nmjj\nwhere pj= lim t→∞Nj(t)\ntandπj= lim n→∞Pn\nijandmjjis the (ensemble) mean\nnumber of time steps between visits to state j.\nCorollary 9.30 For an ergodic DTMC, the limiting probabilities sum to 1(i.e.,/summationtext∞\nj=0πj=1).\nProof This is an immediate consequence of the fact that pj=πjfrom Corollary 9.29:\nBecause the pj’s sum up to 1(as the Markov chain must be in some state at every\nmoment of time), it follows that the πj’s must likewise sum up to 1.\nThe remainder of this section is devoted to proving Theorem 9.28. We start with some\npreliminary theorems that we will need to invoke. Theorem 9.31 reviews the Strong\nLaw of Large Numbers (SLLN) from Theorem 5.5.\nTheorem 9.31 (SLLN) LetX1,X2,... be a sequence of independent, identically\ndistributed random variables each with mean E[X].L e tSn=/summationtextn\ni=1Xi. Then with\nprobability 1,\nlim\nn→∞Sn\nn=E[X].\nWith SLLN in hand, we are ready to deﬁne a renewal process.\nDeﬁnition 9.32 Arenewal process is any process for which the times between\nevents are i.i.d. random variables with a distribution F.\nAn example of a renewal process is shown in Figure 9.4. LetN(t)denote the number\nof events by time t. Then, we have the following theorem.\nEvents\ntime\nX2 X3 X1\nFigure 9.4. A renewal process. Xi∼F,f o ra l l i.",3825
63-9.6 Limiting Probabilities Interpreted as Rates.pdf,63-9.6 Limiting Probabilities Interpreted as Rates,"168 ergodicity theory\nTheorem 9.33 (Renewal Theorem) For a renewal process, if E[X]is the mean\ntime between renewals, we have\nlim\nt→∞N(t)\nt=1\nE[X]with probability 1. (9.16)\nProof The basic idea in this proof is to apply SLLN, which gives us the convergence\non all sample paths (w.p.1). Let Snbe the time of the nth event. Then we have, ∀t,\nSN(t)≤t< S N(t)+1\nSN(t)\nN(t)≤t\nN(t)<SN(t)+1\nN(t).\nBut,\nSN(t)\nN(t)=/summationtextN(t)\ni=1Xi\nN(t)−→E[X]ast→∞ w.p.1. (SLLN)\nLikewise,\nSN(t)+1\nN(t)=SN(t)+1\nN(t)+1·N(t)+1\nN(t)−→E[X]ast→∞ w.p.1. (SLLN)\nSo, by the sandwich theorem, we have that\nt\nN(t)−→E[X]w.p.1.\n⇒N(t)\nt−→1\nE[X]ast→∞ w.p.1.\nProof (Theorem 9.28)To prove Theorem 9.28, we simply apply the Renewal theo-\nrem, where we consider each time that the Markov chain enters state jto be a renewal.\nBecause the Markov chain is irreducible, we know that it will eventually reach state\nj. Because the chain is positive recurrent, we know that mjj<∞, where mjjis the\nmean number of steps between visits to state j. From the Renewal theorem we know\npj= lim\nt→∞Nj(t)\nt=1\nmjjw.p.1,\nand since mjj<∞, we have that pj>0.\n9.6 Limiting Probabilities Interpreted as Rates\nSo far we have seen that, for an ergodic Markov chain,\nπi=limiting probability Markov chain is in state i\n=long-run proportion of time process is in state i.\nNow we observe that\nπiPij=“rate” of transitions from state ito state j.\n9.6limiting probabilities interpreted as rates 169\nTo see this, observe that the DTMC is in state iforπifraction of all time steps.\nFurthermore, Pijfraction of those time steps will result in the chain next moving to j.\nHence, for πiPijfraction of all time steps, the DTMC is in state i, and its next step is to\ngo to state j. Thus, if we look over ttime steps (let tbe large), then πiPijttransitions\nwill have their start point in iand their end point in j. Dividing by t, we see that the\nrate of transitions (number of transitions per time step) that have their start point in i\nand their end point in jisπiPij.\nQuestion: What does/summationtext\njπiPijrepresent?\nAnswer: This is the total rate of transitions out of state i, including possibly returning\nright back to state i(if there are self-loops in the chain).\nQuestion: What does/summationtext\njπjPjirepresent?\nAnswer: This is the total rate of transitions into state i, from any state, including\npossibly from state i(if there are self-loops in the chain).\nRecall the stationary equation for state i:\nπi=/summationdisplay\njπjPji\nWe also know that πi=πi/summationtext\njPij=/summationtext\njπiPij.\nThus we have\nπi=/summationdisplay\njπiPij=/summationdisplay\njπjPji. (9.17)\nYet this says that the stationary equations are simply relating the total rate of transitions\nout of state iwith the total rate of transitions into state i:\nTotal rate leaving state i=Total rate entering state i\nQuestion: Why does it make sense that the total rate of transitions leaving state i\nshould equal the total rate of transitions entering state i?\nAnswer: Every time a transition leaves state i, we cannot have another transition leave\nstateiuntil some transition enters state i. Hence the number of transitions leaving state\niis within 1 of the number of transitions entering state i. Now the rate of transitions\nleaving state iis the total number of transitions over a long period of time, t, divided\nby that time t. Since tis large, the difference of 1in the number of transitions leaving\nstateiand the number entering state ivanishes when divided by t, and hence the rates\nare equal.\nWe can also rewrite the stationary equations, equivalently, as follows by ignoring\nself-loops:\n/summationdisplay\nj/negationslash=iπiPij=/summationdisplay\nj/negationslash=iπjPji (9.18)\nEquation ( 9.18) follows by subtracting πiPiifrom both sides of the stationary equa-\ntion ( 9.17). The set of equations ( 9.18) over all states iare often referred to as",3946
64-9.8 When Chains Are Periodic or Not Irreducible.pdf,64-9.8 When Chains Are Periodic or Not Irreducible,"170 ergodicity theory\nbalance equations because they equate the rate that we leave state ito go to a\nstate other than i, with the rate that we enter state ifrom a state other than i.A s\nyou can see, balance equations are mathematically equivalent to stationary equations –\nhence we can always simply ignore the self-loops and write balance equations. Balanceequations can also be applied to a set of states as well as to a single state. For example,if a Markov chain is divided into two sets of states – call these\nSandSc(hereSc\ndenotes the complement of S) – then we can equate the rate of transitions (the “ﬂux”)\nfromStoScwith the rate of transitions from SctoS.\nQuestion: Why does it make sense that the total ﬂux from StoScshould equal that\nfromSctoS?\nAnswer: The argument is identical to what we observed for a single state. Every time\na transition takes us from StoSc, we have left the states in S. We therefore cannot\nhave another transition from StoScuntil we reenter the states in S, but this requires\na transition from SctoS.\n9.7 Time-Reversibility Theorem\nYou might be wondering at this point whether we can simplify the stationary/balance\nequations even further. In some cases we can. The following theorem is useful becauseit simpliﬁes the balance equations. We will revisit time-reversibility later in the book.\nTheorem 9.34 (Time-reversible DTMC) Given an aperiodic, irreducible Markov\nchain, if there exist x1,x2,x3,...s.t.,∀i, j,\n/summationdisplay\nixi=1 andxiPij=xjPji,\nthen\n1.πi=xi(thexi’s are the limiting probabilities).\n2.We say that the Markov chain is time-reversible.\nProof xiPij=xjPji\n⇒/summationdisplay\nixiPij=/summationdisplay\nixjPji\n⇒/summationdisplay\nixiPij=xj/summationdisplay\niPji\n⇒/summationdisplay\nixiPij=xj\nNow, because we also know that/summationtext\nixi=1, we know that the xj’s satisfy the stationary\nequations. Hence, because by Theorem 9.27 the solution to the stationary equations is\nunique, we know that xj=πj, the limiting probability of being in state j.\n9.8when chains are periodic or not irreducible 171\nThis leads to the following simpler algorithm for determining the πj’s:\n1.First try time-reversibility equations (between pairs of states):\nxiPij=xjPji,∀i,jand/summationtext\nixi=1.\n2.If you ﬁnd xi’s that work, that is great! Then we are done: πi=xi.\n3.If not, we need to return to the regular stationary (or balance) equations.\nThe exercises at the end of this chapter help elucidate which chains are time-reversible\nand which are not.\nExample: Three Types of Equations\nConsider the Markov chain depicted in Figure 9.5.\n1–p 0p\nqp\nqpp\nqqr r r\n00 1 2 3\nFigure 9.5. A very familiar Markov chain.\nRegular Stationary Equations:\nπi=πi−1p+πir+πi+1qand/summationdisplay\niπi=1\nThese are messy to solve.\nBalance Equations:\nπi(1−r)=πi−1p+πi+1qand/summationdisplay\niπi=1\nThese are a little nicer, because we are ignoring self-loops, but still messy to solve.\nTime-Reversibility Equations:\nπip=πi+1qand/summationdisplay\niπi=1\nThese are much simpler to solve.\n9.8 When Chains Are Periodic or Not Irreducible\nFrom the Summary Theorem (Theorem 9.27) we know that if a DTMC is both irre-\nducible and aperiodic, and if we can ﬁnd a solution to the stationary equations, then\nthat solution is the unique limiting distribution for the Markov chain. However, what\ncan be said when we have a chain that is not irreducible or is not aperiodic? What does\nthe solution to the stationary equations (or the time-reversibility equations) representin this case? This section answers these questions.\n9.8.1 Periodic Chains\nWe show that analyzing periodic chains is not a problem. Speciﬁcally, we show in\nTheorem 9.36 that for any periodic, irreducible positive-recurrent chain the stationary\n172 ergodicity theory\ndistribution, /vectorπ, still exists. However /vectorπdoes not represent the limiting distribution,\nbut rather the long-run time-average proportion of time spent in each state. We also\nprove a Summary Theorem for irreducible, periodic chains, Theorem 9.37, which is\nreminiscent of the Summary Theorem for irreducible, aperiodic chains (Theorem 9.27).\nTheorem 9.37 states that for an irreducible, periodic chain, if a stationary distribution,\n/vectorπ, exists, then the chain must be positive recurrent; hence, by Theorem 9.36, it follows\nthat/vectorπis also the time-average distribution.\nWe start with a lemma.5\nLemma 9.35 In an irreducible DTMC, all states have the same period.\nProof Suppose states iandjcommunicate, where the period of iispand the period\nofjisq. Since iandjcommunicate, there is a path of length, say, d1, from itojand\nsome path of length, say, d2, from jtoi. Joining these gives a loop from iback to iof\nlength d1+d2. The period, p, is the GCD of all loops, so in particular\np|(d1+d2)\n(i.e.,pdivides (d1+d2)). Now consider any loop from jback to j(note that the loop\nmay or may not contain i). Let’s say that the length of this loop is x. Now take the path\nfromitojof length d1, then follow the loop of length x, then take the path from jto\niof length d2. This entire journey from itoihas length d1+d2+x; hence\np|(d1+d2+x).\nSubtracting the previous two lines, we have that\np|x\nHowever this is true for all loops from jtoj. Therefore, palso divides the GCD of the\nlengths of all these loops. Thus p|q.\nBy a symmetric argument q|p, so it must be the case that p=q.\nTheorem 9.36 In an irreducible, positive-recurrent DTMC with period d<∞,\nthe solution /vectorπto the stationary equations\n/vectorπ·P=/vectorπand/summationdisplay\niπi=1\nexists, is unique, and represents the time-average proportion of time spent in each\nstate.\nThe majority of this section will be devoted to proving Theorem 9.36. We will follow\nthis outline:\n1.We start by ﬁnding a convenient way to label the states of a periodic chain in\nterms of “residue classes.”\n2.We prove that the distribution of time averages is a stationary distribution.\n3.We show that any stationary distribution equals the time-average distribution.\n5The algebraic argument in this section was proposed by PhD students, Sherwin Doroudi and Misha Lavrov.\n9.8when chains are periodic or not irreducible 173\nLabeling the States of Periodic Chains\nImagine a chain where every state has period d.\nQuestion: Pick a state, i. Does state iget visited once every dsteps? If not, can we at\nleast say that there is some positive probability that state iwill be visited every dsteps?\nAnswer: No. Consider a state iwhose period is 2. There may be a path from itoi\nthat takes 4steps and another path that takes 6steps. There is zero probability of going\nfromitoiin2steps, yet the period is 2, as shown in the coloring of Figure 9.6.\ni\nFigure 9.6. Chain has period 2, as illustrated in the alternating coloring of the states.\nWhat isclear is that the time between visits to any state ican never be less than dtime\nsteps. Now every state has period d, and we must be somewhere at each time step,\nand the chain is irreducible (so we eventually get to each state). It follows that we can\npartition the states into d“residue classes,” with names: 0,1,2,...,d−1, where from\na state in class 0, we can only next transition to a state in class 1, from a state in class\n1we can only next transition to a state in class 2,..., and from a state in class d−1\nwe can only next transition to a state in class 0. Every state is in exactly one class and\nthus will be visited at most once every dsteps. For a more mathematically rigorous\ndeﬁnition of residue classes see Exercise 9.15.\nQuestion: Given a chess board and a knight, if the “state” of the knight is the square\nthat it is currently on, how many residue classes do we have?\nAnswer: The knight alternates between black squares and white ones, and every state\ncan return to itself in 2 steps. Hence we have 2 residue classes: 0and1.\nThe ﬁrst step of the proof is to relabel all states based on their residue classes, so that\ntheir names are as follows:\n01,02,03,...,11,12,13,...,21,22,23,...,(d−1)1,(d−1)2,(d−1)3,...\nMore succinctly, we will refer to the states as (/vector0,/vector1,/vector2,...,−−−→d−1).\nQuestion: Once states are relabeled in this way, what is the form of the transition\nmatrixP? Where are its non-zero elements?\nAnswer:\nP=⎡\n⎢⎢⎢⎢⎢⎣/vector0 /vector1 /vector2 ...−−−→d−1\n/vector0 0A 0,1000\n/vector1 00 A 1,200\n/vector2 00 0 A 2,30\n... 00 0 0...\n−−−→d−1Ad−1,00000⎤\n⎥⎥⎥⎥⎥⎦(9.19)\n174 ergodicity theory\nQuestion: What can we say about the matrices Ai,i+1?\nAnswer: These matrices each have rows that sum to 1(they are stochastic ). This\nfollows from the fact that Pis stochastic.\nQuestion: Are all the elements in Ai,i+1positive?\nAnswer: Not necessarily – there may not be a direct connection between every element\nof/vectoriand−−→i+1.\nNow consider the dth power of P.\nQuestion: What does Pdlook like? How can we express it in terms of the Ai,i+1\nmatrices?\nAnswer:\nPd=⎡\n⎢⎢⎢⎢⎢⎣/vector0 /vector1 /vector2 ...−−−→d−1\n/vector0D0,000 0 0\n/vector1 0D 1,100 0\n/vector2 00 D 2,200\n... 000... 0−−−→d−1000 0 D d−1,d−1⎤\n⎥⎥⎥⎥⎥⎦(9.20)\nwhere\nD0,0=A0,1·A1,2·A2,3···Ad−1,0\nD1,1=A1,2·A2,3···Ad−1,0·A0,1\nD2,2=A2,3···Ad−1,0·A0,1·A1,2\nDi,i=Ai,i+1·Ai+1,i+2···Ai−2,i−1·Ai−1,i (9.21)\nQuestion: IsDi,istochastic? What does Di,irepresent? Is it irreducible? aperiodic?\npositive recurrent?\nAnswer: Di,iis stochastic because it is the product of stochastic matrices, see Exer-\ncise 8.2. The matrix represents the probability of moving between each state in /vectorito\neach of the other states in /vectoriindsteps.Di,iis irreducible since Pis irreducible, and all\npaths from states in /vectorito states in /vectorihave length that is a multiple of d. To see that Di,iis\naperiodic, assume not. Then the period of Di,iis at least 2. But this contradicts the fact\nthat all states in /vectorihave period d. Finally, since the original chain is positive recurrent,\nwe know that Di,iis as well.\nShowing that the Time-Average Distribution is a Stationary Distribution\nUsing the above labeling, consider the time-average distribution, /vectorp:\n/vectorp=(p01,p02,p03,...,p 11,p12,p13,...,p (d−1)1,p(d−1)2,p(d−1)3,...)\nwhere\nd−1/summationdisplay\ni=0/summationdisplay\njpij=1\nHerepijrepresents the long-run proportion of time spent in state ij. In shorthand, we\nwill write /vectorp=(p/vector0,p/vector1,...,p −−→d−1).\n9.8when chains are periodic or not irreducible 175\nQuestion: What do we know about/summationtext\njpij?\nAnswer: Since/vectoriis only visited once every dsteps,/summationtext\njpij=1\nd. Let\nq/vectori=d·p/vectori (9.22)\nObserve that/summationtext\njqij=1.\nQuestion: What does q/vectorirepresent? What does it mean in relation to Di,i?\nAnswer: Imagine observing the chain only everydsteps when it hits states in /vectori. Then\nq/vectorirepresents the time-average proportion of time spent in each state of /vectoriduring those\nobservations and Di,irepresents the probability transition matrix, where its (x, y)th\nentry is the probability that from state ixwe will next transition to iy(at the next\nobservation time).\nSinceDi,iis ergodic, it follows that it has a unique stationary distribution, that is equal\nboth to the limiting distribution and the time-average distribution. Thus ∀i,q/vectoriis the\nunique solution to the stationary equations:\nq/vectori·Di,i=q/vectoriand/summationdisplay\njqij=1 (9.23)\nFrom ( 9.23) it is tempting to start thinking about (p/vector0,p/vector1,...,p −−→d−1)being a stationary\ndistribution for D=Pd. However that’s notwhere we want to go! What we want to\nprove is that (p/vector0,p/vector1,...,p −−→d−1)is a stationary distribution for P. To do this, we need\nto get back to the Ai,i+1matrices, rather than the Di,imatrices.\nFrom ( 9.23) and ( 9.21), we have that:\nq/vectori·Ai,i+1=(q/vectoriDi,i)Ai,i+1\n=q/vectori·(Ai,i+1Ai+1,i+2···Ai−1,i)·Ai,i+1\n=(q/vectoriAi,i+1)·(Ai+1,i+2···Ai,i+1)\n=(q/vectoriAi,i+1)·Di+1,i+1 (9.24)\nLet\n/vectorr=q/vectori·Ai,i+1\nQuestion: What do we know about the sum of the elements in /vectorr?\nAnswer: Since the elements of q/vectorisum to 1, and since Ai,i+1is stochastic and thus\npreserves sums of vectors, we have that the sum of elements of /vectorris 1.\nFrom ( 9.24) we thus have that:\n/vectorr=/vectorr·Di+1,i+1and/summationdisplay\njrj=1\nThus/vectorris a stationary distribution for Di+1,i+1.B u tq−−→i+1is the unique stationary\ndistribution for Di+1,i+1.\nHence it follows that:\n/vectorr=q−−→i+1\n⇒q/vectori·Ai,i+1=q−−→i+1\n176 ergodicity theory\n⇒(q/vector0,q/vector1,...,q −−→d−1)·P=(q/vector0,q/vector1,...,q −−→d−1)where/summationdisplay\ni/summationdisplay\njqij=d\n⇒(p/vector0,p/vector1,...,p −−→d−1)·P=(p/vector0,p/vector1,...,p −−→d−1)where/summationdisplay\ni/summationdisplay\njpij=1\nHence we see that /vectorpsatisﬁes the stationary equations for the original chain with\ntransition matrix P.\nShowing That the Solution to the Stationary Distribution Is Unique\nConsider a stationary distribution /vectors=(s/vector0,s/vector1,...,s −−→d−1). We will show that /vectors=/vectorp.\n/vectors·P=/vectorsand/summationdisplay\njsj=1\n⇒/vectors·Pd=/vectors\n⇒/vectors·D=/vectors\n⇒s/vectori·Di,i=s/vectori\nFurthermore,\n/summationdisplay\njsij=1\nd\nsince we only visit states in /vectorionce every dsteps.\nBut by ( 9.23) and ( 9.22),p/vectoriis the unique solution to:\np/vectori·Di,i=p/vectoriand/summationdisplay\njpij=1\nd\nHence\np/vectori=s/vectori,∀i.\nTheorem 9.37 (Summary Theorem for Periodic Chains) Given an irreducible\nDTMC with period d<∞, if a stationary distribution /vectorπexists for the chain, then\nthe chain must be positive recurrent.\nProof The proof uses much of the proof of Theorem 9.36. We partition all states\nintodresidue classes. We denote by /vectorithe states with residue iand denote by π/vectorithose\ncomponents of /vectorπthat correspond to states with residue i.\nWe deﬁne Di,ias in this section. Via the same arguments as used in this section, we\ncan argue that Di,iis irreducible and aperiodic. (However we don’t know that Di,iis\npositive recurrent.)\nSince/vectorπis stationary, we have that\n/vectorπ·P=/vectorπ.\nIt therefore follows that\n/vectorπ·Pd=/vectorπ.",14222
65-9.10 Proof of Ergodic Theorem of Markov Chains.pdf,65-9.10 Proof of Ergodic Theorem of Markov Chains,"9.9conclusion 177\nLooking at ( 9.20), we see that, ∀i,\nπ/vectori·Di,i=π/vectori.\nWe can now conclude that we have a stationary solution to Di,i, once we multiply π/vectori\nby some appropriate normalizing constant to make sure its probabilities sum to 1.\nAt this point, we have shown that Di,iis aperiodic and irreducible and has a stationary\nsolution. Thus, from Theorem 9.27, it follows that Di,imust be positive recurrent, for\neveryi. But now, since all the Di,i’s are positive recurrent, it must be the case that the\noriginal Markov chain was positive recurrent as well.\n9.8.2 Chains that Are Not Irreducible\nGiven an aperiodic, positive-recurrent chain that is notirreducible, there is still a notion\nof “limiting probabilities.” However two things are no longer true: First, it is no longer\nthe case that the limiting probability of being in state jis necessarily independent\nof the starting state i. Thus, we can’t deﬁne πj= lim n→∞Pn\nij, independent of i,\nas in Theorem 9.27. Second, it is no longer the case that the limiting probability of\nevery state jis positive, as we had in Theorem 9.27, since some states may not be\nreachable, or there may be an “absorbing” state (or states), from which one neverleaves. While the entire chain is not irreducible, the chain can still be subdivided into\nirreducible components (sometimes individual states), where an irreducible component\nmay function as its own ergodic chain. In Section 10.1.2 , we consider some examples\nof chains that are not irreducible and illustrate the above points.\n9.9 Conclusion\nWhat you should take away from this chapter is that, given ergodicity, there are\nmany equivalent representations of limiting probabilities. We can think of the limitingprobability of being in state\njas either the average fraction of time spent in state j, the\nstationary probability of being in state j, the reciprocal of the mean time between visits\nto state j, or even the rate of transitions out of state j. Depending on the occasion,\nyou may ﬁnd it preferable to use one representation over another. Figure 9.7illustrates\nsome of these equivalences.\nReciprocal of time \nbetween visits\n           πj = 1\nmjjStationary probability \nfor state j \n             πj iPij Limitin g probability of \nbein g in state j\n πj = lim Pijn→∞n \nTime−avera ge fraction of \ntime spent in state j\n         πj = lim          = pj    Nj(t)\nt t→∞i\nFigure 9.7. Equivalent representations of limiting probabilities.\n178 ergodicity theory\nYou should also take away the fact that there are many techniques for determining\nthe limiting probabilities, including raising the probability transition matrix Pto high\npowers, solving stationary equations (or equivalently balance equations), or trying to\nsolve time-reversibility equations. Although some techniques are simple (e.g., solvingtime-reversibility equations), they will not always work.\n9.10 Proof of Ergodic Theorem of Markov Chains∗\nThis section is devoted to proving Theorem 9.25, adapting material in Karlin and Taylor\n[105], (Ch. 4).\nOur goal is to show that the sequence {Pn\nii,n=1,2,3,...}converges to1\nmii.O u r\nplan is to deﬁne an upper and lower bound on the sequence of Pn\niiand then show that\nour upper and lower bounds are actually the same, both equaling1\nmii.\nWe begin with the following deﬁnition:\nDeﬁnition 9.38 Deﬁne fk\niito be the probability of ﬁrst returning to state iafter the\nkth transition, where we deﬁne f0\niito be zero. Deﬁne Pkiito represent the probability\nof being in state iafter the kth transition, given that we started in state i, where we\ndeﬁne P0\nii=1. Finally, we deﬁne\nmii=E[Number time steps to return to state i]=∞/summationdisplay\nk=0kfk\nii\nwhich follows by conditioning on the time of the ﬁrst return to state i.\nWe now review deﬁnitions of limsup andliminf and present several preliminary\nlemmas on the limiting behavior of Pn\nii. We then express Theorem 9.25 more precisely\nas Theorem 9.43. Finally, we prove Theorem 9.43.\nDeﬁnition 9.39 Consider a sequence {an}.\n1.We say lim\nn→∞an=bif∀/epsilon1>0,∃n0(/epsilon1)s.t.|an−b|</epsilon1,∀n≥n0(/epsilon1).\n2.We say limsup\nn→∞an=bif∀/epsilon1>0,∃n0(/epsilon1)s.t.,∀n≥n0(/epsilon1),\n(a)an<b+/epsilon1, and\n(b)bis the smallest value for which the above is true.\n3.We say liminf\nn→∞an=bif∀/epsilon1>0,∃n0(/epsilon1)s.t.,∀n≥n0(/epsilon1),\n(a)an>b−/epsilon1, and\n(b)bis the largest value for which the above is true.\nThe following are three immediate consequences of the deﬁnition of limsup . Similar\nconsequences exist for liminf .\n∗This section can be skipped without disturbing the ﬂow of the book.\n9.10 proof of ergodic theorem of markov chains 179\nLemma 9.40 Fromlimsup\nn→∞an=bit follows that\n1.∀/epsilon1>0, the sequence {an}exceeds the value b−/epsilon1inﬁnitely many times.\n2.There exists an inﬁnite subsequence of {an}, denoted by {anj}where\nn1<n 2<n 3<... ,s . t .limj→∞anj=b.\n3.If there is an inﬁnite subsequence of {am}, denoted by {amj}where\nm1<m 2<m 3<... , and if limj→∞amj/negationslash=b(or does not exist), then\nthere exists b/prime<bsuch that there are an inﬁnite number of elements of {amj}\nthat are below b/prime.\nProof\n1.This follows from the fact that there cannot be a “last time” that {an}exceeds\nb−/epsilon1; otherwise b−/epsilon1would be the limsup , rather than b.\n2.We need to show that for any /epsilon1, there is some point on the subsequence after which\nall elements are in the range of b±/epsilon1. We deﬁne our subsequence to meet these\nrequirements as follows: First, by the deﬁnition of limsup , we know that there\nis some n0s.t.∀n>n 0,w eh a v e an<b+/epsilon1. Furthermore by (1.), we know\nthat there are inﬁnitely many elements of {an}withn>n 0, where an>b−/epsilon1.\nWe now consider all those elements as our subsequence, S. If we now pick a\nsmaller /epsilon1/prime, we can just look further out in Sto a point where again all elements\nare less than b+/epsilon1/prime, while still being assured that by (1.) there will be an inﬁnite\nsubsequence of {an}exceeding b−/epsilon1/primeand also contained within S.\n3.Suppose that the subsequence {amj}has a limit, but that limit is not b. Let that\nlimit be b/prime/prime. We know that b/prime/prime<b. Then deﬁne b/primeto lie between b/prime/primeandb.B y\nthe fact that limj→∞{amj}=b/prime/prime, we know that it has an inﬁnite number of\nelements less than b/prime. Now suppose that the subsequence {amj}does not have a\nlimit. In this case, there exists some /epsilon1such that there is no point after which all\nthe elements of {amj}are above b−/epsilon1. Thus, if we deﬁne b/prime=b−/epsilon1, then we\nknow that at any point there is always “yet another” element of {amj}that lies\nbelow b/prime, and hence there are an inﬁnite number of elements of {amj}below b/prime.\nLemma 9.41 Given a recurrent Markov chain, let/braceleftbig\nfk\nii/bracerightbig\nand/braceleftbig\nPk\nii/bracerightbig\nbe the se-\nquences speciﬁed in Deﬁnition 9.38.L e tλ≡limsup\nk→∞Pk\nii. By Lemma 9.40.2 there\nexists a subsequence {Pnj\nii},n1<n 2<... , for which lim\nj→∞Pnj\nii=λ. Given a\nc>0such that fc\nii>0, then\nlim\nj→∞Pnj−c·d\nii =λfor all integers d≥0.\n180 ergodicity theory\nLemma 9.42 Given a recurrent Markov chain, let μ≡liminf\nk→∞Pk\nii. By the ana-\nlogue of Lemma 9.40.2 there exists a subsequence {Pmj\nii},m1<m 2<... , for\nwhich lim\nj→∞Pmj\nii=μ. Given a c>0such that fc\nii>0, then\nlim\nj→∞Pmj−c·d\nii =μfor all integers d≥0.\nWe now present a proof of Lemma 9.41. The proof of Lemma 9.42 follows via a very\nsimilar argument.\nProof (Lemma 9.41)We ﬁrst prove that lim\nj→∞Pnj−c\nii=λ, by using the given condition\nfc\nii>0. Only at the very end of the proof do we consider d.\nSuppose, to the contrary, that lim\nj→∞Pnj−c\nii/negationslash=λ. Then it follows by Lemma 9.40.3 that\nthere exists λ/prime<λ such that Pnj−c\nii<λ/primefor an inﬁnite number of j.\nLet/epsilon1=[fc\nii(λ−λ/prime)]/3. We determine Nsuch that\n∞/summationdisplay\nk=Nfk\nii</epsilon1 . (9.25)\n(We know that/summationtext∞\nk=0fk\nii=1, so we are simply looking at the tail of this distribution.)\nLetjbe chosen so large that nj≥Nand\nPnj\nii>λ−/epsilon1/parenleftbigg\npossible because lim\nj→∞Pnj\nii=λ/parenrightbigg\n, (9.26)\nPnj−c\nii<λ/prime<λ (determination of λ/prime), (9.27)\nPn\nii<λ+/epsilon1∀n≥nj−N (Deﬁnition 9.39.2a). (9.28)\nBy conditioning on the time of ﬁrst return, we get the following equation:\nPn\nii=n/summationdisplay\nk=0fk\niiPn−k\nii∀n>0 (9.29)\nThen,\nPnj\nii=nj/summationdisplay\nk=0fk\niiPnj−k\nii (by9.29)\n≤N/summationdisplay\nk=0fk\niiPnj−k\nii+nj/summationdisplay\nk=N+1fk\nii/parenleftbig\nbecause Pk\nii≤1/parenrightbig\n<N/summationdisplay\nk=0fk\niiPnj−k\nii+/epsilon1(by9.25)\n9.10 proof of ergodic theorem of markov chains 181\n=N/summationdisplay\nk=0,k/negationslash=cfk\niiPnj−k\nii+fc\niiPnj−c\nii+/epsilon1\n<N/summationdisplay\nk=0,k/negationslash=cfk\nii(λ+/epsilon1)+fc\niiλ/prime+/epsilon1\n(Pnj−k\nii<λ+/epsilon1by9.28; andPnj−c\nii<λ/primeby9.27 )\n=/parenleftBiggN/summationdisplay\nk=0fk\nii−fc\nii/parenrightBigg\n(λ+/epsilon1)+fc\nii·λ/prime+/epsilon1\n≤(1−fc\nii)(λ+/epsilon1)+fc\niiλ/prime+/epsilon1\n=λ+2/epsilon1−fc\nii(λ+/epsilon1−λ/prime)\n<λ+2/epsilon1−fc\nii(λ−λ/prime)\n=λ−/epsilon1(by deﬁnition of /epsilon1and the fact that fc\nii>0)\nThus,Pnj\nii<λ−/epsilon1. Yet this contradicts ( 9.26), and so lim\nj→∞Pnj−c\nii=λ.\nBy induction, we ﬁnd that, for any integer d≥0,\nlim\nj→∞Pnj−c·d\nii =λ. (9.30)\nTheorem 9.43 Given a recurrent, aperiodic Markov chain, let/braceleftbig\nfk\nii/bracerightbig\nand/braceleftbig\nPk\nii/bracerightbig\nbe the sequences speciﬁed in Deﬁnition 9.38. Then lim\nn→∞Pn\niiexists, and\nlim\nn→∞Pn\nii=1/summationtext∞\nk=0kfk\nii≡1\nmii.\nProof Let\nrn=fn+1\nii+fn+2\nii+···=P{Time to return to iexceeds n}.\nObserve mii=E[Time to return to i]=/summationtext∞\nk=0kfk\nii=/summationtext∞n=0rn.\nConsider the quantity\nn/summationdisplay\nk=0rkPn−k\nii=n/summationdisplay\nk=0rn−kPk\nii\nQuestion: What is the value of this sum?\nAnswer: This sum equals 1, for all n. To see this, suppose that we start in state iat\ntime0. We now ask, “What is the last time we visit state ibefore time n?” Observe that\nthis could be any time step between 0andn, inclusive. There certainly must exist some\nlast time, because we are already in state iat time 0. The quantity Pk\niirn−krepresents\nthe probability that the last time that we visited state iup to and including time nwas\n182 ergodicity theory\nat time k. We now sum Pk\niirn−kfromk=0tok=n, representing the full domain of\nthe probability distribution; hence,\nn/summationdisplay\nk=0rkPn−k\nii=n/summationdisplay\nk=0rn−kPk\nii=1. (9.31)\nWe would like to take the limit on relation ( 9.31) in such a way that Pn−k\niican be moved\nout of the sum as a constant. We will look for subsequences of Pn\niifor relatively large\nnwhere we can do this by looking at partial sums of Equation ( 9.31), and exploiting\nLemmas 9.41 and9.42.\nLet\nλ= limsup\nn→∞Pn\nii.\nμ= liminf\nn→∞Pn\nii.\nClearly μ≤λ. We will show that μ≥λ. This will establish that πi= lim\nn→∞Pn\nii=\nλ=μ.\nLetn1<n 2<... denote the indices of a subsequence of {Pn\nii}for which lim\nj→∞Pnj\nii=\nλ. This subsequence must exist by Lemma 9.40.2. Likewise, let m1<m 2<... de-\nnote the indices of a subsequence of {Pm\nii}for which lim\nj→∞Pmj\nii=μ. This subsequence\nmust exist by the analogue to Lemma 9.40.2.\nUsing Equation ( 9.31), and because rn≥0and0≤Pn\nii≤1for all n, we obtain, for\nany ﬁnite Mand ﬁxed jsuch that nj,mj>N+M>0,\nnj−M/summationdisplay\nk=0rkPnj−M−k\nii=1=mj−M/summationdisplay\nk=0rkPmj−M−k\nii\nN/summationdisplay\nk=0rkPnj−M−k\nii+nj−M/summationdisplay\nk=N+1rk·0≤1≤N/summationdisplay\nk=0rkPmj−M−k\nii+mj−M/summationdisplay\nk=N+1rk·1.(9.32)\nTo take the limits with the desired effect, we apply Lemmas 9.41 and9.42 and ﬁnd that,\niff1\nii>0, then lim\nj→∞Pnj−M−k\nii =λandlim\nj→∞Pmj−M−k\nii =μ, where M=0. We will\nshortly argue that even if f1\nii=0, so long as the chain is aperiodic we can ﬁx ﬁnite\nM>0and still apply Lemmas 9.41 and9.42.\nEvaluating the inequality chain in Equation ( 9.32)ﬁ r s ta s j→∞ and then as N→∞\ngives\nλN/summationdisplay\nk=0rk≤ 1≤μN/summationdisplay\nk=0rk+∞/summationdisplay\nk=N+1rk(asj→∞ )\nλ∞/summationdisplay\nk=0rk≤ 1≤ μ∞/summationdisplay\nk=0rk (asN→∞ )\nλ≤1/summationtext∞\nk=0rk≤ μ.",12419
66-9.11 Exercises.pdf,66-9.11 Exercises,"9.11 exercises 183\nYet, by deﬁnition of limsup andliminf ,μ≤λ. Thus μ=λ, which means that\nlim\nn→∞Pn\niiexists and its value is\nπi= lim\nn→∞Pn\nii=1/summationtext∞\nk=0rk=1/summationtext∞k=0kfk\nii(9.33)\nWe now consider the remaining case: f1\nii=0. However, because the chain is aperiodic,\nthe greatest common divisor of those cfor which fc\nii>0is 1.\nConsider the set of {ci}such that fci\nii>0, where we know, by aperiodicity, that the\ngreatest common divisor of the {ci}is 1. Now consider any linear combination of the\nci’s:p=/summationtext\nicidi, where di>0. Then we can show by induction on Lemmas 9.41\nand9.42 that\nlim\nj→∞Pnj−p\nii=λand lim\nj→∞Pmj−p\nii=μ.\nApplying the Euclidean number property, we know that there exists an Mwhere any\nn>M can be expressed as a positive linear combination of a set of {ci}whose\ngreatest common divisor is 1.\nTherefore, there exists a sufﬁciently large Msuch that\nlim\nj→∞Pnj−M−d\nii =λand lim\nj→∞Pmj−M−d\nii =μ,∀integers d≥0.\nAt this point we have proved our theorem when πj= lim n→∞Pn\njj.W en o wi n v o k e\nthe irreducibility assumption, which allows us to reach state jfrom any initial state i,\nhence completing the proof of the theorem.\n9.11 Exercises\n9.1 Irreducibility, Aperiodicity, and Positive Recurrence\nFor each of the following transition matrices, state whether the chain is (i)\nirreducible, (ii) aperiodic, or (iii) positive recurrent. [Note: If the period is not\ndeﬁned, then the chain is notaperiodic.]\n(a)⎛\n⎝1\n41\n41\n2\n001\n100⎞\n⎠ (b)⎛⎝010\n010100⎞\n⎠\n(c)⎛⎝1\n302\n31\n43\n40\n001⎞⎠\n9.2 Practice with Balance Equations and Time-Reversibility Equations\nConsider the following Markov chains:\nP(1)=⎛\n⎜⎜⎝02/301 /3\n1/302 /30\n01/302 /3\n2/301 /30⎞\n⎟⎟⎠\nP(2)=⎛\n⎜⎜⎝1/32/30 0\n1/302 /30\n01/302 /3\n00 1 /32/3⎞\n⎟⎟⎠\n(a) Draw the corresponding Markov chains for P(1)andP(2).\n184 ergodicity theory\n(b) Solve for the time-average fraction of time spent in each state for both P(1)\nandP(2). First try to use the time-reversibility equations, and if they do not\nwork, then use the balance equations.\n(c) Was P(1)time-reversible? Was P(2)time-reversible?\n(d) For those chain(s) that were time-reversible, explain why it makes sense\nthat for all states i,jin the chain, the rate of transitions from itojshould\nequal the rate of transitions from jtoi.\n9.3 Data Centers, Backhoes, and Bugs\nData centers alternate between “working” and “down.” There are many reasonswhy data centers can be down, but for the purpose of this problem we mentiononly two reasons: (i) a backhoe accidentally dug up some cable, or (ii) a software\nbug crashed the machines. Suppose that a data center that is working today will\nbe down tomorrow due to backhoe reasons with probability\n1\n6, but will be down\ntomorrow due to a software bug with probability1\n4. A data center that is down to-\nday due to backhoe reasons will be up tomorrow with probability 1. A data center\nthat is down today due to a software bug will be up tomorrow with probability3\n4.\n(a) Draw a DTMC for this problem.\n(b) Is your DTMC ergodic? Why or why not?\n(c) Is your DTMC time-reversible? Why or why not?\n(d) What fraction of time is the data center working?\n(e) What is the expected number of days between backhoe failures?\n9.4 Ergodicity Summary\nY o ua r eg i v e na n aperiodic ,irreducible DTMC, with n>1states.\nPut a check mark in ALL boxes that are valid (possible). Note that some rows\nmay be empty, whereas others may have multiple check marks. (We startedyou off by ﬁlling in some boxes.)\nChain is Chain is Chain is\nPositive Recurrent Transient Null Recurrent\nfj=1√\nfj=0\n0<fj<1\nmjj=∞\nmjj<∞√\n/summationtext∞\nn=0Pn\njj=∞\n/summationtext∞\nn=0Pn\njj<∞\n0<π j<1\nπj=0\nπj=1\nπj<0\nGlossary:\nmjj=mean number of steps to return to jgiven we’re in state j\nPn\nii=probability that the chain is in state iinnsteps given the chain is currently\nin state i\nfj=probability that a chain starting in state jever returns to state j\nπj=limiting probability of being in state j\n9.11 exercises 185\nWarning: Read the directions carefully! Every word is meaningful.\n9.5 Time between Visits\nGiven an ergodic DTMC, let mijdenote the mean number of steps to get from\nstateito state j. Sherwin makes the following conjecture:\nmjj≤mji+mij (9.34)\nEither prove or disprove Sherwin’s conjecture.\n9.6 Pricing Model\nYou are the market maker for GOGO. You have no clue whether GOGO stock\nwill rise or fall, but you are obligated to buy or sell single shares from customersat all times. However, you do get to set the share price.\nTo control the size of your position (number of shares of GOGO you own),\nwhen you are long (i.e., own) GOGO, you set the price so that with probability\np<1\n2, your next trade is a buy, and with probability q=1−pyour next trade\nis a sell. In contrast, if you are short (i.e., owe) GOGO, you set the price so that\nwith probability p, your next trade is a sell, and with probability qyour next\ntrade is a buy.\nYour position is represented by the bidirectional chain in Figure 9.8, with a\nnegative state indicating how many shares you owe and a positive state indicating\nhow many shares you own.\nqqq 0.5 pp\npp 0.5 qqq0 0–1 0 1 –2 2\nFigure 9.8. Bidirectional chain for pricing.\n(a) Given this pricing, what does your position tend to revert to?\n(b) Derive the time-average fraction of time spent in each state.\n(c) Why weren’t you asked to ﬁnd the limiting probabilities?\n(d) What is the expected (absolute value) size of your position?\n9.7 Expected Time until k Failures\nThis is a repeat of Exercise 3.25, where we want to derive the expected number\nof minutes until there are kconsecutive failures in a row, assuming that a failure\noccurs independently every minute with probability p. However this time, the\nproblem should be solved by ﬁnding the limiting probability of some Markov\nchain. Please include a picture of your Markov chain. [Hint: You will have to\nthink a bit to see how to convert from the limiting probabilities of the DTMC\nto what you really want.]\n9.8 Walks on Undirected Weighted Graphs\nThis problem comes up in many areas. Consider any undirected graph withweights, where\nwij=wjiis the weight on edge (i, j). Consider a particle that\nmoves from node to node in the graph in the following manner: A particle\nresiding at node iwill next move to node jwith probability Pijwhere\nPij=wij\nΣjwij.\n186 ergodicity theory\n(Draw a picture to help yourself visualize this.) What is the long-run proportion\nof time that the particle is in state i? [Hint: To answer this question, it will help\nto write out the time-reversibility equations, rather than the stationary equations.\nYou will need to guess a solution to these equations.]\n9.9 Randomized Chess\nThis problem concerns the behavior of various chess pieces as they move\nrandomly around the board. If you are not familiar with chess, all you need toknow for this problem is the following. The game is played on a board divided\ninto 64 squares (\n8×8) that alternate from white to black. There are many\ndifferent types of pieces that each move in a different way. The three pieces in\nthis exercise are the king, bishop, and knight. The king can move one square\nin any direction (including the diagonal). The bishop can move any number\nof squares, but only in the diagonal directions. Finally, the knight moves in anL-shape. That is, the knight moves two squares to either side (left or right) andone square up or down. Or, the knight can move two squares up or down andone square to the side (left or right).\n(a) You are given an empty\n8×8chessboard with a lone king placed in one\ncorner. At each time step, the king will make a uniformly random legal\nmove. Is the corresponding Markov chain for this process (i) irreducible?\n(ii) aperiodic?\n(b) What if a bishop is used instead?\n(c) What if a knight is used instead?\n(d) Now take advantage of Exercise 9.8on undirected weighted graphs and\ntime-reversibility to calculate the expected time for the king to return to\nthe corner. Think about how hard this would be without time-reversibility.[Hint: the calculation should be very simple.]\n(e) Do the same for the bishop.\n(f) Do the same for the knight.\n9.10 Threshold Queue Revisited\nIn Exercise 8.6, we deﬁned a threshold queue, depicted by the chain in Figure 9.9.\n(a) Argue that the Markov chain is aperiodic and irreducible.\n(b) Argue that the Markov chain is positive recurrent.\n0.4\n0.60.4 0.4\n0.6 0.6q0.6\n0.40.60.2\n0.40 0.4 4 2 3 5 1\nFigure 9.9. Threshold chain where threshold point is T=3.\n9.11 Symmetric Random Walk\n[Proposed by PhD student, Srivatsan Narayanan] This problem presents a com-\nbinatorial proof of Theorem 9.23 that uses Catalan numbers. Given the sym-\nmetric random walk shown in Figure 9.10, we know that, if we start at state 0,\nthen, with probability 1, we will return to state 0. Prove that m00=∞, where\nm00denotes the mean time between visits to state 0.\n9.11 exercises 187\n½½½½½\n½½½½½½½\n0 0–1 0 1 –2 2\nFigure 9.10. Symmetric random walk.\n(a) Let T00be a random variable denoting the time of the ﬁrstreturn to state 0.\nIf we knew the probability mass function for T00, how would we use that to\ngetm00?\n(b) Assume WLOG that the ﬁrst step is to the right (from 0 to 1). Then the last\nstep before returning to state 0 must be to the left (from 1 to 0). If T00=n,\nhow can we characterize the middle n−2steps?\n(c) The Catalan number C(k)represents the number of strings of length 2k\nsuch that there are k0’s and k1’s, such that no preﬁx of the strings contains\nmore 0’s than 1’s. Express P{T00=n}in terms of an expression involving\na Catalan number. It may help to start by observing that P{T00=n}=\nP{T00=n|First step is right }.\n(d) It is well known that\nC(k)=1\nk+1/parenleftbigg\n2k\nk/parenrightbigg\n.\nUse this fact and Lemma 9.18 to derive a lower bound on P{T00=n}.\nThen use that lower bound in (a) to show that m00=∞.\n9.12 Stopping Times and Wald’s Equation\nA positive integer-valued random variable Nis said to be a stopping time for\na sequence: X1,X2,X3,...if the event {N=n}is independent of Xn+1,\nXn+2,...That is, the stopping time, N, can depend on everything seen so far,\nbut not on the future.\n(a) Consider a sequence of coin ﬂips. Let Ndenote the time until we see 5 heads\ntotal. Is Na stopping time? How about the time until we see 5 consecutive\nheads?\n(b) Consider a gambler who starts with zero dollars and in each game is equally\nlikely to win a dollar or lose a dollar. Let Xidenote the result of the ith game.\nThe gambler stops whenever he is 2 dollars ahead. Let Nbe the stopping\ntime in terms of number of games. Write a mathematical expression for N,\ninvolving a sum.\n(c) Let Xibe i.i.d. random variables, and let Ydenote a positive integer-valued\nrandom variable that is independent of the Xi’s. What do we know about\nE/bracketleftBig/summationtextY\ni=1Xi/bracketrightBig\n?\n(d) Let Xibe i.i.d. random variables with ﬁnite mean. Let Nbe a stopping\ntime for the sequence X1,X2,X3,...Assume E[N]<∞. Then Wald’s\nequation says that\nE/bracketleftBiggN/summationdisplay\ni=1Xi/bracketrightBigg\n=E[N]E[X]. (9.35)\n188 ergodicity theory\nImportantly, Nisnotindependent of the Xi’s. Prove Wald’s equation. [Hint:\n(i) It may help to deﬁne an indicator random variable In=1 if and only\nifN≥nand then consider the product XnIn. (ii) The fact that the Xi’s\nhave ﬁnite mean will allow you to move an expectation into an inﬁnite\nsummation.]\n9.13 Another Derivation of the Symmetric Random Walk\nWu suggests a different proof of Theorem 9.23 based on Wald’s equation ( 9.35).\nGiven the symmetric random walk shown in Figure 9.11, we know that, because\nthe chain is recurrent, if we start at any state, then with probability 1we will\nreturn to that state. Our goal is to prove that m11=∞, where m11denotes the\nmean time between visits to state 1.\n½½½½½\n½½½½½½½\n0 0–1 0 1 –2 2\nFigure 9.11. Symmetric random walk.\n(a) Prove that m11>0.5m01. It thus sufﬁces to show that m01=∞.\n(b) Let T01denote the time until we ﬁrst hit state 1, given that we start at state\n0. Note that T01is well deﬁned because the symmetric random walk is\nrecurrent. Explain why T01is a stopping time.\n(c) IfXnis the state at time step n, what is XT01?\n(d) Express XT01as a sum of i.i.d. r.v.’s. Assuming that E[T01]is ﬁnite, show\nthat Wald’s equation leads to a contradiction. Hence m01=E[T01]=∞.\n9.14 Recurrent versus Transient\nThis problem involves the DTMC shown in Figure 9.12. Assume throughout\nthis problem that q=1−p.\np\nqpp\nqqqp\nqp\nq0 q 3 1 2 4 0\nFigure 9.12. Markov chain for Exercise 9.14.\n(a) For what values of pis this chain recurrent? For what values of pis it\ntransient? Give an argument for each case based on the expected number\nof visits to each state. You might choose to compute/summationtext\nnPn\n00or to leverage\nany of the other ideas and arguments from this chapter.\n(b) In the case where the chain is transient, compute\nf0=P{Ever return to state 0given start there }\nas a function of p.\n(c) Assume that p<q . LetT00denote the time to go from state 0to state 0.\nDeriveE[T00]. What does this tell us about π0= lim n→∞Pn\n00?\n9.11 exercises 189\n(d) Assume p<q . Use the stationary equations to derive all the limiting prob-\nabilities.\n(e) Again assume p<q . Is the chain time reversible? Why or why not?\n9.15 Residue Classes in Periodic Chains\nIn Section 9.8, we partitioned the states of an irreducible DTMC with period\ndinto “residue classes.” This problem deﬁnes residue classes more rigorously.\nLetibe an arbitrary state. Deﬁne ito have residue class 0. For every other state\nj, deﬁne its residue class as the length of any path from itoj, taken modulo d\n(by irreducibility, there exists at least one such path).\n(a) Show that the notion of residue classes is well-deﬁned, by proving that the\nlengths of any two paths from itojare equivalent modulo d.\n(b) Prove that from a state in residue class kwe can only go to a state in residue\nclassk+1.\n9.16 Finite-State DTMCs\n(a) Prove the following theorem:\nTheorem: For a ﬁnite state, irreducible DTMC, all states are positive\nrecurrent.\nIn your proof, you may make use of the following two class properties,\nwhich are proved in (b):\nrTheorem: Null recurrence is a class property (i.e., if i: null recurrent and\nicommunicates with jthenj: null recurrent).\nrTheorem: Positive recurrence is a class property (i.e., if i: positive recur-\nrent and icommunicates with jthenj: positive recurrent).\n(b) Prove the preceding two class property theorems. Your proof should work\nfor inﬁnite-state Markov chains as well.",14712
67-Chapter 10 Real-World Examples Google Aloha and Harder Chains.pdf,67-Chapter 10 Real-World Examples Google Aloha and Harder Chains,,0
68-10.1 Googles PageRank Algorithm.pdf,68-10.1 Googles PageRank Algorithm,"CHAPTER 10\nReal-World Examples: Google,\nAloha, and Harder Chains∗\nThis chapter discusses applications of DTMCs in the real world. Section 10.1 describes\nGoogle’s PageRank algorithm, and Section 10.2 analyzes the Aloha Ethernet protocol.\nBoth problems are presented from the perspective of open-ended research problems, so\nthat they serve as a lesson in modeling. Both are also good examples of ergodicity issuesthat come up in real-world problems. Finally, in Section 10.3, we consider DTMCs\nthat arise frequently in practice but for which it is difﬁcult to “guess a solution” for thelimiting probabilities. We illustrate how generating functions can be used to ﬁnd thesolution for such chains.\n10.1 Google’s PageRank Algorithm\n10.1.1 Google’s DTMC Algorithm\nMost of you probably cannot remember a search engine before google.com. When\nGoogle came on the scene, it quickly wiped out all prior search engines. The featurethat makes Google so good is not the web pages that it ﬁnds, but the order in which it\nranks them.\nConsider a search on some term; for example, “koala bears.” Thousands of web pages\ninclude the phrase “koala bears,” ranging from the San Diego zoo koala bear homepage, to anecdotes on the mating preferences of Australian lesbian koala bears, to a\nkoala bear chair. The value of a good search engine is to rank these pages so that thepage we need will most likely fall within the “top 10,” thus enabling us to quicklyﬁnd our information. Of course, how can a search engine know exactly which of thethousand pages will be most relevant to us?\nA common solution is to rank the pages in order of the number of links to that page\n(often called backlinks of the page), starting with the page that has the highest number\nof pointers into it. We refer to this strategy as citation counting .\nCitation counting is a very commonly used measure of importance. For example, many\ntenure decisions are determined not by your number of publications, but by the numberof citations to your publications.\nQuestion: Suppose that we could determine the number of backlinks of each page\n(number of links pointing to the page). Why would that notnecessarily be a good\nmeasure of the importance of the page?\n∗This chapter can be skipped without disturbing the ﬂow of the book.\n190\n10.1 google’s pagerank algorithm 191\nAnswer:\n1.Not all links are equal. If a page has a link to it from the Yahoo web page, that\nlink should be counted much more than if a page has a link to it from Joe Schmo’sweb page.\n2.The citation counting scheme is easily tricked. Suppose I want my web page to\nhave a high rank. I simply create a thousand pages that each point to my webpage. Now my web page has a thousand pointers into it, so it should be rankedhighly. (Hmmm\n...not a bad way to handle the tenure citation issue too ...).\nOK, so citation counting is not the best of schemes. While it is insufﬁcient to just count\nthe number of pages pointing into a page, we might do better by weighting each pointerby the number of pages pointing into it.\nQuestion: Why is this system also easy to fool?\nAnswer: Now, to make my web page rank highly, I again create a thousand dummy\nweb pages and have them all point to each other as well as to my page. That is, I createa clique of size 1,000. Now my web page has a high number of backlinks, all of whichalso have a high number of backlinks.\nGoogle’s Solution: Google’s solution is to deﬁne page rank recursively: “A page has\nhigh rank if the sum of the ranks of its backlinks is high.” Observe that this covers boththe case when a page has many backlinks and when a page has a few highly rankedbacklinks.\nQuestion: It is easy to say that “a page has high rank if the sum of the ranks of its\nbacklinks is high,” but how does that help us ﬁgure out the rank of a page?\nAnswer: The “aha” that the Google founders made was to realize that the recursive\ndeﬁnition is actually saying\nπj=n/summationdisplay\ni=1πiPij.\nThat is, the only way for page jto have high limiting probability is if the i’s pointing\nintojhave high limiting probability. Remind you of anything?\nThe rank of a page is thus just its limiting probability in a Markov chain.\nGoogle’s PageRank Algorithm :\n1.Create a DTMC transition diagram where there is one state for each web\npage and there is an arrow from state ito state jif page ihas a link to\npagej.\n2.If page ihask>0outgoing links, then set the probability on each outgoing\narrow from state ito be1/k.\n3.Solve the DTMC to determine limiting probabilities. Pages are then ranked\nbased on their limiting probabilities (higher probability ﬁrst).\nThis simple algorithm was the original basis behind the entire Google company!\n192 real-world examples: google, aloha, and harder chains\nN\nM A\nFigure 10.1. Links between web pages.\nExample\nSuppose the entire web consists of the three pages shown in Figure 10.1. Then the\ncorresponding DTMC transition diagram is shown in Figure 10.2.\n1½\n½½N\nM A½\nFigure 10.2. Corresponding DTMC transition diagram.\nWe now solve the balance equations:\nπA=1\n2πN+πM\n1\n2πN=1\n2πA\nπM=1\n2πA\n1=πA+πM+πN\nThis results in: πA=πN=2\n5;πM=1\n5.\nIntuition behind the Google Algorithm: Imagine that each page initially has one unit\nof importance. At each round, each page shares whatever importance it has among its\nsuccessors. Pages with a lot of incoming links will receive lots of importance (will be\nvisited frequently in the DTMC).\n10.1.2 Problems with Real Web Graphs\nUnfortunately, PageRank does not work well on all web graphs. Consider the following\ntwo examples.\n10.1 google’s pagerank algorithm 193\nExample: Dead End or Spider Trap\nConsider Figure 10.1, where this time there is either no outgoing link from page M (in\nthis case M is called a “dead end”) or there is a self-loop at state M (in this case M is\ncalled a “spider trap”).\nIn either case Figure 10.3 shows the corresponding DTMC transition diagram.\n½\n1½\n½½N\nM A\nFigure 10.3. DTMC for a web graph with a dead end or spider trap at M.\nThe balance equations are\n1\n2πN=1\n2πA\n0·πM=1\n2πA\nπA=1\n2πN\nπA+πN+πM=1.\nThe solution to these equations is πM=1,πN=0= πA. These are also the limiting\nprobabilities (note that the start state does not matter).\nSomehow this solution is very unsatisfying. Just because person M chooses to be\nanti-social and not link to anyone else, it should not follow that person M is the only\nimportant person on the web. Our solution does not match our intuitive view of surﬁnga web graph.\nExample: Two Spider Traps\nNow imagine that both M and N are anti-social and link only to themselves. The\nresulting DTMC transition diagram is shown in Figure 10.4.\nThe corresponding balance equations are:\n0·πN=1\n2·πA\n0·πM=1\n2·πA\nπA=0\nπA+πN+πM=1.\n194 real-world examples: google, aloha, and harder chains\n1\n1½N\nM A½\nFigure 10.4. DTMC for a web graph with two spider traps.\nObserve that there are an inﬁnite number of possible solutions. This is because the\nlimiting probabilities depend on the start state.\nAgain the solution is very unsatisfying.\n10.1.3 Google’s Solution to Dead Ends and Spider Traps\nGoogle’s solution to dead ends and spider traps is to “tax” each page some fraction\nof its “importance” and then distribute that taxed importance equally among all pagesin the web graph. This “tax” keeps the DTMC from getting trapped in a dead end or\nspider trap.\nFigure 10.5 shows the effect of applying a\n30% tax on the DTMC of Figure 10.3. First,\nevery existing transition is multiplied by 70% . Then, for each state sin ann-state\nchain, we add a transition of weight30%\nnfrom state sto every other state, including\nitself. Thus in the three-state chain in Figure 10.3, we add a transition of weight 10%\nfrom each state to every other state.\n.8.1\n.1\n.1.7·½+.1\n.7·½+.1 .7· ½+.1\n.7·½+.1\n.1N\nM A\nFigure 10.5. DTMC transition diagram for Figure 10.3 after 30% tax.\nObserve that the spider trap is now no longer a problem, and we can easily solve for\nthe limiting probabilities:\nπA=.19;πM=.55;πN=.26",8078
69-10.2 Aloha Protocol Analysis.pdf,69-10.2 Aloha Protocol Analysis,"10.2 aloha protocol analysis 195\nThe problem now is that these limiting probabilities are highly dependent on the amount\nof tax.\nThe readings at the end of the chapter describe experiments with other taxation ideas;\nfor example, where the tax is distributed among just one or two pages.\n10.1.4 Evaluation of the PageRank Algorithm\nPageRank is intended to give an indication of the popularity of a page – the fraction\nof times that page is referenced as compared with other pages. This works well whenthe graph is irreducible, but is problematic when there are spider traps or dead ends.The taxation solution for solving the spider trap problem seems ad hoc. If the tax is toosmall, then we still end up with too high a limiting probability at the spider trap state\n(as in\nπM=0.55in Section 10.1.3 ). Thus we need to use a high tax. Yet a high tax\nseems totally unrealistic, because it leads to every state being of equal weight.\nIn practice it seems that when you come to a page with links only back to itself, you\nusually back up (hit the “BACK” key). Perhaps we can combine the idea of taxation\nwith the idea of backing up. That is, we apply a high tax to each page, but the tax isdistributed only among the predecessors of the page, not among all pages of the web.\nThis idea is explored in [ 53].\n10.1.5 Practical Implementation Considerations\nYou might be wondering how in practice Google goes about solving the DTMC for\nthe limiting probabilities, given that it is a huge (ﬁnite) DTMC. Solving such a largenumber of simultaneous equations seems difﬁcult.\nQuestion: Is there another approach to obtain the limiting probabilities?\nAnswer: Yes, we can take powers of\nP, the transition probability matrix. This turns\nout to be faster when the transition probability matrix is large and sparse and only an\napproximate solution is needed. This is the approach employed by Google.\n10.2 Aloha Protocol Analysis\nThe slotted Aloha protocol is the progenitor of the Ethernet protocol. Ethernet is adatalink-level protocol allowing multiple users to transmit a data frame along a single\nwire in a switchless LAN as shown in Figure 10.6. Only one user (host) can use the\nwire at a time. However, because the multiple users are working independently, it\n123 mEthernet\nFigure 10.6. Ethernet with mhosts.\n196 real-world examples: google, aloha, and harder chains\ncould turn out that more than one user tries to send a packet at once. In that case, a\n“collision” occurs, and all messages are corrupted and must be resent. Of course, ifwe had centralized control, we could ensure that the users take turns sending packets.\nHowever, we want to make this work without centralized control.\nEthernet uses CSMA/CD (Carrier Sense Multiple Access/Collision Detection). What\nis important in CSMA/CD is that, although the users basically submit independently ofeach other,\n1when their messages do collide, they are able to detect the collision (they\ndo this by seeing that their data frames are garbled), and then they know that they need\nto resend. The key idea in CSMA/CD is that the retransmissions of the data need to\noccur at random times, so as to minimize the chance of repeated collisions.\nIn this section we use DTMCs to begin to analyze various protocols for how to handle\nthe retransmissions. We start by looking at the Slotted Aloha protocol and studying theproblems with this earlier protocol.\nWe will only go part of the way toward solving this problem during this chapter, but\nthis discussion will give you a feel for how to model such problems with Markov chainsand will also help make concepts of ergodicity more concrete.\n10.2.1 The Slotted Aloha Protocol\nThe Slotted Aloha protocol is deﬁned as follows: Time is divided into discrete time\nsteps or “slots.” There are mtransmitting hosts. At each time step, each of the mhosts\nindependently transmits a new message (frame) with probability p(assume p<1\nm).\nIf exactly 1 message (frame) is transmitted in a slot, the transmission is deemed\n“successful” and the message leaves the system. However, if more than 1 messageis transmitted during a slot, the transmission is deemed “unsuccessful.” In this casenone of those messages leave the system. Every message involved in an “unsuccessful\ntransmission” is then retransmitted at every step with probability\nq, until it successfully\nleaves the system. To keep things stable, we may need to make qvery small; for the\ntime being, assume that qis a very small constant. Note that, regardless of the backlog\nof messages, each of the mhosts continues to transmit newmessages with probability\npat each step.\n10.2.2 The Aloha Markov Chain\nQuestion: Given values of m,p, andq/lessmuchp, what does the Markov chain for the\nSlotted Aloha protocol look like?\nHint: It may not be obvious what we need to track. Each of the mhosts independently\ntransmits a message at each time step with probability p, so there is no need to track\nthat. What we need to track is the number of messages that need retransmission (i.e.,\nthe messages that have been through at least one collision).\n1This is not entirely true, because users do “listen” to the wire before sending, although listening is not sufﬁcient\nto avoid all collisions.\n10.2 aloha protocol analysis 197\nAnswer: Before we begin, observe that the number of new messages transmitted\nduring a time slot is distributed Binomially with parameters mandp. Therefore, the\nprobability of generating knew messages is\npk=/parenleftbigg\nm\nk/parenrightbigg\npk(1−p)m−k,∀k=0,1,...,m .\nLikewise, when there are nmessages in the previously collided pile, the probability of\nkretransmissions occurring is qn\nkwhere,\nqn\nk=/parenleftbigg\nn\nk/parenrightbigg\nqk(1−q)n−k,∀k=0,1,...,n.\nWe deﬁne the state at time step tto be the number of messages remaining in the system\nat the end of time step t. We now describe the transition probabilities for the states.\nFirst, consider state 0(no messages remaining in the system). The probability of\nremaining at state 0is the probability that there are no new transmissions or there is\nexactly 1 new transmission (which gets out of the system). For a state transition tooccur from\n0toj>1, we need jnew transmissions. There cannot be more than m\nnew transmissions. Thus the probability of moving from state 0to state j>m is zero.\nAlso, it is logically impossible to go from state 0to state 1. Hence we have\nP0,0=( 1−p)m+mp(1−p)m−1.\nP0,1=0.\nP0,j=/parenleftbigg\nm\nj/parenrightbigg\npj(1−p)m−j,∀j=2,...,m .\nP0,j=0,∀j>m .\nNow consider state k,k > 0(i.e., there are kunsuccessful messages left in the system\nat the end of the time step, waiting to be retransmitted). Because at most 1 messagegets through at every time step, transitions from\nkto state j≤k−2cannot occur.\nFurther, a maximum of only mnew messages can be generated. Therefore, the state\ncannot increase by more than m. The possible transitions are thus as follows:\nrk→k−1: No new transmissions and 1 retransmission. The retransmitted mes-\nsage gets out of the system. Probability: (1−p)mkq(1−q)k−1.\nrk→k: There are several ways this can happen:\n1. One new transmission and no retransmissions:\nProbability: mp(1−p)m−1(1−q)k.\n2. No new transmission and no retransmissions:\nProbability: (1−p)m(1−q)k.\n3. No new transmission and at least 2 retransmissions:\nProbability: (1−p)m/parenleftbig\n1−(1−q)k−kq(1−q)k−1/parenrightbig\n.\nrk→k+1: One new transmission and at least 1 retransmission. As a result,\ncollision occurs, and the number of messages increases by 1.\nProbability: mp(1−p)m−1/parenleftbig\n1−(1−q)k/parenrightbig\n.\n198 real-world examples: google, aloha, and harder chains\nrk→k+j, j=2,...,m : There are jnew transmissions. The number of re-\ntransmissions does not matter, because collision occurs anyway.\nProbability:/parenleftbigg\nm\nj/parenrightbigg\npj(1−p)m−j.\nTo summarize,\nPk,j=0,∀j≤k−2.\nPk,k−1=( 1−p)mkq(1−q)k−1.\nPk,k=m(1−q)kp(1−p)m−1+/parenleftbig\n1−kq(1−q)k−1/parenrightbig\n(1−p)m.\nPk,k+1=mp(1−p)m−1/parenleftbig\n1−(1−q)k/parenrightbig\n.\nPk,k+j=/parenleftbigg\nm\nj/parenrightbigg\npj(1−p)m−j,∀j=2,...,m .\nPk,j=0,∀j>k +m.\nThese probabilities describe the system completely.\n10.2.3 Properties of the Aloha Markov Chain\nQuestion: Is this chain aperiodic and irreducible?\nAnswer: Yes.\nQuestion: Does the Aloha protocol work?\nHint: Is the Markov chain ergodic (positive recurrent and aperiodic and irreducible),\nor is it transient, or is it null recurrent?\nAnswer: LetP(k)\nbackrepresent the probability of transitioning to a lower numbered state,\ngiven we are in state k. LetP(k)\nforw=1−P(k)\nback. Then,\nP(k)\nback=k−1/summationdisplay\nj=0Pk,j=Pk,k−1=kq(1−q)k−1(1−p)m.\nIt can be seen that for a given constant qandp,\nlim\nk→∞P(k)\nback= lim\nk→∞k(1−p)mq(1−q)k−1=∞·0\n=q(1−p)mlim\nk→∞k\n(1−q)1−k=∞\n∞\n=q(1−p)mlim\nk→∞d\ndk[k]\nd\ndk[(1−q)1−k]\n=q(1−p)mlim\nk→∞1\n(1−q)1−k·ln(1−q)·(−1)\n=0.\n10.2 aloha protocol analysis 199\nlim\nk→∞P(k)\nforw=1−lim\nk→∞P(k)\nback=1.\nlim\nk→∞Pk,k= lim\nk→∞/parenleftbig\nm(1−q)kp(1−p)m−1+/parenleftbig\n1−kq(1−q)k−1/parenrightbig\n(1−p)m/parenrightbig\n= lim\nk→∞/parenleftbig\nm(1−q)kp(1−p)m−1+( 1−p)m/parenrightbig\n−lim\nk→∞/parenleftbig\nkq(1−q)k−1(1−p)m/parenrightbig\n=( 1−p)m+ lim\nk→∞P(k)\nback\n=( 1−p)m<1.\nThus as kincreases, the probability of going to lower states tends to zero, and the\nprobability of staying at the same state tends to a small constant, (1−p)m; with high\nprobability, tending to 1−(1−p)m, we move to higher states. Consider a state k,\nforklarge. Once the state is visited, the probability of returning back to the state\ngoes to zero, because, almost surely, the chain proceeds ahead and never returnsback.\nQuestion: If you make\nqreally, really small, does the Aloha protocol work then?\nAnswer: No, for any constant qthe chain is transient.\nHere’s some more intuition: Consider the expected number of transmissions during a\nslot, given that the DTMC is in state k. The expected number of new transmissions is\nmp. The expected number of retransmissions is kq. Now, if the expected total number\nof transmissions ( E[N]=mp+kq) exceeds 1, then the state either stays the same\nor gets worse. Assume a ﬁxed q. When kgets higher than1\nq, thenE[N]>1. Thus we\nexpect that the number of simultaneous transmissions for each state from that point onexceeds 1.\nUnsurprisingly to us queueing theorists, the original Aloha protocol implementation\nwas subject to occasional unexplained freezes, in which all messages were dropped.However, the protocol was improved and became the basis behind today’s Ethernetprotocol.\n10.2.4 Improving the Aloha Protocol\nQuestion: Can you see a different way to set qso as to make the chain ergodic?\nAnswer: We want to ensure that the expected number of transmissions during a slot is\nless than 1. That is, we want to ensure that, for all states k,\nmp+kq <1.\nThis could perhaps be achieved by making qdecreasing in k(e.g.,q<1−mp\nk), or going\neven further and making qgeometrically decreasing in k, such as q∝α/knwhere\nα<(1−mp)andn>1, or even where q∝β−k, for some β>1.\nQuestion: Is there any drawback to making qsmall?",11189
70-10.3 Generating Functions for Harder Markov Chains.pdf,70-10.3 Generating Functions for Harder Markov Chains,"200 real-world examples: google, aloha, and harder chains\nAnswer: Ifqis small, the probability of retransmission is very low, and unsuccessful\nmessages are likely to remain in the system for a long time. As q→0, the mean delay\nfor retransmission goes to inﬁnity; hence the mean time to send a message goes to\ninﬁnity too. The goal is therefore to look for an optimal value for qthat is just low\nenough to ensure that the Markov chain is ergodic, without being so low as to causethe mean time for a transmission to skyrocket.\nThe actual Ethernet protocol is based on the idea of exponential backoff , where each\nhost waits some random time after each collision before resubmitting and where the\nmean of that “waiting time” increases exponentially as a function of the number ofcollisions experienced so far [ 114].\n10.3 Generating Functions for Harder Markov Chains\nSolving DTMCs is not always easy. In the case of a ﬁnite-state DTMC, we at least\nknow that the number of simultaneous balance equations is ﬁnite. Hence, given enoughcomputing power, we should in theory be able to solve for limiting probabilities. (Of\ncourse, in practice, there are some singularity problems that may arise when the chains\nare too big or the probabilities are too small.)\nHowever, for an inﬁnite-state DTMC, it is not at all obvious that one can even solve\nthe chain. It is often the case that the balance equations take the form of recurrence\nrelations, as in the recurrence from Section 8.10:\nπi+1(r+s)=πi·r+πi+2·s (10.1)\nor equivalently\nπi+2=πi+1/parenleftBigr\ns+1/parenrightBig\n−πi·r\ns.\nSo far, we have been able to “guess” the solution for all the recurrences that we have\nlooked at, and the solution was often simple. For example, the solution to ( 10.1)i s\nπi=ρiπ0 where ρ=r\ns.\nHowever, in general the recurrence relation is not always so easy to solve. Considerfor example, a very simple looking recurrence relation:\nfi=fi−1+fi−2 (10.2)\nQuestion: Do you recognize the relation?\nAnswer: It is the Fibonacci sequence.\nAlthough ( 10.2) seems even simpler than ( 10.1), it turns out to be impossible to solve\nby just unraveling the recurrence or “guessing” the solution – please try it!\nIn this section, we see how to derive a closed-form expression for fn, thenth Fibonacci\nnumber, using a four-step method involving generating functions (that we will introduce\nshortly). This method may seem overly complex. However, for many Markov chains\n10.3 generating functions for harder markov chains 201\nthat come up in practice (see for example Exercise 10.7), there is no clear way to\n“guess” a solution, and using generating functions is the easiest way to solve these\nchains for their limiting distribution.\n10.3.1 The z-Transform\nThe generating function that we choose to use is a called a z-transform . This is one\ntype of generating function. We discuss transforms in much more depth in Chapter 25,\nbut for this chapter you will not need more than the deﬁnition.\nDeﬁnition 10.1 Given a sequence {f0,f1,f2,...}, deﬁne\nF(z)=∞/summationdisplay\ni=0fizi.\nF(z)is the z-transform of the sequence .\nIn the Markov chains that we look at, fitakes the place of πi=P{State is i}, and our\ngoal is to derive a closed-form expression for fi.\n10.3.2 Solving the Chain\nWe illustrate the method on a recurrence relation of this form:\nfi+2=bfi+1+afi (10.3)\nwhere we assume f0andf1are given and aandbare constants. However, the method\ncan obviously be applied more generally.\nStep 1: Represent F(z)as a ratio of polynomials.\nThe goal in Step 1 is to represent F(z)as a ratio of two polynomials in z.F r o m( 10.3),\nwe have\nfi+2=bfi+1+afi.\nfi+2zi+2=bfi+1zi+2+afizi+2.\n∞/summationdisplay\ni=0fi+2zi+2=b∞/summationdisplay\ni=0fi+1zi+2+a∞/summationdisplay\ni=0fizi+2.\nF(z)−f1z−f0=bz∞/summationdisplay\ni=0fi+1zi+1+az2∞/summationdisplay\ni=0fizi.\nF(z)−f1z−f0=bz(F(z)−f0)+az2F(z).\n/parenleftbig\n1−bz−az2/parenrightbig\nF(z)=f1z+f0−bzf0.\nF(z)=f0+z(f1−bf0)\n1−bz−az2. (10.4)\n202 real-world examples: google, aloha, and harder chains\nStep 2: Rewrite F(z)via partial fractions.\nThe goal in Step 2 is to apply partial fractions to F(z).I fF(z)=N(z)\nD(z), then we want\nto write\nF(z)=A\nh(z)+B\ng(z),\nwhere D(z)=h(z)g(z)andh, gare (hopefully) linear.\nLemma 10.2 IfD(z)=az2+bz+1, then\nD(z)=/parenleftbigg\n1−z\nr0/parenrightbigg/parenleftbigg\n1−z\nr1/parenrightbigg\nwhere r0andr1are the (real) roots of D(z).\nProof To see that the two ways of writing D(z)are equivalent, we note that the two\nquadratic expressions have the same two roots, r0andr1, and furthermore have the\nsame constant term, 1.\nIn our case, see ( 10.4),D(z)=−az2−bz+1,s o\n(r0,r1)=/parenleftbigg−b−√\nb2+4a\n2a,−b+√\nb2+4a\n2a/parenrightbigg\n. (10.5)\nD(z)=h(z)·g(z)\nh(z)=1−z\nr0\ng(z)=1−z\nr1\nWe now use N(z)=f0+z(f1−f0b)from ( 10.4) to solve for AandB:\nF(z)=A\n1−z\nr0+B\n1−z\nr1(10.6)\n=A/parenleftBig\n1−z\nr1/parenrightBig\n+B/parenleftBig\n1−z\nr0/parenrightBig\n/parenleftBig\n1−z\nr0/parenrightBig/parenleftBig\n1−z\nr1/parenrightBig\n=(A+B)+z/parenleftBig\n−A\nr1−B\nr0/parenrightBig\n/parenleftBig\n1−z\nr0/parenrightBig/parenleftBig\n1−z\nr1/parenrightBig=N(z)\nD(z)=f0+z(f1−f0b)\nD(z)(10.7)\nMatching the z-coefﬁcients in the numerators of ( 10.7), we have\nA+B=f0\n−A\nr1−B\nr0=f1−f0b",5300
71-10.5 Exercises.pdf,71-10.5 Exercises,"10.4 readings and summary 203\nwhich solves to\nB=r0f0+(f1−f0b)r0r1\nr0−r1. (10.8)\nA=f0−B. (10.9)\nStep 3: Rewrite F(z)via series expansion.\nReturning to ( 10.6), and using the fact that1\n1−αz=/summationtext∞\ni=0(αz)i,w eh a v e\nA\n1−z\nr0=A∞/summationdisplay\ni=0/parenleftbiggz\nr0/parenrightbiggi\nandB\n1−z\nr1=B∞/summationdisplay\ni=0/parenleftbiggz\nr1/parenrightbiggi\n.\nThus, the geometric series expansion of F(z)can be rewritten as follows:\nF(z)=∞/summationdisplay\ni=0fizi=A∞/summationdisplay\ni=0/parenleftbiggz\nr0/parenrightbiggi\n+B∞/summationdisplay\ni=0/parenleftbiggz\nr1/parenrightbiggi\n(10.10)\nStep 4: Match terms to obtain fn.\nFinally, we match the z-coefﬁcients in ( 10.10 ) to obtain the fn’s:\nfn=A\nrn\n0+B\nrn\n1\nSummary\nWe have proven that the solution to a recurrence relation of the form\nfn+2=b·fn+1+a·fn\ngivenf0andf1is given by\nfn=A\nrn\n0+B\nrn\n1\nwhere AandBare obtained from ( 10.9) and ( 10.8) andr0andr1are obtained from\n(10.5).\nIn Exercise 10.5, you will apply these steps to derive a closed-form expression for the\nnth Fibonacci number.\n10.4 Readings and Summary\nThis chapter has explored a couple of open-ended modeling problems illustrating\nthe ergodicity properties that we covered in Chapter 9in the context of real-world\nproblems. There is much more information about both problems available on the\nweb. The exercises at the end of the chapter provide more examples of modeling and\nergodicity. For Google’s PageRank algorithm, we recommend several early researchpapers: [ 139,109,53].\n204 real-world examples: google, aloha, and harder chains\n10.5 Exercises\n10.1 Caching\nIf you think about it, web browsing is basically a Markov chain – the page\nyou will go to next depends on the page you are currently at. Suppose our web\nserver has three pages, and we have the following transition probabilities:\nP1,1=0 P1,2=xP 1,3=1−x\nP2,1=yP 2,2=0 P2,3=1−y\nP3,1=0 P3,2=1 P3,3=0\nwhere Pi,jrepresents the probability that I will next ask for page j, given that\nI am currently at page i. Assume that 0<x<y<1\n2.\nWeb browsers cache pages so that they can be quickly retrieved later. We will\nassume that the cache has enough memory to store two pages. Whenever arequest comes in for a page that is not cached, the browser will store that page\nin the cache, replacing the page least likely to be referenced next based on\nthe current request. For example, if my cache contained pages\n{2,3}and I\nrequested page 1, the cache would now store {1,3}(because x<1−x).\n(a) Find the proportion of time that the cache contains the following pages:\n(i){1,2}(ii){2,3}(iii){1,3}.\n(b) Find the proportion of requests that are for cached pages.\n10.2 DTMC for Stock Evaluation\nA stock has an equilibrium price P, where Pis an integer. The stock price\nﬂuctuates each day according to the DTMC shown in Figure 10.7. Note that,\nfor ease of analysis, we assume that the stock price can go negative.\n½½½¼¼¼\n¼¼¼½½¼¼½¼¼\n½0 0P–1 P P+1 P–2 P+2\nFigure 10.7. DTMC for the stock price.\n(a) What is the fraction of time that the stock is priced at P?\n(b) Let Idenote the difference between the stock price and P. What is the\nexpectation of the absolute value of I?\n10.3 Time to Empty\nConsider a router where, at each time step, the number of packets increases by 1\nwith probability 0.4and decreases by 1with probability 0.6. We are interested\nin the time required for the router to empty. The Markov chain depicting the\nnumber of packets is shown in Figure 10.8. LetT1,0denote the time to get\n0.4\n0.60.4 0.4\n0.6 0.6q0.4\n0.60.4\n0.60 0.6 3 1 2 4 0\nFigure 10.8. Number of packets at router.\n10.5 exercises 205\nfrom state 1to state 0. (a) Compute E[T1,0]. (b) Compute Var(T1,0). [Hint:\nThe variance computation is a little tricky. Be careful not to lump together\ndistinct random variables.]\n10.4 Time to Empty – Extra Strength\nConsider the same setup as in Exercise 10.3. This time, we use Tn,0to denote\nthe time to get from state nto state 0. (a) Compute E[Tn,0]. (b) Compute\nVar(Tn,0).\n10.5 Fibonacci Sequence\nThe Fibonacci sequence is deﬁned by f0=0,f1=1,fn+2=fn+1+fn.\nUse the generating function technique from this chapter to derive fn, thenth\nterm of the Fibonacci sequence.\n10.6 Simple Random Walk: Solution via Generating Functions\nFigure 10.9 shows a simple random walk, where r<s . Follow the generating\nfunction approach in this chapter to solve for the limiting probabilities of thisrandom walk using the z-transform,\nΠ(z)=/summationtext∞\ni=0πizi.[Note: To get the\ninitial probability, π0, observe that Π(z)|z=1=1. You will also need to use\nthe balance equation for state 0to getπ1.]\n0r\nsr\nsr\ns1−r−s 1−r−s 1−r−s\n00 1 2 1−r 3\nFigure 10.9. DTMC for random walk.\n10.7 Processor with Failures\nConsider the DTMC shown in Figure 10.10 . This kind of chain is often used\nto model a processor with failures. The chain tracks the number of jobs in\nthe system. At any time step, either the number of jobs increases by 1 (withprobability\np), or decreases by 1 (with probability q), or a processor failure\noccurs (with probability r), where p+q+r=1. In the case of a processor\nfailure, all jobs in the system are lost. Derive the limiting probability, πi,o f\nthere being ijobs in the system. [Hint: Use the generating function approach\nfrom this chapter.]\nrq+r \nrrp\nqpp\nqqqpp\nq0 1−p 3 1 2 4 0\nFigure 10.10. DTMC for processor with failures.",5438
72-Chapter 11 Exponential Distribution and the Poisson Process.pdf,72-Chapter 11 Exponential Distribution and the Poisson Process,,0
73-11.2 Memoryless Property of the Exponential.pdf,73-11.2 Memoryless Property of the Exponential,"CHAPTER 11\nExponential Distribution and\nthe Poisson Process\nWe ﬁnished discussing Discrete-Time Markov Chains (DTMCs) in Chapter 10 and are\nnow heading toward Continuous-Time Markov Chains (CTMCs). DTMCs are totallysynchronized, in that the state only changes at discrete time steps, whereas in CTMCsthe state can change at any time. This makes CTMCs more realistic for modelingcomputer systems, where events can occur at any time. In preparation for CTMCs, we\nneed to discuss the Exponential distribution and the Poisson arrival process.\n11.1 Deﬁnition of the Exponential Distribution\nWe say that a random variable Xis distributed Exponentially with rate λ,\nX∼Exp(λ)\nifXhas the probability density function:\nf(x)=/braceleftbigg\nλe−λxx≥0.\n0 x<0.\nThe graph of the probability density function is shown in Figure 11.1.\nλ\nλe−λ\nλe−2λ\nλe−3λ\nx\n4f(x)\n0 12 3\nFigure 11.1. Exponential p.d.f., f(x).\nThe cumulative distribution function, F(x)=P{X≤x}, is given by\nF(x)=/integraldisplayx\n−∞f(y)dy=/braceleftbigg\n1−e−λxx≥0.\n0 x<0.\nF(x)=e−λx,x≥0.\n206\n11.2 memoryless property of the exponential 207\nObserve that both f(x)andF(x)drop off by a constant factor, e−λ, with each unit\nincrease of x.\nThe Exponential distribution has mean:\nE[X]=/integraldisplay∞\n−∞xf(x)dx=1\nλ.\nThe second moment of X∼Exp(λ)is\nE/bracketleftbig\nX2/bracketrightbig\n=/integraldisplay∞\n−∞x2f(x)dx=2\nλ2.\nThe variance is\nVar(X)=E/bracketleftbig\nX2/bracketrightbig\n−(E[X])2=1\nλ2.\nQuestion: Why is λreferred to as the “rate” of the distribution?\nAnswer: Because the mean of the distribution is 1/λand “rate” is typically viewed\nas the reciprocal of the “mean.”\nQuestion: What is the squared coefﬁcient of variation of Exp (λ)?\nAnswer: The squared coefﬁcient of variation of random variable Xis deﬁned as\nC2\nX=Var(X)\nE[X]2.\nThis can be thought of as the “scaled” or “normalized” variance. When X∼Exp(λ),\nC2\nX=1.\n11.2 Memoryless Property of the Exponential\nA random variable Xis said to be memoryless if\nP{X>s +t|X>s}=P{X>t},∀s, t≥0.\nQuestion: Prove that X∼Exp(λ)is memoryless.\nAnswer:\nP{X>s +t|X>s}=P{X>s +t}\nP{X>s}=e−λ(s+t)\ne−λs=e−λt=P{X>t}.\nTo understand this, think of Xas being the lifetime of, say, a lightbulb. The expression\nsays that the probability that the lightbulb survives for at least another tseconds before\nburning out, given that the lightbulb has survived for sseconds already, is the same as\nthe probability that the lightbulb survives at least tseconds, independent of s .\nQuestion: Does this seem realistic for a lightbulb?\nAnswer: Who knows?\n208 exponential distribution and the poisson process\nQuestion: What are some real-life examples whose lifetimes can be modeled by an X\nsuch that P{X>s +t|X>s}goes down as sgoes up?\nAnswer: A car’s lifetime. The older a car is, the less likely that it will survive another,\nsay,t=6years.\nDistributions for which P{X>s +t|X>s}goes down as sgoes up are said\nto have increasing failure rate . The device is more and more likely to fail as time\ngoes on.\nQuestion: What are some real-life examples whose lifetimes can be modeled by an X\nsuch that P{X>s +t|X>s}goes up as sgoes up?\nAnswer: One example is UNIX job CPU lifetimes; see [ 85]. The more CPU a job has\nused up so far, the more CPU it is likely to use up. Another example is computer chips.\nIf they are going to fail, they will do so early. That is why chip manufacturers test chips\nfor a while before selling them.\nDistributions for which P{X>s +t|X>s}goes up as sgoes up are said to have\ndecreasing failure rate . The device is less likely to fail as time goes on.\nMore precisely, the failure rate function r(t) (a.k.a. hazard rate function) is deﬁned\nas follows: Let Xbe a continuous random variable with probability density function\nf(t)and cumulative distribution function F(t)=P{X<t}. Then\nr(t)≡f(t)\nF(t).\nTo interpret this expression, consider the probability that a t-year-old item will fail\nduring the next dtseconds:\nP{X∈(t, t+dt)|X>t}=P{X∈(t, t+dt)}\nP{X>t}\n≈f(t)·dt\nF(t)\n=r(t)·dt\nThusr(t)represents the instantaneous failure rate of a t-year-old item.\nDeﬁnition 11.1 When r(t)is strictly decreasing in t, we say that the distribution\nf(t)hasdecreasing failure rate ;i fr(t)is strictly increasing in t, we say that the\ndistribution has increasing failure rate .\nObserve that in general r(t)is not necessarily going to always decrease with tor\nincrease with t– it might behave differently for different t.\nQuestion: Suppose r(t)is constant. What do you know about f(t)?\nAnswer: In Exercise 11.4, we prove that f(t)must be the Exponential p.d.f.",4630
74-11.3 Relating Exponential to Geometric via -Steps.pdf,74-11.3 Relating Exponential to Geometric via -Steps,"11.3 relating exponential to geometric via δ-steps 209\nBank Example\nQuestion: If the time a customer spends in a bank is Exponentially distributed with\nmean 10 minutes, what is P{Customer spends >5 min in bank }?\nAnswer: e−5·1/10=e−1/2.\nQuestion: What is P{Customer spends >15 min in bank total |he is there after\n10 min}?\nAnswer: Same as previous answer.\nThe reason why the Exponential distribution is so convenient to work with is that\nhistory does not matter!\nQuestion: Suppose X∼Exp(λ). What is E[X|X>20]?\nAnswer: The Exponential distribution “starts over” at 20, or at any other point. Hence,\nE[X|X>20] = 20 + E[X] = 20 +1\nλ.\nPost Ofﬁce Example\nSuppose that a post ofﬁce has two clerks. Customer Bis being served by one clerk,\nand customer Cis being served by the other clerk, when customer Awalks in. All\nservice times are Exponentially distributed with mean1\nλ.\nQuestion: What is P{Ais the last to leave }?\nAnswer:1\n2. Note that either BorCwill leave ﬁrst. WLOG, let us say Bleaves ﬁrst.\nThenCandAwill have the same distribution on their remaining service time. It does\nnot matter that Chas been served for a while.\nIt can be proven that the Exponential distribution is the only continuous-time memo-\nryless distribution.\nQuestion: What is the only discrete-time memoryless distribution?\nAnswer: The Geometric distribution.\n11.3 Relating Exponential to Geometric via δ-Steps\nWe ﬁnd it very helpful when reasoning about Exponential random variables to instead\nthink about Geometric random variables, for which we have more intuition. We like tothink of the Exponential distribution as the “continuous counterpart” of the Geometric\ndistribution by making the following analogy: Recall that the Geometric distribution\ncan be viewed as the number of ﬂips needed to get a “success.” The distribution of the\nremaining number of ﬂips is independent of how many times we have ﬂipped so far.The same holds for the Exponential distribution, which is the time until “success.”\nTo unify the Geometric and Exponential distributions, we introduce the notion of a\n“\nδ-step proof.” Throughout the next few chapters, we will use this way of thinking to\n210 exponential distribution and the poisson process\ncome up with quick intuitions and arguments.1The idea is to imagine each unit of time\nas divided into npieces, each of size δ=1\nn, and suppose that a trial (ﬂip) occurs every\nδtime period, rather than at unit times.\nLet\nX∼Exp(λ).\nWe now deﬁne a random variable Y, where Yis Geometrically distributed with\nprobability p=λδof getting a head, for some small δ→0. However, rather than\nﬂipping every unit time step, we ﬂip every δ-step. That is,\nY∼Geometric (p=λδ|ﬂip every δ-step).\nObserve that Ydenotes the number of ﬂips until success. Now deﬁne /tildewideYto be the time\nuntil success under Y:\n/tildewideY=Time associated with Y\nObserve that as δ→0(orn→∞ ),/tildewideYbecomes a positive, real-valued random variable,\nbecause success can occur at any time.\nQuestion: What is E/bracketleftBig\n/tildewideY/bracketrightBig\n?H o wi s/tildewideYdistributed?\nAnswer: The mean of/tildewideYis1\nλ.\nE/bracketleftBig\n/tildewideY/bracketrightBig\n=(avg. number trials until success) ·(time per trial)\n=1\nδλ·δ=1\nλ\nTo understand the distribution of /tildewideY, we observe that /tildewideY> t if all the trials up to at least\ntimethave been failures (i.e., we have had at least t/δfailures).\nP/braceleftBig\n/tildewideY> t/bracerightBig\n=P/braceleftbigg\nat leastt\nδfailures/bracerightbigg\n=( 1−δλ)t\nδ\n=[ ( 1−δλ)1\nδ]t\n=/bracketleftBigg/parenleftbigg\n1−1\n1\nδλ/parenrightbigg1\nδλ·λ/bracketrightBiggt\n−→[(e−1)λ]t,a sδ→0\n=e−λt\nThis says that /tildewideY∼Exp(λ).\n1I concocted this notion of a δ-step proof as a PhD student, struggling with messy integrals. The δ-step proofs\nhelped me reason about properties of the Exponential distribution and Poisson process. They also helped me\nleverage my understanding of DTMCs to quickly reason about CTMCs (see Chapter 12).",4022
75-11.4 More Properties of the Exponential.pdf,75-11.4 More Properties of the Exponential,"11.4 more properties of the exponential 211\nWe have thus seen that an Exponential random variable with rate λrepresents the time\nto a successful event, given that an event occurs every δ-step and is successful with\nprobability λδ, where δ→0.This is depicted in Figure 11.2.\nλδ λδ\nδ 2δ 3 0 δ (n–1)δ nδ\nExp( λ)UnitedStatesofQueueingλδUnitedStatesofQueueingλδUnitedStatesofQueueingλδUnitedStatesofQueueing\nFigure 11.2. Geometric depiction of the Exp (λ)distribution. Time is divided into steps of\nduration δ, and a coin (with probability λδof “heads”) is ﬂipped only at each δ-step.\n11.4 More Properties of the Exponential\nBefore we continue, here is a useful deﬁnition:\nDeﬁnition 11.2\nf=o(δ)iflim\nδ→0f\nδ=0.\nFor example, f=δ2iso(δ)becauseδ2\nδ→0asδ→0. Basically, a function is o(δ)\nif it goes to zero faster than δ,a sδ→0.2\nWe now illustrate how to combine the o(δ)notation with the discretized view of an\nExponential to prove a few properties of the Exponential distribution.\nTheorem 11.3 Given X1∼Exp(λ1),X2∼Exp(λ2),X1⊥X2,\nP{X1<X 2}=λ1\nλ1+λ2.\nProof (Traditional Algebraic Proof)\nP{X1<X 2}=/integraldisplay∞\n0P{X1<X 2|X2=x}·f2(x)dx\n=/integraldisplay∞\n0P{X1<x}·λ2e−λ2xdx\n2This deﬁnition may seem a little odd, if one is used to theoretical computer science where “big-O” and “little-o”\nnotation are deﬁned in terms of some n→∞ , not as δ→0.\n212 exponential distribution and the poisson process\n=/integraldisplay∞\n0(1−e−λ1x)(λ2e−λ2x)dx\n=/integraldisplay∞\n0λ2e−λ2xdx−λ2/integraldisplay∞\n0e−(λ1+λ2)xdx\n=1−λ2\nλ1+λ2\n=λ1\nλ1+λ2\nHere is the more intuitive proof, by analogy with the Geometric distribution:\nProof (Intuitive Geometric Proof) Success of type 1 occurs with probability λ1δon\neachδ-step. Independently, success of type 2 occurs with probability λ2δon each\nδ-step. The problem is really asking the following: Given that a success of type 1 or\ntype 2 has occurred, what is the probability that it is a success of type 1?\nP{type 1|type 1 or type 2 }=P{type 1}\nP{type 1 or type 2 }\n=λ1δ\nλ1δ+λ2δ−(λ1δ)(λ2δ)\n=λ1δ\nλ1δ+λ2δ−o(δ)\n=λ1\nλ1+λ2−o(δ)\nδ\n=λ1\nλ1+λ2asδ→0\nExample\nThere are two potential failure points for our server: the power supply and the disk. The\nlifetime of the power supply is Exponentially distributed with mean 500 days, and thelifetime of the disk is independently Exponentially distributed with mean 1,000 days.\nQuestion: What is the probability that the system failure, when it occurs, is caused by\nthe power supply?\nAnswer:1\n500\n1\n500+1\n1000.\nTheorem 11.4 Given X1∼Exp(λ1),X2∼Exp(λ2),X1⊥X2.\nLet\nX=m i n ( X1,X2).\nThen\nX∼Exp(λ1+λ2).",2613
76-11.5 The Celebrated Poisson Process.pdf,76-11.5 The Celebrated Poisson Process,"11.5 the celebrated poisson process 213\nProof (Traditional Algebraic Proof)\nP{X>t}=P{min(X1,X2)>t}\n=P{X1>tandX2>t}\n=P{X1>t}·P{X2>t}\n=e−λ1t·e−λ2t\n=e−(λ1+λ2)t\nHere is an alternative argument by analogy with the Geometric distribution:\nProof (Intuitive Geometric Proof)\n1.A trial occurs every δ-step.\n2.The trial is “successful of type 1” with probability λ1δ.\n3.The trial is “successful of type 2” independently with probability λ2δ.\n4.We are looking for the time until there is a success of either type. A trial is\n“successful” (either type) with probability\nλ1δ+λ2δ−(λ1δ)·(λ2δ)=δ/parenleftbigg\nλ1+λ2−o(δ)\nδ/parenrightbigg\n.\n5.Thus the time until we get a “success” is Exponentially distributed with rate\nλ1+λ2+o(δ)\nδ,\nand as δ→0this gives the desired result.\nQuestion: In the server from the previous example, what is the time until there is a\nfailure of either the power supply or the disk?\nAnswer: Exponential with rate/parenleftBig\n1\n500+1\n1,000/parenrightBig\n.\n11.5 The Celebrated Poisson Process\nThe Poisson process is the most widely used model for arrivals into a system for two\nreasons:\n1.The Markovian properties of the Poisson process make it analytically tractable.\n2.In many cases, it is an excellent model. For example,\n(a) In communications networks, such as the telephone system, it is a good model\nfor the sequence of times at which telephone calls are originated. Althoughthe calls of a single user do not look like a Poisson process, the aggregateover many users does.\n(b) Many physical phenomena behave in a Poisson fashion, such as the sequence\nof gamma ray emissions from a radioactive substance.\n214 exponential distribution and the poisson process\nThe Poisson process appears often in nature when we are observing the aggregate\neffect of a large number of individuals or particles operating independently. The reason\nfor this is explained by the Limiting Theorem (due to Palm ’43, Khinchin ’60, and\ndescribed in [ 105] pp. 221–228). This theorem states that if you merge n(assume that\nnis very large) identical and independently distributed arrival processes, each with an\narrival rateλ\nn, where each of the arrival processes is a renewal process with an arbitrary\nﬁxed interarrival distribution F, then the aggregate arrival process approaches a Poisson\nprocess with rate λ.\nWhen considering questions on resource allocation, task assignment, scheduling, and\nthe like, we ﬁnd that, whereas the job size distribution has a large effect on meanresponse times, the arrival process of jobs typically has much less of an effect. Specif-ically, assuming a Poisson arrival process for arrivals allows us to analytically predictresponse times, and these predictions are often not too far from results based on trace-\ndriven simulation.\nBefore we deﬁne a Poisson process, we need a little terminology.\nConsider a sequence of events:\nt 0Events\ntime\nDeﬁne N(t),t≥0as the number of events that occurred by time t.\nDeﬁnition 11.5 An event sequence has independent increments if the numbers\nof events that occur in disjoint time intervals are independent. Speciﬁcally, for all\nt0<t1<t2<...<t n, the random variables\nN(t1)−N(t0),N(t2)−N(t1),...,N (tn)−N(tn−1)\nare independent.\nExample\nLet us look at three event processes:\n1.births of children\n2.people entering a building\n3.goals scored by a particular soccer player\nQuestion: Do these event processes have independent increments?\n11.5 the celebrated poisson process 215\nAnswer:\n1.No. Birth rate depends on population, which increases with births.\n2.Yes.\n3.Maybe. Depends on whether we believe in slumps!\nDeﬁnition 11.6 The event sequence has stationary increments if the number of\nevents during a time period depends only on the length of the time period and noton its starting point. That is,\nN(t+s)−N(s)has the same distribution for all s.\nDeﬁnition 1 of the Poisson Process :\nAPoisson process having rate λis a sequence of events such that\n1.N(0) = 0 .\n2.The process has independent increments.\n3.The number of events in any interval of length tis Poisson distributed with\nmeanλt. That is,∀s, t≥0,\nP{N(t+s)−N(s)=n}=e−λt(λt)n\nn!n=0,1,...\nQuestion: Why is λcalled the “rate” of the process?\nAnswer: Observe that E[N(t)] =λt,s oE[N(t)]\nt=λ.\nQuestion: Why only “independent increments” ?\nAnswer: The third item in the deﬁnition implies stationary increments, because the\nnumber of events within an interval of length tdepends only on t.\nObserve that the assumption of stationary and independent increments is equivalent to\nasserting that, at any point in time, the process probabilistically restarts itself ; that is,\nthe process from any point onward is independent of all that occurred previously (byindependent increments) and also has the same distribution as the original process (bystationary increments). Simply put, a Poisson process has no memory. This leads us tothe second deﬁnition of the Poisson process.\nDeﬁnition 2 of the Poisson Process :\nAPoisson process with rate λis a sequence of events such that the interarrival\ntimes are i.i.d. Exponential random variables with rate λandN(0) = 0 .\nQuestion: Which deﬁnition of a Poisson process would you use when trying to simulate\na Poisson process: Deﬁnition 1 or Deﬁnition 2?\nAnswer: Deﬁnition 2.\n216 exponential distribution and the poisson process\nDeﬁnition 1 ⇒Deﬁnition 2\nLetT1,T2,...,T n,... be the interarrival times of a sequence of events. We need to\nshow that Ti∼Exp(λ),∀i. By Deﬁnition 1,\nP{T1>t}=P{N(t)=0}=e−λt(λt)0\n0!=e−λt.\nNext,\nP/braceleftBigg\nTn+1>t/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglen/summationdisplay\ni=1Ti=s/bracerightBigg\n=P/braceleftBigg\n0 events in (s, s+t)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglen/summationdisplay\ni=1Ti=s/bracerightBigg\n=P{0 events in (s, s+t)},\nby independent increments\n=e−λt, by stationary increments .\nDeﬁnition 2 ⇒Deﬁnition 1\nFeller [ 58], p. 11, has a rigorous algebraic proof that Deﬁnition 2 ⇒Deﬁnition 1.\nThe idea is to show that the sum of ni.i.d. Exp (λ)random variables has a Gamma,\nΓ(n,λ), distribution. Feller then uses the Γ(n,λ)distribution to show that the number\nof arrivals by time thas a Poisson distribution.\nRather than going through this tedious algebraic proof, we instead provide an argument\nby analogy with the Geometric distribution: N(t)refers to the number of arrivals by\ntimet. Our goal is to prove that N(t)∼Poisson (λt). Think of an “arrival” as being a\n“success.” Exp (λ)interarrival times correspond to ﬂipping a coin every δ-step, where\na ﬂip is a success (i.e., arrival) with probability λδ.\nN(t)=Number of successes (arrivals) by time t\n∼Binomial (# ﬂips,probability of success of each ﬂip )\n∼Binomial/parenleftbiggt\nδ,λ δ/parenrightbigg\nObserve above that as δ→0,t\nδbecomes very large and λδbecomes very small.\nQuestion: Now what do you know about Binomial( n,p) for large nand tiny p?\nAnswer: Recall from Exercise 3.12 that\nBinomial (n,p)→Poisson (np),asn→∞ andp→0.\nSo asδ→0,\nN(t)∼Poisson/parenleftbiggt\nδ·λδ/parenrightbigg\n=Poisson (λt).\n11.5 the celebrated poisson process 217\nDeﬁnition 3 of the Poisson Process :\nAPoisson process having rate λis a sequence of events such that\n1.N(0) = 0 .\n2.The process has stationary and independent increments.\n3.P{N(δ)=1}=λδ+o(δ).\n4.P{N(δ)≥2}=o(δ).\nWe have shown that Deﬁnition 1 ⇔Deﬁnition 2. To show that all three deﬁnitions are\nequivalent, we now show that Deﬁnition 1 ⇔Deﬁnition 3.\nDeﬁnition 1 ⇒Deﬁnition 3\nThis is taken from [ 127], p. 245:\nP{N(δ)=1}=e−λδ(λδ)1\n1!\n=λδ/bracketleftbigg\n1−λδ+(λδ)2\n2!−···/bracketrightbigg\n=λδ−λ2(δ)2+λ3(δ)3\n2−···\n=λδ+o(δ)\nP{N(δ)=i}=e−λδ(λδ)i\ni!\n=(λδ)i\ni!/parenleftbigg\n1−λδ+(λδ)2\n2!−···/parenrightbigg\n=λiδi\ni!+o(δi)\nSo\nP{N(δ)≥2}=∞/summationdisplay\ni=2P{N(δ)=i}=∞/summationdisplay\ni=2/parenleftbiggλiδi\ni!+o(δi)/parenrightbigg\n=o(δ).\nDeﬁnition 3 ⇒Deﬁnition 1\nA slightly approximate argument is provided in [ 149], Ch. 2, which is very intuitive\nand which we repeat here.\nTo show that N(t)∼Poisson (λt),\nrSubdivide [0,t]into increments of length δ→0.\nrP{Any interval has ≥2events}\n≤(# of intervals )·P{Single interval has ≥2events}\n=t\nδ·o(δ)\n=t·o(δ)\nδ→0,asδ→0.",8279
77-11.6 Merging Independent Poisson Processes.pdf,77-11.6 Merging Independent Poisson Processes,,0
78-11.7 Poisson Splitting.pdf,78-11.7 Poisson Splitting,"218 exponential distribution and the poisson process\nrSo now we can think of each δ-size interval as having 1 event with probability\nλδ+o(δ)and otherwise having 0 events (note this is just an approximation).\nrBut now we see that N(t), the number of events by time tis simply\nN(t)∼Binomial/parenleftbiggt\nδ,λ δ+o(δ)/parenrightbigg\n→Poisson/parenleftbiggt\nδ(λδ+o(δ))/parenrightbigg\nasδ→0\n=Poisson/parenleftbigg\nλt+to(δ)\nδ/parenrightbigg\n→Poisson (λt).\n11.6 Merging Independent Poisson Processes\nTheorem 11.7 Given two independent Poisson processes, where process 1 has\nrateλ1and process 2 has rate λ2, the merge of process 1 and process 2 is a single\nPoisson process with rate (λ1+λ2).\nProof Process 1 has Exp (λ1)interarrival times. Process 2 has Exp (λ2)interarrival\ntimes. The time until the ﬁrst event from either process 1 or process 2 is the time untilthe minimum of Exp\n(λ1)and Exp (λ2), which is distributed Exp (λ1+λ2). Likewise,\nthe time until the second event is also distributed Exp (λ1+λ2), etc. Thus by Deﬁnition\n2 of the Poisson process we have a Poisson process with rate λ1+λ2.\nAlternative Proof LetNi(t)denote the number of events in process iby time t.\nN1(t)∼Poisson (λ1t)\nN2(t)∼Poisson (λ2t)\nYet the sum of two independent Poisson random variables is still Poisson with the sum\nof the means, so\nN1(t)+N2(t)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\nmerged process∼Poisson (λ1t+λ2t).\n/squaresolid\n11.7 Poisson Splitting\nTheorem 11.8 Given a Poisson process with rate λ, suppose that each event is\nclassiﬁed “type A” with probability pand “type B” with probability 1−p. Then\ntype A events form a Poisson process with rate pλ, type B events form a Poisson\nprocess with rate (1−p)λ, and these two processes are independent. Speciﬁcally,\n11.7 poisson splitting 219\nifNA(t)denotes the number of type A events by time t, andNB(t)denotes the\nnumber of type B events by time t, then\nP{NA(t)=n,N B(t)=m}=P{NA(t)=n}·P{NB(t)=m}\n=e−λtp(λtp)n\nn!·e−λt(1−p)(λt(1−p))m\nm!.\nThis is one of those theorems that is very difﬁcult to prove if you just stick to the idea\nof Exponential interarrival times. It is really not clear why the times between the typeA events end up being Exponentially distributed with rate\nλpas opposed to something\nelse. Consider the original Poisson process and a sequence of coin ﬂips with bias p.\nWhen the coin ﬂip comes up “heads” (this happens with probability p), then the event\nis classiﬁed “type A.” If we now consider a sequence of just the type A events, we\nmight imagine that the time between type A events would be Exp( λ), for a time period\nduring which the coin ﬂips had a streak of “heads,” and then there might be a largeinterarrival time consisting of some sum of Exp(\nλ)’s during the time period when\nthe coin ﬂips had a streak of “tails,” after which we return to an interarrival time ofExp\n(λ). It is not at all clear why the interarrival times between type A events are actually\nExp(λp).\nHowever, this theorem is very easy to understand by analogy with the Geometric\ndistribution. We ﬁrst provide intuition for the theorem, by making use of the Geometric\nδ-step arguments. We then provide a rigorous proof of the theorem.\nIntuition – by Analogy with the Geometric Distribution\nThe original process has Exp( λ) interarrival times, which is equivalent to tossing a coin\neveryδ→0steps, where the coin comes up “success” with probability λδ. We refer\nto this λδcoin as the “ﬁrst” coin. Each success (head) of the ﬁrst coin is labeled as a\ntype A success with probability p. Thus we can imagine a second coin being ﬂipped,\nwhere the second coin has probability pof success. Only if both the ﬁrst and second\ncoins are successes do we have a type A success. But this is equivalent to ﬂipping just\na single coin with probability λδp of success. The time between type A successes is\nthen distributed Exp(λp). This proof is illustrated in Figure 11.3 and can be repeated\nfor type B events.\nProof This proof is taken from [ 150], p. 258. What makes this proof precise is that\n(1) it uses no approximations and (2) it explicitly proves independence. Let\nN(t)=Number of events by time tin the original process\nNA(t)=Number of type A events by time t\nNB(t)=Number of type B events by time t\nThe idea is to compute the joint probability that there are nevents of type A and mevents\nof type B by time t,P{NA(t)=n,N B(t)=m}, and then to use this to compute\n220 exponential distribution and the poisson process\nδ 2δ 0λδ λδ λδ λδ λδ λδ λδp p p p p p p\nFirst coin\nδ 2δ 0λδp λδp λδp λδp λδp λδp λδp λδp Single coinSecon d coin\nType A\nsuccess\ntime = Exp( λp)\nFigure 11.3. A “type A success” only occurs if both the λδ-coin and the p-coin are heads.\nP{NA(t)=n}andP{NB(t)=m}, so that we can verify the independence of the\ntwo processes.\nP{NA(t)=n, N B(t)=m}\n=∞/summationdisplay\nk=0P{NA(t)=n, N B(t)=m|N(t)=k}·P{N(t)=k}\n=P{NA(t)=n, N B(t)=m|N(t)=n+m}·P{N(t)=n+m}\n(because this is the only non-zero term in the above sum)\n=P{NA(t)=n, N B(t)=m|N(t)=n+m}·e−λt(λt)n+m\n(n+m)!\n=/parenleftbigg\nn+m\nn/parenrightbigg\npn(1−p)me−λt(λt)n+m\n(n+m)!\n=(m+n)!\nn!m!pn(1−p)me−λt(λt)n+m\n(n+m)!\n=e−λtp(λtp)n\nn!·e−λt(1−p)(λt(1−p))m\nm!(11.1)",5265
79-11.9 Exercises.pdf,79-11.9 Exercises,"11.8 uniformity 221\nNow to compute P{NA(t)=n}, we simply sum the joint probability, ( 11.1), over all\nvalues of m, as follows:\nP{NA(t)=n}=∞/summationdisplay\nm=0P{NA(t)=n,N B(t)=m}\n=e−λtp(λtp)n\nn!∞/summationdisplay\nm=0e−λt(1−p)(λt(1−p))m\nm!\n=e−λtp(λtp)n\nn!\nIn a similar fashion we can show that\nP{NB(t)=m}=e−λt(1−p)(λt(1−p))m\nm!.\nHence by ( 11.1), we have that\nP{NA(t)=n,N B(t)=m}=P{NA(t)=n}·P{NB(t)=m},(11.2)\nshowing that the processes are independent.\nNow because the other conditions in Deﬁnition 1 such as independent increments\nare also obviously satisﬁed, we have that {NA(t),t≥0}forms a Poisson process\nwith rate λpand{NB(t),t≥0}forms an independent Poisson process with rate\nλ(1−p).\n11.8 Uniformity\nTheorem 11.9 Given that one event of a Poisson process has occurred by time t,\nthat event is equally likely to have occurred anywhere in [0,t].\nProof LetT1denote the time of the one event.\nP{T1<s|N(t)=1}=P{T1<sandN(t)=1}\nP{N(t)=1}\n=P{1 event in [0,s]and 0 events in [s, t]}\ne−λt(λt)1\n1!\n=P{1 event in [0,s]}·P{0 events in [s, t]}\ne−λt·λt\n=e−λs·λs·e−λ(t−s)·(λ(t−s))0\ne−λt·λt\n=s\nt\n222 exponential distribution and the poisson process\nGeneralization: Ifkevents of a Poisson process occur by time t, then the kevents are\ndistributed independently and uniformly in [0,t]. This is proven in [ 149], pp. 36–38.\n11.9 Exercises\n11.1 Memorylessness\nLetX∼Exp(λ). What is E[X|X>10]? Solve this in two ways:\n(a) by integrating the conditional p.d.f.\n(b) by a two-line argument via the memoryless property of Exponential dis-\ntribution.\n11.2 Memorylessness Continued\nGiven X∼Exp(1), what is E[X2|X>10]?\n11.3 Doubling Exponentials\nSuppose that job sizes are Exponentially distributed with rate μ. If job sizes\nall double, what can we say about the distribution of job sizes now? Prove it.\n11.4 Failure Rate\nLetXbe a continuous random variable with probability density function\nf(t)and cumulative distribution function F(t)=P{X<t}. We deﬁne the\nfailure rate of Xto ber(t), where\nr(t)≡f(t)\nF(t).\nThusr(t)dtrepresents the probability that a t-year-old item will fail in the\nnextdtseconds.\n(a) Prove that for the Exponential distribution, the failure rate is a constant.\n(b) Prove that the Exponential distribution is the only distribution with constant\nfailure rate.\n11.5 Practice with Deﬁnition of Poisson Process\n(a) Consider a stream of packets arriving according to a Poisson process with\nrateλ=5 0 packets/sec. Suppose each packet is of type “green” with\nprobability 5% and of type “yellow” with probability 95%. Given that 100\ngreen packets arrived during the previous second, (i) what is the expected\nnumber of yellow packets that arrived during the previous second? (ii)\nwhat is the probability that 200 yellow packets arrived during the previoussecond?\n(b) Red packets arrive according to a Poisson process with rate\nλ1=3 0\npackets/sec. Black packets arrive according to a Poisson process with rate\nλ2=1 0 packets/sec. Assume the streams are statistically multiplexed into\none stream. Suppose we are told that 60 packets arrived during the second.\nWhat is the probability that exactly 40 of those were red?\n(c) Suppose packets arrive according to a Poisson process with rate λ, and\nyou are told that by time 30 seconds 100 packets have arrived. What is the\nprobability that 20 packets arrived during the ﬁrst 10 seconds?\n11.9 exercises 223\n11.6 Number of Arrivals of a Poisson Process during a Service\nIn this chapter, we considered, N(t), the number of Poisson( λ) arrivals during\na time t. In queueing, one often needs to know AS, the number of Poisson( λ)\narrivals during S, where Sis a continuous random variable denoting, say, the\nservice time of a job. Derive E[AS]andVar(AS).\n11.7 Malware and Honeypots\nA new malware is out in the Internet! Our goal is to estimate its spread/damage\nby time t, assuming it starts at time 0. Assume that the Internet hosts get infected\nby this malware according to a Poisson process with parameter λ, where λis\nnot known . Thrasyvoulos installs a Honeypot security system to detect whether\nhosts are infected. Unfortunately there is a lag time between when a computer\nis infected by the malware and the Honeypot detects the damage. Assume that\nthis lag time is distributed Exp (μ). Suppose that Thrasyvoulos’s Honeypot\nsystem has detected N1(t)infected hosts by time t. Thrasyvoulos worries that,\nbecause of the lag, the number of infected hosts is actually much higher than\nN1(t). The goal of the problem is to understand how many additional hosts,\nN2(t), are expected to also be infected at time t.\n(a) Suppose that an infection happens at time s, where 0<s<t . What is the\nprobability that the infection is detected by time t?\n(b) Consider an arbitrary infection that happens before time t. What is the (un-\nconditional) probability, p, that the infection is detected by the Honeypot\nby time t?\n(c) How can we use our knowledge of N1(t)to estimate λ?\n(d) Use your estimate of λto determine the expected value of N2(t).\n[Note: None of the above solutions requires more than a couple lines.]\n11.8 Sum of Geometric Number of Exponentials3\nLetN∼Geometric (p). LetXi∼Exp(μ). LetSN=/summationtextN\ni=1Xi. Your goal is\nto prove that SNis Exponentially distributed and derive the rate of SN. Prove\nthis fact using δ-step arguments. [ Note: In Chapter 25you will see how to\nprove this same result using transforms.]\n11.9 Reliability Theory: Max of Two Exponentials\nRedundancy is often built into systems so that if a device (say a disk) fails there\nis no catastrophe. In these settings, we are often concerned with the expectedtime until both disks fail, which is the time until a catastrophe occurs. This can\nbe viewed as the “max” of two random variables.(a) Let\nX1∼Exp(λ). Let X2∼Exp(λ). Suppose X1⊥X2. What is\nE[max( X1,X2)]?\n(b) Let X1∼Exp(λ1). LetX2∼Exp(λ2). Suppose X1⊥X2. What is\nE[max( X1,X2)]?\n11.10 Exponential Downloads\nYou need to download two ﬁles: ﬁle 1 and ﬁle 2. File 1 is available via source\nA or source B. File 2 is available only via source C. The time to download\n3Warning: The result of Exercise 11.8 will be used many times throughout the book.\n224 exponential distribution and the poisson process\nﬁle 1 from source A is Exponentially distributed with rate 1. The time to\ndownload ﬁle 1 from source B is Exponentially distributed with rate 2. The\ntime to download ﬁle 2 from source C is Exponentially distributed with rate\n3. You decide to download from all three sources simultaneously, in the hope\nthat you get both ﬁle 1 and ﬁle 2 as soon as possible. Let Tdenote the time\nuntil you get both ﬁles.\n(a) What is E[T]?\n(b) What is P{T<t}?\n11.11 Reliability Theory: Max of Many Exponentials\nLetX1,X2,X3,...,X nbe i.i.d. Exponentially distributed random variables\nall with rate λ. Let\nZ= max( X1,X2,...,X n).\n(a)What is E[Z]?\n(b)Roughly, what does E[Z]look like as a function of nandλwhennis\nhigh?\n(c)Derive the distribution of Z.\n11.12 Conditional Distribution\nLetX∼Exp(λX)andY∼Exp(λY), where X⊥Y. LetZ=m i n ( X,Y).\nProve that\n(X|X<Y )∼Z.\nThat is, show that P{X>t|X<Y}=P{Z>t}.",7172
80-Chapter 12 Transition to Continuous-Time Markov Chains.pdf,80-Chapter 12 Transition to Continuous-Time Markov Chains,,0
81-12.1 Defining CTMCs.pdf,81-12.1 Defining CTMCs,"CHAPTER 12\nTransition to Continuous-Time\nMarkov Chains\n12.1 Deﬁning CTMCs\nRecall the deﬁnition of a DTMC (repeated from Deﬁnition 8.1):\nDeﬁnition 12.1 ADTMC (Discrete-Time Markov Chain) is a stochastic process\n{Xn,n=0,1,2,...}, where Xndenotes the state at (discrete) time step nand\nsuch that,∀n≥0,∀i, j, and∀i0,...,i n−1,\nP{Xn+1=j|Xn=i, Xn−1=in−1,...,X 0=i0}=P{Xn+1=j|Xn=i}\n=Pij(by stationarity) ,\nwhere Pijis independent of the time step and of past history.\nNotice the three properties of Deﬁnition 12.1:\n1.Transitions are always made at discrete time steps, n=0,1,2,...\n2.The past does not matter. Only the present state matters. In particular, it does\nnot matter how long the Markov chain was sitting in state ialready. This is the\nMarkovian Property (M.P.).\n3.Transition probabilities are “stationary,” meaning that they are independent of\ntime step n.\nContinuous-Time Markov Chains (CTMCs) are the continuous-time analogue of\nDTMCs. Thus we keep properties 2 and 3 of DTMCs. However, we replace prop-erty 1 with: “transitions between states can happen at any time.”\nDeﬁnition 12.2 AContinuous-Time Markov Chain (CTMC) is a continuous-time\nstochastic process {X(t),t≥0}s.t.,∀s, t≥0and∀i,j,x(u),\nP{X(t+s)=j|X(s)=i,X(u)=x(u),0≤u≤s}\n=P{X(t+s)=j|X(s)=i}(by M.P.)\n=P{X(t)=j|X(0) = i}=Pij(t)(stationarity) .\nWe assume throughout that the state space is countable.\nNow consider the quantity τi, deﬁned next.\nDeﬁnition 12.3 Deﬁne τito be the time until the CTMC leaves state i, given that\nthe CTMC is currently in state i.\n225\n226 transition to continuous-time markov chains\nBy the Markovian and stationary properties of the CTMC, the probability that the\nCTMC leaves state iin the next tseconds is independent of how long the CTMC has\nalready been in state i. That is,\nP{τi>t+s|τi>s}=P{τi>t}.\nQuestion: What does this say about τi?\nAnswer: This says that τiis memoryless. But this means τiis Exponentially dis-\ntributed!\nThis means that we can deﬁne a CTMC as follows:\nDeﬁnition 12.4 CTMC – VIEW 1: A CTMC is a stochastic process with the\nproperty that every time it enters state i, the following hold:\n1.The amount of time the process spends in state ibefore making a transition is\nExponentially distributed with some rate (call it νi).\n2.When the process leaves state i, it will next enter state jwith some probability\n(call it pij) independent of the time spent at state i.\nVIEW 1 of a CTMC is depicted in Figure 12.1. In this view, we stay in state ifor\ntimeτi∼Exp(νi). When we leave i, we transition to jwith probability pij, where/summationtext\njpij=1.\nSit here for time Exp( νi);\nthen flip coin to determine \nwhere to go next.pij\npik\npilj\nlk i\nFigure 12.1. VIEW 1 of a CTMC.\nObserve that pij, the probability that when we leave iwe next go to state j, is a constant.\nIt is independent of time, t, by stationarity. It is independent of the time spent in state\ni,τi, by the Markovian property.\nConsider the moment just before we leave state i. At this moment, the time we have\nspent in state iis irrelevant: That is all history (Markovian assumption). All that is\nrelevant is that we are at state iat this moment s. The particular time sis irrelevant as\nwell (stationarity assumption).There is an alternative way to view CTMCs (we call it VIEW 2) that is more\npractical.\n12.1 deﬁning ctmcs 227\nDeﬁnition 12.5 CTMC – VIEW 2: LetXj∼Exp(νipij)represent the time to\ntransition from itoj,∀j/negationslash=i. Letτi=m i n\nj{Xj}be the time until the Markov\nchain leaves state i. Let the next state be mwhere m=a r g m i n\nj{Xj}, i.e.,Xmwas\nthemin\nj{Xj}.\nThis deﬁnition may seem confusing. Here is what VIEW 2 is really saying (see Fig-\nure12.2): Think of yourself as sitting in state i(home) on a Saturday night and waiting\nto receive a phone call that will tell you where to move next. There are three possible\ntransitions that you can take: to j,t ok,o rt o l(these are the names of the three dates\nwho might call). You have three phones. The ﬁrst is a direct line to state jsojcan\ncall you and invite you over. The second is a direct line to state k. The third is a direct\nline to state l. You will go to whomever calls you ﬁrst – you are desperate! The time\nuntil you receive a phone call from state jis a random variable Xj∼Exp(νipij).\nIndependently, the time until you receive a phone call from state kis a random variable\nXk∼Exp(νipik). The time until you receive a phone call from state lis a random\nvariable Xl∼Exp(νipil). All of Xj,Xk,Xlare taking place simultaneously. As soon\nas you get any phone call, you leave state iand go to the party who called you, and the\nprocess starts all over again at that state.\nj\nlk i\nSit here until get \nfirst phone call.Exp( νi · pij) time until call\nExp( νi · pik) time until call\nExp( νi · pil) time until call\nFigure 12.2. VIEW 2 of a CTMC.\nIt is not at all obvious that VIEW 1 is equivalent to VIEW 2.\nProof That VIEW 2 ⇒VIEW 1\nUsing VIEW 2, consider the time spent in state i, namely τi.\nτi=m i n\nj{Xj}∼ Exp/parenleftBigg/summationdisplay\njνipij/parenrightBigg\n=Exp(νi).\nFurthermore, the probability that from state iwe transition to state mis:\nP/braceleftbigg\nXm=m i n\nj{Xj}/bracerightbigg\n=νipim/summationdisplay\njνipij=pim. /squaresolid\n228 transition to continuous-time markov chains\nHeuristic Proof That VIEW 1 ⇒VIEW 2\nUsing VIEW 1, we describe the Markov chain as sitting in state ifor Exp (νi)time.\nAfter that a “direction coin” is ﬂipped. With probability pijthe direction coin points\ntoj. With probability pikthe direction coin points to k. With probability pilthe\ndirection coin points to l. To make this more concrete, let’s assume pij=1\n2,pik=1\n3,\npil=1\n6.\nNow let’s translate the above into its Geometric analogue: The Markov chain (MC) sits\nin state iﬂipping a coin every δsteps. The coin has probability νiδof success. The MC\nwaits for a success. As soon as it gets a success, it ﬂips the direction coin to determine\nthe type of its success.\nThis description is equivalent to the following: The MC sits in state iﬂipping a coin\neveryδsteps. With probability νi·1\n2δ, the coin is a “success type j.” With probability\nνi·1\n3δ, the coin is a “success type k.” With probability νi·1\n6δ, the coin is a “success\ntypel.” With probability 1−νiδ, the coin is not a success. The Markov chain waits\nfor a success (of any type) and heads to the appropriate next destination (based on the\ntype of the success).\nConsidering those coin ﬂips solely from the perspective of whether they lead to a\nsuccess of type j, we see that the time until a success of type jis Exp(νipij). Like-\nwise, independently and in parallel, we see that the time until a success of type k\nis Exp(νipik). And again, independently and in parallel, we see that the time until a\nsuccess of type lis Exp(νipil).\nBut this is exactly VIEW 2. /squaresolid\nRemark: The heuristic proof can be made a little more rigorous by including the\no(δ)probabilities that two success types happen on a given δtime step. We have\nnot included this detail because it washes out in the end as you will see in later\nexamples.\nExample\nLet us model the single-server network shown in Figure 12.3 as a CTMC. Here the\nstate is the number of jobs in the system.\nPoisson ( λ)\ne.g., λ = 3 jobs/sec\nService demand ~Exp( μ)\ne.g., μ = 5 jobs/secμ\nFigure 12.3. A single-server network.\nUsing VIEW 2, we arrive at the equivalent picture shown in Figure 12.4 about which\nwe make the following remarks:",7530
82-12.2 Solving CTMCs.pdf,82-12.2 Solving CTMCs,"12.2 solving ctmcs 229\n1 0λ λλ\n2\nFigure 12.4. VIEW 2 of the same single-server network.\nrλandμarenotprobabilities (we can have λ=3,μ=5).\nrAn event is something that changes our state.\nrSuppose we are in state i, where i≥1. Then the next event is either an arrival or\na departure.\nrLetXAdenote the time to the next arrival. Then XA∼Exp(λ)regardless of\nhow long we have been in the current state. Let XDdenote the time to the\nnext departure. Then XD∼Exp(μ)regardless of how long we have been in the\ncurrent state. XAandXDare independent of each other.\nrThe previous two events are happening in parallel. One of these, the arrival or the\ndeparture, will occur ﬁrst. So τi, the time until we leave state i, has the following\ndistribution: τi∼Exp(λ+μ). Thus, νi=λ+μ.\nrThe probability that when we leave state iwe will next go to state i+1 is\nP{XA<X D}=λ\nλ+μ.\n12.2 Solving CTMCs\nLetπj= lim t→∞Pij(t)=limiting probability of being in state j. How do we deter-\nmine the πj’s?\nDifferent books have different ways of leading the reader to the right method. Ross[149] (see Section 4.8 and then Section 5.5) goes through semi-Markov chains. Trivedi\n[179] goes through Kolmogorov equations. Gallager [ 66] goes through semi-Markov\nchain theory and embedded Markov chains.\nWe go through a more intuitive argument for obtaining the limiting probabilities. For\nease of readability, we continue to refer to the previous very simple chain example, buteverything generalizes to more complex CTMCs, as we discuss later.\n1.Suppose you had a DTMC . Then you would know how to obtain the\nπi’s: Simply\ncheck for aperiodicity and irreducibility, and then try to solve the stationary\nequations, as explained in Theorem 9.27. If a solution to the stationary equations\nexists, that solution is the limiting probability. If no solution to the stationary\nequations exists, then all the limiting probabilities are zero.\n2.But we do not have a DTMC ; we have a CTMC.\n3.However, we can model the CTMC via a DTMC . In the CTMC, if we are in\nstatei,\nrTime to next arrival ∼Exp(λ)\n230 transition to continuous-time markov chains\nrTime to next departure ∼Exp(μ)\nrTime until ﬁrst of these occurs (i.e., leave state i)∼Exp(λ+μ).\nWe can model this situation by ﬂipping two coins simultaneously every δ-step,\nwhere δ→0, as shown in Figure 12.5.\nδ 2δ 3δ 4δ 5δ 6δ\n+1 +1 +0 +0 +0 –1μδλδ λδ\nμδλδ λδ λδ λδ\nμδ μδ μδ μδ Depart ure\nNumber of jobs:Arrival\nFigure 12.5. Flipping two coins simultaneously each δ-step, one with probability λδof heads\nand the other with probability μδof heads.\nThe ﬁrst coin represents arrivals. When the ﬁrst coin is ﬂipped at each δ-step,\nit has probability λδof returning “arrival” and probability 1−λδof returning\nnothing.\nThe second coin represents departures. When the second coin is ﬂipped at each\nδ-step, it has probability μδof returning “departure” and probability 1−μδof\nreturning nothing.\nA “ﬂip” refers to the result of the two coins. Expanding out the four cases yields\nrWith probability λδ(1−μδ), the ﬂip returns “arrival and no departure.”\nrWith probability (1−λδ)μδ, the ﬂip returns “departure and no arrival.”\nrWith probability λδμδ , the ﬂip returns “arrival and departure.”\nrWith probability (1−all of the above ), the ﬂip returns “no arrival and no\ndeparture.”\nBut this looks just like a DTMC that makes a transition every δsteps with the\nprobabilities shown in Figure 12.6.\nλδ(1–μδ)\nμδ(1–λδ)i i–1\n1–λδ(1–μδ)–μδ(1–λδ)i+1\nFigure 12.6. The equivalent DTMC.\n4.Thus the solution to the original CTMC in Figure 12.4 equals the solution to\nthe DTMC in Figure 12.6 where transitions occur at every δ-step. Let’s see if\nwe can clean up this DTMC.\n12.2 solving ctmcs 231\nWe can rewrite\nλδ(1−μδ)−→λδ+o(δ)\nμδ(1−λδ)−→μδ+o(δ)\nλδμδ−→o(δ)\n(1−all of the above )−→1−λδ−μδ+o(δ),\nwhich allows us to represent the DTMC as in Figure 12.7. Observe that the edges\nare just probabilities, and transitions occur on every δ-step. Observe also that if\nthe DTMC is in state i, with high probability it will still be in state iat the next\nδ-step.\nµδ+o(δ)λδ+o(δ) λδ+o(δ)\nµδ+o(δ)i i–1\n1–λδ–µδ+o(δ)i+1\nFigure 12.7. The equivalent DTMC with small factors hidden.\n5.Let’s solve this DTMC, while taking the limit as δ→0. It simpliﬁes the math\nto observe that we can ignore self-loops in a DTMC and write balance equations\n(recall Section 9.6). We then divide by δ, take the limit as δ→0, and solve.\nRate leave state 0 =Rate enter state 0\nπ0(λδ+o(δ)) =π1(μδ+o(δ))\nπ0/parenleftbigg\nλ+o(δ)\nδ/parenrightbigg\n=π1/parenleftbigg\nμ+o(δ)\nδ/parenrightbigg\nlim\nδ→0π0/parenleftbigg\nλ+o(δ)\nδ/parenrightbigg\n= lim\nδ→0π1/parenleftbigg\nμ+o(δ)\nδ/parenrightbigg\nπ0·λ=π1·μ\n⇒π1=λ\nμπ0\nRate leave state 1 =Rate enter state 1\nπ1(λδ+o(δ)+μδ+o(δ)) =π0(λδ+o(δ)) +π2(μδ+o(δ))\nlim\nδ→0π1/parenleftbiggλδ\nδ+o(δ)\nδ+μδ\nδ/parenrightbigg\n= lim\nδ→0π0/parenleftbiggλδ\nδ+o(δ)\nδ/parenrightbigg\n+π2/parenleftbiggμδ\nδ+o(δ)\nδ/parenrightbigg\nπ1(λ+μ)=π0(λ)+π2(μ)\nλ\nμπ0(λ+μ)=λπ0+μπ2\n⇒π2=/parenleftbiggλ\nμ/parenrightbigg2\nπ0",5069
83-12.3 Generalization and Interpretation.pdf,83-12.3 Generalization and Interpretation,"232 transition to continuous-time markov chains\nRate leave state 2 =Rate enter state 2\nπ2(λδ+o(δ)+μδ+o(δ)) =π1(λδ+o(δ)) +π3(μδ+o(δ))\n...\nπ2(λ+μ)=π1(λ)+π3(μ)\n⇒π3=/parenleftbiggλ\nμ/parenrightbigg3\nπ0\netc.\n6.Look at the format of the equations we are left with for the DTMC . These look\njust like what we would imagine “balance equations” should look like for the\noriginal CTMC:\nπ0(λ)=π1(μ) (12.1)\nπ1(λ+μ)=π0(λ)+π2(μ) (12.2)\nπ2(λ+μ)=π1(λ)+π3(μ) (12.3)\nConsider these in light of our original CTMC, redrawn in Figure 12.8. In the\nbalance equations shown in ( 12.1), (12.2), (12.3),λandμarenotprobabilities,\nbut they behave as if they are with respect to creating the equations.\n1 0λ λλ\n2\nFigure 12.8. Our original CTMC.\n7.So it seems that to solve a CTMC, all one has to do is write out the balance\nequations for the CTMC and solve them . That will result in the same answer\nas solving the δ-step DTMC, which is equivalent to the CTMC. Note that we\nhave only shown that this statement is true for this particular example. In the nextsection we discuss more general chains.\n8.To ﬁnd limiting probabilities via balance (or stationary) equations, we still need\nto ensure that the DTMC is irreducible and aperiodic so that we can apply thetheory of DTMCs (Theorem 9.27). To do so, it sufﬁces to check that the Markov\nchain is irreducible (aperiodicity is not an issue in the continuous case).\n12.3 Generalization and Interpretation\nThe argument we just presented for translating from a CTMC to a DTMC was applied\nto one speciﬁc example. Figure 12.9 provides some intuition for why this argument\nworks for a general CTMC.\n12.3 generalization and interpretation 233\nAssume we start with a general CTMC. Consider a single state ias shown in Figure 12.9.\nThe arcs pointing out of state irepresent Exponential rates. We can model the CTMC as\na DTMC where transitions happen every δ-step. The transition probabilities are shown\nin Figure 12.9. There is a self-loop at state ithat contains the remaining probability\nof leaving state i. Observe that in the DTMC interpretation, there is some probability\nthat when we are in state i, more than one of our coins will come up a success during\na particular ﬂip (single δ-step). However, the probability of such an event is just o(δ).\nIt does not matter how we choose to interpret such an event because the o(δ)washes\nout. We will react to the event of more than one success in a single δ-step by simply\nstaying at state i. Now we solve the DTMC by writing out the balance equations for\nthe DTMC. The limiting probabilities we obtain for the DTMC are also the limiting\nprobabilities of the original CTMC. Observe that in the DTMC shown in Figure 12.9,\nif we are in state i, on most δ-step transitions, we simply return to state i. This exactly\nmodels the CTMC where we sit in state ifor a while.\nDTMC with δ-size time step\nModel it as \nan eq uivalent\nDTMC with\nδ-stepsStart with an arbitrary irred ucible CTMC\n(here s a piece of one)\nRewrite using \no() notation\nTheπi’s are \nthe limitin g probabilities \nfor the CTMC as well !Now solve \nthe DTMC \nby solvin g the \nbalance eqns. λk\nλl\nλjlk\njλlδ(1–λjδ)(1–λkδ)\nλjδ(1–λlδ)(1–λkδ)λkδ(1–λjδ)(1–λlδ)\ni lk\nj\nλlδ+o(δ)\nλjδ+o(δ)λkδ+o(δ)\ni lk\nji\nFigure 12.9. The solution of an arbitrary CTMC using our method.",3348
84-12.4 Exercises.pdf,84-12.4 Exercises,"234 transition to continuous-time markov chains\nThe point to take away from this is that in practice we do not need to go through the\ntranslation to a DTMC with δ-steps. Just think that part and write down the balance\nequations for the CTMC directly, from which we can solve for the πi’s.\n12.3.1 Interpreting the Balance Equations for the CTMC\nWe have been referring to the equations we obtain at the end of the translation as“balance equations.” This name is in fact appropriate because they balance the rate atwhich jobs leave state\njin the CTMC with the rate at which jobs enter state jin the\nCTMC, for each state j. Here is the standard notation for CTMCs:\nπjνj=/summationdisplay\niπiqij (12.4)\nThe left-hand side (LHS) of ( 12.4) is the product of the limiting probability of being\nin state j,πj, and the rate the MC leaves state jgiven that it is in state j,νj. Thus the\nLHS represents the total rate of transitions leaving state j.\nTheith term in the summand of the RHS represents the product of the limiting proba-\nbility of being in state i, πi, and the rate the MC leaves state ito go to state jgiven that\nit is in state i, qij. Thus the ith term in the summand of the RHS represents the rate of\ntransitions leaving state ito go to state j. The RHS therefore represents the total rate\nof transitions entering state jfrom any state.\nObserve that qij=νi·pij. Hence we can equivalently write:\nπj/summationdisplay\niqji=/summationdisplay\niπiqij\n12.3.2 Summary Theorem for CTMCs\nBecause CTMCs can basically be viewed as DTMCs in which the time step goes tozero, all the ergodicity theory that we developed for DTMCs carries over to CTMCs.In particular, we have the following summary theorem, analogous to Theorem 9.27.\nTheorem 12.6 (Summary Theorem for CTMCs) Given an irreducible CTMC,\nsuppose∃πi’s s.t.∀j,\nπjνj=/summationdisplay\niπiqijand/summationdisplay\niπi=1.\nThen the πi’s are the limiting probabilities for the CTMC, and the CTMC is ergodic.\n12.4 Exercises\n12.1 Converting a CTMC to a DTMC\nIn this chapter we saw how to model any CTMC as a DTMC where the timestep in the DTMC is of length\nδ. Draw the corresponding DTMC for the CTMC\n12.4 exercises 235\nin Figure 12.10 . Then write out the DTMC balance equations, take the limit as\nδ→0, and show the resulting CTMC balance equations. You need not solve\nthem.\nλ31λ12\nλ21 λ32λ23\n3 1 2\nFigure 12.10. A simple CTMC.\n12.2 Potential Pitfall: Balance /negationslash=Stationary for CTMC\nRecall that for DTMCs, balance equations are equivalent to stationary equa-\ntions (see Sections 9.6and9.7). For a CTMC, the balance equations yield\nthe limiting probabilities, while the stationary equations are meaningless, un-\nless we ﬁrst translate to a DTMC. We illustrate this point for the CTMC inFigure 12.10 .\n(a) Write all the balance equations for the CTMC:\nπjνj=/summationdisplay\niπiqij where/summationdisplay\niπi=1\n(b) Write all the (meaningless) stationary equations for the CTMC:\nπj=/summationdisplay\niπiqij where/summationdisplay\niπi=1\nObserve that these do not match the balance equations.\n(c) Convert the CTMC to a DTMC, as in Exercise 12.1. Now write the balance\nequations and the stationary equations for the DTMC. Explain why these\nare equivalent.",3262
85-Chapter 13 MM1 and PASTA.pdf,85-Chapter 13 MM1 and PASTA,,0
86-13.1 The MM1 Queue.pdf,86-13.1 The MM1 Queue,"CHAPTER 13\nM/M/1 and PASTA\n13.1 The M/M/1 Queue\nThe simplest queueing model consists of a single server in which the service times are\ni.i.d. Exponential random variables with mean 1/μ, and the customers (jobs) arrive\ninto the system according to a Poisson process with rate λ. Such a system is referred\nto as an M/M/1 queueing system and is shown in Figure 13.1.\nPoisson ( λ) μ\nFigure 13.1. The M/M/1 queueing system.\nM/M/1 is Kendall notation and describes the queueing system architecture. The ﬁrst\nslot characterizes the distribution of the interarrival times for the arrival process. The“M” in this ﬁrst slot stands for “memoryless” and says that the interarrival times are\nExponentially distributed. The second slot characterizes the distribution of the service\ntimes. The “M” in this slot says that the service times of jobs are “memoryless,” namelyExponentially distributed. The third slot indicates the number of servers in the system.For now this is 1, but we will see more complicated examples later. A fourth slot istypically used to indicate an upper bound on the capacity of the system in terms of\nthe total space available to hold jobs. Sometimes, however, the fourth slot is used toindicate the scheduling discipline used for the system. The absence of a fourth ﬁeldindicates that the queue is unbounded and that the scheduling policy is FCFS. Kendallnotation is by no means sufﬁcient to fully describe the characteristics of all queueingsystems. For example, systems where jobs move from one queue to another are not\nrepresented by Kendall notation, but it is a reasonable start for describing single-queue\nsystems.\nThe number of customers in an M/M/1 system forms a continuous-time Markov chain\n(CTMC) where the state of the system corresponds to the number of customers in thesystem. Figure 13.2 shows the transition rate diagram for the M/M/1 system.\nλ λ λ\nμμλλ\nμμμλ\nμ0 2 j j+1 1 0\nFigure 13.2. CTMC for the M/M/1 queueing system.\n236\n13.1 the m/m/ 1queue 237\nThe structure of this chain is referred to as a birth-death process , with the λ’s denoting\nthe “births” and the μ’s denoting the “deaths.” In general, in a birth-death process,\ntransitions are only deﬁned between consecutive states, but the rates of the births (ordeaths) do not have to be homogeneous.\nThe limiting probabilities for the states of the M/M/1 CTMC may be obtained\nby solving the balance equations. Recall that the balance equations equate the\nrate at which the system leaves state\njwith the rate at which the system enters\nstatej.\nQuestion: What is the rate of transitions leaving state 1to go to state 2?\nAnswer: π1λ. Observe that λrepresents the rate of transitions (number of transitions\nper second) that move from any state ito the next higher state, i+1. If we multiply\nbyπ1, we are limiting ourselves to only those upward transitions that occur when the\nchain is in state 1.\nHere are the full balance equations:\nState Balance equation Simpliﬁed equation\n0: π0λ=π1μ ⇒π1=λ\nμπ0\n1: π1(λ+μ)=π0λ+π2μ⇒π2=/parenleftbiggλ\nμ/parenrightbigg2\nπ0\n2: π2(λ+μ)=π1λ+π3μ⇒π3=/parenleftbiggλ\nμ/parenrightbigg3\nπ0\ni:πi(λ+μ)=πi−1λ+πi+1μ⇒???\nWe guess that\nπi=/parenleftbiggλ\nμ/parenrightbiggi\nπ0.\nWe check that this is correct by substituting back into the balance equation for state i,\nas follows:\n/parenleftbiggλ\nμ/parenrightbiggi\nπ0(λ+μ)=/parenleftbiggλ\nμ/parenrightbiggi−1\nπ0λ+/parenleftbiggλ\nμ/parenrightbiggi+1\nπ0μ\nλi+1\nμi+λi\nμi−1√\n=λi\nμi−1+λi+1\nμi\n238 m/m/ 1and pasta\nNext we determine π0such that the equation/summationtext∞\ni=0πi=1is satisﬁed:\n∞/summationdisplay\ni=0πi=1\n⇒∞/summationdisplay\ni=0/parenleftbiggλ\nμ/parenrightbiggi\nπ0=1\n⇒π0/parenleftBigg\n1\n1−λ\nμ/parenrightBigg\n=1\n⇒π0=1−λ\nμ\nTherefore, substituting back into the equation for πiwe obtain\nπi=/parenleftbiggλ\nμ/parenrightbiggi/parenleftbigg\n1−λ\nμ/parenrightbigg\n=ρi(1−ρ)\nπ0=1−λ\nμ=1−ρ\nwhere ρ=λ/μ is the server utilization. It should make sense that π0, the probability\nthat the system is idle, equals 1−ρ.\nObserve that the condition ρ<1must be met if the system is to be stable in the sense\nthat the number of customers in the system does not grow without bound. For this\ncondition to be true, we must have λ<μ .\nThe mean number of customers in the system can be derived by conditioning on the\nstate:\nE[N]=∞/summationdisplay\ni=0iπi\n=∞/summationdisplay\ni=1iπi\n=∞/summationdisplay\ni=1iρi(1−ρ)\n=ρ(1−ρ)∞/summationdisplay\ni=1iρi−1\n=ρ(1−ρ)d\ndρ/bracketleftBigg∞/summationdisplay\ni=0ρi/bracketrightBigg",4551
87-13.2 Examples Using an MM1 Queue.pdf,87-13.2 Examples Using an MM1 Queue,"13.2 examples using an m/m/ 1queue 239\n=ρ(1−ρ)d\ndρ/bracketleftbigg1\n1−ρ/bracketrightbigg\n=ρ(1−ρ)1\n(1−ρ)2\n=ρ\n1−ρ.\nFigure 13.3 plots the equation E[N]=ρ/(1−ρ). Observe that for ρ<0.5or even\nρ<0.6, the mean number of customers in the system hardly goes up. However after\nthat point, it goes up a lot. Also, the impact of increasing ρfrom0.8to0.9is much\ngreater than the impact of increasing ρfrom0.7to0.8.\n246810\n0.2 0.4 0.6 0.8 1.00E[N]\nρ\nFigure 13.3. Plot of the expected number of customers in the M/M/1 system vs. ρ.\nIn Exercise 13.12 , we will prove that the variance of the number of customers in the\nsystem is given by\nVar(N)=ρ\n(1−ρ)2.\nThis grows even more sharply than the mean number of jobs.\nThe mean time in the system and mean time in queue are found using Little’s\nLaw:\nE[T]=E[N]\nλ=1\nμ−λ\nE[TQ]=E[T]−1\nμ=ρ\nμ−λ\n13.2 Examples Using an M/M/1 Queue\nExample: Practice with the Formulas\nQuestion: Given an M/M/1 server, what is the maximum allowable arrival rate of jobs\nif the mean job size (service demand) is 3 minutes and the mean waiting time ( E[TQ])\nmust be kept under 6 minutes?\n240 m/m/ 1and pasta\nAnswer: We are given that μ=1/3jobs/minute. We are also given that the expected\ntime in the system must be less than 9 minutes ( E[T]=E[TQ]+E[S]).\nTherefore,\n1\nμ−λ≤9\n⇒λ≤μ−1\n9=2\n9jobs/min .\nExample: Increasing Arrival and Service Rates Proportionally\nGiven an M/M/1 system (with λ<μ ), suppose that we increase the arrival rate λand\nthe service rate μby a factor of keach.\nQuestion: How are the following affected?\nrutilization, ρ?\nrthroughput, X?\nrmean number in the system, E[N]?\nrmean time in system, E[T]?\nAnswer: We are given that\nλnew=kλ.\nμnew=kμ.\nThis yields\nρnew=kλ\nkμ=λ\nμ=ρold.\nXnew=λnew=kλold.\nE[Nnew]=ρnew\n1−ρnew=ρold\n1−ρold=E[Nold].\nE[Tnew]=1\nμnew−λnew=1\nk(μ−λ)=1\nkE[Told].\nThus the system utilization is unchanged. The throughput is increased by a factor of k.\nThe mean number of jobs in the system is unchanged. The mean response time drops\nby a factor of k.\nThese results should help explain the following quote from Bertsekas and Gallager\n[18]:\nA transmission line ktimes as fast will accommodate ktimes as many packets at k\ntimes smaller average delay per packet.\nThis is a very general result that also holds for any distribution on the service timesand even applies to networks of queues.\n13.2 examples using an m/m/ 1queue 241\nQuestion: Why?\nAnswer: By speeding up both arrivals and service times by a factor of k,w ea r e\nbasically just speeding up our “clock speed” by a factor of k. That is, we can imagine\na system where we make no changes, except for making the time scale a factor of k\nsmaller. Now the number of packets an arriving packet sees ahead of it is the same\nunder both time scales, but response time becomes a factor of ksmaller when time\nis scaled. This is the reasoning we used in the example on the Federation versus the\nKlingons from Chapter 1.\nExample: Statistical Multiplexing vs. Frequency-Division Multiplexing\nSuppose mindependent Poisson packet streams, each with an arrival rate of λ/m\npackets per second, are transmitted over a communication line. The transmission time\nfor each packet is Exponentially distributed with mean1\nμ. We wish to analyze the\nperformance of two different approaches to multiplexing the use of the communication\nline.\nStatistical Multiplexing (SM): This approach merges the mstreams into a single\nstream. Because the merge of mPoisson streams is still a Poisson stream, the\nresulting system may be modeled as a simple M/M/1 queueing system as shown in\nFigure 13.4.\nλ μ\nFigure 13.4. The statistical multiplexing model.\nFrequency-Division Multiplexing (FDM): This approach leaves the mstreams sep-\narated and divides the transmission capacity into mequal portions as shown in\nFigure 13.5.\nλ/m μ/mλ/m μ/mλ/m μ/m\nFigure 13.5. The frequency-division multiplexing model.\nQuestion: How do the two methods compare with respect to mean response time?\nAnswer: The expected time in the system for SM is simply\nE/bracketleftbig\nTSM/bracketrightbig\n=1\nμ−λ.",4132
88-13.3 PASTA.pdf,88-13.3 PASTA,"242 m/m/ 1and pasta\nThe expected time in the system for FDM is\nE/bracketleftbig\nTFDM/bracketrightbig\n=1\nμ/m−λ/m=m\nμ−λ.\nThus the response time is mtimes greater under FDM.\nQuestion: Why would one ever use FDM?\nAnswer: Frequency-division multiplexing guarantees a speciﬁc service rate to each\nstream. Statistical multiplexing is unable to provide any such guarantee. More impor-\ntantly, suppose the original mstreams were very regular (i.e., the interarrival times\nwere less variable than Exponential, say closer to Deterministic than Exponential). By\nmerging the streams, we introduce lots of variability into the arrival stream. This leadsto problems if an application requires a low variability in delay (e.g., voice or video).\nWarning: This is one of those results we may overturn later when we discuss higher\nvariability job sizes.\n13.3 PASTA\nIn later examples we will often be interested in the state of the system as seen from the\nperspective of an arrival.\nTo motivate this discussion, consider that you are running a simulation of some system.\nYou want to determine the fraction of time that the system has njobs. To do this, you\nconsider each arrival into the system and ask whether it sees njobs or not. You then\ntrack the fraction of arrivals that witnessed njobs when arriving into the system. The\nquestion is whether this method gives you the right answer.\nWe’ll assume an ergodic continuous-time system. Let πn=pnbe the limiting proba-\nbility that there are njobs in the system (or equivalently the long-run fraction of time\nthat there are njobs in the system). Let anbe the limiting probability that an arrival\nseesnjobs in the system (or equivalently the long-run fraction of arrivals that see n\njobs). Let dnbe the limiting probability that a departure leaves behind njobs in the\nsystem when it departs (or equivalently the long-run fraction of departures that leave\nbehind njobs).\nQuestion: Isan=pn?\nAnswer: No, according to Claim 13.1.\nClaim 13.1 anis not necessarily equal to pn.1\n1Note: Although the average number of jobs in the system is not necessarily the same as the average number\nseen by an arrival, the average time in system (response time) is by deﬁnition the same as the average response\ntime experienced by an arrival. Similarly, the probability that the response time exceeds xis by deﬁnition the\nprobability that an arrival spends more than xseconds in the system.\n13.3 pasta 243\nProof By example. Consider a single queue whose customers have an interarrival\ntime distributed Uniformly between 1 and 2 (i.e., ∼U(1,2)). Assume that all service\ntimes are constant with a value of 1. Then, a0=1 andd0=1 because a customer\nwill complete service before the next customer arrives. However, p0/negationslash=1 because the\nsystem is not always empty.\nQuestion: Isan=dn?\nAnswer: Yes, according to Claim 13.2.\nClaim 13.2 Assuming that customers arrive one at a time and are served one at a\ntime, then an=dn.\nProof An arrival sees ncustomers already in the system whenever the number of\ncustomers in the system goes from nton+1. A departure leaves ncustomers in the\nsystem whenever the number of customers in the system goes from n+1ton.\nBecause customers arrive one at a time and depart one at a time, these events happen\nan equal number of times (within 1). Because all states are recurrent, each of these\nevents happens an inﬁnite number of times. Thus the proportion of arrivals that ﬁnd n\ncustomers in the system is equal to the proportion of departures that leave ncustomers\nin the system, given that the overall arrival rate equals the overall departure rate.\nWe are now ready for PASTA – “Poisson Arrivals See Time Averages” (see\nFigure 13.6). PASTA states that an=pn, and by Claim 13.2,dn=pn, when the\narrivals follow a Poisson process. We state this as Claim 13.3.\nFigure 13.6. PASTA makes us happy.\nClaim 13.3 If the arrival process to the system is a Poisson process, then an=pn.2\nProof Viewing pnandanas limiting probabilities, we have\npn= lim\nt→∞P{N(t)=n}.\nan= lim\nt→∞P{N(t)=n|an arrival occurred just after time t}.\n2Sometimes the following requirement is appended: “Assume that interarrival times and service times are\nindependent.” This is necessary only for the perverse scenario described in the question at the very end of this\nsection.\n244 m/m/ 1and pasta\nWe show that an=pn. LetA(t, t+δ)be the event that an arrival occurred just after\ntimet. Then,\nan= lim\nt→∞lim\nδ→0P{N(t)=n|A(t, t+δ)}\n= lim\nt→∞lim\nδ→0P{N(t)=n,A(t, t+δ)}\nP{A(t, t+δ)}\n= lim\nt→∞lim\nδ→0P{A(t, t+δ)|N(t)=n}P{N(t)=n}\nP{A(t, t+δ)}(∗)\n= lim\nt→∞lim\nδ→0P{A(t, t+δ)}P{N(t)=n}\nP{A(t, t+δ)}(∗∗)\n= lim\nt→∞P{N(t)=n}\n=pn.\nThe key step where the Poisson process assumption is used is in going between lines\n(*) and (**).\nRemark: All you need to make this proof go through is the fact that A(t, t+δ)is\nindependent of N(t).\nQuestion: Why would this proof notgo through for the example of the Uniform arrival\nprocess with Deterministic job service times?\nAnswer: Consider the case where interarrival times are distributed U(1,2)and job\nservice times are Deterministic, equal to 1. In this case, we cannot move from (*) to\n(**) in the PASTA proof because knowing N(t)affects whether there will be an arrival\nin the next δseconds. In particular if N(t)=1 , then there will notbe an arrival in the\nnextδseconds. By contrast, for the Poisson arrival process, an arrival occurs during\n(t, t+δ)with probability λδ+o(δ)independent of N(t). The fact that an arrival\noccurs tells us nothing about N(t)and vice versa.\nQuestion: Why might we need to make the further assumption (stated in the footnote to\nClaim 13.3) that the interarrival times and service times are independent? Isn’t Poisson\narrivals already saying this?\nAnswer: Imagine the perverse situation where you have Poisson arrivals, but the service\ntimes are correlated to the interarrival times of the arrivals. Speciﬁcally, suppose that\nthe service time of the nth arrival is always set to equal half the interarrival time\nbetween packets nandn+1. In this case, an arrival would ﬁnd the system empty;\nhowever, the time-average number of packets in the system would be1\n2. Note that this\nsituation is purely hypothetical because it is not possible to know the interarrival times\nbetween packets until the next arrival occurs.\nApplication to Simulation\nPASTA is useful in system simulations. If we are simulating a Poisson arrival process\nto some system and would like to know the mean number of jobs in the system, or the",6585
89-13.4 Further Reading.pdf,89-13.4 Further Reading,,0
90-13.5 Exercises.pdf,90-13.5 Exercises,"13.5 exercises 245\nfraction of time the system has njobs, or something of that type, then it sufﬁces to\naverage over what arrivals see at the moment they enter the system. By contrast, if the\narrival process is not Poisson, it is very dangerous to average over what arrivals see,\nbecause that may not be the true time average for the system.\n13.4 Further Reading\nPASTA can be stated much more generally, applying to more than just the numberof jobs in the system. For further reading on PASTA, we recommend Wolff [ 195],\npp. 293–96.\n13.5 Exercises\n13.1 Bathroom queue\nIt is well known that women spend twice as long in the restroom on averageas men.\n3That said, the waiting time, TQ, in the women’s line seems much\nlonger than twice that in the men’s line. Is this an illusion or reality? Model\nthe women’s line as an M/M/1 queue with arrival rate λand service rate μ.\nModel the men’s line as an M/M/1 queue with arrival rate λand service rate\n2μ. Derive the ratio\nE[TQ]women\nE[TQ]men\nas a function of the load ρ=λ\nμin the women’s queue. What is the lowest value\nof this ratio? What is the highest?\n13.2 Server Farm\nIn the server farm shown in Figure 13.7, jobs arrive according to a Poisson\nprocess with rate λand are probabilistically split between two servers, with p\nfraction of the jobs going to server 1, which has service rate μ1, andq=1−p\nfraction going to server 2, which has service rate μ2. Assume that job sizes are\nExponentially distributed. Derive an expression for the mean response time,\nE[T], experienced by arrivals to the server farm.\np\n1–pFCFS\nFCFSμ1\nμ2Poisson ( λ)\nFigure 13.7. Server farm from Exercise 13.2.\n3Women spend 89±7seconds, compared to men’s 39±6seconds [ 62].\n246 m/m/ 1and pasta\n13.3 M/M/1 Simulation\nThis problem is a slight twist on Exercise 4.3. Your job is to simulate an\nM/M/1 queue. You can write your simulator in any programming language.\nSee Chapter 4for techniques for generating the needed random variables. The\nmean job size is 10. The mean arrival rate is λ. Adjust λas needed to create\nthe following three loads – ρ=0.5,ρ=0.7, andρ=0.9– and run your\nsimulator under each load to measure mean response time. Compare your\nresults with the steady-state mean response time derived in this chapter.\n13.4 M/M/1 Number in Queue\nFor an M/M/1 queue with load ρ, prove that\nE[NQ]=ρ2\n1−ρ. (13.1)\n13.5 M/M/1/FCFS with Finite Capacity\nYour system consists of a single CPU with ﬁnite buffer capacity. Jobs arrive\naccording to a Poisson process with rate λjobs/sec. The job sizes are Expo-\nnentially distributed with mean 1/μseconds. Jobs are serviced in FCFS order.\nLetN−1denote the maximum number of jobs that your system can hold in\nthe queue. Thus, including the job serving, there are a maximum of Njobs in\nthe system at any one time (this is called an M/M/1/N queue). If a job arrives\nwhen there are already Njobs in the system, then the arriving job is rejected.\nYour DARPA proposal requires that you reduce the loss probability in your\nsystem. To do this you could either ask for money to double the buffer size,\nor, alternatively, you could ask for money to double the speed of the CPU sothat jobs get processed faster, thereby lowering the probability that there are\nNjobs in the system. Assuming both proposals have the same cost, which do\nyou choose? (Asking for both makes you seem greedy.)\nThese are the speciﬁc questions you should answer:\n(a) Draw the CTMC.\n(b) Derive the limiting probabilities.\n(c) What is the utilization of the system?\n(d) What is the fraction of jobs turned away (loss probability)? Use the word\nPASTA in your explanation.\n(e) What is the rate at which jobs are turned away?\n(f) Derive a closed-form expression for E[Number in system ].\n(g) Determine a closed-form expression for E[T]for only those jobs that enter\nthe system.\n(h) Suppose that N=5, andρ=λ\nμ=.4. Which would have the greater effect\non lowering loss probability: doubling the buffer size or doubling the CPU\nspeed?\n(i) Answer the same question as (h) except now N=5, andρ=λ\nμ=.8.\n(j) Explain intuitively why (h) and (i) resulted in different answers.\n13.6 Admission Control\nConsider the M/M/1 with ﬁnite capacity from Exercise 13.5. Now consider\nthose jobs that are turned away (because there are already Njobs in the\n13.5 exercises 247\nsystem). Is the stream of arrivals that are turned away a Poisson process? Why\nor why not?\n13.7 Open versus Closed Networks\nConsider the closed batch network shown in Figure 13.8(a) and the single-\nserver open network shown in Figure 13.8(b). In (a), Nis often called the\n“multiprogramming level” or “load.” In (b), the load is ρ=λ\nμ.\nUnder what criterion does (a) have higher E[T]than (b)? Express your crite-\nrion in terms of Nandρonly. Also try to explain your ﬁnding.\n(a) Close d N\nFCFS\nμ\n(b) OpenPoisson ( λ) μ\nFigure 13.8. Open and closed systems.\n13.8 More Open versus Closed Systems\nFigure 13.9 shows a closed queueing network and an open one. Job sizes are\nExponentially distributed, where the service rate is shown for each server, and\npdenotes a probability.\n(a) Close d systemN = 1,000\np\n1–pμ = 4 \nμ = 1 \n(b) Open systemPoisson ( λ = 1)p\n1–pμ = 4\nμ = 1 \nFigure 13.9. Figure for Exercise 13.8.\n(i) For the closed system, what value of pminimizes mean response time,\nE[T]?\n(ii) Derive an expression for E[T]for the open system.\n(iii) Does the value of pthat you found in (i) minimize E[T]in the open\nsystem? If yes, give a proof. If no, give a counterexample.\n(iv) Under the optimal pfor the closed system, what is the (approximate)\nthroughput Xfor the closed system?\n(v) Under the optimal pfor the open system, what is Xfor the open\nsystem?\n13.9 M/M/1/2\nConsider an M/M/1/2 (see Exercise 13.5) with arrival rate λ, service rate μ,\nand ﬁnite capacity of 2.D e r i v e E[T1,0], the mean time to go from having one\njob in the system until the system is empty.\n248 m/m/ 1and pasta\n13.10 Busy Period in M/M/14\nA busy period, B, is the time from when the system has 1 job until the system\nis ﬁrst empty. (Obviously, the number of jobs may go up and down a lot in\ngoing from state 1 to state 0.) Your goal is to derive E[B]for an M/M/1.\n(a) Draw the CTMC for the M/M/1 with arrival rate λand service rate μ.\n(b) Write a recurrence relation for E[B]by conditioning on the next state that\nthe CTMC moves to after leaving state 1.\n(c) Solve the recurrence relation for E[B]. What does the expression for E[B]\nremind you of?\n13.11 Response time distribution for M/M/14\nIn this problem, you are asked to derive the distribution of response time for\nan M/M/1 queue with arrival rate λand service rate μ. To do this, think about\nthe response time experienced by an arrival, “job x.” Think about the number\nof jobs that job xsees in the system, and the work associated with each of these\njobs. Then express job x’s response time in terms of these quantities.\n(a) At the time when job xarrives, what is the service requirement (job size)\nfor each job in the queue? What is the remaining service requirement for\nthe job in service, if there is one?\n(b) Let Ndenote the total number of jobs in the system that job xsees when\nit arrives. What is P{N=n}? Use PASTA.\n(c) Consider a new distribution N/primewhere N/primeis the number of jobs in the\nsystem seen by job x, plus itself. What is P{N/prime=n}?\n(d) The distribution N/primehas a name. What is the name of the distribution of\nN/primeand what is the appropriate parameter?\n(e) IfSidenotes the service requirement of the ith job in the M/M/1, we can\nexpress the response time of job xas a sum involving some of the random\nvariables above. Write this sum.\n(f) Fully specify the distribution of response time of job xalong with its\nparameter(s). [Hint: you will need to utilize a result from the exercises inChapter 11.]\n13.12 Variance of the Number of Jobs in an M/M/1\nLet\nNdenote the number of jobs in an M/M/1 with load ρ. Prove that\nVar(N)=ρ\n(1−ρ)2.\n[Hint: It may help to make use of Exercise 3.22.]\n13.13 Back to the Server Farm\nConsider again the server farm from Exercise 13.2. Use what you learned in\nExercise 13.11 to derive expressions for\n(a) the tail behavior of response time, P{T>t}\n(b) variance of response time, Var(T).\n4Warning: This result will be used many times throughout the book.\n13.5 exercises 249\n13.14 Threshold Queue\nWe deﬁne a threshold queue with parameter Tas follows: When the number\nof jobs is <T, then jobs arrive according to a Poisson process with rate λand\ntheir service time is Exponentially distributed with rate μ, where λ>μ (i.e.,\nthe queue is running in overload). However, when the number of jobs is >T,\nthen jobs arrive with Exponential rate μand are served with Exponential rate\nλ.\nFigure 13.10 shows the CTMC for the case of T=2. Compute E[N], the\nmean number of jobs in the system, as a function of T. As a check, evaluate\nyour answer when T=0. Note that when T=0,w eh a v e ρ=μ/λ.\nλ λλqλ λ\n0 3 1 2 4 0\nFigure 13.10. Threshold queue with T=2.",9082
91-Part V Server Farms and Networks Multi-server Multi-queue Systems.pdf,91-Part V Server Farms and Networks Multi-server Multi-queue Systems,"PART V\nServer Farms and\nNetworks: Multi-server,\nMulti-queue Systems\nPartVinvolves the analysis of multi-server and multi-queue systems.\nWe start in Chapter 14with the M/M/k server farm model, where kservers all work\n“cooperatively” to handle incoming requests from a single queue. We derive simple\nclosed-form formulas for the distribution of the number of jobs in the M/M/k. We\nthen exploit these formulas in Chapter 15to do capacity provisioning for the M/M/k.\nSpeciﬁcally, we answer questions such as, “What is the minimum number of servers\nneeded to guarantee that only a small fraction of jobs are delayed?” We derive simpleanswers to these questions in the form of square-root stafﬁng rules. In these twochapters and the exercises therein, we also consider questions pertaining to resource\nallocation, such as whether a single fast server is superior to many slow servers, andwhether a single central queue is superior to having a queue at each server.\nWe then move on to analyzing networks of queues, consisting of multiple servers, each\nwith its own queue, with probabilistic routing of packets (or jobs) between the queues.\nIn Chapter 16we build up the fundamental theory needed to analyze networks of\nqueues. This includes time-reversibility and Burke’s theorem. In Chapter 17, we apply\nour theory to Jackson networks of queues. We prove that these have product form,\nand we derive the limiting distribution of the number of packets at each queue. Ourproofs introduce the concept of Local Balance, which we use repeatedly in derivationsthroughout the book. In Chapter 18, we generalize our analysis to allow for classed\nnetworks, where the route of a packet can depend on its class (type). Chapter 19extends\nthe analysis to closed networks of queues. In the exercises in Chapters 17,18, and 19,w e\nderive further extensions, including networks of servers with load-dependent servicerate, where the speed of the server can depend on the number of jobs in the queue, andnetworks of M/M/k queues, where each service station is a server farm.\nThroughout Part V, to facilitate analysis, we assume Markovian distributions, including\nExponentially distributed service times and Poisson arrival processes. Later in Part VI,\nwe explore more general analysis that does not require Markovian assumptions.\n251",2331
92-Chapter 14 Server Farms MMk and MMkk.pdf,92-Chapter 14 Server Farms MMk and MMkk,,0
93-14.1 Time-Reversibility for CTMCs.pdf,93-14.1 Time-Reversibility for CTMCs,"CHAPTER 14\nServer Farms: M/M/k and\nM/M/k/k\nIn today’s high-volume world, almost no websites, compute centers, or call centers\nconsist of just a single server. Instead a “server farm” is used. The server farm is acollection of servers that work together to handle incoming requests. Each requestmight be routed to a different server, so that servers “share” the incoming load. Froma practical perspective, server farms are often preferable to a single “super-fast” server\nbecause of their low cost (many slow servers are cheaper than a single fast one) andtheir ﬂexibility (it is easy to increase/decrease capacity as needed by adding/removingservers). These practical features have made server farms ubiquitous.\nIn this chapter, we study server farms where there is a single queue of requests and where\neach server, when free, takes the next request off the queue to work on. Speciﬁcally,\nthere are no queues at the individual servers. We defer discussion of models with queues\nat the individual servers to the exercises and later chapters.\nThe two systems we consider in this chapter are the M/M/k system and the M/M/k/k\nsystem. In both, the ﬁrst “M” indicates that we have memoryless interarrival times,and the second “M” indicates memoryless service times. The third ﬁeld denotes that\nkservers share a common pool of arriving jobs. For the M/M/k system, there is no\ncapacity constraint, and this common pool takes the form of an unbounded FCFS\nqueue, as shown later in Figure 14.3, where each server, when free, grabs the job at the\nhead of the queue to work on. For the M/M/k/k system shown in Figure 14.1, there is\na capacity constraint of kjobs. This means that there is no room for a queue. If a job\narrives to ﬁnd all kservers busy, then the job is dropped.\nBecause the analysis of the M/M/k/k is easier, we begin with that, in Section 14.2,\nand then go on to the M/M/k, in Section 14.3. Before we discuss these systems, it will\nbe helpful to revisit the concept of time-reversibility, this time for CTMCs rather than\nDTMCs. We do this in Section 14.1.\n14.1 Time-Reversibility for CTMCs\nWe start by reviewing terminology used in CTMCs.\nQuestion: Can you properly deﬁne the following terms: qij,πiqij,νi,νiPij?\nAnswer: Recall that qijis the rate of transitions from state ito state j, given that the\nCTMC is in state i. That is, qijis the label on the arrow from itojin the Markov\ntransition diagram for the CTMC. If πiis the limiting probability that the CTMC is in\n253\n254 server farms: m/m/ kand m/m/ k/k\nstatei, thenπiqijis the rate of transitions from state ito state j. Likewise πjqjiis the\nrate of transitions from state jto state i.\nRecall also that νiis the total rate of transitions leaving i, given that we are in state\ni, andνiPijdenotes the rate of transitions leaving state iand going to state j,g i v e n\nthat we are in state i, i.e.,νiPij=qij. Thus πiνidenotes the rate of transitions leaving\nstatei, andπiνiPijdenotes the rate of transitions leaving iand going to j.\nRecall the useful time-reversibility theorem for DTMCs, Theorem 9.34, which said\nthat, for an aperiodic and irreducible DTMC, if we can ﬁnd xi’s such that\n/summationdisplay\nixi=1 and xiPij=xjPji,∀i, j\nthen these xi’s are the limiting probabilities. We now prove a counterpart to this theorem\nfor CTMCs.\nDeﬁnition 14.1 AC T M Ci s time-reversible if, for all states iandj, the rate of\ntransitions from state ito state jequals the rate of transitions from state jto state i\n(i.e.,πiqij=πjqji, where/summationtext\niπi=1).\nLemma 14.2 Given an irreducible CTMC, suppose we can ﬁnd xi’s such that\n/summationdisplay\nixi=1 and xiqij=xjqji,∀i, j\nwhere qijis the rate of transitions from state ito state jgiven that the MC is in state\ni. Then,\n1.Thexi’s are the limiting probabilities of the CTMC.\n2.The CTMC is time-reversible.\nProof What we need to prove here is that the xi’s are the πi’s (the limiting probabil-\nities). We are given that, ∀i, j,\nxiqij=xjqji.\nThus,\n/summationdisplay\nixiqij=xj/summationdisplay\niqji\n/summationdisplay\nixiqij=xj/summationdisplay\niνjPji\n/summationdisplay\nixiqij=xjνj/summationdisplay\niPji\n/summationdisplay\nixiqij=xjνj.",4201
94-14.2 MMkk Loss System.pdf,94-14.2 MMkk Loss System,"14.2 m/m/ k/kloss system 255\nSince these are the balance equations for the CTMC, by Theorem 12.6 it then follows\nthat the xi’s must be the πi’s. Thus it further follows that\nπiqij=πjqji,∀i,j\nhence the CTMC is time-reversible.\nQuestion: What is an example of a CTMC that is nottime-reversible?\nAnswer: Consider a chain that has an arc from state ito state jlabeled qij, but no arc\nfrom state jto state i. Then the rate of going from state ito state jisπiqij, but the rate\nof going from state jto state iis zero.\nQuestion: Recall that the M/M/1 chain is a birth-death process. Are all birth-death\nprocesses time-reversible?\nAnswer: Yes. Here’s a proof: First observe that during any period of time, t, the number\nof transitions from state ito state i+1is within 1 of the number of transitions from\nstatei+1to state i. The reason for this is that you cannot repeat going from itoi+1\nwithout ﬁrst going back to iagain – and the only way to go back to state iis to make a\ntransition from i+1toi. Thus the long-run rate of transitions (number of transitions\ndivided by time) from state ito state i+1is equal to the rate of transitions from i+1\ntoi(as time gets big, that “difference of 1” can be ignored).\nAs in the case of DTMCs, it is often helpful to write the time-reversibility equations and\nsee if a solution to these can be found. If so, that solution also represents the limitingdistribution. If not, then one needs to go back to the balance equations. Fortunately, wewill see that the CTMCs for the M/M/k/k and the M/M/k are both birth-death processes,and hence the time-reversibility equations will be solvable.\n14.2 M/M/k/k Loss System\nThe M/M/k/k queueing system is also called the k-server loss system. Jobs arrive\naccording to a Poisson process, with some average arrival rate, λ. Job sizes are Expo-\nnentially distributed with rate μ. There are kservers that can each hold one job. The\nsystem only has capacity for kjobs total; if an arrival shows up and sees all kservers\nalready busy with a job, the arrival is dropped.\nThe M/M/k/k loss system originally arose from the early phone switching systems that\ncould handle at most kcalls simultaneously, as shown in Figure 14.1. An incoming\ncall request could be picked up and serviced by any one of the kcircuits. However, if\nnone of the kcircuits was free, the phone call request was dropped. The duration of a\nphone call was assumed to be Exponentially distributed.\nAnother application for the k-server loss system is a system that maintains virtual\nconnections between nodes A and B in a network. Only kvirtual connections are\nallowed. Each incoming request for a virtual connection is given one; however, if all k\nvirtual connections are in use, the request is rejected.\n256 server farms: m/m/ kand m/m/ k/k\nPhone calls \ncome inPhone call may be serviced \nby any one of the k circ uits.\nHowever, if none is free, \nthe phone call is lost.\nDuration of phone call ~ Exp( μ)μ\nμ\nμServer 1\nServer 2\nServer k\nFigure 14.1. The k-server loss system: M/M/k/k.\nThekey question in these types of systems is, “What is the fraction of jobs that are\nlost?” This fraction is known as the blocking probability ,Pblock. We determine the\nblocking probability by modeling the M/M/k/k queueing system as a CTMC.\nQuestion: What should the state space be?\nAnswer: The state represents the number of busy servers in the system. The CTMC is\nshown in Figure 14.2.\nkλ\n2λλ\n3λ\n2 0 1\nFigure 14.2. An M/M/k/k queueing system modeled using a CTMC. The state represents the\nnumber of busy servers.\nWe solve the time-reversibility equations to determine the limiting probabilities for the\nstates as shown in Table 14.1.\nTable 14.1. Time-reversibility equations for the M/M/k/k\nState Time-reversibility equation Simpliﬁed equation\n0 π0λ=π1μπ 1=λ\nμπ0\n1 π1λ=π22μπ 2=/parenleftBig\nλ\nμ/parenrightBig21\n2!π0\n2 π2λ=π33μπ 3=/parenleftBig\nλ\nμ/parenrightBig31\n3!π0\nk−1πk−1λ=πkkμ π k=/parenleftBig\nλ\nμ/parenrightBigk1\nk!π0\nWe guess that\nπi=/parenleftbiggλ\nμ/parenrightbiggi1\ni!π0. (14.1)\n14.2 m/m/ k/kloss system 257\nWe can verify that this is correct by substituting back into the time-reversibility equation\nforπi. Finally, we determine π0such that the equation/summationtextk\ni=0πi=1is satisﬁed:\nk/summationdisplay\ni=0πi=1\nk/summationdisplay\ni=0/parenleftbiggλ\nμ/parenrightbiggi1\ni!π0=1\n⇒π0=1\n/summationtextki=0/parenleftBig\nλ\nμ/parenrightBigi\n1\ni!\nTherefore, substituting back into equation ( 14.1), we obtain\nπi=/parenleftBig\nλ\nμ/parenrightBigi\n/i!\n/summationtextkj=0/parenleftBig\nλ\nμ/parenrightBigj\n1\nj!.\nThe blocking probability, Pblock, is the probability that an arrival ﬁnds all kservers\nbusy. By PASTA, this is the limiting probability that the chain is in state k. Thus,\nPblock=πk=/parenleftBig\nλ\nμ/parenrightBigk\n/k!\n/summationtextk\nj=0/parenleftBig\nλ\nμ/parenrightBigj\n1\nj!. (14.2)\nEquation ( 14.2) is called the Erlang-B formula.\nQuestion: There is an easy way to remember the formula for Pblockby relating it to the\nPoisson distribution. Can you see what it is?\nHint: Multiply both the numerator and denominator by e−λ\nμ.\nLemma 14.3 LetX∼Poisson/parenleftBig\nλ\nμ/parenrightBig\n.Then\nPblock=e−λ\nμ·(λ\nμ)k/k!\n/summationtextk\nj=0e−λ\nμ·/parenleftBig\nλ\nμ/parenrightBigj\n1\nj!=P{X=k}\nP{X≤k}(14.3)\nThe applicability of the Erlang-B formula stems from the fact that it is independent of\nthe service time distribution. That is, this same formula arises when the service demand\nhas a mean of1\nμwith any probability distribution. This is known as an insensitivity\nresult , because the result depends only on the mean of the distribution. Insensitivity\nresults are always quite striking when they occur, because it is much more typical\nthat queueing behavior is highly inﬂuenced by the distribution of the service time.\nInsensitivity results often occur in situations where there is no queue . We will see\nseveral other insensitivity results during the course of this book.",6037
95-14.3 MMk.pdf,95-14.3 MMk,"258 server farms: m/m/ kand m/m/ k/k\n14.3 M/M/k\nFigure 14.3 illustrates the M/M/k queueing system. As in the ﬁxed-capacity system,\nthekservers draw from the same pool of incoming jobs, except that this time the pool\nhas inﬁnite space. Whenever a server becomes free, it takes the next job from the pool.\nThe “pool” is just an FCFS queue with unbounded capacity.\nServer 1\nServer 2\nServer k\nFigure 14.3. An M/M/k queueing system.\nWe can model the number of jobs in the M/M/k queueing system as a CTMC as shown\nin Figure 14.4.\nkλ\n2λλ\n3λ\n2 0 1λ λ λ\nk+2 k+1\nFigure 14.4. An M/M/k queueing system modeled using a CTMC.\nWe write the time-reversibility equations as shown in Table 14.2.\nTable 14.2. Time-reversibility equations for the M/M/k\nState Time-reversibility equation Simpliﬁed equation\n0 π0λ=π1μπ 1=λ\nμπ0\n1 π1λ=π22μπ 2=/parenleftBig\nλ\nμ/parenrightBig21\n2!π0\n2 π2λ=π33μπ 3=/parenleftBig\nλ\nμ/parenrightBig31\n3!π0\nk−1πk−1λ=πkkμ π k=/parenleftBig\nλ\nμ/parenrightBigk1\nk!π0\nkπ kλ=πk+1kμ π k+1=/parenleftBig\nλ\nμ/parenrightBigk+11\nk!1\nkπ0\nk+1 πk+1λ=πk+2kμ π k+2=/parenleftBig\nλ\nμ/parenrightBigk+21\nk!1\nk2π0\n14.3 m/m/ k 259\nTherefore,\nπi=⎧\n⎪⎪⎨\n⎪⎪⎩/parenleftBig\nλ\nμ/parenrightBigi\n1\ni!π0 ifi≤k\n/parenleftBig\nλ\nμ/parenrightBigi\n1\nk!/parenleftbig1\nk/parenrightbigi−kπ0ifi>k.\nLet’s express these equations in terms of the system utilization.\nQuestion: But what is the system utilization?\nAnswer: For an M/M/k, the system utilization is deﬁned as\nρ=λ\nkμ\nwhere λis the arrival rate into the system in jobs/sec, and kμrepresents the total service\ncapacity of the system in jobs/sec.\nNote: In a typical system, the term “system utilization” is not well deﬁned because\ndifferent devices may be running at different utilizations. The term “utilization” is thustypically reserved for a single device. An M/M/k queue is an exception in that systemutilization is well deﬁned because, by symmetry, the utilization (load) is the same atall servers. Speciﬁcally, consider the fraction of time that a particular server is busy.That server, by symmetry, sees an arrival rate of\nλ\nkand experiences a service rate of μ.\nHence the utilization at that server isλ\nkμ. But this is also the utilization at every server.\nLetRdenote the expected number of busy processors.\nQuestion: What is R?\nAnswer: R=λ/μ. To see this, consider that each server is busy with probabilityλ\nkμ\nand there are kservers. Thus the expected number of jobs in service is\nR=E[number in service ]=k·λ\nkμ=λ\nμ. (14.4)\nObserve that Rcan also be viewed as the minimal resource requirement (i.e., the\nminimum number of servers required to handle the arrival rate). For example, if theaverage arrival rate is\nλ=3 0 jobs/sec, and the service rate of each server is μ=5\njobs/sec, then we have a minimal resource requirement of R=λ/μ=3 0/5=6\nservers needed just to maintain stability.\nThese deﬁnitions are used throughout the book, so we state them again for reference:\nDeﬁnition 14.4 For an M/M/k with average arrival rate λand service rate μ, the\nsystem utilization orload is denoted by ρ, where\nρ=λ\nkμ.\n260 server farms: m/m/ kand m/m/ k/k\nThe resource requirement is denoted by R, where\nR=λ\nμ.\nRcan also be viewed as the minimum number of servers needed to keep the system\nstable, or as the expected number of servers that are busy, or as the expected number\nof jobs in service.\nUsing ρ, we rewrite the equations for πias follows:\nπi=/braceleftBigg(kρ)i\ni!π0ifi≤k\nρi\nk!kkπ0ifi>k\nFinally, we need to determine π0:\nπ0+k−1/summationdisplay\ni=1πi+∞/summationdisplay\ni=kπi=1\nπ0/bracketleftBigg\n1+k−1/summationdisplay\ni=1(kρ)i\ni!+∞/summationdisplay\ni=kρi\nk!kk/bracketrightBigg\n=1\nπ0/bracketleftBiggk−1/summationdisplay\ni=0(kρ)i\ni!+kk\nk!ρk\n1−ρ/bracketrightBigg\n=1\n⇒π0=/bracketleftBiggk−1/summationdisplay\ni=0(kρ)i\ni!+(kρ)k\nk!(1−ρ)/bracketrightBigg−1\nProbability That an Arriving Job Has to Queue\nHaving found the stationary probabilities, we now ﬁnd the probability that an arriving\njob has to queue, PQ. Observe that PQis the probability that an arrival ﬁnds all k\nservers busy.\nPQ=P{An arrival ﬁnds all servers busy }\n=P{An arrival sees ≥kjobs in system }\n=Limiting probability that there are ≥kjobs in system (by PASTA)\n=∞/summationdisplay\ni=kπi\n=kk\nk!π0∞/summationdisplay\ni=kρi\n=(kρ)kπ0\nk!(1−ρ)where π0=/bracketleftBiggk−1/summationdisplay\ni=0(kρ)i\ni!+(kρ)k\nk!(1−ρ)/bracketrightBigg−1\n(14.5)\nEquation ( 14.5) is the famous Erlang-C formula.\n14.3 m/m/ k 261\nIt is interesting to compare the probability that an arrival ﬁnds all servers busy in an\nM/M/k, PQ, with the probability that an arrival ﬁnds all servers busy in an M/M/k/k,\nPblock.\nQuestion: Intuitively, which system will have a higher probability that all kservers\nare busy?\nAnswer: The M/M/k system will.\nQuestion: Why?\nAnswer: In the M/M/k system, jobs can arrive during the time that the kservers are\nbusy. These jobs do not disappear but rather queue up, thus creating more work for\nlater and thus affecting the future probability that the system is busy.\nTheorem 14.5 relates the blocking probability for the M/M/k/k to the queueing proba-\nbility for the M/M/k.\nTheorem 14.5 LetPblockdenote the blocking probability for the M/M/k/k and PQ\nthe queueing probability for the M/M/k. Let ρdenote the load (system utilization)\nfor the M/M/k. Then\nPblock=(1−ρ)PQ\n1−ρPQ. (14.6)\nProof Observing that the M/M/k/k chain is contained within the M/M/k chain, we\nhave\nPM/M/k/k\nblock =P{N=k|N≤k}M/M/k\n=P{N=k}M/M/k\nP{N≤k}M/M/k\n=P{N≥k}M/M/k−P{N>k}M/M/k\n1−P{N>k}M/M/k\n=PQ−ρPQ\n1−ρPQ\nwhere the last line follows from the fact that, beyond state k, the M/M/k looks like an\nM/M/1 with load ρ, hence P{N>k}M/M/k=ρ·P{N≥k}M/M/k.\nExpected Number in the Queue\nWe can now calculate the expected number in the queue portion of the M/M/k:\nE[NQ]M/M/k=∞/summationdisplay\ni=kπi(i−k)\n=π0∞/summationdisplay\ni=kρikk\nk!·(i−k)\n262 server farms: m/m/ kand m/m/ k/k\n=π0ρkkk\nk!∞/summationdisplay\ni=kρi−k·(i−k)\n=π0ρkkk\nk!∞/summationdisplay\ni=0ρi·i\n=π0ρkkk\nk!·ρ·1\n(1−ρ)2\n=PQρ\n1−ρ\nQuestion: Explain why\nE[NQ]=PQρ\n1−ρ.\nAnswer:\nE[NQ]=E[NQ|queueing ]·P{queueing}\n+E[NQ|no queueing ]·P{no queueing }.\nBut\nE[NQ|no queueing ]=0.\nSo\nE[NQ]=E[NQ|queueing ]·PQ.\nNow consider the CTMC for the M/M/k, given that there is queueing. That CTMC looks\nidentical to the CTMC for an M/M/1, where the M/M/1 has arrival rate λand service\nratekμ. Speciﬁcally, E[NQ|queueing ]for the M/M/k is just the expected number\nof jobs in system for an M/M/1 queue, where the M/M/1 queue has load ρ=λ\nkμand\nmean number of jobsρ\n1−ρ.S o ,\nE[NQ]=ρ\n1−ρ·PQ. (14.7)\nFinishing up, we can derive the remaining performance metrics for the M/M/k easily\nas follows:\nE[TQ]=1\nλ·E[NQ]=1\nλ·PQ·ρ\n1−ρ(14.8)\nE[T]=E[TQ]+1\nμ=1\nλ·PQ·ρ\n1−ρ+1\nμ(14.9)\nE[N]=λ·E[T]=PQ·ρ\n1−ρ+kρ (14.10)\nAs a check, observe that\nE[Number being served ]=E[N]−E[NQ]=kρ=λ\nμ=R.\nThis is the expected result from ( 14.4).",7018
96-14.5 Readings.pdf,96-14.5 Readings,"14.4 comparison of three server organizations 263\n14.4 Comparison of Three Server Organizations\nConsider the following three different server organizations, all having arrival rate λ,\ntotal service rate kμ, and load ρ=λ\nkμ, shown in Figure 14.5. Under frequency-division\nmultiplexing (FDM), trafﬁc is split into kseparate channels. Under the M/M/k, the\ntrafﬁc is lumped together, but the service capacity is split. Under the M/M/1, nothing is\nsplit. We want to determine which of these conﬁgurations is best for minimizing mean\nresponse time.\nM/M /1 M/M/k\nλ kμFrequency-division\nmultiplexing\nλ/k μλ/k μλ/k μ\nμλ μμ\nFigure 14.5. Frequency-division multiplexing, M/M/1, and M/M/k, all with load ρ=λ\nkμ.\nQuestion: Which is better in terms of mean response time: FDM or the M/M/1?\nAnswer: Obviously the M/M/1. Each job experiences a ktimes higher arrival rate\nunder the M/M/1, but also a ktimes higher service rate. Thus we expect the mean\nresponse time to be ktimes lower for the M/M/1. Computing these response times, we\nhave:\nE[T]FDM=1\nμ−λ\nk=k\nkμ−λ. (14.11)\nE[T]M/M/1=1\nkμ−λ. (14.12)\nBy comparing equations ( 14.11 ) and ( 14.12 ), it is obvious that M/M/1 is ktimes better\nthan FDM.\nQuestion: How does the M/M/1 system compare with the M/M/k system?\nAnswer: Recall that for the M/M/k, from (14.9)\nE[T]M/M/k=1\nλ·PQ·ρ\n1−ρ+1\nμ\nwhere ρ=λ\nkμ, andPQis the probability an arrival is forced to queue.",1427
97-14.6 Exercises.pdf,97-14.6 Exercises,"264 server farms: m/m/ kand m/m/ k/k\nTo compare the M/M/k with the M/M/1, consider\nE[T]M/M/k\nE[T]M/M/1=1\nλ·PQ·ρ\n1−ρ+1\nμ\n1\nλ·ρ\n1−ρ\n=PM/M/k\nQ+λ\nμ·1−ρ\nρ\n=PM/M/k\nQ+k(1−ρ). (14.13)\nNow consider two cases.\nCase 1: ρ≈0\nAs the load drops, the probability of queueing drops, so PM/M/k\nQ≈0, and expression\n(14.13 ) is approximately 0+k=k. Thus, the M/M/1 is ktimes faster than M/M/k.\nQuestion: Explain intuitively why this makes sense.\nAnswer: In the M/M/k, under light load, most servers are idle. The few servers that\nare busy serve the jobs they get at rate μ. By contrast, in the M/M/1, with the same light\nload, every job gets served with rate kμ. Thus jobs complete more quickly in the M/M/1.\nCase 2: ρ≈1\nWith the load high, PM/M/k\nQ≈1, and so expression ( 14.13 ) is approximately 1. Thus,\nthe M/M/k and M/M/1 have the same response time.Question: Explain why this makes sense.\nAnswer: Because the load is high, there are always jobs in the queue. Thus, the state\nof the CTMC for the M/M/k is always greater than\nk. This portion of the CTMC looks\nlike Figure 14.6. Thus the M/M/k under high load behaves just like an M/M/1 with\narrival rate λand service rate kμ.\nλ\nkμλ\nkμk\nFigure 14.6. M/M/k queue under high load.\n14.5 Readings\nWe stated that the k-server loss system exhibits an interesting insensitivity property,\nwhereby the distribution of the number of jobs in the loss system depends only on the\nmean job size, not on its distribution. For a unique and interesting proof of the insensitiv-\nity property for this system and several others, we refer the reader to [ 178], pp. 202–09.\n14.6 Exercises\n14.1 Comparison of Three Server Organizations\nRepeat the comparison of three server organizations from Section 14.4. This\ntime, however, assume k=2and derive exact closed-form formulas for E[T]\nfor each of the three architectures shown in Figure 14.5.\n14.6 exercises 265\n14.2 Scherr’s Thesis 1965\nOnce upon a time, back in 1965, an MIT student named Allan Scherr needed\nto analyze the Compatible Time-Sharing System (CTSS). CTSS was an early\ntime-sharing system in which user programs were swapped in and out of main\nmemory with only one complete program in memory at a time. Because therewas no overlap of program execution and swapping, Scherr modeled the sumof the program execution time and swapping time as the CPU service time,\nS.\nHe modeled the CTSS as a simple interactive system with Nterminals and\none CPU as shown in Figure 14.7. For Scherr’s system, Nwas60, the mean\nCPU service time was E[S]=0.8seconds, and the mean user think time\nwasE[Z]=3 5 seconds. To determine the mean response time of the system,\nE[R], Scherr made the false assumption that ZandSwere Exponentially\ndistributed random variables. This assumption allowed him to set up a CTMC\nand solve for the mean response time of the system. Everyone was surprised\nwhen the mean response time that Scherr got via his analysis was in fact\nvery close to the measured mean response time of the system, given all hissimpliﬁcations, so Scherr got a PhD and won a bunch of awards. His thesis isonline. Don’t you wish it was still 1965?\nN = 60\nE{Z} = 35 seconds\nE{S} = .8 secondsCPU\nFigure 14.7. Scherr’s CTSS model.\n(a) Solve Scherr’s problem as he did, by making the Exponential assumptions\nand setting up a CTMC. Determine the limiting probabilities (can you apply\nthe time-reversibility equations?). Write out an expression for E[R].N o w\nplug in Scherr’s numbers and determine E[R](you will need to write a\nsmall program to do the sum).\n(b) Now use operational analysis (see Chapters 6and7), which is distribution-\nindependent , to obtain asymptotic bounds for E[R]in Scherr’s problem\n(remember to determine N∗).\nIf you have done it all right, you may be wondering at this point why Scherrhimself did not use operational analysis. Turns out operational analysis did not\nexist until the early 1970s.\n14.3 M/M/2/3\nFigure 14.8 shows a 2-server system with a waiting room that can hold only 1\njob. Any arrival that sees\n3jobs already in the system is dropped. Jobs arrive\nfrom outside according to a Poisson process with rate λ=1. Whenever a\nserver ﬁnishes serving a job, it grabs the job from the waiting area, if there is\none. Job sizes are Exponentially distributed with rate μ=1.\n266 server farms: m/m/ kand m/m/ k/k\nPoisson ( λ)μ\nμ\nFigure 14.8. The M/M/2/3 system.\n(a) Draw a CTMC where the state represents the total number of jobs in the\nsystem.\n(b) Suppose that there are exactly 2 jobs in the system. What is the probability\nthat a job arrives before a job completes?\n(c) Use your CTMC to determine the probability that the system is idle (both\nservers are idle).\n(d) What is the throughput of the system?\n(e) What is E[N], the expected number of jobs in the system?\n(f) What is E[T], the expected response time (for those jobs not dropped)?\n(g) Consider the process of arrivals to the system that are not dropped. Is this\na Poisson process? Why or why not?\n14.4 The Inﬁnite Help Desk (M/M/ ∞)\nImagine that you could call up a company for customer service and neverget the message, “We’re sorry; all of our service representatives are busywith other customers ...” This can be modeled by a queueing system with an\ninﬁnite number of servers.\nConcretely, consider the M/M/\n∞queueing system, where interarrival times\nare Exponential with rate λand the service times are Exponential with rate μ,\nbut where there are an inﬁnite number of servers ( k=∞).\n(a) Draw a state diagram for the continuous-time Markov chain of this\nsystem.\n(b) Derive the limiting probabilities. You need to get a closed-form expression\nhere that is simple and easy to recognize.\n(c) From the limiting probabilities, derive a closed-form expression for the\nexpected number of jobs in the system, E[N].\n(d) Applying Little’s Law gives you E[T]. DoesE[T]make sense? Explain.\n14.5 M/M/2 with Heterogeneous Servers\nConsider a variant of the M/M/2 queue where the service rates of the twoprocessors are not identical. Denote the service rate of the ﬁrst processor by\nμ1\nand the service rate of the second processor by μ2, where μ1>μ 2. In the case\nof heterogeneous servers, the rule is that when both servers are idle, the fasterserver is scheduled for service before the slower one. Deﬁne the utilization,\nρ,\nfor this system to be ρ=λ\nμ1+μ2.\nSet up a CTMC and determine the mean number of jobs in the system and the\nmean response time. You should get\nE[N]=1\nA(1−ρ)2(14.14)\n14.6 exercises 267\nwhere\nA=μ1μ2(1 + 2 ρ)\nλ(λ+μ2)+1\n1−ρ. (14.15)\n14.6 Is Load Balancing Good? +More on Closed vs. Open Systems\nConsider the server farm shown in Figure 14.9. The arrival stream is a Poisson\nprocess with rate λ, and job sizes are Exponentially distributed. Each job with\nprobability pis sent to Host 1, which has service rate μ1, and with probability\n1−pis sent to Host 2, which has service rate μ2. There is a queue at each\nhost.\n(a) Assume μ1=μ2. Either prove or disprove that E[TQ]andE[T]are\nalways minimized when pis chosen to balance the load.\n(b) Now assume μ1/negationslash=μ2. Either prove or disprove that E[TQ]andE[T]are\nalways minimized when pis chosen to balance the load.\n(c) Continue to assume μ1/negationslash=μ2, but now suppose that we have a closed sys-\ntem with zero think time and large MPL, N, where Figure 14.9 represents\nthe central subsystem in the closed system. Either prove or disprove that\nE[TQ]andE[T]are always minimized when pis chosen to balance the\nload.\np\n1–pFCFS\nFCFSμ1\nμ2Poisson ( λ)\nFigure 14.9. Distributed server system.\n14.7 Throwing Away Servers\nSuppose your computer center currently consists of a single server of speed μ.\nJobs arrive according to a Poisson process with rate λ, and their service times\nare Exponentially distributed.\nSuppose the current response time is considered intolerable by the users. A\nsecond, faster server, running at speed αμ(forα>1), is purchased and added\nto the system in a heterogeneous M/M/2 structure with a single queue as in\nExercise 14.5. Denote the load (utilization) of the M/M/2 system by ρ. Denote\nthe mean response time of the M/M/2 system by E[T].\n(a) Use the result in ( 14.14 ) from Exercise 14.5 to derive a formula for E[T],\nthe mean response time of the M/M/2 system with heterogeneous servers.\n(b) A hotshot consultant walks in and makes the radical proposal of discon-\nnecting the original server entirely (i.e., simply letting the faster server run\nby itself). Clearly this makes sense with respect to power, but the consul-tant claims this is also a win for\nE[T]. For $400/hr, what is the consultant\nthinking? Come up with an instance, in terms of λ,μ2, andμ1for which\nthe consultant is right. Also, explain intuitively what is happening. [If you\n268 server farms: m/m/ kand m/m/ k/k\nﬁnd this problem interesting, you can think about a general criterion under\nwhich the consultant would be right . . . Throwing away servers is fun!]\n14.8 Comparison of Multi-server Architectures with Heterogeneous Servers\nThis problem asks you to apply ( 14.14 ), but does not require you to have solved\nExercise 14.5. Consider four different server conﬁgurations. In all of these the\noutside arrival process is Poisson with rate λ. Also the service time at Host 1\n(respectively, Host 2) is Exponentially distributed with rate μ1(respectively,\nμ2), where μ1=αμ2,α≥1.\n(1) An M/M/2 heterogeneous server system.(2) A server farm consisting of two hosts, each with its own queue. Every\nincoming job is immediately dispatched to Host 1 (with probability\np)\nor to Host 2 (with probability 1−p). The probabilities pand1−pare\nchosen so as to balance load at the two hosts.\n(3) A server farm consisting of two hosts, each with its own queue. Every\nincoming job is immediately dispatched to Host 1 (with probability p)\nor to Host 2 (with probability 1−p). The probabilities pand1−pare\nchosen so as to minimize mean response time .\n(4) A server farm consisting of two hosts, each with its own queue. Every\nincoming job is immediately dispatched to Host 1 (with probability p)o r\nto Host 2 (with probability 1−p), where we set p=1.\nObserve that\nρ=λ\nμ1+μ2=λ\nαμ2+μ2.\nNow consider the following table:\nρ=low=0.25ρ=high=0.75\nTwo identical hosts: Fill in... Fill in...\nμ1=μ2=1 (useλ=0.5) (useλ=1.5)\nHost 1 is faster: Fill in... Fill in...\nμ1=4,μ2=1 (useλ=1.25) (useλ=3.75)\nYour job is to ﬁll in each entry of this table with a ranking of the four server con-\nﬁgurations in order from greatest mean response time to least mean response\ntime; for example,\nTconﬁg1>T conﬁg2=Tconﬁg3>T conﬁg4.\nYou may use “ >”o r“=” signs, but may notuse ambiguous signs like ≥.\nNote : For conﬁguration (4) observe that the correspondence between ρandλ\ndoes not make sense. Thus when evaluating conﬁguration (4) please just use\ntheλvalue.\nIt will help if you ﬁrst try to think about the problem using intuition. Feel free\nto use Mathematica to compare your expressions.",11045
98-Chapter 15 Capacity Provisioning for Server Farms.pdf,98-Chapter 15 Capacity Provisioning for Server Farms,,0
99-15.1 What Does Load Really Mean in an MMk.pdf,99-15.1 What Does Load Really Mean in an MMk,"CHAPTER 15\nCapacity Provisioning for\nServer Farms\nIf servers were free, then every server farm would have an inﬁnite number of servers,\nand no job would ever have to wait in a queue. Unfortunately, servers are not free tobuy, and they are also not free to operate. Running servers consumes lots of power, andeven leaving a server on, but idle, still consumes nearly 60% of the power consumedby a busy server [ 15]. Given these costs, it pays to spend some time thinking about\nhow many servers one really needs. This subject is called capacity provisioning .\nObserve that we can actually already, in theory, answer the question of how many\nservers we need to achieve a given Quality of Service (QoS) goal, based on theformulas we derived in Chapter 14. In that chapter, we considered the M/M/k server\nfarm model and derived expressions for the distribution of the number of jobs in the\nsystem, the probability of queueing,\nPQ, and the expected response time, E[T].G i v e n\na QoS constraint on E[T]orPQ, we can iterate over these formulas and deduce the\nexact number of servers, k, needed to achieve the desired constraint.\nHowever, iterating over a formula is time consuming and also does not provide any\nintuitions for the result. The purpose of this chapter is to formulate intuitions and rules\nof thumb for understanding how many servers we need to achieve a certain QoS goal,\nand what the impact is of increasing the number of servers.\nAs usual, we build up to the question with discussions aimed at honing our intuition.\nWe start in Section 15.1 by trying to get a better understanding of what load means in a\nmulti-server system. We ﬁnd that, in an M/M/k, having high load does not necessarilyimply high delay. In Section 15.2, we introduce the concept of a server farm with an\ninﬁnite number of servers, the M/M/\n∞. Although this does not exist in the real world,\nthis hypothetical system will simplify many future proofs and will give us a ﬁrst cut\nat a capacity provisioning rule. The chapter culminates in the famous “square-rootstafﬁng rule,” described and proved in Section 15.3, which will provide a very good\napproximation for the number of servers needed in an M/M/k as a function of QoS\ngoals. In the exercises we explore additional QoS goals, such as the 95th percentile ofresponse time.\n15.1 What Does Load Really Mean in an M/M/k?\nA common rule of thumb for a single-server M/M/1 system is that the utilization, ρ,\nshould be kept below 0.8.I fρgets higher (e.g., ρ=0.95), delays explode. For example,\nwithρ=0.8,E[N]for an M/M/1 is 4, whereas for ρ=0.95,E[N]=1 9 . In this\n269\n270 capacity provisioning for server farms\nsection we ask whether this rule of thumb of ρ<0.8makes sense for a multi-server\nM/M/k system as well.\nConsider the formula from ( 14.8) for an M/M/k system:\nE[TQ]M/M/k=1\nλPQρ\n1−ρ(15.1)\nHereρ=λ\nkμrepresents the load or system utilization (see Deﬁnition 14.4). It is hard\nto get a feel for how E[TQ]behaves, because there is a PQfactor, which we also do\nnot have a handle on yet. For convenience, let’s therefore consider a slightly different\nmetric that washes out the PQfactor:E[TQ]/PQ.\nQuestion: What does E[TQ]/PQrepresent?\nAnswer: Observe that\nE[TQ]=E[TQ|delayed ]·PQ+E[TQ|not delayed ]·(1−PQ)\n=E[TQ|delayed ]·PQ.\nThus,\nE[TQ]\nPQ=E[TQ|delayed ].\nNamely, E[TQ]/PQrepresents the expected waiting time of those customers who\nare delayed.\nNow observe from ( 15.1) that\nE[TQ]\nPQ=E[TQ|delayed ]=1\nλ·ρ\n1−ρ=1\nkμ(1−ρ). (15.2)\nSuppose that we now ﬁx ρto be some constant. Then we ﬁnd that the expected waiting\ntime of those customers who are delayed drops in direct proportion to the number of\nservers, k.\nThetake-home message is that high values of system utilization, ρ, do not imply that\ncustomers will suffer, provided that there are sufﬁciently many servers.\nFor example, we might have an average server utilization of ρ=0.95with 5 servers.\nIn this case, the average wait for customers who are delayed is1\n5μ(.05)=4\nμ, namely\n4 times a job size. By contrast, we could have the same average server utilization of\nρ=0.95with 100 servers. In this case, the average wait experienced by customers\nwho are delayed is only1\n100μ(.05)=1\n5μ, namely a ﬁfth of a job size.\nQuestion: Why does having more servers help, given that ρ, the average server utiliza-\ntion, stays the same?\nAnswer: Even if all servers still have utilization ρ, with more servers it is less likely\nthat they are allbusy at the same time. Hence it is more likely that an arrival ﬁnds a\nfree server.\nQuestion: Haven’t we seen an analogous result for a single-server system?",4647
100-15.2 The MM.pdf,100-15.2 The MM,"15.2 the m/m/∞ 271\nAnswer: Yes, even in an M/M/1, if we hold ρconstant, but increase both λandμby\nthe same factor, then delay will drop indeﬁnitely.\n15.2 The M/M/ ∞\nWe start, in Section 15.2.1 , by imagining a server farm with an inﬁnite number of\nservers. Although this is somewhat unrealistic, it will lead us to a good ﬁrst cut at an\napproximation for capacity provisioning, which we describe in Section 15.2.2 .\n15.2.1 Analysis of the M/M/ ∞\nImagine that you could call up the phone company for customer service, and never getthe message, “We’re sorry, but all of our service representatives are busy serving othercustomers ...”\nThis dream situation can be modeled by a queueing system with an inﬁnite number\nof servers, so that there is always a server to take your call. Such a system is called\nthe M/M/\n∞queueing system. The interarrival times are Exponential with rate λ, the\nservice times are Exponential with rate μ, and there are an inﬁnite number of servers.\nWe are interested in deriving the probability distribution of the number of jobs in such\na system.\nQuestion: What does the state diagram look like for the M/M/ ∞?\nAnswer: The Markov chain for the system is shown in Figure 15.1.\nλ\n2μλλ\n3μ 4μλ\nμ2 0 13\nFigure 15.1. CTMC for the M/M/ ∞system.\nQuestion: You should be able to solve this for the limiting probabilities. Can you\nexpress the limiting probabilities via a closed-form expression that is simple and\nclearly recognizable as something you have seen before?\nAnswer: To derive the limiting probabilities, we set up the time-reversibility equations:\nπ1=λ\nμπ0\nπ2=λ\n2μπ1=λ\n2μ·λ\nμ·π0\nπ3=λ\n3μπ2=λ\n3μ·λ\n2μ·λ\nμ·π0\n272 capacity provisioning for server farms\nBased on this, a good guess for the limiting probabilities is\nπi=/parenleftbiggλ\nμ/parenrightbiggi\n·1\ni!·π0.\nYou should recognize this distribution as being the Poisson distribution with meanλ\nμ,\nwhere\nπ0=e−λ\nμ.\nQuestion: From the limiting probabilities, derive a closed-form expression for the\nexpected number of jobs in the system, E[N].\nAnswer:\nNumber of jobs in the M/M/ ∞∼ Poisson/parenleftbiggλ\nμ/parenrightbigg\n. (15.3)\nThe mean of this distribution is\nE[N]=λ\nμ.\nQuestion: Applying Little’s Law gives us E[T]. DoesE[T]make sense?\nAnswer: By Little’s Law,\nE[T]=E[N]\nλ=1\nμ.\nThus the mean response time is just the mean service time. This makes sense, because\njobs do not ever have to queue up!\nQuestion: We have actually seen the M/M/ ∞before when we discussed closed sys-\ntems. Where was this?\nHint: What happens in a closed interactive system?\nAnswer: The think station in a closed interactive system is an M/M/ ∞, where the\nmean “service time” is the mean time spent thinking.You may be worrying that the think time is not necessarily Exponentially distributed.\nHowever, this does not matter because the M/M/\n∞is insensitive to the distribution of\nservice time (see Exercise 15.7).\n15.2.2 A First Cut at a Capacity Provisioning Rule for the M/M/k\nOur goal is to understand how many servers, k, we need in an M/M/k so as to keep the\nprobability of queueing, PQ, below some level, say 20%.\nQuestion: If the average arrival rate is λ, and the average service rate at each server\nisμ, what is the minimum number of servers, k, needed just to keep the system\nstable?\n15.2 the m/m/∞ 273\nAnswer: We need\nρ<1\n⇒λ\nkμ<1\n⇒k>λ\nμ.\nObserve thatλ\nμcan be a fraction, in which case we would actually have to round up to\nthe next integer.\nWe have seen this expression before in Deﬁnition 14.4, which we repeat here for\nreference.\nDeﬁnition 15.1 (Repeated from Deﬁnition 14.4)For an M/M/k with average\narrival rate λand service rate μ, the resource requirement is denoted by R, where\nR=λ\nμ.\nRcan be viewed as the minimum number of servers needed to keep the system\nstable, or as the expected number of servers that are busy, or as the expected number\nof jobs in service.\nWe now argue that, if Ris a large number, then by using relatively few servers more\nthanR, namely\nk=R+√\nR\nservers, we can get PQdown below the 20% range. Our argument is based on the\nM/M/∞queue.\nQuestion: What is the probability of having more than R+√\nRjobs in the M/M/ ∞?\nAnswer: As we saw in ( 15.3), the number of jobs in the M/M/ ∞is Poisson distributed\nwith mean R. Given that Ris large, the Poisson (R)distribution is well approximated\nby a Normal (R,R)distribution (see Feller [ 57], p. 245). Hence, we are asking what is\nthe probability that the Normal (R,R)distribution is more than one standard deviation\nabove its mean. This is simply the probability that the standard Normal exceeds its\nmean by more than one standard deviation, namely 1−Φ(1) , or about 16%.1\nThus, for an M/M/ ∞the probability that we use more than R+√\nRservers is only\n16%. But the question we really wanted to answer was how many servers we need in\nan M/M/k, not an M/M/ ∞!\nQuestion: Is the M/M/∞result an upper bound or a lower bound on the M/M/k?\nAnswer: When a lot of work arrives, the M/M/ ∞has more resources available for\nclearing this work than the M/M/k has (the work may have to queue in the M/M/k).\n1Normal distributions are covered in Section 3.14.",5195
101-15.3 Square-Root Staffing.pdf,101-15.3 Square-Root Staffing,"274 capacity provisioning for server farms\nHence the fraction of time that the M/M/ ∞has more than xservers busy is going to\nbe lower than the fraction of time that the M/M/k has more than xservers busy. Hence\n16% is a lower bound. In fact, as we see in the next section, when using k=R+√\nR\nservers in the M/M/k, PQis about 20%.\n15.3 Square-Root Stafﬁng\nIn this section, we reﬁne the R+√\nRapproximation developed in the previous section.\nAs before, we assume an M/M/k with average arrival rate λand average server speed\nμ. The QoS goal that we set is that PQ, the probability of queueing in the M/M/k,\nshould be below some given value α(e.g.,α= 20% ). Our goal is to determine the\nminimal number of servers, k∗\nα, needed to meet this QoS goal.\nNote that bounding PQis really equivalent to bounding mean response time or mean\nqueueing time, or similar metrics, because they are all simple functions of PQ(e.g.,\nfrom ( 14.9), we have E[TQ]=1\nλ·PQ·ρ\n1−ρ).\nTheorem 15.2 (Square-Root Stafﬁng Rule) Given an M/M/k with arrival rate λ\nand server speed μandR=λ/μ, where Ris large, let k∗\nαdenote the least number\nof servers needed to ensure that PM/M/k\nQ<α. Then\nk∗\nα≈R+c√\nR,\nwhere cis the solution to the equation,\ncΦ(c)\nφ(c)=1−α\nα(15.4)\nwhere Φ(·)denotes the c.d.f. of the standard Normal and φ(·)denotes its p.d.f.\nRemark: It is interesting to observe that the constant cin Theorem 15.2 does not\ndepend on Ror the arrival rate λ. Also, in practice, cis quite small. A good rule of\nthumb to remember is that when α=0.2,c≈1. Thus, to ensure that only 20% of\njobs queue up, it sufﬁces to use just k=R+√\nRservers, where Ris the number of\nservers needed to just maintain stability. Here are a few more values:\nα=0.8α=0.5α=0.2α=0.1\nc=0.173 c=.506 c=1.06c=1.42\nRemark: In Exercise 15.3, you will be asked to derive k∗\nαboth (i) via the approximation\nin Theorem 15.2 and (ii) exactly by evaluating the PM/M/k\nQ at different values of k. What\nyou will ﬁnd is that the approximation in Theorem 15.2 is exact or off by at most 1,\neven for very low R, like 1. This is surprising, because the proof of Theorem 15.2\nassumes large R. Thus Theorem 15.2 even works well for stafﬁng small server farms.\n15.3 square-root stafﬁng 275\nProof (Square-Root Stafﬁng) Our approach is to express PQin terms of Pblockand\ndetermine a simple approximation for Pblock. This may seem logically confusing, since\nPQrefers to the M/M/k, while Pblockis the blocking probability for the M/M/k/k (see\nChapter 14). However, our approach is just an algebraic maneuver, since Pblockis easy\nto derive and will thus quickly yield an approximation for PQ. Recall from ( 14.6) that\nPblock=(1−ρ)PQ\n1−ρPQ.\nThis allows us to express PQin terms of Pblockas follows:\nPQ=Pblock\n1−ρ+ρPblock=kPblock\nk−R+RP block. (15.5)\nWe now turn to deriving Pblock.\nIf we let XRdenote a random variable with Poisson distribution and mean R, then we\ncan use ( 14.3) to express Pblockas\nPblock=P{XR=k}\nP{XR≤k}.\nThese latter expressions involving XRcan be simply expressed if we use the fact\nthat the Poisson distribution of mean Rcan be well approximated by the Normal\ndistribution of the same mean and variance R, provided that Ris large. Speciﬁcally,\nsetting\nk=R+c√\nR,\nwe see that\nP{XR≤k}=P/braceleftBig\nXR≤R+c√\nR/bracerightBig\n≈P/braceleftBig\nNormal (R,R)≤R+c√\nR/bracerightBig\n=P{Normal (0,1)≤c}\n=Φ (c).\nP{XR=k}=P{XR≤k}−P{XR≤k−1}\n≈Φ(c)−P/braceleftBig\nXR≤R+c√\nR−1/bracerightBig\n=Φ (c)−P/braceleftbigg\nXR≤R+√\nR/parenleftbigg\nc−1√\nR/parenrightbigg/bracerightbigg\n≈Φ(c)−Φ/parenleftbigg\nc−1√\nR/parenrightbigg\n≈1√\nRφ(c)(again, we are assuming R: large) .",3670
102-15.4 Readings.pdf,102-15.4 Readings,,0
103-15.5 Exercises.pdf,103-15.5 Exercises,"276 capacity provisioning for server farms\nThus we have\nPblock=P{XR=k}\nP{XR≤k}≈φ(c)√\nRΦ(c). (15.6)\nReturning to the expression for PQin (15.5), and substituting in ( 15.6), as well as the\nfact that k=R+c√\nR,w en o wh a v e\nPQ=kPblock\nk−R+RP block\n≈(R+c√\nR)φ(c)√\nRΦ(c)\nR+c√\nR−R+Rφ(c)√\nRΦ(c)\n=(√\nR+c)φ(c)\nΦ(c)\nc√\nR+√\nRφ(c)\nΦ(c)\n=1+c√\nR\n1+Φ(c)\nφ(c)·c.\nIf we now assume that Ris large so that c< <√\nR, then\nPQ≈/parenleftbigg\n1+Φ(c)\nφ(c)c/parenrightbigg−1\n. (15.7)\nNow recall that our goal is to make PQ<α.\nPQ<α\n⇐⇒/parenleftbigg\n1+Φ(c)\nφ(c)c/parenrightbigg−1\n<α\n⇐⇒Φ(c)\nφ(c)c>1\nα−1\nThe minimum value of cthat satisﬁes the above is the solution to\nΦ(c)\nφ(c)c=1\nα−1,\nwhich is exactly equation ( 15.4).\n15.4 Readings\nThe square-root stafﬁng derivation is based on a beautifully written book by Tijms\n[178].\n15.5 Exercises\n15.1 Effect of Increased Number of Servers\nConsider an M/M/k system, where the service rate at each server is μ=1.\nFix system utilization at ρ=0.95. Now increase the number of servers, k,a s\n15.5 exercises 277\nfollows – 1, 2, 4, 8, 16, 32 – adjusting the arrival rate, λ, accordingly. For each\nnumber of servers, derive (i) the fraction of customers that are delayed and\n(ii) the expected waiting time for those customers who are delayed. We arejust looking for numerical answers here. Feel free to write a math program toevaluate the needed summations. Explain the trend that you see.\n15.2 Capacity Provisioning to Avoid Loss\nIn a call center with\nkoperators, all calls that are not immediately answered\nby an operator are dropped . Calls arrive according to a Poisson process with\nrateλand have Exponentially distributed service times with rate μ=1.F o rλ\nin the set{1,2,4,8}, what should kbe as a function of λto ensure that fewer\nthan1%of calls are dropped? We are just looking for numerical solutions.\nFeel free to write a math program to evaluate the needed summations. When\nλdoubles, does the needed number of operators double?\n15.3 Accuracy of Square-Root Stafﬁng Rule\nThe point of this problem is to test the accuracy of the square-root stafﬁngapproximation given in Theorem 15.2. We want to determine the minimum\nnumber of servers,\nk∗, needed to staff our M/M/k call center, such that fewer\nthan 20% of customers are delayed. Assume that job sizes are Exponentially\ndistributed with mean1\nμ=1. Consider the following cases for the resource re-\nquirement: R=λ\nμ=1,5,10,50,100,250,500,1,000. For each case, derive\nk∗according to the square-root stafﬁng approximation given in Theorem 15.2,\nand then derive it from scratch using PQfor the M/M/k. How close are the\nresults?\n15.4 95th Percentile of Response Time – M/M/1\nWhile mean response time is a common performance metric, many system\nadministrators prefer instead to measure the 95th percentile of response time,denoted by\nT95. Formally, T95is deﬁned to be that xsuch that\nP{T>x}=0.05.\nNamely, only 5% of jobs have higher response time than T95. Consider an\nM/M/1 with service rate μ=1and load ρ=λ.\n(a) How is response time, T, distributed in an M/M/1, in terms of ρ?\n(b) How does E[T]scale with ρ?\n(c) How does T95grow with ρ? How does this compare with how E[T]grows\nwithρ?\n15.5 95th Percentile of Time in Queue – M/M/k\nIn Exercise 15.4 we derived the 95th percentile of response time for the M/M/1.\nWe now wish to follow a similar approach to derive the 95th percentile of the\nqueueing time in the M/M/k, for those jobs that queue. Assume arrival rate λ,\nservice rate μat each of the kservers, and ρ=λ\nkμ<1.\n(a) Consider the queueing time of those jobs which queue, namely\n[TQ|delayed ].\nHow is this quantity distributed?\n(b) What is the 95th percentile of the queueing time of those jobs that queue,\nas a function of k,μ, andλ?\n278 capacity provisioning for server farms\n15.6 How to Split Capacity\nFor the server farm in Figure 15.2, jobs arrive according to a Poisson process\nwith rate λand are probabilistically split between two servers, with p>1\n2\nfraction going to server 1, and q=1−p<1\n2fraction going to server 2. If we\nhave a total service capacity of μfor the two servers, how should we optimally\nsplitμbetween the two servers, into μ1andμ2, where μ=μ1+μ2,s oa st o\nminimize E[T]? Assume job sizes are Exponentially distributed.\np\n1–pFCFS\nFCFSμ1\nμ2Poisson ( λ)\nFigure 15.2. How should we split capacity μbetween two servers?\n(a) Let’s start with some easy cases. What should the answer be if p=1?\nHow about if p=1\n2?\n(b) Returning to the general case of p>1\n2, what is a lower bound on μ1?\nHow about on μ2? After we allocate this minimum capacity to server 1\nand server 2, what is the extra capacity left over?\n(c) Of the “extra capacity” that remains, what fraction do you intuitively\nbelieve should be allocated to server 1?\n(d) Prove that the optimal fraction of extra capacity going to server 1 is\n√p\n√p+√1−p. (15.8)\nThat is, the optimal value for μ1isμ∗\n1=λp+√p√p+√1−p(μ−λ).\n(e) Provide intuition for at least the direction of the result.\n15.7 Insensitivity of M/G/ ∞\nThe M/G/∞system consists of a single FCFS queue, served by an inﬁnite\nnumber of servers, where jobs arrive according to a Poisson process with rate\nλand have generally distributed i.i.d. job service requirements with mean1\nμ.I t\nturns out that the probability that there are kjobs in the M/G/ ∞is insensitive\nto the distribution of G, depending on only the mean of G. Speciﬁcally,\nP{There are kjobs in the M/G/∞}=e−λ\nμ/parenleftBig\nλ\nμ/parenrightBigk\nk!. (15.9)\nThis problem leads us through a heuristic derivation of this result, borrowed\nfrom [ 178], which provides a lot of intuition for the insensitivity result. (This\nargument can be made completely rigorous by using differential equations, see\n[178], pages 10–11.)\n(a) Consider ﬁrst the case where all jobs have the same Deterministic size\nD=1\nμ. Consider a time t>D . Derive the probability that there are k\n15.5 exercises 279\ncustomers at time tand show this agrees with ( 15.9). [Hint: What can you\nsay about the arrival times of customers who are around at time t,g i v e n\nthat all customers have ﬁxed size D?]\n(b) Now consider the case where there are /lscriptclasses of jobs. With probability\npi, an arrival is of class i. Jobs of class ihave Deterministic size Di.\nThe average job size is still1\nμ, that is,/summationtext/lscript\ni=1piDi=1\nμ. Consider a time\nt>max iDi. Derive the probability that there are kcustomers present at\ntimetand show that this agrees with ( 15.9).\n15.8 Pricing and Queueing\nA software ﬁrm is designing a new cloud computing service and has hired you\nas a consultant to help price its service.\nUsers submit computing jobs to an M/M/1 (FCFS) server with arrival rate λ\nand service rate μ=1. The actual job size is unknown to both the user and\nthe server until the job begins receiving service.\nAll users receiving service gain a monetary value worth V−c·Tfor each\ncompleted job, where V>1is a given constant value for all jobs, Tis the\nresponse time of the job, and cis the cost of waiting per unit time. Without loss\nof generality, we will normalize our units to let c=1, so a customer receives\nV−Tvalue from service.\nAt the time of arrival, a user must decide whether to allow his or her job to join\nthe queue based on the following information: (i) The ﬁrm reveals the numberof jobs already in the system,\nn, and (ii) the ﬁrm charges a ﬁxed price of entry\nP>0. The user will allow the job to join if and only if the price of entry is\nno more than the value he or she expects to receive from the service. We can\nexpress this condition as\nV−E[T|N=n]≥P.\nThe ﬁrm wishes to set Pto maximize its own earning rate:\nR=λP·P{an arrival joins the queue }\nBecause not all arrivals will join the queue, the queue will be stable, even for\nλ>1. You may assume throughout this problem that VandPare integers.\n(a) What is the greatest nfor which arrivals are willing to join the queue (in\nterms of VandP)?\n(b) What is the earning rate R(in terms of λ,V, andP)?\n(c) Compute the optimal integer price P∗and the corresponding earning rate\nRfor the following cases: (i) V=6andλ=0.1; (ii)V=6andλ=0.9;\nand (iii) V=6andλ=1.8. (Create a table of Ras a function of different\nPvalues.)\n(d) Sherwin proposes that we can do better by charging a state-dependent\nprice,P(n), when the state is n, where\nP(n)=m a x{1,Highest price users will pay in state n}.\n280 capacity provisioning for server farms\nWe charge 1 when users are unwilling to pay a positive integer price,\neffectively turning these users away and thereby ensuring that we alwaysearn money for each job we serve. Deﬁne\nn0to be the lowest numbered\nstatenfor which users are unwilling to pay a positive price. Determine\nP(n)(in terms of nandVandn0).\n(e) Under state-dependent pricing, the earning rate becomes\nR=λn0−1/summationdisplay\nn=0P(n)·P{an arrival joins the queue and pays P(n)}.\nCompute the earning rate Runder state-dependent pricing for the cases\ngiven in part (c). How do your results compare to those in part (c)? Explainyour ﬁndings intuitively.\nRemark: It turns out that Sherwin’s suggestion can sometimes be improved\non by using a threshold policy whereby users are barred from entry once the\nqueue length reaches a certain threshold [ 39].\n15.9 Congestion Management\nConsider this common congestion management scheme: Jobs are served in an\nM/M/1 queue, provided that the number of jobs is no more than\nThigh. Once\nthe number of jobs hits Thigh, a second server is immediately added, creating\nan M/M/2. The second server continues to be utilized until the number of jobs\ndrops to Tlow, at which point the second server is removed, and we are back\nto an M/M/1, and the process repeats. Assume that jobs arrive according to aPoisson process with rate\nλand that job sizes are Exponentially distributed with\nrateμ. Assume that Tlow=1 andThigh=t, as shown in Figure 15.3.D e r i v e\nan expression for the mean response time, E[T], as a function of t. Your\nexpression does not need to be in closed form. Evaluate E[T]forλ=1.5,\nμ=1, andt=4,8,16,32,64.[Note: This problem is algebraically messy;\nusing a math software package will help.]\nt–1λ\nµλλ\nµλ\nµ2\nλ\n2µ2΄0 1\nµ\nt–1΄λ λ\n2µλ\n2µλ\n2µt+1 t\n2µ\nFigure 15.3. CTMC for Exercise 15.9.\n15.10 M/M/1 with Setup Times\nConsider an M/M/1 queue, where the server immediately shuts off when it isidle (e.g., to save power). When a job arrives and ﬁnds the server off there\nis a setup time ,\nI, required to get the server back on. In this problem we\nassume I∼Exp(α). Setup times are very important in capacity provisioning\n15.5 exercises 281\nfor systems, because they delay not only the job that ﬁnds the server off,\nbut also subsequent jobs that arrive before the server is operational again.Interestingly, for an M/M/1 with an Exponentially distributed setup cost, one\ncan prove the following result, relating the mean response time for an M/M/1\nwith setup to an M/M/1 without setup:\nE[T]M/M/1/setup=E[T]M/M/1+E[I] (15.10)\nDerive ( 15.10 ) by modeling the system via a Markov chain and solving for\nthe limiting probabilities. Warning: While the chain looks simple, the fact that\nthere are two rows makes it a lot harder to solve. This is a difﬁcult problem.[Note: This problem will be revisited in Chapter 27on power management in\ngreater generality.]",11428
104-Chapter 16 Time-Reversibility and Burkes Theorem.pdf,104-Chapter 16 Time-Reversibility and Burkes Theorem,,0
105-16.1 More Examples of Finite-State CTMCs.pdf,105-16.1 More Examples of Finite-State CTMCs,"CHAPTER 16\nTime-Reversibility and\nBurke’s Theorem\nMany practical problems can be represented by a small ﬁnite-state CTMC. When this\nhappens, one is always happy. A ﬁnite-state CTMC, whose transition rates are numbers(not variables), can always be solved, given enough computational power, because it\nsimply translates to a ﬁnite set of linear simultaneous equations. When transition rates\nare arbitrary parameters (\nλ’s and μ’s and such), the chain might still be solvable via\nsymbolic manipulation, provided that the number of equations is not too great. Sec-\ntion16.1 provides additional practice with setting up and solving ﬁnite-state CTMCs.\nUnfortunately, many systems problems involve unbounded queues that translate into\ninﬁnite-state CTMCs. We have already seen the M/M/1 and the M/M/k, which involvejust a single queue and are solvable, even though the number of states is inﬁnite.\nHowever, as we move to queueing networks (systems with multiple queues), we seethat we need to track the number of jobs in each queue, resulting in a chain that is inﬁnitein more than one dimension. At ﬁrst such chains seem entirely intractable. Fortunately,it turns out that a very large class of such chains is easily solvable in closed form. Thischapter, starting with Section 16.2 on time-reversibility and leading into Section 16.3\non Burke’s theorem, provides us with the foundations needed to develop the theory ofqueueing networks, which will be the topic of the next few chapters.\n16.1 More Examples of Finite-State CTMCs\n16.1.1 Networks with Finite Buffer Space\nImagine a small hair salon with only 2 chairs (see Figure 16.1). A customer ﬁrst goes\nto chair 1, by the sink, where her hair is washed, and then to chair 2, by the mirror,\nwhere her hair is cut. There is no standing room in the salon (no queueing). Thus, a\ncustomer only enters the salon if chair 1 is empty, and if a customer is ﬁnished with\nchair 1 but chair 2 is still occupied, the customer waits in chair 1.\nPoisson ( λ)\nExp( μ1)\nservice timeExp( μ2)\nservice time\nFigure 16.1. The hair salon.\n282\n16.1 more examples of finite-state ctmc s 283\nThis example may seem artiﬁcial, but in fact it is quite practical. It represents the\nsituation where there are two routers in tandem, each with a ﬁnite capacity (in this casethe ﬁnite buffer is of size\n1only, but it could be higher in general), and packets continue\nto occupy a buffer simply because the next buffer in the chain of routers is full.\nWe wish to answer these two questions:\n1.What proportion of potential customers enter the salon?\n2.What is the mean response time, E[T]?\nTo answer these questions, we need to determine the state space.\nQuestion: What is wrong with making the state be the number of customers in the\nsystem?\nAnswer: Doing so will not allow us to answer Question 1.\nQuestion: How many customers can we have in each chair?\nAnswer: There can be 0 or 1 customers in each chair.\nQuestion: How about this state space: (0,0), (0,1), (1,0), (1,1)?\nAnswer: Not good enough: (1,1) is ambiguous. Suppose we are in state (1,1). With rate\nμ2, where do we go? If (1,1) represents the fact that there is one customer receiving\nservice in chair 1 and one customer receiving service in chair 2, then with rate μ2we\nshould go to state (1,0). However, if (1,1) represents the fact that there is one customer\nwho has ﬁnished service in chair 1 and one customer still receiving service in chair 2,\nthen with rate μ2we should go to state (0,1).\nFigure 16.2 shows the appropriate CTMC. State (b,1)in the CTMC represents the\nstate where there is a customer in both chairs, but the customer at chair 1 is ﬁnished\nand is blocked, waiting for chair 2.\nμ2λ μ1 μ1\nμ2λ1,1 1,0\n0,10,0\nb,1μ2\nFigure 16.2. The hair salon state space.\nWe now write the balance equations for each state:\n(0,0) : π0,0·λ=π0,1·μ2\n(1,0) : π1,0·μ1=π0,0·λ+π1,1·μ2\n284 time-reversibility and burke’s theorem\n(0,1) : π0,1·(μ2+λ)=π1,0·μ1+πb,1·μ2\n(1,1) : π1,1·(μ2+μ1)=π0,1·λ\n(b,1) : πb,1·μ2=π1,1·μ1/summationdisplay\nπi,j:π0,0+π1,0+π0,1+π1,1+πb,1=1\nWe can now answer our questions, in terms of the limiting probabilities.\nQuestion: What proportion of potential customers enter the salon?\nAnswer: An arrival enters the salon if she sees 0customers in the ﬁrst chair. By PASTA,\nthe probability that an arrival sees 0in the ﬁrst chair is equal to the proportion of time\nthere are 0in the ﬁrst chair, namely: π0,0+π0,1\nQuestion: What is E[N]?\nAnswer: E[N]=π1,0+π0,1+2·(π1,1+πb,1).\nQuestion: What is E[T]for an entering customer?\nAnswer: E[T]=E[N]\nλarrival=E[N]\nλ(π0,0+π0,1).\nImportantly, in applying Little’s Law, we use λarrival, which includes only those arrivals\nthat actually make it through the network.\n16.1.2 Batch System with M/M/2 I/O\nConsider a system consisting of one CPU queue and one I/O queue, where the I/O\nqueue is served by two disks, operating as an M/M/2 system, as shown in Figure 16.3.\nOur goal is to determine the exact throughput for this system (not approximations\nbased on high Nasymptotics).\nN = 3\nμ=1.5 Disk A\nμ=4  CPU\nDisk B\nμ=1.5 \nFigure 16.3. A batch system with M/M/2 I/O.\nQuestion: Show the CTMC for this system.\nAnswer: Figure 16.4 shows the state space of the system.\n444\n1.5 3 31,2 3,0 0,3 2,1\nFigure 16.4. State space of a batch system with M/M/2 I/O.",5356
106-16.2 The Reverse Chain.pdf,106-16.2 The Reverse Chain,"16.2 the reverse chain 285\nState(i, j)represents the fact that there are ijobs in the CPU subsystem (including the\nCPU queue and server) and jjobs in the disk subsystem (including the disk queue and\ntwo disks). There are a total of N=3jobs in the whole system. The balance equations\nare as follows:\nπ3,0·4=π2,1·1.5\nπ2,1·5.5=π3,0·4+π1,2·3\nπ1,2·7=π2,1·4+π0,3·3\nπ0,3·3=π1,2·4\nπ3,0+π2,1+π1,2+π0,3=1\nSolving these, the steady-state probabilities are: π3,0=0.08,π2,1=0.22,π1,2=0.3,\nandπ0,3=0.4.\nQuestion: What is the throughput, X?\nAnswer: Every job passes through the CPU, so it sufﬁces to look at Xcpu:\nρcpu=π3,0+π2,1+π1,2=0.6\nX=Xcpu=ρcpu·μcpu=0.6·4jobs/sec =2.4jobs/sec\nQuestion: How does this compare with what we get from asymptotic calculations\nusing only operational laws and assuming high N, as in Chapter 7?\nAnswer: For high N, we will have X=3 jobs/sec, because at most 3jobs can pass\nthrough the disk module each second.\nQuestion: What is E[Tcpu]?\nAnswer: E[Tcpu]=E[Ncpu]\nXcpu=3·π3,0+2·π2,1+1·π1,2\n2.4=0.41sec.\nQuestion: What is ρdisk a?\nAnswer:1\n2·π2,1+π1,2+π0,3=0.8.\n16.2 The Reverse Chain\nIn the previous examples, the state space was ﬁnite, making the CTMC easy to solve.\nIn open queueing systems, the state space is typically inﬁnite, and it is often inﬁnite inmore than one dimension, because we need to track the “unbounded” number of jobs ateach of several queues. To analyze such systems, we need to develop a new technique.This section and the next present this new technique.\nConsider an ergodic CTMC in steady state. Now imagine we are watching the CTMC\nas it transitions between states:\n···− → 3−→5−→1−→2−→1−→3−→4−→1− →···\n286 time-reversibility and burke’s theorem\nNow consider the reverse process for the CTMC. That is, we watch the CTMC, but\nwe look backward in time (think of watching a movie being played in reverse):\n···← − 3←−5←−1←−2←−1←−3←−4←−1← −···\nThat is, the reverse process transitions from state 1 to 4 to 3 to 1 to 2 to 1, etc.\nClaim 16.1 The reverse process is also a CTMC.\nProof To see this, think of the CTMC via VIEW 1, as described in Chapter 12. The\nforwards process sits in state 3for Exp (ν3)time and then ﬂips a coin with probability\nP3,5of next going to 5. The process then sits in state 5for Exp (ν5)time and again\nﬂips a coin to determine where to go next with probability P5,1of next going to state\n1. The process then sits in state 1for Exp (ν1)time.\nIf we look at just the coin ﬂips (ignoring the time spent in each state), then the sequence\nof coin ﬂips forms what is called an embedded DTMC .\nNow consider the reverse process , transitioning over these same states. The reverse\nprocess also sits in state 1for Exp (ν1)time. It then moves to state 5where it sits for\nExp(ν5)time and then moves to state 3where it sits for Exp (ν3)time. So we already\nsee that each time the reverse process visits state i, it also sits in state ifor Exp (νi)\ntime. To show that the reverse process is a CTMC, all that remains is to show that thereareprobabilities deﬁning the reverse process’s transitions between states.\nThe probability that the reverse process moves from state\n1to state 5is exactly the\nprobability that the forwards process got to state 1from state 5, rather than from some\nother state, given that the forwards process wound up in state 1. LetP∗\nijdenote the\nprobability that the reverse embedded DTMC moves from state ito state j, given that\nit is in state i. To ﬁnish this proof we do not need to explicitly compute P∗\nij; we just\nneed to know that it is a valid probability, meaning that\n/summationdisplay\njP{Reverse process moves from state ito state j}=1,\nwhich is obviously true given that the forward chain must have gotten to state ifrom\nsome state.1\nTo keep from getting confused, we will tag all quantities associated with the reverse\nchain with an asterisk (*). So for example, we have seen that\nνj=ν∗\nj.\nQuestion: How does πjrelate to π∗\nj?\n1We will not need to know this, but if you are curious about what P∗\nijlooks like, you will ﬁnd out in equation ( 16.2).\n16.2 the reverse chain 287\nAnswer: πjrepresents the fraction of time that the forward CTMC chain is in state j.\nBut this is equal to the fraction of time that the reverse chain is in state j. Thus,\nπj=π∗\nj.\nLetπiqijdenote the rate of transitions from itojin the forwards process, where πi\ndenotes the limiting probability of being in state iandqijdenotes the rate of transitions\nfromitoj, given we are in state i. Note here that\nqij=νi·Pij, (16.1)\nwhere νiis the total rate of transitions leaving state i, given that we are in state i.\nQuestion: Is the rate of transitions from state ito state jin the reverse CTMC process\nthe same as the rate of transitions from state ito state jin the forwards CTMC process?\nAnswer: No,π∗\niq∗\nijis not necessarily equal to πiqijbecause q∗\nijis not necessarily\nequal to qij. For example, there may be zero rate of transitions from itojin\nthe forwards chain, and yet a positive rate of transitions from itojin the reverse\nchain.\nClaim 16.2 The rate of transitions from itojin the reverse CTMC process equals\nthe rate of transitions from jtoiin the forwards CTMC process. That is,\nπ∗\niq∗\nij=πjqji.\nThis claim is always true and has nothing to do with time-reversibility.\nProof Consider any observation period T. During Tthe number of transitions that\nthe reverse process makes from itojis exactly equal to the number of transitions that\nthe forwards process makes from jtoi. Thus the rates (number of transitions during\nT, divided by T) are also the same.\nAn immediate corollary of Claim 16.2 combined with ( 16.1) is that2\nP∗\nij=πjνjPji\nπiνi. (16.2)\n2Here is an independent derivation of P∗\nij. Consider the embedded DTMC within our CTMC. Let πDTMC\nibe\nthe limiting probability of being in state ifor the embedded DTMC (note this is not the same as the limiting\nprobability for the CTMC, πCTMC\ni). Observe that the rate of transitions from jtoiin the forward embedded\nDTMC equals the rate of transitions from itojin the reverse embedded DTMC. (This is true for every chain\nand has nothing to do with time-reversibility.) So\nπDTMC\njPji=π∗DTMC\niP∗\nij.\nBut because π∗DTMC\ni=πDTMC\ni,w eh a v e\nπDTMC\njPji=πDTMC\niP∗\nij,\nwhich results in\nP∗\nij=πDTMC\njPji\nπDTMC\ni,",6346
107-16.3 Burkes Theorem.pdf,107-16.3 Burkes Theorem,"288 time-reversibility and burke’s theorem\nIt turns out that we can say a lot more about the reverse chain ifwe know that the\nforwards chain is time-reversible .\nDeﬁnition 16.3 AC T M Ci s time-reversible if, for all i,j:\nπiqij=πjqjiand/summationdisplay\niπi=1. (16.3)\nIn other words, a CTMC is time-reversible if for every pair of states i,j, the rate of\ntransitions from itojin the forwards process equals the rate of transitions from j\ntoiin the forwards process. For example, the CTMC corresponding to a birth-death\nprocess is time-reversible, because the number of transitions from state ito state i+1\nis always within 1 of the number of transitions from state i+1 toi, and hence the\nlong-run rateof transitions from itoi+1equals the rateof transitions from i+1to\ni. Note that time-reversibility is deﬁned as a property of the forwards process.\nClaim 16.4 If a CTMC is time-reversible, then its reverse chain is statistically\nidentical to the forwards chain, meaning that the reverse chain can be described by\nthe same CTMC as the forwards chain.\nProof If the CTMC is time-reversible, then\nπiqij=πjqji(by deﬁnition of time-reversibility)\n=π∗\niq∗\nij(by Claim 16.2)\n=πiq∗\nij.\nTherefore,\nqij=q∗\nij for all i,j.\nBecause these rates deﬁne the CTMC (think VIEW 2 of a CTMC from Chapter 12),\nthe forwards and reverse chains are statistically identical. Note that this also implies\nPij=P∗\nij, because qij=νiPijandνi=ν∗\ni. Thus the embedded DTMCs for the\nforwards and reverse processes are also identical.\n16.3 Burke’s Theorem\nTheorem 16.5 (Burke) Consider an M/M/1 system with arrival rate λ. Suppose\nthe system starts in a steady state. Then the following are true:\nNow observe that there is a clear relation between πDTMC\ni(which spends time 1during each visit to a state) and\nπCTMC\ni(which spends time Exp (νi)during each visit to state i); namely,\nπCTMC\ni=πDTMC\ni·1\nνi·C,\nwhere Cis just a normalizing constant needed to get the limiting probabilities to sum to 1. Hence,\nP∗\nij=πDTMC\njPji\nπDTMC\ni=πCTMC\njνjPji\nπCTMC\niνi.\n16.3 burke’s theorem 289\n1.The departure process is Poisson (λ).\n2.At each time t, the number of jobs in the system at time tis independent of the\nsequence of departure times prior to time t.\nPart (1) of Theorem 16.5 says that the interdeparture times are Exponentially distributed\nwith rate λ. It is not at all obvious that this should be the case. Clearly, while the server\nis busy, the interdeparture times are distributed Exp (μ). But then the server is idle for\nExp(λ)time, so the time until the following departure is Exp (λ)+Exp(μ).I ti sn o t\nobvious then why this should result in a departure process with Exp (λ)interdeparture\ntimes.\nPart (2) of the theorem says that the number of jobs in the system at any time does not\ndepend on the previous departure times or patterns. For example, knowing that therewas recently a stream of closely spaced departures does not indicate that the numberof jobs in the system currently is below average.\nProof\n1.Observe that the departures in the forwards process occur at points of arrivals\nin the reverse process (see Figure 16.5). Now consider the points of arrivals in\nthe reverse process. Because the M/M/1 is time-reversible, the reverse process isstatistically identical to the forwards process by Claim 16.4. Thus the points of\narrivals in the reverse process constitute a Poisson process with rate\nλ.S o( b y\nour previous observation) the points of departures in the forwards process also\nconstitute a Poisson process with rate λ.\ntimeNumber of jobs\nFigure 16.5. Departures in forwards process are arrivals in reverse process.\n2.The sequence of departure times prior to time tin the forwards process is exactly\nthe sequence of arrival times after timetin the reverse process. However, the\nfuture arrival pattern for the reverse process does not depend on the number of\njobs at time t, because this process is a Poisson process. Therefore, looking at\nthe forwards process, the number of jobs at time tis independent of the sequence\nof departures prior to time t.\nThe claims in Burke’s theorem also hold for an M/M/k system. The proofs are exactlythe same.\nQuestion: Give an example of a queueing network for which part (2) of Burke’s\ntheorem does nothold.",4310
108-16.5 Application Tandem Servers.pdf,108-16.5 Application Tandem Servers,"290 time-reversibility and burke’s theorem\nAnswer: Consider a single-server network, where arrivals occur exactly at times 0,2,\n4,6,...S uppose the service time is U(0,2)(i.e., Uniformly distributed between 0and\n2). LetN(t)be the number of jobs in the system at time t. Then N(1)is either 0or1\nand speciﬁcally depends on whether there was a departure during (0,1).\n16.4 An Alternative (Partial) Proof of Burke’s Theorem\nHaving taught this material for many years, I have found that there are always some\nstudents who remain unconvinced about the ﬁrst part of Burke’s theorem, namely\nthat the interdeparture times are distributed Exp (λ). These students argue that the\ninterdeparture times are either Exp (μ)(when the server is busy) or are of the form of\nExp(λ)+Exp(μ)(when the server is idle); the term Exp (λ)+Exp(μ)comes from\nhaving to wait for an arrival and then to wait for that arrival to depart. It is not at\nall clear why having interdeparture times switch between these modes should form aPoisson\n(λ)departure process. This paradox is shown in Figure 16.6.\nEvents\ntime\nExp( μ) Exp( μ) Exp( μ) Exp( μ)+Exp( λ) Exp( μ)\nFigure 16.6. Interdeparture times in M/M/1.\nFor these frustrated students, I offer the following alternative explanation.\nFirst observe that, for an M/M/1, the probability that a departure leaves behind a busy\nsystem is ρ, and the probability that a departure leaves behind an idle system is 1−ρ.\nQuestion: Why is this?\nAnswer: As explained in Section 13.3, by PASTA, an=pn,∀n, implying that the\nprobability that an arrival ﬁnds the system busy is the time-average fraction of time that\nthe system is busy, namely ρ. However, for any ergodic system, an=dn,s odn=pn,\n∀n; hence the probability that a departure leaves behind a busy system is ρ.\nNow, let’s suppose that a departure just happened. We are interested in the quantity T,\nwhich is the time until the next departure. We would like to prove that T∼Exp(λ).\nNow, when the departure leaves, with probability ρ, it leaves behind a busy system,\nsoT∼Exp(μ), and with probability 1−ρ, it leaves behind an idle system, so T∼\nExp(λ)+Exp(μ).\nThus,\nT∼/braceleftbigg\nExp(μ) w.p.ρ\nExp(μ)+Exp(λ)w.p.1−ρ.\n16.5 application: tandem servers 291\nQuestion: Does the distribution of Tlook Exponential?\nAnswer: It does not seem so, but here is the argument. By conditioning on the value,\nt, of Exp (λ),\nP{T>x}=ρe−μx+( 1−ρ)/parenleftbigg/integraldisplayx\nt=0e−μ(x−t)λe−λtdt+/integraldisplay∞\nt=x1·λe−λtdt/parenrightbigg\n=ρe−μx+( 1−ρ)e−μxλ/integraldisplayx\nt=0e(μ−λ)tdt+( 1−ρ)e−λx\n=e−μx/parenleftBigg\nρ+(1−ρ)λ/parenleftbig\ne(μ−λ)x−1/parenrightbig\nμ−λ+( 1−ρ)e(μ−λ)x/parenrightBigg\n=e−μx/parenleftbig\nρ+ρe(μ−λ)x−ρ+( 1−ρ)e(μ−λ)x/parenrightbig\n=e−μx/parenleftbig\ne(μ−λ)x/parenrightbig\n=e−λx.\nHence the time between departures is in fact Exponentially distributed with rate λ.\nNote that this proof is only a partial proof, compared with the proof in Section 16.3,\nbecause it does not argue independence of the interarrival times. Nonetheless it does\nshed some insight onto how the Exp (λ)interdeparture times come about.\n16.5 Application: Tandem Servers\nWe will now see how to apply Burke’s theorem to obtain formulas that allow us to\ninstantly analyze a large class of queueing networks. We start with a simple tandemsystem. We want to ﬁnd the limiting probabilities of the tandem system, shown in\nFigure 16.7.\n2 1 Poisson ( λ)\nρ1 = 1 ρ2 = 2\nFigure 16.7. Tandem queues.\nWe can try to model the system by drawing the CTMC and solving the associated\nbalance equations. We end up with an inﬁnite-state CTMC, where each state is a pair\n(n1,n2)denoting the number of jobs at server 1 and the number at server 2. A piece\nof the CTMC is shown in Figure 16.8.\n292 time-reversibility and burke’s theorem\nn1–1,n2\nn1+1,n2–1\nn1, n2+1n1, n2 n1–1,n2+1\nn1, n2–1λ\nμ1\nμ2λ\nμ1\nμ2n1+1,n2\nFigure 16.8. Portion of CTMC, assuming n1,n2≥1.\nThe corresponding balance equations when n1≥1andn2≥1take the following\nform:\nπn1,n2(λ+μ1+μ2)=πn1−1,n2·λ+πn1+1,n2−1·μ1+πn1,n2+1·μ2\nThese balance equations look hard to solve.\nOn the other hand, we can apply Burke’s theorem to ﬁnd the solution to Figure 16.7\nvery easily. By part (1) of Burke’s theorem, we know that the arrival stream into server\n2 is Poisson (λ). If we view the two servers in isolation, they are both M/M/1 systems\nwith arrival rates λ. Therefore,\nP{n1jobs at server 1 }=ρn1\n1(1−ρ1).\nP{n2jobs at server 2 }=ρn2\n2(1−ρ2).\nNext, we show that the numbers of jobs at the two servers are independent. Let N1(t)\ndenote the number of jobs at server 1at time t. LetN2(t)denote the number of jobs\nat server 2at time t. By part (2) of Burke’s theorem, the sequence of departures from\nserver 1 prior to time tis independent of N1(t). Because departures from server 1 are\narrivals into server 2, we see that the sequence of arrivals into server 2 prior to time tis\nindependent of N1(t).B u tN2(t)is completely determined by the sequence of arrivals\ninto server 2 prior to time t. Therefore N2(t)is independent of N1(t)for all t.\nUsing these results, we can determine the limiting probabilities:\nπn1,n2= lim t→∞P{N1(t)=n1andN2(t)=n2}\n= lim t→∞P{N1(t)=n1}·P{N2(t)=n2}\n= lim t→∞P{N1(t)=n1}·limt→∞P{N2(t)=n2}\n=P{n1at server 1}·P{n2at server 2}\n=ρn1\n1(1−ρ1)ρn2\n2(1−ρ2)\nTo check our answer, we can substitute our expression for πn1,n2back into the balance\nequations:\nπn1,n2(λ+μ1+μ2)=πn1−1,n2λ+πn1+1,n2−1μ1+πn1,n2+1μ2\nTry plugging it in . . . you will see it works. This therefore provides a second proof\nfor why the number of jobs at server 1 and the number of jobs at server 2 are\nindependent.",5675
109-16.7 Readings.pdf,109-16.7 Readings,"16.6 general acyclic networks with probabilistic routing 293\nPoisson ( λ) μ=3 μ=6\nversus\nPoisson ( λ) μ=6 μ=3\nFigure 16.9. Which of these is better?\nQuestion: Which of the systems in Figure 16.9 has better performance?\nAnswer: Both have the same performance. For both systems,\nE[N]=E[N1]+E[N2]=ρ1\n1−ρ1+ρ2\n1−ρ2,\nwhere ρ1=λ\n3andρ2=λ\n6.\n16.6 General Acyclic Networks with Probabilistic Routing\nNow consider any acyclic network of servers with probabilistic routing, as shown in\nFigure 16.10 .\n12 4\n5\n3Poisson ( λ)½⅔\n⅓\n1 ½\nFigure 16.10. An acyclic network of servers.\nBurke’s theorem (Theorem 16.5) can be applied to ﬁnd the limiting probabilities here\nin the same way as we applied Burke’s theorem to the tandem system.\nBy part (1) of Burke’s theorem, we see that, for each server, the arrival process into the\nserver is a (merged and/or split) Poisson process. So each server, in isolation, can be\nviewed as an M/M/1 queue. Using part (2) of Burke’s theorem and the same argumentas for tandem queues, we can show that the numbers of jobs at the different servers areindependent. Thus, assuming\nkservers we have\nπn1,n2,...,n k=P{n1jobs at server 1 }·P{n2jobs at server 2 }···P{nkjobs at server k}\n=ρn1\n1(1−ρ1)·ρn2\n2(1−ρ2)···ρnk\nk(1−ρk).\nQuestion: What is P{N1=n1}in such an acyclic network with kservers?",1334
110-16.8 Exercises.pdf,110-16.8 Exercises,"294 time-reversibility and burke’s theorem\nAnswer:\nP{N1=n1}=/summationdisplay\nn2,n3,...,n kπn1,n2,...,n k\n=/summationdisplay\nn2,n3,...,n kρn1\n1(1−ρ1)ρn2\n2(1−ρ2)···ρnk\nk(1−ρk)\n=ρn1\n1(1−ρ1).\n16.7 Readings\nWith respect to the sections on the reverse chain and on time-reversibility, we highly\nrecommend the following readings: [ 149] (Ch. 5, Section 6), and [ 18] (pp. 214–21).\nBurke’s theorem was originally presented in [ 34].\n16.8 Exercises\n16.1 Practice with Finite-State Chains: Closed System Performance\nFor the closed interactive network in Figure 16.11 , there are N=3 users,\nthink time is Z∼Exp(λ=1 ) , service time is S∼Exp(μ=2 ) , and routing\nprobabilities are as shown. For this network compute\nN = 3\n½ ½\nFigure 16.11. Closed queueing network from Exercise 16.1.\n(a) the exact throughput, X.\n(b) the exact mean response time, E[R], not including think time.\n(c) the asymptotic throughput for high Nusing operational analysis from\nChapter 7.\n16.2 More Closed System Performance\nFor the closed interactive network in Figure 16.12 , there are N=4 users,\nthink time is Z∼Exp(λ=2 ) , service time is S∼Exp(μ=4 ) , and routing\nprobabilities are as shown.(a) Use operational laws to approximate throughput,\nX.\n(b) Derive the exact throughput, X.\n(c) Derive the exact mean response time, E[R], not including think time.\n(d) What is the mean number of users that are thinking?\n16.8 exercises 295\nN = 4\n¼ ¾\nFigure 16.12. Closed queueing network from Exercise 16.2.\n16.3 Chip Manufacturing Plant\nAt a chip manufacturing plant, wafers arrive according to a Poisson process\nwith rate λ=1. The wafers pass through three stations: a photoresist coating\nstation, a circuit imprinting station, and an alkaline rinse station. Each station\nconsists of two identical workers serving a single queue, as shown in Fig-ure16.13 . For the purpose of this problem, assume that all service times are\nExponentially distributed and that the service rate at station\niisμi=i,f o ri=\n1,2,3. Derive the mean time from when a wafer arrives until a chip is created.\nPoisson ( λ)μ1\nμ1Coatin g station\nμ2\nμ2Circ uit imprintin g station\nμ3\nμ3Rinse station\nFigure 16.13. Sequence of M/M/2 stations in chip manufacturing.\n16.4 Application of Square-Root Stafﬁng to Chip Manufacturing\nFigure 16.14 shows the 3 stations that wafers pass through in a chip man-\nufacturing plant: a photoresist coating station, a circuit imprinting station,\nand an alkaline rinse station. Assume that all service times are Exponentially\nμ1Poisson ( λ) μ1μ1\nμ2μ2μ2\nμ3μ3μ3Coating station Circuit Imprinting station Rinse station\nFigure 16.14. Sequence of stations in chip manufacturing.\n296 time-reversibility and burke’s theorem\ndistributed with rates shown, where μi=i. Assume that wafers arrive ac-\ncording to a Poisson process with rate λ=10,000 wafers per second. Use the\nsquare-root stafﬁng rule from Chapter 15 to determine the minimum numberof servers,\nk∗, needed at each station such that at every station fewer than 20%\nof wafers experience any delay.\n16.5 Alternative Views of Time-Reversibility\nTime-reversible chains have many beautiful properties. In this problem youwill prove two of these.\n(a) Prove that for any time-reversible CTMC, for any ﬁnite subset of states,\nS, the product of the transition rates along any cycle involving states in S\nequals the product of the transition rates along the same cycle in reverse\norder. Speciﬁcally, for any states j1,j2,...,j n∈S:\nqj1,j2·qj2,j3·qj3,j4···qjn−1,jn·qjn,j1\n=qj1,jn·qjn,jn−1·qjn−1,jn−2···qj2,j1.\n(b) Prove that for a time-reversible CTMC, the rate of traversing any path\nequals the rate of traversing the same path in the reverse direction. Specif-ically, for any state\njand any states j1,j2,...,j n∈S:\nπj·qj,jn·qjn,jn−1·qjn−1,jn−2···qj2,j1\n=πj1·qj1,j2·qj2,j3···qjn−1,jn·qjn,j.\n[Hint: Part (a) may be useful in proving this.]\n16.6 Burke’s Theorem for Finite Queues?\nConsider the M/M/1/k single-server queue with ﬁnite capacity of k.\n(a) Is this Markov chain time-reversible?\n(b) Can we apply the proof of Burke’s theorem to say that the departure process\nis a Poisson process? Explain.",4185
111-Chapter 17 Networks of Queues and Jackson Product Form.pdf,111-Chapter 17 Networks of Queues and Jackson Product Form,,0
112-17.2 The Arrival Process into Each Server.pdf,112-17.2 The Arrival Process into Each Server,"CHAPTER 17\nNetworks of Queues and Jackson\nProduct Form\nWe are now ready to consider a very general architecture called the “network of queues.”\nThis architecture allows for any number of servers, each with its own (unbounded)queue, and probabilistic routing between the servers. The architecture allows for cyclesin the network and is very useful in modeling packet-routing computer networks ornetworks of manufacturing stations.\nIn this chapter, we consider the simplest such network of queues, called the Jackson\nnetwork. In later chapters, we consider fancier versions. For example, in Chapter 18, the\nrouting probabilities are allowed to depend on the “class” of the packets, which makes\nit even more applicable to packet-routing in the Internet. The point of this chapter is toprove the Jackson Product Form theorem, which provides us with an immediate simple\nclosed-form solution for the limiting probabilities of any Jackson network.\n17.1 Jackson Network Deﬁnition\nA Jackson network is a very general form of queueing network. In a Jackson\nnetwork, there are kservers, each with its own (unbounded) queue. Jobs at a server are\nserved in FCFS order. The ith server has service rate Exp (μi). Each server may receive\narrivals from inside andoutside the network. The arrivals into the ith server from outside\nthe network constitute a Poisson process with rate ri. The routing of jobs is proba-\nbilistic. Speciﬁcally, every job that completes at server iwill be transferred to server\njwith probability Pij, or will exit the system with probability Pi,out=1−/summationtext\njPij.\nFigure 17.1 shows the general setup of a Jackson network.\nPoisson ( ri)Server i Server kServer j\nPoisson ( rj)\nPoisson ( rk)PijPj,out\nPi,outPjk\nPkiPik\nFigure 17.1. A simple Jackson network.\n297\n298 networks of queues and jackson product form\nThe response time of a job is deﬁned as the time from when the job arrives to the\nnetwork until it leaves the network, including possibly visiting the same server or\ndifferent servers multiple times.\nFor each server i, we denote the total arrival rate into server ibyλi.\nQuestion: What is the total rate at which jobs leave server j?\nAnswer: λjis both the total rate at which jobs enter server jand at which they leave\nserver j.\nQuestion: What is the total rate at which jobs leave server j, going to server i?\nAnswer: λjPji.\nThe total arrival rate into server iis the sum of the outside arrival rate (rate of jobs\narriving to server ifrom outside the network) and the inside arrival rate (rate of jobs\narriving to server ifrom inside the network):\nλi/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\ntotal arrival= ri/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\noutside arrival+/summationdisplay\njλjPji\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\ninternal transition. (17.1)\nWe can solve these simultaneous equations to obtain all the λi’s. Equivalently, we can\nwrite\nλi(1−Pii)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\ntotal arrival= ri/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\noutside arrival+/summationdisplay\nj/negationslash=iλjPji\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\ninternal transition(17.2)\nwhere ( 17.2) is identical to ( 17.1), except that on both sides we are not including\ntransitions from server iback to server i.\nNote: Be careful not to confuse servers with states. Right now we are only talking\nabout servers.\n17.2 The Arrival Process into Each Server\nAt this point we see how to compute λi, the total arrival rate into server i. If we knew\nthat the arrival process into each server was a Poisson process, then we could view each\nserver as an M/M/1 queue and determine the distribution of the number of jobs at that\nserver. This is the approach that we followed in the last chapter for acyclic networks.\nQuestion: For acyclic networks, we saw that the arrival process into each server is a\nPoisson process. Can we still say that the arrival process into each server is a Poisson\nprocess if the network is not acyclic?\n17.2 the arrival process into each server 299\nMore speciﬁcally, consider the network in Figure 17.2. Here the output of a server feeds\nback into the same server. Is the arrival process into the server in Figure 17.2 a Poisson\nprocess?\np\n1–p Poisson ( λ)\nFigure 17.2. Network with feedback.\nAnswer: At ﬁrst one might think the answer is yes. Here is the WRONG argument:\nWe start with an M/M/1 with Poisson arrivals of rate λ. The departures of an M/M/1\nare also a Poisson process of rate λby Burke’s theorem. Some fraction, 1−pof those\ndepartures leaves, and the remaining fraction, p, gets fed back. This portion that gets\nfed back is also a Poisson process (by Poisson splitting) of rate λp. This gets merged\nwith the outside arrival process, which is a Poisson process, and we know that the merge\nof two Poisson processes is still a Poisson process. Hence the total arrival process into\nthe queue is a Poisson process.\nUnfortunately, the above answer is wrong. To see this, consider the network in\nFigure 17.3.\n0.99\nPoisson ( λ: very low) 0.01μ\nfast\nFigure 17.3. Illustrating why we do not see Poisson arrivals.\nSuppose that the arrival rate, λ, is very low, so that the time between arrivals is\ntypically very high. Now suppose there is an arrival at the server at time t. Then with\nhigh probability there will be another arrival to the server shortly. That is, it is much\nmore likely that there is an arrival during (t, t+/epsilon1)than during some other /epsilon1-interval.\nThus the arrival process into server idoes not have independent increments. So it is\nnot a Poisson process.\nQuestion: What was wrong with the argument that said we were merging two Poisson\nprocesses and therefore should get a Poisson process?\nAnswer: The two Poisson processes that we were merging were not independent\nPoisson processes; therefore their merge was not a Poisson process.\nBecause the arrival process into this server is not a Poisson process, we cannot use\nthe simpliﬁcations we used for solving tandem queues, where each server becomes anindependent M/M/1.",6272
113-17.4 The Local Balance Approach.pdf,113-17.4 The Local Balance Approach,"300 networks of queues and jackson product form\n17.3 Solving the Jackson Network\nSo let’s go back to modeling the network with a CTMC and trying to solve the balance\nequations. The states of the network can be deﬁned as a set of k-tuples\n(n1,n2,...,n k),\nin which the jth element in the tuple represents the number of jobs at server j(including\nboth the queue and the server). We need to write the balance equation for each state.\nRemember the balance equation for each state is\nRate of jobs leaving the state =Rate entering the state.\nSuppose the system is in state (n1,n2,...,n k). To simplify the writing of balance\nequations, we will assume throughout the chapter that ni>0,∀i. The case where\nsome states have 0jobs is left as an exercise.\nThe CTMC leaves state (n1,n2,...,n k)when there is either (i) an outside arrival, or\n(ii) a service completion at any of the servers. Observe that both of these events happenwith Exponential rates. The rate of transitions leaving the state\n(n1,n2,...,n k)(and\nnot returning to the state) is\nπn1,n2,...,n k·/bracketleftBiggk/summationdisplay\ni=1ri+k/summationdisplay\ni=1μi(1−Pii.)/bracketrightBigg\n.\nNow consider the rate at which the CTMC enters the state (n1,n2,...,n k)(from some\nother state). State (n1,n2,...,n k)is entered at moments where (i) there is an outside\narrival, or (ii) there is a departure to outside, or (iii) there is an internal transition. Againthese are Exponential rates. The rate of transitions entering the state is\nk/summationdisplay\ni=1πn1,...,n i−1,...,n k·ri\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\noutside arrival+k/summationdisplay\ni=1πn1,...,n i+1,...,n k·μiPi,out\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright\ndeparture to outside\n+k/summationdisplay\ni=1/summationdisplay\nj/negationslash=iπn1,...,n i−1,...,n j+1,...,n k·μjPji\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\ninternal transition from server jto server i,j/negationslash=i.\nTherefore the balance equation for state (n1,...,n k)is\nπn1,n2,...,n k·/bracketleftBiggk/summationdisplay\ni=1ri+k/summationdisplay\ni=1μi(1−Pii)/bracketrightBigg\n=k/summationdisplay\ni=1πn1,...,n i−1,...,n k·ri+k/summationdisplay\ni=1πn1,...,n i+1,...,n k·μiPi,out\n+k/summationdisplay\ni=1/summationdisplay\nj/negationslash=iπn1,...,n i−1,...,n j+1,...,n k·μjPji.. (17.3)\n17.4 the local balance approach 301\nOf course ( 17.3) is the balance equation for just one particular state, (n1,...,n k).W e\nneed to write out the balance equation for each state.\nQuestion: Why are there no λi’s in the balance equation?\nAnswer: Theevents that change the state are only arrivals or service completions, all\nof which are Exponentially distributed. The λi’s are not events; they denote average\nrates at which packets arrive and are thus used when discussing the network of servers ,\nnot the Markov chain with states.\nMaking a guess as to the limiting probabilities based on these complicated balance\nequations is impossible. Furthermore, it is going to get a lot messier in the next chapterwhen we move on to classed networks, where routing probabilities depend on class.\n17.4 The Local Balance Approach\nWe need an approach to simplify the huge number of balance equations. Many popular\nbooks (e.g., [ 18,149,150]) at this point go into the “reverse chain argument.” They try\nto guess what the reverse chain looks like and then use the limiting probabilities for the\nreverse chain. We do not want to take this approach because it is long and unintuitive,\nand how in the world can you start picturing what the reverse chain looks like whenthe forwards process is so complicated already?\nInstead we are going to take a different approach based on the idea of local balance .\nThis idea is not precisely deﬁned and is just part of the “bag of tricks” that queueing\ntheorists use. Although local balance is brieﬂy mentioned in several texts (e.g., [ 151]),\nthere is typically no algorithm provided for how to set up the local balance equations.\nThat part is the “art,” which is learned through trial and error. In the next few chapters,we will repeatedly show one particular way of using local balance that has worked very\nwell for us when analyzing complex networks of queues.\nThe idea is to break down the left-hand side and right-hand side of the balance equation\n(17.3) into\nk+1 matching components. If we can ﬁnd a solution that maintains the\nequality for each matching component (local balance), then we know that it is a solution\nto the equation as a whole (global balance). Observe that satisfying local balance is a\nstronger condition than satisfying global balance. Because the local balance equations\nare so much simpler looking, it will be much easier to make a guess based on theseequations and also to “check” that a guess satisﬁes these equations. Figure 17.4 shows\nthe way to break down a balance equation into\nk+1distinct components. It is very\nimportant that you do it in exactly this way . There are many other ways of subdividing\na balance equation that do not satisfy the local balance.\nWe want to ﬁnd a solution that makes A=A/primeandBi=B/prime\nitrue for all 1≤i≤k.H e r e\nAdenotes the rate of leaving state (n1,n2,...,n k)due to an outside arrival coming\ninto the network. Here Bidenotes the rate of leaving state (n1,n2,...,n k)due to a\ndeparture from server i. This departure may either go to some other server j/negationslash=ior\nmay leave the network. Likewise A/primedenotes the rate of entering state (n1,n2,...,n k)\n302 networks of queues and jackson product form\nA\nB\nBkRate\nleavin g\n(n1, n2, ..., n k)Due to\noutside\narrival\nDue to \na depart ure \nfrom...B1\nserver 1\nB2\nserver 2\nserver kA\nB\nBkRate′\nenterin g\n(n1, n2, ..., n k)Due to\noutside\ndepart ure\nDue to \nan arrival\nat...B1\nserver 1\nB2\nserver 2\nserver k=\n=\n=\n=′\n′′\n′\nFigure 17.4. Local balance decomposition approach.\ndue to a job departing to outside the network. B/prime\nidenotes the rate of entering state\n(n1,n2,...,n k)due to an arrival at server i, where this arrival may either be coming\nfrom outside the network, or from another server j/negationslash=i.\nAt this point we are not even sure whether a solution satisfying local balance\nexists. If we are lucky enough to ﬁnd a solution that satisﬁes all the local balanceequations, then we have global balance as well.\nFirst we try to solve\nA=A/prime. To show A=A/prime, we need to show that\nk/summationdisplay\ni=1πn1,...,n i,...,n kri=k/summationdisplay\ni=1πn1,...,n i+1,...,n kμiPi,out.\nWe need to make a guess for πn1,...,n kand show that it satisﬁes this A=A/primeequation.\nHere is how we come to our guess: Observe that the πn1,...,n i,...,n kterm in Aand the\nπn1,...,n i+1,...,n kterm in A/primeonly differ in the nispot. Let’s suppose that\nπn1,...,n i,...,n k·ci=πn1,...,n i+1,...,n k,\nwhere ciis some constant depending on i.\nThen rewriting the A=A/primeequation, we have\nk/summationdisplay\ni=1πn1,...,n i,...,n kri=k/summationdisplay\ni=1πn1,...,n i+1,...,n kμiPi,out.\nk/summationdisplay\ni=1πn1,...,n i,...,n kri=k/summationdisplay\ni=1πn1,...,n k·ci·μiPi,out.\nk/summationdisplay\ni=1ri=k/summationdisplay\ni=1(ci·μi)Pi,out. (17.4)\n17.4 the local balance approach 303\nQuestion: Can you ﬁgure out what we would like cito be?\nAnswer: Observe that if\n(ci·μi)=λi,\nthen ( 17.4) is true because it would then say that\nk/summationdisplay\ni=1ri=k/summationdisplay\ni=1λiPi,out,\nwhich simply says that the total rate of jobs entering the system from outside is the\nsame as the total rate of jobs leaving the system (to go outside). This is obviously truein steady state.\nThus in our earlier guess, we want\nci=λi\nμi=ρi.\nLet’s return to the process of making a guess for πn1,...,n k. We know that to satisfy\nA=A/primewe would like to have\nπn1,...,n i,...,n k·ρi=πn1,...,n i+1,...,n k,∀i.\nThus it seems a reasonable guess is that\nπn1,...,n i,...,n k=Cρn1\n1...ρnk\nk,\nwhere Cis the usual normalizing constant.\nNow we try to solve for Bi=B/prime\ni.H e r e Biis the rate of transitions leaving state\n(n1,...,n k)due to a departure from server i(not back to i), namely,\nBi=πn1,...,n k·μi(1−Pii).\nB/prime\niis the rate of transitions entering (n1,...,n k)due to an arrival at server i. This\nincludes outside arrivals into server ior internal arrivals from other servers. Therefore\nthe expression for B/prime\niis\nB/prime\ni=/summationdisplay\njs.t.j/negationslash=iπn1,...,n i−1,...,n j+1,...,n k·μjPji\n/bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright\ninternal transition from server jto server i(j/negationslash=i)+πn1,...,n i−1,...,n k·ri/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\noutside arrival.\nLet’s use our previous guess for πn1,...,n kand check if it satisﬁes Bi=B/prime\ni. Let\nπn1,...,n i,...,n k=Cρn1\n1ρn2\n2...ρnk\nk.\n304 networks of queues and jackson product form\nNow check that\nBi=B/prime\ni\nCρn1\n1ρn2\n2···ρnk\nkμi(1−Pii)=/summationdisplay\nj/negationslash=iCρn1\n1ρn2\n2···ρnk\nk/parenleftbiggρj\nρi/parenrightbigg\nμjPji\n+Cρn1\n1ρn2\n2...ρnk\nk/parenleftbigg1\nρi/parenrightbigg\nri\nμi(1−Pii)=/summationdisplay\nj/negationslash=iρjμj\nρiPji+ri\nρi\nρiμi(1−Pii)=/summationdisplay\nj/negationslash=iρjμjPji+ri\nλi(1−Pii)=/summationdisplay\nj/negationslash=iλjPji+ri. (17.5)\nQuestion: Is Equation ( 17.5) true?\nAnswer: Yes, of course, this is exactly equation ( 17.2), the equation deﬁning the\noutside arrival rates. So our guess for πn1,...,n kalso satisﬁes Bi=B/prime\ni.\nLastly, we need to ﬁnd the normalizing constant C:\n/summationdisplay\nn1,...,n kπn1,...,n k=1\nC/summationdisplay\nn1,...,n kρn1\n1···ρnk\nk=1\nC/summationdisplay\nn1ρn1\n1/summationdisplay\nn2ρn2\n2···/summationdisplay\nnkρnk\nk=1\nC/parenleftbigg1\n1−ρ1/parenrightbigg/parenleftbigg1\n1−ρ2/parenrightbigg\n···/parenleftbigg1\n1−ρk/parenrightbigg\n=1\nHence,\nC=( 1−ρ1)( 1−ρ2)···(1−ρk).\nAs a result,\nπn1,...,n k=ρn1\n1(1−ρ1)ρn2\n2(1−ρ2)···ρnk\nk(1−ρk). (17.6)\nThis is an example of a product form solution for the limiting probabilities.\nQuestion: What does the previous expression tell us about the distribution of the\nnumber of jobs at server 1?\n17.4 the local balance approach 305\nAnswer:\nP{n1jobs at server 1}=/summationdisplay\nn2,...,n kπn1,...,n k\n=/summationdisplay\nn2,...,n kρn1\n1(1−ρ1)ρn2\n2(1−ρ2)...ρnk\nk(1−ρk)=ρn1\n1(1−ρ1).\nLikewise,\nP{nijobs at server i}=ρni\ni(1−ρi).\nThat means all servers still behave like M/M/1 queues in terms of their stationary queue\nlength distributions! This is really surprising because the arrival process into eachserver is notusually a Poisson process. Furthermore, by ( 17.6), the number of jobs at\nthe different queues is independent . Speciﬁcally, we have now proven Theorem 17.1.\nTheorem 17.1 A Jackson network with kservers has product form, namely,\nP/braceleftbigg\nState of network\nis(n1,n2,...,n k)/bracerightbigg\n=k/productdisplay\ni=1P{nijobs at server i}=k/productdisplay\ni=1ρni\ni(1−ρi).\nWarning: So far, we have only proven product form for networks of queues that ﬁt\nthe Jackson model; that is, there is a probabilistic routing between servers, the outsidearrivals are Poisson, the service times are Exponentially distributed, and jobs are served\nin FCFS order at each server.\nExample: Web Server\nConsider a web server that receives requests for ﬁles according to a Poisson arrival\nprocess, as shown in Figure 17.5. Each request requires alternating between the CPU\nand I/O some Geometrically distributed number of times as the ﬁle is segmented intopackets and sent to the network.\nCPU\nI/OPoisson ( λ) p\n1–pμ1\nμ2\nFigure 17.5. Example of a web server.\nQuestion: What is πn1,n2for Figure 17.5?\nAnswer: The system is a Jackson network. We ﬁrst solve for λ1andλ2:\nλ1=λ+λ2\nλ2=( 1−p)λ1",11909
114-17.5 Readings.pdf,114-17.5 Readings,,0
115-17.6 Exercises.pdf,115-17.6 Exercises,"306 networks of queues and jackson product form\nHence λ1=λ\npandλ2=λ\np(1−p). Thus,\nρ1=λ1\nμ1=λ\npμ1.\nρ2=λ2\nμ2=λ(1−p)\npμ2.\nWe can now substitute these values into\nπn1,n2=ρn1\n1ρn2\n2(1−ρ1)(1−ρ2).\nQuestion: What is the average number of jobs in the system, E[N]?\nAnswer:\nP{n1jobs at server 1}=ρn1\n1(1−ρ1).\nP{n2jobs at server 2}=ρn2\n2(1−ρ2).\nE[N1]=ρ1\n1−ρ1,E[N2]=ρ2\n1−ρ2,E[N]=E[N1]+E[N2].\n17.5 Readings\nJackson networks and their product form solution were introduced in [ 102]. This paper\nwas printed in Management Science’s “Ten Most Inﬂuential Titles of Management\nScience’s First Fifty Years.”\n17.6 Exercises\n17.1 Practice Analyzing Jackson Networks\nFigure 17.6 shows a queueing network with three FCFS servers. All servers\nhave Exponentially distributed service times with rates as shown. Outside\narrivals occur according to a Poisson process with rate λ=1packets/sec. The\nedges of the network indicate routing probabilities (assume 1 if none shown).\nWhat is the mean response time, E[T]?\nPoisson ( λ=1) μ1=3 μ2=5μ3=6\n0.250.75Server 2Server 3\nServer 1\nFigure 17.6. Queueing network from Exercise 17.1.\n17.2 More Practice Analyzing Jackson Networks\nA packet-switched Jackson network routes packets among two routers accord-ing to the routing probabilities shown in Figure 17.7. Notice that there are two\n17.6 exercises 307\npoints at which packets enter the network and two points at which they can\ndepart.\nPoisson ( r1)\nPoisson ( r2=1)μ1=3 μ2=5\nFigure 17.7. Jackson network from Exercise 17.2.\n(a) What is the maximum allowable rate r1that the network can tolerate? Call\nthisrmax\n1.\n(b) Set r1=0.9rmax\n1. What is the mean response time for a packet entering at\nthe router 1 queue?\n17.3 Queue with Feedback\nFigure 17.8 shows a simple queueing network. Jobs arrive according to a\nPoisson process with rate λ. When a job completes service, the job goes back\ninto the queue with probability pand leaves the system with probability 1−p.\nThus a single job may serve multiple times before leaving the system. Eachtime the job serves, its service time is a new Exponentially distributed random\nvariable with rate\nμ.\np\n1–p Poisson ( λ)\nFigure 17.8. Network with feedback from Exercise 17.3.\nYour goal is to derive the mean response time for a job in up to four different\nways. A job’s response time is the time from when the job ﬁrst arrives until itﬁnally leaves, including possibly multiple visits to the queue.\n(1) To start, use the theory of Jackson networks from this chapter to derive an\nexpression for the mean response time in terms of\nλ,μ, andp.\n(2) Now again derive the mean response time, but this time do it by solving a\nCTMC that tracks the number of jobs in the system (draw only transitions\nthatchange the state).\n(3) Tinglong makes the following suggestion: Why not view the whole network\nas a single M/M/1 where the arrival rate is ˆλ=λ\n1−pand the service rate\nisμ. Does Tinglong’s solution result in the correct mean response time?\nWhy or why not?\n(4) Runting makes a different suggestion: Let E[Tvisit]be the mean response\ntime experienced by jobs during one visit to the server (including queue-\ning plus service time). Then E[T]=E[Tvisit]·E[Number visits ]. Does\nRunting’s suggestion work? Why or why not?\n308 networks of queues and jackson product form\n17.4 Network with Feedback\nFor the Jackson network in Figure 17.9, assume that 0<p<q< 1and\nassume that ris chosen so as to not overload the network. Answer the following\nquestions:\np\n 1–pq\n 1–q Poisson ( r) µµ\nFigure 17.9. Network for Exercise 17.4.\n(a) Determine the mean response time, E[T], as a function of r,μ,p, andq.\n(b) If we interchange the order of the queues (i.e., the pandqare ﬂipped),\ndoesE[T]increase, decrease, or stay the same?\n17.5 Supercomputing Center\n(This result was originally proved in [ 7].) In a supercomputing center, arriving\njobs are parallel, typically running on several servers at once, as shown in\nFigure 17.10 . Consider a supercomputing center with kservers and no waiting\nroom, where outside arrivals occur according to a Poisson process with rate λ\n(think M/M/k/k). Assume that with probability pian arriving job is of “type i,”\nwhich means that the job requires iservers simultaneously. If there are fewer\nthaniservers free, the type ijob is dropped. Otherwise the type ijob grabs the\niservers that it needs and holds these for Exp (μi)time, after which it releases\nalliservers at once.\nPoisson ( λ) Service time ~ Exp ( μ3)Service time ~ Exp ( μ2)\nService time ~ Exp ( μ2)\nFigure 17.10. Supercomputing center with two jobs of type 2 and one job of type 3.\nLet(n1,n2,...,n k)be the state of the system, where niis the number of jobs\nof type i. Prove that\nπn1,n2,...,n k=k/productdisplay\ni=1ρni\ni\nni!·C,\nwhere ρi=λi\nμiandλi=λpiandCis a normalizing constant.\n17.6 exercises 309\n17.6 Cloud Service Center\n(This result was originally proved in [ 187].) A cloud service center consists\nof two server farms. The ﬁrst server farm has CPU-powerful servers, and the\nsecond has I/O-powerful servers. Each incoming request (job) to the cloudservice center asks for some number of CPU servers,\ni, and some number\nof I/O servers, j. Requests occur according to a Poisson process with rate λ,\nwhere a request is of type (i, j)with probability pij. If there are fewer than i\nfree CPU servers or fewer than jfree I/O servers, then a request of type (i,j)\nwill be dropped. Otherwise, the request will grab all its requested servers and\nwill hold these for time Exp (μij), after which it will release all the servers at\nonce. This is illustrated in Figure 17.11 .\nPoisson ( λ)CPU farmJob 1\nService time ~ Exp ( μ23)\nJob 2\nService time ~ Exp ( μ32)\nJob 3\nService time ~ Exp ( μ21)\nI/O farm\nFigure 17.11. Cloud service center where three requests are being satisﬁed.\nLet(n11,n12,...,n 1k,n21,n22,...,n 2k,...,n k1,nk2,...,n kk)denote the\nstate of the system, where nijis the number of jobs of type (i, j)in the system.\n310 networks of queues and jackson product form\nProve that\nπn11,n12,n13,...,n kk=k/productdisplay\ni=1k/productdisplay\nj=1ρnij\nij\nnij!·C,\nwhere ρij=λij\nμijandλij=λpijandCis a normalizing constant.",6235
116-Chapter 18 Classed Network of Queues.pdf,116-Chapter 18 Classed Network of Queues,,0
117-18.1 Overview.pdf,117-18.1 Overview,,0
118-18.2 Motivation for Classed Networks.pdf,118-18.2 Motivation for Classed Networks,"CHAPTER 18\nClassed Network of Queues\n18.1 Overview\nThroughout this chapter, when talking about a queueing network, we will use the\nvector,\n(n1,n2,...,n k),\nto denote that there are n1jobs at server 1 and n2jobs at server 2 and so on.\nIn the previous chapter, we saw that Jackson networks exhibit the “product form”property:\nP/braceleftbigg\nDistribution of jobs is\n(n1,n2,...,n k)/bracerightbigg\n=k/productdisplay\ni=1P{nijobs at server i}=k/productdisplay\ni=1ρni\ni(1−ρi)\nThe ﬁrst equality represents the fact that the queues behave in an independent fashion.\nThe second equality says that we can consider all the queues to behave as independentM/M/1 queues from a performance standpoint (although the arrival stream into each\nserver is not actually Poisson).\nIn the next several chapters, as well as in the exercises at the end of this chapter, we will\ngeneralize the Jackson result to a much broader class of networks that exhibit product\nform. For example, we ﬁnd in Chapter 19that product form holds for closed Jackson\nnetworks as well as open Jackson networks (for closed networks, the product form\nrequires a normalizing constant). We also ﬁnd in that chapter’s exercises that productform holds for Jackson-type networks where the service rate is allowed to depend onthe number of jobs at the server; see Exercise 19.3. These are called load-dependent\nservers. In particular, each server could be an M/M/k station. We furthermore ﬁnd thatwe can allow the routing probabilities,\nPij, (here i,jare servers, not states) to depend\nnot just on i, jbut also on the “class” of the packet or job. Such networks are called\nclassed networks and are the topic of the current chapter. Finally, in Chapter 22,w e\nprove product form results for networks of queues where the scheduling policy at the\nqueues is no longer FCFS. Throughout, we use the method of local balance.\n18.2 Motivation for Classed Networks\nWe provide three examples motivating the need for classed networks.\n311\n312 classed network of queues\nMotivating Example 1: Connection-Oriented Networks\nConsider a network where each packet follows a particular route based on its type. A\npacket’s type might, for example, be the concatenation of its source IP address andits destination IP address. For example, in the network shown in Figure 18.1 and the\nroutes shown in Figure 18.2, type 1 packets always follow “route 1,” meaning that they\ngo to server 1, then server 2, then server 3. Type 2 packets always follow “route 2,”\nmeaning that they ﬁrst go to server 3, then to server 2, then to server 4, then to server 5.\n23 1\n5Poisson ( r1)Poisson ( r3)\n4\nFigure 18.1. The network.\nAssume we know the average outside arrival rate of packets along each route. A typical\ngoal in such an example might be to determine E[T]for packets on route 2.\nRoute 1:\nRoute 2:2 1 3\n2 3 5 4\nFigure 18.2. The routes.\nQuestion: Why can’t we model this network as a Jackson network?\nAnswer: The probability of going from server 2 to server 3 depends on the route. If the\npacket is of type 1, then the packet leaving server 2 always goes to server 3. However,\nif the packet is of type 2, then the packet leaving server 2 never goes to server 3.\nSo we would like the routing probability to be able to depend on the type of the\npacket.\nMotivating Example 2: CPU-Bound and I/O-Bound Jobs\nConsider a computer system with two different workloads. Suppose that I/O-bound\njobs have a high probability of visiting the I/O device and a low probability of visiting\n18.2 motivation for classed networks 313\nthe CPU. In contrast, CPU-bound jobs have a high probability of visiting the CPU and\na low probability of visiting the I/O device.\nPoisson ( r1)\nPoisson ( r2)CPU\nI/O\nWe need different routing probabilities for the CPU-bound and I/O-bound jobs.\nMotivating Example 3: Service Facility with Repair Center\nJobs repeatedly visit some service facility. After each visit, with low probability the job\nneeds to go to the repair center. If a job ever visits the repair center, it gets repaired andreturns to the service facility; however, from then onward, there is a high probabilitythat this job will have to go to the repair center again.\nPoisson ( r)Service Facility\nRepair Center\nSo again we want the routing probability to depend on the “type” of job. We would like\nto differentiate between two types of jobs: “good” and “bad.” Good jobs have nevervisited the repair center, whereas bad jobs have visited the repair center.\nQuestion: What else do we need?\nAnswer: We need to be able to change a job’s type from “good” to “bad” once it visits\nthe repair center.\nSummary\nIn general, we would like our model to accommodate the following:\n1.The outside arrival rate at server\ni,ri(c), should depend on the job class c.\n2.The routing probabilities for moving from server ito server jshould be allowed\nto depend on the job class c.\n3.Jobs should be allowed to change classes after service.",4987
119-18.4 A Single-Server Classed Network.pdf,119-18.4 A Single-Server Classed Network,"314 classed network of queues\nTo accommodate items (2.) and (3.), we use P(c1)(c2)\nij to denote the probability that a\njob of class c1at server inext moves to server jand changes class to c2.\n18.3 Notation and Modeling for Classed Jackson Networks\nIn this section we deﬁne classed Jackson networks . We assume an open queueing\nnetwork with kservers and /lscriptclasses of packets. We deﬁne the following quantities:\nri=arrival rate to server ifrom outside the network\nri(c)=arrival rate of class cjobs to server ifrom outside the network\nλi=total arrival rate to server i,from both inside and outside\n=total departure rate from server i\nλi(c)=total arrival rate of class cjobs to server i\n=total departure rate of class cjobs from server i\nP(c)(c/prime)\nij =probability that job at server iof class cnext moves to server jand\nbecomes a class c/primejob\nμi=service rate at server i\nρi=λi\nμi=utilization at server i\nc(j)\ni=the class of the jth job in the queue at server i\nObserve that\nri=/lscript/summationdisplay\nc=1ri(c).\nλi=/lscript/summationdisplay\nc=1λi(c).\nRemark: It is important to note that, although the class of a packet determines the\nrouting probability, it does not determine the service rate at a server. The service rate at\nserver iis assumed to be μifor all packets. Although this is a drawback of the classed\nJackson model, it is not as limiting as it may seem in that the routing probability canbe used to force a certain class of packets to visit a server multiple times on average,thereby in effect creating a greater “service demand” at the server for that class.\nTypically, we are given the outside arrival rates,\nri(c), the per-class routing probabili-\nties,P(c)(c/prime)\nij , and the service rates, μi, for all i,j,c,c/prime, and we are asked to determine\nsome metric like E[Ni], the mean number of jobs at server i.\nQuestion: Can we solve for λj, the total arrival rate into server j, directly?\nAnswer: No. Here is an attempt:\nλj=rj+k/summationdisplay\ni=1λiPij,\nbutPijis not deﬁned.\n18.4 a single-server classed network 315\nHowever, we can compute λj(c), the arrival rate of class cjobs into server j.I ti s\ndetermined by solving the following system of simultaneous equations:\nλj(c)=rj(c)+k/summationdisplay\ni=1/lscript/summationdisplay\nc/prime=1λi(c/prime)P(c/prime)(c)\nij (18.1)\nThen we get λjby summing the per-class rates as follows:\nλj=/lscript/summationdisplay\nc=1λj(c)\nQuestion: We need to be able to derive limiting probabilities. What should the “states”\nof the CTMC look like?\nHint: What’s wrong with using (n1,n2,...,n k)where nidenotes the number of jobs\nat server i?\nAnswer: This is not detailed enough information for our CTMC because, to know the\nprobability of moving between states, we need to at least know the class of the job at\nthe head of the queue at each server.\nWe deﬁne the state of the network to be\nz=(z1,z2,...,z k),\nwhere ziis the state of server i. Speciﬁcally,\nzi=/parenleftBig\nc(1)\ni,c(2)i,...,c(ni)\ni/parenrightBig\n,\nwhere nidenotes the number of packets at server i, andc(1)\nidenotes the class of the\n1st job at server i(the one serving), c(2)\nidenotes the class of the 2nd job at server i,\nandc(ni)\nidenotes the class of the last job queued at server i.\nThus,\nz=(z1,z2,...,z k)\n=/parenleftBig/parenleftBig\nc(1)\n1,c(2)1,...,c(n1)\n1/parenrightBig\n,/parenleftBig\nc(1)2,c(2)2,...,c(n2)\n2/parenrightBig\n,...,/parenleftBig\nc(1)\nk,c(2)k,...,c(nk)\nk/parenrightBig/parenrightBig\n.\n18.4 A Single-Server Classed Network\nTo get a feel for classed networks, let’s start by considering the case where the whole\nnetwork consists of just a single server, say server 1. Server 1 represents a classedM/M/1 queue with\n/lscriptclasses of jobs (see Figure 18.3). Class cpackets arrive with\nrateλ1(c), and we use λ1to denote the total arrival rate from all classes into server\n1; that is, λ1=/summationtext\ncλ1(c). All packets are served with rate μ1. The class has no\neffect in this simple example, because all packets leave after serving (i.e., there is no\nrouting).\n316 classed network of queues\nPoisson ( λ1(2))\nPoisson ( λ1())Poisson ( λ1(1))\nμ1\nFigure 18.3. Single-server classed network.\nWe are interested in the limiting probability that the state of the system is\n(c(1)\n1,c(2)1,...,c(n1)\n1); that is, the probability that there are n1jobs in the system and\nthat their classes (in order from head to tail) are c(1)1,c(2)1,...,c(n1)\n1, respectively. Here\nc(i)\n1denotes the class of the ith job queued at server 1.\nQuestion: Can you guess what the limiting probability π(c(1)\n1,c(2)1,...,c(n1)\n1)looks like?\nAnswer: We know that the limiting probability must be related to the limiting prob-\nability that there are n1jobs in the system, which is ρn1\n1(1−ρ1), where ρ1=λ1\nμ1.\nHowever, we also know that we need to include the particular classes of the jobs. Thus\nit seems plausible that\nπ(c(1)\n1,c(2)1,...,c(n1)\n1)=λ1/parenleftBig\nc(1)\n1/parenrightBig\nλ1/parenleftBig\nc(2)1/parenrightBig\n···λ1/parenleftBig\nc(n1)\n1/parenrightBig\nμn1\n1·(1−ρ1).(18.2)\nObserve that, under the conjecture in ( 18.2),\nP{n1jobs at server }\n=/lscript/summationdisplay\nc(1)\n1=1/lscript/summationdisplay\nc(2)1=1···/lscript/summationdisplay\nc(n1)\n1=1π(c(1)\n1,c(2)1,...,c(n1)\n1)\n=/lscript/summationdisplay\nc(1)1=1/lscript/summationdisplay\nc(2)1=1···/lscript/summationdisplay\nc(n1)\n1=1λ1/parenleftBig\nc(1)\n1/parenrightBig\nλ1/parenleftBig\nc(2)1/parenrightBig\n···λ1/parenleftBig\nc(n1)\n1/parenrightBig\nμn1\n1·(1−ρ1)\n=( 1−ρ1)/lscript/summationdisplay\nc(1)\n1=1λ1/parenleftBig\nc(1)\n1/parenrightBig\nμ1·/lscript/summationdisplay\nc(2)\n1=1λ1/parenleftBig\nc(2)\n1/parenrightBig\nμ1···/lscript/summationdisplay\nc(n1)\n1=1λ1/parenleftBig\nc(n1)\n1/parenrightBig\nμ1\n=λn1\n1\nμn1\n1(1−ρ1)\n=ρn1\n1(1−ρ1)\nas desired.\nWe now prove that the guess in ( 18.2) satisﬁes the balance equations. We equate\nthe rate that we leave the state/parenleftBig\nc(1)\n1,c(2)1,...,c(n1)\n1/parenrightBig\nwith the rate that we enter\nthe state/parenleftBig\nc(1)1,c(2)1,...,c(n1)\n1/parenrightBig\n. Leaving the state happens when we are in the state/parenleftBig\nc(1)1,c(2)1,...,c(n1)\n1/parenrightBig\nand have either an arrival or a departure. Entering the state",6313
120-18.5 Product Form Theorems.pdf,120-18.5 Product Form Theorems,"18.5 product form theorems 317\noccurs in one of two ways: Either we are in state/parenleftBig\nc(1)\n1,c(2)1,...,c(n1−1)\n1/parenrightBig\nand we\nhave an arrival of class c(n1)\n1, which joins the end of the queue, orwe are in state/parenleftBig\nc,c(1)1,c(2)1,...,c(n1)\n1/parenrightBig\n, where the job at the head of the queue is of class c, and we\nhave a departure, so the job of class cleaves:\nRate Leave =Rate Enter\nπ(c(1)\n1,c(2)1,...,c(n1)\n1)(μ1+λ1)=π(c(1)1,c(2)1,...,c(n1−1)\n1)λ1/parenleftBig\nc(n1)\n1/parenrightBig\n+/summationdisplay\ncπ(c,c(1)\n1,c(2)1,...,c(n1)\n1)μ1\nSubstituting in our “guess” from ( 18.2), we note that, for example,\nπ(c,c(1)1,c(2)1,...,c(n1)\n1)=λ1(c)\nμ1π(c(1)1,c(2)1,...,c(n1)\n1),\nallowing us to reduce the rates of entering and leaving as follows:\nRate Leave =Rate Enter\nπ(c(1)1,c(2)1,...,c(n1)\n1)(μ1+λ1)=π(c(1)1,c(2)1,...,c(n1−1)\n1)λ1/parenleftBig\nc(n)\n1/parenrightBig\n+/summationdisplay\ncπ(c,c(1)1,c(2)1,...,c(n1)\n1)μ1\nπ(c(1)1,c(2)1,...,c(n1)\n1)(μ1+λ1)=μ1\nλ1/parenleftBig\nc(n1)\n1/parenrightBig·π(c(1)1,c(2)1,...,c(n1)\n1)λ1/parenleftBig\nc(n1)\n1/parenrightBig\n+/summationdisplay\ncλ1(c)\nμ1π(c(1)1,c(2)1,...,c(n1)\n1)μ1\nμ1+λ1=μ1\nλ1/parenleftBig\nc(n1)\n1/parenrightBig·λ1/parenleftBig\nc(n1)\n1/parenrightBig\n+/summationdisplay\ncλ1(c)\nμ1·μ1\nμ1+λ1=μ1+/summationdisplay\ncλ1(c)√\nWe have thus veriﬁed that the limiting probabilities for the M/M/1 classed queue are\ngiven by equation ( 18.2). We use this in the next section.\n18.5 Product Form Theorems\nTheorem 18.1 The classed network of queues with kservers has product form,\nnamely,\nπ(z1,z2,...,z k)=k/productdisplay\ni=1P{state at server iiszi},\n318 classed network of queues\nwhere zi=/parenleftBig\nc(1)\ni,c(2)i,...,c(ni)\ni/parenrightBig\n, and server ibehaves like an M/M/1 classed\nqueue . Speciﬁcally,\nP{state at server iiszi}=λi/parenleftBig\nc(1)\ni/parenrightBig\nλi/parenleftBig\nc(2)i/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμini·(1−ρi)\nProof We use the concept of local balance, as explained in Chapter 17.\nStatez\n≡(z1,z2,...,z k)\n=/parenleftBig/parenleftBig\nc(1)\n1,c(2)1,...,c(n1)\n1/parenrightBig\n,/parenleftBig\nc(1)2,c(2)2,...,c(n2)\n2/parenrightBig\n,...,/parenleftBig\nc(1)\nk,c(2)k,...,c(nk)\nk/parenrightBig/parenrightBig\nWe deﬁne (see Figure 18.4):\nA=rate at which leave state zdue to arrival from outside\nBi=rate at which leave state zdue to departure from server i(1≤i≤k)\nA/prime=rate at which enter state zdue to departure to outside\nB/prime\ni=rate at which enter state zdue to arrival at server i(1≤i≤k)\nNote that\nRate at which leave state z=k/summationdisplay\ni=1Bi+A\nA\nB\nBkRate\nleave\nstate zDue to\noutside\narrival\nDue to a\ndepart ure\nfrom...B1\nserver 1\nB2\nserver 2\nserver kA\nB\nBkRate\nenter\nstate zDue to\noutside\ndepart ure\nB1\nserver 1\nB2\nserver 2\nserver k=\n=\n=\n=\n=Bi Bi\nserver i server iDue to \nan arrival\nat...′\n′ ′\n′\n′\n′\nFigure 18.4. Balancing the rate of leaving and entering state z.\n18.5 product form theorems 319\nand\nRate at which enter state z=k/summationdisplay\ni=1B/prime\ni+A/prime.\nWe will make the following guess, inspired by our analysis of the single-server classed\nnetwork, see ( 18.2):\nπz=π(z1,z2,...,z k)=k/productdisplay\ni=1(1−ρi)λi/parenleftBig\nc(1)\ni/parenrightBig\nλi/parenleftBig\nc(2)i/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμni\ni(18.3)\nwhere ρi=λi\nμiandλi=/summationtext/lscript\nc=1λi(c).\nIt sufﬁces to show that our guess satisﬁes Bi=B/prime\nifor all 1≤i≤kandA=A/prime.W e\nwill now prove each of these statements.\nTo simplify notation, when denoting the state of the system, we will assume that the\nstate at each server iis the usual zi=/parenleftBig\nc(1)\ni,c(2)i,...,c(ni)\ni/parenrightBig\n, unless otherwise stated.\nThus we will typically show only the state at those servers at which a job arrives or\ndeparts. To keep the number of cases down, we will for now ignore border cases wherethere are zero jobs at one or more queues. These cases can be handled very similarly\nto what is done here. One last remark: In the derivation of the unclassed Jacksonnetworks (Theorem 17.1), we viewed the rate of leaving a state (or entering a state)\nas including only transitions that change the state, not transitions that return to the\nsame state. However, in the following derivation, it is easier to broaden the deﬁnitionof leaving the state (or entering) to include transitions back into the same state. Noneof this affects the validity of the balance equations.\nTo show\nBi=B/prime\nifor all 1≤i≤k:\nBi=Rate at which leave state zdue to departure from server i\n=π(z1,z2,...,z k)·μi\nNote that the service rate does not depend on the class of the job.\nB/prime\ni=Rate at which enter state zdue to arrival at server i\n=π(...,(c(1)\ni,c(2)i,...,c(ni−1)\ni),...)·ri/parenleftBig\nc(ni)\ni/parenrightBig\n+k/summationdisplay\nj=1/lscript/summationdisplay\ncj=1π/parenleftBig\n...,(c(1)\ni,c(2)i,...,c(ni−1)\ni),...,/parenleftBig\ncj,c(1)j,...,c(nj)\nj/parenrightBig\n,.../parenrightBig·μjP(cj)(c(ni)\ni)\nji\n=π(z1,z2,...,z k)·μi\nλi/parenleftBig\nc(ni)\ni/parenrightBig·ri/parenleftBig\nc(ni)\ni/parenrightBig\n+k/summationdisplay\nj=1/lscript/summationdisplay\ncj=1π(z1,z2,...,z k)·μi\nλi/parenleftBig\nc(ni)\ni/parenrightBig·λj(cj)\nμj·μjP(cj)(c(ni)\ni)\nji\n320 classed network of queues\n=πz·μi\nλi/parenleftBig\nc(ni)\ni/parenrightBig·⎡\n⎣ri/parenleftBig\nc(ni)\ni/parenrightBig\n+k/summationdisplay\nj=1/lscript/summationdisplay\ncj=1λj(cj)P(cj)(c(ni)\ni)\nji⎤⎦\n=π\nz·μi\nλi/parenleftBig\nc(ni)\ni/parenrightBig·λi/parenleftBig\nc(ni)\ni/parenrightBig\n(by Equation ( 18.1))\n=πz·μi\n=Bi\nTo show A=A/prime:\nA=Rate at which leave state zdue to outside arrival\n=π(z1,z2,...,z k)·k/summationdisplay\ni=1/lscript/summationdisplay\nc=1ri(c)\nA/prime=Rate at which enter state zdue to departure to outside\n=k/summationdisplay\ni=1/lscript/summationdisplay\nci=1π(...,(ci,c(1)\ni,...,c(ni)\ni),...)·μiP(ci)(∗)\ni,out (the(∗)denotes any class)\n=π(z1,z2,...,z k)·k/summationdisplay\ni=1/lscript/summationdisplay\nci=1λi(ci)\nμi·μiP(ci)(∗)\ni,out\n=π(z1,z2,...,z k)·k/summationdisplay\ni=1/lscript/summationdisplay\nci=1λi(ci)P(ci)(∗)\ni,out\nNow observe that\nA=πz·(total rate of entering the network from outside )\nA/prime=πz·(total rate of leaving the network )\nBecause the network is in equilibrium, the total average rate of entering the network\nmust equal the total average rate of leaving the network; hence we have A=A/prime.√\nVerify that the product form holds :\nWe would like to show that\nπ(z1,z2,...,z k)=k/productdisplay\ni=1P{state at server iiszi},\ngiven our guess from ( 18.3) that\nπ(z1,z2,...,z k)=k/productdisplay\ni=1(1−ρi)λi/parenleftBig\nc(1)\ni/parenrightBig\nλi/parenleftBig\nc(2)i/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμni\ni.\nTo compute P{state at server iiszi}, we simply sum ( 18.3) over all zj, where j/negationslash=i.\nObserve that summing over zjinvolves both summing over all possible classes in the\n18.5 product form theorems 321\nvector/parenleftBig\nc(1)\nj,c(2)j,...,c(nj)\nj/parenrightBig\nand also summing over all possible values of nj. This is\nillustrated in the following expressions:\nP{state at server iiszi}\n=/summationdisplay\nzj,j/negationslash=iπ(z1,z2,...,z k)\n=( 1−ρi)λi/parenleftBig\nc(1)i/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμni\ni\n×k/productdisplay\nj=1,j/negationslash=i∞/summationdisplay\nnj=0/summationdisplay\nc(1)\nj,...,c(nj)\nj(1−ρj)λj/parenleftBig\nc(1)\nj/parenrightBig\n···λj/parenleftBig\nc(nj)\nj/parenrightBig\nμnj\nj\n=( 1−ρi)λi/parenleftBig\nc(1)\ni/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμni\nik/productdisplay\nj=1,j/negationslash=i∞/summationdisplay\nnj=0(1−ρj)λnj\nj\nμnj\nj\n=( 1−ρi)λi/parenleftBig\nc(1)\ni/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμni\nik/productdisplay\nj=1,j/negationslash=i1\n=( 1−ρi)λi/parenleftBig\nc(1)i/parenrightBig\n···λi/parenleftBig\nc(ni)\ni/parenrightBig\nμni\ni\nHence we can rewrite ( 18.3)a s\nπ(z1,z2,...,z k)=k/productdisplay\ni=1P{state at server iiszi},\nwhich is the deﬁnition of product form.\nCorollary 18.2 In a classed network of queues, the number of jobs in each queue\nobeys the following distribution:\nP/braceleftbigg\nDistribution of jobs is\n(n1,n2,...,n k)/bracerightbigg\n=k/productdisplay\ni=1P{nijobs at server i}=k/productdisplay\ni=1ρni\ni(1−ρi)\nObserve that Corollary 18.2 is identical to what we proved for the unclassed Jackson\nnetwork.\nProof We again use the shorthand:\nzi=/parenleftBig\nc(1)\ni,c(2)i,...,c(ni)\ni/parenrightBig",8660
121-18.6 Examples Using Classed Networks.pdf,121-18.6 Examples Using Classed Networks,"322 classed network of queues\nP{Distribution of jobs is (n1,n2,...,n k)}\n=/summationdisplay\nc(1)\n1...c(n1)\n1,...,c(1)\nk...c(nk)\nkP⎧\n⎪⎪⎨\n⎪⎪⎩state at server 1isz1,\nstate at server 2isz2,\n...\nstate at server kiszk⎫\n⎪⎪⎬\n⎪⎪⎭\n(Thm 18.1)=/summationdisplay\nc(1)\n1...c(n1)\n1,...,c(1)\nk...c(nk)\nkk/productdisplay\ni=1P{state at server iiszi}\n=k/productdisplay\ni=1/summationdisplay\nc(1)\ni...c(ni)\niP/braceleftBig\nstate at server iis/parenleftBig\nc(1)\ni,...,c(ni)\ni/parenrightBig/bracerightBig\n=k/productdisplay\ni=1/summationdisplay\nc(1)\ni...c(ni)\niλi/parenleftBig\nc(1)\ni/parenrightBig\nλi/parenleftBig\nc(2)i/parenrightBig\n...λ i/parenleftBig\nc(ni)\ni/parenrightBig\nμini·(1−ρi)\n=k/productdisplay\ni=1ρni\ni·(1−ρi)\nThus, we have shown that\nP{Distribution of jobs is (n1,n2,...,n k)}=k/productdisplay\ni=1ρni\ni·(1−ρi).(18.4)\nSumming both sides of ( 18.4) over all i/negationslash=j, we have further shown that\nP{njjobs at server j}=ρnj\nj(1−ρj).\nHence we have shown that\nP{Distribution of jobs is (n1,n2,...,n k)}=k/productdisplay\ni=1P{nijobs at server i}.\n18.6 Examples Using Classed Networks\nIn this section, we elaborate on some of the motivating examples mentioned in Sec-\ntion18.2. Our ﬁrst example only requires Corollary 18.2, whereas the other examples\nneed the full power of Theorem 18.1.\n18.6.1 Connection-Oriented ATM Network Example\nConsider a connection-oriented network (not shown) with particular routes along whichpackets ﬂow. The routes are shown in Figure 18.5.\n18.6 examples using classed networks 323\nRoute 1:\nPoisson (3 pkts/sec) o ut\nout\nout\noutRoute 2:\nPoisson (4 pkts/sec)\nRoute 3:\nPoisson (5 pkts/sec)\nRoute 4:\nPoisson (6 pkts/sec)1 2 3\n1 3 4\n22\n33 4\nµ2 = 10 µ1 = 10 µ3 = 20 µ4 = 10\nFigure 18.5. Routes for connection-oriented network.\nGoal: We want to determine E[T]for packets on route 2.\nQuestion: How can we express this problem as a classed network?\nAnswer: We want to associate the packets on each route with a particular class.\nri(c)=outside arrival rate into server iof class cpackets\nP(c)\nij=probability that when a packet of class cﬁnishes at server i,\nit next moves to server j\nλi(c)=total arrival rate into server iof class cpackets\nSo, we have the following:\nFor class 1: r1(1) = 3; P(1)\n12=1 ; P(1)\n23=1 ; P(1)\n3,out=1\nFor class 2: r1(2) = 4; P(2)\n13=1 ; P(2)\n34=1 ; P(2)\n4,out=1\nFor class 3: r2(3) = 5; P(3)\n23=1 ; P(3)\n34=1 ; P(3)\n4,out=1\nFor class 4: r3(4) = 6; P(4)\n3,out=1\nAll other ri(c)’s and P(c)\nij’s are zero.\nNow, we can solve for the λi(c)’s by solving these simultaneous equations:\nλj(c)=rj(c)+/summationdisplay\niλi(c)P(c)\nij\n324 classed network of queues\nHowever, in this case, the problem is so easy that we can determine the λj(c)’s by sight\n(it helps to read these from right to left):\nλ3(1) = λ2(1) = λ1(1) = r1(1) = 3 jobs/sec\nλ4(2) = λ3(2) = λ1(2) = r1(2) = 4 jobs/sec\nλ4(3) = λ3(3) = λ2(3) = r2(3) = 5 jobs/sec\nλ3(4) = r3(4) = 6 jobs/sec\nQuestion: How do we determine the λi’s?\nAnswer:\nλj=Total arrival rate into server j=/lscript/summationdisplay\nc=1λj(c).\nλ1=λ1(1) + λ1(2) = 3 + 4 = 7 jobs/sec\nλ2=λ2(1) + λ2(3) = 3 + 5 = 8 jobs/sec\nλ3=λ3(1) + λ3(2) + λ3(3) + λ3( 4 )=3+4+5+6=1 8 jobs/sec\nλ4=λ4(2) + λ4(3) = 4 + 5 = 9 jobs/sec\nQuestion: How do we determine the ρi’s?\nAnswer:\nρi=load at server i=λi\nμi.\nρ1=7\n10;ρ2=8\n10;ρ3=18\n20;ρ4=9\n10.\nQuestion: What is E[Tfor route 2 packets ]?\nAnswer: We ﬁrst determine the expected time that is spent at each server by determining\nthe expected number of packets at each server and applying Little’s Law.\nE[Ni]=Expected number of packets at server i=ρi\n1−ρi.\nE[N1]=0.7\n0.3=7\n3;E[N2]=4 ; E[N3]=9 ; E[N4]=9\nE[Ti]=Expected time at server iper visit =E[Ni]\nλi\nE[T1]=E[N1]\nλ1=7/3\n7=1\n3sec\nE[T2]=E[N2]\nλ2=4\n8=1\n2sec\nE[T3]=E[N3]\nλ3=9\n18=1\n2sec\nE[T4]=E[N4]\nλ4=9\n9=1sec\n18.6 examples using classed networks 325\nThe total time a packet spends on route 2 is the sum of the times spent at each server\nthat it visits.\nE[Tfor packets on route 2 ]=E[T1]+E[T3]+E[T4]=11\n6sec\n18.6.2 Distribution of Job Classes Example\nIn the previous example, we only needed Corollary 18.2. Sometimes we need the more\npowerful Theorem 18.1. Suppose, for example, that there are only two job types called\nclass1and class 2, and we want to know the probability that there are exactly sjobs\nof class 1 and tjobs of class 2 at server i. Theorem 18.1 implies\nP{Server ihassjobs of class 1andtjobs of class 2}\n=/parenleftbigg\ns+t\ns/parenrightbiggλi(1)sλi(2)t\nμs+t\ni·(1−ρi),\nwhere ρi=λi\nμiandλi=λi(1) + λi(2).\nLet’s see if we can write this expression in a more intuitive way:\nP{Server ihassjobs of class 1andtjobs of class 2}\n=/parenleftbigg\ns+t\ns/parenrightbiggλi(1)sλi(2)t\nμs+t\ni·(1−ρi)\n=/parenleftbigg\ns+t\ns/parenrightbiggλi(1)sλi(2)t\nμs+t\niρs+t\ni·ρs+t\ni(1−ρi)\n=/parenleftbigg\ns+t\ns/parenrightbiggλi(1)sλi(2)t\nλs+t\ni·ρs+t\ni(1−ρi)\n=/parenleftbigg\ns+t\ns/parenrightbigg/parenleftbiggλi(1)\nλi/parenrightbiggs\n·/parenleftbiggλi(2)\nλi/parenrightbiggt\n·ρs+t\ni(1−ρi)\n=/bracketleftBigg/parenleftbigg\ns+t\ns/parenrightbigg/parenleftbiggλi(1)\nλi(1) + λi(2)/parenrightbiggs\n·/parenleftbiggλi(2)\nλi(1) + λi(2)/parenrightbiggt/bracketrightBigg\n·/bracketleftbig\nρs+t\ni(1−ρi)/bracketrightbig\n(18.5)\nWe have written the result as a product of two factors (in brackets).\nQuestion: What is the right factor in ( 18.5)?\nAnswer: The right factor is just the probability that there are s+tjobs at server i.\nQuestion: What is the left factor in ( 18.5)?\nAnswer: By deﬁnition the left factor of ( 18.5) must represent the probability that there\naresjobs of type 1 and tjobs of type 2 at server i, given that there are s+tjobs total\nat server i. In fact, setting\np=λi(1)\nλi(1) + λi(2)=λi(1)\nλi=Fraction of type 1 arrivals at server i,\n326 classed network of queues\nwe can rewrite the left factor of ( 18.5)a s\n/parenleftbiggs+t\ns/parenrightbigg\nps(1−p)t(18.6)\nIf we now think of each job at server ias independently being of type 1 with probability\npand type 2otherwise, we see that ( 18.6) represents exactly what we want, namely\nthe probability that there are sjobs of type 1 and tof type 2 at server i, given that there\nares+tjobs total at server i.\n18.6.3 CPU-Bound and I/O-Bound Jobs Example\nHere is a more complex example. Your system consists of two devices: a CPU device\nwith Exponential service rate 2 jobs/sec and an I/O device with Exponential servicerate 1 job/sec. There are two different types of jobs: CPU-bound jobs andI/O-bound\njobs.\nCPU-bound jobs arrive at the CPU from outside according to a Poisson process of rate\n0.2 jobs/sec. After serving at the CPU, three things can happen to a CPU-bound job:\n1.With probability 0.3, the job leaves the system.\n2.With probability 0.65, the job returns to the CPU queue to repeat the process.\n3.With probability 0.05, the job goes to the I/O device queue, serves there once,\nand immediately returns to the CPU queue to repeat the process.\nThe I/O-bound jobs arrive at the I/O from outside the network according to a Poissonprocess with rate 0.25 jobs/sec. After serving at the I/O, there are three things that can\nhappen to an I/O-bound job:\n1.With probability 0.4, the job leaves the system.\n2.With probability 0.5, the job returns to the I/O queue to repeat the process.\n3.With probability 0.1, the job goes to the CPU device queue. Each time\nthe job serves at the CPU device, it has a 0.05 probability of return-\ning to the CPU device and a 0.95 probability of returning to the I/O\nqueue.\nOur goal is to answer the following questions:\n(a)What is the expected time in system of CPU-bound jobs?\n(b)What is the average number of CPU-bound jobs at the CPU?\nSolution: We model the routing of jobs between servers as shown in Figure 18.6. Let\nthe CPU be device 1 and the I/O be device 2. Also, let\nCbe the class of a CPU-bound\njob and Ibe the class of an I/O-bound job.\nFor the CPU-bound jobs,\nλC\n1=rC\n1+λC1·PC\n1,1+λC2·PC\n2,1\n=0.2+0.65λC1+λC2.\nλC2=rC\n2+λC2·PC\n2,2+λC1·PC\n1,2=0.05λC1.\n18.6 examples using classed networks 327\nDevice 2: I/ODevice 1: C PU\nP1,out= 0.3C\nP2,out= 0.4  I\np2,2= 0.5  IP1,1= 0.65 CP1,1= 0.05  I\nP1,2= 0.05  CP2,1= 0.1  IP1,2= 0.95  I\nP2,1= 1  C  Cr1= 0.2\nr2= 0.25  I\nFigure 18.6. Class-based routing probabilities.\nSolving these simultaneous equations, we get\nλC\n1=2\n3,λC\n2=1\n30.\nSimilarly for the I/O-bound jobs,\nλI\n1=rI\n1+λI\n1·PI\n1,1+λI\n2·PI\n2,1\n=0.05λI\n1+0.1λI\n2.\nλI\n2=rI\n2+λI\n2·PI\n2,2+λI\n1·PI\n1,2\n=0.25 + 0 .95λI\n1+0.5λI\n2.\nAgain we solve these simultaneous equations and get\nλI1=5\n76,λI\n2=5\n8.\nWe now ﬁnd the other parameters that we are interested in:\nλ1=λC\n1+λI\n1=0.7325\nλ2=λC\n2+λI\n2=0.6583\nρ1=λ1\nμ1=0.3663\nρ2=λ2\nμ2=0.6583\nE[N1]=ρ1\n1−ρ1=0.578\nE[N2]=ρ2\n1−ρ2=1.9265\nE[T1]=E[N1]\nλ1=0.7895\nE[T2]=E[N2]\nλ2=2.9265\n328 classed network of queues\n(a) What is the expected time in system of CPU-bound jobs?\nLet the expected time in system of CPU-bound jobs be E[TC].\nMethod 1\nE/bracketleftbig\nTC/bracketrightbig\n=0.3E[T|leaves after visiting 1 ]\n+0.65E[T|loops back to 1 ]\n+0.05E[T|loops back to 1 via 2 ]\n=0.3E[T1]+0.65(E[T1]+E/bracketleftbig\nTC/bracketrightbig\n)+0.05(E[T1]+E[T2]+E/bracketleftbig\nTC/bracketrightbig\n)\nE/bracketleftbig\nTC/bracketrightbig\n=3.117\nMethod 2\nE/bracketleftbig\nTC/bracketrightbig\n=E/bracketleftbig\nVC\n1/bracketrightbig\n·E[T1]+E/bracketleftbig\nVC\n2/bracketrightbig\n·E[T2]\nWe obtain E[VC\n1]andE[VC\n2]by solving these simultaneous equations:\nE/bracketleftbig\nVC\n1/bracketrightbig\n=1+0 .65E/bracketleftbig\nVC\n1/bracketrightbig\n+1.0E/bracketleftbig\nVC\n2/bracketrightbig\nE/bracketleftbig\nVC\n2/bracketrightbig\n=0.05E/bracketleftbig\nVC\n1/bracketrightbig\n(b) What is the average number of CPU-bound jobs at the CPU?\nQuestion: We need to ﬁnd E[NC\n1]. How can we do this?\nHint: Use ( 18.5).\nAnswer: From ( 18.5) it follows that the expected number of CPU-bound jobs at server\n1 is the expected number of jobs at server 1multiplied by p, the fraction of those jobs\nthat are CPU-bound jobs. That is,\nE/bracketleftbig\nNC\n1/bracketrightbig\n=E[Number jobs at CPU ]·p=ρ1\n1−ρ1·λC\n1\nλC\n1+λI1.\nIn case the above is not obvious, here is a full derivation:\nE/bracketleftbig\nNC\n1/bracketrightbig\n=∞/summationdisplay\ns=0P{sjobs of type Cat server 1}·s\n=∞/summationdisplay\ns=0∞/summationdisplay\nn1=sP{sjobs of type Cat server 1 and n1jobs total}·s",10538
122-18.7 Readings.pdf,122-18.7 Readings,,0
123-18.8 Exercises.pdf,123-18.8 Exercises,"18.8 exercises 329\n=∞/summationdisplay\ns=0∞/summationdisplay\nn1=s/parenleftBign1\ns/parenrightBig\nps(1−p)n1−s·ρn1\n1(1−ρ1)·sby (18 .5)\n=∞/summationdisplay\nn1=0ρn1\n1(1−ρ1)/parenleftBiggn/summationdisplay\ns=0/parenleftBign1\ns/parenrightBig\nps(1−p)n1−s·s/parenrightBigg\n=∞/summationdisplay\nn1=0ρn1\n1(1−ρ1)(n1·p)(mean of Binomial (n1,p))\n=E[N1]·p.\n18.7 Readings\nA nice example of using a classed Jackson network to solve a problem is provided in\nthe SIGCOMM ’99 best student paper [ 145].\n18.8 Exercises\n18.1 Classed Queueing Network\nThe server in Figure 18.7 processes jobs at an Exponential rate of μ=1 0\njobs/sec. There are two types of jobs being served at the FCFS server. Jobs\nof type 1 arrive according to a Poisson process with rate r(1)=0.5jobs/sec.\nAfter each visit to the server, they require an additional visit with probability\n0.75. Jobs of type 2 arrive according to a Poisson process with rate r(2)=3\njobs/sec. After each visit to the server, they require an additional visit with\nprobability 0.5. What is the mean response time for jobs of type 1? Type 2?\nr(1) = 0.5\nr(2) = 3.0P(1) = 0.75\nP(2) = 0.5\nμ=10\nFigure 18.7. Classed queueing network.\n18.2 Quick versus Slow Customers\nConsider a single queue with a single service station with service time dis-\ntributed Exponentially with mean 1. There are two types of customers:\n1. “Quick customers” arrive according to a Poisson process with rate1\n3, visit\nthe server once, and leave.\n2. “Slow customers” arrive according to a Poisson process with rate1\n6and\nvisit the server a Geometric number of times with mean 3.\nOn average, how many quick customers and how many slow customers are in\nthe system?\n330 classed network of queues\n18.3 Jobs Needing Repair\nA system consists of a service facility and a repair facility. The service time\nat both facilities is Exp/parenleftbig1\n10/parenrightbig\n. Jobs arrive at the service facility according to\na Poisson process with rate λ. After each visit to the service facility, the job\neither:\nrleaves the system (probability 0.1)\nrrequires repair (probability 0.01)\nrrevisits the service facility (probability 0.89).\nAfter completing repair, a job returns to the service facility, except that now,after each visit to the service facility, the job either:\nrleaves the system (probability 0.1)\nrrequires repair (probability 0.5)\nrrevisits the service facility (probability 0.4).\nPlease answer the following questions about the system:(a) What is the expected number of times that a job visits the service facility?\n(b) What is the highest possible throughput,\nλ?\n(c) Set λ=1\n200. What is the expected time in system, E[T]?\n18.4 Class-Based Service Rates?\nConsider a Jackson network with /lscriptclasses. Until now we have always assumed\nthat the service rate is the same for each of the classes. Suppose you want tohave the service rate depend on the class of the job (e.g., jobs of class\ncare\nserved at rate μ(c)). Can you solve balance equations for the case of a single\nserver with class-dependent service rates? Why or why not? If you can, do itand determine the limiting probabilities:\nπ(c(1),...,c(n)), where c(i)denotes the\nclass of the ith job in queue at the server.\n18.5 Distribution of Job Classes\nIn Section 18.6.2 , we considered a network with two classes of jobs and derived\nthe probability that server ihassjobs of class 1 and tjobs of class 2, namely:\nP{Server ihassjobs of class 1andtjobs of class 2}\n=/bracketleftBigg/parenleftbigg\ns+t\ns/parenrightbigg/parenleftbiggλi(1)\nλi(1) + λi(2)/parenrightbiggs\n·/parenleftbiggλi(2)\nλi(1) + λi(2)/parenrightbiggt/bracketrightBigg\n·/bracketleftbig\nρs+t\ni(1−ρi)/bracketrightbig\n.\n(a) Generalize this expression to /lscriptclasses; namely, derive\nP{Server ihasm1jobs of class 1,m2of class 2,...,m /lscriptof class /lscript}.\n(b) Provide an expression for the expected number of class 1 jobs at server i.\n18.6 Not All Networks Have Product Form\nGive an example of a 2-server network that does nothave a product form\nlimiting distribution. Analyze the limiting distribution of your network and\nprove that there exist n1,n2, such that\nP{n1jobs at server 1 & n2jobs at server 2 }\n/negationslash=P{n1jobs at server 1 }·P{n2jobs at server 2 }.",4283
124-Chapter 19 Closed Networks of Queues.pdf,124-Chapter 19 Closed Networks of Queues,,0
125-19.1 Motivation.pdf,125-19.1 Motivation,"CHAPTER 19\nClosed Networks of Queues\nThus far, all of our analysis of networks of queues involved open queueing networks.\nWe have witnessed the product form property for Jackson-type networks (those with\nprobabilistic routing), which has allowed us to instantly derive the probability distribu-tion of the number of jobs at each of the servers. It turns out that the same basic productform idea applies to closed queueing networks. The only difference is that additional\nwork is involved in computing the normalizing constant for the case of closed networks,\nwhereas it has a simple closed form for the case of open networks.\nIn this chapter, we brieﬂy illustrate the product form analysis of closed queueing\nnetworks with probabilistic routing, also known as closed Jackson networks. To keepthings simple, we stick to single-class networks, although everything that we say\napplies to multi-class networks as well. Also, we throughout assume a batch closed\nnetwork, meaning zero think time (see Section 2.6.2 ). The extension to interactive\nclosed networks is studied in the Exercise 19.3(4).\n19.1 Motivation\nConsider a closed system with multiple queues and probabilistic routing between the\nqueues, as shown in the batch network in Figure 19.1. Our goal might be to determine\nthe probability that there are 2jobs at the third server.\nN = 2\nμ2\nμ3μ1p\n1–p\nFigure 19.1. Example of a closed batch network.\nFor this example, the possible states are (0,0,2),(0,2,0),(2,0,0),(1,0,1),(1,1,0),\nand(0,1,1). The corresponding 6-state Markov chain results in a ﬁnite number of\n331\n332 closed networks of queues\nsimultaneous equations, which can be solved to obtain the limiting probability of being\nin each state. In particular, we can obtain π0,0,2, which is what we wanted. The Markov\nchain is shown in Figure 19.2.\n3\n2 2 1p 1p\n1p1(1–p) 1(1–p)3\n1(1–p)3\n21,1,0\n0,2,02,0,0 0,0, 2 1,0,1\n0,1,1\nFigure 19.2. The corresponding CTMC.\nIn fact, any closed batch network is solvable, at least in theory, because we are dealing\nwith a ﬁnite number of simultaneous equations. Provided that the total number of jobs,\nN, and the total number of servers/queues, k, are not too large, speciﬁc instances of the\nclosed network (meaning chains with speciﬁc values of the μi’s) should be tractable.\nLet’s make this more concrete.\nQuestion: Suppose there are kservers and Njobs total. What is the number of\nsimultaneous balance equations that need to be solved for the CTMC?\nAnswer:\nNumber of simultaneous equations =Number of states =/parenleftbigg\nN+k−1\nk−1./parenrightbigg\n.\nNote: This expression represents all the ways of dividing the Njobs among kservers\nor, alternatively, of distributing k−1“dividers” into N+k−1slots, as shown in\nFigure 19.3.\nFigure 19.3. Distributing a dozen balls into 5 bins (the 4th is empty).\nThe point of this chapter is to ﬁnd a faster way to get to the limiting probabilities. We\nwant to be able to express these limiting probabilities in closed form, as a function ofthe\nμi’s and routing probabilities.",3061
126-19.2 Product Form Solution.pdf,126-19.2 Product Form Solution,"19.2 product form solution 333\n19.2 Product Form Solution\nWe consider a general closed batch Jackson-type network. This is characterized by the\nfollowing properties. There are kservers, each with a FCFS queue. There is probabilistic\nrouting between the servers: With probability Pij, when a job leaves server i,i tn e x t\ngoes to server j, as for example in Figure 19.4. There are no outside arrivals and no\ndepartures to the outside. There is a ﬁxed multiprogramming level, N. That is, there\nare exactly Njobs in the network at any time. The state is (n1,n2,...,n k), where ni\ndenotes the number of jobs at server i.\np12\np32 p23 p31μ1 μ2\nμ3\nFigure 19.4. Closed batch Jackson network.\nQuestion: It seems that a closed Jackson network is deﬁned exactly like an open\nJackson network, except for what?\nAnswer: For the closed network, ri=0andPi,out=0for all i.\nThus, the balance equations for closed networks are identical to the balance\nequations for the open networks, except that some of the terms ( ri’s and Pi,out’s)\nare now set to zero. Thus it would seem that\nπn1,...,n k=Cρn1\n1ρn2\n2...ρnk\nk (19.1)\nmight still work as a solution for the limiting probabilities. However, the set of balance\nequations in a closed network is a subset of the set of balance equations in the open\nnetwork; some states are not allowed in the closed network because the number of jobs\nin the system do not sum up to N. Hence it is not obvious that the guess in ( 19.1) will\nwork.\n19.2.1 Local Balance Equations for Closed Networks\nThe local balance equations for a closed network equate Bi, the rate of leaving a state\ndue to a departure from server i, withB/prime\ni, the rate of entering the state due to an arrival\nat server i. In both BiandB/prime\ni, we will allow for transitions which take us back to the\nsame state.\nQuestion: Why don’t we need to worry about A=A/prime?\nAnswer: There are no outside departures or arrivals.\n334 closed networks of queues\nWe now need to check that the guess in ( 19.1) satisﬁes Bi=B/prime\ni.\nBi\nRate leave state (n1,n2,...,n k)\ndue to departure from server i=B/prime\ni\nRate enter state (n1,n2,...,n k)\ndue to arrival at server i\nπn1,...,n k·μi=k/summationdisplay\nj=1πn1,...,n i−1,...,n j+1,...,n k·μj·Pji\nμi=k/summationdisplay\nj=1ρj\nρiμj·Pji\nλi=k/summationdisplay\nj=1λj·Pji\nThe ﬁnal line simply states that the total arrival rate into server iis the sum of the de-\nparture rates into server ifrom the other servers. This is obviously true, so we are done.\nQuestion: Great, so we have veriﬁed that\nπn1,...,n k=Cρn1\n1ρn2\n2...ρnk\nk.\nBut what is ρi?\nAnswer: ρi=λi\nμi\nQuestion: But how do we determine λi?\nAnswer: For open networks, we determined λiby solving ksimultaneous equations:\nλi=ri+k/summationdisplay\nj=1λjPji\nQuestion: Suppose we try solving these simultaneous equations for the case of a closed\nnetwork. What goes wrong?\nAnswer: For closed networks, ri=0so theksimultaneous equations only have k−1\nlinearly independent variables. So we cannot get a unique solution.\nFor example, consider the closed network of servers shown in Figure 19.5.\nμ1\nμ20.5\n0.70.3 0.5\nFigure 19.5. Simple example.\nThe simultaneous equations are\nλ1=λ2(0.7) +λ1(0.5).\nλ2=λ1(0.5) +λ2(0.3).\n19.2 product form solution 335\nBoth equations are the same. So λ2=5\n7λ1, but we do not know λ1.\nAnother way to think about this is that we only know the λi’s to within a constant\nfactor. That is, we know\n(cλ1,c λ2,...,cλ k)\nbut we do not know what cis. This turns out to be OK, however, because the c’s get\nhidden into the normalizing constant in the limiting probabilities:\nπn1,...,n k=C/parenleftbigg\ncλ1\nμ1/parenrightbiggn1/parenleftbigg\ncλ2\nμ2/parenrightbiggn2\n.../parenleftbigg\ncλk\nμk/parenrightbiggnk\n=CcNρn1\n1...ρnk\nk\n=C/primeρn1\n1...ρnk\nk\nWhat is important in this expression is that the ﬁnal constant, C/prime, is the same for any\nstate of the CTMC. We summarize the procedure below.\nSolving Closed Batch Jackson Networks :\n1.Determine λi’s. To do this, solve the simultaneous rate equations. You will\nhave an inﬁnite number of solutions that work. Pick any one solution (e.g.,\nsetλ1=1).\n2.Compute ρi=λi\nμi, for all i.\n3.Setπn1,...,n k=C/primeρn1\n1ρn2\n2...ρnk\nk\n4.Finally compute C/prime. To do this, use the fact that\n/summationdisplay\nn1,...,n k\ns.t./summationtext\nini=NC/prime·ρn1\n1ρn2\n2···ρnk\nk=1\n19.2.2 Example of Deriving Limiting Probabilities\nConsider again the closed system shown in Figure 19.1, where μ1=1,μ2=2,μ3=3,\nandp=1\n3.\nWe want to determine E[Number jobs at server 1]. The ﬁrst thing to do is determine the\nρi’s. To do this we want to determine the λi’s. This is done by solving the simultaneous\nrate equations:\nλ1=λ2+λ3\nλ2=1\n3·λ1\nλ2=2\n3·λ1\n336 closed networks of queues\nThese equations are not linearly independent, so we arbitrarily set\nλ1=1.\nThis leaves us with\nλ2=1\n3\nλ3=2\n3.\nWe now compute ρi=λi\nμias follows, for i=1,2,3:\nρ1=1,ρ 2=1\n6,ρ 3=2\n9\nQuestion: Are the above utilizations?\nAnswer: No.These are not “real loads. ” They do not mean anything in terms of load\nbecause they are based on a made-up value for λ1.\nTo determine any performance metric, we ﬁrst need to determine the limiting\nprobabilities of the CTMC. We use the product form representation of the limitingprobabilities:\nπn1,n2,n3=C·ρn1\n1·ρn2\n2·ρn3\n3\nTo use this formula we need to determine C. We consider all the possible states: (0,0,2),\n(0,2,0), (2,0,0), (1,0,1), (1,1,0), (0,1,1):\n1=/summationdisplay\nall statesπstate\n=C/parenleftbig\nρ0\n1ρ02ρ23+ρ0\n1ρ22ρ03+ρ2\n1ρ02ρ03+ρ1\n1ρ02ρ13+ρ1\n1ρ12ρ03+ρ0\n1ρ12ρ13/parenrightbig\n=C/parenleftBigg/parenleftbigg2\n9/parenrightbigg2\n+/parenleftbigg1\n6/parenrightbigg2\n+( 1 )2+/parenleftbigg2\n9/parenrightbigg\n+/parenleftbigg1\n6/parenrightbigg\n+/parenleftbigg1\n6·2\n9/parenrightbigg/parenrightBigg\n=C·1.5031\nSo we are left with\nC=1\n1.5031=.6653.\nNow we can use Cand the ρi’s to get the limiting probabilities:\nπ0,0,2=C·ρ0\n1ρ02ρ23=0.033\nπ0,2,0=C·ρ0\n1ρ22ρ03=0.018\nπ2,0,0=C·ρ2\n1ρ02ρ03=0.665\nπ1,0,1=C·ρ1\n1ρ02ρ13=0.148\nπ1,1,0=C·ρ1\n1ρ12ρ03=0.111\nπ0,1,1=C·ρ0\n1ρ12ρ13=0.025",6176
127-19.3 Mean Value Analysis MVA.pdf,127-19.3 Mean Value Analysis MVA,"19.3 mean value analysis (mva) 337\nGiven the limiting probabilities, it is easy to determine any performance metric. For\nexample,\nE[Number at server 1] =π1,0,1+π1,1,0+2π2,0,0=1.589.\nUtilization of server 1 =1−π0,0,2−π0,2,0−π0,1,1=0.924.\n19.3 Mean Value Analysis (MV A)\nThe only difﬁculty in the previous approach for closed systems is that it requirescomputing\nC/prime, the normalizing constant for the limiting probabilities. This involves\nsumming\nr=/parenleftbigg\nN+k−1\nk−1/parenrightbigg\nterms. Thus the number of terms we have to add up grows exponentially in Nand\nk. (Note this is already a lot better than solving the original CTMC from scratch,\nwhere rather than just having to add rterms, we have to solve that many simultaneous\nequations.)\nIn practice, for a single-class closed network, summing these rterms to determine\nthe normalizing constant is not usually a big deal. Typically the number of servers, k,\nis low. Now, if Nisalso low, then we can easily compute the normalizing constant.\nOtherwise, if Nis high, operational bounds analysis will work very well.\nNonetheless, many people still ﬁnd it cumbersome to have to determine this\nnormalizing constant and there has been research into faster approaches for com-\nputing it [ 35]. We now present an alternative method for analyzing closed product\nform networks, which is very efﬁcient and intuitive. This method is called Mean Value\nAnalysis (MV A). The downside of MV A is that it does not provide more than mean\nmetrics. That is, rather than providing the distribution of the number of jobs at each\nserver, MV A provides only the mean number of jobs at each server.\nMV A recursively relates the mean number of jobs at server jin a closed system where\nthe total number of jobs is M, namely E/bracketleftBig\nN(M)\nj/bracketrightBig\n, to the mean number of jobs at server\njin the same system where the total number of jobs is M−1, namely E/bracketleftBig\nN(M−1)\nj/bracketrightBig\n(note that we have switched to writing Mfor the total number of jobs, rather than N,\nto avoid notation overload). This recursive relationship allows us to then start with a\n1-job system ( M=1), which is easy to reason about; then use that to get the mean\nresponse time for the 2-job system; then use that to get the mean response time for the\n3-job system; and so on, building up to the M-job system.\nThe recursive relationship between the M-job system and the ( M−1)-job system is\ncaptured in the Arrival Theorem.\n338 closed networks of queues\n19.3.1 The Arrival Theorem\nTheorem 19.1 (The Arrival Theorem) In a closed Jackson network with M>1\ntotal jobs, an arrival to server jwitnesses a distribution of the number of jobs at\neach server equal to the steady-state distribution of the number of jobs at each\nserver in the same network with M−1total jobs. In particular, the mean number\nof jobs that the arrival sees at server jisE/bracketleftBig\nN(M−1)\nj/bracketrightBig\n.\nThe Arrival Theorem may make some intuitive sense because the arrival is seeing a\nsystem that does not contain itself; hence it has M−1total jobs. However, it is not\ntrue for all networks.\nQuestion: Provide an example of a closed network for which the Arrival Theorem is\nfalse.\nAnswer: Imagine a closed system consisting of two servers in tandem with M=2\njobs, where the service time at each server is deterministically 1. Suppose that we start\nout with one job at each server. Then forever after, there will be exactly one job ateach server (because jobs move in lock-step). Thus, an arrival, job\nj, into server 1will\nalways witness 0jobs at server 1and yet E/bracketleftBig\nN(1)\n1/bracketrightBig\n=1\n2.\nThe previous question/answer illustrates why the Arrival Theorem can be thought of as\nthe “counterpart to PASTA” for closed systems: it requires job sizes to be Exponentially\ndistributed.\nIn the rest of the section, we prove the Arrival Theorem and then show how to use it\nto derive E/bracketleftbig\nT(M)/bracketrightbig\n, the mean response time in a closed system with Mjobs. Before\nwe do this, however, we need to digress and recall the limiting probability for a closed\nJackson network with Mjobs. We use the superscript Mto denote the fact that this is\nanM-job system.\nRecall that\nπ(M)\nn1,n2,...,n k=C(M)/parenleftBigg\nλ(M)\n1\nμ1/parenrightBiggn1\n·/parenleftBigg\nλ(M)\n2\nμ2/parenrightBiggn2\n···/parenleftBigg\nλ(M)\nk\nμk/parenrightBiggnk\n(19.2)\nwhenever/summationtextk\ni=1ni=M, and0otherwise. Here λ(M)\njdenotes the total arrival rate into\nserver j, given a closed system with Mjobs, and C(M)is the appropriate normalizing\nconstant for the M-job system. The problem is that the λ(M)\njterm in ( 19.2) depends\nonM. For reasons that will become clear soon, it will be very helpful to replace\nthis with a term that does not depend on M. Let’s deﬁne a term that we call pj,\nwhere\npj=λ(M)\nj\nλ(M). (19.3)\n19.3 mean value analysis (mva) 339\nHereλ(M)=/summationtextk\nj=1λ(M)\njdenotes the total arrival rate into all servers in the M-job\nsystem. Observe that pjis just the fraction of total arrivals that are arrivals to server j\n(as opposed to some other server). Because pjis a proportion rather than an absolute\nquantity, pjis independent of M.1\nWe can now rewrite the limiting probabilities from ( 19.2) in terms of pjas follows:\nπ(M)\nn1,n2,...,n k=C/prime(M)/parenleftbiggp1\nμ1/parenrightbiggn1\n·/parenleftbiggp2\nμ2/parenrightbiggn2\n···/parenleftbiggpk\nμk/parenrightbiggnk\n, (19.5)\nwhenever/summationtextki=1ni=M, and0otherwise.\nWhat is nice about the limiting probabilities given by ( 19.5) is that all the terms\ninvolving “ M” have been subsumed into the constant.\nWe now prove the Arrival Theorem, after which we illustrate the derivation of\nE/bracketleftbig\nT(M)/bracketrightbig\n.\nProof (Arrival Theorem) We consider a job, job x,i na n M-job system, that has just\nleft server iand is headed to server j. We wish to determine the distribution of jobs at\neach server, as seen by job x. We will show that the probability that job xobserves n1\njobs at server 1, n2at server 2, n3at server 3, etc., where/summationtextkj=1nj=M−1(we are\nnot including the job itself), is exactly π(M−1)\nn1,n2,...,n k.\nOur argument follows that of [ 150]. We start by observing that the probability that\njobxobserves state (n1,n2,...,n k), where/summationtextkj=1nj=M−1is the same as the\nratio of two rates: the rate of transitions from server ito server jwhich observe state\n(n1,n2,...,n k)and the total rate of transitions from server ito server j.\nP/braceleftBig\njobxobserves (n1,n2,...,n k), where/summationtextkj=1nj=M−1/bracerightBig\n=π(M)\nn1,...,n i+1,...,n kμiPij/summationdisplay\nh1,...,hk\ns.t./summationtext\n/lscripth/lscript=M−1π(M)\nh1,...,h i+1,...h kμiPij\n=π(M)\nn1,...,n i+1,...,n k/summationdisplay\nh1,...,hk\ns.t./summationtext\n/lscripth/lscript=M−1π(M)\nh1,...,h i+1,...h k\n1To illustrate why pjis independent of M, letVjdenote the number of visits to server jper job completion\n(independent of M), and let X(M)denote the total rate of job completions per second in a system with M\njobs. Then\npj=λ(M)\nj\nλ(M)=X(M)Vj/summationtextk\nj=1X(M)Vj=Vj/summationtextkj=1Vj, (19.4)\nwhich is clearly independent of M.\n340 closed networks of queues\n=pi\nμi·k/productdisplay\n/lscript=1/parenleftbiggp/lscript\nμ/lscript/parenrightbiggn/lscript\n/summationdisplay\nh1,...,hk\ns.t./summationtext\n/lscripth/lscript=M−1π(M)\nh1,...,h i+1,...h kby(19.5)\n=Ck/productdisplay\n/lscript=1/parenleftbiggp/lscript\nμ/lscript/parenrightbiggn/lscript\n,where C:constant, independent of n1,n2,...,nk\n=π(M−1)\nn1,n2,...,n k.\nThe last line follows from the fact that the probability over what job xsees is a\n“density” in the sense that, when we sum it over all possible n1,n2,...,n k, where/summationtextk\n/lscript=1n/lscript=M−1, we get 1. Hence the constant Cabove is the unique constant\nneeded to make this density sum to 1. But that means that C=C(M−1), the unique\nconstant needed to make the density in ( 19.5) sum to 1.\nThe above chain of equalities is true for all i,j, completing the proof.\n19.3.2 Iterative Derivation of Mean Response Time\nWe are now ﬁnally ready to express E/bracketleftBig\nT(M)\nj/bracketrightBig\nin terms of E/bracketleftBig\nT(M−1)\nj/bracketrightBig\n. Once we have\ndone this, we can then start with E/bracketleftBig\nT(1)\nj/bracketrightBig\nand use that to get E/bracketleftBig\nT(2)\nj/bracketrightBig\n, which we will\nthen use to get E/bracketleftBig\nT(3)\nj/bracketrightBig\n, and so forth, until we have E/bracketleftBig\nT(M)\nj/bracketrightBig\n.\nQuestion: Pop quiz: What is E/bracketleftBig\nT(1)\nj/bracketrightBig\n?\nAnswer: We are asking what is the mean response time at server jwhen the number\nof jobs in the system is 1. This is just the mean service time:1\nμj.\nInvoking the Arrival Theorem, we have\nE/bracketleftBig\nT(M)\nj/bracketrightBig\n=1\nμj+E[Number at server jas seen by an arrival to j]\nμj\n=1\nμj+E/bracketleftBig\nN(M−1)\nj/bracketrightBig\nμj(by the Arrival Theorem)\n=1\nμj+λ(M−1)\njE/bracketleftBig\nT(M−1)\nj/bracketrightBig\nμj(by Little’s Law)\n=1\nμj+pj·λ(M−1)E/bracketleftBig\nT(M−1)\nj/bracketrightBig\nμj(by defn of pjin19.3)\n19.3 mean value analysis (mva) 341\nAt this point, we have expressed E/bracketleftBig\nT(M)\nj/bracketrightBig\nin terms of E/bracketleftBig\nT(M−1)\nj/bracketrightBig\n:\nE/bracketleftBig\nT(M)\nj/bracketrightBig\n=1\nμj+pj·λ(M−1)E/bracketleftBig\nT(M−1)\nj/bracketrightBig\nμj(19.6)\nHowever, we still have a λ(M−1)term in there.\nQuestion: H o wd ow eg e t λ(M−1)?\nHint: Use the fact that/summationtextk\nj=1E/bracketleftBig\nN(M−1)\nj/bracketrightBig\n=M−1and apply Little’s Law.\nAnswer:\nM−1=k/summationdisplay\nj=1E/bracketleftBig\nN(M−1)\nj/bracketrightBig\n=k/summationdisplay\nj=1λ(M−1)\njE/bracketleftBig\nT(M−1)\nj/bracketrightBig\n=k/summationdisplay\nj=1pjλ(M−1)E/bracketleftBig\nT(M−1)\nj/bracketrightBig\n,by (19.3)\n=λ(M−1)k/summationdisplay\nj=1pjE/bracketleftBig\nT(M−1)\nj/bracketrightBig\n.\nFrom this expression we have that\nλ(M−1)=M−1\n/summationtextkj=1pjE/bracketleftBig\nT(M−1)\nj/bracketrightBig. (19.7)\nCombining equations ( 19.6) and ( 19.7), we have the recurrence for E/bracketleftBig\nT(M)\nj/bracketrightBig\n.\n19.3.3 An MVA Example\nConsider a closed system composed of 2 servers in tandem, where the second server\nis twice as fast as the ﬁrst server, as shown in Figure 19.6. Given that the system has\nM=3 jobs, how many of these are at server 1 and how many are at server 2 on\naverage? To simplify calculations, we assume that the service rate at the ﬁrst server is\nμ=1.\nN = 3\n2\nFigure 19.6. An MV A example. What is the expected number of jobs at each server?\n342 closed networks of queues\nQuestion: What do you expect the number of jobs at each server to be?\nAnswer: One might naively think that because the ﬁrst server is half the speed of the\nsecond server, there should be twice as many jobs at the ﬁrst server. This is not true.\nAs we will see, the expected number of jobs at the ﬁrst server is actually more than\nthree times that at the second server.\nOur goal is to determine E/bracketleftBig\nN(3)\n1/bracketrightBig\n. We will get this by deriving E/bracketleftBig\nT(3)\n1/bracketrightBig\nvia MV A\nand then applying Little’s Law.\nQuestion: What are p1andp2?\nAnswer: Normally we would have to solve the simultaneous equations in ( 19.4) to get\nthese, but in this case they are simple. Because the number of arrivals to server 1 is\nequal to the number of arrivals to server 2, we have that p1=p2=1\n2.\nWe start by deriving E/bracketleftBig\nT(1)\n1/bracketrightBig\n,E/bracketleftBig\nT(1)\n2/bracketrightBig\n, andλ(1).\nE/bracketleftBig\nT(1)\n1/bracketrightBig\n=1\nμ1=1\nE/bracketleftBig\nT(1)\n2/bracketrightBig\n=1\nμ2=1\n2\nλ(1)=1\n1\n2·/parenleftbig\n1+1\n2/parenrightbig=4\n3by (19.7)\nFrom here we immediately move to E/bracketleftBig\nT(2)\n1/bracketrightBig\n,E/bracketleftBig\nT(2)\n2/bracketrightBig\n, andλ(2).\nE/bracketleftBig\nT(2)\n1/bracketrightBig\n=1+1\n2·4\n3·1\n1=5\n3by (19.6)\nE/bracketleftBig\nT(2)\n2/bracketrightBig\n=1\n2+1\n2·4\n3·1\n2\n2=2\n3by (19.6)\nλ(2)=2\n1\n2·/parenleftbig5\n3+2\n3/parenrightbig=12\n7by (19.7)\nNext, we move to E/bracketleftBig\nT(3)\n1/bracketrightBig\n,E/bracketleftBig\nT(3)\n2/bracketrightBig\n, andλ(3).\nE/bracketleftBig\nT(3)\n1/bracketrightBig\n=1+1\n2·12\n7·5\n3\n1=17\n7by (19.6)\nE/bracketleftBig\nT(3)\n2/bracketrightBig\n=1\n2+1\n2·12\n7·2\n3\n2=11\n14by (19.6)\nλ(3)=3\n1\n2·/parenleftbig17\n7+11\n14/parenrightbig=28\n15by (19.7)",12633
128-19.4 Readings.pdf,128-19.4 Readings,,0
129-19.5 Exercises.pdf,129-19.5 Exercises,"19.5 exercises 343\nFinally, we derive E/bracketleftBig\nN(3)\n1/bracketrightBig\n:\nE/bracketleftBig\nN(3)\n1/bracketrightBig\n=E/bracketleftBig\nT(3)\n1/bracketrightBig\n·λ(3)\n1\n=E/bracketleftBig\nT(3)\n1/bracketrightBig\n·p1·λ(3)\n=17\n7·1\n2·28\n15\n=34\n15\nAs a check, we also derive E/bracketleftBig\nN(3)\n2/bracketrightBig\n:\nE/bracketleftBig\nN(3)\n2/bracketrightBig\n=E/bracketleftBig\nT(3)\n2/bracketrightBig\n·λ(3)2\n=E/bracketleftBig\nT(3)\n2/bracketrightBig\n·p2·λ(3)\n=11\n14·1\n2·28\n15\n=11\n15\nObserve that E/bracketleftBig\nN(3)\n1/bracketrightBig\n+E/bracketleftBig\nN(3)\n2/bracketrightBig\n=3as expected.√\n19.4 Readings\nThere has been a lot of work on obtaining the normalizing constants for closed queueing\nnetworks. Some good references are [ 94], [72], [40].\nMV A was developed by Reiser and Lavenberg [ 147]. In this book we have chosen to\nonly give a brief explanation of MV A and why it works. While our exposition was\nlimited to single-class closed networks with no think time, the MV A method appliesmuch more generally. A comprehensive discussion of the use of MV A for solving\nboth single-class and multi-class product form networks is provided in [ 23]. The MV A\nmethod needs to be modiﬁed slightly to allow for think times as well as multiple classes.Some good references that explain these modiﬁcations are [ 125] and [ 5].\n19.5 Exercises\n19.1 Closed Jackson Network\nConsider the very simple closed Jackson network given in Figure 19.7.D e -\nrive the expected number of jobs at server 1 in the case where the total\nnumber of jobs is (i) M=1, (ii)M=2, and (iii) M=3. Do not use\nMV A.\n344 closed networks of queues\n½\n½1\n2=11=1\nFigure 19.7. Jackson network for Exercise 19.1.\n19.2 MV A\nRepeat Exercise 19.1 using MV A to get your answers.\n19.3 Networks with Load-Dependent Service Rates\nThis is a four-part question, with dependent parts, so please do these in order.\nThroughout, assume all packets come from a single class.\n(1) The system consists of just a single (FCFS) server. Jobs arrive according\nto a Poisson process with rate λ. The service rate at the server is “load-\ndependent,” meaning that when there are njobs in the system, the job\nin service is served with rate μ(n). Systems with load-dependent service\nrate are used to model parallel processing applications. Determine the\ndistribution of the number of jobs in the system.\n(2) Now your system is a (single-class) open Jackson network of load-\ndependent servers. The state of the network is (n1,n2,...,n k), where\nnidenotes the number of jobs at server i. Letμi(ni)denote the service\nrate at server iwhen there are nijobs at server i.\ni. Solve for the limiting probabilities, π(n1,n2,...,n k), using the local\nbalance approach. These will not be in closed form.\nii. Prove that the limiting probabilities have a product form solution;\nnamely that\nπ(n1,n2,...,n k)=k/productdisplay\ni=1P{Number of jobs at server iisni}.\niii. Check your solution by making the service rate constant at each server\n(i.e.,μi(ni)=μi,∀ni), and showing that you get the solution for\nordinary open Jackson networks.\n(3) Now your system is a Jackson network where each server is an M/M/m.\nDetermine the limiting probabilities, π(n1,n2,...,n k).\n(4) This chapter described the analysis of closed batch Jackson networks, but\ndid not say anything about closed interactive Jackson networks. Assume\nthat you can extend the analysis you have done in this problem to closed\n19.5 exercises 345\nbatch Jackson networks, with load-dependent service rates. Explain in\nwords how this would help you analyze a closed interactive Jackson net-\nwork with Exponentially distributed think time with mean E[Z]. Specif-\nically, explain how you would derive mean response time and throughputfor a closed interactive network.",3832
130-Part VI Real-World Workloads High Variability and Heavy Tails.pdf,130-Part VI Real-World Workloads High Variability and Heavy Tails,"PART VI\nReal-World Workloads:\nHigh Variability and\nHeavy Tails\nPart VIdiscusses queueing analysis where the arrival process and/or service process\nare generally distributed.\nWe start with Chapter 20, where we study empirical job size distributions from com-\nputing workloads. These are often characterized by heavy tails, very high variance,\nand decreasing failure rate. Importantly, these are very different from the Markovian(Exponential) distributions that have enabled the Markov-chain-based analysis that wehave done so far.\nNew distributions require new analysis techniques. The ﬁrst of these, the method of\nphase-type distributions, is introduced in Chapter 21. Phase-type distributions allow us\nto represent general distributions as mixtures of Exponential distributions. This in turn\nenables the modeling of systems involving general distributions using Markov chains.However, the resulting Markov chains are very different from what we have seen\nbefore and often have no simple solution. We introduce matrix-analytic techniques for\nsolving these chains numerically. Matrix-analytic techniques are very powerful. They\nare efﬁcient and highly accurate. Unfortunately, they are still numerical techniques,meaning that they can only solve “instances” of the problem, rather than solving theproblem symbolically in terms of the input variables.\nIn Chapter 22we consider a new setting: networks of Processor-Sharing (PS) servers\nwith generally distributed job sizes. These represent networks of computers, where\neach computer time-shares among several jobs. We again exploit the idea of phase-type distributions to analyze these networks, proving the BCMP product form theoremfor networks with PS servers. The BCMP theorem provides a simple closed-formsolution for a very broad class of networks of PS servers.\nAnother analysis technique, called the “tagged-job” technique, is introduced in Chap-\nter23. This technique provides us with a clean simple formula for the mean delay\nin an M/G/1 FCFS queue, known as the Pollaczek-Khinchin (P-K) formula. We alsostudy extensions of the M/G/1 in the exercises, such as mean delay for the M/G/1 withfailures and repairs, as well as the notion of a semi-Markov process that transitionsbetween states, but allows for sitting in a state for a generally distributed time beforetransitioning. The P-K mean delay formula is so simple that it facilitates the analysis of\n347\n348 real-world workloads: high variability and heavy tails\nwhole server farms consisting of FCFS queues. Chapter 24is an applications chapter,\nwhere we combine everything we have learned about FCFS queues and PS queues to\ndesign and analyze routing policies for general server farms.\nAlthough the P-K formula is elegant and insightful, it does not provide us information\nabout the variability of response time. To get higher moments of response time, weneed transform analysis. Laplace transforms and z-transforms, as applied to queueinganalysis, are introduced in Chapter 25. These are then applied to analyzing the M/G/1\nqueue in Chapter 26.\nChapter 27is another applications chapter, this time looking at power management in\nservers, where there are tradeoffs between keeping the server on to reduce response\ntime and turning it off to save on power. The problem is complicated by the fact thatthere is a “setup cost” for turning on a server. Transform analysis is extremely useful\nin analyzing systems with setup costs under generally distributed workloads – in fact,\nwe do not know of any other solution technique for this problem.",3584
131-Chapter 20 Tales of Tails A Case Study of Real-World Workloads.pdf,131-Chapter 20 Tales of Tails A Case Study of Real-World Workloads,,0
132-20.2 UNIX Process Lifetime Measurements.pdf,132-20.2 UNIX Process Lifetime Measurements,"CHAPTER 20\nTales of Tails: A Case Study\nof Real-World Workloads\nWe have alluded several times during this book to the fact that computing workloads\nhave highly variable job sizes (service requirements), that are not well described byan Exponential distribution. This chapter is a story of my own experience in studyingUNIX jobs in the mid-1990s, as a PhD student at U.C. Berkeley. Results of this researchare detailed in [ 84,85]. The story serves as both an introduction to empirical measure-\nments of computer workloads and as a case study of how a deeper understanding of\ncomputer workloads can lead to improved computer system designs. The remaining\nchapters in the book address modeling and performance evaluation of systems withhigh-variability workloads.\n20.1 Grad School Tales ...Process Migration\nIn the mid-1990s, an important research area was CPU load balancing in a Network\nof Workstations (at U.C. Berkeley it was coined the “N.O.W. project”). The idea inCPU load balancing is that CPU-bound jobs might beneﬁt from being migrated from\na heavily loaded workstation to a more lightly loaded workstation in the network. CPU\nload balancing is still important in today’s networks of servers. It is not free, however:Migration can be expensive if the job has a lot of “state” that has to be migrated withthe job (e.g., lots of open ﬁles associated with the job), as is common for jobs thathave been running for a while. When the state associated with the job is great, then the\ntime to migrate the job to another machine is high, and hence it might not be worthmigrating that job.\nThere are two types of migration used in load balancing techniques:\n1.migration of newborn jobs only – also called initial placement orremote execution\n2.migration of jobs that are already active (running) – also referred to as active\nprocess migration\nIn the mid-1990s it was generally accepted that migrating active processes was a bad\nidea, because of their high migration cost. Except for one or two experimental operatingsystems, like MOSIX [ 13], people only migrated newborn jobs.\nImportant terminology: When we talk about a job’s size we mean its total CPU\nrequirement. When we talk about a job’s agewe mean its total CPU usage thus far.\nA job’s lifetime refers to its total CPU requirement (same thing as size). A job’s\nremaining lifetime refers to its remaining CPU requirement.\n349\n350 tales of tails: a case study of real-world workloads\nObserve that what we really want to know is a job’s remaining lifetime. If the job has\na high remaining CPU requirement, then it may pay to migrate the job, even if the jobhas accumulated a lot of state, because the job will get to spend its long remaining\nlifetime on a lightly loaded machine.\nSadly, we do not know a job’s remaining lifetime, just its current CPU age.\nThe common wisdom in the 1990s, backed up by many research papers, was that UNIX\njob CPU lifetimes were Exponentially distributed .\nQuestion: What is the implication of UNIX job lifetimes being Exponentially dis-\ntributed?\nAnswer: Exponential distributions exhibit a constant failure rate. That is, all jobs have\nthe same remaining lifetime (and the same probability of requiring another second of\nCPU), regardless of their current age. Since newborn jobs and older (active) jobs havethesame expected remaining lifetime, yet newborn jobs are much cheaper to migrate,\nit makes sense to migrate only the newborn jobs.\n20.2 UNIX Process Lifetime Measurements\nRefusing to believe that there were no beneﬁts to active process migration, I decided\nto measure the distribution of job lifetimes.\nI collected the CPU lifetimes of millions of jobs on a wide range of different machines,\nincluding instructional, research, and administrative machines, over the course of many\nmonths. Figure 20.1 shows the fraction of jobs whose size exceeds x, for all jobs whose\nsize is greater than 1 second.\n32 16 8 421x secondsP{Job size > x}\n1\n½\n¼\n⅛\nFigure 20.1. Plot of measured distribution, F(x)=P{Job size >x}.\nAt a ﬁrst glance this plot looks like an Exponential distribution, F(x)=e−λx. But on\ncloser examination you can see that it is not Exponential.\nQuestion: How can you tell that it is not Exponential?\n20.2 unix process lifetime measurements 351\nAnswer: For an Exponential distribution, the fraction of jobs remaining should drop\nby a constant factor with each unit increase in x(constant failure rate). In Figure 20.1,\nwe see that the fraction of jobs remaining decreases by a slower and slower rate as we\nincrease x(decreasing failure rate). In fact, looking at the graph, we see that if we start\nwith jobs of CPU age 1second, half of them make it to 2seconds. Of those that make\nit to2seconds, half of those make it to 4seconds. Of those that make it to 4seconds,\nhalf of those make it to 8seconds. Of those that make it to 8seconds, half of those\nmake it to 16seconds, and so on.\nTo see the distribution more easily it helps to view it on a log-log plot as shown in\nFigure 20.2. The bumpy line shows the data, and the straight line is the best-ﬁt curve.\nFigure 20.2. Log-log plot of measured distribution, F(x)=P{Job size >x}.\nTo see that the measured distribution is notan Exponential distribution, consider\nFigure 20.3, which shows the best-ﬁt Exponential distribution in juxtaposition with the\nmeasured distribution from Figure 20.2.\nFigure 20.3. Plot of measured distribution on log-log axes along with best-ﬁt Exponential\ndistribution.",5514
133-20.5 Heavy Tails.pdf,133-20.5 Heavy Tails,"352 tales of tails: a case study of real-world workloads\nFrom Figure 20.2 it is apparent that the tail of the distribution of jobs with lifetimes\nlonger than 1second decays like1\nx. That is,\nP{Job size >x|Job size >1}=1\nx.\nAt the time (mid-90s), I did not recognize this distribution and was suspicious of\nits simplicity, so I tried measuring different types of UNIX workloads. I also triedremoving shells and daemon processes, as well as removing very short jobs. No matter\nwhat I tried, in all cases, I saw a straight line on a log-log plot, indicating the following\ndistribution:\nF(x)=1\nxα,x≥1,\nwhere αranged from about 0.8to about 1.2, in my measurements, across machines.\nMost commonly αwas very close to 1, and the regression showed goodness of ﬁt ( R2)\nvalues of more than 0.96.\n20.3 Properties of the Pareto Distribution\nIt turns out that the distribution that I had measured has a name in economic theory. It\nis called the Pareto distribution, or “power-law distribution.”\nDeﬁnition 20.1 A distribution, FX(x), such that\nFX(x)=P{X>x}=x−α,forx≥1,\nwhere 0<α< 2is called a Pareto(α)distribution .\nQuestion: What is the failure rate of the Pareto distribution?\nAnswer:\nF(x)=P{X>x}=x−α,x≥1\n⇒F(x)=P{X<x}=1−x−α,x≥1\n⇒f(x)=dF(x)\ndx=αx−α−1,x≥1\n⇒r(x)=f(x)\nF(x)=αx−α−1\nx−α=α\nx,x≥1.\nNotice that/integraltext∞\n1f(x)dx=/integraltext∞\n1αx−α−1dx=1,s of(x)is a valid probability distri-\nbution.\nBecause r(x)=α\nxdecreases with x, the Pareto distribution has decreasing failure rate\n(DFR). Thus the older a job is (the more CPU it has used up so far), the greater its\nprobability of using another second of CPU.\n20.4 the bounded pareto distribution 353\nQuestion: For a Pareto with α≤1, what are the mean and variance of the distribution?\nAnswer: The calculations are straightforward, by integration over the density function.\nIf0<α≤1,\nE[Lifetime ]=∞\nE[ith moment of Lifetime ]=∞,i=2,3,...\nE[Remaining Lifetime |age=a>1] =∞.\nQuestion: How do these answers change when αis above 1?\nAnswer: Both the expected lifetime and the expected remaining lifetime are now\nﬁnite. Higher moments of lifetime are still inﬁnite.\nQuestion: Under the Pareto distribution with α=1, what is the probability that a job\nof CPU age alives to CPU age b, where b>a ?\nAnswer:\nP{Life>b|Life≥a>1}=1/b\n1/a=a\nb.\nUsing this expression, for the Pareto (α=1 ) distribution, we can interpret the distri-\nbution in the following way:\nrOf all the jobs currently of age 1sec, half of those will live to age ≥2sec.\nrThe probability that a job of age 1sec uses >T sec of CPU is1\nT.\nrThe probability that a job of age Tsec lives to be age ≥2Tsec is1\n2.\n20.4 The Bounded Pareto Distribution\nWhen we look for a curve ﬁt to the measured data , we observe that the measured data\nhave a minimum job lifetime and a maximum job lifetime. Thus the measured data\nhave all ﬁnite moments. To model the measured data, we therefore want a distribution\nwith a Pareto shape, but truncated on both ends. We refer to such a distribution as aBounded Pareto distribution.\nDeﬁnition 20.2 TheBounded Pareto (k, p, α )distribution has density function\nf(x)=αx−α−1·kα\n1−/parenleftBig\nk\np/parenrightBigα,\nfork≤x≤pand0<α< 2. We often write BP(k,p,α )for short.\nThe factorkα\n1−(k/p)αin Deﬁnition 20.2 is a normalization factor needed to make the\nintegral of the density function between kandpcome out to 1. For the Bounded Pareto\ndistribution, obviously all of the moments are ﬁnite.",3481
134-20.7 Pareto Distributions Are Everywhere.pdf,134-20.7 Pareto Distributions Are Everywhere,"354 tales of tails: a case study of real-world workloads\nFor the UNIX job sizes that I measured, the squared coefﬁcient of variation, C2,w a s\nﬁnite, ranging between C2=2 5 andC2=4 9 . This may seem like a very high level\nof variability, but computer workloads today exhibit even higher squared coefﬁcients\nof variation.\n20.5 Heavy Tails\nThe following are three properties of the Pareto distribution:\n1. Decreasing failure rate (DFR) — The more CPU you have used so far, the more\nyou will continue to use.\n2. Inﬁnite or near-inﬁnite variance\n3. Heavy-tail property — A minuscule fraction of the very largest jobs comprise\nhalf of the total system load. For example, when α=1.1, the largest 1%of the\njobs comprise about1\n2of the load. (Note that this is much more biased than the\noften quoted 80–20 rule.)\nThe last property, which we call the “heavy-tail property,” comes up in many othersettings. For example, in economics, when studying people’s wealth, it turns out thatthe richest\n1%of all people have more money between them than all the remaining 99%\nof us combined. The heavy-tail property is often referred to as “a few big elephants (big\njobs) and many, many mice (little jobs),” as illustrated in Figure 20.4. For comparison,\nin an Exponential distribution with the same mean, the largest 1%of the jobs comprise\nonly about 5%of the total demand.\nFigure 20.4. Heavy-tail property: “Elephants and mice.”\nThe parameter αcan be interpreted as a measure of the variability of the distribution\nand the heavy-tailedness: α→0yields the most variable and most heavy-tailed dis-\ntribution, whereas α→2yields the least variable and least heavy-tailed distribution.\nThese properties are explored in more depth in the exercises.\nThese properties largely hold for the Bounded Pareto distribution as well as the Pareto,\nalthough clearly the Bounded Pareto cannot have pure DFR, because there is an upperbound on job size.\n20.6 The Beneﬁts of Active Process Migration\nNow, let’s return to the original question of CPU load balancing.\nQuestion: What does the DFR property of the Pareto distribution tell us about whether\nit pays to migrate older jobs?\n20.7 pareto distributions are everywhere 355\nAnswer: DFR says that older jobs have higher expected remaining lifetimes. This leads\nus to think that it may pay to migrate oldjobs. Although an old job may have a high\nmigration cost because it has accumulated a lot of state (memory), if the job is really\nold then it has a high probability of using a lot more CPU in the future. This meansthat the cost of migration can then be amortized over a very long lifetime, as the job\ngets to spend its long remaining lifetime running on a lightly loaded machine.\nQuestion: What does the heavy-tail property of the Pareto distribution tell us?\nAnswer: By the heavy-tail property, it may only be necessary to migrate the\n1%biggest\njobs, because they contain most of the work.\nHowever, it is not clear which jobs are “old enough” as a function of their migration\ncost. The confusion comes from the fact that for a Pareto distribution with α≤1,all\njobs (regardless of age) have the same expected remaining lifetime, namely ∞. Does\nthis mean all jobs are “old enough” to make them worth migrating? The difﬁculty\nin working with distributions with inﬁnite moments is coming up with a modeling\napproach that gets around all the inﬁnities.\nWe need some criterion to determine if a job is “old enough.” This criterion should\ntake into account the job’s age and its migration cost, as well as the difference in load\nat the source and target host.\nAllen Downey (a fellow grad student) and I developed such a criterion, based on the\nPareto job size distribution. The trick for getting around the “inﬁnities” was to lookat the expected slowdown of a job, rather than its expected response time (recall that\nthe slowdown of a job is its response time normalized by its size). In experimentsinvolving networks of workstations, we showed that active process migration, basedon our criterion, ends up migrating fewer than\n4%of jobs, while vastly reducing mean\nslowdown when compared with remote execution. We will not spend time discussing\nthe criterion here, but if you are intrigued at this point, we encourage you to read the\npaper [ 85].\n20.7 Pareto Distributions Are Everywhere\nIt is not just UNIX jobs that ﬁt a heavy-tailed Pareto distribution. Pareto job size\ndistributions are everywhere! Here are some more practical and interesting stories.\nAround 1996–98, Mark Crovella, Azer Bestavros, and Paul Barford at Boston Univer-\nsity were measuring the sizes of ﬁles at websites. They found that these sizes had a\nPareto distribution with α≈1.1. They also found similar results for the sizes of ﬁles\nrequested from websites. Their SURGE web workload generator is based on these\nﬁndings [ 14,47,48].\nAround this same time, the three Faloutsos brothers were observing a similar distri-\nbution when looking at the Internet topology. They observed, for example, that most\nnodes have low out-degree, but a very few nodes have very high out-degree, and the dis-tribution of the degrees follows a Pareto distribution. This and other observations werepublished in their beautiful 1999 paper that won the Sigcomm Test of Time award [ 54].\n356 tales of tails: a case study of real-world workloads\nIn 1999, Jennifer Rexford, Anees Shaikh, and Kang Shin at AT&T were working\non routing IP ﬂows to create better load balancing. They did not want to have toreroute all ﬂows because the overhead would be too high. Ideally, they wanted to\nhave to reroute only\n1%of the IP ﬂows. Would that be enough? Fortunately, their\nmeasurements showed that the number of packets in IP ﬂows follows a heavy-tailed\nPareto distribution. Consequently, the 1%largest IP ﬂows (those with the most packets)\ncontain about 50% of the bytes in all ﬂows. Thus by rerouting only 1% of the ﬂows, they\nwere able to redistribute half the load. Their paper appeared in Sigcomm 99 [ 166] and\ngenerated a large group of follow-up papers dealing with sampling methods for how\nto detect which ﬂows are large, based on using the DFR property and the knowledge\nof how many packets the ﬂow has sent so far.\nAround this same time, my students and I, in collaboration with Mark Crovella at Boston\nUniversity, started a project called SYNC (Scheduling Your Network Connections).The goal was to improve the performance of web servers by changing the order inwhich they scheduled their jobs to favor requests for small ﬁles over requests for largeﬁles. Clearly favoring requests for small ﬁles over large ones would decrease meanresponse time. However people had not tried this in the past because they were afraidthat the requests for large ﬁles would “starve” or at least be treated unfairly compared torequests for small ﬁles. Using the heavy-tail property of web ﬁle sizes, we were able toprove analytically and in implementation that this fear is unfounded for the distributionof web ﬁles. The crux of the argument is that, although short requests do go aheadof long requests, all those short requests together make up very little load (more thanhalf the load is in the top 1% of long requests) and hence do not interfere noticeablywith the long requests [ 12,46,92]. In 2004, Ernst Biersack, Idris Rai, and Guillaume\nUrvoy-Keller extended the SYNC results to TCP ﬂow scheduling by exploiting theDFR property of the Pareto distribution to discern which ﬂows have short remainingduration [ 144,142].\nThere are many, many more examples of the Pareto distribution in measured distri-butions involving jobs created by humans. Wireless session times have been shown\nto follow a Pareto distribution [ 22]. Phone call durations have been shown to follow\na distribution similar to a Pareto. Human wealth follows a Pareto distribution. Natu-\nral phenomena too follow Pareto distributions. For example, John Doyle at Caltechhas shown that the damage caused by forest ﬁres follows a Pareto distribution, withmost forest ﬁres causing little damage, but the largest few forest ﬁres causing themajority of the damage. The same property holds for earthquakes and other naturaldisasters.\nGiven the prevalence of the Pareto distribution, there has been a great deal of research\ninterest in why the Pareto distribution comes up everywhere. Ideally, we would like to\nprove something similar in nature to the Central Limit Theorem, which explains the\nubiquity of the Normal distribution, but this time for the Pareto distribution. We donot have room to delve into the many theories proposed for the origin of the Paretodistribution (e.g., the HOT theory [ 37]). To date, this is still an open research problem\nof great practical importance.",8783
135-20.8 Exercises.pdf,135-20.8 Exercises,"20.8 exercises 357\n20.8 Exercises\n20.1 Simulation of M/BP/1\nIn this problem you will simulate a single FCFS server, where jobs arrive\naccording to a Poisson process with rate λ, and job sizes are distributed\naccording to a Bounded Pareto distribution, BP(k,p,α ), with mean 3,000.\nWe will experiment with two values of α:α=1.5(high variability and heavier\ntail) and α=2.9(low variability and light tail).1Fixp=1 010, and set k\nappropriately so as to keep the mean steady at 3,000 (for example, when\nα=1.5you want k≈1,000, and when α=2.9you want k≈1,970). Now\nsetλappropriately to create a server utilization of ρ=0.8.\nYour goal is to measure the mean time in the queue, E[TQ]. You will do this\nby averaging independent samples.\nLet one “run” of the simulator consist of running the system from empty state\nfor ﬁfty thousand arrivals and then recording the time in queue experienced by\narrival number 50,001.\nYou will perform n(independent) runs, each of which will generate one sample\nand then you will determine the mean of the nsamples.\nFor each of the two values of α:\n(a) Perform n=5,000runs of the simulator. Let X1,X2,...,X ndenote the\nnsamples you obtain for TQ. Determine the sample mean, SM:\nSM=X1+X2+···+Xn\nn\nDetermine the sample variance, SV, via the following well-known formula:\nSV=1\nn−1n/summationdisplay\ni=1(Xi−SM)2\n(b) Compute the “true” E[TQ]andVar(TQ)using the following formulas\n(these will be proven in Chapter 23) for the M/G/1 queue, where Sdenotes\nthe job size, which is in this case two instances of a Bounded Pareto:\nE[TQ]=ρ\n1−ρ·E[S2]\n2E[S](20.1)\nVar(TQ)=(E[TQ])2+λE[S3]\n3(1−ρ)(20.2)\nCompare your results with the sample mean and sample variance.\n(c) For the lower αcase, it will likely turn out that your analytically derived\nvalues for E[TQ]and Var(TQ)are much higher than your measured\n(simulated) values. Why is this?\n(d) Why did we ask you to make each run consist of so many arrivals before\ntaking a sample point? For example, why couldn’t you just have used 1,000\narrivals in each run?\n1When the αparameter is this high, the distribution is often no longer considered to be Pareto because the tail\nis so light.\n358 tales of tails: a case study of real-world workloads\n20.2 The Heavy-Taile Property\nWe explore three distributions for job size:\n(1) Exponential distribution with mean 3,000\n(2) Bounded Pareto distribution BP(k=.0009,p=1 010,α=0.5)with\nmean 3,000\n(3) Bounded Pareto distribution BP(k= 332 .067,p=1 010,α=1.1)with\nmean 3,000\nIn each case, compute the fraction of load made up by just the top 1%of all\njobs. Also report the size cutoff xdeﬁning the top 1%of jobs. It is easiest to\nuse a symbolic math package to do this calculation.\n20.3 Why It Is So Hard to Simulate the Bounded Pareto\nThis problem will illustrate why it is so hard to correctly generate instances\nof the Bounded Pareto. To generate instances of BP(k,p,α ), we follow the\nusual Inverse-Transform procedure, obtaining\nx=k/parenleftbigg\n1+u/parenleftbigg/parenleftbiggk\np/parenrightbiggα\n−1/parenrightbigg/parenrightbigg 1\nα\nwhere xis an instance of BP(k,p,α ), anduis an instance of Uniform(0,1).\nThis formula is correct except that uis not really an instance of Uniform (0,1),\nbecause the UNIX random number generator function rand() actually re-\nturns integers between 0and231−1. Thus uis actually an instance of\nUniform (0,1−2−31). Close enough, right? We will see ...\nTable 20.1 shows different Bounded Pareto distribution parameters. Fill in the\nblank entries for this table. In particular, for the column pActual, ﬁll in the actual\nmaximum value possible, given that uis never higher than 1−2−31.U s e\npActual to compute C2\nActual for the Bounded Pareto that is actually generated,\nas compared with C2\nTheory , the value we should have obtained if we had used\npTheory .\nAspTheory gets higher, what do you notice about C2\nActual as compared with\nC2\nTheory ?\nTable 20.1. Theory versus what is actually generated\nkp Theory αE[XTheory]C2\nTheory pActualE[XActual]C2\nActual\n0.297 1031.4 1\n0.290 1041.4 1\n0.287 1051.4 1\n0.286 1061.4 1\n0.286 1071.4 1",4148
136-Chapter 21 Phase-Type Distributions and Matrix-Analytic Methods.pdf,136-Chapter 21 Phase-Type Distributions and Matrix-Analytic Methods,,0
137-21.1 Representing General Distributions by Exponentials.pdf,137-21.1 Representing General Distributions by Exponentials,"CHAPTER 21\nPhase-Type Distributions and\nMatrix-Analytic Methods\nWe have seen many examples of systems questions that can be answered by modeling\nthe system as a Markov chain. For a system to be well modeled by a Markov chain,it is important that its workloads have the Markovian property. For example, if jobsizes and interarrival times are independent and Exponentially distributed, and routingis probabilistic between the queues, then the system can typically be modeled easily\nusing a CTMC. However, if job sizes or interarrival times are distributed according toa distribution that is not memoryless, for example Uniform\n(0,100) , then it is not at all\nclear how a Markov chain can be used to model the system.\nIn this chapter, we introduce a technique called “the method of stages” or “the method\nof phases.” The idea is that almost all distributions can be represented quite accurately\nby a mixture of Exponential distributions, known as a phase-type distribution (PH). We\nwill see how to represent distributions by PH distributions in Section 21.1. Because\nPH distributions are made up of Exponential distributions, once all arrival and service\nprocesses have been represented by PH distributions, we will be able to model oursystems problem as a CTMC, as shown in Section 21.2.\nThe Markov chains that result via the method of phases are often much more complexthan Markov chains we have seen until now. They typically cannot be solved in closedform. Thus, in Section 21.3, we introduce the matrix-analytic method, a very powerful\nnumerical method that allows us to solve many such chains that come up in practice.\n21.1 Representing General Distributions by Exponentials\nVariance plays a big role in representing general distributions.\nDeﬁnition 21.1 Thesquared coefﬁcient of variation (SCV) ,C2\nX,o fr . v . X,i sg i v e n\nby\nC2\nX=Var(X)\nE[X]2=E[X2]\nE[X]2−1.\nOne can view C2as a normalized variance, because the variance is being scaled down\nby the square of the mean. Recall that if X∼Exp(μ), thenE[X]=1\nμ,Var(X)=1\nμ2,\nandC2\nX=1. We will now consider distributions with lower C2and higher C2.\n359\n360 phase-type distributions and matrix-analytic methods\nSuppose that we would like to model a service time distribution with C2<1by using\nExponential distributions. For example, we might be trying to describe the transmission\ntime of a packet through a wire, which we denote by r.v. T. Although Tmay exhibit\nsome small variability, the distribution of Tis much closer to a Deterministic (constant-\nvalued) distribution, with C2=0, than to an Exponential.\nQuestion: How can we mix Exponential distributions to create a Deterministic or\nnear-Deterministic distribution?\nHint: Think about putting Exponential distributions in series.\nAnswer: We could model Tas the time to pass through kstages, each requiring\nExp(kμ)time, as shown in Figure 21.1. That is, let Ti∼Exp(kμ), where\nT=T1+T2+T3+···+Tk.\nExp(kμ) Exp(kμ) Exp(kμ)\nFigure 21.1. The time, T, to pass through all kstages has an Erlang-k distribution.\nDeﬁnition 21.2 IfTis the sum of ki.i.d. Exponential random variables, then T\nis said to have an Erlang-k distribution. A generalized Erlang distribution (also\ncalled a Hypoexponential distribution) is a sum of Exponential random variables\nwith different rates.\nQuestion: What are E[T],Var(T), andC2\nTfor Figure 21.1?\nAnswer:\nE[T]=k·1\nkμ=1\nμ.\nVar(T)=k·Var(Single Stage )=k·/parenleftbigg1\nkμ/parenrightbigg2\n=1\nk·1\nμ2.\nC2\nT=Var(T)\nE[T]2=1\nk.\nQuestion: What happens to Task→∞ ?\nAnswer: Ask→∞ ,C2\nT→0, andTconverges to the Deterministic distribution of\nvalue1\nμ.\nThus with an inﬁnite number of Exponential phases (or stages), we can approach aDeterministic distribution. The important point is that, given any mean\nE[T]=1\nμand\n21.1 representing general distributions by exponentials 361\nC2\nTof the form of C2\nT=1\nk, for some integer k>1, one can construct an Erlang-k\ndistribution matching that given E[T]and that C2\nT.\nIn the same way that an Erlang-k distribution is useful for approximating distributions\nwithC2<1, we can also deﬁne a mixture of Exponentials that is useful for approxi-\nmating distributions with C2>1. For example, it is well known that the time to serve\nweb requests has high variability [ 47]. IfTrepresents the time to serve a web request,\nwe might have E[T]=1 seconds and C2\nT=2 5 .\nQuestion: How do we create a distribution with C2>1using Exponential stages?\nAnswer: Rather than putting the Exponential stages in series, we instead view these\n“in parallel,” as shown in Figure 21.2.\n1–p\np\n2Exp(1)\nExp(2)\nFigure 21.2. Hyperexponential distribution.\nDeﬁnition 21.3 IfTis distributed as Exp (μ1)with probability pand is distributed\nas Exp (μ2)with probability 1−p, then we say that Tfollows a Hyperexponential\ndistribution, denoted by H2.\nT∼/braceleftbiggExp(μ1) with probability p\nExp(μ2) with probability 1−p\nThis is also sometimes referred to as a 2-phase Hyperexponential. If there are k>2\nphases, where Tis distributed as Exp (μi)with probability pi,f o r1≤i≤k, then\nwe say that Tfollows a k-phase Hyperexponential distribution, denoted by Hk.\nObserve that the Hyperexponential distribution has three parameters: μ1,μ2, andp.\nThus it seems reasonable that, given a mean and a C2value, we should be able to ﬁnd\nsome setting of the parameters of the Hyperexponential to match them. It turns out\nthat the (2-phase) Hyperexponential distribution sufﬁces to match any mean and C2,\nprovided C2>1; see [ 152]. It can even be used to match 3 moments of a distribution,\nprovided that the third moment is sufﬁciently high; see [ 185]. (One can express each of\n3 moments of Tas an equation involving the 3 parameters. This system of 3 equations\nand 3 parameters often has a solution.) However, the Hyperexponential is not usefulfor the case of\nC2<1.\nTo gain some intuition for why the Hyperexponential is good at representing high-\nvariability distributions, let us analyze the simple case of a Degenerate Hyperexpo-\nnential distribution, where one of the phases is identically zero:\nT∼/braceleftbiggExp(pμ) with probability p\n0 with probability 1−p\n362 phase-type distributions and matrix-analytic methods\nQuestion: What is E[T]?\nAnswer: E[T]=p·1\npμ=1\nμ.\nQuestion: What is C2\nT?\nAnswer:\nE/bracketleftbig\nT2/bracketrightbig\n=p·2/parenleftbigg1\npμ/parenrightbigg2\n.\nVar(T)=E/bracketleftbig\nT2/bracketrightbig\n−(E[T])2=p·2/parenleftbigg1\npμ/parenrightbigg2\n−/parenleftbigg1\nμ/parenrightbigg2\n=2−p\np·/parenleftbigg1\nμ/parenrightbigg2\n.\nC2\nT=2−p\np=2\np−1.\nObserve that by deﬁnition C2\nT>1. As the value of pdecreases, the value of C2\nT\nincreases.\nThe important point is that, given anymeanE[T]=1\nμand any C2\nT≥1, we can\nﬁnd a Degenerate Hyperexponential to match that mean and C2\nT(by setting p=\n2/(C2\nT+1 ) ).\nQuestion: Does the (non-degenerate) Hyperexponential distribution have increasing\nfailure rate or decreasing failure rate or neither?\nHint: There is an easy way to argue this intuitively without doing any derivations.\nAnswer: In Exercise 21.5, we will prove that the failure rate is decreasing, by going\nback to the original deﬁnition of failure rate. Here is a more intuitive argument: Imagine\nthatTis distributed Hyperexponentially with 2 branches, where μ1>μ 2. The longer\nThas lasted so far, the greater the probability that we are in the μ2branch, and thus\nthe greater the probability that Twill last even longer.\nThus far we have seen how to model distributions with C2<1, with an Erlang\ndistribution, and distributions with C2>1, with a Hyperexponential distribution. By\ncombining these ideas of phases in series and phases in parallel, we can represent\n(almost) any distribution.\nA phase-type distribution (PH) denotes the most general mixture of Exponential dis-\ntributions in series and parallel.\nDeﬁnition 21.4 Ak-phase PH distribution with parameters (/vectora,T)is the distribu-\ntion of time until absorption in the following (k+1 ) -state CTMC:\nrStates 1through kare transient, and state 0is absorbing.\nr/vectora=(a0,a1,...,a k)where aidenotes the probability that the starting state\nisi, and/summationtextk\ni=0ai=1.\nrTis ak×(k+1 ) rate transition matrix from states {1,2,...,k}to\n{0,1,...,k}, where Tij=μijis the rate of moving from state ito state\nj, where i/negationslash=j.\nThere is no transition out of state 0, and none from a state back to itself.\n21.1 representing general distributions by exponentials 363\nµ12 µ23 µ30\nµ32\nµ31µ13\nµ21µ20µ10a0\na3\na2\na11 2 3 0\nFigure 21.3. A 3-phase PH distribution is the time until absorption in this CTMC, where the\ninitial state is chosen according to probability vector /vectora=(a0,a1,a2,a3).\nAn illustration of a 3-phase PH distribution is given in Figure 21.3.\nThe power of PH distributions lies in the fact that they are dense in the class of all non-\nnegative distribution functions. Practically speaking, this means that a PH distributionwith a sufﬁcient number of phases can approximate any non-negative distributionarbitrarily closely (see [ 8], Theorem 4.2).\nA\nk-phase PH distribution has more than k2parameters. It is not obvious that one needs\nso many parameters to be able to well approximate arbitrary distributions. The class\nof Coxian distributions is still dense in the class of non-negative distribution functions\n[153,154], yet Coxian distributions have many fewer parameters (they are a subset\nof the PH distributions). A k-stage Coxian distribution, depicted in Figure 21.4, looks\nsimilar to an Erlang-k, except that there are probabilities of stopping after each stage.\nExp(μ1) Exp(μ2) Exp(μk)a0\nb0 b1 b2 bk–1a1 a2 ak–1\nFigure 21.4. Ak-stage Coxian distribution. The ai’s and bi’s are probabilities, where ai+bi=1,∀i.\nIn general, modeling an arbitrary distribution as a Coxian distribution is non-trivial,\nbut doable. It is very common for researchers to match the ﬁrst 3 moments of a given\ndistribution using a 2-phase Coxian distribution, see Section 21.6. This allows us to\nrepresent problems involving general distributions via Markov chains, which we can\noften solve. We will see this in the next section.\nRemark: The fact one can match the several moments of a distribution by a Coxian\nor PH distribution does not always mean that one has truly “captured” the character of\nthe distribution, particularly its tail behavior, P{X>t}. The question of how to best\ncharacterize a distribution using Exponential phases is still part of ongoing debate.",10567
138-21.2 Markov Chain Modeling of PH Workloads.pdf,138-21.2 Markov Chain Modeling of PH Workloads,"364 phase-type distributions and matrix-analytic methods\n21.2 Markov Chain Modeling of PH Workloads\nIn this section we consider four simple examples of using Markov chains to model PH\nworkloads. We defer discussion of how to solve these Markov chains to Section 21.3.\nMarkov Chain for M/E 2/1\nConsider a single FCFS queue, with Poisson arrivals of rate λ, where the service times\nfollow an Erlang-2 distribution. Speciﬁcally, the mean job size is1\nμ, and a job’s service\nrequires ﬁrst passing through an Exp (μ1)hurdle and then passing through an Exp (μ2)\nhurdle, where μ1=μ2=2μ.\nQuestion: What do we need to track in the state space?\nAnswer: Observe that, because the service order is still FCFS, only the earliest arrival\ncan be serving. Assuming there is at least one job in the system, the job at the head of\nthe queue is in either phase 1or phase 2. The other jobs are waiting in the queue.\nThus a reasonable choice of state space is (i,j)where iindicates the number of jobs\nthat are queueing (not serving) and jtakes on value 1or2, depending on whether the\njob in service is in phase 1or phase 2. Figure 21.5 shows the resulting Markov chain.\nμ2 μ1 μ2 μ1 μ2 μ1 μ1λλλ\nμ21,1 3,1\nλ2,1\n0,0\nλλλ0,1\n0,2 1,2 2,2 3,2\nFigure 21.5. Markov chain for M/E 2/1, with average arrival rate λand average service rate μ.\nState(i, j)indicates that there are ijobs waiting in the queue and the job in service (if there\nis one) is in phase j. Throughout μ1=μ2=2μ.\nMarkov Chain for M/H 2/1\nNext consider a single-server FCFS queue, with Poisson arrivals of rate λ, where the\nservice times follow a Hyperexponential distribution. Speciﬁcally, with probability p,\na job will require Exp (μ1)service, and with probability 1−pthe job will require\nExp(μ2)service.\nQuestion: What should the Markov chain look like?\nHint: It is tempting to assign the job size at the time that the job arrives. What is the\nproblem with doing this?\nAnswer: If we assign the job size at the time that it arrives, then for every job in the\nqueue we need to track whether it has size Exp (μ1)or Exp (μ2). Thus, it is wiser to\nhold off determining the job’s size until it is about to serve. Only when a job ﬁnishes\nserving is the size of the next job determined.\n21.2 markov chain modeling of ph workloads 365\nQuestion: What then is the state space?\nAnswer: One reasonable choice is to again use (i, j), where idenotes the number of\njobs in the queue (not serving) and jdenotes that the job in service (assuming there is\none) has size Exp (μj). The resulting chain is shown in Figure 21.6.\nλλλ\nλλλ\nμ2(1–p μ ) 2(1–p μ ) 2(1–p)μ2p μ2p μ2pμ1(1–p μ ) 1(1–p μ ) 1(1–p)\nμ2μ1\nλ(1–p)μ1p μ1p μ1p1,1 3,1λp2,1\n0,0\n1,2 0,2 2,2 3,20,1\nFigure 21.6. Markov chain for M/H 2/1, with average arrival rate λ. State (i, j)indicates that\nthere are ijobs waiting in the queue and the job in service (if there is one) has size Exp (μj).\nMarkov Chain for E 2/M/1\nSometimes it is the arrival process, not the service process, that is non-Markovian.\nThe E 2/M/1 queue is a single-server FCFS queue where job sizes are distributed as\nExp(μ), but the interarrival times between jobs follow an Erlang-2 distribution. The\nmean interarrival time is1\nλ; hence the rate of each phase of the Erlang-2 is 2λ.\nQuestion: What should the Markov chain look like?\nAnswer: The key is to realize that the time until the next arrival involves two phases (two\nhurdles), and a second arrival cannot begin until both those hurdles have completed.\nThat is, two arrivals cannot be “in progress” at the same time.\nThe resulting state space is therefore (i,j), where now idenotes the number of jobs\nin the system (including the job in service) and j∈{1,2}denotes the phase of the\narrival in progress. The resulting chain is shown in Figure 21.7.\nμμμμλ1\nμμμ1,2 0,2 2,2 3,2\n1,10,1\n2,1 3,1 4,1λ1 λ2 λ1 λ2 λ1 λ2 λ2\nFigure 21.7. Markov chain for E 2/M/1 with average arrival rate λand service rate μ. State\n(i, j)indicates that there are ijobs in the system, including the job in service, and jdenotes the\nphase of the arrival in progress. The top row indicates that there is an arrival in progress that has\njust completed phase 1and is trying to complete phase 2. The bottom row indicates that there\nis an arrival in progress that is still trying to complete phase 1. Throughout λ1=λ2=2λ.",4362
139-21.4 Analysis of Time-Varying Load.pdf,139-21.4 Analysis of Time-Varying Load,"366 phase-type distributions and matrix-analytic methods\nMarkov Chain for M t/M/1\nAnother example of a queue with a non-Markovian arrival process is the case of a\ntime-varying arrival rate, where the arrival rate ﬂuctuates between λH(some high\nrate) and λL(some low rate), spending Exp (αH)time in the high arrival rate regime\nand Exp (αL)time in the low arrival rate regime, as depicted in Figure 21.8. Time-\nvarying load is denoted by M t. The notation M t/M/1 indicates that the arrival rate\nchanges over time. The notation M/M t/1 indicates that the service rate changes over\ntime.\nλHλH\nλLλLExp( αH) Exp( αH)\nExp( αL) Exp( αL)\nFigure 21.8. The arrival process is called a Markov-modulated Poisson process.\nQuestion: What should the Markov chain look like for the M t/M/1?\nAnswer: We need to track whether the system as a whole is operating in the high-load\nphase or the low-load phase. We use the upper (respectively, lower) row of the chain to\ndenote that the system is in the high load (respectively, low load) phase. The resultingMarkov chain is shown in Figure 21.9.\nλLλLαLαHαLαHαLαLαHαHλHλHλH\nλLμμ μ\nμμ μ0H1H2H3H\n3L2L1L0L\nFigure 21.9. Markov chain for M t/M/1, where the arrival rate oscillates between λHfor\nExp(αH)duration and λLfor Exp (αL)duration. The state indicates the number of jobs in the\nsystem, and the superscript indicates the current regime.\n21.3 The Matrix-Analytic Method\nConsider the inﬁnite-state Markov chains from Section 21.2. These look like the\nrandom walk of the M/M/1; however, rather than having just one row, they have two\nrows – and possibly more than two rows if more than two phases are used in the\nPH distribution. If we attempt to write out the balance equations for these chains, we\n21.4 analysis of time-varying load 367\nquickly see that they are quite complex, and there is no obvious “guess” for the limiting\ndistribution.\nDeveloped by Marcel Neuts [ 129,130], matrix-analytic methods are approximate\nnumerical methods for solving Markov chains where the chains (i) repeat (after some\npoint) and (ii) grow unboundedly in no more than one dimension. In particular, matrix-analytic methods can be used to solve all the chains we have seen in Section 21.2.A l l\nthese chains grow unboundedly in one dimension (increasing number of jobs), yet they\nhave only a ﬁnite number of states (two, in all the examples we have seen) in the otherdimension, and they all repeat. By saying that matrix-analytic methods are “numericalmethods,” we mean that they do not provide a closed-form symbolic solution, in termsof\nλ’s and μ’s, but rather we can only solve an instance of the chain (where the rates\nare all numbers). The solution is obtained by iteration, and there is an error associated\nwith the solution. In practice, the number of iterations is not too large, allowing the\nsolution of chains such as those in Section 21.2 to be obtained within seconds. Also in\npractice the error is quite small, except for very unusual PH distributions with highly\nunbalanced rates, created for example by modeling workloads with extremely high C2\nvalues in the thousands.\nThe remainder of this chapter serves as a very brief introduction to matrix-analytic\nmethods. For a more comprehensive treatment, we refer the reader to [ 115].\n21.4 Analysis of Time-Varying Load\nOur ﬁrst illustration of matrix-analytic methods is the M t/M/1 queue, shown earlier in\nFigure 21.8. This is a particularly nice example, because the repetition starts right from\nthe beginning.\n21.4.1 High-Level Ideas\nWe think of the M t/M/1 chain as being divided into levels. Level 0consists of the states\n0Hand0L. Likewise, level iconsists of the states iHandiL. In the same way that for\nthe M/M/1 we sought πi, we now seek /vectorπi, where\n/vectorπi=(πiH,πiL).\nThe high-level idea behind matrix-analytic methods is that we recursively express /vectorπi\nin terms of /vectorπi−1. However, rather than being related by a constant, ρ, as in the M/M/1,\nthey are instead related by a matrix R, such that\n/vectorπi=/vectorπi−1·R,\nwhich, when expanded, yields\n/vectorπi=/vectorπ0·Ri.\n368 phase-type distributions and matrix-analytic methods\nFinding this matrix Rrequires solving a matrix equation by iteration. Note that through-\nout, we still denote the limiting distribution by /vectorπ, where /vectorπis the vector of all limiting\nprobabilities. In the case of the M t/M/1,\n/vectorπ=(π0H,π0L,π1H,π1L,π2H,π2L,...).\n21.4.2 The Generator Matrix, Q\nTo illustrate the method, it is useful to start by rewriting the balance equations in terms\nof a “generator matrix,” Q. This is a matrix such that\n/vectorπ·Q=/vector0 where /vectorπ·/vector1=1. (21.1)\nHere/vectorπis the limiting distribution, and /vector1is always an appropriately sized vector\nof 1s.\nQuestion: Try to write down Qfor the case of an M/M/1, just to get the feel of it.\nAnswer: Q=⎡\n⎢⎢⎢⎢⎣0 123 ···\n0−λλ\n1μ−(λ+μ) λ\n2 μ−(λ+μ) λ\n3 μ−(λ+μ) ···\n... μ...⎤\n⎥⎥⎥⎥⎦.\nEquation ( 21.1) directly translates to the balance equations:\n0=π0·(−λ)+π1·μ\n0=π0·λ+π1·(−(λ+μ)) +π2·μ\n0=π1·λ+π2·(−(λ+μ)) +π3·μ\n...\nObserve that the diagonal entries of Qare all negative and represent the negation of\nthe total rate of leaving the corresponding state.\nQuestion: LetQ(∗,i)denote the ith column of Q. What is the value of the dot product\n/vectorπ·Q(∗,i)?\nAnswer: Each column of Q, when multiplied by /vectorπ, corresponds to a single balance\nequation. Thus, by deﬁnition, the dot product is 0.\nQuestion: Now try to write Qfor the M t/M/1.\n21.4 analysis of time-varying load 369\nAnswer: It helps to recall that /vectorπ=(π0H,π0L,π1H,π1L,π2H,π2L,...).\nNow, viewing each column as the coefﬁcients of a balance equation, we have\nQ=\n⎡\n⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0H0L1H1L2H2L···\n0H−/parenleftbig\nλH+αH/parenrightbig\nαH/vextendsingle/vextendsingle/vextendsingleλH0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n0LαL−/parenleftbig\nλL+αL/parenrightbig/vextendsingle/vextendsingle/vextendsingle0 λL/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n1Hμ 0/vextendsingle/vextendsingle/vextendsingle−/parenleftbig\nλH+αH+μ/parenrightbig\nαH/vextendsingle/vextendsingle/vextendsingleλH0/vextendsingle/vextendsingle/vextendsingle\n1L0 μ/vextendsingle/vextendsingle/vextendsingleαL−/parenleftbig\nλL+αL+μ/parenrightbig/vextendsingle/vextendsingle/vextendsingle0 λL/vextendsingle/vextendsingle/vextendsingle\n2H/vextendsingle/vextendsingle/vextendsingleμ 0/vextendsingle/vextendsingle/vextendsingle−/parenleftbig\nλH+αH+μ/parenrightbig\nαH/vextendsingle/vextendsingle/vextendsingle\n2L/vextendsingle/vextendsingle/vextendsingle0 μ/vextendsingle/vextendsingle/vextendsingleαL−/parenleftbig\nλL+αL+μ/parenrightbig/vextendsingle/vextendsingle/vextendsingle\n···/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle...⎤\n⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦.\nWe can see that this Qmatrix is composed of three 2×2matrices that repeat, plus\none2×2matrix that does not repeat:\nB=/bracketleftbigg(i−1)H(i−1)L\niHμ 0\niL0 μ/bracketrightbigg\n(“Backwards”) i>0\nL=/bracketleftbiggiHiL\niH−(λH+αH+μ) αH\niL αL−(λL+αL+μ)/bracketrightbigg\n(“Local”) i>0\nF=/bracketleftbigg(i+1 )H(i+1 )L\niHλH0\niL0 λL/bracketrightbigg\n(“Forwards”) i≥0\nL0=/bracketleftbiggiHiL\niH−(λH+αH) αH\niL αL−(λL+αL)/bracketrightbigg\n(“Initial Local”) i=0\nWe can now write Qmore economically as\nQ=⎡\n⎢⎢⎣2 222\n2|L0F\n2|BLF\n2| BLF\n2| B...⎤\n⎥⎥⎦.\n370 phase-type distributions and matrix-analytic methods\nUsing the notation /vectorπi=(πiH,πiL), we now rewrite the balance equations /vectorπ·Q=/vector0\nasmatrix equations :\n/vector0=/vectorπ0·L0+/vectorπ1·B\n/vector0=/vectorπ0·F+/vectorπ1·L+/vectorπ2·B\n/vector0=/vectorπ1·F+/vectorπ2·L+/vectorπ3·B\n/vector0=/vectorπ2·F+/vectorπ3·L+/vectorπ4·B\n...\n21.4.3 Solving for R\nWe make the educated guess that\n/vectorπi=/vectorπ0·Ri,∀i>0\nfor some matrix R, to be determined, where /vectorπ0=(π0H,π0L)and/vectorπi=(πiH,πiL).\nSubstituting this guess into the matrix equations yields the following:\n/vector0=/vectorπ0·L0+/vectorπ0·RB ⇒ /vectorπ0(L0+RB)=/vector0\n/vector0=/vectorπ0·F+/vectorπ0·RL+/vectorπ0·R2B⇒/vectorπ0(F+RL+R2B)=/vector0\n/vector0=/vectorπ1·F+/vectorπ1·RL+/vectorπ1·R2B⇒/vectorπ1(F+RL+R2B)=/vector0\n/vector0=/vectorπ2·F+/vectorπ2·RL+/vectorπ2·R2B⇒/vectorπ2(F+RL+R2B)=/vector0\n...\nObserve the common portion is: F+RL+R2B=0. We use this common portion\nto determine Ras follows:\nF+RL+R2B=0\n⇒RL=−/parenleftbig\nR2B+F/parenrightbig\n⇒R=−/parenleftbig\nR2B+F/parenrightbig\nL−1\nWe now solve for Rby iterating (here Rndenotes the nth iteration of R):\n1.LetR0=0(or a better guess, if available).\n2.While||Rn+1−Rn||>/epsilon1,\nSetRn+1=−(R2\nnB+F)L−1.\nThis process keeps iterating until it determines that Rhas “converged.” Sadly there is\nno known closed-form solution for the above matrix quadratic in general; thus iteration\nis the approach that is used.1OnceRconverges, we set /vectorπi=/vectorπ0Ri. These limiting\nprobabilities satisfy the balance equations.\nThere are several points related to solving for Rthat we have not deﬁned. First, there\nare several possible deﬁnitions of the metric: ||Rn+1−Rn||. The typical deﬁnition is\nthe maximum of all the elements in the matrix Rn+1−Rn. Thus, while the biggest\n1For some special chains Rcan be expressed in closed form; see [ 115].\n21.4 analysis of time-varying load 371\ndifference exceeds /epsilon1, we continue iterating. Only when all the element-wise differences\nare smaller than /epsilon1do we stop iterating. Also, the deﬁnition of /epsilon1is unspeciﬁed. We\ntypically start with /epsilon1=1 0−7; however, if convergence is slow, we might try increasing\n/epsilon1by a factor of 10. This is tricky because small differences in Rcan have a profound\neffect on the ﬁnal limiting probabilities.\n21.4.4 Finding /vectorπ0\nThe only value remaining is /vectorπ0=(π0H,π0L). We have two equations involving /vectorπ0:\nFirst, we have the ﬁrst matrix balance equation listed in Section 21.4.3 :\n/vectorπ0(L0+RB)=/vector0 (21.2)\nSecond we have the normalizing equation:\n/vectorπ·/vector1=1 (21.3)\nJust as we did in the scalar case, we are going to replace one of the balance equations\nwith the normalization equation. We start by rewriting the normalizing equation ( 21.3)\nin terms of /vectorπ0:\n∞/summationdisplay\ni=0/vectorπi·/vector1=1,where /vector1=( 1 ,1)\n∞/summationdisplay\ni=0/vectorπ0Ri·/vector1=1\n/vectorπ0/parenleftBigg∞/summationdisplay\ni=0Ri/parenrightBigg\n/vector1=1\n/vectorπ0(I−R)−1/vector1=1 (21.4)\nFor notational simplicity, let Φ=L0+RB andΨ=(I−R)−1/vector1. Thus, ( 21.2)\nbecomes /vectorπ0Φ=/vector0and ( 21.4) becomes /vectorπ0Ψ=1.\nExpanding out /vectorπ0Φ=/vector0to show its components, we have\n/bracketleftbigπ0Hπ0L/bracketrightbig/bracketleftbigg\nΦ00Φ01\nΦ10Φ11/bracketrightbigg\n=/bracketleftbig00/bracketrightbig\n.\nAfter replacing one balance equation (one column) with the normalizing equation, we\nget:\n/bracketleftbigπ0Hπ0L/bracketrightbig/bracketleftbigg\nΨ0Φ01\nΨ1Φ11/bracketrightbigg\n=/bracketleftbig10/bracketrightbig\n.\nThis system of equations has a unique solution, and we solve this system for /vectorπ0=\n(π0H,π0L). Using /vectorπi=/vectorπ0Ri, we now have all the /vectorπi.",11360
140-21.5 More Complex Chains.pdf,140-21.5 More Complex Chains,"372 phase-type distributions and matrix-analytic methods\n21.4.5 Performance Metrics\nFrom the limiting probabilities, we now develop a closed-form expression for E[N]\nin terms of only /vectorπ0andR:\nE[N]=∞/summationdisplay\ni=0i·/vectorπi·/vector1\n=∞/summationdisplay\ni=0i·/vectorπ0·Ri·/vector1\n=/vectorπ0·∞/summationdisplay\ni=1i·Ri−1·R·/vector1\n=/vectorπ0·d\ndR/parenleftBigg∞/summationdisplay\ni=0Ri/parenrightBigg\n·R·/vector1(matrix calculus)\n=/vectorπ0·d\ndR(I−R)−1·R·/vector1\n=/vectorπ0·(I−R)−2·R·/vector1\nSimilarly, we can deﬁne higher moments of N.\nTo determine E[T], we ﬁrst deﬁne the average arrival rate λavg,b y\nλavg=1\nαHλH+1\nαLλL\n1\nαH+1\nαL.\nThen, via Little’s Law,\nE[T]=1\nλavgE[N]=1\nλavg·/vectorπ0·(I−R)−2·R·/vector1.\nThe analysis of the M t/M/1 is discussed further in Exercise 21.2.\nQuestion: Suppose that we applied the matrix-analytic method to derive the limiting\nprobabilities for the M/M/1. What would Rlook like?\nAnswer: In this case, Ris just a 1×1matrix, namely a scalar, and does not require\niteration to obtain. You will solve for it in Exercise 21.1.\n21.5 More Complex Chains\nSometimes the repeating portion of a chain only starts after level M. In this case,\nwe can still use matrix-analytic methods to solve the chain. However, the initial ma-\ntrix,L0, must be larger, so as to encompass the entire non-repeating portion of the\nchain.\nTo illustrate how this works, consider the following example, which we refer to as the\nM∗/E∗\n2/1. Here the arrival process is Poisson, but the average arrival rate is λwhenever\nthe system is non-empty and is λ/primewhen the system is empty (imagine that the queue is\nsent additional work from another source when it is empty, as part of a load balancing\neffort). The job service distribution is a two-phase generalized Erlang, where the ﬁrst\n21.5 more complex chains 373\nλλλ\nμ21,1 3,1\nλ′2,1\n0,0\nλλλ0,1\n0,2 1,2 2,2 3,2μ2 μ1 μ2 μ1 μ2 μ1 μ1\nFigure 21.10. Markov chain for M∗/E∗\n2/1.\nphase is distributed as Exp (μ1)and the second is distributed as Exp (μ2). We deﬁne the\nstate as (i,s), where iis the number of jobs in queue (not counting any job in service)\nandsis the phase of the job in service, or 0if there is no job in service.\nFigure 21.10 shows the CTMC for this system.\nQuestion: Deﬁning a1=−(λ+μ1)anda2=−(λ+μ2), express Qusinga1and\na2.\nAnswer:\nQ=⎡\n⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣(0,0) (0 ,1) (0 ,2) (1 ,1) (1 ,2) (2 ,1) (2 ,2) (3 ,1) (3 ,2) ···\n(0,0)−λ/primeλ/prime0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle00/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(0,1)0a1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleλ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(0,2)μ20a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0λ/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(1,1)000/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglea1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleλ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(1,2)0μ20/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0λ/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(2,1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle00/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglea1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleλ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(2,2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleμ20/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0λ/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(3,1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle00/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglea1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n(3,2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleμ20/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\n.../vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle...⎤\n⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦\n.\n374 phase-type distributions and matrix-analytic methods\nMore succinctly, this can be written as\nQ=⎡\n⎢⎢⎢⎢⎣3 2 222\n3|L0F0\n2|B0LF\n2| BLF\n2| BLF\n2| B...⎤\n⎥⎥⎥⎥⎦.\nIn this case L0is a3×3matrix, representing the non-repeating portion of the chain.\nAlso observe that we needed to introduce F0andB0which are very similar to F\nandB, respectively, but have asymmetric dimensions, which are needed to “link” the\nnon-repeating portion of the chain to the repeating portion of the chain.\nWe deﬁne /vectorπ0=/parenleftbig\nπ(0,0),π(0,1),π(0,2)/parenrightbig\nand/vectorπi=/parenleftbig\nπ(i,1),π(i,2)/parenrightbig\n,∀i>0.N o ww e\nrewrite the balance equations /vectorπ·Q=/vector0as matrix equations:\n/vector0=/vectorπ0·L0+/vectorπ1·B0\n/vector0=/vectorπ0·F0+/vectorπ1·L+/vectorπ2·B\n/vector0=/vectorπ1·F+/vectorπ2·L+/vectorπ3·B\n/vector0=/vectorπ2·F+/vectorπ3·L+/vectorπ4·B\n/vector0=/vectorπ3·F+/vectorπ4·L+/vectorπ5·B\n...\nWe now guess that\n/vectorπM+i=/vectorπM·Ri. (21.5)\nQuestion: What is Mhere?\nAnswer: In the time-varying load example from Section 21.4,Mwas0, but for this\nchain, M=1.\nSubstituting the above guess into the balance equations yields the following matrix\nequations:\n/vector0=/vectorπ0·L0+/vectorπ1·B0\n/vector0=/vectorπ0·F0+/vectorπ1·L+/vectorπ1·RB\n/vector0=/vectorπ1·F+/vectorπ1·RL+/vectorπ1·R2B⇒/vectorπ1/parenleftbig\nF+RL+R2B/parenrightbig\n=0\n/vector0=/vectorπ2·F+/vectorπ2·RL+/vectorπ2·R2B⇒/vectorπ2/parenleftbig\nF+RL+R2B/parenrightbig\n=0\n/vector0=/vectorπ3·F+/vectorπ3·RL+/vectorπ3·R2B⇒/vectorπ3/parenleftbig\nF+RL+R2B/parenrightbig\n=0\n...\n21.5 more complex chains 375\nThe common portion is again F+RL+R2B=0. Thus\nRL=−(R2B+F)\n=⇒R=−/parenleftbig\nR2B+F/parenrightbig\nL−1.\nWe now solve for Rby iterating:\n1.LetR0=0(or a better guess, if available).\n2.While||Rn+1−Rn||>/epsilon1,\nSetRn+1=−(R2\nnB+F)L−1.\nAs before, we iterate until Rhas “converged.”\nAll that is left is to determine the initial limiting probabilities. In this case, this means\ndetermining both /vectorπ0=/parenleftbig\nπ(0,0),π(0,1),π(0,2)/parenrightbig\nand/vectorπ1=/parenleftbig\nπ(1,1),π(1,2)/parenrightbig\n.\nThe “local” portion of the balance equations can be written as\n/bracketleftbig/vectorπ0/vectorπ1/bracketrightbig/bracketleftbigg\nL0F0\nB0L+RB/bracketrightbigg\n=/vector0,\nor equivalently/bracketleftbig/vectorπ0/vectorπ1/bracketrightbig\nΦ=→\n0where\nΦ=/bracketleftbigg\nL0F0\nB0L+RB/bracketrightbigg\n. (21.6)\nHere/vector0refers to [0,0,0,0,0].\nWe also have the normalizing equation /vectorπ·/vector1=1 . We again replace one of the balance\nequations with the normalization equation. Rewriting the normalization equation interms of\n/vectorπ0and/vectorπ1,\n/vectorπ0·/vector1+∞/summationdisplay\ni=1/vectorπi·/vector1=1.\n/vectorπ0·/vector1+∞/summationdisplay\ni=0/vectorπ1Ri·/vector1=1.\n/vectorπ0·/vector1+/vectorπ1/parenleftBigg∞/summationdisplay\ni=0Ri/parenrightBigg\n/vector1=1.\n/vectorπ0·/vector1+/vectorπ1(I−R)−1/vector1=1.\nNote that the ﬁrst /vector1in each equation above has dimension 3, while the second /vector1has\ndimension 2. We deﬁne\nΨ=/bracketleftbigg/vector1\n(I−R)−1·/vector1/bracketrightbigg\nto be a column vector of size 5.",8681
141-21.6 Readings and Further Remarks.pdf,141-21.6 Readings and Further Remarks,,0
142-21.7 Exercises.pdf,142-21.7 Exercises,"376 phase-type distributions and matrix-analytic methods\nThen we can write the normalization equation as\n/bracketleftbig/vectorπ0/vectorπ1/bracketrightbig\nΨ=1.\nTo combine the balance equations with the normalization equation, we return to equa-\ntion ( 21.6), repeated here for easy reference:\n/bracketleftbig/vectorπ0/vectorπ1/bracketrightbig\nΦ=[ 0,0,0,0,0],where Φ=/bracketleftbigg\nL0F0\nB0L+RB/bracketrightbigg\nWe replace the ﬁrst column of ΦwithΨ, and the ﬁrst element of the zero vector with\n1. We then solve the resulting system of 5 linear equations for (/vectorπ0,/vectorπ1).F r o m( 21.5),\nwe now obtain all the remaining limiting probabilities.\n21.6 Readings and Further Remarks\nSome additional information on phase-type distributions is provided in [ 5], pp. 148–\n59. Representing general distributions by phase-type distributions is a very powerful\ntechnique. It is often the only technique known for Markov modeling of problems\ninvolving general distributions. To make the Markov chain tractable, it is important that\nthe PH representation of these general distributions does not require too many phases ortoo many parameters. There is a great deal of research into ﬁnding PH representationsof general distributions that use few phases and yet accurately represent the givendistribution. We recommend [ 135] and [ 137] as examples of moment matching and\n[56] as an example of tail ﬁtting.\nUnfortunately there are not many books that explain matrix-analytic methods. Latouche\nand Ramaswami [ 115] have an excellent textbook devoted to matrix-analytic methods.\nThe book goes much further than this chapter, explaining the meaning behind the\nR\nmatrix. The book also discusses convergence properties of the iteration. Matrix-analytic\nmethods are also covered in Nelson’s book [ 127].\nOne ﬁnal remark: There are situations where matrix-analytic methods break down\nbecause higher powers of Rbecome singular. This can happen for a number of reasons,\nbut one condition that induces such behavior is highly variable distributions. Suppose\nfor example that one is studying delay in the M/H 2/2 system. If one chooses H2with\nC2<100, matrix-analytic methods are excellent for deriving mean delay. However,\nwithC2>1000 , matrix-analytic methods can sometimes break down.\n21.7 Exercises\n21.1 Applying Matrix-Analytic Methods to the M/M/1\nConsider the M/M/1 with arrival rate λand service rate μ. Solve for the limiting\nprobabilities using the matrix-analytic method in this chapter. Speciﬁcally,\nderiveQ,B,L,F, andR, and then use these to write out the limiting\nprobabilities.\n21.7 exercises 377\n21.2 Time-Varying Load\nConsider the M t/M/1 with a mean job size of 1and mean load 0.7, where the\narrival rate ﬂuctuates between high-load, 1.2, and low-load, 0.2, with Exp (α)\ntime in each state. Apply the matrix-analytic procedure described in this chapter\nto determine the mean response time, E[T], for a range of switching rates, α,\nranging from very quick alternation to very slow alternation (use a log scale).\n(a) Create a plot of E[T]versus α.\n(b) When alternation is very fast (high α), what does your E[T]converge to?\nWhy?\n(c) When alternation is very slow (very low α), what happens to E[T]?W h y ?\n(d) Suppose that the arrival rate instead ﬂuctuates between 0.9and0.5with\nExp(α)time in each state. Again the mean is 0.7. What should the mean\nresponse time look like now in the case when alternation is very slow (verylow\nα)? Why?\nRemark: Unfortunately, exact closed-form solutions for the M t/M/1 require\nsolving a cubic, and thus are not straightforward, nor has much been developed\nin terms of approximations. See [ 78] for additional insights.\n21.3 Applying Matrix-Analytic Methods to the M/Cox/1\nUse the matrix-analytic method to analyze the M/Cox/1 queue. The arrival\nprocess is Poisson( λ). The service time distribution is phase-type with 2 stages,\nthe ﬁrst of duration Exp (μ1)and the second of duration Exp (μ2), where the\nsecond stage is only invoked with probability p(with probability 1−p, service\ncompletes immediately after the ﬁrst stage). Derive E[N]andE[T]when\nλ=1,μ1=2,μ2=3, andp=0.4.\nHere are some steps:\n(a) Deﬁne a state space.\n(b) Draw out the Markov chain.\n(c) Write out the generator matrix Q(it is inﬁnite, so a portion will do).\n(d) Write out the matrices: F0,L0,B0,F,L,B. [Check: Lshould be a 2×2\nmatrix.]\n(e) Write out the balance equations, and make the appropriate guess for the\nrepeating part of the limiting probabilities.\n(f) Solve for the matrix R. [Check: Rshould be a 2×2matrix.]\n(g) Use the initial (non-repeating) balance equations together with the normal-\nization constraint to solve for the initial limiting probabilities. Remember\nthat these may be vectors. [Check: Compute the probability of there being\nzero jobs in the system. This should equal 1−ρ≈0.367.]\n(h) At this point you should have all the limiting probabilities. Use these to\ncompute E[N]andE[T].\n21.4 Effect of Variability in Service Time\nCreate a Hyperexponential distribution, H2, with balanced branches/parenleftBig\np\nμ1=1−p\nμ2/parenrightBig\n, ﬁxed mean E[S]=1 , andC2=1 0 . Now use matrix-analytic\nmethods to determine mean response time, E[T], for the M/H 2/1 when the\naverage load is ρ=0.8. Hold ρandE[S]ﬁxed but increase C2.T r yC2=2 0 ,\n378 phase-type distributions and matrix-analytic methods\nC2=3 0 ,C2=4 0 , andC2=5 0 . What happens to E[T]? Why do you think\nthis occurs?\n21.5 Hyperexponential Distribution: DFR\nProve that the H2Hyperexponential distribution has decreasing failure rate\n(DFR). Derive the failure rate function, r(x)=f(x)\nF(x), and then take its deriva-\ntive to show that r(x)is decreasing in x. Also explain intuitively why the\nHyperexponential has DFR.\n21.6 Variance of Number of Jobs\nIn the same way that we derived a closed-form expression for the mean number\nof jobs, E[N], in terms of R, we can also write a closed-form expression\nforVar(N)in terms of R, using a little more matrix calculus. Derive this\nexpression.\n21.7 Effect of Variability in Service Time in Multi-Server Systems\nIn this problem we repeat the analysis from Exercise 21.4, except that we\ndeal with a 2-server system. Again create an H2with balanced branches/parenleftbigp\nμ1=1−p\nμ2/parenrightbig\nand ﬁxed mean E[S]=1 andC2=1 0 . This time, use matrix-\nanalytic methods to determine E[T]for the M/H 2/2 when the system load is\nρ=0.8. Hold ρandE[S]ﬁxed but increase C2.T r yC2=2 0 ,C2=3 0 ,\nC2=4 0 , andC2=5 0 . What happens to E[T]? Is the effect of increased\nvariability more or less pronounced than for the case of a single server? Give\nas much intuition as you can for what is going on.\nThere is no known closed-form solution for the mean response time in an\nM/H 2/2. The best known approximation is due to Lee and Longton [ 118]w h o\nstate that\nE/bracketleftbig\nTM/G/k\nQ/bracketrightbig\n≈/parenleftbiggC2+1\n2/parenrightbigg\nE/bracketleftbig\nTM/M/k\nQ/bracketrightbig\n,\nwhere Ghere denotes any general distribution, including the H2. How do your\nresults compare to the Lee and Longton approximation?\n21.8 Understanding Setup Times\nThe effect of setup times is not well understood in multi-server systems, see[68]. This exercise uses matrix-analytic methods to analyze these systems\nnumerically.\nSetup times for the M/M/1 were introduced in Exercise 15.10 . We deﬁne a\nsetup time for a multi-server system as follows: When a server goes idle, it\nimmediately shuts off. When a job arrives, it needs to set up a server before itcan use the server. The setup time is denoted by\nI. If a server, s1, is in setup\nmode, and another server s2becomes free, then the job waiting for s1is routed\ntos2. At this point server s1is shut off, unless there is a job in the queue, in\nwhich case the queued job takes over waiting for s1.\n(a) Draw a CTMC for an M/M/1 with setup time, I, where I∼Exp(α).\n(b) Draw a CTMC for an M/M/1 with setup time, I, where I∼Erlang-2 with\nmean1\nα.\n(c) Draw a CTMC for an M/M/2 with setup time, I, where I∼Exp(α).\n21.7 exercises 379\n(d) Draw a CTMC for an M/M/2 with setup time, I, where I∼Erlang-2 with\nmean1\nα.\n(e) For parts (a) and (c), use matrix-analytic methods to analyze response time,\nassuming μ=1,α=0.1, andρ=0.5,0.7,0.9. How does setup affect\nthe M/M/2 as compared with the M/M/1?",8365
143-Chapter 22 Networks with Time-Sharing PS Servers BCMP.pdf,143-Chapter 22 Networks with Time-Sharing PS Servers BCMP,,0
144-22.1 Review of Product Form Networks.pdf,144-22.1 Review of Product Form Networks,,0
145-22.2 BCMP Result.pdf,145-22.2 BCMP Result,"CHAPTER 22\nNetworks with Time-Sharing\n(PS) Servers (BCMP)\nIn Chapter 21, we saw one application for phase-type (PH) distributions: If we need\nto analyze a system whose workload involves distributions that are non-Exponential\n(e.g., high-variability workloads), then we can use a PH distribution to at least match2 or 3 moments of that workload distribution. This allows us to represent the systemvia a Markov chain, which we can often solve via matrix-analytic methods.\nIn this chapter we see another application of PH distributions. Here, we are interested\nin analyzing networks of Processor-Sharing (time-sharing) servers (a.k.a. PS servers).It will turn out that networks of PS servers exhibit product form solutions, evenunder general service times. This is in contrast to networks of FCFS servers, whichrequire Exponential service times. Our proof of this PS result will rely on phase-type\ndistributions. This result is part of the famous BCMP theorem [ 16].\n22.1 Review of Product Form Networks\nSo far we have seen that all of the following networks have product form:\nrOpen Jackson networks: These assume probabilistic routing, FCFS servers with\nExponential service rates, Poisson arrivals, and unbounded queues.\nrOpen classed Jackson networks: These are Jackson networks, where the outsidearrival rates and routing probabilities can depend on the “class” of the job.\nrClosed Jackson networks\nrClosed classed Jackson networks\nWe have also seen (see Exercise 19.3) that Jackson networks with load-dependent\nservice rates have product form. Here the service rate can depend on the number of\njobs at the server. This is useful for modeling the effects of parallel processing. Note\nthat all of our results thus far have assumed FCFS scheduling at each server.\n22.2 BCMP Result\nIn 1975 Baskett, Chandy, Muntz, and Palacios-Gomez wrote a very famous paper\nproviding a broad classiﬁcation of networks with product form. We describe here asubset of the results in this paper and refer the reader to the original paper [ 16] for full\nresults.\n380\n22.2 bcmp result 381\nThe results can be subdivided based on the type of service discipline (scheduling\npolicy) at the servers. The ﬁrst set of results assumes FCFS servers (we are alreadyfamiliar with these). The second set of results assumes either Processor-Sharing (PS)service discipline or one of a few other service disciplines at the servers.\n22.2.1 Networks with FCFS Servers\nFor networks with FCFS servers with unbounded queues, BCMP states that prod-\nuct form solutions exist for open, closed, single-class, and multi-class networks withprobabilistic routing with the following restrictions:\nConditions\nrThe outside arrivals must be Poisson.\nrThe service times at the servers must be Exponentially distributed.\nrThe service rate at a server may be load dependent but cannot be class\ndependent.\nThe BCMP results for the case of networks of FCFS servers are very powerful. They\nsay that, for the purpose of performance evaluation, we can think of the servers asindependent M/M/1 queues.\nHowever, the BCMP requirements (for the case of FCFS servers) are also unrealistic\nin two ways. First, the fact that the service times must be Exponentially distributed issomewhat restrictive.\nThe second drawback is referred to as “Kleinrock’s independence assumption.”\nThis says that every time a job visits a server, its service time at the server is a newindependent random variable. In particular, a job may visit the same server twice andexperience different service times during the two visits.\nThe issue is that the service time is associated with the server , not with the job.W e\nneed this in order to get product form. If we could at least allow the service rate tobe associated with the class of the job, then we could model the idea of different job\nsizes (e.g., “small jobs” that have very fast service rates at every server and “big jobs”\nthat have slow service rates at every server). That is, we could maintain the “size” of a\njob as it moves between servers, so that subsequent visits of a job to the same serverdo not result in different service requirements. But alas, in the case of networks ofFCFS servers, we cannot analyze the model where the service rate depends on the jobclass.\nUsefulness for Communication Networks\nNevertheless, despite the Exponential service rates and the highly unrealistic Klein-\nrock’s independence assumption, the BCMP results are highly useful for predictingdelays in communication networks. In communication networks, the “jobs” are just\n382 networks with time-sharing (ps) servers (bcmp)\nﬁxed-size packets (all packets have the same size). Time is only spent when a\npacket is transmitted on a link. Servers are thus used to model the links leaving a\nrouter – one server per outgoing link. The service time of a job at a server corresponds\nto the packet’s transmission time (the time to put the packet onto the wire). There isan FCFS queue associated with each server, made up of packets waiting to go onto\nthat corresponding link. Note that a job’s “service time” (transmission time for thepacket) is really some constant (depending on the link bandwidth). An Exponentialservice time distribution does a decent enough job of modeling that situation, because\nthe Exponential has somewhat low variability. A Jackson network with Exponential\nservice times actually provides an upper bound (with respect to mean response time)on the same network with constant service times, see [ 81] for a proof. Furthermore, it\nis especially convenient that we can make the routing of packets be class dependent\nto represent the fact that certain packets follow one route while other packets followother routes.\n22.2.2 Networks with PS Servers\nThe main BCMP results deal with networks where the servers use Processor-Sharing\nservice order. In this case the results are much more powerful!\nDeﬁnition 22.1 A server with service rate μoperates under Processor-Sharing\n(PS) service order if, whenever there are njobs at the server, each of the jobs is\nprocessed at rateμ\nn.\nUnder PS scheduling, every job in the queue receives service at all times. However, the\nshare received by a job depends on how many other jobs are currently present.\nQuestion: Give an example of Processor-Sharing in computer systems.\nAnswer: A time-sharing CPU rotates in round-robin order between the njobs in the\nsystem, giving the ﬁrst job one quantum, then the second job one quantum, ..., then\nthenth job one quantum, and then returning back to the ﬁrst job to repeat. If we think\nof the quantum size as approaching 0, we get PS. Note that under PS there is no cost\nfor switching between jobs, whereas in time-sharing CPUs there is a small overhead\nfor context-switching.\nQuestion: Suppose njobs arrive at time 0to a PS server with service rate 1. They each\nhave service requirement 1. At what time do they complete? What is their slowdown?\nAnswer: All jobs complete at time nand have slowdown n.\nQuestion: The previous question/answer may make it seem that PS is a poor scheduling\npolicy. When is PS scheduling useful?Answer: PS scheduling is useful when job sizes have high variability. PS prevents\nshort jobs from having to wait behind long jobs, without requiring knowledge of the\nsize of the job a priori. We will learn more about this in Chapter 30.\n22.2 bcmp result 383\nPS\nFigure 22.1. PS server\nTo indicate the fact that in a PS server all jobs are being worked on at once, we will\noften draw the queue as in Figure 22.1.\nBCMP states that for networks where servers use PS service order, product form\nsolutions exist for open, closed, single-class, or multi-class networks with probabilisticrouting, with the following conditions:\nConditions\nrThe outside arrivals must be Poisson.\nrThe service times at servers can follow any Coxian distribution .\nrThe service rate at a server may be load dependent, and the service time distri-\nbution is also allowed to depend on the class of the job.\nThe last two “conditions” are not actually restrictions. Recall from Chapter 21 that\nCoxian distributions are dense in the class of non-negative distributions. Hence, givenenough phases, the service time at the servers can approximate any general non-negativedistribution arbitrarily closely.\nThe Processor-Sharing (PS) result is often ignored by most books. This is probably\nbecause most books are concerned with communication networks and thus FCFSservers. However, in analyzing networks of workstations, it is much more common thatthe workstations are time-sharing machines, scheduling their jobs in PS order. Thismakes the PS result very important to computer system designers.\nWhy the PS Result is Important\nThe standard weakness in queueing networks is that service time is afﬁliated with the\nserver, not with the job. However, observe that for networks of PS servers, we cancircumvent this drawback: We make the service time afﬁliated with the job by makingthe service time afﬁliated with the class of the job! The job’s class then determines\nthe job’s service time at all servers. Observe that service time can even be a (near)\nconstant dependent on the class. Thus some jobs always have size\n1, and some have\nsize2, and some have size 3, etc. We can even go so far as to create a realistic workload\ndistribution by using enough different classes. To take this idea even further, we could\nuse the fact that jobs can change classes to model the notion of a job’s remaining\nservice time increasing based on its service time so far.\nThe possible ideas for networks of PS servers are limitless. Much more research needs\nto be done on exploiting this fantastic result.",9726
146-22.4 MCox1PS.pdf,146-22.4 MCox1PS,"384 networks with time-sharing (ps) servers (bcmp)\nOutline of the Rest of the Chapter\nWe have discussed why the PS result is so powerful. The rest of this chapter is devoted\nto proving a small piece of the PS result. To keep from losing the intuition, we derivethe limiting probabilities for only the cases of 1 PS queue and 2 PS queues in tandem,\nwith only a single class of jobs. The proof for the case of\nkPS queues is very similar\nto that for the case of 2 PS queues, and we expect the reader to be able to see how to\nexpand the 2-server proof to kservers. Rather than state the general result upfront, we\nkeep the suspense alive by deriving the results one at a time, because the derivations areas beautiful as the results themselves. We refer the reader to the BCMP paper [ 16]f o r\na description of the full product form formulas in the case of multi-classed networks\nand the case of class-dependent service rates.\nRemark: The BCMP paper [ 16] describes many results that we will not be proving.\nFor example, the results for the PS service discipline are extended to the Preemptive-\nLast-Come-First-Served (PLCFS) service discipline. Under PLCFS a running job isalways preempted by the last job to arrive. Surprisingly, PLCFS exhibits product formas well, and the proofs are similar in style to the proofs we present for PS service order.We will not study the PLCFS service order until Chapter 30. The BCMP results also\nallow for service stations with an inﬁnite number of servers (no delay). The BCMPpaper also allows for mixing different types of servers – for example, both PS and\nFCFS servers – within the same network.\n22.3 M/M/1/PS\nBefore we discuss Coxian service times, it is instructive to start by considering Ex-\nponentially distributed service times and see what we can say about the M/M/1/PSqueue.\nConsider a single M/M/1/PS queue with arrival rate\nλand service rate μ. The server\nservices jobs in PS order; namely, when there are njobs at the server, each is being\nserviced with rate μ/n.\nQuestion: What is the limiting probability of there being njobs in the M/M/1/PS\nqueue? How does your answer compare with that of an M/M/1/FCFS server?\nHint: This may seem like a really hard problem. The trick is to model the M/M/1/PS\nqueue via a CTMC.\nAnswer: Figure 22.2 describes the CTMC for M/M/1/PS. States represent the number\nof jobs at the server. The arrival rate at each state is λ, so the forward transitions are\nFigure 22.2. CTMC for M/M/1/PS.\n22.4 m/cox/ 1/ps 385\nclear. To understand the backward transitions, suppose that the chain is in state i. The\nrate at which an individual job gets serviced in state iisμ/i, because the server is\nshared among the ijobs. However, because all ijobs are running, the rate at which some\njob completes is i·(μ/i)=μ(recall that the minimum of iExponentially distributed\nrandom variables is still Exponentially distributed with rate equal to the sum of their\nrates). So, given that the CTMC is in state i, the rate of moving to state i−1isμ.\nThus this CTMC looks exactly like the regular M/M/1/FCFS. We already know how\nto solve this chain:\nπn=P{njobs at server }=ρn(1−ρ).\n22.4 M/Cox/1/PS\nNow consider a single M/Cox/1/PS server. A general k-phase Coxian distribution is\nshown in Figure 22.3, where the pi’s are probabilities. We simplify the computation\nby just doing the analysis for an abridged 2-phase Coxian service distribution, asshown in Figure 22.4, because the idea is the same as you increase the number of\nphases.\n1–p1 1–p2 1–p3p1 p0 p3 p2 pk–1μ1 μ2 μk μ3 λ\n1–p0\nFigure 22.3. Service time is Coxian with kphases.\nIn the abridged Coxian distribution with 2 phases, each job independently must ﬁrstcomplete phase 1 and then, with probability\np, must complete phase 2. However, this\nis a PS server, not a FCFS server. Thus there is no queue, and all jobs are actuallyserving at once (they are all in the gray region). Speciﬁcally, there may be several jobs\nλ\n1–pp\nμ1 μ2\nFigure 22.4. Service time is abridged Coxian distribution with 2 phases.\n386 networks with time-sharing (ps) servers (bcmp)\nworking on completing phase 1, and there may be several others working on completing\nphase2.\nWe deﬁne the state of our system to be\n(n1,n2),\nwhere n1represents the number of jobs currently in phase 1andn2represents the\nnumber of jobs currently in phase 2. We deﬁne πn1,n2to be the probability of the\nserver being in state (n1,n2).\nThe way to picture this is to imagine a professor with ngraduate students. Each of\nher students is in one of two phases of graduate school – the “quals” phase, where thestudent is preparing for qualiﬁer exams, which takes time Exp\n(μ1), and the “thesis”\nphase, where the student is writing a thesis, which takes time Exp (μ2). At any moment\nof time the professor has n1students simultaneously trying to get through the “quals”\nphase and n2students simultaneously trying to get through the “thesis” phase. The\negalitarian professor splits her time evenly between all nstudents.\nQuestion: What is the service rate experienced by a student in phase 1(the “quals”\nphase)?\nAnswer: If there were no other students, a student in phase 1would be served at rate\nμ1. However, because the student has to share the professor with all other students of\nthe professor, the student is actually served at rate\nμ1\ntotal number of students=μ1\nn1+n2.\nTo determine πn1,n2, we need to write balance equations for the M/Cox/1/PS. These\ncan get quite complex. We therefore solve for the limiting probabilities via the methodof local balance, except that this time we apply local balance to each phase . That is,\nwe will equate\nBi=Rate leave state (n1,n2)\ndue to a departure from phase i=Rate enter state (n1,n2)\ndue to an arrival into phase i=B/prime\ni.\nNote about notation: We use B0to represent the rate that we leave state (n1,n2)due\nto a departure from phase 0, where phase 0represents the outside. Thus a departure\nfrom phase 0represents an arrival from outside. Hence B0represents the rate that we\nleave state (n1,n2)due to an arrival from outside. Likewise B/prime\n0represents the rate that\nwe enter state (n1,n2)due to an arrival into phase 0, where phase 0represents the\noutside. Hence B/prime\n0represents the rate that we enter state (n1,n2)due to a departure to\nthe outside.\nQuestion: Warmup: How do we deﬁne B1, the rate of leaving state (n1,n2)due to a\ndeparture from phase 1?\nAnswer: There are n1jobs at phase 1. Each leaves phase 1 with Exponential rate\nπn1,n2·μ1\nn1+n2.\n22.4 m/cox/ 1/ps 387\nNote: We divided by n1+n2because the job is slowed down by all the other jobs in\nthe PS server – not just in its phase. Thus the total rate of leaving state (n1,n2)due to\na departure from phase 1is\nn1·πn1,n2·μ1\nn1+n2.\nBi: Rate leaving state (n1,n2)due to a departure from phase i:\nB0=πn1,n2λ\nB1=πn1,n2μ1n1\nn1+n2\nB2=πn1,n2μ2n2\nn1+n2\n(Recall that B0means “leaving the outside” or, equivalently, arriving from outside into\nthe system.)\nB/prime\ni: Rate entering state (n1,n2)due to an arrival into phase i:\nB/prime\n0=πn1+1,n2μ1(n1+1)(1 −p)\nn1+n2+1+πn1,n2+1μ2(n2+1)\nn1+n2+1\nB/prime\n1=πn1−1,n2λ\nB/prime\n2=πn1+1,n2−1μ1(n1+1)p\nn1+n2\n(Recall that B/prime\n0means “entering outside” or leaving the system.)\nWe now need to make a guess for the limiting probability πn1,n2.\nQuestion: Look at equating B1andB/prime\n1. What guess makes B1=B/prime\n1?\nHint: Observe that\nB1=B/prime\n1=⇒πn1,n2=ρ1n1+n2\nn1πn1−1,n2,where ρ1=λ\nμ1.\nAnswer: The fact that the limiting probabilities differ by factors involving n1+n2\nandn1suggests a combinatorial choose. A guess for the limiting probabilities is:\nπn1,n2=/parenleftbigg\nn1+n2\nn1/parenrightbigg\nρ1n1ρ2n2π0,0, (22.1)\nwhere ρ1=λ\nμ1andρ2=λp\nμ2. Note that ρ1andρ2do not mean anything here. This is\njust a notational convenience.\nLet’s verify this guess by checking Bi=B/prime\nifor all i.\n388 networks with time-sharing (ps) servers (bcmp)\nCheck for i=1 :\nB/prime\n1=πn1−1,n2λ\n=/parenleftbign1+n2−1\nn1−1/parenrightbig\nρ1n1−1ρ2n2π0,0λ\n=/parenleftbign1+n2\nn1/parenrightbign1\nn1+n2ρ1n1ρ2n2π0,0λ\nρ1\n=πn1,n2n1\nn1+n2λ\nρ1\n=πn1,n2μ1n1\nn1+n2\n=B1\nCheck for i=2 :\nB/prime\n2=πn1+1,n2−1μ1(n1+1)p\nn1+n2\n=/parenleftbign1+n2\nn1+1/parenrightbig\nρ1n1+1ρ2n2−1π0,0μ1(n1+1)p\nn1+n2\n=/parenleftbign1+n2\nn1/parenrightbign2\nn1+1ρ1n1ρ2n2π0,0μ1(n1+1)p\nn1+n2ρ1\nρ2\n=πn1,n2n2\nn1+1μ1(n1+1)p\nn1+n2ρ1\nρ2\n=πn1,n2μ2n2\nn1+n2\n=B2\nCheck for i=0 :\nB/prime\n0=πn1+1,n2μ1(n1+1)(1 −p)\nn1+n2+1+πn1,n2+1μ2(n2+1)\nn1+n2+1\n=/parenleftbign1+n2+1\nn1+1/parenrightbig\nρ1n1+1ρ2n2π0,0μ1(n1+1)(1 −p)\nn1+n2+1+/parenleftbign1+n2+1\nn1/parenrightbig\nρ1n1ρ2n2+1π0,0μ2(n2+1)\nn1+n2+1\n=πn1,n2n1+n2+1\nn1+1ρ1μ1(n1+1)(1 −p)\nn1+n2+1+πn1,n2n1+n2+1\nn2+1ρ2μ2(n2+1)\nn1+n2+1\n=πn1,n2λ(1−p)+πn1,n2λp\n=πn1,n2λ\n=B0\nSo the guess in ( 22.1) works. Let’s use this guess to express P{njobs in system }. Let\nn=n1+n2. Then by ( 22.1)w eh a v e\nP{njobs in system }=n/summationdisplay\nn1=0πn1,n−n1=n/summationdisplay\nn1=0/parenleftbiggn\nn1/parenrightbigg\nρ1n1ρ2n−n1π0,0.\n22.4 m/cox/ 1/ps 389\nNote that the last expression on the right is just a binomial expansion:\nn/summationdisplay\nn1=0/parenleftbiggn\nn1/parenrightbigg\nρ1n1ρ2n−n1π0,0=(ρ1+ρ2)nπ0,0.\nSo\nP{njobs in system }=(ρ1+ρ2)nπ0,0. (22.2)\nQuestion: What is ρ1+ρ2?\nAnswer:\nρ1+ρ2=λ\nμ1+λp\nμ2\n=λ·/parenleftbigg1\nμ1+p\nμ2/parenrightbigg\n.\nQuestion: Does this term/parenleftBig\n1\nμ1+p\nμ2/parenrightBig\nhave a meaning?\nAnswer: Yes! Observe that/parenleftbigg1\nμ1+p\nμ2/parenrightbigg\n=Average service requirement of job entering the system =E[S].\nSo\nρ1+ρ2=λ·E[S]\n=ρ=load for the single-server system.\nThus we have from ( 22.2),\nP{njobs in system }=ρnπ0,0.\nNow, we just need the normalization constant π0,0, which allows\n∞/summationdisplay\nn=0P{njobs in system }=1.\nClearly, because π0,0is the fraction of time that the server is idle,\nπ0,0=1−ρ.\nHence,\nP{njobs in system }=ρn(1−ρ).\nBut this is the same as for an M/M/1.\nUNBELIEV ABLE!\nThe fact that the limiting probabilities of the M/G/1/PS are independent of the job\nsize distribution (they depend only on its mean) is called an insensitivity property .\n390 networks with time-sharing (ps) servers (bcmp)\nInsensitivity properties are rare and always very interesting. It is hard to ﬁnd intuitive\nexplanations for why certain queueing networks exhibit insensitivity.\nExample 1 – Single Server\nConsider a time-sharing CPU, shown in Figure 22.5. The jobs arriving to this server\nhave service requirements (sizes) that come from some unknown distribution. The\narrival process is Poisson with rate λ=3jobs/sec. The mean job service requirement\nis1/5sec.\nPoisson ( λ) PS\nJob sizes come from \nany weird distrib ution yo u like \nFigure 22.5. M/G/1/PS.\nQuestion: What is the mean response time for this system?\nAnswer: The solution is the same as if we had an M/M/1/FCFS:\nE[T]=1\nμ−λ=1\n5−3=1\n2sec\nExample 2 – Server Farm\nSuppose you have a distributed server system consisting of two hosts. Each host is a\ntime-sharing host. Host 1 is twice as fast as Host 2.\nJobs arrive to the system according to a Poisson process with rate λ=1/9jobs/sec.\nThe job service requirements come from some general distribution with mean 3seconds\nif run on Host 1, but take twice as long on Host 2. When a job enters the system, with\nprobability p=3\n4it is sent to Host 1, and with probability 1−p=1\n4is sent to Host 2.\nMean service time \nis 3 seconds. \nPoisson (1/9) ¾\n¼PS\nPS\nMean service time\nis 6 seconds. \nFigure 22.6. PS server farm.",11602
147-22.5 Tandem Network of MG1PS Servers.pdf,147-22.5 Tandem Network of MG1PS Servers,"22.5 tandem network of m/g/ 1/ps servers 391\nQuestion: What is the mean response time for jobs?\nAnswer: Figure 22.6 shows the server farm.\nThe mean response time is simply\nE[T]=3\n4·(Mean response time at server 1) +1\n4·(Mean response time at server 2)\n=3\n4·1\n1\n3−1\n9·3\n4+1\n4·1\n1\n6−1\n9·1\n4=24\n5sec.\n22.5 Tandem Network of M/G/1/PS Servers\nFigure 22.7 displays two PS servers in tandem, each with two phases. Here, the state\nis the number of jobs at every phase of every server: ( n1,n2,m1,m2). To determine\nthe limiting probabilities, once again we apply local balance to each phase . That is, we\nequate\nBi=Rate leave state (n1,n2,m1,m2)\ndue to a departure from phase i=Rate enter state (n1,n2,m1,m2)\ndue to an arrival into phase i=B/prime\ni.\nHere we have 5 phases: phase 0 corresponds to “outside,” and phases 1, 2, 3, and 4 are\nas shown in Figure 22.7. We now deﬁne the rates of leaving/entering a state.\nBi: Rate leaving state ( n1,n2,m1,m2) due to a departure from phase i:\nB0=πn1,n2,m1,m2λ\nB1=πn1,n2,m1,m2μ1n1\nn1+n2\nB2=πn1,n2,m1,m2μ2n2\nn1+n2\nB3=πn1,n2,m1,m2μ3m1\nm1+m2\nB4=πn1,n2,m1,m2μ4m2\nm1+m2\nλ\n1–pp\nμ1 μ212\n1–qq\nμ3 μ434Phases: 1,2  Phases: 3,4\nFigure 22.7. Tandem network.\n392 networks with time-sharing (ps) servers (bcmp)\nB/prime\ni: Rate entering state ( n1,n2,m1,m2) due to an arrival into phase i:\nB/prime\n0=πn1,n2,m1+1,m2μ3(m1+1)(1 −q)\nm1+m2+1+πn1,n2,m1,m2+1μ4(m2+1)\nm1+m2+1\nB/prime\n1=πn1−1,n2,m1,m2λ\nB/prime\n2=πn1+1,n2−1,m1,m2μ1(n1+1)p\nn1+n2\nB/prime\n3=πn1,n2+1,m1−1,m2μ2(n2+1)\nn1+n2+1+πn1+1,n2,m1−1,m2μ1(n1+1)(1 −p)\nn1+n2+1\nB/prime\n4=πn1,n2,m1+1,m2−1μ3(m1+1)q\nm1+m2.\nThe following is a product form guess for the limiting probabilities:\nπn1,n2,m1,m2=/parenleftbiggn1+n2\nn1/parenrightbigg\nρ1n1ρ2n2/parenleftbiggm1+m2\nm1/parenrightbigg\nρ3m1ρ4m2π0, (22.3)\nwhere ρ1=λ/μ 1,ρ2=λp/μ 2,ρ3=λ/μ 3,ρ4=λq/μ 4, andπ0is a short form for\nπ0,0,0,0.\nIt is easy to see that this guess satisﬁes the local balance equations ( Bi=B/prime\ni)f o r\ni=0,1,2,3,4using very similar algebra to what was used in the case of a single\nserver. The algebra is left to Exercise 22.2.\nWe now need to ﬁnd π0to determine the limiting probabilities. Let n=n1+n2, and\nm=m1+m2. Note that the load on the ﬁrst server, ρa,i sρa=ρ1+ρ2, and the load\non the second server, ρb,i sρb=ρ3+ρ4.S ow eh a v e\nP{njobs at server 1 ,mjobs at server 2 }\n=n/summationdisplay\nn1=0m/summationdisplay\nm1=0πn1,n−n1,m1,m−m1\n=π0n/summationdisplay\nn1=0/parenleftbiggn\nn1/parenrightbigg\nρ1n1ρ2n−n1m/summationdisplay\nm1=0/parenleftbiggm\nm1/parenrightbigg\nρ3m1ρ4m−m1\n=π0(ρ1+ρ2)n(ρ3+ρ4)m\n=π0ρanρbm.\nNow, using the fact that\n∞/summationdisplay\nn=0∞/summationdisplay\nm=0P{njobs at server 1,mjobs at server 2}=1,\nwe get\nπ0=( 1−ρa)(1−ρb).",2776
148-22.7 Readings.pdf,148-22.7 Readings,"22.6 network of ps servers with probabilistic routing 393\nFurthermore,\nP{njobs at server 1 }=∞/summationdisplay\nm=0π0ρanρbm=∞/summationdisplay\nm=0(1−ρa)(1−ρb)·ρanρbm\n=( 1−ρa)ρan\nand likewise\nP{mjobs at server 2 }=( 1−ρb)ρbm.\nThus,\nP{njobs at server 1 ,mjobs at server 2 }\n=ρan(1−ρa)ρbm(1−ρb)\n=P{njobs at server 1 }·P{mjobs at server 2 }.\nSo two M/G/1/PS servers in tandem have a product form solution, where the distribution\nof the number of jobs at each server again follows an M/M/1.\n22.6 Network of PS Servers with Probabilistic Routing\nGiven a network of PS servers, with Poisson outside arrivals, and general (Coxian)service times, we still have product form and the format of the product form looksexactly like it did for the case of Jackson networks with FCFS servers. Namely,\nP/braceleftbigg\nNumber of jobs at each queue is\n(n1,n2,...,n k)/bracerightbigg\n=k/productdisplay\ni=1P{nijobs at server i}\n=k/productdisplay\ni=1ρni\ni·(1−ρi)\nwhere ρi=λiE[Si].\nThe proof follows along the same lines as that in Section 22.5. Again, we say that a\nnetwork of PS servers exhibits the insensitivity property , because only the mean of the\njob size distribution is relevant.\nQuestion: Why don’t these nice product form results come up when we have a network\nof FCFS servers with Coxian service times? Why doesn’t the same analysis go through?\nAnswer: The state space and job behavior look very different for a network of FCFS\nservers than for a network of PS servers. In the case of PS servers, all jobs are inside\nthe gray bubble (representing the server) at all times, and all jobs move through thephases independently of each other (with the other jobs only affecting their rate). Inthe case of FCFS servers, only one job at a time can be processing within the gray\nbubble. The rest of the jobs are queued outside the bubble. The movement of jobs is\nthus very restricted. Generally, insensitivity arises in situations where there is no strictqueueing – jobs receive service right away, as in PS queues or an M/G/\n∞system.",2051
149-Chapter 23 The MG1 Queue and the Inspection Paradox.pdf,149-Chapter 23 The MG1 Queue and the Inspection Paradox,"394 networks with time-sharing (ps) servers (bcmp)\n22.7 Readings\nThe purpose of this chapter was to illustrate another application of the method of phases.\nWe saw that we could prove that the M/Cox/1/PS queue behaves like an M/M/1/FCFSqueue, and furthermore that a network of PS queues with Coxian service times and\nprobabilistic routing between queues has product form and can be decomposed into\nM/Cox/1/PS queues. These results and the further extension to classed networks areprovided in the original BCMP paper [ 16]. The BCMP result has also been rederived\nvia other techniques, see for example Harrison’s work [ 95].\nThe product form results described in this chapter have been extended by Frank Kelly\n[106] to networks of quasi-reversible queues , which allow for more general queueing\ndisciplines than PS or PLCFS. Some good references describing this broader class of\nproduct form networks are [ 127] and [ 38].\n22.8 Exercises\n22.1 M/BP/1/PS\nRecall Exercise 20.1, which asked you to simulate the M/G/1/FCFS queue,\nwhere Gwas a Bounded Pareto( k,p,α) distribution with mean 3,000. There\nwere two settings of parameters for the Bounded Pareto: (i) k=1,000,p=\n1010,α=1.5, and (ii) k=1,970,p=1 010,α=2.9. The arrival rate, λ,\nwas set to create a server load of ρ=0.8. Suppose now that you are asked to\nredo the experiment in Exercise 20.1 under PS scheduling. That is, you now\nneed to simulate an M/BP/1/PS queue, ﬁrst under α=1.5and then under\nα=2.9, with the goal of measuring mean response time. What do you expect\nthe mean response time to be in the two cases? Either ﬁgure it out analytically,\nor simulate it and ﬁnd out.\n22.2 Verifying Product Form Solution for Tandem Network of PS Servers\nIn Section 22.5, we considered a tandem network of PS servers. We made the\nfollowing “guess” for the limiting probabilities of this network:\nπn1,n2,m1,m2=/parenleftbiggn1+n2\nn1/parenrightbigg\nρ1n1ρ2n2/parenleftbiggm1+m2\nm1/parenrightbigg\nρ3m1ρ4m2π0,\nwhere ρ1=λ/μ 1,ρ2=λp/μ 2,ρ3=λ/μ 3,ρ4=λq/μ 4, andπ0is a short\nform for π0,0,0,0. This expression represents the probability that there are n1\njobs in phase 1 at server 1, and n2jobs in phase 2 at server 1, and m1jobs in\nphase 3 (this is phase 1 at server 2) and m2jobs in phase 4 (this is phase 2 at\nserver 2).\nProve that this guess satisﬁes the local balance equations: Bi=B/prime\nifori=\n0,1,2,3,4, as deﬁned in Section 22.5.",2415
150-23.2 The MG1 Queue and Its Analysis.pdf,150-23.2 The MG1 Queue and Its Analysis,"CHAPTER 23\nThe M/G/1 Queue and the\nInspection Paradox\nIn Chapter 22we studied the M/G/1/PS queue and derived simple closed-form solutions\nforπn,E[N], andE[T](assuming Gis any Coxian distribution).\nIn this chapter we move on to the M/G/1/FCFS queue. We have already had some\nexposure to thinking about the M/G/1/FCFS. Using the matrix-analytic techniques of\nChapter 21, we saw that we could solve the M/PH/1/FCFS queue numerically, where\nPH represents an arbitrary phase-type distribution. However, we still do not have a\nsimple closed-form solution for the M/G/1/FCFS that lets us understand the effect ofload and the job size variability on mean response time.\nThis chapter introduces a simple technique, known as the “tagged job” technique, which\nallows us to obtain a simple expression for mean response time in the M/G/1/FCFSqueue. The technique will not allow us to derive the variance of response time, nor willit help us understand the higher moments of the number of jobs in the M/G/1/FCFS –for those, we will need to wait until we get to transform analysis in Chapter 25.\nNonetheless, the resulting simple formula for mean response time will lead to many\ninsights about the M/G/1 queue and optimal system design for an M/G/1 system.\n23.1 The Inspection Paradox\nWe motivate this chapter by asking several questions. We will come back to these\nquestions repeatedly throughout the chapter. By the end of the chapter everything willbe clear.\nQuestion: Suppose buses arrive at a bus stop every 10 minutes on average, and the\ntime between arrivals at the bus stop is Exponentially distributed. I arrive at the bus\nstop at a random time. How long can I expect to wait for a bus?\nt\nEXCESSExp(10)1Exp(10)1Exp(10)1\nFigure 23.1. The Inspection Paradox.\n395\n396 the m/g/ 1queue and the inspection paradox\nQuestion: While you are thinking about the answer to the ﬁrst question, also ask\nyourself whether your answer changes if we change the distribution of the time between\nbuses (the mean time between buses is still 10 minutes). What is the range of possible\nanswers across all distributions?\nDeﬁnition 23.1 is associated with Figure 23.1.\nDeﬁnition 23.1 LetAdenote the time between bus arrivals. Let’s suppose a person\narrives at a random time. Then the time that person has to wait until the next bus is\ndenoted by the random variable Aeand is called the excess of A .\n23.2 The M/G/1 Queue and Its Analysis\nAn M/G/1 queue consists of a single server and queue with Poisson job arrivals, wherethe size (a.k.a. service time) of a job has a general distribution (see Figure 23.2). That\nis, the job service time, denoted by the random variable\nS, may follow any distribution,\nwhereE[S]=1/μ. First-Come-First-Served (FCFS) service order is assumed unless\notherwise stated.\nPoisson ( λ)FCFS\nGeneral service timeμ\nFigure 23.2. An M/G/1 queue.\nIn this chapter we study the tagged-job technique, in which we “tag” an arbitrary\narrival and reason about the time that the tagged arrival spends in the queue. We will\nneed the following notation:\nTQ: time in queue\nNQ: number in queue\nNA\nQ: number in queue as seen by the arrival\nS: service time of a job, where E[S]=1/μ\nSi: service time of the ithjob in the queue\nSe: excess of S – the remaining service time of the job in service, given that there is\nsome job in service.\nThe deﬁnition of Seis elucidated by Figure 23.3.\nWe now have\nE[TQ]=E[Unﬁnished work that an arrival witnesses in the system ]\n=E[Unﬁnished work in queue ]+E[Unﬁnished work at the server ]\n(Expectations add even if r.v.s are not independent.)\n23.2 the m/g/ 1queue and its analysis 397\n=E⎡\n⎣NA\nQ/summationdisplay\ni=1Si⎤⎦+E[\nUnﬁnished work at server ] (23.1)\n=E/bracketleftbig\nNA\nQ/bracketrightbig\n·E[S]+P{Arrival sees job in service }·E[Se] (23.2)\n=E[NQ]E[S]+( Time-avg probability server busy )·E[Se] (23.3)\n=E[NQ]·E[S]+ρ·E[Se] (23.4)\n=E[TQ]·λ·E[S]+ρ·E[Se]\n=E[TQ]·ρ+ρ·E[Se]\n=ρ\n1−ρ·E[Se].\nt\nS S S\nSe\nFigure 23.3. Given that there is a job in service (system is busy), a Poisson arrival sees Se\ntime remaining on the job in service.\nWe have thus easily obtained a formula for the mean time in queue in an M/G/1 system\n(a.k.a. mean delay), provided we can compute E[Se]where Seis the excess of the\nservice time S:\nE[TQ]=ρ\n1−ρ·E[Se] (23.5)\nQuestion: Why were we allowed to break up the expectation in ( 23.1) into a product\nof expectations?\nAnswer: TheSi,i=1,2,...,NA\nQ, are all independent of NA\nQ, because these jobs\nhave not run yet, and hence their size has not inﬂuenced the queueing time seen by the\ntagged arrival.\nQuestion: Where in the previous derivation have we used the fact that the arrival\nprocess is a Poisson process?\nAnswer: We invoked PASTA twice when moving from ( 23.2)t o(23.3). First, we used\nthe PASTA assumption in stating that\nP{Arrival sees a job in service }=Time-average probability the server is busy.\n398 the m/g/ 1queue and the inspection paradox\nSecond, we used PASTA in stating that\nE/bracketleftbig\nNA\nQ/bracketrightbig\n=E[NQ].\nWe will soon derive a general formula for E[Se], but ﬁrst it is instructive to go through\nsome examples:\nExamples\nrM/M/1 Queue: The service time, S, is Exponentially distributed with mean 1/μ.\nBecause the service time distribution is memoryless, E[Se]=1/μ. Therefore,\nE[TQ]=ρ\n1−ρ·1\nμ.\nThis agrees with our previous results for the M/M/1 queue.\nrM/D/1 Queue: The service time is Deterministic (constant) and equal to 1/μ.\nE[Se]=1\n2μ, because the remaining service time of a job in service is Uniformly\ndistributed between 0and1\nμ. Therefore,\nE[TQ]=ρ\n1−ρ·1\n2μ.\nNote that the expected time in queue is halfthat of the M/M/1 queue.\nrM/E k/1 Queue: The service time has an Erlang-k distribution (see Deﬁni-\ntion 21.2). The Ekdistribution consists of kstages in series, each with Ex-\nponential service time with mean 1/kμ. If there is a job in service at the time\nof an arrival, then it is equally likely that the job is at each of the kstages. On\naverage, the job in service will be at the middle stage, leaving/ceilingleftbigk+1\n2/ceilingrightbig\nstages left\nto be completed. We therefore should have\nE[Se]=/ceilingleftbiggk+1\n2/ceilingrightbigg\n·1\nkμ.\nMean time in queue is then given by\nE[TQ]=ρ\n1−ρ·/ceilingleftbiggk+1\n2/ceilingrightbigg\n·1\nkμ.\nObserve that for k=1 this is equal to the M/M/1 expression and for k→∞\nthis is equal to the M/D/1 expression.\nrM/H 2/1 Queue: The service time has a Hyperexponential distribution, H2,a si n\nDeﬁnition 21.3. Here it is not as obvious how to derive E[Se].\nTo compute E[Se]exactly, for any random variable S, we need to use the Renewal-\nReward theorem , which we describe in the next section.",6742
151-23.4 Applying Renewal-Reward to Get Expected Excess.pdf,151-23.4 Applying Renewal-Reward to Get Expected Excess,"23.3 renewal-reward theory 399\n23.3 Renewal-Reward Theory\nRenewal-Reward theory is a powerful technique that allows us to obtain time averages\nof many quantities by considering only the average over a single renewal cycle. Wecan then compute the time-average excess, which, by PASTA, is also the excess seen\nby a random Poisson arrival.\nWe start with a reminder of the deﬁnition of a renewal process and a reminder of the\nRenewal theorem. We then build up from there.\nDeﬁnition 23.2 (restated from Deﬁnition 9.32)Any process for which the times\nbetween events are i.i.d. r.v.s with a common distribution, F, is called a renewal\nprocess .\nFigure 23.4 illustrates a renewal process.\nEvents\ntime\nX2 X3 X1\nFigure 23.4. A renewal process. The Xi’s all have common distribution F.\nTheorem 23.3 (restated from Theorem 9.33)For a renewal process, if E[X]>0\nis the mean time between renewals (events), and N(t)is the number of renewals\n(events) by time t, then we have, with probability 1,\nN(t)\nt→1\nE[X]ast→∞. (23.6)\nNow consider a renewal process having i.i.d. interarrival times Xn,n≥1with dis-\ntribution Fand mean E[X], and suppose that each time a renewal occurs we receive\na reward. We denote by Rnthe reward earned over the course of the nthrenewal.\nWe shall assume that the Rn,n≥1, are i.i.d. with mean E[R]≥0.H o w e v e r ,w ed o\nallow for the possibility that the Rnmay (and often will) depend on Xn, the length of\nthenthrenewal interval. If we let R(t)represent the total reward earned by time t,\nthen\nN(t)/summationdisplay\nn=1Rn≤R(t)≤N(t)+1/summationdisplay\nn=1Rn.\n400 the m/g/ 1queue and the inspection paradox\nTheorem 23.4 (Renewal-Reward) If0≤E[R]<∞and0<E[X]<∞, then\nwith probability 1,\nR(t)\nt→E[R]\nE[X]ast→∞.\nQuestion: Interpret Theorem 23.4.\nAnswer: The Renewal-Reward theorem says that the average rate at which we earn\nreward is equal to the expected reward earned during a cycle, divided by the ex-\npected cycle length. This should make a lot of sense intuitively, because every cycle\nis probabilistically identical. The result is non-trivial, however, because normally it is\nmeaningless to just divide two expectations. Therein lies the power of the theorem.\nProof\nN(t)/summationdisplay\nn=1Rn≤R(t)≤N(t)/summationdisplay\nn=1Rn+RN(t)+1\n/summationtextN(t)\nn=1Rn\nt≤R(t)\nt≤/summationtextN(t)\nn=1Rn\nt+RN(t)+1\nt. (23.7)\nWe know that\n/summationtextN(t)\nn=1Rn\nN(t)−→E[R]ast→∞,w.p.1.(by SLLN )\nN(t)\nt−→1\nE[X]ast→∞,w.p.1.(by Theorem 23.3)\nCombining these, we have that\nlim\nt→∞/summationtextN(t)\nn=1Rn\nt= lim\nt→∞/summationtextN(t)\nn=1Rn\nN(t)·lim\nt→∞N(t)\nt=E[R]\nE[X]. (23.8)\nPutting together ( 23.8) and ( 23.7), we have that\nE[R]\nE[X]≤lim\nt→∞R(t)\nt≤E[R]\nE[X]+ lim\nt→∞RN(t)+1\nt.\nObserving thatRN(t)+1\nt→0ast→∞ , because rewards are ﬁnite, we have the desired\nresult.\n23.4 Applying Renewal-Reward to Get Expected Excess\nWe now apply Renewal-Reward theory to derive the expected excess. The deﬁnition of\nexcess presumes that the server is busy. We thus consider a renewal process consistingof a sequence of service times, each an instance of the r.v.\nS, as shown in Figure 23.5:\n23.4 applying renewal-reward to get expected excess 401\nt\nS S S\nFigure 23.5. Renewal occurs at the end of each service time.\nHere the server is assumed to be always busy, with a renewal occurring at the end of\neach service.\nFigure 23.6 illustrates the function Se(t), the excess at time t.\nt\nS S SSe(t)\nFigure 23.6. The function Se(t)represents the excess service time at time t.\nQuestion: How do we express E[Se]in terms of Se(t)?\nAnswer:\nE[Se]=Time-average Excess = lim\ns→∞/integraltexts\n0Se(t)dt\ns.\nTo compute E[Se], we need to express it as a long-run average award. Let R(s)denote\nthe total “reward” earned by time s.\nQuestion: What is R(s)for our problem?\nAnswer:\nR(s)=/integraldisplays\n0Se(t)dt.\nQuestion: So what is the time-average reward?\nAnswer:\nTime-average Reward = lim\ns→∞R(s)\ns= lim\ns→∞/integraltexts\n0Se(t)dt\ns=E[Se]\nNow, by Renewal-Reward theory, the time-average reward is equal to the reward earned\nduring one cycle divided by the expected length of one cycle.\nQuestion: What is a “cycle?”\nAnswer: A cycle is one service time.",4241
152-23.6 Back to the MG1 Queue.pdf,152-23.6 Back to the MG1 Queue,"402 the m/g/ 1queue and the inspection paradox\nNow we can use Renewal-Reward theory to determine the time-average reward, which\nis the same as the time-average excess:\nReward earned during a cycle =/integraldisplayS\n0(S−t)dt=S2−S2\n2=S2\n2\nE[Reward earned during a cycle ]=E[S2]\n2\nE[Length of one cycle ]=E[S]\nTime-avg Reward =E[Reward during cycle ]\nE[Cycle length ]=E[S2]\n2E[S]\nHence,\nE[Se]=E[S2]\n2E[S].\nThis derivation was a calculus-based argument, which is needed when the rewardfunction is a complex curve. For this particular problem, the following simple geometricargument sufﬁces: Looking at Figure 23.6, the reward earned during one cycle is just\nthe area under a triangle, where the height and base of the triangle have length\nS. Thus\nthe area is S2/2. Hence the expected reward earned during a cycle is E[S2]/2.N o w\nbecause the expected length of a cycle is E[S], we have, by Renewal-Reward, the\nresult that the time-average reward isE[S2]\n2E[S].\n23.5 Back to the Inspection Paradox\nWe now return to our buses question.\nQuestion: Suppose buses arrive at a bus stop every 10 minutes on average and the time\nbetween arrivals at the bus stop is Exponentially distributed. I arrive at the bus stop at\na random time. How long can I expect to wait for a bus?\nAnswer: Let r.v. Sdenote the time between arrivals of buses. Then the average time\nuntil the next bus is just the average excess, E[Se]; namely\nTime-average Excess =E[Se]=E[S2]\n2E[S]. (23.9)\nIfShas an Exponential distribution, then the above quantity is equal to E[S], namely\n10 minutes. If Shas a Deterministic (constant) distribution, then the above quantity\nis justE[S]/2, namely 5 minutes. If Shas very high variability, as in the Pareto\ndistribution, then the expected excess will be much higher thanE[S].\nThus far we have been interested in the “time until the next bus arrives.” We could also\nhave asked about the time since the last bus arrived. If Sdenotes the time between\nbuses, then the time since the last bus arrived is called the age of S .\n23.6 back to the m/g/ 1queue 403\nQuestion: What would you guess is the mean age of S?\nAnswer: The age of Shas the same mean and even the same distribution as Se, the\nexcess of S. To understand why, see Exercises 23.5 and23.11 , which are argued using\na Renewal-Reward argument.\nAdding the expected age and the expected excess, we see that a random arrival is likely\nto land in an interval where\nExpected time between buses as seen by arrival =E[S2]\n2E[S]+E[S2]\n2E[S]=E[S2]\nE[S].\nIfSis highly variable, this quantity can be far higher than E[S].\nQuestion: Is this just “Murphy’s Law,” or is there some reason why a random arrival\nis likely to experience a bigger-than-average time between buses?\nAnswer: If you think about the renewal process represented by the interarrival times\nbetween buses, you will see that some renewals are short and some are long. It is more\nlikely that a random arrival lands in a long interval than in a short interval. This iscalled the Inspection Paradox .\nWe can also express\nE[Se]in terms of the squared coefﬁcient of variation of S,C2\nS.\nRecalling that\nC2\nS=Var(S)\nE[S]2=E[S2]\nE[S]2−1,\nit follows that\nE[Se]=E[S2]\n2E[S]=E[S]\n2·E[S2]\nE[S]2=E[S]\n2·(C2\nS+1 ). (23.10)\nThis says that higher variability implies higher excess. In fact, observe that when\nC2\nS=1, we have that E[Se]=E[S], and for C2\nS/greatermuch1,E[Se]explodes. In practical\nterms, you arrive at the bus stop and ﬁnd that the time until the next bus is many times\nhigher than the mean time between buses.\nRemark: We refer to Seas the excess ofS, but this is also commonly referred to as\ntheequilibrium distribution ofS.\n23.6 Back to the M/G/1 Queue\nRecall that when analyzing the M/G/1/FCFS queue we proved equation ( 23.5), repeated\nbelow for reference:\nE[TQ]=ρ\n1−ρE[Se], (23.11)\nwhereE[Se]was deﬁned as the expected remaining service time on the job in service\nat the time of an arrival, given that there is a job in service.\n404 the m/g/ 1queue and the inspection paradox\nFrom ( 23.10 ), we know that\nE[Se]=E[S2]\n2E[S]=E[S]\n2·(C2\nS+1 ). (23.12)\nSubstituting ( 23.12 ) into ( 23.11 ), we get the Pollaczek-Khinchin (P-K) formula [ 141,\n107], written here in several equivalent forms:\nE[TQ]=ρ\n1−ρ·E[S2]\n2E[S](23.13)\nE[TQ]=ρ\n1−ρ·E[S]\n2·(C2\nS+1 ) (23.14)\nE[TQ]=λE[S2]\n2(1−ρ)(23.15)\nQuestion: Looking at ( 23.14 ), why does C2\nSplay such a key role in determining delay?\nAnswer: What causes delays is “bunching up of jobs.”\nrFor the D/D/1 queue, with arrival rate λand service rate μ>λ , there are no\ndelays, because arrivals see no one in service.\nrFor the M/D/1 queue, delays occur because arrivals sometimes “bunch up.”\nrFor the M/M/1 queue, “bunching up” is also created by occasional long service\ntimes. Thus the expected delay in M/M/1 is greater than that in M/D/1.\nrFor the M/G/1 queue, with highly variable job size, there is even more “bunchingup” of jobs.\nSo what creates delays is the occasional extra-long service time (or extra-large number\nof arrivals) in some service period. That is, delay is proportional to the variance in the\narrival andservice processes. Of course once one job is delayed, that affects all jobs\nin the queue behind it. The P-K formula assumes a Poisson arrival process, and the\nC2\nS\nrefers only to variability in the service times.\nVery Important Observation: Expected waiting time in an M/G/1 queue can be huge ,\neven under very low utilization, ρ,i fC2\nSis huge. For example, if ρ=0.5,E[S]=1 ,\nbutC2\nS=2 5 (which is not unusual, as pointed out in Chapter 20), thenE[TQ]=1 3 ,\nwhich is 13 times the mean job size, even though system load is low.\nFinal Remark: The result below follows from the transform of waiting time, which\nwe will derive in Chapter 26:\nVar(TQ)=(E[TQ])2+λE[S3]\n3(1−ρ)\nWhat is interesting here is that the second moment of delay depends on the third\nmoment of service time, similarly to the way that the ﬁrst moment of delay dependson the second moment of service time. In general the\nith moment of delay is related to\nthe (i+1)th moment of service time.",6155
153-23.7 Exercises.pdf,153-23.7 Exercises,"23.7 exercises 405\n23.7 Exercises\n23.1 M/H 2/1\nFor the M/H 2/1 queue with arrival rate λ, where the job sizes are speciﬁed in\nDeﬁnition 21.2, derive expressions for E[Excess] andE[TQ].\n23.2 M/G/1 – Doubling Service Rate and Arrival Rate\nJobs arrive to a CPU according to a Poisson process with rate λ. The CPU\nrequirement of each job is drawn from some general distribution G, with ﬁnite\nmoments. The CPU currently has load ρ=λ·E[S]<1, where Sdenotes\nthe CPU requirement of jobs. The current mean response time is denoted by\nE[Tcurrent]. Suppose that the arrival rate now increases by a factor of two.\nTo compensate, we buy a CPU that is twice as fast, so each job’s service\nrequirement on the new CPU is half what it was on the old CPU. Apply theP-K formula to determine the new mean response time and compare it withthe original mean response time.\n23.3 M/G/1 with Different Job Types\nConsider an M/G/1 queue that serves two types of jobs: red and blue. Red\njobs arrive according to a Poisson process with rate\nλR=1\n4jobs/sec, and blue\njobs arrive according to a Poisson process with rate λB=1\n2jobs/sec. Red job\nsizes have mean 1 and variance 1, whereas blue job sizes have mean 0.5 and\nvariance 1. All jobs arrive to the same FCFS queue, so that, at any time, the\nserver might be serving a red job or a blue one, and there might be jobs of one\nor both types in the queue. What is the mean response time of red jobs, and\nwhat is the mean response time of blue jobs?\n23.4 Understanding the Inspection Paradox\nImagine that there are two types of renewals: short renewals of length exactly\n1 and long renewals of length exactly 10. Suppose that short renewals occurwith probability\n2\n3and long renewals occur with probability1\n3.\n(a) What is the average length of a renewal?\n(b) What is the probability that a randomly thrown dart lands in a long renewal?\n(c) What is the expected length of a renewal that I see if I arrive at a random\ntime (use part (b))?\n(d) How does your answer to (c) compare with your answer to (a)? This\ndifference is the Inspection Paradox.\n23.5 Deriving the Expected Age\nLetAbe a random variable denoting the time between bus arrivals, with mean\nE[A]and second moment E[A2]. The time since the last bus arrival is called\ntheage of A and is denoted by Aa. Use Renewal-Reward theory to derive\nE[Aa], the mean age of A. Follow the approach given in this chapter, showing\nthe diagram of age across time. How does your answer compare with E[Ae],\nthe mean excess of A?\n23.6 Effect of Variability on Waiting Time in M/G/1\nConsider a single M/G/1 queue. Let the service time, S, follow a 2-point\ndistribution:\nS=/braceleftBigg\n0 with probability q\n1\n1−qwith probability 1−q\n406 the m/g/ 1queue and the inspection paradox\nObserve that as qgets close to 1, most jobs have service time 0.\n(a) Determine E[S], the expected service time. Is this affected by q?\n(b) Determine E[Se].\n(c) Determine C2\nS, the squared coefﬁcient of variation of the service time.\nWhat is the range of possible values of C2\nSas a function of q?\n(d) Now determine E[TQ], the mean waiting time for this system, as a function\nofq, assuming load ρ<1. Simplify your expression as much as you can\nso that it is in terms of qandρ. What happens in the system as qapproaches\n1? Give some intuition for what is going on.\n23.7 Application of Renewal Reward – M/G/1 Busy Period\nConsider an M/G/1 queue with arrival rate λand mean service time E[S].\nA busy period starts when the server becomes busy and ends when it goes\nidle. Determine the mean length of a busy period. Do notsolve this problem\nvia transforms or via conditioning on the job size: Use only Renewal-Reward,\nthinking about busy and idle periods. [Hint: The answer is very short (3 lines)if you see the trick for how to apply Renewal-Reward.]\n23.8 Application of Renewal-Reward – M/M/\n∞Busy Period\nRecall the M/M/ ∞system from Section 15.2: Jobs arrive according to a\nPoisson process with rate λ. Job sizes are Exponentially distributed with mean\n1\nμ. There are an inﬁnite number of servers, so that whenever a job arrives, it\nis given a new server. A busy period is deﬁned to be the time from when the\nM/M/∞ﬁrst becomes busy (a single job arrives) until the M/M/ ∞becomes\nidle. Derive the mean length of a busy period. [Hint: This is again a 3-line\nargument. It may help to recall that for the M/M/ ∞,πi=e−RRi\ni!, where\nR=λ\nμ.]\n23.9 Application of Renewal-Reward – Mean Time between Visits to a State in\na CTMC\nConsider the expected time between visits to state iin a CTMC. Use a Renewal-\nReward type argument to prove that\nE[Time between visits to state i]=1\nπi·1\nνi,\nwhere νiis the total rate of leaving state iin the CTMC, given that we are in\nstatei. (Note the difference between this result and that for a DTMC.)\n23.10 Semi-Markov Process\nConsider a stochastic process that moves between states according to sometransition probability matrix,\nP, where Pijrepresents the probability of next\nmoving to state jgiven that we are currently in state i. However, when the\nprocess is in state i, it stays there for some holding time, Hi, where the Hi’s are\ngenerally distributed random variables, from possibly different distributions.\nSuch a process is called a semi-Markov process. We will be interested in πSM\ni,\nthe stationary probability of being in state ifor the semi-Markov process.\nTo understand πSM\ni, it helps to consider πD\ni, the stationary probability for the\nembedded DTMC with the same transition matrix P, where one spends exactly\n23.7 exercises 407\ntime1in each state. The goal of the problem is to prove that\nπSM\ni=πD\ni·E[Hi]/summationtext\nkπD\nk·E[Hk]. (23.16)\n(a) Explain why ( 23.16 ) makes intuitive sense.\n(b) Consider a long period of time, consisting of nstate transitions. Let Ni(n)\ndenote the number of visits to state iduring these ntransitions. Pick n\nlarge enough, so that Ni(n)is large. Let H(j)\nidenote the time spent in\nstateiduring the jth visit to state i. Let\nf(n)=/summationtextNi(n)\nj=1H(j)\ni/summationtext\nk/summationtextNk(n)\nj=1H(j)\nk.\nWhat does f(n)represent?\n(c) Use tricks similar to those in the proof of Theorem 23.4 to reformulate\nf(n)so that it becomes the expression in ( 23.16 )a sn→∞ .\n23.11 Distribution of Excess\nConsider a renewal process where Xrepresents the time between renewals.\nF(x)andf(x)are the c.d.f. and p.d.f. for X, respectively. We use Xeto denote\nthe excess of X. Use Renewal-Reward to derive Fe(k)=P{Xe<k}.\n23.12 Server with Failures and Repairs\nConsider an M/G/1 queue, where at any time when the server is busy it can fail.\nThe time until the next failure is Exponentially distributed with rate α. Once the\nserver fails, it goes into repair mode. The repair time is a generally distributedrandom variable denoted by\nR. After the server is repaired, it continues serving\nthe job that it was serving from the point that it left off (i.e., no work is lost).\nAssume that the repair times are i.i.d. and are independent of the job sizes.\nCompute the mean response time of a job arriving to this M/G/1 queue. [Hint:\nThis problem is challenging. Exercise 11.6 and Theorem 3.34 may help.]",7229
154-Chapter 24 Task Assignment Policies for Server Farms.pdf,154-Chapter 24 Task Assignment Policies for Server Farms,"CHAPTER 24\nTask Assignment Policies\nfor Server Farms\nIn this chapter we revisit server farms, however this time in the context of high-\nvariability job sizes (indicative of the workloads described in Chapter 20), rather than\nExponential job sizes.\nThe server farm architecture is ubiquitous in computer systems. Rather than using a\nsingle, powerful server to handle all incoming requests (assuming such a beast caneven be purchased), it is more cost efﬁcient to buy many slow, inexpensive serversand pool them together to harness their combined computational power. The server\nfarm architecture is also popular for its ﬂexibility: It is easy to add servers when loadincreases and easy to take away servers when the load drops. The term server farm\nis used to connote the fact that the servers tend to be co-located, in the same room or\neven on one rack.\nThus far, we have primarily studied server farms with a central queue , as in the M/M/k\nsystem, which we initially examined in Chapter 14and then revisited from a capacity\nprovisioning perspective in Chapter 15. In the M/M/k, jobs are held in a central queue,\nand only when a server is free does it take on the job at the head of the queue.\nBy contrast, in computer systems, most server farms do immediate dispatching (also\nknown as task assignment ), whereby incoming jobs are immediately assigned to servers\n(also known as hosts ). There is typically no central queue; instead the queues are at the\nindividual hosts.Such server farms with immediate dispatching of jobs require an important policy\ndecision, known as the task assignment policy . This is the rule that is used by the\nfront-end router (also known as a dispatcher orload balancer ) to assign incoming\njobs to servers. For example, incoming jobs may be assigned to servers in round-robinorder, or each incoming job might be assigned to the server with the shortest queue.\nThe choice of task assignment policy hugely inﬂuences the response time of jobs atthe server farm, sometimes by orders of magnitude. Using the right task assignmentpolicy is particularly important when the job size distribution has high variability. Amajor question in computer systems design is ﬁnding a good task assignment policy tominimize mean response time (or some other performance variant).\nFigure 24.1 illustrates the server farm model that is the focus of this chapter. The high-\nspeed front-end router deploys the task assignment policy , which assigns incoming\njobs to hosts. Observe that the scheduling policy deployed at an individual host is not\nﬁxed, but is typically application dependent. For example, in web server farms, the\nservers are typically time-sharing servers, and each server “simultaneously” serves all\n408\ntask assignment policies for server farms 409\nSched uling Policy\nSched uling Policy\nSched uling PolicyHigh-speed\nRouterT ask Assi gnment Policy\nIncomin g \njobs\nFigure 24.1. Server farm model.\njobs in its queue; that is, each server deploys the PS scheduling policy. By contrast,\nin manufacturing systems and in many supercomputing settings, jobs are often non-preemptible, and each server serves one job at a time in FCFS order.\nThe goal of this chapter is to understand the performance of different task assignment\npolicies. The literature is so vast in this area that we can only hope to highlight someimportant results. Our goal throughout is to provide intuition. The readings noted in\nSection 24.4 contain greater depth.\nIn Section 24.1, we consider the case where jobs are non-preemptible and each server\nserves the jobs in its queue in FCFS order, as shown in Figure 24.2. In Section 24.2,\nwe assume that jobs are preemptible and each server serves the jobs in its queue inPS order, as shown in Figure 24.6. For each of the settings in Sections 24.1 and24.2,\nwe look for task assignment policies that minimize mean response time. To facilitateanalysis in these sections, we assume a Poisson arrival process. In Section 24.3,w e\nask more broadly how one could design optimal server farms in the case where jobsare preemptible and all design decisions are open (i.e., we can use any task assignmentpolicy and any scheduling policy at the servers). Throughout we assume that job\nFCFS\nFCFSFCFS\nHigh-speed\nRouterT ask Assi gnment Policy\nIncomin g \njobs\nFigure 24.2. Server farm model with FCFS scheduling at hosts.",4397
155-24.1 Task Assignment for FCFS Server Farms.pdf,155-24.1 Task Assignment for FCFS Server Farms,"410 task assignment policies for server farms\nsizes are drawn from a high-variability distribution, such as the Bounded Pareto from\nChapter 20, because such distributions reﬂect empirically measured job sizes.\n24.1 Task Assignment for FCFS Server Farms\nIn this section, we assume the server farm model as shown in Figure 24.2, with k\nservers. In particular, we assume that jobs are not preemptible and that each server\nprocesses jobs in its queue in FCFS order. For simplicity, we assume that servers are\nhomogeneous . We assume that job sizes are independently and identically distributed\naccording to some high-variability distribution, G, with mean1\nμ. We also assume that\njobs arrive according to a Poisson process with average rate λ. As usual, we denote the\nsystem utilization, ρ,b y\nρ=λ\nkμ,0≤ρ≤1\nand the resource requirement, R,b y\nR=λ\nμ=kρ, 0≤R≤k\nin accordance with Deﬁnition 14.4.\nThis model is common in manufacturing settings where it is often difﬁcult, if not\nimpossible, to preempt a job in progress. It is also common in supercomputing settings,where jobs are typically parallel computations, which makes them very difﬁcult topreempt.\nThere are many choices for task assignment policies under this model. Many policies\nare not analytically tractable. However, in some cases their performance can be ap-\nproximated. In others, even approximations are poor. Our discussion of these policiestherefore sometimes relies on empirical results.\nWe can divide task assignment policies into those that make use of knowing the size\n(service requirement) of an arrival and those that do not assume any knowledge of thesize of an arrival.\nQuestion: What are some examples of task assignment policies for Figure 24.2 that\ndo not assume any knowledge of the size of an arrival?\nAnswer: We list some common policies:\nUnder the RANDOM policy, each job is assigned to one of the\nkhosts with equal\nprobability. The aim of the RANDOM policy is to equalize the expected number of\njobs at each host.\nUnder the ROUND-ROBIN policy, jobs are assigned to hosts in a cyclical fashion\nwith the ith job being assigned to host number (imodk)+1 . This policy also aims\nto equalize the expected number of jobs at each host.\nUnder the JSQ (Join-the-Shortest-Queue) policy, each incoming job is assigned to\nthe host that has the shortest queue (the queue with the fewest number of jobs) at the\n24.1 task assignment for fcfs server farms 411\ntime when the job arrives. If several hosts have the same fewest number of jobs, then\nJSQ picks one of these hosts at random. This policy tries to equalize the instantaneousnumber of jobs at each host.\nAll three policies immediately dispatch jobs to hosts, where there is a queue of jobs at\neach host. Alternatively, we could instead imagine a single central queue (like in the\nM/M/k), where a host, when free, picks the job at the head of the queue to run. Because\nwe are assuming generally distributed i.i.d. job sizes, this architecture is referred to\nas the M/G/k . Note that, although the M/G/k is not strictly within our model because\nthere are not queues at the hosts, it still obeys the general framework of our model,because jobs are non-preemptible and the (single) queue is serviced in FCFS order,and we do not need to know job sizes. Thus we include M/G/k as one of our policies.\nQuestion: Which of these policies – RANDOM, ROUND-ROBIN, JSQ, or M/G/k –\nwould you guess has the lowest mean response time?Answer: We will discuss and compare the policies one at a time\n...but hold on to your\nguess.\nQuestion: Which do you think is superior: ROUND-ROBIN or RANDOM? Why?\nAnswer: It turns out that ROUND-ROBIN slightly outperforms RANDOM. To see why\nthis is so, observe that the arrival process into each queue under RANDOM is a Poisson\nprocess, by Poisson splitting. By contrast, the interarrival time into each queue under\nROUND-ROBIN is a sum of Exponentials – namely, an Erlang-k distribution – whichhas less variability than an Exponential. Hence, in RANDOM each queue behaves likean M/G/1, with average arrival rate\nλ/k, where Gis the job size distribution, whereas\nunder ROUND-ROBIN each queue behaves like an Ek/G/1, with average arrival rate\nλ/k. The lower variability of the Ek, compared to the M(Exponential), results in\nROUND-ROBIN having lower mean response time.\nComparing ROUND-ROBIN with JSQ is more difﬁcult, because for JSQ it is not\npossible to boil down the behavior of each queue to some simple G/G/1 queue. Theissue is that the arrival process into a given queue under JSQ depends on the state ofthe other queues. To precisely analyze JSQ, one would need a\nk-dimensional Markov\nchain that tracks the number of jobs in each of the kqueues. Unfortunately, no one\nknows how to analyze such a k-dimensional chain that grows unboundedly in all k\ndimensions. Even the case of just k=2 dimensions and Exponential service times\ndoes not yield a closed form, and, for higher k(k>2), only approximations exist (see\nSection 24.4 for details). Based on the approximations that are known, it seems clear\nthat JSQ is far superior to ROUND-ROBIN with respect to mean response time under\nhigher job size variability. In fact, for high-variability job size distributions, JSQ canlower mean response time by an order of magnitude compared to ROUND-ROBIN.\nQuestion: Intuitively, why does it make sense that JSQ should outperform ROUND-\nROBIN under higher job size variability?\nAnswer: JSQ balances the instantaneous number of jobs at each queue, whereas\nROUND-ROBIN balances the expected number of jobs. The difference is that JSQ\ncan react quickly. Imagine that all queues have 5 jobs, but there is a lot of variability\n412 task assignment policies for server farms\namong job sizes and one of the queues empties suddenly. JSQ can quickly remedy\nthe situation by sending the next 5 arrivals to that queue, whereas ROUND-ROBINwould have to wait for\nk/2more arrivals on average before even one job could be\nsent to the empty queue. During that period of waiting for k/2arrivals, the server\ncorresponding to the empty queue is not being utilized, increasing the load on all otherservers and increasing overall mean response time. When job size variability is high,queues can empty very suddenly. This is why the dynamic properties of JSQ are soimportant.\nDeﬁnition 24.1 Adynamic policy is one that adapts based on changes in the state\nof the system (e.g., the number of jobs at each queue), whereas a static policy is\noblivious to the changes in state.\nThus JSQ is dynamic , whereas ROUND-ROBIN is static .\nQuestion: How would you guess that JSQ compares with M/G/k under high job size\nvariability? Why?\nAnswer: Both M/G/k and JSQ are dynamic policies, and both are good at making sure\nthat no host is left idle. However M/G/k has a big additional advantage: It holds off onassigning jobs to hosts as long as possible. Observe that in JSQ it could happen thatall queues have 5 jobs, and suddenly one queue empties, creating a situation whereone server is unutilized. This underutilization can never happen under M/G/k, becausewhenever there are\n≥kjobs, every host is busy.\nEmpirical results show that M/G/k can outperform JSQ by an order of magnitude with\nrespect to mean response time when job size variability is high.\nNow suppose that we know the sizeof a job when it arrives. Clearly there are many\nmore task assignment policies possible if we know the job size. One obvious exampleis the LWL policy.\nUnder the LWL (Least-Work-Left) policy, each job goes to the queue where it will\nachieve the lowest possible response time. This is a greedy policy, because each job is\nacting in its own best interest. Speciﬁcally, each incoming job is assigned to the queuethat has the least total work at the time when the job arrives. Note that the work a jobsees ahead of it is exactly its waiting time. Unlike some of the policies we saw earlierthat aim to equalize the number of jobs at each host, the LWL policy aims to equalize\nthe total work at each host.\nThe LWL policy is exactly what we do when we go to the supermarket. We look at\neach line and count not the number of people (jobs) there, but rather we look at the\nnumber of items in each person’s basket (the job size) for every person in each line.We then join the line with the smallest total number of items (least work remaining).\nRecall that under JSQ we only look at the number of jobs in each queue in deciding\nwhere to route a job. When job size variability is high, the number of jobs in a queue\n24.1 task assignment for fcfs server farms 413\ncan be a poor estimate of the total work in that queue. In this sense LWL is far superior\nto JSQ.\nQuestion: How do LWL and M/G/k compare?\nAnswer: We will prove in Exercise 24.4 that LWL and M/G/k are actually equivalent,\n(i.e., LWL =M/G/k). Speciﬁcally, if both policies are fed the same arrival sequence\nof jobs, and ties are resolved in the same way in both systems, then it can be shown\nthat the same job goes to the same host at the same time under both policies. Observe\nthat when a job arrives to the M/G/k system, it may sit in the central queue for a while\nbefore being dispatched. However, the host that it will eventually go to is exactly thehost that had the least work in front of it under LWL.\nUnfortunately the analysis of M/G/k (and hence LWL) is a long-standing open problem\nin queueing theory. It is hard to imagine why the M/G/k is so hard to analyze, giventhat the M/M/k is so simple. Many young queueing theorists have devoted severalyears to beating their heads against the problem of analyzing the M/G/k system. Ofcourse, one can always replace the job size distribution\nGwith some phase-type\ndistribution, PH, and use matrix-analytic methods to solve the M/PH/k system (see\nExercise 21.7). Although this yields numerical solutions, it does not provide insight\ninto which properties of the job size distribution matter and how these properties affect\nthe solution. Also, even from a numerical standpoint, matrix-analytic solutions are nota panacea, because they can become very unstable (the matrices become near singular)when the distributions are highly skewed (e.g., when the squared coefﬁcient of variationof the job size distribution,\nC2, is very high).\nThe ﬁrst closed-form approximation for waiting time in an M/G/k was proposed by Lee\nand Longton [ 118] over a half-century ago; it says that the waiting time in an M/G/k is\nbasically the same as that in an M/M/k, but scaled up by a simple factor related to C2:\nE/bracketleftbig\nTM/G/k\nQ/bracketrightbig\n≈/parenleftbiggC2+1\n2/parenrightbigg\nE/bracketleftbig\nTM/M/k\nQ/bracketrightbig\n(24.1)\nMany other authors have also proposed closed-form approximations for mean delay\nin the M/G/k, all involving only the ﬁrst 2 moments of the job size distribution (seeSection 24.4). Unfortunately, any approximation of mean delay based on using only\nthe ﬁrst 2 moments is provably inaccurate for some job size distributions; in addition,\nthe inaccuracy of the approximation can be off by a factor proportional to\nC2[76].\nTable 24.1 (borrowed from [ 76]) illustrates why two moments of the job size distri-\nbution are insufﬁcient for predicting E[TQ]. The ﬁrst row of the table shows E[TQ]\nfor an M/G/10 with mean job size of 1 and C2=1 9 (ﬁrst column) or C2=9 9 (sec-\nond column) according to approximation ( 24.1). The remaining rows show various\ndistributions, all of which have been parameterized to have the same mean job size,\nE[S]=1 , and appropriate C2. As shown, the difference in E[TQ]across distributions\ncan be very high – E[TQ]differs by a factor of close to 2whenC2=1 9 and by a\nfactor of more than 3whenC2=9 9 .\n414 task assignment policies for server farms\nTable 24.1. Simulation results for the 95% conﬁdence intervals in an M/G/k,\nwithk=1 0 ,ρ=0.9, andE[S]=1\nE[TQ]forC2=1 9 E[TQ]forC2=9 9\n2-Moment Approximation ( 24.1) 6.6873 33.4366\nWeibull 6.0691±0.01 25 .9896±0.18\nBounded Pareto ( α=1.1) 5.5277±0.02 24 .6049±0.28\nLognormal 4.994±0.025 19 .543±0.42\nBounded Pareto ( α=1.3) 4.879±0.025 18 .774±0.36\nBounded Pareto ( α=1.5) 3.947±0.032 10 .649±0.54\nT h eﬁ r s tl i n es h o w s E/bracketleftbig\nTQ/bracketrightbig\nfor the 2-moment approximation given in ( 24.1). The remaining\nlines show various distributions with appropriate C2.\nTable 24.2 summarizes the task assignment policies that we have considered so far.\nThere is one more commonly employed policy shown in the table that also makes use\nof knowing the size of jobs, namely the SITA policy.\nTable 24.2. Examples of common task assignment policies\nRANDOM Each job is assigned to one of the khosts with equal probability.\nROUND-ROBIN The ith job is assigned to host (imodk)+1 .\nJSQ Each job is assigned to the host with the fewest number of jobs.\nLWL Each job is assigned to the host with the least total work.\nM/G/k When a server is free, it grabs the job at the head of the central queue.\nSITA Small jobs go to host 1, mediums to host 2, larges to host 3, etc.\nUnder the SITA (Size-Interval-Task-Assignment) policy [ 83], each host is assigned\nto a size interval, where the size intervals are non-overlapping and span the full range\nof possible job sizes. For example, the ﬁrst host is assigned only “small” jobs (thoseof size between\n0ands, for some s); the second host is assigned only “medium” jobs\n(those of size between sandm, for some m>s ); the third host is assigned only\n“large” jobs (those of size between mandl, for some l>m ), etc. Every incoming job\nis routed to the appropriate host based on its size.\nQuestion: What is the point of the SITA policy? Why does it make sense?\nAnswer: The SITA policy is similar to the “express lane” in your local supermarket,\nwhere one or two queues are reserved for “short” jobs only. When job size variability\nis high, there can be some very large jobs and some very small ones. By dedicatingcertain queues to short jobs only, we provide isolation for short jobs, so that they donot get stuck waiting behind long jobs.\nObserve that we have not fully speciﬁed the SITA policy, because we have not speciﬁed\nthe size cutoffs.\nQuestion: Under SITA, what size cutoffs make sense?\nAnswer: One might think that choosing cutoffs that balance expected load among the\nqueues makes sense. That is, we would choose\ns,mandlsuch that\n/integraldisplays\n0tf(t)dt=/integraldisplaym\nstf(t)dt=/integraldisplayl\nmtf(t)dt.\n24.1 task assignment for fcfs server farms 415\nHowever, it turns out that choosing the cutoffs to balance expected load can be very far\nfrom optimal. This point is explored in Exercise 24.6.\nFinding the optimal cutoff is very counterintuitive and often involves severely unbal-\nancing the load between the servers. For example, for a Bounded Pareto with α<1,\none wants to choose cutoffs that unbalance the load, favoring small jobs by underload-\ning the servers of small jobs, whereas for a Bounded Pareto with α>1, one wants to\nchoose cutoffs that unbalance the load, favoring large jobs by underloading the serversof large jobs [ 93,82]. In the case of just\nk=2 servers, the optimal cutoff can be ob-\ntained by search; however, the search becomes less feasible with more than 2servers.\nAs of the date of this book, the problem of ﬁnding closed-form cutoffs that minimize\nmean response time for general job size distributions is still wide open [ 93].\nQuestion: How can we analyze SITA given that we know the cutoffs?\nAnswer: Once we are given size cutoffs, the analysis of SITA (under a Poisson arrival\nprocess) is very straightforward. Because the size of the incoming job is drawn at\nrandom from the size distribution, G, we can view the splitting of jobs into queues as\nprobabilistic Poisson splitting of the arrival process. The ith queue can then be modeled\nas an M/G i/1 queue, where Girepresents the job size distribution of jobs arriving at\nqueue i. An example is provided in Exercise 24.1.\nQuestion: How does the performance of SITA and LWL =M/G/k compare?\nAnswer: This is a surprisingly difﬁcult question. Part of the problem, of course, is that\nneither SITA (with unknown cutoffs) nor LWL is analytically tractable in closed form.We start with some intuitions about each policy and then move on to what results existin the literature.\nOne advantage of the LWL policy over any other policy is that it is ideal at keeping\nservers utilized. This can be seen by viewing LWL as M/G/k. It is impossible under\nLWL for one server to have zero jobs while another server has a job queueing.\nOne advantage of the SITA policy is that it is ideally suited to reducing variability\nat each queue. Suppose that the original job size distribution,\nG, has high variability.\nUnder most policies, this same high variability is transferred to all the queues. This is\nproblematic because we know, from the P-K formula (Chapter 23), that queueing delay\nis directly proportional to the variability of the job size distribution. SITA speciﬁcally\ndivides up the job size distribution so that each queue sees only a portion of the domainof the original distribution, greatly decreasing the job size variability at each queue.Another way of putting this is that SITA provides short jobs protection from long jobs.\nBecause most jobs in computing-based systems are short jobs, and because long jobs\ncan be very, very long, isolating the many short jobs from long jobs greatly reduces\nmean response time.\nThe SITA policy and its variants have been part of the common wisdom for a long time\nand have been the focus of many papers (see Section 24.4 for references). Because of\nSITA’s beneﬁts in reducing job size variability, for a very long time it was believed\nthat SITA, or some SITA-like variant, was far superior to LWL\n=M/G/k with respect\n416 task assignment policies for server farms\nto mean response time when the job size variability was very high. Many papers\nspeciﬁcally compared the performance of SITA to LWL and found that as job sizevariability is increased , SITA becomes far superior to LWL.\nFigure 24.3 illustrates SITA’s superiority on a server farm with\nk=2 servers. The\njob size distribution shown is a Bounded Pareto ( k,p,α) with α=1.4. The resource\nrequirement is R=0.95, equivalent to ρ=0.95/2.C2is increased while holding\nE[S]ﬁxed by increasing the upper limit, p, while decreasing the lower limit, k. The\nSITA mean response times are computed analytically by ﬁrst numerically deriving theoptimal splitting cutoff. The LWL mean response times are not analytically tractable,\nso we use a (very loose) upper bound on LWL performance, given in [ 157]. Figure 24.3\nshows the effect on mean response time,\nE[T],a sC2is increased, under LWL and\nSITA. According to the ﬁgure, SITA is far superior to LWL. Although the results for\nLWL are loose, the trend of SITA’s superiority over LWL is in good agreement with\nsimulation results and those in earlier research papers.\n1001021041061080200040006000800010000\nC2E[T]\nSITA LWL\nFigure 24.3. Expected response time, E[T], for SITA and LWL versus C2in a 2-server system\nwith Bounded Pareto job size distribution with α=1.4and resource requirement R=0.95.\nTo more clearly illustrate SITA’s superiority, we consider a server farm, again with k=\n2servers, where this time R=1.8and the job size distribution is a Hyperexponential,\nH2, with unbalanced means (speciﬁcally Q=0.7fraction of the load is contained\nin one of the Hyperexponential branches). The advantage of using an H2is that\nwe can analytically solve for the (nearly) exact mean response time under LWL via\nmatrix-analytic methods, so that we do not have to use any upper bound. The H2also\nlends itself nicely to increasing C2while holding E[S]constant. Figure 24.4 clearly\nillustrates SITA’s superiority over LWL for this H2job size distribution.\nDespite comparisons such as those depicted in Figures 24.3 and24.4 which show that\nSITA outperforms LWL by orders of magnitude for high job size variability, a proof\nof SITA’s superiority over LWL never materialized. SITA itself is difﬁcult to analyze,\neven for Poisson arrivals, because in general there is no closed-form expression forthe optimal size cutoffs and for the resulting response time. Furthermore, LWL (whichis equivalent to M/G/k) is in general only approximable. Thus, many of the existingcomparisons have used simulation to assert their claims or have compared responsetime only under heavy-trafﬁc regimes.\n24.1 task assignment for fcfs server farms 417\n10010110210301020304050\nC2E[T]\nSITA LWL\nFigure 24.4. Expected response time, E[T], for SITA and LWL versus C2in a 2-server system\nwithR=1.8and job size distribution H2with unbalanced branches ( Q=0.7).\nIn 2009, a surprising result was proven, showing that the common wisdom is actually\nwrong [90]: There are cases where SITA is not superior to LWL under high C2, and\nin fact, SITA is provably unboundedly worse than LWL as C2→∞ in some regimes.\nAn example of such a regime is provided in Figure 24.5.\n10010510100200040006000800010000\nC2E[T]\nSITA\nLWL\nFigure 24.5. Expected response time, E[T], for SITA and LWL versus C2in a 2-server system\nwith Bounded Pareto job size distribution with α=1.6andR=0.95.\nFigure 24.5 considers a server farm identical to that of Figure 24.3, except that the\nBounded Pareto parameter αhas changed from α=1.4toα=1.6. As in the case of\nFigure 24.3, the mean response time for SITA is computed analytically, while we use\nan upper bound from [ 157] for the mean response time for LWL. This time, however,\nthe comparison between SITA and LWL looks very different. For lower C2, SITA still\nimproves on LWL; however, there is a crossover point, at sufﬁciently high C2, after\nwhich SITA’s response time diverges, whereas LWL’s response time converges. This\ncrossover point is actually at a much lower C2than it appears in the graph, because\nthe upper bound for LWL is loose.\nThis crossover point, after which SITA’s response time diverges but LWL’s response\ntime converges, was not observed in prior work (which mostly relies on simulation, nu-\nmerical methods, heavy-trafﬁc approximations or 2-moment M/G/2 approximations),possibly because the earlier literature did not consider the very high\nC2regions, thus\n(incorrectly) concluding that SITA is always superior to LWL.\n418 task assignment policies for server farms\nQuestion: But why would SITA be inferior to LWL under high job size variability?\nIsn’t SITA speciﬁcally designed to combat high variability?\nAnswer: Consider a server farm with two hosts, and the Bounded Pareto (k,p,α )job\nsize distribution from Figure 24.5 asp→∞ andC2→∞ . SITA needs to place its\nsize cutoff somewhere. If it places the size cutoff at any ﬁnite value, x, then the ﬁrst\nhost sees a job size distribution with ﬁnite variance (because sizes range from ktox);\nhowever, the second host sees a job size distribution with inﬁnite variance (because\nsizes range from xto∞,a sp→∞ ). Since mean response time is a weighted sum\nof the response time at the two hosts, the mean response time under SITA will tend toinﬁnity as\nC2→∞ . Note that we can instead make the cutoff, x, increase with p. This\nhowever, means that as p→∞ , the ﬁrst host experiences inﬁnite variability, which\nagain means that SITA has inﬁnite mean response time.\nBy contrast, under LWL performance is only bad if two big jobs arrive near to each\nother, blocking off both servers. But the probability of such a bad event can be verylow if the resource requirement is sufﬁciently light (e.g.,\nR<1with 2 servers). In this\ncase the second server is not really needed, and is thus available to serve shorter jobs\nif one server gets blocked with a long job.\nIn general, for a system with kservers, we deﬁne the number of spare servers as\nNumber spare servers =k−⌈R⌉.\nThese spare servers can be extremely effective in combating variability. Even if C2\nfor the job size distribution approaches inﬁnity, the spare servers can be used to let the\nsmaller jobs have a “freeway” so that they do not get stuck behind large jobs, allowing\nthe response time of LWL to converge.\nOne might think that SITA could similarly beneﬁt from spare servers, but the strict\nrouting in SITA makes it unable to enjoy this beneﬁt.\nQuestion: But why was there a difference between the Bounded Pareto with α=1.4,\nshown in Figure 24.3, and the Bounded Pareto with α=1.6, shown in Figure 24.5,\ngiven that both cases were run with one spare server?\nAnswer: The Bounded Pareto with α=1.4has a fatter tail, implying there are more\nmedium and large jobs. This increases the probability of a “bad event” where two\nlarge jobs arrive at near the same time. It turns out that in this case one spare server is\ninsufﬁcient for LWL. The difference is captured more precisely in the 3/2moment of\nthe job size distribution. Observe that E/bracketleftbig\nS3\n2/bracketrightbig\nis inﬁnite for α=1.4, whereas E/bracketleftbig\nS3\n2/bracketrightbig\nis ﬁnite for α=1.6. Theorem 24.2 explains that the 3/2moment of Sis crucial in\nunderstanding the response time of the M/G/2 (LWL).\nTheorem 24.2 [155,156,157,158] For (almost) all job size distributions with r.v.\nS, the mean response time of the M/G/2 is bounded (ﬁnite) if and only if E/bracketleftbig\nS3\n2/bracketrightbig\nis\nﬁnite and there is at least one spare server.\nAlthough we do not have space to prove this theorem, in Section 24.4 we elaborate\non generalizations of the result to k>2servers. Note that this stability result is very",25640
156-24.2 Task Assignment for PS Server Farms.pdf,156-24.2 Task Assignment for PS Server Farms,"24.2 task assignment for ps server farms 419\ndifferent from an M/G/1, whose mean response time is ﬁnite if and only if E[S2]is\nﬁnite.\nSummary\nThis section has dealt with ﬁnding task assignment policies for server farms in the\ncase where jobs are not preemptible and job size variability is high. Our discussion\ncovers only the highlights of a vast body of literature in the area. The main pointis that task assignment is non-obvious and can be counterintuitive. Many common,well-known policies, such as RANDOM, ROUND-ROBIN, and JSQ, are virtuallyworthless when job size variability is high. Furthermore, it is difﬁcult to rank the\npolicies: As we have seen, sometimes SITA can be farsuperior to LWL, and sometimes\nthe reverse is true. Even a seemingly innocuous and obvious goal like “load balancing”is questionable, because SITA can perform far better when the load across servers ispurposely unbalanced. Finally, the analysis of task assignment policies is often verydifﬁcult and is still in its infancy. We have collected some important references inSection 24.4.\nQuestion: So far we have only considered the case of high job size variability. Suppose\nthat instead the job size variability is very low. How do the policies that we haveconsidered compare in this situation?\nAnswer: When job sizes are Deterministic (e.g., all jobs have size\n1), the ROUND-\nROBIN policy is optimal, because the arrivals to a server are maximally spaced out;\nin fact, if job sizes and interarrival times are both Deterministic, then no job will bedelayed under ROUND-ROBIN, assuming that the system is not in overload. The JSQ\npolicy will actually end up doing the same thing as ROUND-ROBIN, because the\nshortest queue will be that which has not received a new job in the longest time. By thesame logic, LWL will end up doing the same thing as ROUND-ROBIN. In contrast,\nRANDOM will sometimes make the “mistake” of sending two consecutive arrivalsto the same queue, incurring some delay. SITA will reduce to RANDOM, becauseall jobs have the same size. Even with occasional mistakes by RANDOM, we expectmean response time to be very low. To see this, consider the case of RANDOM withDeterministic job sizes and Poisson arrivals. By Poisson splitting, each queue becomesan M/D/1 queue, which we know has only half the delay of an M/M/1.\n24.2 Task Assignment for PS Server Farms\nWe now turn to a very different model of a server farm. Figure 24.6 depicts a queueing\nmodel of a web server farm. Here the incoming requests are HTTP requests. These must\nbe immediately dispatched to one of the server hosts, because they are connections thatneed immediate attention. Requests are fully preemptible in that any request can bestopped and restarted where we left off. Given that this is a network-based application,\nrunning on TCP, it is important that the service seem immediate and constant. Forthis reason, we cannot have requests waiting in a FCFS queue. Instead, each host\n420 task assignment policies for server farms\ntime-shares among all the requests in its queue, so that each HTTP request receives\n“constant” service. This scheduling is modeled as Processor-Sharing (PS).\nPS\nPS\nPSHigh-speed\nRouterT ask Assi gnment Policy\nIncomin g \njobs\nFigure 24.6. Server farm model with PS scheduling at hosts.\nThere are many common high-speed routers used for dispatching HTTP requests in\na web server farm. Some examples are Cisco’s LocalDirector [ 42], IBM’s Network\nDispatcher [ 140], and F5’s BIG-IP [ 21]. The job size distribution for websites is known\nto be highly variable and heavy-tailed [ 47,48]. To ease the analysis, we assume that\nthe arrival process is a Poisson process with average rate λand that job sizes are i.i.d.\nAssuming a Poisson arrival process is not necessarily unrealistic, particularly if the\narrival process is the merge of many disparate users. However, our assumptions that\njob sizes are independent of each other and independent of the interarrival times are not\ntrue in practice, as pointed out in several papers, [ 70,47,169]. As before, we assume k\nidentical servers and use Sto denote the job size, where E[S]=1\nμ. The system load\nis denoted by ρ=λ\nkμand the resource requirement by R=λ\nμ.\nGiven the huge prevalence of web server farms, it is important to consider what task\nassignment policies are best for the PS server farm model and how they compare. We\nagain consider the policies in Table 24.2; all except for the M/G/k (which by deﬁnition\nuses a FCFS queue) are reasonable options for a PS server farm. Let’s see how thesecompare.\nQuestion: Consider ﬁrst the RANDOM policy and the SITA policy. Recall that for\nthe FCFS server farm, the SITA policy was far superior to RANDOM when the job\nsize distribution was highly variable. How do these policies compare for the PS serverfarm, again assuming high job size variability?\nHint: Analyzing SITA of course depends on the size cutoffs. It turns out that, in\ncontrast to FCFS server farms, the optimal size cutoffs for PS server farms are those\nthatbalance load between the servers (see Exercise 24.2). Thus the load at every server\nis\nρ, just like the overall system load. It is therefore easiest to express the response time\nof each policy in terms of ρ.\nHint: Both RANDOM and SITA experience Poisson splitting, because the size cutoffs\nin SITA can be viewed as sending a fraction, pi, of jobs to server i.\nAnswer: For RANDOM, we note that an arrival goes to a random queue with load ρ\nand arrival rate λ/k. By Poisson splitting, this random queue is an M/G/1/PS queue,\n24.2 task assignment for ps server farms 421\nbut the mean response time for M/G/1/PS is the same as that of M/M/1/FCFS (see\nChapter 22). Thus, the random arrival goes to a queue with (on average)ρ\n1−ρjobs. By\nLittle’s Law, its response time at this queue is then\nE[T]RANDOM=1\nλ/k·ρ\n1−ρ=k\nλ·ρ\n1−ρ.\nFor SITA, WLOG assume that the job size distribution ranges from 0to∞and that\nthe size cutoffs are s1,s2,...s k−1, where jobs in the interval (0,s1)go to host 1, jobs\nof size (si−1,si)go to host i, and jobs of size (sk−1,∞)go to host k. The fraction of\njobs that go to host iispiwhere pi=/integraltextsi\nsi−1f(t)dt, where f(t)is the density of the\njob size distribution. The load at queue iisρ(see the ﬁrst hint). By Poisson splitting,\nqueue iis an M/G/1/PS queue (see second hint). The arrival rate into queue iisλi,\nwhere λi=λpi. Putting these facts together we have\nE[T|job goes to host i]SITA=1\nλi·ρ\n1−ρ.\nE[T]SITA=k/summationdisplay\ni=1pi·E[T|job goes to host i]\n=k/summationdisplay\ni=1pi·1\nλi·ρ\n1−ρ\n=k/summationdisplay\ni=11\nλ·ρ\n1−ρ\n=k\nλ·ρ\n1−ρ.\nThus we have that\nE[T]RANDOM=E[T]SITA. (24.2)\nThe fact that RANDOM and SITA have the same mean response time (for server\nfarms with PS servers) might be surprising, because these policies yield very different\nperformance for FCFS servers. The reason that RANDOM and SITA were so differentfor server farms with FCFS servers is that RANDOM does nothing to reduce job sizevariability, whereas SITA does a lot to reduce variability. However, PS scheduling isinvariant to job size variability, and hence the beneﬁt of SITA in reducing job size\nvariability is superﬂuous.\nQuestion: For server farms with PS servers, which is better: JSQ or LWL? Which was\nbetter for server farms with FCFS servers?\nAnswer: Recall that for the case of server farms with FCFS servers, LWL was superior\nto JSQ. For FCFS servers, LWL represented the greedy policy, whereby each job was\nrouted to the host where it would itself experience the lowest response time, namely\nthe host with the least total work.\nFor the case of PS servers, JSQ represents the greedy policy that routes jobs to the host\nwhere it will likely experience the lowest response time. Speciﬁcally, under JSQ, each\njob is routed to the host where it will time-share with the fewest jobs. By contrast,\n422 task assignment policies for server farms\nknowing the total work at a PS host does not necessarily have any bearing on the job’s\nresponse time at that host.\nUnfortunately, analyzing JSQ is no easier for a PS server farm than for a FCFS\nserver farm, even when the job size distribution is Exponential. Modeling JSQ requirestracking the number of jobs at each queue, so that we can determine to which host anarrival should be routed. But tracking the number of jobs in each queue necessitates a\nstate space that grows unboundedly in\nkdimensions (one for each queue), making it\nintractable. The problem is only ampliﬁed for LWL where we need to track the total\nwork at each queue.\nOne idea for analyzing JSQ in a PS server farm is to approximate the dependence\nbetween the queues while only tracking what is going on in a single oneof the k\nqueues, WLOG queue 1 [ 79]. The dependence is captured by making the arrival rate\ninto queue 1 be dependent on the number of jobs at queue 1. For example, the average\narrival rate into queue 1 should be λ/k. However, if queue 1 currently has 0jobs, then\nthe arrival rate into queue 1 should be greater than λ/k, because it is likely that the other\nqueues have more jobs than queue 1. Likewise, if queue 1 currently has many jobs, thenthe arrival rate into queue 1 will be less than\nλ/k, because the other queues likely have\nfewer jobs. By deriving the correct load-dependent arrival rate into queue 1, one canapproximate the inﬂuence of the other\nk−1queues on queue 1. Finally, since queue 1\nwas chosen WLOG, the delay experienced by an arrival to queue 1 is the system delay.\nA recent ﬁnding is that JSQ is surprisingly (nearly) insensitive to job size variability\nfor PS server farms [ 79]. At ﬁrst, this may seem to follow from the insensitivity of the\nM/G/1/PS queue. However, there is more to it than that, because LWL, as we will soon\nsee, is not at all insensitive to job size variability for PS server farms. A proof of thenear insensitivity of JSQ has not yet been found, as of the time of writing of this book.\nFigure 24.7 shows simulation results for the performance of all the task assign-\nment policies we have considered over a range of job size distributions, described in\nDet\nExp\nBim−1\nBim−2Weib−1\nWeib−2E[N]\n56789\nJSQLWLROUND−ROBIN\nOPT−0RANDOM = SITA\nFigure 24.7. Simulation results for a server farm with two PS hosts, under different task as-\nsignment policies. The x-axis shows a variety of job size distributions (described in Table 24.3)\nin order of increasing variability from left to right. The y-axis depicts the mean number of jobs\nper host of the server farm, under each job size distribution. The server farm load is ρ=0.9.\n24.2 task assignment for ps server farms 423\nTable 24.3. Job size distributions, each with mean 2, but increasing\nvariance from top to bottom\nDistribution Mean Variance\nDeterministic: point mass at 2 20\nErlang-2: sum of two Exp (1)random variables 2 2\nExponential: Exp (0.5)random variable 2 4\nBimodal-1:/braceleftbigg\n1w.p.0.9\n11w.p.0.129\nWeibull-1: (shape parameter 0.5, scale parameter 1)2 2 0\nWeibull-2: (shape parameter1\n3, scale parameter1\n3)2 7 6\nBimodal-2:/braceleftbigg\n1 w.p.0.99\n101 w.p.0.0129 9\nTable 24.3.1Each distribution has mean 2, but the distributions have increasing vari-\nance, ranging from a variance of 0for the Deterministic distribution to a variance of\n99 for the Bimodal-2 distribution. As we consider distributions with higher and higher\nvariance, we see that the performance of ROUND-ROBIN and LWL both deteriorate.By contrast, the performance of SITA, RANDOM, and JSQ appear insensitive to thejob size variability (JSQ is not actually insensitive, because there is a 1% variation, not\nvisible by eye). The JSQ policy is clearly the best of the policies we have consideredthus far.\nTo gauge the optimality of JSQ, we also compare policies against the OPT-0 policy.\nThe OPT-0 policy, introduced in [ 25], assigns each incoming job so as to minimize\nthe mean response time for all jobs currently in the system, assuming that there are\n0\nfuture arrivals . Note that we are not being greedy from the perspective of the incoming\njob, but rather trying to minimize across all the jobs in the system. This policy is\nfollowed for each successive incoming arrival. Although the JSQ policy is far simpler\nthan OPT-0, its performance is within about 5% of OPT-0, for all job size distributions\nin the table. Thus the JSQ policy appears to be near optimal.\nSummary\nThis section has dealt with ﬁnding task assignment policies for server farms in the case\nwhere jobs are preemptible, the scheduling at the servers is PS, and job size variability ishigh. Unlike the previous section that dealt with FCFS scheduling at the servers, there ispresently very little literature on this topic, see [ 6], [79], and [ 101], probably because the\noperations research community deals far less with PS servers than with FCFS servers.\nThe main point of this section is that task assignment is very different for server farms\ncomposed of PS servers as compared to FCFS servers. Whereas JSQ is a pretty badpolicy for server farms of FCFS servers, because of its ineffectiveness in alleviatingdelays created by high job size variability, JSQ is an excellent policy for server farmsof PS servers. Similarly, SITA, a top performer for server farms with FCFS servers, is\n1The Weibull distribution has p.d.f. f(t)=α\nλ/parenleftbigt\nλ/parenrightbigα−1e−(t\nλ)α\n,f o rt>0,w h e r e α>0is called the shape\nparameter and λ>0is called the scale parameter; see [ 181]. The parameters that we chose in the table result\nin heavy-tailed distributions.",13643
157-24.3 Optimal Server Farm Design.pdf,157-24.3 Optimal Server Farm Design,"424 task assignment policies for server farms\namong the worst performers for server farms with PS servers. Under server farms of\nPS servers, job size variability is not a big problem, and some policies, like JSQ, arenearly insensitive to job size variability.\nThe analysis of server farms with PS servers is a wide open area, full of open problems.\nFor example, we did not even discuss the very interesting problem of task assignmentpolicies for the case of heterogeneous servers.\n24.3 Optimal Server Farm Design\nWe now turn to the more theoretical question of how to optimally design a server farm\nif one is allowed to choose both the task assignment policy and the scheduling policy at\nthe individual hosts; both these decisions are shown in Figure 24.1. This is a theoretical\nquestion, because typically the scheduling policy at the individual hosts is dictated by\nthe operating system at the servers and the application. To give ourselves maximumﬂexibility, we further assume that jobs are fully preemptible and that we know a job’ssize when it arrives (of course we do not know future jobs). Finally, we allow ourselvesthe ﬂexibility of having a central queue at the router, if we want one. As usual, weassume a job size distribution with high variability, mean job size\nE[S], and a Poisson\narrival process with average rate λ.\nUnfortunately, there exists almost no stochastic analysis in the area of optimal server\nfarm design. All the work in the area of optimal server farm design deals with worst-\ncase analysis and competitive ratios. In worst-case analysis , one is no longer looking\nat the performance of a policy, P, under a Poisson arrival process with i.i.d. job sizes\ntaken from some distribution, as we have been assuming. Instead, one imagines an\nadversary who can generate any arrival sequence, where the arrival sequence consists\nof arrival times of jobs and their sizes. The policy Pis now evaluated on each possible\narrival sequence and is compared with the optimal policy for that arrival sequence.\nSpeciﬁcally, we imagine some algorithm OPT that behaves optimally on each arrival\nsequence. We do not know what OPT looks like, and it does not have to be consistent\nacross arrival sequences (that is, OPT can follow a different algorithm on each arrivalsequence); we just use OPT to denote the best possible solution for everyarrival sequence. Now consider the whole space of possible arrival sequences. Foreach arrival sequence,\nA, consider the following ratio:\nrP(A)=E[T(A)]P\nE[T(A)]OPT,\nwhereE[T(A)]Pis the expected response time of policy Pon arrival sequence A.\nThen the competitive ratio of policyPis deﬁned as\nCompetitive ratio of P=m a x\nArP(A).\nIn worst-case analysis, the higher the competitive ratio of a policy, the “worse” that\npolicy is. Note that a policy Pcan have a high competitive ratio even if it performs\npoorly on just a single arrival sequence.\n24.3 optimal server farm design 425\nWorst-case analysis can yield a very different ranking of policies than that obtained by\nthe stochastic analysis described in most of this book. A policy Pcan be viewed as very\npoor in a worst-case sense, because it performs badly on one particular arrival sequence,\nbut that arrival sequence can be a very low-probability event in a stochastic sense.\nQuestion: Returning to the question of optimal server farm design, what are good\nrouting/scheduling policy choices?\nHint: For the case of a single queue, with fully preemptible jobs, where we know the\nsize of the job, what is the best scheduling policy on every arrival sequence?\nAnswer: In Exercise 2.3, we proved that the SRPT policy, which always (preemptively)\nruns that job with the shortest remaining processing time, is optimal with respect to\nmean response time, for the case of a single queue. This result was originally provedin [159] and holds under any arrival sequence of job sizes and arrival times.\nThe optimality of SRPT for a single queue inspires the server farm conﬁguration shown\nin Figure 24.8. It is like an M/G/k, except that the central queue is served in SRPT order.\nSpeciﬁcally, the\nkhosts are always serving those kjobs with the currently shortest\nremaining processing times. Suppose, WLOG, that server iis working on a job with\nremaining processing requirement ri, where ri>rj, for all active servers j. Then, if\na job comes in with shorter remaining time than ri, that arrival is immediately put into\nservice at the ith server, and the prior job being served at the ith server is put back into\nthe queue. We refer to this as the Central-Queue-SRPT policy.\nSRPT\nIncomin g\njobs\nFigure 24.8. Server farm with Central-Queue-SRPT policy.\nThe Central-Queue-SRPT policy looks very good. Because at every moment of time\nthekjobs with shortest remaining processing time are those in service, the server farm\nbehaves very much like a single queue with a server that is ktimes the speed.\nQuestion: Is Central-Queue-SRPT optimal in the worst-case sense? That is, does\nCentral-Queue-SRPT minimize E[T]on every arrival sequence?\nAnswer: Sadly, the answer is no. The following is an example of a “bad” arrival\nsequence, for the case of a 2-server system, where Central-Queue-SRPT does not\nproduce the minimal mean response time. This is adapted from [ 119]:\nrAt time 0, 2 jobs of size 29arrive, as well as 1 job of size 210.\nrAt time 210, 2 jobs of size 28arrive, as well as 1 job of size 29.\nrAt time 210+29, 2 jobs of size 27arrive, as well as 1 job of size 28.\nrAt time 210+29+28, 2 jobs of size 26arrive, as well as 1 job of size 27.\nrA n ds of o r t h ...\n426 task assignment policies for server farms\nLet’s name our two servers, server A and server B. The optimal algorithm, at time 0,\nwill run the 2 jobs of size 29on server A and will simultaneously run the job of size 210\non server B. By time 210, all work that arrived at time 0will be complete. At time 210,\nthe optimal algorithm will run the 2 jobs of size 28on server A and will simultaneously\nrun the job of size 29on server B, and so forth. The point is that the optimal algorithm\nis always able to pack the jobs in such a way that the servers are both fully utilized at\nall times.\nBy contrast, Central-Queue-SRPT makes a mess of this arrival sequence. At time 0,i t\ntries to run one of the jobs of size 29on server A and the other job of size 29on server\nB, because these are the jobs with smallest remaining time. Only when these complete\ndoes Central-Queue-SRPT start to run the job of size 210, leaving one of the servers idle.\nUnfortunately, this does not leave enough time to complete the job of size 210, which\nmust be preempted at time 210when the next batch of jobs comes in. Central-Queue-\nSRPT continues its mistakes, by now running one of the jobs of size 28on server A and\nthe other job of size 28on server B. Only when these complete does it start to run the job\nof size 29. Unfortunately, there is not enough time for the job of size 29to complete be-\nfore the new batch of jobs arrive, etc. Central-Queue-SRPT packs the jobs badly, so that\nthe two servers are not both fully utilized; hence, resources are wasted and jobs do not\ncomplete.\nAlthough the Central-Queue-SRPT algorithm performs particularly badly on this ar-\nrival sequence, Leonardi and Raz [ 119] prove that it is still the best possible online\nalgorithm from a worst-case competitive-ratio perspective. It is shown in [ 119] that\nthe competitive ratio of Central-Queue-SRPT is proportional to log/parenleftbigb\ns/parenrightbig\n, where bis\nthe biggest job size possible and sis the smallest job size possible, and that no online\nalgorithm can improve on this competitive ratio by more than a constant multiplicative\nfactor.\nIt is important to note that, although the Central-Queue-SRPT algorithm is not optimal\nin a worst-case sense, that does not mean that it is not optimal in a stochastic sense.\nFor example, it might be the best possible policy given a Poisson arrival process\nand i.i.d. job sizes from any general distribution. Unfortunately, we do not knowthe answer to this question, because no one to date has been able to analyze theCentral-Queue-SRPT policy from a stochastic perspective, even under a Poisson arrivalprocess and Exponentially distributed job sizes. The closest approximation to this\nis [89], which analyzes an M/PH/k queue with an arbitrary number of preemptive\npriority classes, where jobs are prioritized in order of shortest expected remaining\ntime. Unfortunately, the results in [ 89] are numerical in form; no closed-form analysis\nexists. Analyzing Central-Queue-SRPT stochastically is an important open problem inqueueing.\nA related open problem is the question of optimal task assignment under the restriction\nthat jobs need to be immediately dispatched to hosts, meaning that they cannot be\nheld in a central queue. This restriction is of practical importance, because, in manyapplications, like web servers, the request needs to be assigned to a host that can\nimmediately establish a connection with the client. In the case where jobs need to be\n24.3 optimal server farm design 427\nimmediately assigned to hosts, it is optimal to run SRPT scheduling at the individual\nhosts.2Thus we have the architecture shown in Figure 24.9.\nSRPT\nSRPT\nSRPTHigh-speed\nRouterT ask Assi gnment Policy\nIncomin g \njobs\nFigure 24.9. Server farm with immediate dispatch and SRPT scheduling at the hosts.\nQuestion: Given SRPT scheduling at the individual hosts as in Figure 24.9, what is\na good (immediate dispatch) task assignment policy for minimizing mean responsetime?\nHint: SRPT is very effective at getting short jobs out.\nAnswer: Simple RANDOM task assignment is not a bad policy here, because each\nqueue then looks like an M/G/1/SRPT queue with arrival rate\nλ/k and mean job size\nE[S]. The idea proposed independently by [ 9] and by [ 49] is to go a step further and\nmake sure that the short jobs are spread out over all the SRPT servers, so that the\nservers can each be working on getting as many short jobs out as possible. Speciﬁ-\ncally, the IMD algorithm in [ 9] divides jobs into size classes (small, medium, large,\netc.) and then assigns each incoming job to the server with the smallest number of\njobs in that size class. The point is to make sure that each server has some smalls,some mediums, and some larges, so that their SRPT scheduling can be maximallyeffective.\nAvrahami and Azar [ 9] prove that when the server farm in Figure 24.9 is run with\nthe IMD task assignment policy, the performance is on the order of that achieved by\nCentral-Queue-SRPT in a worst-case sense, meaning that the two algorithms result incompetitive ratios within a constant factor of each other. An exact stochastic analysisof IMD is not known, although an approximation is given in [ 49].\nSummary\nThis section has looked at server farm conﬁgurations using “optimal” task assignment/\nscheduling policy pairings. Almost all the available analysis is worst-case analysis.\n2Using proof by contradiction, one can argue that not running SRPT scheduling at the host will only increase\nmean response time.",11187
158-24.4 Readings and Further Follow-up.pdf,158-24.4 Readings and Further Follow-up,"428 task assignment policies for server farms\nUnfortunately, there is almost no stochastic analysis known for any of the models that\nwe considered. This is also a wide-open area. A reader interested in working on suchanalysis should ﬁrst read Chapters 32and33, which consider SRPT and related variants\nfor a single-server system.\n24.4 Readings and Further Follow-up\nBelow we list additional references on the topic of task assignment for server farms.\nMore on SITA and Its Variants for Server Farms with FCFS Servers\nIt is not clear where the idea of size-based task assignment originated, because it\nhas been part of the common wisdom for a long time. Size-based splitting was usedin the Cornell Theory Center [ 99]. The SITA policy was formally introduced by\nHarchol-Balter, Crovella, and Murta in [ 83]. In a follow-up paper [ 82], Harchol-Balter\nintroduced a variant of SITA called TAGS that does not require knowing the size of the\njob, but nevertheless achieves response times close to those of SITA. The SITA policyand its variants have been the focus of many papers including [ 99,83,82,177,50,\n134,41,172,65,32,11,59,36,161]. Because of SITA’s beneﬁts in reducing job size\nvariability, for a very long time it was believed that SITA, or some SITA-like variant,was far superior to LWL\n=M/G/k with respect to mean response time when the job\nsize variability was very high. Many papers speciﬁcally compared the performance of\nSITA to LWL and found that, as job size variability is increased , SITA becomes far\nsuperior to LWL [ 32,41,50,65,82,83,134,172,177]. Although the above papers\nsuggest that SITA should be superior to LWL under high job size variability, [ 90] ﬁnds\nthat the opposite can actually be true for certain job size distributions and loads, as\nexplained in this chapter. This work was further extended in [ 91], where variants of\nSITA were considered that combine the strengths of SITA and LWL. For example [ 91]\nconsiders an M/G/2 server farm, where the top server only serves small jobs, but the\nbottom server can serve any job, referred to as Hybrid . Surprisingly, [ 91] proves that\neven Hybrid can sometimes be inferior to LWL.\nMore on M/G/k and G/G/k\nThe mean response time for the M/G/k, and hence also G/G/k, remains a longstand-\ning open problem in the queueing literature [ 76]. After the Lee and Longton [ 118]\napproximation in 1959, many other authors proposed alternative simple closed-formapproximations for mean waiting time; see [ 97,98,112,132,26,196]. Unfortunately,\nall of these closed-form approximations also involve only the ﬁrst 2 moments of thejob size distribution, which is shown to be insufﬁcient in [ 76].\nThere are several key analytical papers that are concerned with the G/G/k under high\njob size variability. Scheller-Wolf and Sigman [ 156,155] prove an upper bound on\nmean delay in a G/G/k system where this upper bound does not depend on any moment\n24.4 readings and further follow-up 429\nof service time higher than thek+1\nkmoment, and it particularly does not depend on the\nvariance of job size. The [ 155] result requires that the resource requirement, R, is not\ntoo high: R<⌊k/2⌋(where R=kρ). However, [ 156] generalizes the result to allow\nfor higher load, R<k−1. The converse of the [ 156,155] results was presented by\nScheller-Wolf and Vesilo in [ 158] for a large class of distributions. It is known that\nifR>k−1, then the G/G/k diverges as C2→∞ [157], where C2is the squared\ncoefﬁcient of variation of the job size.\nWhitt [ 184] and Foss and Korshunov [ 64] consider a G/G/2 and study the delay tail\nbehavior when job size is heavy-tailed. They ﬁnd that for low load, the delay tail grows\nlike the tail of the equilibrium distribution, squared, whereas for high load the delay\ntail grows like the tail of the equilibrium distribution. These results are consistent with[155] and [ 158].\nMore on JSQ\nFor the case of server farms with PS servers, there has been very little analysis of\nJSQ, see [ 79]. However, there is a substantive simulation study by Bonomi [ 25] that\nexamines both JSQ and a few policies that improve slightly over JSQ (5% improvement)\nby exploiting knowledge of the remaining service times of jobs.\nBy contrast, there is a lot of work on JSQ for server farms with FCFS scheduling at\nthe servers. For workloads with non-decreasing failure rate, where job sizes are notknown a priori, the JSQ policy is provably optimal [ 180,194,52]. As we have pointed\nout, however, JSQ is far from optimal for FCFS servers with highly variable job sizes\n[83,82].\nAlmost all papers analyzing JSQ for server farms with FCFS servers are limited to\nk=2servers, an Exponential job size distribution, and the mean response time metric.\nEven here, the papers are largely approximate and often require truncation of the state\nspace or of some inﬁnite sums [ 108,61,73,44,146,122,3]. Sometimes the results are\nexact, but are not computationally efﬁcient and do not generalize to higher values of k\n[27].\nFor analyzing JSQ with more than k=2 servers, for the case of server farms with\nFCFS servers, again with Exponential job sizes, only approximations exist. Nelsonand Philips [ 128] use the following idea: They look at the steady-state probability of\nthe M/M/k queue (with a central queue) as an estimate for the total number of jobs\nin the JSQ/FCFS system; they then assume that the jobs in the system are dividedequally (within 1) among each of the queues. Lin and Raghavendra [ 120] follow the\napproach of approximating the number of busy servers by a Binomial distribution andthen also assume that the jobs are equally divided among each of the queues (within\n1). Both approximations are surprisingly accurate, with reported accuracy in the\n2%\nto8%error range. There are also some numerical methods papers that do not lead to a\nclosed-form solution, but are accurate and computationally efﬁcient for not-too-large\nk; see for example [ 2,122,4].",5981
159-24.5 Exercises.pdf,159-24.5 Exercises,"430 task assignment policies for server farms\nFinally, Bramson, Lu, and Prabhakar [ 30] consider the limiting regime where the\nnumber of queues goes to inﬁnity ( k→∞ ). In this regime they prove that, for any\nﬁxed number of queues, the numbers of jobs at each of the queues become independent.\nThis allows them to derive various performance metrics, including queue lengths.\nCycle Stealing in Server Farms\nThe performance of server farms can be improved dramatically by allowing servers to\nshare their work. Cycle stealing is the idea of allowing an idle server to take on some\nwork from a busy server’s queue. Analyzing the performance of a server farm with\ncycle stealing has the same difﬁculties as analyzing JSQ, because one needs to trackthe number of jobs at each server, resulting in a Markov chain that grows unboundedlyin\nkdimensions. Even for k=2 this is only approximable. There are a long list of\napproximations for different variants of cycle stealing, including approximations based\non truncating the state space along one of the dimensions [ 74,170,171]; approximations\nbased on boundary-value methods [ 55,113,43]; heavy-trafﬁc techniques [ 17,63];\napproximations based on the idea of Dimensionality Reduction of Markov chains\n[86,136,89,88,192,20,137,138,87,135]; and others [ 168,193].\n24.5 Exercises\n24.1 Server Farm with Size-Interval-Task-Assignment\nWe are given a server farm with 2 identical FCFS hosts. Arrivals into the system\noccur according to a Poisson process with rate λ. Job sizes follow a power-law\ndistribution, denoted by random variable S, where P{S>x}=x−2.5,f o r\n1≤x<∞. Small jobs (those of size <10) are routed to the ﬁrst server, and\nlarge jobs (those of size ≥10) are routed to the second server.\n(a) Derive the mean response time, E[T], for this system.\n(b) What would E[T]be if the job size distribution were changed to\nP{S>x}=x−1.5,f o r1≤x<∞.\n24.2 PS Server Farm\nConsider a server farm with 2 identical PS hosts and SITA task assignment.\nArrivals into the system occur according to a Poisson process with rate λ.\nJob sizes follow some (general) distribution. Prove that the SITA cutoff which\nminimizes mean response time is that which balances load between the two\nhosts.\n24.3 Hybrid Server Farm\nWe are given a server farm with 2 identical hosts. Arrivals into the system\noccur according to a Poisson process with rate λ. Job sizes are denoted by the\nrandom variable S, with p.d.f. fS(t), where 0≤t≤∞ , and c.d.f. FS(t)=\nP{S<t}.\nBecause our job size distribution FShas high variability, we decide to combat\nthis by using a variant of size-interval scheduling, where small jobs are sent\nto server 1, where they are scheduled in FCFS order, and large jobs are sentto server 2, where they are scheduled according to PS. Assume that the size\n24.5 exercises 431\ncutoff is chosen such that load is balanced between “small” and “large” jobs.\nSpeciﬁcally, ρ=λE[S]\n2represents both the load of the server farm and the load\nat each host. Suppose that this (balanced-load) size cutoff is 10. Thus a job is\nconsidered “small” if its size is less than 10, and is called “large” otherwise.\nFCFS\nPS Poisson ( λ)\nWrite an expression for E[T], the mean response time experienced by an\narriving job, as a function of ρ,λ,fS(t), andFS(t).\n24.4 Equivalence of LWL and M/G/k\nAssume that LWL and M/G/k are fed the same arrival sequence of jobs and\nare both run on kservers. Assume also that ties are resolved the same way in\nboth systems. Prove by induction that each job is served by the same server\nin both the systems. Furthermore, the job begins and ends service at the same\ntime in both systems.\n24.5 One Fast Machine versus Two Slow Ones\nConsider the question of whether one fast machine or two slow ones is better\nfor minimizing mean waiting time, E[TQ]. Each slow machine works at half\nthe rate of the single fast machine. Speciﬁcally, a job that requires sseconds\nof processing time on the fast machine will require 2sseconds of processing\ntime on a single slow machine.\n(a) Back in Chapter 14, we addressed this question for the M/M/k, where job\nsizes were drawn from an Exponential distribution. Which architecture\n(one fast or two slow) was superior there?\n(b) Does the answer change when the job size distribution is not Exponential?\nSpeciﬁcally, consider the following distribution of job sizes:\nr100\n101fraction of the jobs have service requirement (size) 0.01 seconds\nwhen run on a slow machine. These are called small jobs.\nr1\n101fraction of the jobs have service requirement (size) 1 second when\nrun on a slow machine. These are called large jobs.\nObserve that this job size distribution has the heavy-tail property, whereby\nthe 1% largest jobs comprise about half the total load. Assume jobs arrive\naccording to a Poisson process with rate λ, and consider two ways of\nprocessing the workload:\n1. Use a single “fast” machine: M/G/1.\n2. Use two slow machines and split the incoming jobs so that small jobs\ngo to machine 1 and large jobs go to machine 2.\nCompute E[TQ]as a function of λin both of these cases. Which case\nresults in a lower E[TQ]? Explain what is going on. If we had deﬁned the\njob size distribution to be less heavy-tailed, would the answer change?\n432 task assignment policies for server farms\n24.6 To Balance Load or Not to Balance Load?\nThe purpose of this problem is to determine whether load balancing between\ntwo identical FCFS hosts is always a good idea for minimizing E[TQ],\nor whether we might want to purposely unbalance load. Assume that jobs\narrive from outside according to a Poisson process with rate λ, where S\ndenotes the job size, and the system load is ρ=λE[S]\n2=0.5. Assume a\nBounded Pareto (k=.0009,p=1 010,α=0.5)job size distribution with\nmean 3,000.\n(a) First consider the SITA-E task assignment policy, where the size cutoff,\nx, is chosen to equalize the load at the two hosts (E stands for “equalize\nload”).\ni. What is the cutoff xunder SITA-E?\nii. What fraction of jobs are sent to each host under SITA-E?\niii. What is the mean delay, E[TQ], under SITA-E?\niv. What is E[TQ]under RANDOM, and how does this compare with\nE[TQ]under SITA-E?\n(b) Returning to SITA-E, now purposely unbalance the load by dropping x,\nthe SITA-E cutoff.\ni. Try different values of xand record the corresponding E[TQ].A p -\nproximately how low should xbe to minimize E[TQ]?\nii. What is the load at each host under this new cutoff x?\niii. What fraction of jobs are sent to each host under this new cutoff x?\n24.7 A Better SITA-E?\nBased on [ 10]. Consider a server farm with two identical FCFS hosts and\nSITA-E task assignment (see Exercise 24.6). Eitan proposes a new cutoff\nheuristic: rather than ﬁnding cutoffs which balance load, we instead de-\nrive cutoffs which equalize the expected number of queued jobs, E[NQ],\nat each host. Determine whether Eitan’s idea is useful by evaluating it on\nthe workload from Exercise 24.6: Assume that jobs arrive from outside ac-\ncording to a Poisson process, with system load ρ=λE[S]\n2=0.5. Assume\naBP(k=.0009,p=1 010,α=0.5)job size distribution with mean 3,000.\nWhich cutoff scheme (balanced load or Eitan’s scheme) is better for minimiz-ing overall mean delay,\nE[TQ]? How does Eitan’s heuristic for ﬁnding cutoffs\ncompare with using the optimal cutoff?\n24.8 Additional Recommended Problem\nExercise 21.7 on understanding the effect of job size variability in an M/G/2\nsystem is recommended as well.",7514
160-Chapter 25 Transform Analysis.pdf,160-Chapter 25 Transform Analysis,,0
161-25.1 Definitions of Transforms and Some Examples.pdf,161-25.1 Definitions of Transforms and Some Examples,"CHAPTER 25\nTransform Analysis\nThis chapter is a very brief introduction to the wonderful world of transforms. One can\nthink of the transform of a random variable as an onion. This onion is an expressionthat contains inside it all the moments of the random variable. Getting the momentsout of the onion is not an easy task, however, and may involve some tears as the onionis peeled, where the “peeling process” involves differentiating the transform. The ﬁrst\nmoment is stored in the outermost layer of the onion and thus does not require toomuch peeling to reach. The second moment is stored a little deeper, the third momenteven deeper (more tears), etc. Although getting the moments is painful, it is entirelystraightforward how to do it – just keep peeling the layers.\nTransforms are a hugely powerful analysis technique. For example, until now we have\nonly learned how to derive the mean response time,\nE[T], for the M/G/1. However,\nby the end of the next chapter, we will be able to derive the transform of T, which will\nallow us to obtain any desired moment of T.\nThe subject of transforms is very broad. In this chapter we only cover a small subset,\nnamely those theorems that are most applicable in analyzing the performance of queues.\nWe use transforms heavily in analyzing scheduling algorithms in Part VII.\n25.1 Deﬁnitions of Transforms and Some Examples\nDeﬁnition 25.1 The Laplace transform ,Lf(s), of a continuous function, f(t),\nt≥0, is deﬁned as\nLf(s)=/integraldisplay∞\n0e−stf(t)dt.\nYou can think of sas just being some parameter, where the Laplace transform is\na function of s. When we speak of the Laplace transform of a continuous random\nvariable (r.v.), X, we are referring to the Laplace transform, Lf(s), of the p.d.f., fX(·),\nassociated with X. We write/tildewideX(s)to denote the Laplace transform of X.\nObserve that if Xis a continuous r.v. and f(t),t≥0, is the p.d.f. of X, then\n/tildewideX(s)=Lf(s)=E/bracketleftbig\ne−sX/bracketrightbig\n.\n433\n434 transform analysis\nExample: Derive the Laplace transform of X∼Exp(λ):\n/tildewideX(s)=Lf(s)=/integraldisplay∞\n0e−stλe−λtdt=λ/integraldisplay∞\n0e−(λ+s)tdt=λ\nλ+s\nExample: Derive the Laplace transform of X=a, where ais some constant:\n/tildewideX(s)=Lf(s)=e−sa\nExample: Derive the Laplace transform of X∼Uniform (a, b),a, b≥0:\n/tildewideX(s)=Lf(s)=/integraldisplay∞\n0e−stf(t)dt\n=/integraldisplayb\nae−st1\nb−adt\n=/parenleftbigg−e−sb\ns+e−sa\ns/parenrightbigg1\nb−a\n=e−sa−e−sb\ns(b−a)\n(Observe that here f(t)is deﬁned to be 0when it is outside the (a, b)range.)\nQuestion: How do we know that the Laplace transform as deﬁned necessarily con-\nverges?\nAnswer: (Partial) It does if f(t)is a p.d.f. of some non-negative random variable and\ns≥0. To see this observe that\ne−t≤1,\nfor all non-negative values of t. Thus\ne−st=/parenleftbig\ne−t/parenrightbigs≤1,\nassuming that sis non-negative. Thus,\nLf(s)=/integraldisplay∞\n0e−stf(t)dt≤/integraldisplay∞\n01·f(t)dt=1.\nDeﬁnition 25.2 The z-transform ,Gp(z), of a discrete function, p(i),f o ri=0,\n1,2,... is deﬁned as:\nGp(z)=∞/summationdisplay\ni=0p(i)zi.\nObserve that the z-transform is a polynomial in z. When we speak of the z-transform\nof a discrete r.v. X, we are referring to the z-transform of the p.m.f., pX(·), associated\n25.1 deﬁnitions of transforms and some examples 435\nwithX. We write/hatwideX(z)to denote the z-transform of X. Observe that if Xis a discrete\nr.v. and p(i),i=0,1,2,..., is its p.m.f., then\n/hatwideX(z)=Gp(z)=E/bracketleftbig\nzX/bracketrightbig\n.\nExample: Derive the z-transform of X∼Binomial (n, p):\n/hatwideX(z)=Gp(z)=n/summationdisplay\ni=0/parenleftbiggn\ni/parenrightbigg\npi(1−p)n−izi\n=n/summationdisplay\ni=0/parenleftbiggn\ni/parenrightbigg\n(zp)i(1−p)n−i\n=(zp+( 1−p))n\nExample: Derive the z-transform of X∼Geometric (p):\n/hatwideX(z)=Gp(z)=∞/summationdisplay\ni=1p(1−p)i−1zi\n=zp∞/summationdisplay\ni=1(z(1−p))i−1\n=zp\n1−z(1−p)\nDeﬁnition 25.3 The random variable Atwill be used to denote the number of\narrivals by time t, where the arrival process is Poisson (λ).\nExample : Derive the z-transform of At:\n/hatwiderAt(z)=Gp(z)=∞/summationdisplay\ni=0(λt)ie−λtzi\ni!\n=e−λt∞/summationdisplay\ni=0(λtz)i\ni!\n=e−λt·eλtz\n=e−λt(1−z)\nDeﬁnition 25.4 The random variable ASwill be used to denote the number of\narrivals by time S, where Sis a random variable (typically denoting service time),\nand the arrival process is Poisson (λ).",4446
162-25.2 Getting Moments from Transforms Peeling the Onion.pdf,162-25.2 Getting Moments from Transforms Peeling the Onion,"436 transform analysis\nExample: Derive the z-transform of AS:\n/hatwiderAS(z)=∞/summationdisplay\ni=0P{AS=i}zi\n=∞/summationdisplay\ni=0/parenleftbigg/integraldisplay∞\n0P{AS=i|S=t}fS(t)dt/parenrightbigg\nzi\n=∞/summationdisplay\ni=0/parenleftbigg/integraldisplay∞\n0e−λt(λt)i\ni!fS(t)dt/parenrightbigg\nzi\n=/integraldisplay∞\n0e−λtfS(t)∞/summationdisplay\ni=0(λtz)i\ni!dt\n=/integraldisplay∞\n0e−λtfS(t)eλtzdt\n=/integraldisplay∞\n0e−λ(1−z)tfS(t)dt\n=LS(λ(1−z))\n=/tildewideS(λ(1−z)) (25.1)\n(We will see a quicker way to derive /hatwiderAS(z)soon.)\n25.2 Getting Moments from Transforms: Peeling the Onion\nTheorem 25.5 LetXbe a continuous r.v. with p.d.f. f(t),t≥0. Then\nE[Xn]=(−1)ndnLf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0.\nEven if f(t)is not a p.d.f., it still holds that\n/integraldisplay∞\nt=0tn·f(t)dt=(−1)ndnLf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0.\nNote: If the above moments are not deﬁned at s=0, one can instead consider the\nlimit as s→0, where evaluating the limit may require using L’Hospital’s rule.\nProof\ne−st=1−(st)+(st)2\n2!−(st)3\n3!+...\ne−stf(t)=f(t)−(st)f(t)+(st)2\n2!f(t)−(st)3\n3!f(t)+...\n25.2 getting moments from transforms: peeling the onion 437\nLf(s)=/integraldisplay∞\n0e−stf(t)dt\n=/integraldisplay∞\n0f(t)dt−/integraldisplay∞\n0(st)f(t)dt+/integraldisplay∞\n0(st)2\n2!f(t)dt−/integraldisplay∞\n0(st)3\n3!f(t)dt+...\n=1−sE[X]+s2\n2!E/bracketleftBig\nX2/bracketrightBig\n−s3\n3!E/bracketleftBig\nX3/bracketrightBig\n+...\ndLf(s)\nds=−E[X]+sE/bracketleftBig\nX2/bracketrightBig\n−3s2\n3!E/bracketleftBig\nX3/bracketrightBig\n+...\ndLf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=−E[X]\nd2Lf(s)\nds=E/bracketleftBig\nX2/bracketrightBig\n−sE/bracketleftBig\nX3/bracketrightBig\n+...\nd2Lf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=E/bracketleftBig\nX2/bracketrightBig\nWe can see from the original Taylor series expansion that each time we take another\nderivative, we get a higher moment, with alternating sign.\nExample: Compute the kth moment of X∼Exp(λ):\n/tildewideX(s)=Lf(s)=λ\nλ+s\nE[X]=−dLf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=−−λ\n(λ+s)2/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=1\nλ\nE/bracketleftbig\nX2/bracketrightbig\n=(−1)2d2Lf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=d\nds/parenleftbigg−λ\n(λ+s)2/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=2λ\n(λ+s)3/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=2\nλ2\nE/bracketleftbig\nXk/bracketrightbig\n=(−1)kdkLf(s)\nds/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=k!λ\n(λ+s)k+1/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0=k!\nλk\nTheorem 25.6 ForXa discrete r.v. with p.m.f. p(i),i=0,1,2,..., the sequence\n/braceleftBig\nG(n)\np(z)/vextendsingle/vextendsingle\nz=1:n≥1/bracerightBig\nprovides the moments of X, as follows:\nG/prime\np(z)|z=1=E[X]\nG/prime/prime\np(z)|z=1=E[X(X−1)]\nG/prime/prime/prime\np(z)|z=1=E[X(X−1)(X−2)]\nG(n)\np(z)|z=1=E[X(X−1)(X−2)···(X−n+1 ) ]\nNote: If the above moments are not deﬁned at z=1, one can instead consider the\nlimit as z→1, where evaluating the limit may require using L’Hospital’s rule.\n438 transform analysis\nProof Here we illustrate how the moments pop out of the sequence. The proof can\nbe obtained formally via induction.\nGp(z)=∞/summationdisplay\ni=0p(i)zi\nG/prime\np(z)=d\ndz/parenleftBigg∞/summationdisplay\ni=0p(i)zi/parenrightBigg\n=d\ndz/parenleftBigg∞/summationdisplay\ni=1p(i)zi/parenrightBigg\n=∞/summationdisplay\ni=1ip(i)zi−1\nG/prime\np(z)/vextendsingle/vextendsingle\nz=1=∞/summationdisplay\ni=1ip(i)=E[X]\nG/prime/prime\np(z)=d\ndz/parenleftBigg∞/summationdisplay\ni=1ip(i)zi−1/parenrightBigg\n=d\ndz/parenleftBigg∞/summationdisplay\ni=2ip(i)zi−1/parenrightBigg\n=∞/summationdisplay\ni=2i(i−1)p(i)zi−2\nG/prime/prime\np(z)/vextendsingle/vextendsingle\nz=1=∞/summationdisplay\ni=2i(i−1)p(i)=E[X(X−1)]\nG/prime/prime/prime\np(z)=d\ndz/parenleftBigg∞/summationdisplay\ni=2i(i−1)p(i)zi−2/parenrightBigg\n=d\ndz/parenleftBigg∞/summationdisplay\ni=3i(i−1)p(i)zi−2/parenrightBigg\n=∞/summationdisplay\ni=3i(i−1)(i−2)p(i)zi−3\nG/prime/prime/prime\np(z)/vextendsingle/vextendsingle\nz=1=∞/summationdisplay\ni=3i(i−1)(i−2)p(i)=E[X(X−1)(X−2)]\nExample: Compute the variance of X∼Geometric (p):\n/hatwideX(z)=zp\n1−z(1−p)\nE[X]=d\ndz/parenleftbiggzp\n1−z(1−p)/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1=p\n(1−z(1−p))2/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1=1\np\nE/bracketleftbig\nX2/bracketrightbig\n=/hatwideX/prime/prime(z)/vextendsingle/vextendsingle/vextendsingle\nz=1+E[X]=2p(1−p)\n(1−z(1−p))3/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1+1\np\n=2(1−p)\np2+1\np=2−p\np2\nVar(X)=E/bracketleftbig\nX2/bracketrightbig\n−(E[X])2=1−p\np2",4944
163-25.3 Linearity of Transforms.pdf,163-25.3 Linearity of Transforms,"25.3 linearity of transforms 439\nExample: Use transforms to compute the ﬁrst moment of AS, the number of arrivals\nduring a service time, where S∼Exp(μ).\nWe show here two ways to do this. It is good to know both. The ﬁrst way is by expanding\nthe transform and then differentiating it:\n/hatwiderAS(z)=/tildewideS(λ(1−z)) =μ\nμ+λ(1−z)\n/hatwiderAS/prime(z)=μλ\n(μ+λ(1−z))2\nE[AS]=/hatwiderAS/prime(z)/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1=μλ\nμ2=λ\nμ\nThe second way does not expand the transform, so the chain rule needs to be applied.\nE[AS]=/hatwiderAS/prime(z)/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1\n=d\ndz/tildewideS(λ(1−z))/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1\n=/tildewideS/prime(λ(1−z))/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1·(−λ)/vextendsingle/vextendsingle/vextendsingle/vextendsingle\nz=1\n=/tildewideS/prime(0)·(−λ)\n=−E[S]·(−λ)\n=λ\nμ\n25.3 Linearity of Transforms\nTheorem 25.7 LetXandYbe continuous, independent random variables with\np.d.f.x(t),t≥0, andy(t),t≥0, respectively. Let Z=X+Ywhere z(t),t≥0,\nis the p.d.f. of Z. Then the Laplace transform of Zis given by\n/tildewideZ(s)=/tildewideX(s)·/tildewideY(s). (25.2)\nIn particular, if X1,...,X nare i.i.d. random variables, and Z=X1+···+Xn,\nthen/tildewideZ(s)=(/tildewideX(s))n.\nLet the convolution of x(·)andy(·)beg=x⊗y, where\ng(t)=/integraldisplayt\n0x(t−k)y(k)dk.\nThen the Laplace transform of g(t), denoted by Lg(s), is given by\nLg(s)=Lx⊗y(s)=Lx(s)Ly(s), (25.3)\neven when XandYare not independent (although g(t)only equals z(t)when\nX⊥Y).\n440 transform analysis\nProof LetX⊥Y, andZ=X+Y. Then\n/tildewideZ(s)=/integraldisplay∞\n0e−stz(t)dt\n=/integraldisplay∞\n0e−st/integraldisplayt\nk=0z(t|Y=k)·y(k)dk dt (25.4)\n=/integraldisplay∞\n0e−st/integraldisplayt\nk=0x(t−k|Y=k)·y(k)dk dt (25.5)\n=/integraldisplay∞\n0e−st/integraldisplayt\nk=0x(t−k)·y(k)dk dt (25.6)\n=/integraldisplay∞\nk=0y(k)/integraldisplay∞\nt=ke−stx(t−k)dt dk (25.7)\n=/integraldisplay∞\nk=0y(k)e−sk/integraldisplay∞\nt=ke−s(t−k)x(t−k)dt dk\n=/integraldisplay∞\nk=0y(k)e−sk/integraldisplay∞\nv=0e−svx(v)dv dk (letting v=t−k,dv=dt)\n=Ly(s)·Lx(s)\n=/tildewideY(s)·/tildewideX(s) (25.8)\nQuestion: In proving ( 25.2), where was the independence of XandYused?\nAnswer: In moving from ( 25.5)t o( 25.6).\nQuestion: The proof of ( 25.3) should notrequire that XandYare independent. How\nis this possible?\nAnswer: The proof of ( 25.3) starts on line ( 25.6) above. It therefore does not depend\nonXandYbeing independent.\nHere is an alternative proof of ( 25.2), assuming that XandYare independent:\nProof /tildewideZ(s)=E/bracketleftbig\ne−sZ/bracketrightbig\n=E/bracketleftbig\ne−s(X+Y)/bracketrightbig\n=E/bracketleftbig\ne−sX·e−sY/bracketrightbig\n=E/bracketleftbig\ne−sX/bracketrightbig\n·E/bracketleftbig\ne−sY/bracketrightbig\n(because X⊥Y)\n=/tildewideX(s)·/tildewideY(s)\nTheorem 25.8 LetXandYbe discrete independent random variables. Let Z=\nX+Y. Then the z-transform of Zis given by/hatwideZ(z)=/hatwideX(z)·/hatwideY(z).",3068
164-25.4 Conditioning.pdf,164-25.4 Conditioning,"25.4 conditioning 441\nProof The proof follows exactly the lines of the proof of Theorem 25.7 and can again\nbe done in two ways; see Exercise 25.1.\nExample: LetX∼Binomial (n,p)andY∼Binomial (m, p)be independent random\nvariables. What is the distribution of X+Y?\n/hatwideZ(z)=/hatwideX(z)·/hatwideY(z)\n=(zp+( 1−p))n(zp+( 1−p))m\n=(zp+( 1−p))m+n\nObserve that (zp+( 1−p))m+nis the z-transform of a Binomial random variable\nwith parameters m+nandp. Thus, the distribution of X+Yis Binomial (m+n,p).\n25.4 Conditioning\nTheorem 25.9 LetX,A, andBbe continuous random variables where\nX=/braceleftbiggAwith probability p\nBwith probability 1−p.\nThen\n/tildewideX(s)=p·/tildewideA(s)+( 1−p)·/tildewideB(s).\nProof\n/tildewideX(s)=E/bracketleftbig\ne−sX/bracketrightbig\n=E/bracketleftbig\ne−sX/vextendsingle/vextendsingleX=A/bracketrightbig\n·p+E/bracketleftbig\ne−sX/vextendsingle/vextendsingleX=B/bracketrightbig\n·(1−p)\n=pE/bracketleftbig\ne−sA/bracketrightbig\n+( 1−p)E/bracketleftbig\ne−sB/bracketrightbig\n=p/tildewideA(s)+( 1−p)/tildewideB(s)\nTheorem 25.10 LetX,A, andBbe discrete random variables where\nX=/braceleftbiggAwith probability p\nBwith probability 1−p.\nThen\n/hatwideX(z)=p·/hatwideA(z)+( 1−p)·/hatwideB(z).\n442 transform analysis\nProof\n/hatwideX(z)=E/bracketleftbig\nzX/bracketrightbig\n=E/bracketleftbig\nzX/vextendsingle/vextendsingleX=A/bracketrightbig\n·p+E/bracketleftbig\nzX/vextendsingle/vextendsingleX=B/bracketrightbig\n·(1−p)\n=E/bracketleftbig\nzA/bracketrightbig\n·p+E/bracketleftbig\nzB/bracketrightbig\n·(1−p)\n=p/hatwideA(z)+( 1−p)/hatwideB(z)\nWe can generalize Theorems 25.9 and25.10 . Theorem 25.11 is a generalization of\nTheorem 25.9. The generalization for Theorem 25.10 follows similarly.\nTheorem 25.11 LetYbe a continuous random variable, and let XYbe a continu-\nous random variable that depends on Y. Then, if fY(y)denotes the density function\nofY, we have that\n/tildewidestXY(s)=/integraldisplay∞\ny=0/tildewiderXy(s)fY(y)dy.\nProof\n/tildewidestXY(s)=E/bracketleftbig\ne−sXY/bracketrightbig\n=/integraldisplay∞\ny=0E/bracketleftbig\ne−sXY/vextendsingle/vextendsingleY=y/bracketrightbig\n·f\nY(y)dy\n=/integraldisplay∞\ny=0E/bracketleftbig\ne−sXy/bracketrightbig\n·fY(y)dy\n=/integraldisplay∞\ny=0/tildewiderXy(s)·fY(y)dy\nExample\nRecall the lengthy derivation of /hatwiderAS(z), resulting in ( 25.1). We now show a much faster\nderivation via conditioning. We condition on Sas follows:\n/hatwiderAS(z)=/integraldisplay∞\n0/hatwiderAS(z|S=t)fS(t)dt\n=/integraldisplay∞\n0/hatwiderAt(z)fS(t)dt\n=/integraldisplay∞\n0e−λ(1−z)tfS(t)dt\n=/tildewideS(λ(1−z)) (25.9)",2616
165-25.8 Readings.pdf,165-25.8 Readings,"25.5 distribution of response time in an m/m/ 1 443\n25.5 Distribution of Response Time in an M/M/1\nSuppose we want to derive the distribution of the response time Tfor the M/M/1. We\ncan leverage the fact that we know the distribution of N, the number in system, to get\nthe Laplace transform of T.\nLetTkbe the response time, given that the arrival ﬁnds kjobs in the system. Then, by\nTheorem 25.9 and its generalizations, we have\n/tildewideT(s)=∞/summationdisplay\nk=0/tildewiderTk(s)·P(kin system ).\nNow observe that\nTk=S1+S2+···+Sk+Sk+1,\nwhere Siis the size of the ith job in the system, and Sk+1is the size of the arrival.\nSince the Si’s are i.i.d., by Theorem 25.7,\n/tildewiderTk(s)=/parenleftBig\n/tildewideS(s)/parenrightBigk+1\n=/parenleftbiggμ\ns+μ/parenrightbiggk+1\n.\nFinally,\n/tildewideT(s)=∞/summationdisplay\nk=0/parenleftbiggμ\ns+μ/parenrightbiggk+1\n·ρk(1−ρ)\n=(1−ρ)μ\ns+μ·∞/summationdisplay\nk=0/parenleftbiggμ\ns+μ·ρ/parenrightbiggk\n=(1−ρ)μ\ns+μ·1\n1−μρ\ns+μ\n=(1−ρ)μ\ns+μ·s+μ\ns+μ−μρ\n=μ−λ\ns+(μ−λ).\nQuestion: What does this say about the distribution of T?\nAnswer:\nTM/M/1∼Exp(μ−λ).\n444 transform analysis\n25.6 Combining Laplace and z-Transforms\nTheorem 25.12 (Summing a Random Number of i.i.d. Random Variables) Let\nZ=Y1+Y2+...+YX,\nwhere the Yi’s are i.i.d. continuous r.v. ’s, and where Xis a discrete random variable,\nwhere X⊥Yi,∀i.L e t/hatwideX(z)be the z-transform of X, and let/tildewideY(s)be the Laplace\ntransform of Yi. Then\n/tildewideZ(s)=/hatwideX/parenleftBig\n/tildewideY(s)/parenrightBig\n.\nExample: Derive the Laplace transform of a Poisson (λ)number of i.i.d. Exp (μ)\nrandom variables. Recall that for X∼Poisson (λ)we have that\n/hatwideX(z)=e−λ(1−z).\nRecall likewise that for Y∼Exp(μ)we have that\n/tildewideY(s)=μ\ns+μ.\nFrom this it follows that\n/tildewideZ(s)=/hatwideX/parenleftBig\n/tildewideY(s)/parenrightBig\n=e−λ(1−z)/vextendsingle/vextendsingle/vextendsingle\nz=μ\ns+μ=e−λ(1−μ\ns+μ)=e−λs\ns+μ.\nProof (Theorem 25.12 )Let/tildewideZ(s|X=n)denote the Laplace transform of Z\ngiven that X=n. Then, by Theorem 25.7,/tildewideZ(s|X=n)=/parenleftBig\n/tildewideY(s)/parenrightBign\n.N o w ,b y\nconditioning,\n/tildewideZ(s)=∞/summationdisplay\nn=0P{X=n}/tildewideZ(s|X=n)\n=∞/summationdisplay\nn=0P{X=n}/parenleftBig\n/tildewideY(s)/parenrightBign\n=/hatwideX/parenleftBig\n/tildewideY(s)/parenrightBig\n.\nQuestion: Can we apply Theorem 25.12 to a sum of a random variable number of\ndiscrete random variables?\n25.7 more results on transforms 445\nAnswer: Yes, the same proof works, and the ﬁnal result is then /hatwideZ(z)=/hatwideX/parenleftBig\n/hatwideY(z)/parenrightBig\n.\n25.7 More Results on Transforms\nNormally we look at the Laplace transform of the p.d.f., but we could also ask what is\nthe Laplace transform of any function. Theorem 25.13 considers the Laplace transform\nof the c.d.f. and relates that to the Laplace transform of the p.d.f.\nTheorem 25.13 Consider a p.d.f., b(·), where B(·)is the cumulative distribution\nfunction corresponding to b(·). That is,\nB(x)=/integraldisplayx\n0b(t)dt.\nLet\n/tildewideb(s)=Lb(t)(s)=/integraldisplay∞\n0e−stb(t)dt.\nLet\n/tildewideB(s)=LB(x)(s)=/integraldisplay∞\n0e−sxB(x)dx=/integraldisplay∞\n0e−sx/integraldisplayx\n0b(t)dtdx.\nThen\n/tildewideB(s)=/tildewideb(s)\ns.\nProof\n/tildewideB(s)=/integraldisplay∞\nx=0e−sx/integraldisplayx\nt=0b(t)dt dx\n=/integraldisplay∞\nx=0e−st·e−s(x−t)/integraldisplayx\nt=0b(t)dt dx\n=/integraldisplay∞\nt=0b(t)e−stdt/integraldisplay∞\nx=te−s(x−t)dx\n=/integraldisplay∞\nt=0b(t)e−stdt/integraldisplay∞\ny=0e−sydy\n=/tildewideb(s)·1\ns\nHere is one last little bit of information that comes in handy when differentiating\ntransforms.",3701
166-25.9 Exercises.pdf,166-25.9 Exercises,"446 transform analysis\nTheorem 25.14 For all random variables, X,\n/tildewideX(0) = 1 and/hatwideX(1) = 1 .\n25.8 Readings\nThere is a lot more that can be said on transforms. For an entire book on the use of\ntransforms in probability modeling, see [ 71].\n25.9 Exercises\n25.1 Sums of Discrete Random Variables\nLetXandYbe discrete independent random variables. Let Z=X+Y.\nProve that the z-transform of Zis given by/hatwideZ(z)=/hatwideX(z)·/hatwideY(z).\n25.2 Sum of Poissons\nLetX1∼Poisson (λ1). LetX2∼Poisson (λ2). Suppose X1⊥X2. LetY=\nX1+X2.H o wi s Ydistributed? Prove it using z-transforms. Note that the\nparameter for the Poisson denotes its mean.\n25.3 Moments of Poisson\nLetX∼Poisson (λ).D e r i v e E[X(X−1)(X−2)···(X−k+1 ) ] for\nk=1,2,3,...\n25.4 Moments of Binomial\nLetX∼Binomial (n,p).D e r i v e E[X(X−1)(X−2)···(X−k+1 ) ]\nfork=1,2,3,...\n25.5 Convergence of z-Transform\nLetpX(i)represent the p.m.f. of a discrete, non-negative r.v. X, and let\n/hatwideX(z)=/summationtext∞\ni=0pX(i)zidenote the z-transform of X. Prove that if |z|≤1,\nthen/hatwideX(z)converges. Speciﬁcally, show that /hatwideX(z)is bounded from above\nand below.\n25.6 Sum of Geometric Number of Exponentials\nLetN∼Geometric (p). LetXi∼Exp(μ), where the Xi’s are independent\nof each other and of N. LetSN=/summationtextN\ni=1Xi. Prove that SNis Exponentially\ndistributed and derive the rate of SN.\n(a) First do this using δ-step arguments.\n(b) Now do this again using transforms via Theorem 25.12 .\n(c) Suppose we are given a Poisson process, where packets are colored “blue”\nwith probability p. What does the above result tell us about the distribution\nof the spacing between blue packets?\n25.7 Practice with Laplace Transforms: A Useful Identity\nLetXbe an arbitrary random variable. Let Y∼Exp(λ), where XandYare\nindependent. Prove that\nP{X<Y}=/tildewideX(λ).\n25.9 exercises 447\n25.8 Review of M/M/1\n(a) What do we know about the distribution of N, the number of jobs in an\nM/M/1? [Hint: It is not quite a Geometric, but it can be expressed as aGeometric plus or minus something.]\n(b) Given your previous answer, what are\nE[N]andVar(N)?\n(c) What do we know about the distribution of T, the M/M/1 response time?\n(d) Given your previous answer, what are E[T]andVar(T)?\n(e) Recall the derivation in this chapter for the Laplace transform of T. Follow\na similar approach to derive the Laplace transform of TQ, the waiting time\nfor the M/M/1.\n(f) How can you check that your answer for /tildewiderTQ(s)is correct, given that you\nknow/tildewideT(s)?\n25.9 Downloading Files\nYou need to download two ﬁles: ﬁle 1 and ﬁle 2. File 1 is available viasource A or source B. File 2 is available only via source C. The time todownload ﬁle 1 from source A is Exponentially distributed with rate\n1. The\ntime to download ﬁle 1 from source B is Exponentially distributed with rate 2.\nThe time to download ﬁle 2 from source C is Exponentially distributed withrate\n3. You decide to download from all three sources simultaneously, in the\nhope that you get both ﬁle 1 and ﬁle 2 as soon as possible. Let Tdenote the\ntime until you get both ﬁles. What is/tildewideT(s)?\n25.10 Two-Sided Laplace Transform\nIn the case where a distribution can take on negative values, we deﬁne theLaplace transform as follows: Let\nXbe a random variable with density function\nf(t),−∞<t<∞:\n/tildewideX(s)=Lf(s)=/integraldisplay∞\n−∞e−stf(t)dt\nLetX∼Normal (0,1)be the standard Normal. Show that\n/tildewideX(s)=es2\n2.\n25.11 Transforms Derivation of Burke’s Theorem\nIn an M/M/1, when the server is busy, jobs depart at rate μ. However, when the\nM/M/1 is idle, then no jobs depart. Thus, the interdeparture times are either dis-tributed Exp\n(μ)(when the server is busy), or Exp (λ)+Exp(μ)(when idle) –\nthis latter term comes from having to wait for an arrival and then for that arrivalto depart. It is not at all clear how having interarrival times switch between\nthese modes could form a Poisson\n(λ)departure process.\nLetTdenote the time between departures. Prove that T∼Exp(λ)by deriving\nits Laplace transform via conditioning.\n25.12 M/M/2/3\nIn the M/M/2/3, jobs arrive according to a Poisson process with rate λ. There\nare 2 servers, each serving at rate μ, and a single central queue; however,\nthere is only room for 3 jobs total (one waiting job and two serving jobs).\n448 transform analysis\nWhen an arrival ﬁnds 3 jobs already in the system, the arrival is dropped; see\nFigure 25.1. LetTdenote the response time for the M/M/2/3. Derive /tildewideT(s).\nPoisson ( λ)μ\nμ\nFigure 25.1. The M/M/2/3.\n25.13 Busy Period in M/M/1\nDerive the duration of a busy period in an M/M/1 queue with arrival rate λand\nservice rate μ. A busy period, B, is the time from when a job arrives at an idle\nsystem until the system is ﬁrst empty again. (Obviously, the number of jobs\nmay go up and down a lot in between going from state 1 to state 0.)\n(a) First derive E[B]. How does E[B]compare with E[T]for the M/M/1?\n(b) At this point, you may be wondering if the busy period is Exponentially\ndistributed. Find out by deriving the Laplace transform of the busy period,\n/tildewideB(s). [Hint: Conditioning helps. Also, at the very end, you may need to\nmake use of the fact that /tildewideB(0) = 1 ].\n25.14 Transform of Seand Moments of Excess1\nConsider a renewal process where Srepresents the time between renewals.\nF(x)andf(x)are the c.d.f. and p.d.f. for S. We use Seto denote the excess\nofS(a.k.a. the equilibrium distribution of S), andFe(x)andfe(x)to denote\nits c.d.f. and p.d.f. Your job is to calculate the ﬁrst 2 moments of excess: E[Se]\nandE[S2\ne].\n(a) Use Renewal-Reward to derive Fe(k), the time-average fraction of time\nthatSe<k.\n(b) Differentiate your result in (a) to derive fe(k). You should get\nfe(k)=F(k)\nE[S]. (25.10)\n(c) Derive/tildewiderSe(s)=Lfe(s)and simplify to get\n/tildewiderSe(s)=1−/tildewideS(s)\nsE[S]. (25.11)\n(d) Differentiate /tildewiderSe(s)appropriately to determine the ﬁrst 2 moments of Se.\n25.15 Heuristic Proof of Central Limit Theorem via Transforms\nIn this problem, you will derive a heuristic proof of the Central Limit Theorem\n(CLT). Let X1,X2,...be a sequence of i.i.d. random variables, each with\nmeanμand variance σ2. CLT says that the distribution of\nX1+X2+···+Xn−nμ\nσ√n(25.12)\n1Warning: the result of this problem will be used repeatedly throughout the rest of the book.\n25.9 exercises 449\ntends to the standard Normal as n→∞ . Speciﬁcally,\nP/braceleftbiggX1+X2+···+Xn−nμ\nσ√n≤a/bracerightbigg\n→1√\n2π/integraldisplaya\n−∞e−x2/2dx,asn→∞.\nThe high-level idea in our approach is to show that the Laplace transform of\n(25.12 ) roughly converges to the Laplace transform of the standard Normal\ndistribution, as given in Exercise 25.10 . Showing that the two transforms are\nthe same implies that ( 25.12 ) and the standard Normal agree on all moments,\nthus having the same distribution. Let\nS=X1+X2+···+Xn√n.\n(a) Start with the case where μ=0andσ2=1.\ni. Show that\n/tildewideS(s)≈/parenleftbigg\n1−sE[X]√n+s2E[X2]\n2n/parenrightbiggn\n.\nii. Using what you know about μandσ2, show that\n/tildewideS(s)→/tildewiderN(0,1)(s),asn→∞.\n(b) Now generalize your solution to arbitrary μandσ.\n25.16 M/M/2 Transform\nFor the M/M/2 with arrival rate λ, where each server serves at rate μ, derive:\n/hatwideN(z),/hatwiderNQ(z), and/tildewiderTQ(s). The z-transforms are obtained directly from the\nlimiting probabilities on the number of jobs in the system. The Laplace trans-\nform is obtained by conditioning on the number of jobs seen by an arrival.\nThis same approach can be used to derive the M/M/k transform.",7672
167-Chapter 26 MG1 Transform Analysis.pdf,167-Chapter 26 MG1 Transform Analysis,,0
168-26.1 The z-Transform of the Number in System.pdf,168-26.1 The z-Transform of the Number in System,"CHAPTER 26\nM/G/1 Transform Analysis\nIn this chapter we derive the Laplace transform of the response time for an M/G/1\nqueue. Among other beneﬁts, the transform allows us to get moments of responsetime.\nWe follow the two-step outline shown in Figure 26.1 that involves ﬁrst computing the\nz-transform of the number of jobs in the M/G/1,\n/hatwideN(z)(see Section 26.1), and then\nusing that to get the Laplace transform of the response time for the M/G/1, /tildewideT(s)(see\nSection 26.2). Note that we cannot simply use Little’s Law to make the conversion,\nbecause it applies only to means.\nSTE P 1: Section 26.1\nDerive N(z)^STE P 2: Section 26.2\nDerive T(s)~\nFigure 26.1. Two-step outline.\n26.1 The z-Transform of the Number in System\nWe deﬁne\n/hatwideN(z)=∞/summationdisplay\ni=0πM/G/1\nizi. (26.1)\nHereπM/G/1\ni denotes the long-run fraction of time that there are ijobs in the M/G/1. We\nsometimes write simply πiwhen the context is clear. We could get /hatwideN(z),i fw ek n e w\nπM/G/1\ni.\nQuestion: How can we get πM/G/1\ni? Can we do the same thing we did for the M/M/1?\nAnswer: (Attempt 1) For the M/M/1, we created a CTMC, where the state was the\ncurrent number of jobs, and then we solved the CTMC. It is not obvious how to do\nthis for the M/G/1 because the service times are not Exponential. To create a Markov\nchain, we need to know that the time until we leave a state does not depend on history,such as how much time we have already spent in the state. Yet for an M/G/1, the timeuntil a job departs could certainly depend on how long it has been running so far (think\ndecreasing failure rate, as in Chapter 20).\nSo we need another idea for getting\nπM/G/1\ni. Here is a hint:\n450\n26.1 the z-transform of the number in system 451\nHint: Sometimes it is easier to think about the embedded discrete-time Markov chain\n(DTMC) that ignores the time spent at each state. How can we use this?\nAnswer: (Attempt 2) The solution is to consider the M/G/1 only at points in time\nwhere a departure occurs. The state of the chain is deﬁned to be the number of jobs\nat the server at the time of the last departure . We can form a stochastic process\nX1,X2,X3,...,X i,..., where Xidenotes the number of jobs left behind at the\ntime of the ithdeparture. This is the embedded discrete-time Markov chain. In the\nembedded DTMC, there is a probability (not a rate) of moving from state to state,\nwhich we deﬁne shortly.\nLetπembed\ni denote the limiting probability of being in state iof the embedded DTMC.\nThis is the fraction of M/G/1 departures that leave behind ijobs.\nQuestion: How do πembed\ni andπM/G/1\ni compare?\nAnswer: They are the same:\nπembed\ni=πM/G/1\ni\nRecall from Chapter 13that the probability that a departure leaves behind ijobs(di)\nis equal to the probability that an arrival sees ijobs(ai), but by PASTA this in turn is\nequal to the proportion of time that there are ijobs(pi).\nThus it sufﬁces to derive πembed\ni and use that as πM/G/1\ni in (26.1). To derive πembed\ni we\nsolve the embedded DTMC.\nQuestion: What is Pijfor the embedded DTMC process: X1,X2,X3,...?\nWarning : Be careful. The sequence of states followed by the embedded DTMC is just\na subset of those followed by the original M/G/1, because we consider only those states\nleft behind by a departure of the M/G/1.\nAnswer: Ifj<i−1, thenPij=0.\nForj≥i−1, where i/negationslash=0,w eh a v e\nPij=P{jjobs at time of next departure |ijobs at time of current departure }\n=P{j−i+1arrivals during a job’s service time, S}\n=/integraldisplay\nxP{j−i+1arrivals during time x}·P{service time of job =x}\n=/integraldisplay\nxe−λx(λx)j−i+1\n(j−i+1 ) !fS(x)dx.\nObserve that P0j=P1jbecause we have to wait for an arrival before the next departure\ncan occur. When that new arrival departs, there will be a probability, P1j, of transitioning\nto state j(where state jdenotes the state of having jjobs left behind by the last\ndeparture).\n452 m/g/ 1transform analysis\nNow that we have Pijfor the embedded DTMC, we can get πembed\ni from the stationary\nequations:\nπembed\nj=/summationdisplay\niπembed\niPij,/summationdisplay\niπembed\ni=1 (26.2)\nUnfortunately, given the complexity of the expressions for Pij, trying to solve these\nsimultaneous equations does not seem very appealing. What we really want is a way\nto determine\n/hatwideN(z)=∞/summationdisplay\ni=0πM/G/1\ni·zi=∞/summationdisplay\ni=0πembed\ni·zi(26.3)\nwithout having to ever ﬁgure out a closed-form formula for πembed\ni.\nA New Idea!\nHere is how to achieve this. We will express\nπj=πM/G/1\nj=πembed\nj=P{M/G/1 departure leaves jjobs in system }\nin terms of\naj=P{jarrivals during S}.\nOnce we do this, we will be able to express\n/hatwideN(z)= z-transform of number of jobs in system as seen by departure\nin terms of\n/hatwideAS(z)= z-transform of number of jobs which arrive during service S.\nThis is good because we already know /hatwideAS(z)from ( 25.9), which will allow us to skip\nover actually deriving the πj’s. We will follow three steps:\nStep 1: Express πjin terms of aj,\nP0j=aj\nPij=aj−i+1,1≤i≤j+1\nwhere\naj=/integraldisplay∞\n0e−λx(λx)j\nj!·fS(x)dx.\nThus we have that\nπj=π0aj+j+1/summationdisplay\ni=1πiaj−i+1. (26.4)\n26.1 the z-transform of the number in system 453\nStep 2: Multiply every term of ( 26.4)b yzj, so that we can express /hatwideN(z)in terms of\n/hatwideAS(z).\nπj=π0aj+j+1/summationdisplay\ni=1πiaj−i+1\n∞/summationdisplay\nj=0πjzj=π0∞/summationdisplay\nj=0ajzj+∞/summationdisplay\nj=0j+1/summationdisplay\ni=1πiaj−i+1zj\n/hatwideN(z)=π0/hatwideAS(z)+∞/summationdisplay\ni=1∞/summationdisplay\nj=i−1πiaj−i+1zj\n=π0/hatwideAS(z)+∞/summationdisplay\ni=1πizi−1∞/summationdisplay\nj=i−1aj−i+1zj−i+1\n=π0/hatwideAS(z)+1\nz∞/summationdisplay\ni=1πizi∞/summationdisplay\nu=0auzu(where u=j−(i−1))\n=π0/hatwideAS(z)+1\nz/parenleftBig\n/hatwideN(z)−π0/parenrightBig\n·/hatwideAS(z)\nz/hatwideN(z)=zπ0/hatwideAS(z)+/hatwideN(z)/hatwideAS(z)−π0/hatwideAS(z)\n/hatwideN(z)=(z−1)π0/hatwideAS(z)\nz−/hatwideAS(z)\nAll that is left is to determine π0.\nQuestion: We already know that π0=1−ρ, where ρ=λE[S]is the fraction of time\nthat the server is busy. But suppose that you were working on a problem where you did\nnot know π0. What would you do then?\nAnswer: You could try to set z=1in the expression in Step 2 for /hatwideN(z)and then solve\nforπ0. Note that it is often the case when you do this that you need to use L’Hospital’s\nrule...sometimes repeatedly!\nFor this example in Step 2, you can immediately see that\n1 = lim\nz→1/hatwideN(z)=0\n0\n= lim\nz→1(z−1)π0/hatwideA/prime\nS(z)+π0/hatwideAS(z)\n1−/hatwideA/prime\nS(z)\n=π0\n1−λE[S]\n⇒π0=1−λE[S]=1−ρ.",6672
169-26.2 The Laplace Transform of Time in System.pdf,169-26.2 The Laplace Transform of Time in System,"454 m/g/ 1transform analysis\nSo we have ﬁnally\n/hatwideN(z)=/hatwideAS(z)(1−ρ)(z−1)\nz−/hatwideAS(z). (26.5)\nStep 3: Substitute in our known formula for /hatwideAS(z).\nRecall that from ( 25.9)\n/hatwideAS(z)=/tildewideS(λ−λz). (26.6)\nSubstituting this into Equation ( 26.5)w eh a v e\n/hatwideN(z)=/tildewideS(λ−λz)(1−ρ)(1−z)\n/tildewideS(λ−λz)−z. (26.7)\n26.2 The Laplace Transform of Time in System\nOur goal is to get /tildewideT(s), using the fact that we know /hatwideN(z). To do this, ﬁrst consider\nagain the equation we have seen so many times:\n/hatwideAS(z)=/tildewideS(λ−λz), (26.8)\nwhere ASis the number of Poisson arrivals within service time S. What we want is a\nresult about T.\nQuestion: Equation ( 26.8) holds for any r.v. S(review the derivation of ( 25.9)). What\nrandom variable would you like to substitute for S?\nAnswer: Let’s substitute TforSin (26.8):\n/hatwideAT(z)=/tildewideT(λ−λz) (26.9)\nEquation ( 26.9) equates the Laplace transform of T(what we want) to the z-transform\nofAT.\nQuestion: Is there a nicer name for AT?\nAnswer: ATis the number of arrivals during T, which is equivalently the number of\njobs in the system as seen by a departure!\nSo\nAT=N,\nwhere Nis the number of jobs seen by a departure. Hence,\n/tildewideT(λ−λz)=/hatwideAT(z)=/hatwideN(z). (26.10)\nSubstituting in Equation ( 26.7)f o r/hatwideN(z), into ( 26.10 ), we get\n/tildewideT(λ−λz)=/tildewideS(λ−λz)(1−ρ)(1−z)\n/tildewideS(λ−λz)−z. (26.11)\n26.2 the laplace transform of time in system 455\nWe now make a simple change of variables. Let\ns=λ−λz.\nz=1−s\nλ.\nThen ( 26.11 ) becomes\n/tildewideT(s)=/tildewideS(s)(1−ρ)/parenleftbigs\nλ/parenrightbig\n/tildewideS(s)−1+s\nλ.\nOr equivalently,\n/tildewideT(s)=/tildewideS(s)(1−ρ)s\nλ/tildewideS(s)−λ+s. (26.12)\nWe are done! Now we can differentiate ( 26.12 ) with respect to sto get all moments\nofT. This is done in Exercise 26.2. You will see that you need to apply L’Hospital’s\nrule twice when differentiating just to get the mean. So it is not so easy, but it is\nstraightforward.\nQuestion: How could we get the Laplace transform of TQ?\nAnswer: Observe\nT=S+TQ.\nSo\n/tildewideTQ(s)=/tildewideT(s)\n/tildewideS(s)=(1−ρ)s\nλ/tildewideS(s)−λ+s. (26.13)\nOne thing that may seem surprising is that the above expression for /tildewideTQ(s)does not in-\nvolveSe, the excess of S. The excess is in there – it just takes a few more steps to extract.\nRecall from ( 25.11 ) that the Laplace transform for the excess is\n/tildewiderSe(s)=1−/tildewideS(s)\nsE[S].\nWe can then express /tildewideTQ(s)in terms of/tildewiderSe(s)as follows:\n/tildewideTQ(s)=(1−ρ)s\nλ/tildewideS(s)−λ+s\n=1−ρ\nλ/parenleftBig/tildewideS(s)−1\ns/parenrightBig\n+1\n=1−ρ\nρ/parenleftBig/tildewideS(s)−1\nsE[S]/parenrightBig\n+1\n=1−ρ\n1−ρ/tildewiderSe(s)(26.14)",2804
170-26.3 Readings.pdf,170-26.3 Readings,,0
171-Chapter 27 Power Optimization Application.pdf,171-Chapter 27 Power Optimization Application,"456 m/g/ 1transform analysis\nWe will discuss some cool properties of ( 26.14 ) in Chapter 30, after we have covered\nsome scheduling results, which will provide insight into interpreting ( 26.14 ).\n26.3 Readings\nThis material in this chapter borrows from three excellent texts [ 110,149,45].\n26.4 Exercises\n26.1 M/H 2/1 Transform\nYou are given an M/G/1 queue where the job size, S, has an H2distribution:\nS∼/braceleftBigg\nExp(μ1) with probability p\nExp(μ2) with probability 1−p\n(a) Derive E[TQ].\n(b) Derive/tildewiderTQ(s).\n26.2 Variance of Response Time for the M/G/1\nDerive Var(TQ)for the M/G/1 by differentiating /tildewideTQ(s).\n26.3 z-Transform of NQ\nIn this chapter we derived /hatwideN(z), the z-transform of the number of jobs in\nsystem in an M/G/1. Suppose that we instead wanted /hatwiderNQ(z), the z-transform\nof the number of jobs queued. Show how to get that from /hatwideN(z).\n26.4 Distributional Little’s Law for M/G/1 and M/G/c\nConsider an M/G/1 queue with average arrival rate λ, where Ndenotes the\nnumber of jobs in the system and Tdenotes the response time. The Distribu-\ntional Little’s Law states that, for all integers k≥1,\nE[N(N−1)(N−2)···(N−k+1 ) ]= λkE/bracketleftbig\nTk/bracketrightbig\n(26.15)\n(a) Derive ( 26.15 ) from ( 26.10 ). [Hint: Differentiate.]\n(b) Does the law also hold if Nis replaced by NQandTbyTQ?\n(c) Now consider an M/G/c, with arrival rate λ, but look only at the queue\nportion of this system. What can you say about how the moments of NM/G/c\nQ\nare related to the moments of TM/G/c\nQ ?\nThe Distributional Little’s Law is very powerful in settings like the M/H 2/c,\nwhere we can derive moments of NQvia matrix-analytic methods, but have\nno easy way to get moments of TQ.\n26.5 M/M/2 Transform\nIn this chapter, we saw how to convert /hatwideN(z)to/tildewideT(s)for the M/G/1. In\nthis problem, you will apply this same technique to the M/M/2. First derive\n/hatwiderNQ(z)for the M/M/2. Then convert /hatwiderNQ(z)to/tildewiderTQ(s)using the approach in\nExercise 26.4. This same approach can be applied to derive the M/M/k waiting\ntime transform.",2123
172-27.1 The Power Optimization Problem.pdf,172-27.1 The Power Optimization Problem,"CHAPTER 27\nPower Optimization Application\nThis chapter combines and applies many analytical techniques we have studied thus\nfar (Renewal-Reward, general transform analysis, and M/G/1 response time analysis)toward analyzing the problem of power management of a single server. The goal is\nto understand when a server should be turned off to save on power (sometimes called\n“power napping”) and when it should be left on.\nIn Section 27.1 we provide background on powering a server and state the speciﬁc\npower optimization problem that we address. To solve this problem, we ﬁrst need to\ndevelop two more analysis topics.\nThe ﬁrst topic is busy period analysis for the M/G/1. We have touched on busy periods\nin the exercise sections of prior chapters, but in Section 27.2, we go into much more\ndepth in describing busy periods, including different types of busy periods and the\nLaplace transform of the busy period.\nThe second topic is the analysis of an M/G/1 with setup time , where the ﬁrst job starting\na busy period incurs an extra delay, known as the setup time. Setup times have also\nbeen discussed in earlier exercises; however, in Section 27.3 we consider their effect\non the M/G/1.\nFinally, in Section 27.4, we combine the analyses in Sections 27.2 and27.3 to solve\nour power optimization problem.\n27.1 The Power Optimization Problem\nConsider the operation of a single-server system, speciﬁcally an M/G/1/FCFS queue.\nThus far, we have only been concerned about the response time of the system. We nowdiscuss the power usage. We distinguish between three states that a server can be in:\nON: The server is on and is busy serving a job. The server burns power at a rate of\nPon.\nIDLE: The server is on and available, but is currently idle. The server burns power at\na rate of Pidle.\nOFF: The server is off.\nIn the ON state, a server might burn power at a rate of 240 Watts1(i.e.,Pon= 240 ). In\nthe OFF state, a server burns 0 Watts.\n1All the numbers given here involving power measurements and setup costs are based on measurements in our\ndata center lab at Carnegie Mellon University during the year 2011.\n457\n458 power optimization application\nQuestion: At what rate would you guess that power is burned when the server is in the\nIDLE state?\nAnswer: Surprisingly, the answer is that Pidleis almost as much as Pon.A nI D L Es e r v e r\ntypically burns power at a rate of about Pidle= 180 Watts. Thus a server running at\nloadρburns power at an average rate of\nE[Power]=ρ·240Watts+( 1−ρ)·180Watts.\nBecause this seems very wasteful when ρis low, the obvious idea is to turn off the\nserver when it is idle.\nQuestion: What is wrong with turning off a server when it is idle?\nAnswer: There is a huge setup cost to turning a server back on.\nThesetup cost is the cost required to transition a server from the OFF state to the ON\nstate. ( Note: there is no cost for transitioning from the IDLE state to the ON state).\nThe setup cost consists of two components: a time component and a power component.\nThe exact setup time varies depending on the type of application and server. However,a setup time of 200 seconds or so is not at all uncommon for most data center servers,and it can be much higher. The second component is power: During the entire setuptime, the server is burning power at a rate of\nPon.\nGiven the setup cost, it is no longer obvious that one wants to turn off the server when\nit becomes idle. From the perspective of solely minimizing response time, one neverwants to turn off the server. From a power perspective, if the setup cost is not too highrelative to mean job size, one may want to turn off the server when it goes idle.\nThe power optimization problem aims to resolve this power/response time tradeoff.\nSpeciﬁcally, we would like to maximize the Performance-per-Watt (Perf/W):\nPerformance-per-Watt\n=1\nE[Power]·E[Response Time ]\nThat is, we want to minimize both mean response time and mean power.\nIn this chapter, we do not solve the general power management problem. However, we\ndo analyze and compare two simple policies:\nON/OFF – Under this policy, the server is switched to the OFF state immediately\nwhen it goes idle. When a job arrives, the server is then turned on, involving a setupcost.\nON/IDLE – Under this policy, the server is never turned off. Hence it moves between\nthe ON state and the IDLE state.\nOur goal is to determine the parameter regime (in terms of\nρand setup cost) under\nwhich the ON/OFF policy is superior to the ON/IDLE policy with respect to Perf/W.",4560
173-27.2 Busy Period Analysis of MG1.pdf,173-27.2 Busy Period Analysis of MG1,"27.2 busy period analysis of m/g/ 1 459\n27.2 Busy Period Analysis of M/G/1\nAn important component in overall power usage is understanding how long the server\nis busy. In the case of a single-server system, the busy period is deﬁned to be the time\nfrom when the server ﬁrst becomes busy until the server ﬁrst goes idle. If one looks\nat an M/G/1 over time, one can see that the M/G/1 alternates between being in the“busy” state and the “idle” state. We use\nBto denote the length of a single busy period.\nThroughout, we assume that the average arrival rate is λ, that job sizes are denoted by\nthe r.v. S, and that load is ρ=λE[S].\nQuestion: What is the distribution of the length of an idle period?\nAnswer: The length of an idle period is distributed Exp (λ), because the idle period is\njust the time until an arrival occurs, see Figure 27.1.\nbusy busy busy\nidle idleB B B\nExp( λ) Exp( λ)\nFigure 27.1. Busy and idle periods.\nBusy periods are hard to describe because they are recursive . Consider a single busy\nperiod, started by a job, j, of size S. If no new arrivals come in while jruns, then the\nlength of the busy period is just S. However, any new arrival that occurs while jruns\nwill need to run once jcompletes and will create the opening for more new arrivals to\noccur while it runs. Speciﬁcally, if a single job j/primearrives before jcompletes, then the\nlength of the busy period is S+B, where Sis the time for job jandBis the busy\nperiod created by job j/prime. Likewise, if two jobs j/primeandj/prime/primearrive before jcompletes,\nthen they each start their own busy period. In this case the length of the busy period\nisS+B1+B2, where B1⊥B2andBi∼B,i=1,2. The job that starts the initial\nbusy period is often referred to as the parent , and the jobs that arrive during a busy\nperiod are often called the offspring . Each offspring can be viewed as starting its own\nbusy period. It may look like a single busy period never ends! But we know that is not\ntrue, because the system is idle 1−ρfraction of the time.\nWhen we talk about the busy period, B, we implicitly assume that all jobs during the\nbusy period come from the same job size distribution. However, in general, one can\nalso talk about a busy period started by a ﬁxed amount of work, x, which is present\nwhen the server ﬁrst turns on, where all future jobs have size S. The duration of such\na busy period is denoted by B(x).\nOur ﬁrst goal is to derive /tildewideB(s), the Laplace transform of B. It turns out that to fully\ndeﬁne B, we need to ﬁrst look at B(x).\n460 power optimization application\nQuestion: How can we write a general expression for B(x)? Feel free to use Bwithin\nyour expression.\nHint: LetAxdenote the number of Poisson arrivals that occur during time x.\nAnswer:\nB(x)=x+Ax/summationdisplay\ni=1Bi (27.1)\nwhere the Bi’s are independent and are each distributed identically to B. That is, we\nstart with the job of size xand then each arrival during that time xcan be thought of\nas starting its own busy period, where that busy period is a busy period started by an\narbitrary job of random size S.\nObserve an important property of busy periods:\nB(x+y)=B(x)+B(y), (27.2)\nmeaning that a busy period started by x+ywork can be viewed as a busy period\nstarted by xwork, followed by a busy period started by ywork.\nEquation ( 27.1) does not look like it is helping us get any closer to getting B, but it is.\nThe next step is to derive the Laplace transform of B(x).\nQuestion: How can we use ( 27.1) to derive an expression for /tildewideB(x)(s)?\nHint: Use the fact that we know /hatwiderAx(z).\nAnswer: Taking the Laplace transform of ( 27.1), we have\n/tildewideB(x)(s)=/tildewidex·⎛\n⎝/tildewiderAx/summationdisplay\ni=1Bi⎞⎠\n=e\n−sx·/hatwiderAx/parenleftBig\n/tildewideB(s)/parenrightBig\n(by Theorem 25.12 ).\nNow we can use our knowledge of /hatwiderAx(z), from ( 25.1) to get\n/hatwiderAx/parenleftBig\n/tildewideB(s)/parenrightBig\n=e−λx(1−/tildewideB(s)).\nAnd so,\n/tildewideB(x)(s)=e−sx·e−λx(1−/tildewideB(s))=e−x(s+λ−λ/tildewideB(s)). (27.3)\nEquation ( 27.3) provides an expression for the Laplace transform of B(x). The next\nstep is to uncondition , by integrating over all x, to turn ( 27.3) into an expression for\nthe Laplace transform of Bas follows:\n/tildewideB(s)=/integraldisplay∞\n0/tildewideB(x)(s)fS(x)dx=/integraldisplay∞\n0e−x(s+λ−λ/tildewideB(s))fS(x)dx\nQuestion: Is there a nicer way of writing the above expression?\n27.2 busy period analysis of m/g/ 1 461\nAnswer: Yes,\n/tildewideB(s)=/tildewideS/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\n. (27.4)\nEquation ( 27.4) deﬁnes the transform of Bin terms of itself. Unfortunately, this is the\nbest we can do. Fortunately, this is sufﬁcient to get the moments of B. We do this next.\nThe ﬁrst moment, E[B], is given by\nE[B]=−/tildewideB/prime(s)|s=0=−/tildewideS/prime/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0·/parenleftBig\n1−λ/tildewideB/prime(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle/vextendsingle\ns=0\n=−/tildewideS/prime(0 +λ−λ(1))(1 + λE[B])\n=−/tildewideS/prime(0)(1 + λE[B])\n=E[S]( 1+ λE[B]).\nSolving for E[B], we get\nE[B]=E[S]\n1−λE[S]=E[S]\n1−ρ. (27.5)\nTo get the second moment, we differentiate /tildewideB/prime(s)again and evaluate the result at\ns=0. This yields\nE/bracketleftbig\nB2/bracketrightbig\n=/tildewideB/prime/prime(s)|s=0=d\nds/bracketleftBig\n/tildewideS/prime/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig/parenleftBig\n1−λ/tildewideB/prime(s)/parenrightBig/bracketrightBig/vextendsingle/vextendsingle/vextendsingle\ns=0\n=/tildewideS/prime/prime(0)/bracketleftBig\n1−λ/tildewideB/prime(0)/bracketrightBig2\n+/tildewideS/prime(0)/parenleftBig\n−λ/tildewideB/prime/prime(0)/parenrightBig\n=E/bracketleftbig\nS2/bracketrightbig/bracketleftbig\n1+λE[B]/bracketrightbig2+λE[S]E/bracketleftbig\nB2/bracketrightbig\n.\nSubstituting E[B]=E[S]\n1−ρand solving for E[B2]we get\nE/bracketleftbig\nB2/bracketrightbig\n=E[S2]\n(1−ρ)3. (27.6)\nQuestion: What role does the variability of Splay in the mean busy period duration,\nE[B], and how does this compare to its role in mean response time, E[T]?W h yi s\nthere a difference?\nAnswer: The variability of Splays a key role in E[T]due to the Inspection Paradox\nand the effect of E[Se](see Chapter 23). By contrast, E[B]does not involve an E[Se]\ncomponent, because there are no jobs already in service when the busy period starts;\nthus there is no “excess” to contend with. The variability of Bis naturally affected by\nthe variability of S, because Bis a sum of S’s, and in general the ith moment of Bis\ndependent on the ith moment of S. By contrast, the ith moment of Tis dependent on\nthe (i+1)th moment of S.\nNow that we understand standard busy periods, consider how we can modify this\nanalysis to derive different types of busy periods. For example, let BWdenote the",6953
174-27.3 MG1 with Setup Cost.pdf,174-27.3 MG1 with Setup Cost,"462 power optimization application\nlength of a busy period started by Wwork, where Wis a random variable and the jobs\nin the busy period have size S.\nQuestion: What is the transform of BW?\nAnswer: Starting with ( 27.3), we have that\n/tildewideB(x)(s)=e−x(s+λ−λ/tildewideB(s))\n/tildewidestBW(s)=/integraldisplay∞\n0/tildewideB(x)(s)fW(x)dx\n=/integraldisplay∞\n0e−x(s+λ−λ/tildewideB(s))fW(x)dx\n=/tildewiderW/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\n.\nQuestion: What is the mean length of BW?\nAnswer:\nE[BW]=E[W]\n1−ρ. (27.7)\nThis result follows from the following calculation:\nE[BW]=−/tildewidestBW/prime(s)/vextendsingle/vextendsingle/vextendsingle\ns=0=−/tildewiderW/prime/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle\ns=0·/parenleftBig\n1−λ/tildewideB/prime(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle\ns=0\n=−/tildewiderW/prime(0 +λ−λ(1))(1 + λE[B])\n=−/tildewiderW/prime(0)(1 + λE[B])\n=E[W]( 1+ λE[B])\nSubstituting E[B]=E[S]\n1−ρ, we get E[BW]=E[W]\n1−ρ.\nIntuitively, ( 27.7) can be viewed as the size of the job (or work) starting the busy period,\nE[W], scaled up by a factor,1\n1−ρ, related to the load of jobs that make up the busy\nperiod. The higher the load, ρ=λE[S], the more jobs that arrive during Wand the\nlonger the busy period.\n27.3 M/G/1 with Setup Cost\nWe now switch gears and consider a different problem: How does setup cost affect\nresponse time?\nSuppose that the ﬁrst job to start each busy period experiences an initial setup time, I,\nbefore its service is started, where Iis a continuous random variable. Here Idenotes\nthe time required to “initialize” or power up the server, switching it from being in the\nOFF state to the ON state. Again we are dealing with an M/G/1 with job sizes denotedby r.v.\nS.\n27.3 m/g/ 1with setup cost 463\nOur goal is to derive the Laplace transform of Tsetup\nQ, where Tsetup\nQis the delay experi-\nenced by an arrival into an M/G/1 with setup cost I.\nA few remarks before diving into the derivation: First, observe that the setup cost, I,\naffects more than just the job that starts the busy period; many jobs could arrive during\nthe setup time itself, all of which have to wait for the machine to ﬁnish powering up.\nQuestion: What is the mean duration of a busy period in an M/G/1 with setup I?\nAnswer: We can think of the busy period, Bsetup, as a busy period that is started by\ntotal work, I+S, where Iis the setup time and Sis the size of the job starting the\nbusy period. Then by ( 27.7), we have\nE[Bsetup]=E[I]+E[S]\n1−ρ. (27.8)\nEquation ( 27.8) can also be viewed as a sum of two terms, where the ﬁrst is a busy\nperiod started by the setup time and the second is a standard M/G/1 busy period, which\nstarts after the setup busy period is over. Looking at things that way, we have\nE[Bsetup]=E[I]\n1−ρ+E[B].\nQuestion: In an M/G/1 with setup I, what fraction of time is the server busy? Here\n“busy” includes setting up, because that too requires power.\nAnswer: Clearly, the answer is no longer simply ρ. Letρsetupdenote the fraction of\ntime that the server is busy for the M/G/1 with setup I. To determine ρsetup, we think in\nterms of renewals. The server is busy forE[I]+E[S]\n1−ρtime (where ρ=λE[S]), followed\nby a period of length1\nλof being idle, and then the cycle repeats itself. By the Renewal-\nReward theorem (Theorem 23.4), it sufﬁces to look at the fraction of time that the\nserver is busy during one cycle:\nρsetup=E[Busy during cycle ]\nE[Cycle time ]=E[I]+E[S]\n1−ρ\nE[I]+E[S]\n1−ρ+1\nλ\n=λE[I]+ρ\nλE[I]+ρ+1−ρ\n=λE[I]+ρ\nλE[I]+1. (27.9)\nWe are now ready to derive /tildewideTsetup\nQ(s). We follow the same approach used for the M/G/1\nwithout setup, by looking at the embedded DTMC, as in Chapter 26. Again πidenotes\nthe probability that the last departure left behind ijobs, which by PASTA is equal to\nthe time-average probability that there are ijobs. There is only one difference: The\ntransition probabilities for leaving the 0 state must reﬂect the initial cost.\nLet\naj=P{jarrivals in Sseconds}\n464 power optimization application\nand let\na/prime\nj=P{jarrivals in S+Iseconds}.\nThen\nPij=aj−i+1,fori>0andP0j=a/primej.\nThus we can write\nπj=π0a/primej+j+1/summationdisplay\ni=1πiaj−i+1\n∞/summationdisplay\nj=0πjzj=π0∞/summationdisplay\nj=0a/primejzj+∞/summationdisplay\nj=0j+1/summationdisplay\ni=1πiaj−i+1zj\n/hatwideNsetup(z)=π0/hatwideAS+I(z)+1\nz∞/summationdisplay\ni=1πizi∞/summationdisplay\nj=i−1aj−i+1zj−i+1\n=π0/hatwideAS(z)/hatwideAI(z)+1\nz/parenleftBig\n/hatwideNsetup(z)−π0/parenrightBig\n/hatwideAS(z)\n⇒/hatwideNsetup(z)=π0z/hatwideAS(z)/hatwideAI(z)−/hatwideAS(z)\nz−/hatwideAS(z). (27.10)\nWe now continue to follow the approach in Chapter 26to convert/hatwideNsetup(z)to/tildewideTsetup(s)\nby following the usual sequence of observations:\n/hatwideAS(z)=/tildewideS(λ(1−z)),for any S\n⇒/hatwideATsetup(z)=/tildewideTsetup(λ(1−z)),setting S=Tsetup\n⇒/hatwideNsetup(z)=/tildewideTsetup(λ(1−z)),sinceATsetup=Nsetup\n⇒/tildewideTsetup(λ(1−z)) =π0z/hatwideAS(z)/hatwideAI(z)−/hatwideAS(z)\nz−/hatwideAS(z),by (27.10 )\n⇒/tildewideTsetup(λ(1−z)) =π0z/tildewideS(λ(1−z))/tildewideI(λ(1−z))−/tildewideS(λ(1−z))\nz−/tildewideS(λ(1−z))\n⇒/tildewideTsetup(s)=π0(1−s/λ)/tildewideS(s)/tildewideI(s)−/tildewideS(s)\n1−s/λ−/tildewideS(s),vias=λ(1−z)\n=π0(λ−s)/tildewideS(s)/tildewideI(s)−λ/tildewideS(s)\nλ−s−λ/tildewideS(s)\nHence,\n/tildewideTsetup\nQ(s)=/tildewideTsetup(s)\n/tildewideS(s)=π0·λ−(λ−s)/tildewideI(s)\ns−λ+λ/tildewideS(s). (27.11)",5549
175-27.4 Comparing ONIDLE versus ONOFF.pdf,175-27.4 Comparing ONIDLE versus ONOFF,"27.4 comparing on/idle versus on/off 465\nQuestion: What is π0?\nAnswer: From ( 27.9), we have\nπ0=1−ρsetup=1−λE[S]\n1+λE[I]. (27.12)\nSubstituting π0into ( 27.11 ) yields\n/tildewideTsetup\nQ(s)=1−λE[S]\n1+λE[I]·λ−(λ−s)/tildewideI(s)\ns−λ+λ/tildewideS(s)\n=(1−ρ)s\ns−λ+λ/tildewideS(s)·λ−(λ−s)/tildewideI(s)\n(1 +λE[I])s\n=/tildewiderTQM/G/1(s)·λ−(λ−s)/tildewideI(s)\n(1 +λE[I])s. (27.13)\nTo get the mean, we differentiate ( 27.13 ) and also apply L’Hospital’s rule to get:\nE[TQ]setup=λE[S2]\n2(1−ρ)+2E[I]+λE[I2]\n2(1 + λE[I]). (27.14)\nQuestion: What is the effect of setup when the setup, I, is Exponentially distributed?\nAnswer: In the case of I∼Exp(α),w eh a v e E[I2]=2(E[I])2, which reduces to\nE[TQ]setup=E[TQ]+E[I]. (27.15)\nThus, in the case where I∼Exp(α), the setup cost is just an additive cost.\nThe delay for the M/G/1 with setup in ( 27.13 ) and (27.14) can be written in terms of\ntwo distinct components, the ﬁrst involving delay for an M/G/1 without setup and the\nsecond involving just some setup-related terms. It is really neat (and rare) when results\ndecompose in such a pretty way. Such results are referred to as decomposition results.\n27.4 Comparing ON/IDLE versus ON/OFF\nWe are now ready to derive the mean power consumption and mean response time for\nthe ON/OFF and ON/IDLE power management policies.\nThe analysis of ON/IDLE is simple. The response time is just that of an M/G/1 queue.\nThe power is Ponwhen the server is busy and Pidlewhen it is idle. Hence we have\nE[Power]ON/IDLE=ρPon+( 1−ρ)Pidle (27.16)\nE[T]ON/IDLE=λE[S2]\n2(1−ρ)+E[S] (27.17)\nwhere ρ=λE[S].\nThe analysis of ON/OFF is more involved, but at this point we have all the computations\nwe need. With respect to power, the server might be in one of three states: ON, inSETUP, or OFF. When the server is ON or in SETUP, the power used is\nPon. Otherwise\n466 power optimization application\nthe power is zero. Fortunately, we already know the fraction of time that the server is\nbusy from ( 27.9). Hence we have\nE[Power]ON/OFF=ρsetup·Pon=λE[I]+ρ\nλE[I]+1·Pon, (27.18)\nwhere ρ=λE[S]andE[I]represents the expected setup time.\nThe response time under ON/OFF is just the response time for an M/G/1 with setup,\nwhich we have from ( 27.14 ), namely\nE[T]ON/OFF=λE[S2]\n2(1−ρ)+2E[I]+λE[I2]\n2(1 + λE[I])+E[S]. (27.19)\nThese two formulas allow us to compare the ON/IDLE and ON/OFF policies with\nrespect to the following Perf/W metric:\nPerformance-per-Watt =1\nE[Power]·E[Response Time ].\nTable 27.1 compares our policies for a range of values of ρ=0.1,0.3,0.5,0.7,0.9\nandE[I]=1\n8,1\n4,1\n2,1,2,4,8. Throughout, we assume E[S]=1 ,E[S2]=2 0 , and\nE[I2]=5E[I]2(there is no particular reason for choosing these values).\nTable 27.1 shows the ratio of Perf/W under ON/IDLE versus that under ON/OFF.\nWhen the ratio exceeds 1, then the ON/IDLE policy is better (has higher Perf/W), and\nwhen the ratio is less than 1, then the ON/OFF policy is better. Looking at the table, wesee that, under low load and low setup time, the ON/OFF policy is about 6 times better(ratio is\n0.152), whereas under low load and high setup time, the ON/IDLE policy is\nalmost 5 times better. It makes sense that, as the setup time increases, ON/IDLE will\nbecome preferable, because turning OFF the server becomes costly.\nTable 27.1. ThePerformance-per-WattON/IDLE\nPerformance-per-WattON/OFFratio\nE[I]=1\n8E[I]=1\n4E[I]=1\n2E[I]=1 E[I]=2 E[I]=4 E[I]=8\nρ=0.1 0.152 0.177 0.231 0.361 0.705 1.708 4.720\nρ=0.3 0.404 0.445 0.528 0.702 1.085 1.964 3.962\nρ=0.5 0.612 0.652 0.726 0.866 1.130 1.645 2.674\nρ=0.7 0.787 0.815 0.865 0.950 1.092 1.340 1.803\nρ=0.9 0.935 0.945 0.963 0.990 1.032 1.099 1.219\nWhen the ratio is <1, the ON/OFF policy is superior.\nWhat is more surprising is the effect of load. One would expect that increasing theload makes ON/OFF perform worse, relative to ON/IDLE, because under high load itdoes not pay to turn the server OFF and suffer the setup cost. This intuition is true,\nprovided that the setup cost is not too high. However, when the setup cost is high, the\nreverse trend seems to happen – namely as the load increases, ON/IDLE’s superiorityover ON/OFF decreases. This could be due to the fact that the values of\nE[T]and\nE[Power]are just so high under both policies when both setup costs and load are high\nthat the ratios of the policies become closer to each other.",4386
176-27.5 Readings.pdf,176-27.5 Readings,,0
177-27.6 Exercises.pdf,177-27.6 Exercises,"27.6 exercises 467\n27.5 Readings\nThe formulas ( 27.13 ) and ( 27.14 ) for the M/G/1 with setup time were ﬁrst obtained in\n[182]. Setup time is also known as exceptional ﬁrst service in the queueing literature.\nThe material in this chapter, on the M/G/1 with setup times, was applied by a former\nstudent, Brian Gold, in the well-known paper, “PowerNap: Eliminating Server IdlePower” [ 124].\nAlthough this chapter only dealt with a single-server queue, it is natural to ask how\npolicies like ON/OFF might perform in a multi-server system, like the M/M/k system,for example. Surprisingly, analyzing the M/M/k with setup cost is a very difﬁcultproblem. The exact analysis is not yet known, but approximations exist in [ 68].\n27.6 Exercises\n27.1 Review of Formulas\nThroughout, assume that you have an M/G/1 (FCFS) queue, except in part (j),\nwhere M/M/1 is stated. The average arrival rate is λ, andSrepresents job size.\nTen quantities are given, labeled (a) through (j). Many of these quantities areequivalent. Your job is to form them into equivalence classes.\n(a)\nE[AT]: mean number of arrivals during response time T\n(b)E[AS]: mean number of arrivals during time S\n(c)E[N]: mean number of jobs in the system\n(d)E[TQ]: mean queueing time\n(e)ρ: load\n(f)E[W]: mean work in system\n(g)λ·E[T]: product of arrival rate and mean response time\n(h)E[N]−E[NQ]: mean number of jobs in service\n(i)E[B]: mean duration of busy period\n(j)E[TM/M/1]: mean response time in M/M/1 queue\n27.2 Server Vacations\nImagine you are running a shop with a lazy server. The server serves customersin an M/G/1 queue when there are customers in the shop. However, when the\nshop is empty, the server walks next door to get coffee. The time to get coffeeis denoted by\nVand is known as a server vacation . When the server returns\nfrom getting coffee, there may or may not be new customers queued, waiting\nfor the server. If there is no one waiting when the server returns, the server goes\nto get another cup of coffee, and this continues until the server ﬁnds someone\nin the queue. Assume that “vacation times” are i.i.d. instances of V.\nLetTM/G/1/Vacdenote the response time in an M/G/1 with Vacations. Prove\nthe following decomposition result:\n/tildewideTM/G/1/Vac(s)=/tildewideTM/G/1(s)·/tildewideVe(s)\nwhere Veis the excess of V. [Hint: Follow the derivation of M/G/1/setup in\nthis chapter.]\n468 power optimization application\n27.3 Shorts-Only Busy Period\nConsider an M/G/1 queue where job sizes have p.d.f. f(·)and c.d.f. F(·).\nDeﬁne a job to be “short” if its size is <tand “long” otherwise. Suppose\nthat short jobs have preemptive priority over long ones. That is, whenever\nthere is a short job in the system, there can never be a long job in service. We\ndeﬁne a “short busy period” to be a busy period started by a short job, con-\ntaining only short jobs. Derive the mean and Laplace transform of a short busyperiod.\n27.4 ON/OFF for M/M/\n∞\nConsider a very large data center, comprising tens of thousands of servers, as\nis common in companies like Google, Facebook, and Microsoft. Such a datacenter might be approximated by an M/M/\n∞system, where there is no queue\nand all jobs are immediately served (see Section 15.2). To save power, when a\nserver goes idle, we assume that it is immediately shut off. When a job arrives,\nit needs to turn on a server, requiring setup time I, where I∼Exp(α).I fa\nserver, s1, is in setup mode and another server, s2, becomes free, then the job\nwaiting for s1goes to s2. At this point, server s1is shut off.\nThe effect of setup times for the M/M/ ∞was ﬁrst derived in [ 68], where\nthe following beautiful decomposition property was observed. Here λis the\noutside arrival rate, μis the service rate at each server, and R=λ\nμ.\nP{iservers are busy & jservers are in setup }\n=P{iservers are busy }·P{jservers are in setup }(27.20)\nwhere\nP{iservers are busy }=e−R·Ri\ni!(27.21)\nP{jservers in setup }=Cj/productdisplay\n/lscript=1λ\nλ+/lscriptα(27.22)\nThat is, the number of busy servers follows a Poisson distribution with mean\nR, just as in an M/M/ ∞without setup, and is independent of the number of\nservers in setup.\nIn this problem, you will verify the above result:\n(a) Draw the CTMC for the M/M/ ∞with setup, where the states are (i, j)as\ndeﬁned above.\n(b) Write the balance equation for state (i,j)and verify that the above formulas\nsatisfy the balance equation.\n(c) Equation ( 27.21 ) makes intuitive sense because the long-run number of\nbusy servers should not be affected by the fact that servers ﬁrst need a\nsetup; hence a Poisson (R)distribution is reasonable. What is the intuition\nfor equation ( 27.22 )? [Hint: Assume that there are always exactly Rservers\nthat are busy and draw a birth-death chain representing the number of\nservers that are in setup, given that assumption.]\n27.6 exercises 469\n27.5 Number of Jobs Served during M/M/1 Busy Period\nLetNBdenote the number of jobs served during an M/M/1 busy period.\n(a) Derive E[NB].\n(b) Derive the z-transform: /hatwiderNB(z). Determine the ﬁrst and second moments\nofNBby carefully differentiating your transform.\n27.6 Number of Jobs Served during M/G/1 Busy Period\nLetNBdenote the number of jobs served during an M/G/1 busy period. Derive\nthe z-transform: /hatwiderNB(z). Determine the ﬁrst and second moments of NBby\ncarefully differentiating your transform.\n27.7 Number of Jobs Served during M/G/1 Busy Period with Setup Time\nThis problem builds on Exercise 27.6. Consider an M/G/1 system where the\nserver shuts off whenever it goes idle and where there is a generally distributed\nsetup time, denoted by I, needed to turn on a server if an arrival ﬁnds the\nserver off. Let Nsetup\nBdenote the number of jobs served during a busy period\nof this M/G/1/setup system. Derive the z-transform:/hatwideNsetup\nB(z). Then derive its\nmean,E/bracketleftbig\nNsetup\nB/bracketrightbig\n, and provide intuition for this result.\nIn your derivations, be careful to distinguish between Nsetup\nB andNB. Both\nrefer to the number of jobs served during a busy period, but the former is\na busy period in an M/G/1/setup, whereas the latter is a busy period in an\nM/G/1.\n27.8 A New Power-Saving Policy: DelayedOff\nThis problem builds on Exercise 27.7. Anshul suggests the following power-\nsaving policy for an M/G/1 system. When the server becomes idle, rather than\nturning off the server immediately, we set a timer of duration twait. The server\nidles until either the timer goes off, in which case the server is shut off, or until\nthere is a new arrival, in which case the server resumes running. The goal of\nthis policy, called DelayedOff , is to obviate the setup cost by not turning off\nthe server every time that it goes idle.\nYour job is to evaluate the DelayedOff policy, and to determine how much\npower is saved over policies like ON/OFF and ON/IDLE and what the optimal\ntwaitconstant should be. Here are the parameters you should assume: The\nserver consumes power at rate 240 Watts when on, 180 Watts when idle, and 0\nWatts when off. Arrivals occur with average rate λ. When an arrival ﬁnds the\nserver off, it requires a setup cost to get it on. The setup time is denoted by the\ngeneral random variable I. Power is consumed at a rate of 240 Watts during\nthe entire period I. In expressing your solution you may use ρ=λE[S]or\nρsetup=λE[I]+ρ\nλE[I]+1.\n(a) Derive mean response time, E[T], for the DelayedOff policy.\n(b) Derive E[Power]for the DelayedOff policy.\n(c) Which value of twaitminimizes E[T]?\n(d) Which value of twaitminimizes E[Power]?\n(e) Does the DelayedOff policy make sense for the M/G/1 queue?\nThe DelayedOff policy ends up being very powerful in multi-server systemswith the appropriate routing, see [ 67].\n470 power optimization application\n27.9 ON/OFF for M/M/1\n[This is a repeat of Exercise 15.10 .] The analysis of the ON/OFF policy\nin this chapter was based on using transforms. For this problem, we revisit\nthe ON/OFF policy, this time for an M/M/1, with average arrival rate λand\nservice rate μ, where the setup time is distributed as Exp (α). This time, the\napproach is to set up a Markov chain for the system and derive the following\nquantities:\n(a) limiting probabilities for all states\n(b) limiting probability that the number of jobs in the system exceeds k\n(c) mean response time\nFor each of these quantities, compare with the case of an M/M/1 without setuptime.",8478
178-Part VII Smart Schedulingin the MG1.pdf,178-Part VII Smart Schedulingin the MG1,"PART VII\nSmart Scheduling\nin the M/G/1\nPartVIIis dedicated to scheduling.\nScheduling is an extremely important topic in designing computer systems, manufac-\nturing systems, hospitals, and call centers. The right scheduling policy can vastly reduce\nmean response time without requiring the purchase of faster machines. Scheduling canbe thought of as improving performance for free . Scheduling is also used to optimize\nperformance metrics other than mean response time, such as “fairness” among users,\nand to provide differentiated levels of service where some class of jobs is guaranteed\nlower mean delay than other classes.\nStochastic scheduling analysis, even in the case of the M/G/1 queue, is not easy and is\nomitted from most textbooks. A notable exception is the 1967 Conway, Maxwell, andMiller book, Theory of Scheduling [45], which beautifully derives many of the known\nscheduling analyses.\nIn this part, we study scheduling in the M/G/1 queue, where\nGis continuous with ﬁnite\nmean and variance. We are interested in mean response time, the transform of response\ntime, and other metrics like slowdown and fairness. Throughout we are interested in\nthe effects of high variability in job size distribution.\nScheduling policies can be categorized based on whether the policy is preemptive or\nnon-preemptive. A policy is preemptive if a job may be stopped partway through its\nexecution and then resumed at a later point in time from the same point where it was\nstopped (this is also called preemptive-resume ). A policy is non-preemptive if jobs are\nalways run to completion. Scheduling policies can be differentiated further based on\nwhether the policy assumes knowledge of the job sizes.\nThe chapters are organized as follows. Chapter 28covers the different performance\nmetrics commonly used in evaluating scheduling policies. Chapter 29considers\nnon-preemptive scheduling policies that do not make use of job size. Examples are First-\nCome-First-Served, RANDOM, and Last-Come-First-Served. Chapter 30considers\npreemptive scheduling policies that do not make use of job size. Examples includeProcessor-Sharing, Preemptive-Last-Come-First-Served, and Foreground-Backgroundscheduling (also known as Least-Attained-Service). Chapter 31considers non-\npreemptive policies that make use of size. These include Shortest-Job-First and non-preemptive priority queues. Chapters 32and33consider preemptive policies that make\nuse of size. These include Preemptive-Shortest-Job-First and Shortest-Remaining-Processing-Time. Also included are preemptive priority queues.\n471",2597
179-Chapter 28 Performance Metrics.pdf,179-Chapter 28 Performance Metrics,,0
180-28.2 Commonly Used Metrics for Single Queues.pdf,180-28.2 Commonly Used Metrics for Single Queues,"CHAPTER 28\nPerformance Metrics\nThis is a very short chapter that explains some performance metrics that will be used\nin evaluating the different scheduling policies that we will study in this part. In ourdiscussion below, we will be assuming an open system with some arbitrary outside\narrival process.\n28.1 Traditional Metrics\nWe have already been using the following traditional performance metrics:\nE[T]:mean response time or “mean time in system”\nE[TQ]=E[T]−E[S]:mean waiting time or “wasted” time, also known as mean\ndelay or mean queuing time\nE[N]:mean number in system\nE[NQ]:mean number in queue\nQuestion: Suppose someone tells you they have a super scheduling algorithm that\nimproves mean waiting time in their system by a factor of 100. Before you buy thealgorithm, what question should you ask?\nHint: Just because\nE[TQ]improves by a factor of 100, does E[T]necessarily improve\nby a comparable factor?\nAnswer: In fact, you need to know the mean job size, E[S], so you can determine the\nbeneﬁt to E[T].\nSuppose\nE[S]>E[TQ].\nThen an improvement in E[TQ]by a factor of 100,000 still yields less than a factor of\n2 improvement in E[T].\nMore typically, we have\nE[TQ]/greatermuchE[S],\nso improvements in E[TQ]translate to comparable improvements in E[T].\n473",1285
181-Chapter 29 Scheduling Non-Preemptive Non-Size-Based Policies.pdf,181-Chapter 29 Scheduling Non-Preemptive Non-Size-Based Policies,"474 performance metrics\n28.2 Commonly Used Metrics for Single Queues\nSuppose you have a single queue. Consider these two metrics:\nWork in system: remaining work left to do in the system\nUtilization of device: fraction of time that the device is busy\nDeﬁne an arrival sequence as a sequence of arrival times and job sizes.\nQuestion: Suppose you are told that two scheduling policies, run on the same arrival\nsequence, result in the same work in system over all time and the same device utilization.Does that mean that the two policies also have the same mean response time?\nDeﬁnition 28.1 Awork-conserving scheduling policy is one that always performs\nwork on some job when there is a job in the system. Also, the policy does not createnew work (e.g., by re-running parts of jobs).\nObserve that “work in system” is the same across all work-conserving scheduling\npolicies, and so is the server utilization. Let’s reformulate the question then.\nQuestion: Do all work-conserving scheduling policies have the same mean response\ntime?\nAnswer: No. Consider two work-conserving policies\nAandB. Suppose policy A\nserves the shortest available job ﬁrst, so that only a few big jobs are left, whereas B\nserves the longest available job ﬁrst, so that many more jobs are left. Then E[N]is\nmuch higher for policy B, and by Little’s Law, E[T]is thus higher for B.\n28.3 Today’s Trendy Metrics\nDeﬁnition 28.2 The slowdown of a job is its response time divided by its size:\nSlowdown =T\nS.\nObserve that the slowdown of a job is always at least 1.\nQuestion: Why is mean slowdown preferable to mean response time?\nAnswer: Ideally, one wants the response time of a job to be correlated with the job’s\nsize. We would like small jobs to have small response times and big jobs to have bigresponse times. We would like to make sure the slowdown of every job is no more than,\nsay,\n10.\nQuestion: But why does knowing mean slowdown is low tell us anything about the\nmax slowdown?\n28.4 starvation/fairness metrics 475\nAnswer: If we know E[Slowdown ]=2 , then we know there cannot be many jobs\nwith slowdown much greater than 3. In particular, fewer than half the jobs can have\nslowdown greater than or equal to 3 (note that all jobs have slowdown of at least 1).\nFewer than 1/4of the jobs can have slowdown of at least 5. Fewer than1\nn−1fraction\nof jobs can have slowdown of at least n.\nSo by making the mean slowdown low, we have also restricted the fraction of jobs with\nvery high slowdowns, which means that few jobs have response time too much greater\nthan their service requirement.\nThere are many other performance metrics of interest. Variability in response time,\nVar(T), and variability in slowdown, Var(Slowdown ), are sometimes even more\nimportant to system designers than mean metrics. This is why we often derive the\nLaplace transform of response time, rather than just the mean.\nAnother metric of importance is the tail behavior of response time (or tail of\nslowdown). This is deﬁned as the probability that the response time exceeds some\nlevelx, namely P{T>x}. Understanding the tail behavior is very important in\nsetting Service Level Agreements (SLA’s), where a company might be willing to pay\nto ensure that their response time stays below xwith probability 95%. Unfortunately,\ntail behavior is often not easy to derive. Boxma and Zwart [ 28] survey recent research\nin understanding the tail behavior of different scheduling policies.\n28.4 Starvation/Fairness Metrics\nThe increasing popularity of mean slowdown as a performance metric has led some\nresearchers to worry that certain scheduling policies might be achieving low meanslowdown at the expense of starving the few big jobs. For example, the Shortest-\nRemaining-Processing-Time (SRPT) policy results in low mean slowdown because\nmost jobs are small and they get treated well, at the expense of delaying large jobs.\nQuestion: What performance metric will tell us if jobs are being starved?\nAnswer: We recommend looking at mean slowdown as a function of job size .F o r\nexample, consider asking “What is the expected slowdown of jobs of size\nx?” or\n“What is the expected slowdown of the max job size?” or “What is the expected\nslowdown of jobs in the 99th percentile of the job size distribution?”\nWe use E[Slowdown (x)]to denote the expected slowdown of a job of size x. We might\nthen say that scheduling policy Pis “starving some jobs” or at least “treating some\njobs unfairly” if the expected slowdown of a job of size xis higher under policy P\nthan it is under Processor-Sharing (PS), for some x. We compare with PS because PS\nprovides equal expected slowdown to all jobs (this statement will become more clear\nwhen we get to Chapter 30) and hence is considered “fair.” We likewise might say that\na scheduling policy Pis “fair” even if it does not provide equal expected slowdown to\nall job sizes, as long as E[Slowdown (x)]under policy Pis lower than that under PS,\nfor all x.\n476 performance metrics\nStarvation is often a deceptive thing. Consider the following example.\nQuestion: Suppose I tell you that switching from scheduling policy A to scheduling\npolicy B resulted in strictly improving the response time of almost all jobs and in nojob\nending up with a worse response time under policy B than under A. Is this possible?\nAnswer: Sure it is. Consider the case of a single server, where njobs all arrive at time\n0and have size 1. Under Processor-Sharing, they each have response time of n.N o w\nwe switch to FCFS. The response time of n−1of the jobs strictly improves. The\nresponse time of one job stays the same. No job has a worse response time.\nSection 33.4 proves more counterintuitive results on fairness, such as the “All-Can-\nWin” theorem for SRPT scheduling.\n28.5 Deriving Performance Metrics\nIn the next few chapters, we consider various scheduling policies for the M/G/1 queue.Typically, for every scheduling policy we derive\nE[T](mean time in system) and\nE[T(x)](mean time in system for a job of size x).\nQuestion: How can we derive E[Slowdown ],g i v e nE[T]andE[T(x)]?\nHint: It isnotE[T]/E[S].\nAnswer: First derive the mean slowdown for a job of size xas follows:\nE[Slowdown (x)] =E/bracketleftbiggT\nS/vextendsingle/vextendsingle/vextendsingle/vextendsinglejob has size S=x/bracketrightbigg\n=E/bracketleftbiggT(x)\nx/bracketrightbigg\n=1\nxE[T(x)].\nNotice that we were able to pull out the xbecause it is just a constant. Now we use\nE[Slowdown (x)]to get mean slowdown:\nE[Slowdown ]=/integraldisplay\nxE[Slowdown|job has size x]fS(x)dx\n=/integraldisplay\nxE[Slowdown( x)]fS(x)dx\n=/integraldisplay\nx1\nxE[T(x)]fS(x)dx\nTo derive the transform of response time, we typically ﬁrst derive the transform of\nT(x)and then integrate that to get the transform of response time, as follows:\n/tildewideT(s)=/integraldisplay\nx/tildewideT(x)(s)fS(x)dx\nSimilarly, for the transform of slowdown, we ﬁrst derive the transform of Slowdown (x)\nand then integrate that.\n28.6 readings 477\n28.6 Readings\nThe fairness metric that we use here was introduced in [ 12]. The slowdown metric has\nreceived very little attention in the world of scheduling until recently, see [ 100] and the\nreferences therein.",7256
182-29.1 FCFS LCFS and RANDOM.pdf,182-29.1 FCFS LCFS and RANDOM,"CHAPTER 29\nScheduling: Non-Preemptive,\nNon-Size-Based Policies\nThis chapter and all the remaining chapters focus on scheduling for the case of an\nM/G/1 queue. We always assume ρ<1and that Gis continuous with ﬁnite mean and\nﬁnite variance. Every scheduling policy we consider is work-conserving (i.e., whenever\nthere is a job to be worked on, some job will receive service).\nDeﬁnition 29.1 Anon-preemptive service order is one that does not preempt a job\nonce it starts service (i.e., each job is run to completion).\nThis chapter focuses on non-preemptive scheduling policies that do not make use of\nknowing a job’s size.\n29.1 FCFS, LCFS, and RANDOM\nThe following three non-preemptive policies do not assume knowledge of job size:\nFCFS: When the server frees up, it always chooses the job at the head of the queue to\nbe served and runs that job to completion.\nLCFS (non-preemptive): When the server frees up, it always chooses the last job to\narrive and runs that job to completion.\nRANDOM: When the server frees up, it chooses a random job to run next.\nQuestion: When would one use LCFS?\nAnswer: Consider the situation where arriving jobs get pushed on a stack, and therefore\nit is easiest to access the job that arrived last (e.g., the task at the top of the pile on my\ndesk!).\nQuestion: Which of these three non-preemptive policies do you think has the lowest\nmean response time?\nAnswer: It seems like FCFS should have the best mean response time because jobs\nare serviced most closely to the time they arrive, whereas LCFS may make a job wait\na very long time. However, surprisingly, it turns out that all three policies have exactlythesame mean response time. In fact, an even stronger statement can be made.\nTheorem 29.2 [45]All non-preemptive service orders that do not make use of job\nsizes have the same distribution of the number of jobs in the system.\n478\n29.1 fcfs, lcfs, and random 479\nCorollary 29.3 All non-preemptive service orders that do not make use of job\nsizes have the same E[N], and hence the same E[T].\nQuestion: Does this mean that all these policies also have the same E[Slowdown]?\nAnswer: See Exercise 29.2.\nQuestion: Any ideas for how the proof for Theorem 29.2 might go?\nHint: It will help to recall the embedded DTMC formulation for the M/G/1/FCFS\nqueue. The idea is to look at the M/G/1 queue just at the point of departures.\nAnswer: For the M/G/1/FCFS queue in Chapter 26, we let the current state be the\nnumber of jobs in the M/G/1 system at the time of the last departure. The sequence of\nstates{Xi,i≥0}forms a DTMC, where, for i>0,\nPij=Probability that when leave state iwe next go to state j\n=P/braceleftbigg\nThe next departure will leave behind jjobs,\ngiven that the last departure left behind ijobs/bracerightbigg\n=P{j−i+1jobs arrive during the service time S}\n=/integraldisplay\nxP{j−i+1arrivals during time x}fS(x)dx\n=/integraldisplay\nxe−λx(λx)j−i+1\n(j−i+1 ) !fS(x)dx.\nThe limiting probability, πi, for this DTMC process speciﬁes the fraction of jobs that\nleave behind ijobs. This in turn, by PASTA (see Chapter 13), equals the limiting\nprobability that there are ijobs in the M/G/1.\nQuestion: So, having recalled this argument for M/G/1/FCFS, what would the argu-\nment be like to determine the limiting number of jobs in the system for M/G/1/LCFS?\nAnswer: The argument does not change at all when the service order is LCFS. In fact\nit is the same analysis for anyservice order that does not make use of job size.\nQuestion: Why do we require that the scheduling policy not make use of size?\nAnswer: If you used size in determining which job got to serve next, then that would\naffect the distribution of the number of jobs that arrive during one service time.\nQuestion: Consider again the set of all non-preemptive scheduling policies that do\nnot make use of size. Is Var(T)the same for all these policies?\nAnswer: No. Observe that LCFS can generate some extremely high response times\nbecause we have to wait for the system to become empty to take care of that ﬁrst arrival.\nIt turns out that, in agreement with intuition, we have\nVar(T)FCFS<Var(T)RANDOM<Var(T)LCFS.\n480 scheduling: non-preemptive, non-size-based policies\nWe already know how to derive Var(T)FCFS. We now show how to derive Var(T)LCFS.\nWe do this by computing the Laplace transform of waiting time, /tildewideTLCFS\nQ(s). Before we\nbegin, it helps to recall a few formulas from Chapter 27and Exercise 25.14 .\nB(x)= length of busy period started by a job of size x\n=x+Ax/summationdisplay\ni=1Bi,where Ax= number arrivals by x\n/tildewideB(x)(s)=e−x(s+λ−λ/tildewideB(s))\nB=length of busy period made up of jobs of size S\n/tildewideB(s)=/integraldisplay∞\nx=0/tildewideB(x)(s)fS(x)dx=/tildewideS/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\nBW=length of busy period made up of jobs of size S, started by work W\n/tildewidestBW(s)=/tildewiderW/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\nSe=excess of S\n/tildewiderSe(s)=Lfe(s)=1−/tildewideS(s)\nsE[S]\nConsider an arrival into the M/G/1/LCFS queue. Conditioning on whether the arrival\nsees an empty system or a busy system, we can immediately write\n/tildewideTLCFS\nQ(s)=( 1−ρ)·/tildewideTLCFS\nQ(s|idle)+ρ·/tildewideTLCFS\nQ(s|busy). (29.1)\nQuestion: What is/tildewideTLCFS\nQ(s|idle)?\nAnswer: If the arrival sees an empty system, then the waiting time is zero, so\n/tildewideTLCFS\nQ(s|idle)=1.\nQuestion: How long does the arrival wait if it ﬁnds the server busy?\nAnswer: At ﬁrst one might think that the waiting time is just the excess of a service\ntime,Se, because the arrival has to wait for the job in service to ﬁnish serving. This\nis, however, not quite correct, because more jobs may arrive during Se, and those jobs\nhave precedence over our arrival. In fact, the waiting time for our arrival is the lengthof a busy period started by a job of size\nSe.\n/tildewideTLCFS\nQ(s|busy)=/tildewiderSe/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\n=1−/tildewideS/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\n/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\nE[S]\n=1−/tildewideB(s)/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\nE[S]",6187
183-29.2 Readings.pdf,183-29.2 Readings,,0
184-Chapter 30 Preemptive Non-Size-Based Policies.pdf,184-Chapter 30 Preemptive Non-Size-Based Policies,"29.3 exercises 481\nReturning to ( 29.1)w eh a v e\n/tildewideTLCFS\nQ(s)=( 1−ρ)·/tildewideTLCFS\nQ(s|idle)+ρ·/tildewideTLCFS\nQ(s|busy)\n=( 1−ρ)+ρ·1−/tildewideB(s)/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig\nE[S]\n=( 1−ρ)+λ(1−/tildewideB(s))/parenleftBig\ns+λ−λ/tildewideB(s)/parenrightBig.\nFrom this transform, we can derive the second moment of waiting time, E/bracketleftbig\nT2\nQ/bracketrightbig\n.W e\nﬁnd that\nE/bracketleftbig\nT2\nQ/bracketrightbigLCFS=λE[S3]\n3(1−ρ)2+(λE[S2])2\n2(1−ρ)3.\nIn comparison, for FCFS scheduling we saw\nE/bracketleftbig\nT2\nQ/bracketrightbigFCFS=λE[S3]\n3(1−ρ)+(λE[S2])2\n2(1−ρ)2.\nSo\nE/bracketleftbig\nT2\nQ/bracketrightbigLCFS=E/bracketleftbig\nT2\nQ/bracketrightbigFCFS·1\n1−ρ.\nThus, although the mean waiting times are the same for FCFS and LCFS, the second\nmoment of waiting time differs by a factor that depends on ρ, but not on the job\nsize distribution. Under high loads, the second moment of waiting time under LCFS\nbecomes very high compared with the second moment of waiting time under FCFS.\n29.2 Readings\nTheorem 29.2 was taken from [ 45], Section 8.5. Very few books analyze scheduling\npolicies in a stochastic setting. However, two good ones with lots of insights are\n[45,111].\n29.3 Exercises\n29.1 Reviewing LCFS\nDerive the mean queueing time under LCFS, E[TQ]LCFS. Derive this by con-\nditioning on whether an arrival ﬁnds the system busy or idle, but without using\ntransforms.\n29.2 Non-Preemptive, Non-Size-Based Policies\nIn this chapter, we saw that the FCFS, LCFS and RANDOM scheduling\ndisciplines all have the same distribution of the number of jobs in the systemfor an M/G/1 queue. How do they compare with respect to mean slowdown(again, for an M/G/1)? Prove your answer.",1755
185-30.1 Processor-Sharing PS.pdf,185-30.1 Processor-Sharing PS,"CHAPTER 30\nScheduling: Preemptive,\nNon-Size-Based Policies\nThis chapter is about preemptive scheduling policies that do not make use of knowing\na job’s size or its priority class.\nDeﬁnition 30.1 A policy is preemptive if a job may be stopped partway through\nits execution and then resumed at a later point in time from the same point where itwas stopped (this is also called preemptive-resume ).\nWe deﬁne three preemptive scheduling policies during this chapter, none of which make\nuse of job size. The policies are Processor-Sharing (PS) (Section 30.1), Preemptive-\nLast-Come-First-Served (PLCFS) (Section 30.2), and Generalized Foreground-\nBackground (FB) (Section 30.3).\n30.1 Processor-Sharing (PS)\n30.1.1 Motivation behind PS\nIn Chapter 29, we saw that all non-preemptive, non-size-based scheduling policies for\nthe M/G/1 result in the\nsame distribution on N⇒sameE[N]⇒sameE[T]⇒sameE[TQ].\nThus all non-preemptive, non-size-based service orders for the M/G/1 have E[T]equal\nto that for M/G/1/FCFS, namely\nE[T]=λE[S2]\n2(1−ρ)+E[S].\nWe also saw that for all these policies,\nE[T(x)] =x+λE[S2]\n2(1−ρ).\n(Note:E[TQ(x)] =E[TQ]for all x.)\nThe problem is that this mean response time can be very high when E[S2]is high (job\nsize variability is high). Intuitively, short jobs queue up behind long jobs, resulting in\nlong delays. In particular, the mean slowdown, E[Slowdown( x)] =E[T(x)]\nx,i sv e r y\nhigh for small x.\nProcessor-Sharing, by contrast, is not negatively affected by high job size variability.\nQuestion: Why are short jobs not affected by long ones under PS?\n482\n30.1 processor-sharing (ps) 483\nAnswer: When a short job arrives, it immediately time-shares with all the jobs in the\nsystem. It does not have to wait for long jobs to ﬁnish.\nHistorically, CPU scheduling has always involved time-sharing, where each job is\ngiven a tiny quantum and the CPU takes turns serving jobs in a round-robin fashion. Ifthe quantum size goes to zero, we get the Processor-Sharing abstraction.\nThere are two reasons, historically, why PS is used in CPU scheduling. The ﬁrst is that\nPS allows short jobs (which require just a few quanta of service) to get out quickly.\nBecause PS helps the many short jobs ﬁnish quickly, it should in theory also help reduce\nE[T]and particularly E[Slowdown ], as compared to FCFS. The other reason for PS\nis that time-sharing the CPU might allow an increase of overall system throughput in\na multi-resource system. Imagine, for example, a multi-resource system, including a\nCPU, disk, memory, etc. It is useful to have many jobs running simultaneously (rather\nthan just one job at a time), because jobs requiring different resources can be overlappedto increase throughput.\nBut PS is not better than FCFS for every arrival sequence.\nQuestion: Give an example of an arrival sequence for which PS is worse than FCFS\nfor both\nE[T]andE[Slowdown ]?\nAnswer: Consider two jobs, both arriving at time 0, and both having size 1:\nE[T]FCFS=1.5E[Slowdown ]FCFS=1.5\nE[T]PS=2 E[Slowdown ]PS=2\nQuestion: We have seen that PS does not outperform FCFS on every arrival sequence.\nCan we say that M/G/1/PS outperforms M/G/1/FCFS with respect to expected response\ntime in a stochastic setting? If so, what conditions, if any, are needed on G?\nAnswer: Recall that we proved in Chapter 22that the distribution of the number of\njobs in the M/G/1/PS system is the same as that in an M/M/1/FCFS system (for any\nCoxian distribution G). Hence the mean number of jobs and mean response time are\nthe same for the M/G/1/PS and the M/M/1/FCFS.\nSo M/G/1/PS is better in expectation than M/G/1/FCFS exactly when M/M/1/FCFS is\nbetter than M/G/1/FCFS, namely when\nC2\nG>1,\nwhere C2\nGis the squared coefﬁcient of variation of G.\nIn summary, it is the fact that the mean response time for PS is insensitive to job size\nvariability that makes PS so powerful in practice.\n30.1.2 Ages of Jobs in the M/G/1/PS System\nDeﬁnition 30.2 The ageof a job is the total service it has received so far.\n484 scheduling: preemptive, non-size-based policies\nBy deﬁnition, 0≤age(j)≤size(j), where age (j)denotes the age of job jand size (j)\ndenotes the (original) size of job j.\nAlthough the steady-state number of jobs in the M/G/1/PS and M/M/1/FCFS queues\nis the same,\nP{nin system}=ρn(1−ρ),\nthe distribution of the ages of their jobs is very different. Under FCFS, the jobs\nin queue all have age 0 and the job in service (if there is one) has age (and excess)\ndistributed according to the equilibrium distribution, where the equilibrium distribution\nhas probability density function, fe(·), deﬁned by\nfe(x)=F(x)\nE[S]. (30.1)\nHence Sdenotes job size, f(·)is the job size p.d.f. of arriving jobs, and F(x)=/integraltext∞\nxf(t)dtis the probability that an arriving job has size ≥x(see Exercise 25.14 for\nthe derivation and Chapter 23for more intuition).\nQuestion: Can you guess at how the ages of the jobs in PS are distributed?\nAnswer: Under PS, all jobs are worked on simultaneously, and thus an arrival sees\nevery job through an Inspection Paradox. It therefore is unsurprising that an arrival to\nthe M/G/1/PS ﬁnds that alljobs in the system have i.i.d. ages, distributed according to\nthe equilibrium distribution.\nTheorem 30.3 For the M/G/1/PS queue, given there are njobs in the system,\ntheir ages are independent and have distribution density fe(·). Furthermore, the\ndeparture process is a Poisson process with rate λ.\nProof The proof of this theorem is sketched in [ 149]. The proof is very technical and\ndoes not provide intuition, so we have not repeated it here. The basic idea is to makea guess about the reverse process, whereby we guess that the excesses of jobs in thereverse process are distributed according to the equilibrium distribution, and then we\nprove that this guess satisﬁes the balance equations.\n30.1.3 Response Time as a Function of Job Size\nWe now show that in the M/G/1/PS, every job has the same expected slowdown.\nTheorem 30.4\nE[T(x)]M/G/1/PS=x\n1−ρ.\n30.1 processor-sharing (ps) 485\nCorollary 30.5\nE[Slowdown( x)]PS=1\n1−ρ\nE[Slowdown]PS=1\n1−ρ\nThe remainder of this section is devoted to proving Theorem 30.4.\nRecall Little’s Law for red jobs: “The average number of red jobs in the system equals\nthe average arrival rate of red jobs multiplied by the average time a red job spends in\nthe system.” To ﬁgure out the mean time in system for a job of size x, we thus need to\nﬁgure out the mean number of jobs in the system with size x. (Note that we are talking\nhere about “original size” x, not “remaining service requirement” x).\nQuestion: Can we express the expected number of jobs in the system with size between\nxandx+hasE[N]f(x)h+o(h)?\nAnswer: No. Although original job sizes are drawn from distribution density f(·), the\nsizes of those jobs in the system have a p.d.f. possibly different from f(·), because PS\nﬁnishes off small jobs more quickly.\nLet\nf(·)= job size p.d.f. for arriving jobs.\nfsys(·)= job size p.d.f. for jobs in the system.\nQuestion: Sadly, we do not know anything about the probability that a job in the system\nhas size, say, w. However, we do know the probability that a job in the system has age\nw. Can we use this?\nAnswer: Yes! Our approach will be to condition on the job’s age:\nfsys(w)=/integraldisplayw\nx=0fsys(w|job has age x)·P{job has age x}\n=/integraldisplayw\nx=0fsys(w|job has age x)·fe(x)dx, by Theorem 30.3\n=/integraldisplayw\nx=0f(w|job has size ≥x)·fe(x)dx\n=/integraldisplayw\nx=0f(w)\nF(x)·fe(x)dx\n=/integraldisplayw\nx=0f(w)\nE[S]dx, by (30.1)\n=wf(w)\nE[S]\n486 scheduling: preemptive, non-size-based policies\nSo\nfsys(w)=f(w)·w\nE[S]. (30.2)\nQuestion: Explain the intuition behind ( 30.2).\nAnswer: In (30.2), the factor that f(w)gets weighted by isw\nE[S]. When wis small\ncompared to E[S], this factor is less than 1. When wis large compared to E[S], this\nfactor is greater than 1. This indicates that more large jobs are going to be in the system\nthan would be true under f(w).\nUsing ( 30.2), we have, for small h,\nE[Number of jobs in system with (original) size ∈(x, x+h)]\n=E[N]·fsys(x)·h+o(h)\n=ρ\n1−ρ·x·f(x)\nE[S]·h+o(h)\n=λ\n1−ρ·x·f(x)·h+o(h).\nE[Rate of arrivals of jobs into system with size ∈(x, x+h)]\n=λ·f(x)h+o(h).\nNow applying Little’s Law, we have\nE[Time in system for jobs with (original) size ∈(x, x+h)]\n=λ\n1−ρ·x·f(x)·h+o(h)\nλ·f(x)h+o(h)\n=λ\n1−ρ·x·f(x)+o(h)\nh\nλ·f(x)+o(h)\nh\n=λ\n1−ρ·x·f(x)\nλ·f(x)ash→0\n=x\n1−ρ.\nHence we have shown that\nE[T(x)]M/G/1/PS=x\n1−ρ,\ncompleting the proof of Theorem 30.4.\n30.1 processor-sharing (ps) 487\n30.1.4 Intuition for PS Results\nConsider Theorem 30.4 and its corollary. These say that the expected slowdown for a\njob of size xunder the M/G/1/PS is a constant , independent of the size x. Remember\nthat for non-preemptive non-size-based scheduling, the mean slowdown for small jobs\nwas greater than the mean slowdown for large jobs. By contrast, under PS, all jobshave same slowdown. For this reason, people always refer to PS as fair scheduling .\nIn Chapter 28, we discussed what would be a good metric for evaluating whether a\npolicy, like SRPT, is starving big jobs. The criterion we advocate using is to determine\nmean slowdown of big jobs under SRPT and see whether the big jobs have much higher\nmean slowdown under SRPT than they would have under PS, which produces equalslowdown for all jobs. We will discuss fairness in detail in Chapter 33.\nQuestion: What is the intuition behind Theorem 30.4?\nHint: An arrival sees\nE[N]=ρ\n1−ρ\njobs in the system.\nAnswer: The arrival is slowed by a factor ofE[N]+1 , where\nE[N]+1=ρ\n1−ρ+1=1\n1−ρ.\nThus, any arrival of size xshould take E[T(x)] =x·1\n1−ρtime to leave the system.\n(This is not a proof, just intuition.)\nQuestion: What else that we have studied recently has the formx\n1−ρ?\nAnswer: E[B(x)] =x\n1−ρis the expected length of a busy period started by a job of\nsizex.\nThus the mean response time for a job of size xfor the M/G/1/PS queue is also equal to\nthe mean length of a busy period started by a job of size x. Although this may lead one\nto think that the response time under M/G/1/PS is really just a busy period duration,\nhigher moment analysis shows this not to be true.\nRemark: Although results for E[T]PSandE[T(x)]PSare really simple and beautiful,\nthis is not true for Var(T)PS, which cannot even be expressed in a closed form. There\nare still theses being written today on the M/G/1/PS queue. There are pretty solutions\nwhenGis Deterministic, and obviously when it is Exponential, but not for much else\n(see Section 30.4).\n30.1.5 Implications of PS Results for Understanding FCFS\nRecall the transform equation for waiting time (delay) in the M/G/1/FCFS queue from\n(26.14 ):\n/tildewiderTQFCFS(s)=1−ρ\n1−ρ/tildewiderSe(s)(30.3)",10859
186-30.2 Preemptive-LCFS.pdf,186-30.2 Preemptive-LCFS,"488 scheduling: preemptive, non-size-based policies\nRemember that we needed an entire chapter (all of Chapter 26) to prove this result. We\nnow rederive this result in one page. We start by writing ( 30.3) as a summation.\nQuestion: How can we express ( 30.3) as a sum?\nAnswer:\n/tildewiderTQFCFS(s)=( 1−ρ)∞/summationdisplay\nk=0/parenleftBig\nρ/tildewiderSe(s)/parenrightBigk\n=∞/summationdisplay\nk=0(1−ρ)ρk/parenleftBig\n/tildewiderSe(s)/parenrightBigk\n. (30.4)\nQuestion: What does/parenleftBig\n/tildewiderSe(s)/parenrightBigk\nrepresent?\nAnswer:/parenleftBig\n/tildewiderSe(s)/parenrightBigk\nis the Laplace transform of/summationtextk\ni=1S(i)\newhere the S(i)\ne,f o r1≤\ni≤k, represent i.i.d. instances of Se.\nKleinrock, vol. I [ 110] writes that no one has been able to explain the curious for-\nmulation of/tildewiderTQFCFS(s)g i v e ni n( 30.4). Indeed it seems quite strange to see the term\nρk(1−ρ)within an expression for the M/G/1/FCFS queue.\nQuestion: Using what we have learned about PS, explain in four lines why\n/tildewiderTQFCFS(s)=∞/summationdisplay\nk=0(1−ρ)ρk/parenleftBig\n/tildewiderSe(s)/parenrightBigk\n.\nAnswer: LetWFCFSdenote the stationary work in an M/G/1/FCFS system. WFCFSis\nthe same as the work in system as witnessed by a Poisson arrival. This in turn equals\nthe delay experienced by a Poisson arrival under FCFS.\nLetWPSdenote the stationary work in an M/G/1/PS system.\n/tildewiderTQFCFS(s)=/tildewiderWFCFS(s)\n=/tildewiderWPS(s)(both FCFS and PS are work-conserving)\n=∞/summationdisplay\nk=0/tildewiderWPS(s|arrival sees kjobs)·P{arrival sees kjobs}\n=∞/summationdisplay\nk=0/parenleftBig\n/tildewiderSe(s)/parenrightBigk\n·ρk(1−ρ)\nThat completes the derivation of the M/G/1/FCFS delay transform.\n30.2 Preemptive-LCFS\nAnother preemptive non-size-based scheduling policy is Preemptive-LCFS (PLCFS) ,\ndeﬁned as follows: Whenever a new arrival enters the system, it immediately preempts\nthe job in service. Only when that arrival completes does the preempted job get toresume service.\n30.2 preemptive-lcfs 489\nQuestion: What do you recall about the performance of the (non-preemptive) LCFS\npolicy?\nAnswer: It was identical in performance to FCFS – and thus not very good for highly\nvariable job size distributions.\nQuestion: Any guesses as to what the performance of PLCFS will be like?\nAnswer: We will prove the following theorem:\nTheorem 30.6\nE[T(x)]PLCFS=x\n1−ρ\nE[Slowdown(x)]PLCFS=1\n1−ρ\nThe remainder of this section is devoted to proving Theorem 30.6. The derivation\nis actually quite simple and instructive. We derive the mean, E[T(x)], here, and in\nExercise 30.6 we will derive the full transform, which will yield additional insight.\nConsider a particular tagged job of size x.\nKey Observation: Once a job is interrupted, it will not get back the processor until all\njobs arriving after that point are completed (refer to Figure 30.1).\nstart\njobn+2end\njobn+2end\njobn+1end\njobntimejobn+2\njobn+1\njobn\nstart\njobnstart\njobn+1\nFigure 30.1. Jobs under Preemptive-LCFS.\nQuestion: So how long will it be, on average, from when our tagged job is interrupted\nuntil it gets back the processor?\nAnswer: We can think of the point when our job gets interrupted as marking the\nbeginning of a busy period in an M/G/1 queue, because the job will not resume until\nthe interruption, and all work that arrives during its busy period, completes. So,\nE[Time until job gets back processor ]=E[Length of busy period ]=E[S]\n1−ρ.\nNote: The mean length of the busy period is the same regardless of the service order in\nthe M/G/1 so long as the service order is work-conserving.",3648
187-30.3 FB Scheduling.pdf,187-30.3 FB Scheduling,"490 scheduling: preemptive, non-size-based policies\nQuestion: What is E[# times our tagged job gets interrupted ]?\nAnswer: Because our job has size x, the expected number of times it will be interrupted\nis just λx, the expected number of arrivals during time x.\nLet Wasted-Time (x)refer to the time the tagged job is in the system but not serving.\nE[Wasted-Time (x)] =E[# times tagged job is interrupted ]·E[length of interruption ]\n=λx·E[S]\n1−ρ\n=ρx\n1−ρ\nE[T(x)] =x+E[Wasted-Time (x)] =x+ρx\n1−ρ=x\n1−ρ\nE[Slowdown (x)] =1\n1−ρ\nThus although the PLCFS policy looks very different from PS, its mean performance\nis the same as for PS – even its mean performance on jobs of size x.W eh a v en o w\ncompleted the proof of Theorem 30.6.\nQuestion: Can you see any advantage to using PLCFS over PS?\nAnswer: PLCFS offers the same expected performance with many fewer preemptions.\nQuestion: Exactly how many preemptions will we have under PLCFS?\nAnswer: Each job creates two preemptions – one when it arrives and one when it\ndeparts. Thus we have only two preemptions per job in PLCFS, whereas in a real-\nworld implementation of PS, with small quantum sizes, the number of preemptionscan be much higher. If preemptions actually have a cost, then PLCFS wastes less timedoing them, as compared with PS.\n30.3 FB Scheduling\nSo far, all the preemptive non-size-based scheduling policies we have seen produce the\nsame mean slowdown for all job sizes:\nE[Slowdown (x)] =1\n1−ρ\nWouldn’t it be nice if we could somehow get lower slowdowns for the smaller jobs, sothat we could drop our mean slowdown?\nQuestion: But how can we give preference to the smaller jobs if we do not know job\nsize?\n30.3 fb scheduling 491\nAnswer: Wedoknow a job’s age (the service it has received so far), and age is an\nindication of the job’s remaining CPU demand.\nIf the job size distribution has DFR (decreasing failure rate), as does the Pareto distri-\nbution, then the greater the job’s age, the greater its expected remaining demand. Sowe should give preference to jobs with low age (younger jobs), and this will have theeffect of giving preference to jobs that we expect to ﬁnish quickly.\nUNIX does this using Multi-Level Processor-Sharing (MLPS), also called Foreground-\nBackground scheduling. There are two queues served by the same one server, where\nqueue 1 is high priority and queue 2 is low priority. All jobs start out in queue 1. Jobs\nin queue 1 are run using PS. When a job hits a certain age\na, it is moved to queue 2.\nJobs in queue 2 get service only when queue 1 is empty.\nWe will study this idea in the limit as the number of queues goes to inﬁnity. This\nlimiting algorithm is called Generalized Foreground-Background (FB) scheduling\nand is deﬁned as follows:\nrThe job with the lowest CPU age gets the CPU to itself.\nrIf several jobs have same lowest CPU age, they share the CPU using PS.\nThis algorithm is known in the literature both under the name FB and under the name\nLeast-Attained-Service (LAS).\nQuestion: Consider the following arrival sequence:\nrAt time 0, a job (customer) of size 3 arrives.\nrAt time 1, a job (customer) of size 2 arrives.\nrAt time 2, a job (customer) of size 1 arrives.\nWhen will each of these complete under FB?\nAnswer: The size 1 job leaves at time 3; the size 2 job leaves at time 5; and the size 3\njob leaves at time 6, as shown in Figure 30.2.\ntime\n45 6size\n0 1123\n23\nFigure 30.2. State of system at several points in time under FB scheduling. As jobs (customers)\nare worked on, they start to “disappear.” When a job becomes “invisible,” it departs.\nThe performance improvement of FB over PS obviously has to do with how good a pre-\ndictor age is of remaining size, which depends on the distribution of job sizes. Ourgoal is to compute\nE[T(x)]FB. Before we start, let’s work through a small mathematical\nexercise that will come in handy later.\n492 scheduling: preemptive, non-size-based policies\nLetf(y)be the probability density function (p.d.f.) for our size distribution. Deﬁne\nfx(y)to be the p.d.f. for the transformed size distribution, where each job of size >x\nhas been replaced by a job of size x, as shown in Figure 30.3.\nReplace by size x\nx\nxAll jobs of size >  x\nare replaced by size xf(y)\nsize\nsizefx(y)\nFigure 30.3. Original p.d.f., f(y), and the transformed p.d.f., fx(y).\nIfSxdenotes the job size under the transformed distribution, then\nE[Sx]=/integraldisplayx\n0yf(y)dy+x(1−F(x))(integration\nby parts)=/integraldisplayx\n0F(y)dy.\nE[Sn\nx]=/integraldisplayx\n0ynf(y)dy+xn(1−F(x))(integration\nby parts)=/integraldisplayx\n0yn−1F(y)dy.\nUtilization :ρx=λE[Sx].\nNow let us return to the problem of deriving E[T(x)]FB. Let jobxdenote a job of size\nx. To derive E[T(x)]FB, think about all the units of work that have to get done before\njobxcan leave the system:\n(1)xunits (this is just the size of job x).\n(2) The expected remaining work in the system when job xarrives, except that in\ndoing this computation we need to pretend that every job in the system has a\nservice requirement no more than x. That is, every job of size >x is assumed\nto have size x, for the purpose of computing the remaining work in the system\nwhen job xarrives. To understand this, realize that from job x’s viewpoint, a job\njwith size >x looks exactly like it has size x, because once job jreaches age\nxit will never again affect job x. So in totaling the expected remaining work in\n30.3 fb scheduling 493\nthe system that will affect job x, we need to shrink each job’s size to x. If a job\nhas already reached age ≥x, we just ignore that job, because it will not receive\nservice until after job xcompletes.\n(3) The expected work due to new arrivals while job xis in the system, where again\njobs are counted only by how much they can affect job x.\nWe use Sxin determining quantities (2) and (3) in E[T(x)]FB:\nDerivation of (2): Item (2) basically says that when job xarrives into the system, it\nlooks at all jobs through “transformer glasses” (see Figure 30.4), which “decapitate”\neach job of size >xto form to a job of size x. Then we total the remaining work in the\ntransformed system.\nx\nx\nFigure 30.4. Transformer glasses for FB.\nClaim 30.7 If the queue is using FB scheduling, then the remaining work in the\nsuddenly transformed system is the same as if we had simply transformed each job\nat the instant it arrived to the system.\nProof Let system A be the original system, no transformations. Let system B be a\nsystem where each job is transformed the instant it arrives. Whenever system B is\nworking, system A is also working on a job of age <x. The only time system A is\nworking on a job of age >xis when both (i) system B is idle and (ii) all jobs in system\nA have age >x. Thus, if we walked up to system A at any moment and suddenly put\non our transformer glasses, system A would look just like system B.\nThus, (2) is asking for the remaining work in a system doing FB scheduling where\neach job is transformed immediately on arrival. In other words, (2) is asking for theremaining work in an FB system where the job size is\nSx.\nQuestion: But what is the remaining work in such a system?\nAnswer: Remember, the remaining work in any work-conserving system is the same as\nany other, so we may as well ask what is the expected remaining work in a M/G/1/FCFS\n494 scheduling: preemptive, non-size-based policies\nwhere the job size is Sx. But this is simply\nE[Remaining work in M/G/1/FCFS ]=E[TQ]M/G/1/FCFS=λE[S2\nx]\n2(1−ρx).\nSo\n(2) =λE[S2\nx]\n2(1−ρx).\nDerivation of (3): To derive (3), observe that\n(3) =E[# arrivals during T(x)]·E[size of arrivals as viewed by job x]\n=λE[T(x)]FBE[Sx].\nSo,\nE[T(x)]FB= (1) + (2) + (3)\n=x+λE[S2\nx]\n2(1−ρx)+λE[T(x)]FBE[Sx]\n=x+λE[S2\nx]\n2(1−ρx)+ρxE[T(x)]FB.\nNow collecting the E[T(x)]FBterms together we have\nE[T(x)]FB(1−ρx)=x+λE[S2\nx]\n2(1−ρx).\nSo\nE[T(x)]FB=x+λE[S2\nx]\n2(1−ρx)\n1−ρx(30.5)\n=x(1−ρx)+1\n2λE[S2\nx]\n(1−ρx)2. (30.6)\nExpression ( 30.5) gives us another way of thinking about E[T(x)]FB– as the mean\nlength of a busy period. Consider a busy period started by only the job itself ( x) plus\nthe “relevant” work that it ﬁnds in the system when it arrives/parenleftbigg\nλE[S2\nx]\n2(1−ρx)/parenrightbigg\n, where all\njobs arriving during the busy period have job sizes Sx. Then ( 30.5) is the mean length\nof that busy period (see Section 27.2).\nSeveral interesting results regarding FB will be explored in the exercises:\nrIf the job size distribution has DFR, then younger jobs have lower remaining\nservice times, so\nE[T]FB<E[T]PS\nas expected; see [ 189] for a formal proof.",8658
188-30.5 Exercises.pdf,188-30.5 Exercises,"30.4 readings 495\nrIf the job size distribution has increasing failure rate (IFR), then younger jobs\nhave higher remaining service time, so favoring the younger jobs (as FB does) isbad and\nE[T]FB>E[T]PS\nas expected.\nrIf the job size distribution has constant failure rate (Exponentially distributed),then remaining time is independent of age, so we might expect that\nE[T]FB=E[T]PS.\nIn Exercise 30.3, you will prove this equality for the Exponential distribution.\nrAlso for an Exponential job size distribution, we will see in Exercise 30.2 that\nE[Slowdown ]FB<E[Slowdown ]PS.\nQuestion: Why would the slowdown under FB, under an Exponential job size\ndistribution, be strictly smaller than under PS, although their mean response timesare equal?\nAnswer: Here is a heuristic argument: Under an Exponential workload, age is\nindependent of remaining time. So, biasing toward jobs with small ages does\nnot favor jobs with small remaining service requirement, and remaining service\nrequirement is what affects\nE[T]. However, biasing toward jobs with small ages\ndoes slightly favor jobs with smaller expected original size. So FB is in essence\ngiving slight preference to short jobs even under the Exponential distribution,\nand this is what improves E[Slowdown ].\n30.4 Readings\nAthough the M/G/1/PS has simple solutions for E[T]andE[T(x)], the variance\nof response time, Var(T), is far more difﬁcult to analyze and is not known in a\nsimple closed form. For those interested in learning more, a good place to start is\nthe survey paper by Yashkov and Yashkova [ 197]. There are also many variants of\nPS in the literature, which allow for time-sharing with different weights, including\nDiscriminatory Processor-Sharing (DPS) and Generalized Processor-Sharing (GPS).A survey of these and other variants is given in [ 1].\nForeground-Background (FB) scheduling, also known as Least-Attained-Service\n(LAS), has received a lot of attention, both analytically and from a practical per-spective. On the analytical front, we recommend the thesis by Misja Nuijens [ 133]\nand [ 143]. On the implementation front, FB has been used for IP ﬂow scheduling; see\n[144,142].\nPolicies like PS and FB that do not make use of size are sometimes called blind ; see\n[60]. Additional references on all these scheduling policies can be found in Adam\nWierman’s thesis [ 188].\n496 scheduling: preemptive, non-size-based policies\n30.5 Exercises\n30.1 Review of Scheduling Formulas\nMatch each of the following 12 expressions to oneof the formulas (a) through\n(g). Read the glossary to make sure you understand all the expressions.\n(1)E[T]M/G/1/FCFS(7)E[T]M/M/1/FB\n(2)E[T]M/G/1/PS(8)ρ\n(3)E[T]M/G/1/LCFS(9)E[B]M/G/1/FCFS\n(4)E[T]M/G/1/PLCFS(10)E[B]M/M/1/FCFS\n(5)E[T]M/M/1/FCFS(11)E[Se]\n(6)E[T]M/M/1/PS(12)E[W]M/G/1/FCFS\nFormulas:\n(a)λE[S](b)E[S2]\n2E[S](c)E[S]\n1−ρ(d)ρ\n1−ρE[Se](e)ρ\n1−ρE[Se]+E[S]\n(f)E[Se]\n1−ρ(g) None of the above\nGlossary:\nρ=load = fraction of time server is busy\nT=response time\nB=busy period duration\nλ=average arrival rate\nS=service requirement for jobs\nSe=excess of S\nW=work seen by an arrival into the queue\n30.2 Comparison of FB and PS Scheduling Policies\nConsider an M/G/1 server with load ρ=0.8. Consider two job size distribu-\ntions:\n(a) Exponential distribution with mean 3,000\n(b) Bounded Pareto distribution BP(k= 332 .067,p=1 010,α=1.1)with\nmean 3,000\nFor each distribution, compute E[T]andE[Slowdown ]under both FB and\nPS scheduling. Use a symbolic math package to do the computations.1\n30.3 FB versus PS under Exponential Workloads\nIn Exercise 30.2 you should have found that the mean response time under\nFB and under PS was the same if the job size distribution was Exponential. In\nthe chapter, we gave intuition for why this might be true. Prove formally that\nthis should be the case. [Hint: There is an ugly long proof and a very beautifulshort proof.]\n30.4 Starvation under FB\nConsider an M/G/1 server with load\nρ=0.8. Consider two job size distribu-\ntions:\n1The following link provides all the functions that you will need already coded for use with MathematicaTM:\nhttp://www.cs.cmu.edu/ ∼harchol/PerformanceModeling/software.html.\n30.5 exercises 497\n(a) Exponential distribution with mean 3,000.\n(b) Bounded Pareto distribution, BP(k= 332 .067,p=1 010,α=1.1),\nwith mean 3,000.\nThe FB policy favors small jobs (or those that are expected to be small). In this\nway it improves on the performance of PS. However, there is a fear that thisbeneﬁt may come at the cost of causing large jobs to suffer unfairly. In thisproblem, we compare the mean slowdown of large jobs under FB and underPS to study the effect of this unfairness. You will need to use a symbolic math\npackage (use the link in Footnote 1).\n(a) Compare the mean slowdown of a job in the 90th percentile under FB and\nunder PS.\n(b) Compare the mean slowdown of a job in the 99th percentile under FB and\nunder PS.\n(c) What is the ﬁrst percentile where a job does worse under FB than under\nPS?\n(d) Explain why so few jobs suffer under FB.\n30.5 Analysis of Preemptive-LCFS\nThis question develops a clearer understanding of PLCFS.(a) Determine the Laplace transform for time in system under PLCFS,\n/tildewideT(s)PLCFS. Follow exactly the approach we used in the chapter where\nwe ﬁrst consider the response time of a job of size xand then look at how\nmany times that job gets interrupted and what the contribution of each such\ninterruption looks like.\n(b) Use this transform to determine the ﬁrst 2 moments of response time.\n(c) You should notice something very simple about your transform. It should\nlook identical to a transform that you derived recently. This will give you a\nnew way of looking at PLCFS. Explain why this alternative, simpler, view\nof PLCFS is also correct.\n30.6 M/G/1/FB Transform\nIn this chapter we derived the mean response time for FB. Use the same\narguments to derive the transform of response time.\n30.7 Database Performance\nBianca observes that her database throughput drops when she runs too many\ntransactions concurrently (this is typically due to thrashing). She also observes\nthat if she runs too few transactions concurrently, her database throughputdrops as well (this is often due to insufﬁcient parallelism). To capture theseeffects, Bianca models her time-sharing database system as an M/M/1/PSqueue with load-dependent service rate,\nμ(n), where ndenotes the number of\nconcurrent transactions. The function μ(n)is shown in Figure 30.5.\n(a) Solve for the mean response time under Bianca’s M/M/1/PS system. As-\nsume arrival rate λ=0.9. [Hint: Use a Markov chain.]\n(b) Bianca has a great idea: Rather than allow all transactions into the database\nas before, she decides to allow at most 4 transactions to run concurrently in\nthe database, where all remaining transactions are held in a FCFS queue.\nBianca’s new queueing architecture is shown in Figure 30.6. Compute\nthe mean response time for Bianca’s new architecture, again assuming\n498 scheduling: preemptive, non-size-based policies\n(n)\nn\n01123\n23456789 1 0\nFigure 30.5. Service rate in the database changes depending on number of concurrent trans-\nactions, n, staying constant at 1 for n≥6. Ignore non-integral values of n.\nλ=0.9, and Exponentially distributed service times with rates from Fig-\nure30.5. What is the intuition behind Bianca’s hybrid FCFS/PS architec-\nture?\nPS\nMPL = 4(n) λFCFS\nFigure 30.6. Processor-Sharing with limited multiprogramming level, MPL =4.\n(c) Varun suggests that if the job size distribution is highly variable (much\nmore variable than an Exponential), it may be better to increase the MPL\nto more than 4, even though that causes the service rate to drop. What\nis the intuition behind Varun’s suggestion? [Hint: Observe that Bianca’s\nFCFS/PS architecture has some properties of FCFS and some properties\nof PS.]\nIf you would like to learn more about analyzing the limited Processor-Sharing\nsystem in Figure 30.6, we recommend [ 77,198,199].",8044
189-Chapter 31 Scheduling Non-Preemptive Size-Based Policies.pdf,189-Chapter 31 Scheduling Non-Preemptive Size-Based Policies,,0
190-31.1 Priority Queueing.pdf,190-31.1 Priority Queueing,"CHAPTER 31\nScheduling: Non-Preemptive,\nSize-Based Policies\nUntil now, we have only considered scheduling policies that do not have any knowledge\nof the job sizes. In this chapter and the next two chapters, we will look at size-basedscheduling policies, starting with non-preemptive size-based policies (this chapter)and followed by preemptive size-based policies (next two chapters). The size-basedpolicies that we will be studying include the following:\nSJF – (non-preemptive) Shortest-Job-First (Chapter 31)\nPSJF – Preemptive-Shortest-Job-First (Chapter 32)\nSRPT – (preemptive) Shortest-Remaining-Processing-Time (Chapter 33)\nIt will be convenient to evaluate these size-based policies as special cases of priority\nqueueing, so we start by analyzing priority queues, which are important in their own\nright.\nSize-based scheduling is a very important topic, which is why we devote three chapters\nto it. The proper size-based scheduling policy can greatly improve the performanceof a system. It costs nothing to alter your scheduling policy (no money, no newhardware), so the performance gain comes for free. The above size-based policies areimplemented in real systems. For web servers serving static content, SRPT schedulinghas been implemented in the Linux kernel to schedule HTTP requests [ 92]. It has\nalso been used to combat transient overload in web servers [ 162]. Priority queues are\nlikewise prevalent in computer systems. Prioritization of jobs is used in databases toprovide differentiated levels of service, whereby high-priority transactions (those thatbring in lots of money) are given priority over low-priority transactions (those thatare less lucrative). Prioritization can be implemented in different ways in database\nservers, sometimes internally by scheduling the database lock queues, and sometimes\nexternally by limiting the multiprogramming level in the database to favor high-prioritytransactions; see [ 123,164,163] and the references therein.\n31.1 Priority Queueing\nWe now describe a model for an M/G/1 priority queue. Arriving jobs are divided into n\npriority classes, where class 1is the highest priority and class nis the lowest priority.\nClasskjob arrivals form a Poisson process with rate λk=λ·pk, where/summationtextn\nk=1pk=1.\nThe service time distribution for a job of class khas moments E[Sk]andE[S2\nk].\n499\n500 scheduling: non-preemptive, size-based policies\npriority 1\njobs1st priority\n2nd priority\nnth prioritypriority 2\njobs\npriority n\njobs\nFigure 31.1. When a server frees up, it takes the job at the head of the highest priority,\nnon-empty queue.\nWe can picture the M/G/1 priority queue as maintaining a separate (imaginary) queue\nfor each class. When the server becomes free, it always chooses the job at the head ofthe highest priority non-empty queue to work on, as shown in Figure 31.1.\nWe consider two types of priority queueing:\n1. Non-Preemptive Priority Queueing – Once a job starts running, it cannot be\npreempted, even if a higher priority job comes along.\n2. Preemptive Priority Queueing – The job in service is preempted if a higher\npriority job arrives, and the higher priority job is then served. No work is lost.\nQuestion: What are some examples where non-preemptive priority queueing is used\nand where preemptive priority queueing is used?\nAnswer: Non-preemptive priority queueing is used whenever a job cannot be stopped\nonce it has started running. For example, airline ticket counters want to ticket the\nﬁrst-class customers before the coach customers, but once they start ticketing a coachcustomer, they cannot stop midway if a ﬁrst-class customer arrives.\nPreemptive priority queueing is often used for job scheduling in computer systems.\nInteractive jobs get precedence over batch jobs and can preempt a running batch job.\nNotation\nWe always write the priority in parentheses. Class 1 jobs have highest priority; class 2\nnext highest priority, etc. Class\nnjobs have lowest priority.\nAs you can probably guess, priority will eventually become related to size; a job’s size\nwill be its priority, where a job of size xhas priority over a job of size yifx<y ,f o r\nreal-valued xandy.\nSk=size of priority kjob\nE[NQ(k)] = average number of priority kjobs in the queue\nE[TQ(k)] = average time in queue for priority kjobs",4334
191-31.2 Non-Preemptive Priority.pdf,191-31.2 Non-Preemptive Priority,"31.2 non-preemptive priority 501\nE[T(k)] = average time in system for priority kjobs\nλk=λ·pk=average arrival rate of jobs of priority k\nρk=λkE[Sk]=contribution to the load due to jobs of priority k\nWe will require that the server utilization, ρ, is less than 1:\nn/summationdisplay\ni=1ρi=n/summationdisplay\ni=1λiE[Si]=n/summationdisplay\ni=1λ·piE[Si]=λE[S]=ρ<1.\nNote that S, as usual, represents an arbitrary job’s size. Hence,\nE[S]=n/summationdisplay\nk=1pkE[Sk];E/bracketleftbig\nS2/bracketrightbig\n=n/summationdisplay\nk=1pkE/bracketleftbig\nS2\nk/bracketrightbig\n;E[Se]=E/bracketleftbig\nS2/bracketrightbig\n/E[S]2\n31.2 Non-Preemptive Priority\nWe will use a “tagged-job” type of argument to derive the performance of a non-\npreemptive M/G/1 priority queue. It will help greatly to review the “tagged-job” argu-ment for the M/G/1/FCFS queue from Chapter 23before reading this section.\nDeriving\nTQ(1)– Time in Queue for Jobs of Priority 1\nConsider a priority 1 arrival. That arrival has to wait for both\n(i) The job currently in service, if there is one.\n(ii) All jobs of priority 1 in queue when the job arrives.\nE[TQ(1)] = P{Server busy}·E[Se]+E[NQ(1)]·E[S1]\n=ρ·E[Se]+E[TQ(1)]·λ1·E[S1]\n=ρ·E[Se]+E[TQ(1)]·ρ1\n=ρ·E[Se]\n1−ρ1\nDeriving TQ(2)– Time in Queue for Jobs of Priority 2\nConsider a priority 2 arrival. That arrival has to wait for\n(i) The job currently in service, if there is one.\n(ii) All jobs of priority 1 or 2 in queue when the job arrives.\n(iii) All jobs of priority 1 that arrive while the new job is waiting (not in service).\nE[TQ(2)] = ρ·E[Se]+E[NQ(1)]·E[S1]+E[NQ(2)]·E[S2]\n+E[TQ(2)]·λ1E[S1]\n=ρ·E[Se]+E[TQ(1)]·ρ1+E[TQ(2)]·ρ2+E[TQ(2)]·ρ1\n502 scheduling: non-preemptive, size-based policies\nE[TQ(2)]·(1−ρ1−ρ2)=ρE[Se]+ρ1·E[TQ(1)]\nE[TQ(2)]·(1−ρ1−ρ2)=ρE[Se]+ρ1·ρE[Se]\n1−ρ1=ρE[Se]\n(1−ρ1)\nE[TQ(2)] =ρE[Se]\n(1−ρ1)(1−ρ1−ρ2)\nDeriving TQ(k)– Time in Queue for Jobs of Priority k\nConsider a priority karrival. That arrival has to wait for\n(i) The job currently in service, if there is one.\n(ii) All jobs of priority 1,2,...,k in queue when the job arrives.\n(iii) All jobs of priority 1,2,...,k−1that arrive while the new job is waiting.\nAfter some algebra, we can show by induction that\nE[TQ(k)]NP-Priority=ρE[Se]/parenleftBig\n1−/summationtextk\ni=1ρi/parenrightBig/parenleftBig\n1−/summationtextk−1\ni=1ρi/parenrightBig.\nFinally, substituting in the formula for E[Se], from ( 23.9), we have\nE[TQ(k)]NP-Priority=ρE[S2]\n2E[S]/parenleftBig\n1−/summationtextki=1ρi/parenrightBig/parenleftBig\n1−/summationtextk−1\ni=1ρi/parenrightBig. (31.1)\nInterpreting the Formula for E[TQ(k)]NP-Priority\nQuestion: Explain the difference between the formula for E[TQ(k)]NP-Priorityand the\nformula for E[TQ]FCFS.\nAnswer: Recall that for the M/G/1/FCFS queue\nE[TQ]FCFS=ρE[S2]\n2E[S]\n1−ρ.\nRecall in the tagged job analysis for the M/G/1/FCFS queue that the numerator, ρE[S2]\n2E[S],\nis due to waiting for the job in service. Speciﬁcally, this numerator represents the\nprobability that there is a job in service ( ρ) multiplied by the expected remaining time\non that job given that there is a job in service (E[Se]=E[S2]\n2E[S]). This is also the case in\nthe numerator for the M/G/1/NP-Priority queue.\nRecall next that in the M/G/1/FCFS queue, the denominator, 1−ρ, is due to waiting\nfor the jobs already in the queue. In the M/G/1/NP-Priority formula, the denominator\n31.2 non-preemptive priority 503\nhas two components. The\n/parenleftBigg\n1−k/summationdisplay\ni=1ρi/parenrightBigg\nterm can be thought of as the contribution due to waiting for jobs in the queue of higher\nor equal priority. Observe that a job of class konly needs to wait behind those jobs in\nthe queue of class up to k. The\n/parenleftBigg\n1−k−1/summationdisplay\ni=1ρi/parenrightBigg\nterm can be thought of as the contribution due to those jobs that arrive after our job, but\nhave strictly higher priority than our tagged job (i.e., jobs of class 1tok−1arriving\nafter our job). This second part of the denominator obviously does not occur underFCFS.\nQuestion: Now compare what happens to high-priority jobs (low\nk) under non-\npreemptive priority queueing versus under FCFS.\nHint:\nE[TQ(k)]NP-Priority≈1\n(1−/summationtextk\ni=1ρi)2·ρE[S2]\n2E[S].\nE[TQ(k)]FCFS=E[TQ]FCFS=1\n1−ρ·ρE[S2]\n2E[S].\nAnswer: TheE[TQ(k)]NP-Priorityformula has the disadvantage of the squared denom-\ninator, due to having to wait behind later arrivals. However it has the advantage of onlyseeing load due to jobs of class\nkor less. Here is the point: Suppose kis low (i.e., we\nhave a high-priority job). Then,\nk/summationdisplay\ni=1ρi/lessmuchρ.\nSo\nE[TQ(k)]NP-Priority<E[TQ]FCFS.\nNow let’s suppose that the job’s priority is related to its size, where the smaller the job\nis, the higher its priority. Recall that if the service time distribution has the heavy-tailproperty, then the largest\n1%of the jobs make up most of the load. Thus, even for\nhigher values of k(but not the max k) we have that\nk/summationdisplay\ni=1ρi/lessmuchρ.\nSo\nE[TQ(k)]NP-Priority<E[TQ]FCFS,",5087
192-31.3 Shortest-Job-First SJF.pdf,192-31.3 Shortest-Job-First SJF,"504 scheduling: non-preemptive, size-based policies\neven for higher values of k. Of course, for a job of class n, NP-Priority is worse than\nFCFS, because of the squared term in the denominator.\nQuestion: H o wd ow eg e t E[TQ]NP-Priority,g i v e nE[TQ(k)]?\nAnswer:\nE[TQ]NP-Priority=n/summationdisplay\nk=1E[TQ(k)]·pk=n/summationdisplay\nk=1E[TQ(k)]·λk\nλ.\n31.3 Shortest-Job-First (SJF)\nOne way of assigning priorities is as a function of the job size.\nQuestion: If your goal is minimizing mean response time, which do you think should\nhave higher priority: the large jobs or the small ones?Answer: The small ones. See Exercise 31.1.\nShortest-Job-First (SJF) is a non-preemptive scheduling policy (once a job is running,\nit is never interrupted). Whenever the server is free, it chooses to work on the job with\nthesmallest size .\nQuestion: How can we analyze the performance of SJF given what we have just seen?\nAnswer: We can use our results for non-preemptive priority queueing. We model SJF\nby having an inﬁnite number of priority classes, where the smaller the job, the higherits priority.\nAnalysis of SJF\nConsider again the situation of\nnpriority classes. Let’s assume that the job sizes range\nbetween x0=0andxn. Deﬁne boundary points x1,x2,...x n−1such that\nx0<x 1<x 2<···<x n−1<x n.\nAssign all jobs of size ∈(xk−1,xk)to class k, as shown in Figure 31.2. Then,\nE[TQ(k)]NP-Priority=ρE[S2]\n2E[S]·1/parenleftBig\n1−/summationtextk−1\ni=1ρi/parenrightBig/parenleftBig\n1−/summationtextk\ni=1ρi/parenrightBig\nwhereE[TQ]NP-Priority=n/summationdisplay\nk=1pk·E[TQ(k)].\nClass 1\n0 x1 x2 x3 xn–1 xnClass 2 Class 3 Class n\nFigure 31.2. Deﬁning classes based on job size.\n31.3 shortest-job-first (sjf) 505\nObserve that pk, the fraction of jobs in class k, equals F(xk)−F(xk−1), where\nF(xn)=1 , andF(x0)=0 . So far we have not used anything but the original NP-\nPriority formulas.\nNow consider the situation where n→∞ andxk−xk−1→0. That is, the number of\nclasses, n, is allowed to grow to ∞, in such a way that (xk−xk−1)becomes arbitrarily\nsmall∀k.\nWe are interested in the expected waiting time for a job of size xk.A sn→∞ ,\nLoad of jobs in class 1tok→Load of jobs of size <x k\nk/summationdisplay\ni=1ρi=λk/summationdisplay\ni=1piE[Si]→λ/integraldisplayxk\nt=0tf(t)dt.\nLoad of jobs in class 1tok−1→Load of jobs of size <x k−1\nk−1/summationdisplay\ni=1ρi=λk−1/summationdisplay\ni=1piE[Si]→λ/integraldisplayxk−1\nt=0tf(t)dt→λ/integraldisplayxk\nt=0tf(t)dt.\nSo,\nE[TQ(x)]SJF=ρE[S2]\n2E[S]·1\n(1−λ/integraltextx\nt=0tf(t)dt)2. (31.2)\nAnd\nE[TQ]SJF=/integraldisplayxn\nx=0E[TQ(x)]f(x)dx\n=ρE[S2]\n2E[S]·/integraldisplayxn\nx=0f(x)dx\n(1−λ/integraltextx\nt=0tf(t)dt)2. (31.3)\nNow, let’s compare SJF with FCFS for a job of size x. To do this, we ﬁrst need to\ndeﬁne a term.\nDeﬁnition 31.1 Let\nρx=λ/integraldisplayx\nt=0tf(t)dt. (31.4)\nThe term ρxdenotes the load composed of jobs of size 0tox. Note that we can\nexpress ρxequivalently as\nρx=λF(x)/integraldisplayx\nt=0tf(t)\nF(x)dt, (31.5)\nwhich shows more explicitly that we are multiplying the arrival rate of jobs of size\nno more than x, namely λF(x), by the expected size of jobs of size no more than\nx, namely/integraltextx\nt=0tf(t)\nF(x)dt.\nNote:ρxis different from ρx, which we saw in the FB policy analysis.",3302
193-Chapter 32 Scheduling Preemptive Size-Based Policies.pdf,193-Chapter 32 Scheduling Preemptive Size-Based Policies,"506 scheduling: non-preemptive, size-based policies\nRewriting ( 31.2) using ρx,w eh a v e\nE[TQ(x)]SJF=ρE[S2]\n2E[S]·1\n(1−ρx)2.\nBy comparison we have, for FCFS:\nE[TQ(x)]FCFS=ρE[S2]\n2E[S]·1\n1−ρ.\nObserve that ρxis typically much less than ρ. For small jobs (small x),E[TQ(x)]SJF\nshould be lower than E[TQ(x)]FCFS. For very large jobs, E[TQ(x)]SJFis higher than\nE[TQ(x)]FCFSbecause of the squared factor in the denominator. If the service time\ndistribution is heavy-tailed, then E[TQ(x)]SJFis only higher for the very, very large\njobs. Because most jobs are small,\nE[TQ]SJF<E[TQ]FCFS.\n31.4 The Problem with Non-Preemptive Policies\nQuestion: Nonetheless, we claim that SJF is still a poor choice of scheduling policies\nin the case of a heavy-tailed job size distribution, when trying to minimize mean time\nin queue. Why is this?\nAnswer: The expression for mean time in queue contains an E[S2]term, and in\nheavy-tailed job size distributions, the variance is huge! It would be much better to use\na scheduling policy whose mean delay does not involve an E[S2]term. For example,\nwe might use the PS, PLCFS, or FB policies that we discussed in the last chapter.\nQuestion: What about the mean time in queue for really small jobs?\nAnswer: Even for small jobs, performance is still affected by the variance in the job\nsize distribution. True, a system with high load ρmay appear as if it has low load from\nthe perspective of a small job; however, the variance in the job size distribution can\ndominate everything! So even a small job may not do well under SJF.\nQuestion: Explain intuitively (without using the formula) why it is that even a small\njob is not expected to do well under SJF.\nAnswer: A small job can still get stuck behind a big job, if the big job started running\nbefore the small job got there.\nSo what we really need in order to get good performance is the ability to preempt jobs.\nThis is the topic of the next chapter.Question: What can be done if preemption is not available?\nAnswer: The ability to preempt jobs is, in fact, so important that in cases where\npreemption is not naturally available, it pays to take up extra time to checkpoint the\njob, saving its state, so that it can be stopped and restarted again from that point.\n31.5 exercise 507\nQuestion: But what if checkpointing is not available either? It seems one has no choice\nthen but to run jobs to completion?\nAnswer: If the job size variability is high enough and one does not know how long a\njob is going to take, it can actually be better to kill a running job after some time, given\nthat there are other jobs queued up. This may seem foolish, because the killed job willeventually have to be restarted from scratch, and this creates extra work. However, if\nthere are many jobs queued up, they are likely to include many short jobs, and meanresponse time will improve by letting those short jobs get a chance to run. This is theidea behind the TAGS policy [ 82].\n31.5 Exercise\n31.1 Why Small Jobs Should Get Priority\nConsider an M/G/1 system with non-preemptive priority scheduling. Suppose\nthere are two customer classes of jobs – S (small) and L (large) – with arrival\nratesλSandλLand mean job size E[SS]andE[SL], where\nE[SS]<E[SL].\nProve that, to minimize the mean waiting time over all jobs, we should give\nclass S jobs priority over class L jobs. Do this by deriving E[TQ]NP-Priorityfor\nthe case where S has priority and for the case where L has priority.",3484
194-32.1 Motivation.pdf,194-32.1 Motivation,,0
195-32.2 Preemptive Priority Queueing.pdf,195-32.2 Preemptive Priority Queueing,"CHAPTER 32\nScheduling: Preemptive,\nSize-Based Policies\nIn this chapter, we discuss preemptive scheduling policies that make use of knowing\nthe size of the job. As in the last chapter, we start by deﬁning and evaluating preemptivepriority queueing, and then we extend that analysis to the Preemptive-Shortest-Job-First(PSJF) scheduling policy.\n32.1 Motivation\nRecall that we can divide scheduling policies into non-preemptive policies and pre-emptive policies.\nQuestion: What is discouraging about the mean response time of all the non-preemptive\nscheduling policies that we have looked at?\nAnswer: They all have an\nE[S2]factor that comes from waiting for the excess of the\njob in service. This is a problem under highly variable job size distributions.\nWe have also looked at preemptive policies. These tend to do better with respect to\nmean response time under highly variable job size distributions. Not all of these haveequal performance, however. Preemptive policies like PS and PLCFS that do not makeuse of size have mean response time equal to that of M/M/1/FCFS; namely, they areinsensitive to the job size distribution beyond its mean. This is already farbetter than\nnon-preemptive scheduling policies, when the job size distribution has high variability.However, preemptive policies that make use of size or age can do even better by biasingtoward jobs with small size. So far, we have seen this only for the FB scheduling policythat favors jobs with small age. In this chapter and the next, we will examine policiesthat make use of a job’s (original) size and remaining size.\n32.2 Preemptive Priority Queueing\nWe start with preemptive priority queueing. As in the non-preemptive case, we assume\nthe following:\nrThere are nclasses.\nrClass 1 has highest priority.\nrClasskjobs arrive according to a Poisson process with rate λk=λ·pk.\nrClasskjobs have service requirements with moments E[Sk]andE[S2\nk].\nrThe load of class kisρk=λk·E[Sk].\n508\n32.2 preemptive priority queueing 509\nAt every point in time, the server is working on the highest priority job in the system.\nPreemptive priority queueing differs from non-preemptive queueing in that whenevera job arrives with a higher priority than the job currently in service, the job in ser-vice is preempted and the higher priority job begins service. No work is lost underpreemptions.\nOne application of preemptive priority queueing is a network where a number of differ-\nent packet streams with different priorities are trying to use the same communicationlink. Each stream consists of a sequence of packets. Only one stream ﬂows through thecommunication link at a time. If a higher priority stream starts up, the current streamsuspends its service and waits for the higher priority stream to ﬁnish.\nWe will compute\nE[T(k)]P-Priority, the mean time in system for a job of priority kin\na system with preemptive priority. To do this, imagine a job of priority kentering the\nsystem and consider all the work that must be completed before the job can leave thesystem. This work is made up of three components:\n1.\nE[Sk]– the mean service time for a job of priority class k\n2.the expected time required to complete service on all jobs of priority 1tok\nalready in the system when our arrival walks in\n3.the expected total service time required for all jobs of priority 1tok−1that\narrive before our arrival leaves\nObserve that component (3) is simply\n(3) =k−1/summationdisplay\ni=1E[T(k)]·λi·E[Si]=E[T(k)]k−1/summationdisplay\ni=1ρi.\nBut, how do we compute component (2)?\nQuestion: Can we do what we did in the case of non-preemptive priority, namely, add\nup the expected number of jobs in each class for classes 1tok, each weighted by the\nmean job size for that class?\nAnswer: No. The jobs in queue may already have been partially worked on (remember,\nthis is a preemptive queue).\nTo determine (2), we make the following arguments:\n(2) =/parenleftBigExpected remaining work in the system due to only jobs of priority\n1through k./parenrightBig\n=/parenleftBiggTotal expected remaining work in preemptive priority system if the\nsystem only ever had arrivals of priority 1through k(because jobs\nof class >kdo not affect jobs of class 1through k)./parenrightBigg\n=⎛\n⎜⎝Total expected remaining work in system if the system only ever had\narrivals of class 1through kandthe scheduling order was any work-\nconserving order; for example, FCFS (because all work-conservingpolicies have the same remaining work).⎞\n⎟⎠\n510 scheduling: preemptive, size-based policies\n=/parenleftBigE/bracketleftbig\nTQ/bracketrightbigunder FCFS scheduling order, where the system only has\narrivals of class 1through k/parenrightBig\n=/summationtextk\ni=1ρi\n1−/summationtextki=1ρi·/summationtextki=1p\ni\nFkE[S2\ni]\n2/summationtextki=1p\ni\nFkE[Si],where Fk=k/summationdisplay\ni=1pi\nThis can be simpliﬁed a bit as follows:\n(2) =λ/summationtextki=1piE[Si]\n1−/summationtextki=1ρi·/summationtextki=1piE[S2\ni]\n2/summationtextki=1piE[Si]=λ/summationtextki=1piE[S2\ni]\n2(1−/summationtextki=1ρi)=/summationtextki=1ρiE[S2\ni]\n2E[Si]\n1−/summationtextki=1ρi.\nSo, ﬁnally, adding (1) and (2) and (3), we have\nE[T(k)]P-Priority=E[Sk]+/summationtextki=1ρiE[S2\ni]\n2E[Si]\n1−/summationtextki=1ρi+E[T(k)]k−1/summationdisplay\ni=1ρi\nE[T(k)]/parenleftBigg\n1−k−1/summationdisplay\ni=1ρi/parenrightBigg\n=E[Sk]+/summationtextki=1ρiE[S2\ni]\n2E[Si]\n1−/summationtextki=1ρi\nE[T(k)]P-Priority=E[Sk]\n1−/summationtextk−1\ni=1ρi+/summationtextki=1ρiE[S2\ni]\n2E[Si]\n(1−/summationtextk−1\ni=1ρi)(1−/summationtextki=1ρi).(32.1)\nInterpretation of E[T(k)]P-Priority\nWe now look for a way to interpret ( 32.1). For preemptive service disciplines, one can\nview the time in system of a job as divided into two components:\n1.the time until the job ﬁrst starts serving (also called waiting time ), denoted by\nWait\n2.the time from when the job ﬁrst receives some service, until it leaves the system\n(also called residence time ), denoted by Res\nQuestion: Is residence time the same as service time?\nAnswer: No. The residence time is a lot longer. It includes all interruptions.\nQuestion: Consider the expression ( 32.1) for the mean time in system for a job of class\nkunder preemptive priority queueing. What does the ﬁrst term\nE[Sk]\n1−/summationtextk−1\ni=1ρi(32.2)\nrepresent?\nAnswer: This represents the mean residence time of the job of class k,E[Res(k)].Y o u\nshould recognize this formula as being the expected length of a busy period started by\na job of size E[Sk], where the only jobs that are allowed in the busy period (after the\nﬁrst job) are those of class 1through k−1.\n32.2 preemptive priority queueing 511\nObserve that once the job of class kstarts to serve, it can only be interrupted by jobs\nof class 1through k−1. The time until our job of class kcan leave is thus the length\nof the busy period created by those interruptions of class 1through k−1.\nQuestion: Now explain the second term in ( 32.1).\nAnswer: By deﬁnition, the remaining term in ( 32.1)i s\nE[Wait(k) ]=/summationtextk\ni=1ρiE[S2\ni]\n2E[Si]/parenleftBig\n1−/summationtextk−1\ni=1ρi/parenrightBig/parenleftBig\n1−/summationtextk\ni=1ρi/parenrightBig,\nrepresenting the mean time until the job of priority kﬁrst receives service. Note that\nthis term is almost identical to E[TQ(k)]for the non-preemptive priority queue ( 31.1),\nexcept that the numerator (corresponding to excess of the job in service) now represents\nonly excess due to jobs of class 1through k.1This is clear, because a job in service of\nclass greater than kwill just be immediately preempted.\nIt is sometimes convenient to rewrite ( 32.1)a s\nE[T(k)]P-Priority=E[Sk]\n1−/summationtextk−1\ni=1ρi+λ\n2/summationtextk\ni=1piE[S2\ni]\n(1−/summationtextk−1\ni=1ρi)(1−/summationtextki=1ρi).(32.3)\nQuestion: Recall that in the case of non-preemptive priority and SJF, we found that a\nhigh priority job (or a “small” job in SJF) does not necessarily obtain good performance\nbecause it still has to combat the variability in the job size distribution. Is that the casehere as well?\nAnswer: No. Observe that both terms in\nE[T(k)]P-Prioritydepend only on the ﬁrst k\npriority classes, as we would expect, as compared with the non-preemptive priority\nsystem.\nThis means that a high priority (low k) job in preemptive priority queueing really does\nwin, even in a high-variability job size distribution, because it only sees the variability\n1In the non-preemptive case, we had\nE/bracketleftbig\nTQ(k)/bracketrightbigNP-Priority=ρE[S2]\n2E[S]/parenleftBig\n1−/summationtextk\ni=1ρi/parenrightBig/parenleftBig\n1−/summationtextk−1\ni=1ρi/parenrightBig.\nThe denominator of this expression is equal to that for the preemptive priority queue. The\nnumerator of this expression can be viewed as\nρE/bracketleftbig\nS2/bracketrightbig\n2E[S]=λ\n2E/bracketleftbig\nS2/bracketrightbig\n=λ\n2n/summationdisplay\ni=1piE/bracketleftbig\nS2\ni/bracketrightbig\n=n/summationdisplay\ni=1λi·E/bracketleftbig\nS2\ni/bracketrightbig\n2=n/summationdisplay\ni=1ρi/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n↑\nProbability there is a job\nin service of class i·Expected excess for job\nin service of class i/bracehtipdownleft/bracehtipupright/bracehtipupleft/bracehtipdownright\nE/bracketleftbig\nS2\ni/bracketrightbig\n2E[Si].\nThus for the non-preemptive priority queue, all nclasses (rather than just kclasses) contribute\nto the excess.",9482
196-32.3 Preemptive-Shortest-Job-First PSJF.pdf,196-32.3 Preemptive-Shortest-Job-First PSJF,"512 scheduling: preemptive, size-based policies\ncreated by the ﬁrst kclasses and not the variability of the entire distribution. Also, it\nsees only the load created by the ﬁrst kclasses and not the entire system load (this\nlatter property is also true for non-preemptive priority and SJF).\n32.3 Preemptive-Shortest-Job-First (PSJF)\nThe PSJF policy is deﬁned similarly to the SJF (Shortest-Job-First) policy, except that\nthe size-based priorities are enforced preemptively. Thus at any moment in time, thejob in service is the job with the smallest original size. A preemption only occurs when\na new job arrives whose size is smaller than the original size of the job in service.\nQuestion: How can we analyze the mean response time of PSJF?\nAnswer: There are two approaches. We cover both here.\nThe ﬁrst approach is to make use of our results for scheduling with preemptive priority\nclasses, where we assume that a job’s class is its size, and we take the limit as thenumber of classes goes to inﬁnity. Starting with the preemptive priority response timefor class\nk,(32.3),\nE[T(k)]P-Priority=E[Sk]\n1−/summationtextk−1\ni=1ρi+λ\n2/summationtextk\ni=1piE[S2\ni]\n(1−/summationtextk−1\ni=1ρi)(1−/summationtextki=1ρi),\nand performing the same limiting operations as we did in analyzing SJF (where we\nimagine that jobs of size xform one “class” and that there are an inﬁnite number of\nclasses), we have\nE[T(x)]PSJF=x\n1−ρx+λ\n2/integraltextx\n0f(t)t2dt\n(1−ρx)2, (32.4)\nwhere f(t)is the p.d.f. of job size, S, andρx=λ/integraltextx\n0tf(t)dtis deﬁned to be the load\nmade up by jobs of size less than x, see ( 31.4).\nNow let’s pretend that we did not have a preemptive priority class formula and look at\nhow we could have derived the mean response time for PSJF from scratch. We start by\nbreaking up response time into waiting time and residence time:\nE[T(x)]PSJF=E[Wait(x) ]PSJF+E[Res(x)]PSJF\nHere Wait(x) represents the time until job xreceives its ﬁrst bit of service, and Res(x)\nrepresents the time from when job xreceives its ﬁrst bit of service until it is complete.\nQuestion: What is E[Res(x)]PSJF?\nAnswer: Res(x) is just the duration of a busy period started by a job of size x, where\nthe only jobs that make up this busy period are jobs of size ≤x. Thus\nE[Res(x)]PSJF=x\n1−ρx.\nQuestion: Can we also think of E[Wait(x) ]PSJFas a busy period duration?\n32.3 preemptive-shortest-job-first (psjf) 513\nAnswer: Yes! When a job of size xwalks in, it sees some work. However, not all the\nwork that it sees is relevant to it. The only relevant work is that made up by jobs of\n(original) size ≤x. Let’s call that work Wx.N o w , Wait(x) can be viewed as the length\nof a busy period started by a phantom job of size Wx, where the only jobs that make\nup this busy period are jobs of size ≤x.\nx\nx\nFigure 32.1. Transformer glasses for PSJF. Whereas in FB, the transformer glasses truncate\nall jobs of size >x to size x, in PSJF, the transformer glasses make jobs of size >x invisible.\nQuestion: What is E[Wx]PSJF?\nAnswer: This is the work in the system as seen when job xputs on transformer glasses\nthat make anyone whose (original) size is greater than xinvisible (see Fig. 32.1). But\ngiven that the policy is PSJF (so jobs of size ≤xare always worked on before jobs\nof size >x), we see that this is the same as the amount of work under PSJF, where\nthe only jobs allowed into the system are jobs of size ≤x. However, because PSJF is\nwork-conserving, this is the same as the amount of work in an FCFS system where\nthe only jobs in the system are jobs of size ≤x. But that work is the same as the\ntime-in-queue in an FCFS system where the only jobs in the system are jobs of size\n≤x.\nWe will use the random variable Sxto denote the size of a job of size ≤x. The density\nofSxisf(t)\nF(x)where f(t)is the density of S.\nSo,\nE[Wait(x) ]PSJF=E[Wx]\n1−ρx(mean length of busy period )\n=E[TQ|where job sizes are Sx]\n1−ρxFCFS\n=λF(x)E[S2\nx]\n2(1−ρx)\n1−ρx",3990
197-32.4 Transform Analysis of PSJF.pdf,197-32.4 Transform Analysis of PSJF,"514 scheduling: preemptive, size-based policies\n=λF(x)/integraltextx\n0t2f(t)\nF(x)dt\n2(1−ρx)2\n=λ/integraltextx\n0t2f(t)dt\n2(1−ρx)2. (32.5)\nThus\nE[T(x)]PSJF=x\n1−ρx+λ/integraltextx\n0t2f(t)dt\n2(1−ρx)2,\njust like ( 32.4).\n32.4 Transform Analysis of PSJF\nWe now derive the Laplace transform of the response time of the M/G/1/PSJF queue.\nBefore reading this, it is helpful to review Section 27.2.\nLet\nT=Response time .\nT(x)=Response time for a job of size x.\nGiven the Laplace transform of T(x), we can get the transform for Tby conditioning\non job size as follows:\n/tildewideT(s)=/integraldisplay\nx/tildewideT(x)(s)f(x)dx.\nThus we only need to determine /tildewideT(x)(s):\n/tildewideT(x)(s)=/tildewiderWait(x) (s)·/tildewiderRes(x)(s), (32.6)\nwhere Wait(x) denotes the waiting time of a job of size xandRes(x) denotes the\nresidence time of a job of size x. Both these quantities will be analyzed in terms of\nbusy periods.\nWe need the following notation:\nλx=λF(x)=arrival rate of jobs of size ≤x\nSx=arbitrary size of a job whose size is ≤x\nNote:E[Sx]=/integraldisplayx\n0tf(t)\nF(x)dt\nρx=λxE[Sx]=λ/integraldisplayx\n0tf(t)dt=load made up of jobs of size ≤x\nWx=work in system made up of jobs of size ≤x\nBx=duration of busy period of jobs of size ≤xonly\nAx\ny=number of arrivals of size ≤xduring time y\n32.4 transform analysis of psjf 515\nQuestion: Pop Quiz: What is /tildewiderBx(s)?\nAnswer:\n/tildewiderBx(s)=/tildewiderSx/parenleftBig\ns+λx−λx/tildewiderBx(s)/parenrightBig\n.\nWe are now ready to describe /tildewiderWait(x) (s)and/tildewiderRes(x)(s).\nRes(x) =duration of a busy period started by a job of size xmade up by arrivals\nof size≤x\nQuestion: Is/tildewiderRes(x)(s)=/tildewiderBx(s)?\nAnswer: No. Both BxandRes(x) are busy periods composed of jobs of size ≤x.\nHowever, the starting job in Bxis any job of size ≤x, whereas Res(x) must start with\na job of size exactly x.\nRes(x) =x+Ax\nx/summationdisplay\ni=1B(i)\nx(B(i)\nxis theith busy period )\n/tildewiderRes(x)(s)=e−sx·/hatwiderAx\nx(/tildewiderBx(s))\n=e−sx·e−(λx)x(1−/tildewiderBx(s))\n=e−x(s+λx−λx/tildewiderBx(s))(32.7)\nNow we move on to Wait(x) .\nWait(x) =duration of a busy period started by Wx, where the only arrivals are\nof size≤x\n/tildewiderWait(x) (s)=/tildewiderWx/parenleftBig\ns+λx−λx/tildewiderBx(s)/parenrightBig\n(32.8)\nQuestion: What do we know about /tildewiderWx(s)?\nAnswer:\nWx=work in PSJF system made up by jobs of size ≤x\n=work in PSJF system if there only existed those jobs of size ≤xand no others\n=work in FCFS system if there only existed jobs of size ≤xand no others\n=queueing time in FCFS system where there are only jobs of size ≤x\nHence, from ( 26.13 ), using Sx,λx, andρx,w eh a v e\n/tildewiderWx(s)=(1−ρx)s\nλx/tildewiderSx(s)−λx+s. (32.9)",2787
198-32.5 Exercises.pdf,198-32.5 Exercises,"516 scheduling: preemptive, size-based policies\nCombining equations ( 32.9), (32.8), (32.7), and ( 32.6), we have the Laplace transform\nof response time for jobs of size xunder PSJF:\n/tildewideT(x)PSJF\n(s)=/tildewiderWait(x) (s)·/tildewiderRes(x)(s)\n=/tildewiderWx/parenleftBig\ns+λx−λx/tildewiderBx(s)/parenrightBig\n·e−x(s+λx−λx/tildewiderBx(s))\n=(1−ρx)/parenleftBig\ns+λx−λx/tildewiderBx(s)/parenrightBig\n·e−x(s+λx−λx/tildewiderBx(s))\nλx/tildewiderSx/parenleftBig\ns+λx−λx/tildewiderBx(s)/parenrightBig\n−λx+/parenleftBig\ns+λx−λx/tildewiderBx(s)/parenrightBig\n32.5 Exercises\n32.1 Warmup: Preemptive Priority Queue\nConsider an M/M/1 with npreemptive priority classes, where class ijobs\narrive with rate λi. Assume that all job sizes are Exponentially distributed with\nmean1. Use the formulas in this chapter to derive a very simple expression\nfor the mean response time of the kth class.\n32.2 The cμ-Rule\n(Contributed by Urtzi Ayesta) Suppose you have a single-server queue with n\nclasses of jobs and Exponential service times. Class ijobs arrive with some\naverage rate λiand have mean service time1\nμi. Assume that there is a holding\ncost,ci, associated with class i, meaning that a class ijob incurs a cost of ci\ndollars for every second that it spends in the system. Let E[Nπ\ni]denote the\nmean number of jobs of class iunder some scheduling policy π. LetE[Wπ\ni]\ndenote the mean total work of all class ijobs in the system under scheduling\npolicy π. LetCost(π)=/summationtextn\ni=1ciE[Nπ\ni]denote the mean operational cost\nunder policy π;E[Nπ]denote the mean number of jobs in the system under\npolicy π; andE[Tπ]denote the mean response time under policy π.\nWithout loss of generality, assume that\nc1μ1>c2μ2>···>cnμn\nLetcμdenote the policy that gives preemptive priority to jobs in order of their\nclass (class 1has priority over class 2, which has priority over class 3, etc.),\ni.e., the class with the highest product of c·μgets highest priority. Observe\nthat it makes sense to give these jobs priority because they either have a high\nholding cost, or are small, or both.\nThecμ-Rule states that the cμpolicy is optimal for minimizing Cost(π), over\nall policies π, where we limit ourselves to policies that do not know the exact\nsizes of jobs, only the mean size for that class. This exercise will lead you\nthrough a very simple proof of the cμ-Rule. The key idea in the proof is to ﬁrst\nshow that the cμpolicy minimizes a certain sum of work and then to translate\nthe work result into a result about Cost(π).\n(a) If we set all the costs to be the same, i.e., ci=c,∀i, what does the cμ-Rule\nsay about mean response time?\n32.5 exercises 517\n(b) Explain via sample-path arguments why the following work sum inequality\nholds for all policies π:\nj/summationdisplay\ni=1E[Wcμ\ni]≤j/summationdisplay\ni=1E[Wπ\ni]∀j (32.10)\n(c) Prove the following simple identity, where the ai’s and bi’s are constants\nandan+1=0:\nn/summationdisplay\ni=1aibi=n/summationdisplay\ni=1(ai−ai+1)i/summationdisplay\nj=1bj (32.11)\n(d) Prove that\nCost(cμ)=n/summationdisplay\ni=1ciE[Ncμ\ni]≤n/summationdisplay\ni=1ciE[Nπ\ni]=Cost(π)\nfor all policies π. To do this, you will need to ﬁrst translate E[Ni]into\nE[Wi], by observing that\nE[Wπ\ni]=E[Nπ\ni]·1\nμ(why?? )\nThen apply both ( 32.11 ) and ( 32.10 ) to produce the result.",3356
199-Chapter 33 Scheduling SRPT and Fairness.pdf,199-Chapter 33 Scheduling SRPT and Fairness,,0
200-33.1 Shortest-Remaining-Processing-Time SRPT.pdf,200-33.1 Shortest-Remaining-Processing-Time SRPT,"CHAPTER 33\nScheduling: SRPT and Fairness\nIn this chapter, we introduce Shortest-Remaining-Processing-Time (SRPT) scheduling.\nSRPT is even superior to the PSJF policy that we saw in the last chapter, because ittakes a job’s remaining service requirement into account, not just the original job size .\nWe also compare all the scheduling policies that we have studied so far with respect to\nmean response time as a function of load and the variability of the job size distribution.Finally, we study the fairness of SRPT by comparing it to the (fair) PS policy and\nproving the All-Can-Win theorem.\n33.1 Shortest-Remaining-Processing-Time (SRPT)\nUnder SRPT, at all times the server is working on that job with the shortest re-\nmaining processing time. The SRPT policy is preemptive so that a new arrival willpreempt the current job serving if the new arrival has a shorter remaining processing\ntime.\nObserve that, under SRPT, once a job,\nj, starts running, it can only be preempted\nby a new arrival whose size is shorter than j’s remaining time. In particular, any\njobs that are in the system with j, while jis running, will never run before j\ncompletes.Remember that in Exercise 2.3we proved that SRPT achieves the lowest possible mean\nresponse time on every arrival sequence. In this section, we analyze the mean response\ntime for SRPT in the M/G/1 setting.\nQuestion: Can we look at SRPT as some type of preemptive priority system with\nclasses?\nAnswer: No!The problem is that in SRPT a job’s priority is its “remaining” size,\nwhich changes as the job ages. The preemptive priority model does not allow jobs to\nchange priorities while in queue.\nIt turns out that the response time analysis of SRPT is somewhat involved. The proof\nis outlined in two different ways in the Schrage and Miller paper from 1966 [ 160]. In\nthis section we give another sketch of the proof of response time for SRPT. This sketch\nmay feel precise, but it is missing a few details. In Section 33.2, we ﬁll in these missing\ndetails.\n518\n33.1 shortest-remaining-processing-time (srpt) 519\nWe start by looking at the ﬁnal result and then try to understand where each term comes\nfrom:\nE[T(x)]SRPT=E/bracketleftBiggTime until job of size\nxﬁrst receives service\n(waiting time)/bracketrightBigg\n+E/bracketleftBiggTime from when job ﬁrst\nreceives service until it is\ndone (residence time)/bracketrightBigg\n=E[Wait(x) ]+E[Res(x)]\n=λ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2+/integraldisplayx\nt=0dt\n1−ρt,\nwhere ρx=λ/integraltextx\n0tf(t)dtas in ( 31.4).\nUnderstanding the Residence Time\nRecall that the term representing mean residence time for the preemptive priority queue\nfor a job of class kwas\nE[Sk]\n1−/summationtextk−1\ni=1ρi.\nThis term represents the job size, slowed down by the load of all jobs of higher priority\nthan itself.\nIf we just tried to translate this directly to the continuous case we would have the mean\nresidence time for a job of size xunder PSJF; namely,\nE[Res(x)]PSJF=x\n1−ρx,\nwhich represents a busy period started by a job of size x(“jobx”) and consisting of\nonly jobs of size ≤x.\nBy contrast, in SRPT, a job of size xhas mean residence time\n/integraldisplayx\nt=0dt\n1−ρt.\nTo understand this expression, ﬁrst observe that in SRPT, a job’s “priority” increases\nas it ages. Thus the factor by which the job is slowed down, once it has started service,should depend on its remaining service requirement,\nt, and should be related to the\nload of all jobs of size less than t. Now think of the job of size xas broken intox\ndt\npieces of size dteach. The job starts out with remaining time xand slowly receives\nservice. Consider the time required for the job to move from having t+dtremaining\nservice time to tremaining service time. This is a busy period, started by dtwork,\nwhere only jobs of size <tare included in the busy period, because they are the ones\nthat have priority over our job. The length of such a busy period is exactlydt\n1−ρt.\nThe ﬁrst busy period, needed for the job to decrease from remaining size xto remaining\nsize(x−dt), takes a long time, because almost every job counts in the busy period.\n520 scheduling: srpt and fairness\nHowever the later busy periods, needed for the job to decrease from say x/2to\n(x/2−dt), go a lot faster, because only smaller jobs count.\nThe residence time of job xis just the sum (integration) of all these busy periods.\nUnderstanding the Waiting Time\nLet’s now think about the intuition behind the expression for waiting time:\nE[Wait(x) ]=λ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2\nQuestion: If you ignore the second term in the numerator, what does this expression\nremind you of?\nAnswer: Ignoring the second term in the numerator, we have exactly the mean waiting\ntime from the M/G/1/PSJF; see ( 32.5). Recall that the mean waiting time from the\nM/G/1/PSJF is the duration of a busy period, started by Wx, the total remaining work\nin the system from jobs of size ≤x, and made up of all new arrivals of size ≤xthat\noccur during Wx. (Recall that E[Wx]PSJF=λ\n2/integraltextx\nt=0t2f(t)dt\n1−ρxand that E[Wait(x) ]PSJF=\nE[Wx]PSJF\n1−ρx.)\nThe mean waiting time for SRPT also looks like such a busy period; however, the work\nstarting the busy period includes an extra term:\nλ\n2x2F(x)\nQuestion: What is this extra term? Why does it occur?\nAnswer: It looks like all jobs of original size >x (the jobs that occur with probability\nF(x)) are contributing x2to the SRPT expression. To understand this, observe that\nin PSJF only jobs of size <x can contribute to job x’s waiting time. By contrast, in\nSRPT alljobs contribute to job x’s waiting time. However, the big jobs only contribute\nat most xto job x’s waiting time, because job xonly sees the big jobs once their\nremaining time is reduced to x.\nQuestion: Does the numerator of E[Wait(x) ]SRPTremind you of another distribution\nwe have seen?\nAnswer: Yes, it is like the Sxjob size, which we used for FB scheduling, where jobs\nof size >x are transformed into jobs of size x; see Section 30.3.\nIn SRPT, the numerator in the waiting time expression isλ\n2E[S2\nx], as in FB; see ( 30.6).\nHowever, the denominator of the SRPT expression involves ρxas in PSJF, not ρxas in\nFB, because only jobs of size ≤xare allowed to enter the busy period.",6342
201-33.2 Precise Derivation of SRPT Waiting Time.pdf,201-33.2 Precise Derivation of SRPT Waiting Time,"33.2 precise derivation of srpt waiting time 521\nIn fact, SRPT is related to both FB and to PSJF. The exact relationship will become\nclearer in the next section.\n33.2 Precise Derivation of SRPT Waiting Time∗\nSection 33.1 provided a proof sketch for response time of SRPT. The derivation of\nRes(x) was precise. We now make the derivation of Wait(x) precise as well.\nLetWSRPT\nx denote the work that an arrival of size xﬁnds in the system that is “relevant”\nto itself (i.e., work in the system that will run before the arrival of size xgets to start\nrunning). Then Wait(x) is simply a busy period started by WSRPT\nx, where the only jobs\nallowed to enter are those of size ≤x. Hence,\nE[Wait(x) ]SRPT=E[WSRPT\nx]\n1−ρx. (33.1)\nWe spend the rest of the section analyzing E[WSRPT\nx].WSRPT\nx is composed of two types\nof jobs:\nType a: These are jobs that job xﬁnds in the system of (original) size ≤x.\nType b: These are jobs that job xﬁnds in the system of (original) size >x that now\nhave remaining size ≤x.\nIf all we had to worry about was work made up of type ajobs, this would be an easy\nproblem. The work made up of type ajobs is the same as WPSJF\nx. Unfortunately, we\nalso have type bjobs.\nQuestion: How many jobs can there be of type b?\nAnswer: There can be at most one job of type b. Furthermore, no more type b’s will\nenter the system until job xhas left the system entirely.\nThe difﬁculty in analyzing the work made up of type aandbjobs lies in the strangeness\nof the type bjobs. From the perspective of job x, jobs of type bappear at the server,\nhaving size x, according to some non-Poisson process, where there can only be at most\none type bjob in the system at a time. The fact that there can only be one type bjob is\nparticularly at odds with respect to all the analysis techniques we have used so far.\nTo determine the total work in the system made up of type aand type bjobs, we use\nthe following trick: We imagine that our queueing system is broken into two pieces,\nthequeue part and the server part . Note that by deﬁnition there can only be one job\nof either type in the server at a time. We imagine type bjobs as arriving directly into\nthe server, whereas all other jobs arrive at the queue. We also imagine type bjobs as\nalways having priority over type ajobs, so that they never leave the server once they\nare in there. That is, they always run to completion. Making type bjobs have priority\nover type ajobs does not change the amount of work in the system, but it does allow\nus to ensure that type b’s never enter the queue part .\n∗Warning: This is a difﬁcult section and can be skipped.\n522 scheduling: srpt and fairness\nThus we can think of the queue part as a system made up of only type ajobs and\ntheserver part as consisting of jobs from distribution Sxfrom the FB analysis (this\nincludes both the type ajobs and the type bjobs). We call this system of a’s and b’s\n“system X.”\nOur goal is to understand the work in system X. This work is the same as the delay\nexperienced ( TQ) by an arrival of type ainto system X, if we now pretend that all\narrivals of type aare of equal priority with respect to each other and hence are served\nFCFS.\nWe now use a tagged-job argument to determine the mean delay for a type aarrival\ninto system X. Note that we cannot simply pretend that system Xis a regular FCFS\nqueue, because type bjobs only enter the server. Hence we cannot just apply the P-K\nformula, and we instead need to do the tagged-job analysis from scratch.\nA type aarrival to system Xwill see some number of jobs in the queue, NQ. These\nwill all be of type a. Hence their size can be represented by Sx, which denotes the\njob size for jobs of size ≤xonly. The probability that a type aarrival sees a job in\nservice is ρx, where ρx=λE[Sx](as in the FB policy). To understand why this is so,\nwe think about the server as a separate system and look at it from a Renewal-Reward\nperspective. It is important to note that every single job eventually enters the server.\nHowever, the jobs of size >x that enter the server enter it as being size x. Thus, the job\nsize distribution of jobs entering the server is Sx, and the fraction of time that the server\nis busy is ρx. Going back to our type aarrival, that (Poisson) arrival sees time-average\nbehavior; namely, with probability ρxit sees a busy server, and the expected remaining\nservice time of the job serving is the expected excess of Sx.\nPutting these together we have\nE[TQ]=E[NQ]·E[Sx]+ρxE[Excess of Sx]\n=E[TQ]λF(x)·E[Sx]+ρx·E[Excess of Sx]\n=E[TQ]ρx+ρx·E[Excess of Sx]\n=ρxE[Excess of Sx]\n1−ρx\n=ρx\n1−ρx·E[S2\nx]\n2E[Sx]\n=λE[Sx]\n1−ρx·E[S2\nx]\n2E[Sx]\n=λ\n1−ρx·E[S2\nx]\n2\n=λ\n2·/integraltextx\n0t2f(t)dt+F(x)·x2\n1−ρx.",4759
202-33.3 Comparisons with Other Policies.pdf,202-33.3 Comparisons with Other Policies,"33.3 comparisons with other policies 523\nThis expression for E[TQ]represents WSRPT\nx. Hence, returning to ( 33.1), we have\nE[Wait(x) ]SRPT=E[WSRPT\nx]\n1−ρx=λ\n2·/integraltextx\n0t2f(t)dt+F(x)·x2\n(1−ρx)2\nas desired.\n33.3 Comparisons with Other Policies\nLet’s return to the formula for SRPT response time:\nE[T(x)]SRPT=λ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2+/integraldisplayx\nt=0dt\n1−ρt.(33.2)\nWe can make several immediate observations. First, observe that the response time\nfor a job of size xis not inﬂuenced by the variance of the entire job size distribution,\nbut rather just by the variance of the distribution up to size x.E[T(x)]is also not\ninﬂuenced by the entire load, but rather just by the load made up of jobs of size ≤x.\nAlso, once our job of size xstarts receiving service, the only inﬂuencing factor is the\nload made up of jobs of size less than the current remaining service time of our job.\nThis explains why small jobs (small size x) do so well under SRPT.\n33.3.1 Comparison with PSJF\nIt’s clear that the waiting time for SRPT is greater than that for PSJF because of the\nextrax2term in the numerator. In contrast, the residence time for SRPT is clearly\nbetter than that for PSJF, because a job only has to wait for those jobs smaller than\nits current remaining service requirement under SRPT, whereas it has to wait behind\nall jobs smaller than its original size in PSJF. Compare ( 32.4) with ( 33.2) and imagine\nintegrating over all x. It turns out that this beneﬁt in E[Res(x)]makes SRPT superior to\nPSJF with respect to overall mean response time, E[T], where E[T]is the weighted\nintegral of E[T(x)]over all x.\n33.3.2 SRPT versus FB\nWithout looking at the formulas, it might not seem obvious how SRPT and FB compare.\nSRPT and FB are in a sense complements. In SRPT, a job gains priority as it receivesmore service. Its response time can be thought of as a snowball rolling downhill,\nwhich at ﬁrst rolls slowly, but gains momentum and moves faster and faster. In FB,\nthe reverse is true. A job has highest priority when it ﬁrst enters. As time goes on, itloses priority. One might imagine that the performance of SRPT and FB are somehowrelated. Lemma 33.1 shows that, on every job size\nx, SRPT beats FB.\nLemma 33.1 In an M/G/1, for all xand for all ρ,\nE[T(x)]SRPT≤E[T(x)]FB.\n524 scheduling: srpt and fairness\nProof The proof follows from the fact that both the mean residence time and the\nmean waiting time are lower under SRPT as compared with FB. In the case of mean\nwaiting time, SRPT and FB have the same numerator, but FB has a (1−ρx)2term in\nthe denominator, as compared to (1−ρx)2in SRPT, where ρx>ρx.\nE[T(x)]FB=x(1−ρx)+1\n2λE/bracketleftbig\nSx2/bracketrightbig\n(1−ρx)2\n=x\n1−ρx+1\n2λ/parenleftbig/integraltextx\n0y2f(y)dy+x2F(x)/parenrightbig\n(1−ρx)2\n≥x\n1−ρx+1\n2λ/parenleftbig/integraltextx\n0y2f(y)dy+x2F(x)/parenrightbig\n(1−ρx)2\n≥/integraldisplayx\nt=0dt\n1−ρt+1\n2λ/integraltextx\n0y2f(y)dy+1\n2λx2F(x)\n(1−ρx)2\n=E[T(x)]SRPT\n33.3.3 Comparison of All Scheduling Policies\nAt this point we have derived at least E[T(x)]for all scheduling policies. However,\nit is not obvious just from looking at these formulas how these policies compare with\nrespect to overall mean response time, E[T]– most of us are not born doing triple\nnested integrals in our heads :-).\nTo facilitate understanding, we have evaluated all the formulas for E[T]using Math-\nematica for the different policies. Mean response time as a function of load is given\nin Figure 33.1, and mean response time as a function of C2is given in Figure 33.2.\nIn both ﬁgures, we have used a Weibull job size distribution. The Weibull, deﬁned by\nE[T]\nρ5\n4\n3\n2\n0.2 0.4 0 0.8 0.6 1.016789FCFS\nSJF\nPS = PLCFSSRPTFB\nPSJFFCFS\nSJF\nPS = PLCFS\nSRPTFB\nPSJF\nFigure 33.1. Mean response time as a function of load for the M/G/1 with various scheduling\npolicies. The job size distribution is a Weibull with mean 1andC2=1 0 .",3982
203-33.4 Fairness of SRPT.pdf,203-33.4 Fairness of SRPT,"33.4 fairness of srpt 525\nFCFS\nSJF\nPS = PLCFS\nSRPTPSJFFBE[T]\nC25\n4\n3\n2\n0.2 0.4 0 0.8 0.6 1.016789\nFCFS\nSJF\nPS = PLCFS\nSRPTFB\nPSJF\nFigure 33.2. Mean response time as a function of variability ( C2) for the M/G/1 with various\nscheduling policies. Load is ﬁxed at ρ=0.7. The job size distribution is a Weibull with ﬁxed\nmean1and changing C2.\nF(x)=e−(x\nλ)α\nwith parameters λandα>0, is convenient because when α<1,i t\nhas decreasing failure rate (DFR) and C2can be made as high as desired.\nLooking at Figure 33.1, we see that the policies are ordered as we would expect.\nKnowing the size helps. Being able to preempt jobs helps even more.\nQuestion: The SJF policy is not so great for low loads (due to the high C2). However,\nit suddenly starts looking a lot better, comparatively, under high loads, even beating\nPS. Why is this?\nAnswer: There is a 1−ρxterm in the denominator of E[TQ(x)]SJF, as compared with\na1−ρterm in the denominator of E[T(x)]PS. That helps SJF a lot under high load.\nLooking at Figure 33.2, we see that under high C2, the policies are ranked as expected.\nQuestion: Why is the line for PS =PLCFS ﬂat?\nAnswer: These policies are invariant to the variability of the job size distribution.\nQuestion: Why do policies like FB look worse for low C2?\nAnswer: FB needs DFR to perform well, and higher DFR is coupled with higher C2.\n33.4 Fairness of SRPT\nAlthough the SRPT scheduling policy is optimal with respect to mean response time\nand has a comparatively low second moment as well, it is rarely used for schedulingjobs. Consider for example a typical web server.\n526 scheduling: srpt and fairness\nQuestion: Which scheduling policy best represents scheduling in a web server?\nAnswer: PS. The server time-shares between HTTP requests. Both the CPU and the\noutgoing bandwidth are scheduled in round-robin order, approximating Processor-\nSharing.\nThis seems suboptimal, because the mean response time for PS is clearly far higher\nthan that for SRPT. One might wonder whether there are other issues in applying SRPT.\nA possible objection to using SRPT is that the job size is not always known. However,\nfor web servers serving static (GET File) requests, the sizes of these ﬁles are known\nby the server and accurately represent the job service requirement. Implementationof SRPT scheduling for web servers is also easy, it turns out. In [ 92,162], SRPT\nscheduling is implemented for an Apache web server running on Linux by modifying\nthe Linux kernel to schedule outgoing bandwidth so as to favor HTTP requests with\nsmall remaining ﬁle size.\nQuestion: So what is the problem with using SRPT?\nAnswer: The problem is that people deeply fear that SRPT will cause long jobs to\n“starve.”\nNow clearly, when\nρ<1, no job actually starves, because every busy period is ﬁnite,\nso every job will eventually get to run. When people talk about “starvation,” they are\nreally talking about jobs doing worse under SRPT than they would under a fairpolicy\nlike PS. By fairwe mean a policy that affords every job the same expected slowdown,\nregardless of its size.\nQuestion: Consider the question illustrated in Figure 33.3. An M/G/1 queue is shown,\nwhere the job size distribution is a Bounded Pareto ( k= 332 ,p=1 010,α=1.1).\nMr. Max\nsize1010f(x)\nx\n332 1010\nQuestion:\nWhich q ueue \ndoes Mr. Max \nprefer ?\n(Ass ume ρ = 0.9)PS\nSRPT?\n?Bounded Pareto (332,1010,α = 1.1) \nFigure 33.3. Which policy is best for the largest job: SRPT or PS?\n33.4 fairness of srpt 527\nThe load is ρ=0.9. Consider now the very biggest job in the job size distribution\n(we call him, Mr. Max). Mr. Max is a job of size x=1 010. The question is whether\nMr. Max prefers to go to an M/G/1/PS queue, or an M/G/1/SRPT queue. That is, is\nE[T(1010)]lower under PS scheduling or under SRPT scheduling?\nDiscussion: Clearly small jobs should favor SRPT. By contrast, large jobs have the\nlowest priority under SRPT, but they get treated like equal citizens under PS, where\nthey time-share equally with all other jobs. It therefore seems much better for Mr. Maxto go to the PS queue, where he will be treated as an equal citizen. That is, it seems\nthat\nE[T(1010)]PSshould be far lower than E[T(1010)]SRPT.\nAnswer: This intuition turns out to be wrong!\nIn fact, for the same M/G/1 setup as in Figure 33.3, we produced Table 33.1 via\nMathematicaTM.\nAs seen in Table 33.1, not only does the largest job prefer SRPT to PS, but almost all\njobs (99.9999% ) prefer SRPT to PS by more than a factor of 2. In fact 99% of jobs\nprefer SRPT to PS by more than a factor of 5.\nTable 33.1. E[Slowdown( x)]under SRPT and under PS for increasing x\nExpected slowdown Expected slowdown\nPercentile of job size distribution under SRPT under PS\n90%-tile 1.28 10\n99%-tile 1.62 1099.99%-tile 2.69 10\n99.9999%-tile 4.73 10\n99.999999%-tile 8.50 1099.99999999%-tile 9.53 10100%-tile (Mr. Max) 9.54 10\nBut how can this be? Can every job really do better in expectation under SRPT than\nunder PS? The answer is YES, and not just for the Bounded Pareto job size distribution.\nTheorem 33.2 (All-Can-Win [ 12])Given an M/G/1, if ρ<1\n2, then,∀x,\nE[T(x)]SRPT≤E[T(x)]PS.\nThe All-Can-Win theorem says that every single job (every x) prefers SRPT to PS\nin expectation, assuming ρ<1\n2. Remarkably, the All-Can-Win theorem holds for all\njob size distributions G.F o rm a n y G, the restriction on ρis much looser. In fact, for\nthe Bounded Pareto distribution with α=1.1, shown in Figure 33.3, the All-Can-Win\ntheorem holds whenever ρ<0.96.\nQuestion: Do you have any intuition for whythe All-Can-Win theorem should hold?\nAnswer: Here is the intuition. First realize that, although it seems that large jobs are\nignored under SRPT, this is only the case until the large job gets some service. Once a\nlarge job starts to get some service, it gains priority over other jobs. In the end, even thelargest job will have a period where it has highest priority. Now imagine that load is\n528 scheduling: srpt and fairness\nlight. Then it seems plausible that the E[Wait(x) ]component of SRPT is low, because\nan incoming job often ﬁnds the system empty. In this case, the E[Res(x)]component\ncould be a major part of a job’s response time under SRPT. Now compare with PS.PS has no Wait(x) component, only a Res(x) . However, the Res(x) component for PS\nis clearly way higher than that for SRPT. Thus, it seems plausible that under light loadconditions even a job of large size\nxcould do worse under PS than under SRPT.\nHere is the formal proof:\nProof (All-Can-Win)\nE[T(x)]SRPT≤E[T(x)]PS\n/arrowdblbothv\nλ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2+/integraldisplayx\nt=0dt\n1−ρt≤x\n1−ρ\n/arrowdblbothv\nλ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2≤x\n1−ρ−/integraldisplayx\nt=0dt\n1−ρt\n/arrowdblbothv\nλ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2≤/integraldisplayx\nt=0dt\n1−ρ−/integraldisplayx\nt=0dt\n1−ρt\n/arrowdblbothv\nλ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2≤/integraldisplayx\nt=0ρ−ρt\n(1−ρ)(1−ρt)dt\nNow, because\n/integraldisplayx\nt=0ρ−ρt\n(1−ρ)(1−ρt)dt >/integraldisplayx\nt=0ρ−ρt\n(1−ρ)dt,\nit sufﬁces to show that\nλ\n2/integraltextx\nt=0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2≤/integraldisplayx\nt=0ρ−ρt\n(1−ρ)dt.\nBefore showing this, we observe, using integration-by-parts, that\n/integraldisplayx\nt=0ρ−ρt\n(1−ρ)dt=1\n1−ρ/parenleftbigg\n(ρ−ρt)t/vextendsingle/vextendsinglet=x\nt=0+/integraldisplayx\n0tρ/prime\ntdt/parenrightbigg\n=(ρ−ρx)x\n1−ρ+λ/integraltextx\n0t2f(t)dt\n1−ρ.\nSo it sufﬁces to show that\nλ\n2/integraltextx\n0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2≤(ρ−ρx)x\n1−ρ+λ/integraltextx\n0t2f(t)dt\n1−ρ.",7683
204-33.5 Readings.pdf,204-33.5 Readings,"33.5 readings 529\nWe further observe that\nx(ρ−ρx)=λx/integraldisplay∞\nxtf(t)dt > λx2(1−F(x)).\nThus it sufﬁces to show that\nλ\n2/integraltextx\n0t2f(t)dt+λ\n2x2(1−F(x))\n(1−ρx)2≤λx2(1−F(x))\n1−ρ+λ/integraltextx\n0t2f(t)dt\n1−ρ.\nFrom the above expression, it sufﬁces to show that\n2(1−ρx)2>1−ρ.\nBecause ρ>ρ x, it sufﬁces to show that\n2(1−ρx)2>1−ρx.\nDividing both sides by 1−ρx, we see that this is clearly true when\nρx<1\n2,\nwhich is true by the theorem assumption that ρ<1\n2.\nWe have shown that fairness is counterintuitive. A seemingly “unfair” policy, like\nSRPT, can outperform a fair policy, like PS, in expectation, on every job size.\n33.5 Readings\nThere is a lot of recent work on fairness of scheduling policies. The proof techniquefrom Section 33.2 is illustrated more generally in [ 191]. Many references and further\nresults can be found in the thesis of Adam Wierman [ 188], in [ 190], and in a wonderful\nbook by Hassin and Haviv [ 96].",962
205-Bibliography.pdf,205-Bibliography,"Bibliography\n[1] S. Aalto, U. Ayesta, S. Borst, V . Misra, and R. N ´u˜nez Queija. Beyond processor sharing.\nPerformance Evaluation Review , 34(4):36–43, 2007.\n[2] I.J.B.F. Adan, G.J. van Houtum, and J. van der Wal. Upper and lower bounds for the waiting\ntime in the symmetric shortest queue system. Annals of Operations Research , 48:197–217,\n1994.\n[3] I.J.B.F. Adan, J. Wessels, and W.H.M. Zijm. Analysis of the symmetric shortest queue problem.\nStochastic Models , 6:691–713, 1990.\n[4] I.J.B.F. Adan, J. Wessels, and W.H.M. Zijm. Matrix-geometric analysis of the shortest queue\nproblem with threshold jockeying. Operations Research Letters , 13:107–112, 1993.\n[5] A.O. Allen. Probability, Statistics, and Queueing Theory with Computer Science Applications .\nAcademic Press, 2nd edition, 1990.\n[6] E. Altman, U. Ayesta, and B. Prabhu. Load balancing in processor sharing systems. Telecom-\nmunication Systems , 47(1–2):35–48, 2011.\n[7] E. Arthurs and J.S. Kaufman. Sizing a message store subject to blocking criteria. In Proceedings\nof the Third International Symposium on Modeling and Performance Evaluation of Computer\nSystems , pages 547–564, 1979.\n[8] S. Asmussen. Applied Probability and Queues . Springer-Verlag, 2nd edition, 2003.\n[9] N. Avrahami and Y . Azar. Minimizing total ﬂow time and total completion time with imme-\ndiate dispatching. In Proceedings of the Annual ACM Symposium on Parallel Algorithms and\nArchitectures (SPAA) , pages 11–18, 2003.\n[10] E. Bachmat and A. Natanzon. Analysis of the large number of hosts asymptotics of SITA\nqueues. In Workshop on Mathematical Performance Modeling and Analysis (MAMA) , 2012.\n[11] E. Bachmat and H. Sarfati. Analysis of size interval task assignment policies. Performance\nEvaluation Review , 36(2):107–109, 2008.\n[12] N. Bansal and M. Harchol-Balter. Analysis of SRPT scheduling: investigating unfairness.\nInProceedings of the 2001 ACM Sigmetrics Conference on Measurement and Modeling of\nComputer Systems , pages 279–290. Cambridge, MA, June 2001.\n[13] A. Barak, S. Guday, and R.G. Wheeler. The Mosix Distributed Operating System: Load Bal-\nancing for Unix . Springer Verlag, 1993.\n[14] P. Barford and M.E. Crovella. Generating representative web workloads for network and\nserver performance evaluation. In Proceedings of the 1998 ACM Sigmetrics Conference on\nMeasurement and Modeling of Computer Systems , pages 151–160, July 1998.\n[15] L.A. Barroso and U. H ¨olzle. The case for energy-proportional computing. Computer ,\n40(12):33–37, 2007.\n[16] F. Baskett, K.M. Chandy, R.R. Muntz, and F. Palacios-Gomez. Open, closed and mixed net-\nworks of queues with different classes of customers. Journal of the ACM , 22:248–260, 1975.\n[17] S.L. Bell and R.J. Williams. Dynamic scheduling of a system with two parallel servers in heavy\ntrafﬁc with complete resource pooling: asymptotic optimality of a continuous review threshold\npolicy. Annals of Applied Probability , 11(3):608–649, 2001.\n[18] D. Bertsekas and R. Gallager. Data Networks . Prentice Hall, 1992.\n[19] D. Bertsimas and D. Nakazato. The distributional Little’s law and its applications. Operations\nResearch , 43(2):298–310, 1995.\n531\n532 bibliography\n[20] A. Bhandari, A. Scheller-Wolf, and M. Harchol-Balter. An exact and efﬁcient algorithm for\nthe constrained dynamic operator stafﬁng problem for call centers. Management Science ,\n54(2):339–353, 2008.\n[21] Big-IP. F5 Products. http://www.f5.com/products/big-ip.\n[22] D.P. Blinn, T. Henderson, and D. Kotz. Analysis of a wi-ﬁ hotspot network. In International\nWorkshop on Wireless Trafﬁc Measurements and Modeling , pages 1–6, June 2005.\n[23] G. Bolch, S. Greiner, H. de Meer, and K.S. Trivedi. Queueing Networks and Markov Chains .\nJohn Wiley and Sons, 2006.\n[24] A. Bondi and W. Whitt. The inﬂuence of service-time variability in a closed network of queues.\nPerformance Evaluation , 6(3):219–234, 1986.\n[25] F. Bonomi. On job assignment for a parallel system of processor sharing queues. IEEE Trans-\nactions on Computers , 39(7):858–869, 1990.\n[26] O. Boxma, J. Cohen and N. Huffels. Approximations in the mean waiting time in an M/G/s\nqueueing system. Operations Research , 27:1115–1127, 1979.\n[27] O.J. Boxma and J.W. Cohen. Boundary Value Problems in Queueing System Analysis .N o r t h\nHolland, 1983.\n[28] O.J. Boxma and B. Zwart. Tails in scheduling. Performance Evaluation Review , 34(4):13–20,\n2007.\n[29] M. Bramson. Stability of Queueing Networks . Springer Verlag, 2008.\n[30] M. Bramson, Y . Lu, and B. Prabhakar. Randomized load balancing with general service time\ndistributions. In Proceedings of the 2010 ACM Sigmetrics Conference on Measurement and\nModeling of Computer Systems . New York, NY , pages 275–286, June 2010.\n[31] P. Bratley, B. Fox, and L. Schrage. A Guide to Simulation . Springer-Verlag, 2nd edition,\n1983.\n[32] J. Broberg, Z. Tari, and P. Zeephongsekul. Task assignment with work-conserving migration.\nParallel Computing , 32:808–830, 2006.\n[33] S.L. Brumelle. A generalization of L=λW to moments of queue length and waiting times.\nOperations Research , 20:1127–1136, 1972.\n[34] P.J. Burke. The output of a queueing system. Operations Research , 4(6):699–704, 1956.\n[35] J. P. Buzen. Computational algorithms for closed queueing networks with exponential servers.\nCommunications of the ACM , 16(9):527–531, 1973.\n[36] V . Cardellini, E. Casalicchio, M. Colajanni, and P.S. Yu. The state of the art in locally distributed\nweb-server systems. ACM Computing Surveys , 34(2):1–49, 2002.\n[37] J.M. Carlson and J. Doyle. Highly optimized tolerance: a mechanism for power laws in designed\nsystems. Physical Review E , 60:1412–1427, 1999.\n[38] H. Chen and D.D. Yao. Fundamentals of Queueing Networks . Springer, 2001.\n[39] H. Chen and M. Frank. State dependent pricing with a queue. IIE Transactions , 33(10): 847–\n860, 2001.\n[40] G.L. Choudhury, K.K. Leung, and W. Whitt. Calculating normalization constants of closed\nqueueing networks by numerically inverting their generating functions. Journal of the ACM ,\n42(5):935–970, 1995.\n[41] G. Ciardo, A. Riska, and E. Smirni. Equiload: a load balancing policy for clustered web servers.\nPerformance Evaluation , 46:101–124, 2001.\n[42] Cisco Systems LocalDirector. http://www.cisco.com/warp/public/cc/pd/cxsr/400/index.shtml.\n[43] J.W. Cohen and O.J. Boxma. Boundary Value Problems in Queueing System Analysis . North-\nHolland Publishing, 1983.\n[44] B.W. Conolly. The autostrada queueing problem. Journal of Applied Probability , 21:394–403,\n1984.\n[45] R.W. Conway, W.L. Maxwell, and L.W. Miller. Theory of Scheduling . Addison-Wesley, 1967.\nbibliography 533\n[46] M.E. Crovella, R. Frangioso, and M. Harchol-Balter. Connection scheduling in web servers.\nInUSENIX Symposium on Internet Technologies and Systems , pages 243–254, Boulder, CO,\nOctober 1999.\n[47] M.E. Crovella and A. Bestavros. Self-similarity in World Wide Web trafﬁc: evidence and\npossible causes. In Proceedings of the 1996 ACM Sigmetrics International Conference on\nMeasurement and Modeling of Computer Systems , pages 160–169, May 1996.\n[48] M.E. Crovella, M.S. Taqqu, and A. Bestavros. Heavy-tailed probability distributions in the\nworld wide web. In A Practical Guide To Heavy Tails , chapter 1, pages 1–23. Chapman & Hall,\nNew York, 1998.\n[49] D. Down and R. Wu. Multi-layered round robin scheduling for parallel servers. Queueing\nSystems: Theory and Applications , 53(4):177–188, 2006.\n[50] M. El-Taha and B. Maddah. Allocation of service time in a multiserver system. Management\nScience , 52(4):623–637, 2006.\n[51] M. El-Taha and S. Stidham. Sample-Path Analysis of Queueing Systems . Kluwer Academic\nPublisher, Boston, 1999.\n[52] A. Ephremides, P. Varaiya, and J. Walrand. A simple dynamic routing problem. IEEE Trans-\nactions on Automatic Control , 25(4):690–693, 1980.\n[53] R. Fagin, A. Karlin, J. Kleinberg, P. Raghavan, S. Rajagopalan, R. Rubinfeld, M. Sudan, and\nA. Tomkins. Random walks with back buttons. Annals of Applied Probability , 11(3):810–862,\n2001.\n[54] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On power-law relationships of the internet\ntopology. In Proceedings of SIGCOMM , pages 251–262, 1999.\n[55] G. Fayolle and R. Iasnogorodski. Two coupled processors: the reduction to a Riemann-Hilbert\nproblem. Zeitschrift fur Wahrscheinlichkeitstheorie und vervandte Gebiete , 47:325–351,\n1979.\n[56] A. Feldmann and W. Whitt. Fitting mixtures of exponentials to long-tailed distribu-\ntions to analyze network performance models. Performance Evaluation , 31(8):963–976,\n1998.\n[57] W. Feller. An Introduction to Probability Theory and Its Applications , volume I. John Wiley\nand Sons, 3rd edition, 1968.\n[58] W. Feller. An Introduction to Probability Theory and Its Applications , volume II. John Wiley\nand Sons, 2nd edition, 1971.\n[59] H. Feng, V . Misra, and D. Rubenstein. Optimal state-free, size-aware dispatching for hetero-\ngeneous M/G-type systems. Performance Evaluation , 62:475–492, 2005.\n[60] H. Feng, V . Misra, and D. Rubenstein. PBS: A uniﬁed priority-based scheduler. In Proceedings\nof the 2007 ACM Sigmetrics International Conference on Measurement and Modeling of\nComputer Systems , pages 203–214, June 2007.\n[61] L. Flatto and H.P. McKean. Two queues in parallel. Communications on Pure and Applied\nMathematics , 30:255–263, 1977.\n[62] Flushing away Unfairness. The Economist , July 8, 2010.\n[63] R.D. Foley and D. McDonald. Exact asymptotics of a queueing network with a cross-trained\nserver. In Proceedings of INFORMS Annual Meeting , Applied Probability Cluster, October\n2003.\n[64] S. Foss and D. Korshunov. Heavy tails in multi-server queue. Queueing Systems , 52:31–48,\n2006.\n[65] B. Fu, J. Broberg, and Z. Tari. Task assignment strategy for overloaded systems. In Proceedings\nof the Eighth IEEE International Symposium on Computers and Communications , pages 1119–\n1125, 2003.\n[66] R. G. Gallager. Discrete Stochastic Processes . Kluwer Academic Publishers, 1996.\n534 bibliography\n[67] A. Gandhi, V . Gupta, M. Harchol-Balter, and M. Kozuch. Optimality analysis of energy-\npeformance trade-off for server farm management. Performance Evaluation , 11:1155–1171,\n2010.\n[68] A. Gandhi, M. Harchol-Balter, and I. Adan. Server farms with setup costs. Performance\nEvaluation , 67(11):1123–1138, 2010.\n[69] A. Gandhi, M. Harchol-Balter, R. Das, and C. Lefurgy. Optimal power allocation in server\nfarms. In ACM Sigmetrics 2009 Conference on Measurement and Modeling of Computer\nSystems , pages 157–168, 2009.\n[70] S. Ghosh and M. Squillante. Analysis and control of correlated web server queues. Computer\nCommunications , 27(18):1771–1785, 2004.\n[71] W.C. Gifﬁn. Transform Techniques in Probability Modeling . Academic Press, 1975.\n[72] J.J. Gordon. The evaluation of normalizing constants in closed queueing networks. Operations\nResearch , 38(5):863–869, 1990.\n[73] W.K. Grassmann. Transient and steady state results for two parallel queues. Omega , 8:105–112,\n1980.\n[74] L. Green. A queueing system with general use and limited use servers. Operations Research ,\n33(1):168–182, 1985.\n[75] D. Gross and C.M. Harris. Fundamentals of Queueing Theory . John Wiley and Sons,\n3rd edition, 1998.\n[76] V . Gupta, J. Dai, M. Harchol-Balter, and B. Zwart. On the inapproximability of M/G/k: why two\nmoments of job size distribution are not enough. Queueing Systems: Theory and Applications ,\n64(1):5–48, 2010.\n[77] V . Gupta and M. Harchol-Balter. Self-adaptive admission control policies for resource-sharing\nsystems. In ACM Sigmetrics 2009 Conference on Measurement and Modeling of Computer\nSystems , pages 311–322, 2009.\n[78] V . Gupta, M. Harchol-Balter, A. Scheller-Wolf, and U. Yechiali. Fundamental characteristics\nof queues with ﬂuctuating load. In Proceedings of the 2006 ACM Sigmetrics Conference on\nMeasurement and Modeling of Computer Systems , pages 203–215, 2006.\n[79] V . Gupta, M. Harchol-Balter, K. Sigman, and W. Whitt. Analysis of join-the-shortest-queue\nrouting for web server farms. Performance Evaluation 64(9–12):1062–1081, 2007.\n[80] P.R. Halmos. Measure Theory . Graduate Texts in Mathematics. Springer, 2000.\n[81] M. Harchol-Balter. Network Analysis without Exponentiality Assumptions . PhD thesis, Univer-\nsity of California, Berkeley, 1996.\n[82] M. Harchol-Balter. Task assignment with unknown duration. Journal of the ACM , 49(2):260–\n288, 2002.\n[83] M. Harchol-Balter, M.E. Crovella, and C. Murta. On choosing a task assignment policy for a\ndistributed server system. IEEE Journal of Parallel and Distributed Computing , 59:204–228,\n1999.\n[84] M. Harchol-Balter and A. Downey. Exploiting process lifetime distributions for dynamic load\nbalancing. In Proceedings of the 1996 ACM Sigmetrics Conference on Measurement and\nModeling of Computer Systems , pages 13–24, Philadelphia, May 1996.\n[85] M. Harchol-Balter and A. Downey. Exploiting process lifetime distributions for dynamic load\nbalancing. ACM Transactions on Computer Systems , 15(3):253–285, 1997.\n[86] M. Harchol-Balter, C. Li, T. Osogami, A. Scheller-Wolf, and M. Squillante. Cycle stealing\nunder immediate dispatch task assignment. In 15th ACM Symposium on Parallel Algorithms\nand Architectures , pages 274–285, San Diego, June 2003.\n[87] M. Harchol-Balter, C. Li, T. Osogami, A. Scheller-Wolf, and M. Squillante. Task assignment\nwith cycle stealing under central queue. In 23rd International Conference on Distributed\nComputing Systems , pages 628–637, Providence, RI, May 2003.\nbibliography 535\n[88] M. Harchol-Balter, T. Osogami, and A. Scheller-Wolf. Robustness of threshold policies in a\nbeneﬁciary-donor model. Performance Evaluation Review , 33(2):36–38, 2005.\n[89] M. Harchol-Balter, T. Osogami, A. Scheller-Wolf, and A. Wierman. Multi-server queueing\nsystems with multiple priority classes. Queueing Systems: Theory and Applications , 51(3–\n4):331–360, 2005.\n[90] M. Harchol-Balter, A. Scheller-Wolf, and A. Young. Surprising results on task assignment\nin server farms with high-variability workloads. In ACM Sigmetrics 2009 Conference on\nMeasurement and Modeling of Computer Systems , pages 287–298, 2009.\n[91] M. Harchol-Balter, A. Scheller-Wolf, and A. Young. Why segregating short jobs from long\njobs under high variability is not always a win. In Forty-Seventh Annual Allerton Conference\non Communication, Control, and Computing , University of Illinois, Urbana-Champaign, pages\n121–127, October 2009.\n[92] M. Harchol-Balter, B. Schroeder, N. Bansal, and M. Agrawal. Size-based scheduling to improve\nweb performance. ACM Transactions on Computer Systems , 21(2):207–233, 2003.\n[93] M. Harchol-Balter and R. Vesilo. To balance or unbalance load in size-interval task allocation.\nProbability in the Engineering and Informational Sciences , 24(2):219–244, 2010.\n[94] P.G. Harrison. On normalizing constants in queueing networks. Operations Research , 33:464–\n468, 1985.\n[95] P.G. Harrison. Reversed processes, product forms and a non-product form. Linear Algebra and\nIts Applications , 386:359–381, 2004.\n[96] R. Hassin and M. Haviv. To Queue or not to Queue . Kluwer Academic Publishers, 2003.\n[97] P. Hokstad. Approximations for the M/G/m queue. Operations Research , 26(3):510–523, 1978.\n[98] P. Hokstad. The steady state solution of the M/K 2/mqueue. Advances in Applied Probability ,\n12(3):799–823, 1980.\n[99] S. Hotovy, D. Schneider, and T. O’Donnell. Analysis of the early workload on the Cornell\nTheory Center IBM SP2. Technical Report 96TR234, Cornell Theory Center, January 1996.\n[100] E. Hyyti ¨a, S. Aalto, and A. Penttinen. Minimizing slowdown in heterogeneous size-aware\ndispatching systems. In Proceedings of the 2012 ACM Sigmetrics Conference on Measurement\nand Modeling of Computer Systems . London, U.K., pages 29–40, June 2012.\n[101] E. Hyyti ¨a, J. Virtamo, S. Aalto, A. Penttinen. M/M/1-PS queue and size-aware task assignment.\nPerformance Evaluation , 68:1136–1148, 2011.\n[102] J.R. Jackson. Jobshop-like queueing systems. Management Science , 10(1):131–142, 1963.\n[103] G. Jain. A Rate Conservation Analysis of Queues and Networks with Work Removal .P h D\nthesis, Columbia University, IEOR Department, 1996.\n[104] R. Jain. The Art of Computer Systems Performance Analysis . John Wiley and Sons, 1991.\n[105] S. Karlin and H. M. Taylor. A First Course in Stochastic Processes . Academic Press,\n2nd edition, 1975.\n[106] F. P. Kelly. Reversibility and Stochastic Networks . John Wiley and Sons, 1979.\n[107] A. Khinchin. Mathematical theory of a stationary queue. Matematicheskii Sbornik , 39(4):73–\n84, 1932.\n[108] J.F.C. Kingman. Two similar queues in parallel. Biometrika , 48:1316–1323, 1961.\n[109] J. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM ,\n46(5):604–632, 1999.\n[110] L. Kleinrock. Queueing Systems, Volume I: Theory . Wiley-Interscience Publication, 1975.\n[111] L. Kleinrock. Queueing Systems, Volume II. Computer Applications . John Wiley & Sons, 1976.\n[112] J. K ¨ollerstr ¨om. Heavy trafﬁc theory for queues with several servers. I. Journal of Applied\nProbability , 11:544–552, 1974.\n[113] A. Konheim, I. Meilijson, and A. Melkman. Processor-sharing of two parallel lines. Journal of\nApplied Probability , 18:952–956, 1981.\n536 bibliography\n[114] J.F. Kurose and K.W. Ross. Computer Networking: A Top-Down Approach Featuring the\nInternet . Pearson Education, 2003.\n[115] G. Latouche and V . Ramaswami. Introduction to Matrix Analytic Methods in Stochastic Mod-\neling . ASA-SIAM, Philadelphia, 1999.\n[116] A.M. Law and W.D. Kelton. Simulation Modeling and Analysis . McGraw-Hill Companies,\n2000.\n[117] E. Lazowska, J. Zahorjan, G. Graham, and K. Sevcik. Quantitative System Performance:\nComputer System Analysis Using Queueing Network Models . Prentice Hall, 1984.\n[118] A.M. Lee and P.A. Longton. Queueing process associated with airline passenger check-in.\nOperations Research Quarterly , 10:56–71, 1959.\n[119] S. Leonardi and D. Raz. Approximating total ﬂow time on parallel machines. In Proceedings\nof the Annual ACM Symposium on Theory of Computing (STOC) , pages 110–119, 1997.\n[120] H.C. Lin and C.S. Raghavendra. An analysis of the join the shortest queue (JSQ) policy.\nInProceedings of the 12th International Conference on Distributed Computing Systems ,\npages 362–366, 1992.\n[121] J.D.C. Little. A proof of the queueing formula L=λW.Operations Research , 9:383–387,\n1961.\n[122] J.C.S. Lui, R.R. Muntz, and D.F. Towsley. Bounding the mean response time of the minimum\nexpected delay routing policy: an algorithmic approach. IEEE Transactions on Computers ,\n44(12):1371–1382, 1995.\n[123] D. McWherter, B. Schroeder, N. Ailamaki, and M. Harchol-Balter. Improving preemp-\ntive prioritization via statistical characterization of OLTP locking. In Proceedings of the\n21st International Conference on Data Engineering , pages 446–457. San Francisco, April\n2005.\n[124] D. Meisner, B. Gold, and T. Wenisch. Powernap: Eliminating server idle power. In Proceedings\nof ASPLOS , pages 205–216, 2009.\n[125] D.A. Menasc ´e, V .A.F. Almeida, and I.W. Dowdy. Capacity Planning and Performance Mod-\neling . Prentice Hall, 1994.\n[126] M. Miyazawa. Rate conservation laws: a survey. Queueing Systems , 15(1–4):1–58, 1994.\n[127] R. Nelson. Probability, Stochastic Processes, and Queueing Theory . Springer-Verlag, 1995.\n[128] R.D. Nelson and T.K. Philips. An approximation to the response time for shortest queue routing.\nPerformance Evaluation Review , 17:181–189, 1989.\n[129] M.F. Neuts. Probability distributions of phase type. In Liber Amicorum Prof. Emeritus H.\nFlorin . University of Louvain, Belgium, pages 173–206, 1975.\n[130] M.F. Neuts. Matrix-Geometric Solutions in Stochastic Models . Johns Hopkins University Press,\n1981.\n[131] Normal Distribution Table for Finite Mathematics. www.zweigmedia.com/RealWorld/\nnormaltable.html.\n[132] S.A. Nozaki and S.M. Ross. Approximations in ﬁnite-capacity multi-server queues with Poisson\narrivals. Journal of Applied Probability , 15(4):826–834, 1978.\n[133] M. Nuijens. The Foreground-Background Queue . PhD thesis, Universiteit van Amsterdam,\n2004.\n[134] K. Oida and K. Shinjo. Characteristics of deterministic optimal routing for a simple trafﬁc\ncontrol problem. In Performance, Computing and Communications Conference, IPCCC , pages\n386–392, February 1999.\n[135] T. Osogami and M. Harchol-Balter. Closed form solutions for mapping general distributions\nto quasi-minimal PH distributions. Performance Evaluation , 63(6):524–552, 2006.\n[136] T. Osogami, M. Harchol-Balter, and A. Scheller-Wolf. Analysis of cycle stealing with switching\ntimes and thresholds. In Proceedings of the 2003 ACM Sigmetrics Conference on Measurement\nand Modeling of Computer Systems , pages 184–195, San Diego, June 2003.\nbibliography 537\n[137] T. Osogami, M. Harchol-Balter, and A. Scheller-Wolf. Analysis of cycle stealing with switching\ntimes and thresholds. Performance Evaluation , 61(4):374–369, 2005.\n[138] T. Osogami, M. Harchol-Balter, A. Scheller-Wolf, and L. Zhang. Exploring threshold-base\npolicies for load sharing. In Forty-Second Annual Allerton Conference on Communication,\nControl, and Computing , pages 1012–1021, University of Illinois, Urbana-Champaign, October\n2004.\n[139] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: bringing order\nto the web. Technical Report 1999–66, Stanford InfoLab, November 1999.\n[140] M. Pistoia and C. Letilley. IBM WebSphere Performance Pack: Load Balancing with\nIBM SecureWay Network Dispatcher , International Technical Support Organization, October\n1999.\n[141] F. Pollaczek. ¨Uber eine aufgabe der wahrscheinlichkeitstheorie. Mathematische Zeitschrift ,\n32:64–100, 1930.\n[142] I.A. Rai, E. W. Biersack, and G. Urvoy-Keller. Size-based scheduling to improve the perfor-\nmance of short TCP ﬂows. IEEE Network , January 2005.\n[143] I.A. Rai, G. Urvoy-Keller, and E.W. Biersack. Analysis of LAS scheduling for job size distri-\nbutions with high variance. In Proceedings of the ACM Sigmetrics Conference on Measurement\nand Modeling of Computer Systems , pages 218–228, 2003.\n[144] I.A. Rai, G. Urvoy-Keller, and E.W. Biersack. LAS scheduling approach to avoid bandwidth\nhogging in heterogeneous TCP networks. Lecture Notes in Computer Science , 3079:179–190,\n2004.\n[145] S. Raman and S. McCanne. A model, analysis, and protocol framework for soft state-based\ncommunication. In Proceedings of SIGCOMM , pages 15–25, 1999.\n[146] B.M. Rao and M.J.M. Posner. Algorithmic and approximation analyses of the shorter queue\nmodel. Naval Research Logistics , 34:381–398, 1987.\n[147] M. Reiser and S. Lavenberg. Mean-value analysis of closed multichain queueing networks.\nJournal of the ACM , 27(2):313–322, 1980.\n[148] S.M. Ross. Simulation . Academic Press, 2002.\n[149] S.M. Ross. Stochastic Processes . John Wiley and Sons, New York, 1983.\n[150] S.M. Ross. Introduction to Probability Models , 9th edition, Elsevier, New York, 2007.\n[151] C.H. Sauer and K.M. Chandy. Computer Systems Performance Modeling . Prentice-Hall,\n1981.\n[152] C.H. Sauer and K.M. Chandy. Approximate analysis of central server models. IBM Journal of\nResearch and Development , 19:301–313, 1975.\n[153] R.S. Schassberger. On the waiting time in the queueing systems GI/G/1. Annals of Mathematical\nStatistics , 41:182–187, 1970.\n[154] R.S. Schassberger. Warteschlangen . Springer-Verlag, 1973.\n[155] A. Scheller-Wolf and K. Sigman. New bounds for expected delay in FIFO GI/GI/c queues.\nQueueing Systems , 28:169–186, 1997.\n[156] A. Scheller-Wolf. Further delay moment results for FIFO multiserver queues. Queueing Sys-\ntems, 34:387–400, 2000.\n[157] A. Scheller-Wolf and K. Sigman. Delay moments for FIFO GI/GI/s queues. Queueing Systems ,\n25:77–95, 1997.\n[158] A. Scheller-Wolf and R. Vesilo. Structural interpretation and derivation of necessary and suf-\nﬁcient conditions for delay moments in FIFO multiserver queues. Queueing Systems , 54:221–\n232, 2006.\n[159] L.E. Schrage. A proof of the optimality of the shortest remaining processing time discipline.\nOperations Research , 16:687–690, 1968.\n[160] L.E. Schrage and L. W. Miller. The queue M/G/1 with the shortest remaining processing time\ndiscipline. Operations Research , 14:670–684, 1966.\n538 bibliography\n[161] B. Schroeder and M. Harchol-Balter. Evaluation of task assignment policies for supercomput-\ning servers: the case for load unbalancing and fairness. Cluster Computing: The Journal of\nNetworks, Software Tools, and Applications , 7(2):151–161, 2004.\n[162] B. Schroeder and M. Harchol-Balter. Web servers under overload: how scheduling can help.\nACM Transactions on Internet Technologies , 6(1):20–52, 2006.\n[163] B. Schroeder, M. Harchol-Balter, A. Iyengar, and E. Nahum. Achieving class-based QoS\nfor transactional workloads. In Proceedings of the 22nd International Conference on Data\nEngineering Poster Paper , pages 153–155, Atlanta, GA, April 2006.\n[164] B. Schroeder, M. Harchol-Balter, A. Iyengar, E. Nahum, and A. Wierman. How to deter-\nmine a good multi-programming level for external scheduling. In Proceedings of the 22nd\nInternational Conference on Data Engineering , pages 60–70, Atlanta, GA, April 2006.\n[165] B. Schroeder, A. Wierman, and M. Harchol-Balter. Open versus closed: a cautionary tale. In\nProceedings of Networked Systems Design and Implementation (NSDI) , 2006.\n[166] A. Shaikh, J. Rexford, and K.G. Shin. Load-sensitive routing of long-lived IP ﬂows. In Pro-\nceedings of ACM SIGCOMM , pages 215–226, September 1999.\n[167] K. Sigman. Lecture Notes borrowed from Karl Sigman’s Stochastic Processes Class, 2005.\n[168] M.S. Squillante, C.H. Xia, D.D. Yao, and L. Zhang. Threshold-based priority policies for\nparallel-server systems with afﬁnity scheduling. In Proceedings of the IEEE American Control\nConference , pages 2992–2999, June 2001.\n[169] M.S. Squillante, D.D. Yao, and L. Zhang. Internet trafﬁc: periodicity, tail behavior and perfor-\nmance implications. E. Gelenbe, editor, Systems Performance Evaluation: Methodologies and\nApplications , pages 23–37, CRC Press, 2000.\n[170] D.A. Stanford and W.K. Grassmann. The bilingual server system: a queueing model featuring\nfully and partially qualiﬁed servers. INFOR , 31(4):261–277, 1993.\n[171] D.A. Stanford and W.K. Grassmann. Bilingual server call centers. D.R. McDonald and S.R.E.\nTurner, editors, Analysis of Communication Networks: Call Centers, Trafﬁc and Performance ,\npages 31–47, American Mathematical Society, 2000.\n[172] Z. Tari, J. Broberg, A. Zomaya, and R. Baldoni. A least ﬂow-time ﬁrst load sharing approach\nfor a distributed server farm. Journal of Parallel and Distributed Computing , 65:832–842,\n2005.\n[173] Y .C. Tay. Analytical Performance Modeling for Computer Systems . Morgan & Claypool Pub-\nlishers, 2010.\n[174] E. Thereska. Enabling What-If Explorations in Systems . PhD thesis, Carnegie Mellon Univer-\nsity, 2007.\n[175] E. Thereska, M. Abd-El-Malek, J.J. Wylie, D. Narayanan, and G.R. Ganger. Informed data\ndistribution selection in a self-predicting storage system. In Proceedings of the International\nConference on Autonomic Computing (ICAC’06) , pages 187–198, June 2006.\n[176] G.B. Thomas and R.L. Finney. Calculus and Analytic Geometry . Addison-Wesley, 9th edition,\nJune 1996.\n[177] N. Thomas. Comparing job allocation schemes where service demand is unknown. Journal of\nComputer and System Sciences , 74:1067–1081, 2008.\n[178] H.C. Tijms. A First Course in Stochastic Models . John Wiley and Sons, 2003.\n[179] K.S. Trivedi. Probability and Statistics with Reliability, Queueing and Computer Science\nApplications . Prentice-Hall, 1982.\n[180] R.W. Weber. On optimal assignment of customers to parallel servers. Journal of Applied\nProbability , 15:406–413, 1978.\n[181] Weibull Distribution. Characteristics of the Weibull. http://www.weibull.com/hotwire/issue14/\nrelbasics14.htm.\n[182] P.D. Welch. On a generalized M/G/1 queueing process in which the ﬁrst customer of each busy\nperiod receives exceptional service. Operations Research , 12:736–752, 1964.\nbibliography 539\n[183] W. Whitt. A review of L=λW and extensions. Queueing Systems , 9:235–268, 1991.\n[184] W. Whitt. The impact of a heavy-tailed service-time distribution upon the M/GI/s waiting-time\ndistribution. Queueing Systems , 36:71–87, 2000.\n[185] W. Whitt. Approximating a point process by a renewal process: two basic methods. Operations\nResearch , 30:125–147, 1982.\n[186] W. Whitt. Open and closed models for networks of queues. AT&T Bell Laboratories Technical\nJournal , 63(9):1911–1979, 1984.\n[187] W. Whitt. Blocking when service is required from several facilities simultaneously. AT&T Bell\nLaboratories Technical Journal , 64(8):1807–1856, 1985.\n[188] A. Wierman. Scheduling for Today’s Computer Systems: Bridging Theory and Practice .P h D\nthesis, Carnegie Mellon University, 2007.\n[189] A. Wierman, N. Bansal, and M. Harchol-Balter. A note on comparing response times in\nM/GI/1/FB and M/GI/1/PS queues. Operations Research Letters , 32(1):73–76, 2004.\n[190] A. Wierman and M. Harchol-Balter. Classifying scheduling policies with respect to unfairness\nin an M/GI/1. In Proceedings of the 2003 ACM Sigmetrics Conference on Measurement and\nModeling of Computer Systems , pages 238–249, San Diego, CA, June 2003.\n[191] A. Wierman, M. Harchol-Balter, and T. Osogami. Nearly insensitive bounds on SMART\nscheduling. In ACM Sigmetrics 2005 Conference on Measurement and Modeling of Computer\nSystems , pages 205–215, 2005.\n[192] A. Wierman, T. Osogami, M. Harchol-Balter, and A. Scheller-Wolf. How many servers are\nbest in a dual-priority M/PH/k system? Performance Evaluation , 63(12):1253–1272, 2006.\n[193] R.J. Williams. On dynamic scheduling of a parallel server system with complete resource\npooling. D.R. McDonald and S.R.E. Turner, editors, Analysis of Communication Networks:\nCall Centers, Trafﬁc and Performance . American Mathematical Society, pages 49–72, 2000.\n[194] W. Winston. Optimality of the shortest line discipline. Journal of Applied Probability , 14:181–\n189, 1977.\n[195] R.W. Wolff. Stochastic Modeling and the Theory of Queues . Prentice-Hall, 1989.\n[196] D.D. Yao. Reﬁning the diffusion approximation for the M/G/m queue. Operations Research ,\n33:1266–1277, 1985.\n[197] S.F. Yashkov and A.S. Yashkova. Processor sharing: a survey of the mathematical theory.\nAutomation and Remote Control , 68(9):1662–1731, 2007.\n[198] J. Zhang. Limited Processor Sharing Queues and Multi-server Queues . PhD thesis, Georgia\nInstitute of Technology, 2009.\n[199] J. Zhang, J.G. Dai, and B. Zwart. Diffusion limits of limited processor sharing queues. Annals\nof Applied Probability , 21:745–799, 2011.\n[200] D. Zwillinger. CRC Standard Mathematical Tables and Formulae . Chapman & Hall, 31st\nedition, 2003.",31055
206-Index.pdf,206-Index,"Index\nAS,223,435,442\nAt,435\nAx\ny,514\nB,248,459\nBx,514\nC2,207\nDi,110\nDmax,116\nN,15\nNQ,15\nPQ,260\nPblock,261\nPij,131\nR,259,420\nS,14\nSe,403\nSx,514\nSx,492\nT,14\nTQ,15\nWx,513\nZ,21\nλ,14\nλi,298\nλx,514\nμ,14\nπj,135\nρ,100\nρ, for multi-server system, 259,269,420\nρi,100\nρx,505\nρx,492\nτi,225\nan,242\ndn,242\nni,305\no(δ),212\npj,148\npn,242\nr(t),208\nAccessible states, 150\nAcyclic networks, 293\nAdmission control, 246Age of service, 403\nAll-Can-Win Theorem, 527\nAloha protocol, 195\nAperiodic, 88,183\nAperiodic chain, 150\nArrival rate, 14\nTime-varying, 366\nArrival Theorem, 337\nProof of, 339\nAsymptotic analysis, 116\nBalance equations, 170,234\nBatch system, 22\nBayes Law, 36\nBCMP, 380\nFCFS servers, 381\nPLCFS servers, 384\nPS servers, 382\nBidirectional chain, 185\nBigIP, 420\nBimodal, 423\nBinomial distribution, 67\nBirth-death process, 236\nBlocking probability, 257\nBottleneck device, 119\nBottleneck Law, 110\nBounded Pareto distribution, 353,357,\n358\nBurke’s Theorem, 288\nAlternative proof, 290\nProof of, 289\nVia transforms, 447\nBusy period\nExpectation, 248,406,448\nM/G/1\nMoments, 461\nNumber of jobs served during, 469\nTransform, 459,461\nWith setup time, 469\nM/M/∞,406\nM/M/1\nNumber of jobs served during, 468\nTransform, 448\nShorts-only, 467\n541\n542 index\ncμ-Rule, 516\nCaching, 204\nCapacity provisioning, 272,274,277,seeOne\nfast or many slow\nCatalan numbers, 187\nCentral Limit Theorem, 61,356\nHeuristic proof via transforms, 448\nCentral subsystem, 22\nChebyshev’s Inequality, 91\nClass-based service rates\nFCFS servers, 330,381\nPS servers, 383\nClassed Jackson network, 314\nClass-based service rates, 330\nExamples, 322,325,326,329\nLimiting probabilities, 318\nClosed Jackson network, 333,345\nLimiting probabilities, 335\nClosed networks, 20\nBatch system, 96\nInteractive system, 96,345\nM/M/2, 284\nPerformance of, 284,294\nTerminal-driven system, 96\nCloud service center, 309\nCommunicating states, 150\nCommunication networks, 381\nCompatible time-sharing system, 265\nCompetitive ratio, 424\nCongestion management, 280\nConnection-oriented network, 312\nConstant failure rate, 350\nConvergence, 79\nConvergence almost surely, 80\nConvergence in probability, 82\nConvergence with probability 1, 80\nCorrelation, 67\nCoupon collection, 70\nCovariance, 67\nCoxian distribution, 380,383,385\nCPU process lifetimes, 208,349\nCSMA/CD, 196\nCTMC, seeMarkov chains\nCycle stealing, 430\nD/D/1, 404\nDamage caused by forest ﬁres, 356\nDatabase modeling, 497\nDecreasing failure rate, 208,354\nDelta-step proof ( δ-step), 209,212,213,\n219\nDeparture process, 289,291,451\nDevice demand, 110\nDFR, seeDecreasing failure rateDimensionality reduction, 430\nDispatcher, 408\nDistributional Little’s Law, 111,456\nDoubling arrival and service rates, 5,240,405\nDoubly stochastic matrix, 145\nDTMC, seeMarkov chains\nE2distribution, 364\nE2/M/1, 365\nEmbedded DTMC, 286,451,479\nEmpirical measurements, 350\nHuman wealth, 356\nIP ﬂow durations, 356\nNatural disasters, 356\nPhone call durations, 356\nWeb ﬁle sizes, 355\nWireless session times, 356\nEnsemble average, 84,86 200\nEquilibrium distribution, 396,403\nDistribution, 407\nTransform, 448\nEquivalence between Geometric and\nExponential, 209,211\nErgodic, 88,164\nErgodic theorem of Markov chains, 164,\n178\nErgodicity, 148\nErlang-2, 423\nErlang-B formula, 257\nErlang-C formula, 261\nErlang-k distribution, 360\nExceptional ﬁrst service, 280\nExcess of random variable, 396\nDistribution, 407\nExpectation, 401\nTransform, 448\nExcess of service, 396,402\nExpected number of visits to state, 157\nExpected time to k failures, 185\nExponential distribution, 206,350\nExponential phases, 360\nFailure rate function, 208,222\nFailures and repair, 407\nFairness, 356,475\nAll-Can-Win Theorem, 527\nFair scheduling, 487,526\nFeedback in network, 307,308\nFibonacci sequence, 205\nFinancial application, 185\nFinite buffer space, 282\nFirst-Come-First-Served (FCFS), 478\nFlow time, 14\nForced Flow Law, 106\nindex 543\nForward chain, 286\nFractional moments, 70\nFrequency-division multiplexing, 241,263\nG/G/k, 428\nStability, 428\nGambler’s ruin, 160\nGeneral service times, 383\nGeneralized Erlang, 360\nGenerating random variables\nAccept/Reject method, 72\nInverse-Transform method, 70\nGenerator matrix, 368\nGeometric distribution, 69,209\nGoogle’s PageRank algorithm, 190,191\nDead end, 192\nImplementation, 195\nSpider trap, 193\nGrabbing multiple servers simultaneously, 308,\n309\nH2distribution, 361\nHair salon, 282\nHeavy-tail property, 354,358\nHeterogeneous servers, 266,268\nHigh-variability job sizes, 408\nHoneypot, 223\nHTTP request scheduling, 356\nHTTP request times, 355\nHuman wealth, 356\nHyperexponential distribution, 361,377,378\nDecreasing failure rate, 362,378\nDegenerate, 362\nHypoexponential, 360\nImmediate dispatching, 408\nIncreasing failure rate, 208\nIncreasing number of servers, 276\nIndependent increments, 214\nIndicator random variables, 56\nInﬁnite variance, 354\nInsensitivity results, 257,278\nInspection Paradox, 395,402\nInteractive closed system, 21\nInterarrival time, 14\nIP ﬂow durations, 356\nIrreducible, 88,183\nIrreducible chain, 150\nJackson network, 297,305\nAcyclic, 293\nArrival process into server, 299\nClassed, seeClassed Jackson network\nExample, 306Limiting probabilities, 305\nLocal balance, 301\nProduct form, 304\nTotal arrival rate into server, 298\nWith load-dependent service rates, 344\nWith M/M/k queues, 344\nJob\nAge, 349,403\nLifetime, 349\nRemaining lifetime, 349\nSize, 14,349\nJob migration, 349\nCriterion, 355\nJoin-Shortest-Queue, seeTask assignment\npolicy\nKendall notation, 236,253\nKleinrock’s independence assumption, 381\nLaplace transform, 433\nConditioning, 441\nLinearity, 439\nMoments, 436,439\nSum of random number of random variables,\n444\nTwo-sided, 447\nLast-Come-First-Served (LCFS), 478\nLaw of large numbers\nStrong, 84\nWeak, 83\nLeast-Work-Left, seeTask assignment policy\nLimited processor-sharing, 498\nLimiting distribution, 136,140\nLimiting probabilities as rates, 168\nLimiting probability, 134,135,136,140,242\nAs seen by arrival, 242\nAs seen by departure, 242\nLittle’s Law, 95,98\nDistributional, 111,456\nFor closed systems, 96,101,112\nFor open systems, 95\nFor red jobs, 101\nFor waiting time, 100\nLittle-o, o(δ),211\nLoad, 18\nResource requirement, R,259,273\nSystem utilization, ρ,259,269\nLoad balancer, 408\nLoad balancing, 349\nLoad balancing versus unbalancing, 267,268,\n415,432\nLoad in multi-server system, 273\nLoad-dependent service rates, 344\nLocal balance, 301,318,333,386\n544 index\nLocalDirector, 420\nLog-log plot, 351\nM∗/E∗\n2/1,372\nMt,366\nMt/M/1, 366\nM/E 2/1,364\nM/E k/1,398\nM/H 2/1,364,398\nM/H 2/2,378\nWith setup time, 378\nM/BP/1/PS, 394\nM/Cox/1/PS, 385\nM/D/1, 398,404\nM/G/∞,278\nInsensitivity, 278\nM/G/1, 395\nBusy period, 459,461\nDifferent job types, 405\nFailures and repair, 407\nLaplace transform of response time, 450,\n488\nLow utilization, 404\nMean time in queue, 397\nPriority queue, seePriority queue\nSpecial busy periods, 462\nStability, 419\nTagged-job argument, 397\nTime in queue, 404\nVariability in service time, 405\nVariance time in queue, 404,456\nWith setup time\nMean, 465\nTransform, 464\nZ-transform of number in queue, 456\nZ-transform of number in system, 450\nM/G/1/PS, 385,394\nAges of jobs, 484\nM/G/2, 418\nStability, 418\nM/G/k, 413,428\nInaccuracy of approximations, 413\nLee-Longton approximation, 413\nM/M/∞,266,271\nBusy period, 406\nWith setup time, 468\nM/M/1, 236\nBusy period, 448\nBusy period mean, 248\nDeparture process, 289,291\nFinite capacity, 246\nNumber in queue, 246\nNumber in system, mean, 239\nNumber in system, variance, 239Response time, distribution, 248,443,447\nResponse time, mean, 239\nSimulation of, 246\nThreshold queue, 249\nWith feedback loop, 307\nWith setup time, 280,465\nM/M/1/N, 246\nM/M/1/PS, 384\nM/M/2\nHeterogeneous servers, 266,268\nTransform analysis, 449,456\nWith setup time, 378\nM/M/2/3, 447\nExample, 265\nM/M/k, 253,258\nCapacity provisioning, 272\nDeparture process, 289\nDistribution time in queue, 277\nExpected number busy, 259,262\nExpected number in queue, 262\nIncreasing number of servers, 276\nMean time in queue, 270\nMean time in queue given delayed, 270\nProbability of queueing, PQ,261\nResource requirement, R,259\nSystem utilization, ρ,259,269\nTransform analysis, 449,456\nM/M/k/k, 253,255\nBlocking probability, 256\nErlang-B formula, 257\nInsensitivity result, 257\nM/PH/1, 377\nMarkov chains\nAccessible states, 150\nAperiodic, 150,183\nBalance equations, 170,234\nCommunicating states, 150\nContinuous-time (CTMC), 130,225\nView 1, 226\nView 2, 227\nConverting CTMC to DTMC, 229,234,\n235\nDiscrete-time (DTMC), 129,130\nErgodic, 164\nErgodic theorem, 164,178\nErgodicity, 148\nExpected number of visits to state, 157\nFinite-state, 131,138,189\nGambler’s ruin, 160\nInﬁnite-state, 139\nIrreducible, 150,183\nLimiting distribution, 135,136,139,140\nLimiting distribution equals stationary\ndistribution, 136,140\nindex 545\nLimiting probabilities, 134,135,136,139,\n140\nLimiting probabilities as rates, 168\nMarkovian property, 130,225\nn-step transition probabilities, 133\nNull recurrent, 162\nPeriodic, 171\nPositive recurrent, 162,183\nPowers of P,133\nRandom walk, 160\nRecurrent chain, 161\nRecurrent state, 156,157\nRecurrent versus transient, 188\nSemi-Markov process, 406\nSolution via generating functions, 201,205\nStationary distribution, 136,140\nStationary equations, 136\nStationary property, 131\nSteady state, 137\nSummary theorem, 165\nSymmetric random walk, 163\nTime average, 166\nTime average versus ensemble average, 88,\n148\nTime between visits to state, 153,164,406\nTime to empty, 204\nTime until leave state, 226\nTime-reversibility equations, 171,254\nTime-reversible, 170,254\nTransient chain, 159,161\nTransient state, 156,157\nTransition probability matrix, 131\nMarkov-modulated Poisson process, 366\nMarkov’s Inequality, 91\nMarkovian property, 130,225\nMatching moments of distribution, 361,\n363\nMatrix-analytic method, 359,366\nGenerator matrix, 368\nM/PH/1, 377\nTime-varying load, 377\nMax of Exponentials, 223,224\nMean value analysis (MV A), 337,340\nMemoryless, 207,222\nMemoryless distribution, 209\nMethod of phases, 359\nMethod of stages, 359\nMigrating jobs, 349\nMigrating old jobs, 355\nMinimum of Exponentials, 212\nModiﬁcation analysis, 114,118,124\nMultiple resources at once, 309\nMultiprogramming level (MPL), 21,23\nFor Processor-Sharing, 497Network Dispatcher, 420\nNetwork of PS servers, 391,393\nNetwork of workstations, 349,383\nNetwork with two job types, 326\nNon-Markovian arrival process, 366\nNormal approximation, 68\nNull recurrent, 162\nOne fast or many slow, 7,263,431\nOpen networks, 16\nOpen versus closed systems, 123,247,267\nOperational laws, 93\nAsymptotic analysis, 116\nBottleneck Law, 110\nCombining operational laws, 107,112\nForced Flow Law, 106\nLittle’s Law, 95,98\nFor closed systems, 101,112\nFor mean slowdown, 113\nFor red jobs, 101\nFor waiting time, 100\nModiﬁcation analysis, 118,124\nResponse Time Law, 103\nUtilization Law, 100\nPacket-routing network, 312\nParallel jobs, 308\nPareto distribution, 352,355,415\nPASTA, 242,243,338\nPerformance metrics, 473\nPerformance-per-Watt, 458\nPeriodic chains, 171,189\nPhase-type distribution, 359,362\nPhone call durations, 356\nPoisson\nNumber of arrivals during S, 223\nPoisson approximation to Binomial, 67\nPoisson Arrivals See Time Averages\n(PASTA), 242,243,398\nApplication to simulations, 244\nPoisson process, 213,222\nDeﬁnition 1, 215\nDeﬁnition 2, 215\nDeﬁnition 3, 217\nIndependent increments, 214\nMerging processes, 218\nNumber of arrivals during service, 223,435\nPoisson splitting, 218\nStationary increments, 215\nUniformity, 221\nPollaczek-Khinchin (P-K) formula, 404\nPositive correlation, 67\nPositive recurrent, 88,162,183\nPower laws in Internet, 355\n546 index\nPower management, 457\nDynamic power management, 111\nPerformance-per-Watt, 466\nPolicies\nDelayedOff, 469\nON/IDLE, 458,465\nON/OFF, 458,466,469\nPower allocation, 125\nServer farm, 467\nSetup cost, 458\nPower-law distribution, 352\nPreemptive-resume, 482\nPricing for queues, 279\nPriority queue, 499\nNon-preemptive, 500,502\nPreemptive, 500,508\nProbability\nAlternative deﬁnition of expectation, 69\nBayes Law, 36,68\nBernoulli distribution, 38\nBinomial distribution, 39\nConditional independence, 68\nConditional probability, 33\nConditional random variables, 49\nConditionally independent events, 34\nConditioning, 53\nCovariance, 67\nExpectation, 44\nExpectation of product, 48,65\nExpectation of quotient, 65\nExpected time to kfailures, 185\nExponential distribution, 42\nGeometric distribution, 39\nIndependent events, 34\nIndependent random variables, 48\nIndicator random variables, 56\nLaw of Total Probability, 35,53\nLinear transformation property, 60\nLinearity of Expectation, 54\nMarkov’s Inequality, 91\nMutually exclusive events, 32\nNormal distribution, 57,68\nPareto distribution, 43\nPoisson distribution, 40\nRandom variable\nContinuous, 37\nDiscrete, 37\nSum of Geometric number of Exponentials,\n223\nSum of random number of random variables,\n62,187\nVariance, 46\nVariance of sum, 56,65\nProcess migration, 349Processor with failures, 205\nProcessor-Sharing, 380\nProduct form, 304,311,318,330,333,380,\n392,394\nProgram analysis example, 132\nLimiting distribution, 145\nQuality of Service, 67\nQuick versus slow customers, 329\nR a i s i n gm a t r i xt op o w e r , 133\nRandom, seeTask assignment policy, 478\nRandom walk, 160\nRandomized chess, 186\nRecurrent chain, 161\nRecurrent state, 156,157\nRecurrent versus transient, 188\nRelationship between closed and open systems,\n25\nReliability\nMax of Exponentials, 223,224\nMin of Exponentials, 212\nRemaining service requirement, 518\nRemote execution, 349\nRenewal process, 167,399\nRenewal theorem, 167\nRenewal-Reward theorem, 400\nRenewal-Reward theory, 399,406\nRepair facility, 330\nRepair facility example, 131,133,138\nRerouting IP ﬂows, 356\nResidence time, 510,519\nResidual distribution, 396\nResidue classes, 173,189\nResource requirement, R,273\nResponse time, 14\n95th percentile, 277\nResponse time in closed system, 22\nResponse Time Law for Closed Systems, 103\nReverse chain, 285,286\nReverse process, 286\nRound-Robin, seeTask assignment policy\nRouting\nClass-based, 311,326\nRouting probability, 297\nSample mean, 357\nSample path, 80\nSample variance, 357\nScheduling\nComparison of policies, 524\nFairness, seeFairness\nFirst-Come-First-Served (FCFS), 10\nForeground-Background (FB), 490\nindex 547\nResponse time, 494\nTransform, 497\nLast-Come-First-Served (LCFS), 10\nTransform, 481\nLeast-Attained-Service (LAS), 491\nLimited Processor-Sharing, 497\nMinimizing mean slowdown, 125\nNon-preemptive, 410,478,479,481\nPreemptive, 482\nPreemptive-LCFS (PLCFS), 488\nResponse time, 489\nTransform, 497\nPreemptive-Shortest-Job-First (PSJF),\n512\nTransform, 514\nProcessor-Sharing (PS), 382,483\nResponse time, 486\nRandom, 10,478\nRS policy, 113\nShortest-Job-First (SJF), 499,505\nShortest-Remaining-Processing-Time\n(SRPT), 26,113,356,519\nSRPT beats FB, 523\nStarvation, 356,475\nWork-conserving policy, 474\nScheduling web requests, 356,499\nScherr’s thesis, 265\nSecurity application, 223\nSemi-Markov process, 406\nServer farm, 408\nFCFS servers, 410\nOptimal design, 424\nPS and FCFS servers, 430\nPS servers, 391,419,430\nTask assignment, seeTask assignment in\nserver farms\nService rate, 14\nService requirement, 14\nSetup cost, 11,458\nSetup time, 280,378,465,468\nSimulation\nGenerating random variables, 70\nM/BP/1, 357\nM/M/1, 78\nPareto, 358\nSample mean, 357\nSample variance, 357\nTime average versus ensemble average,\n90\nSize-Interval-Task-Assignment (SITA), seeTask\nassignment policy\nSlotted Aloha protocol, 196\nSlowdown, 26,474,481\nSojourn time, 14Solving recurrences via generating functions,\n201\nSquare-root stafﬁng, 274,277\nSquared coefﬁcient of variation, C2,65,207,\n359\nStability, 26\nM/G/2, 418\nMinimum number of servers needed, 273\nSingle queue, 15,419\nStarvation, 475,496\nStationary distribution, 136,140\nStationary equations, 136\nStationary increments, 215\nStationary property, 131\nStatistical multiplexing, 241\nSteady state, 137\nStirling’s approximation, 155\nStochastic process, 130\nStopping time, 187\nStrong Law of Large Numbers, 84,167\nSum of Geometric number of Exponentials,\n223\nWith transforms, 446\nSum of random number of random variables,\n62,187\nWith transforms, 444\nSupercomputer center, 308\nSURGE, 355\nSymmetric random walk, 163,187,188\nSYNC, 356\nSystem utilization, ρ,259,269\nTagged-job argument, 396\nTail of response time, 475\nTandem queue, 291\nWith ﬁnite buffers, 282\nTask assignment in server farms, 9,408\nDynamic, 412\nLoad balancing, 267\nLoad balancing versus unbalancing, 267,268\nStatic, 412\nTask assignment policy, 408\nCentral queue, 411\nCentral-Queue-SRPT, 425\nComparison, 423\nCycle stealing, 430\nHybrid, 428\nIMD, 427\nJoin-Shortest-Queue (JSQ), 429\nFor PS servers, 422\nLeast-Work-Left (LWL), 412,431\nM/G/k, 411,431\nOPT-0, 423\nRandom policy, 410\n548 index\nTask assignment policy ( cont. )\nRound-Robin policy, 410\nSITA versus LWL, 416\nSize-Interval-Task-Assignment (SITA), 414\nOptimal size cutoffs, 414\nTAGS, 428\nUnder low variability, 419\nTCP ﬂow scheduling, 356\nThink time, 21\nThreshold queue, 146,249\nThroughput, 17\nThroughput in closed system, 23\nThroughput of device, 18\nThrowing away servers, 267\nTime average, 84,86,166\nTime average versus ensemble average, 88,148\nTime between visits to state, 153,164,406\nTime in system, 14\nTime-reversibility, 170,288,294\nTime-reversibility equations, 171,254\nTime to empty, 204\nTime until kconsecutive failures, 70\nTime-sharing, 380\nTime-sharing CPU, 382\nTime-varying arrival rate, 366\nTime-varying load, 377\nTransient chain, 159,161\nTransient state, 156,157\nTransition probability matrix, 131\nTransmission time, 382\nTurnaround time, 14\nUmbrella problem example, 132,133,139\nUnbounded queue example, 142UNIX process lifetime, 349\nDistribution, 350\nEmpirical measurements, 350\nUtilization, 17,100\nDerivation of, 100\nUtilization Law, 19,100\nUtilization of device, 18\nUtilization of multi-server system, 273\nVacation of server, 467\nVariability in service time, 377,378,403,\n405\nVariance, 46\nWaiting time, 510\nWald’s equation, 187\nWalk on undirected weighted graph, 186\nWeak Law of Large Numbers, 83,91\nWeb ﬁle sizes, 355\nWeb server farm, 419\nWeibull distribution, 423,524,525\nWhat-if questions, 93,114\nWireless session times, 356\nWork in system, 474\nWork-conserving policy, 474\nWorst-case analysis, 424\nZ-transform, 201,434\nConditioning, 441\nFor solving recurrences, 201\nLinearity, 440\nMoments, 437\nSum of random number of random variables,\n444",18955

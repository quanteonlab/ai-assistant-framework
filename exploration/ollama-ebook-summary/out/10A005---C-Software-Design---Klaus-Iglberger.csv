filename,title,text,len
01-Preface.pdf,01-Preface,,0
02-Software Design.pdf,02-Software Design,"Preface\nIn your hands you’re holding the C++ book that I wish I would have had\nmany years ago. Not as one of my first books, no, but as an advanced book,\nafter I had already digested the language mechanics and was able to think\nbeyond the C++ syntax. Y es, this book would have definitely helped me\nbetter understand the fundamental aspects of maintainable software, and\nI’m confident that it will help you too.\nWhy I Wrote This Book\nBy the time I was really digging into the language (that was a few years\nafter the first C++ standard had been released), I had read pretty much\nevery C++ book there was. But despite the fact that many of these books\nwere great and definitely paved the way for my current career as a C++\ntrainer and consultant, they were too focused on the little details and the\nimplementation specifics, and too far away from the bigger picture of\nmaintainable software.\nAt the time, very few books truly focused on the bigger picture, dealing\nwith the development of lar ge software systems. Among these were John\nLakos’ s Large Scale C++  Softwar e Design , a great but literally heavy\nintroduction to dependency management, and the so-called Gang of Four\nbook, which is the classic book on software design patterns.  Unfortunately ,\nover the years, this situation hasn’ t really changed: most books, talks, blogs,\netc., primarily focus on language mechanics and features—the small details\nand specifics. V ery few , and in my opinion way too few , new releases focus\non maintainable software, changeability , extensibility , and testability . And if\nthey try to, they unfortunately quickly fall back into the common habit of\nexplaining language mechanics and demonstrating features.\nThis is why I’ve written this book. A book that does not, in contrast to most\nothers, spend time on the mechanics or the many features of the language,1\n2\nbut primarily focuses on changeability , extensibility , and testability of\nsoftware in general. A book that does not pretend that the use of new C++\nstandards or features will make the dif ference between good or bad\nsoftware, but instead clearly shows that it is the management of\ndependencies that is decisive, that the dependencies in our code decide\nbetween it being good or bad. As such, it is a rare kind of book in the world\nof C++ indeed, as it focuses on the bigger picture: software design.",2397
03-Who This Book Is For.pdf,03-Who This Book Is For,"What This Book Is About\nSoftware Design\nFrom my point of view , good software design is the essence of every\nsuccessful software project. Y et still, despite its fundamental role, there is\nso little literature on the topic, and very little advice on what to do and how\nto do things right. Why? W ell, because it’ s difficult. V ery dif ficult. Probably\nthe most dif ficult facet of writing software that we have to face. And that’ s\nbecause there is no single “right” solution, no “golden” advice to pass on\nthrough the generations of software developers. It always depends.\nDespite this limitation, I will give advice on how to design good, high-\nquality software. I will provide design principles, design guidelines, and\ndesign patterns that will help you to better understand how to manage\ndependencies and turn your software into something you can work with for\ndecades. As stated before, there is no “golden” advice, and this book\ndoesn’ t hold any ultimate or perfect solution. Instead, I try to show the most\nfundamental aspects of good software, the most important details, the\ndiversity and the pros and the cons of dif ferent designs. I will also formulate\nintrinsic design goals and demonstrate how to achieve these goals with\nModern C++.\nModern C++\nFor more than a decade, we’ve been celebrating the advent of Modern C++,\napplauding the many new features and extensions of the language, and by\ndoing so, creating the impression that Modern C++ will help us solve all\nsoftware-related problems. Not so in this book. This book does not pretend\nthat throwing a few smart pointers at the code will make the code “Modern”\nor automatically yield good design. Also, this book won’ t show Modern\nC++ as an assortment of new features. Instead, it will show how the\nphilosophy of the language has evolved and the way we implement C++\nsolutions today .\nBut of course, we will also see code. Lots of it. And of course this book will\nmake use of the features of newer C++ standards (including C++20).\nHowever , it will also make an ef fort to emphasize that the design is\nindependent of the implementation details and the used features. New\nfeatures don’ t change the rules about what is good design or bad design;\nthey merely change the way we implement good design. They make it\neasier to implement good design. So this book shows and discusses\nimplementation details, but (hopefully) doesn’ t get lost in them and always\nremains focused on the big picture: software design and design patterns.\nDesign Patterns\nAs soon as you start mentioning design patterns, you inadvertently conjure\nup the expectation of object-oriented programming and inheritance\nhierarchies. Y es, this book will show the object-oriented origin of many\ndesign patterns. However , it will put a strong emphasis on the fact that there\nisn’t just one way to make good use of a design pattern. I will demonstrate\nhow the implementation of design patterns has evolved and diversified,\nmaking use of many dif ferent paradigms, including object-oriented\nprogramming, generic programming, and functional programming. This\nbook acknowledges the reality that there is no one true paradigm and does\nnot pretend that there is only one single approach, one ever -working\nsolution for all problems. Instead it tries to show Modern C++ for what it\ntruly is: the opportunity to combine all paradigms, weave them into a strong\nand durable net, and create software design that will last through the\ndecades.\nI hope this book proves to be the missing piece in C++ literature. I hope it\nhelps you as much as it would have helped me. I hope that it holds some\nanswers you have been looking for and provides you with a couple of key\ninsights that you were missing. And I also hope that this book keeps you\nsomewhat entertained and motivated to read everything. Most importantly ,\nhowever , I hope that this book will show you the importance of software\ndesign and the role that design patterns play . Because, as you will see,\ndesign patterns are everywhere!",4070
04-OReilly Online Learning.pdf,04-OReilly Online Learning,"Who This Book Is For\nThis book is of value to every C++ developer . In particular , it is for every\nC++ developer interested in understanding the usual problems of\nmaintainable software and learning about common solutions to these\nproblems (and I assume that is indeed every  C++ developer). However , this\nbook is not a C++ beginner ’s book. In fact, most of the guidelines in this\nbook require some experience with software development in general and\nC++ in particular . For instance, I assume that you have a firm grasp of the\nlanguage mechanics of inheritance hierarchies and some experience with\ntemplates. Then I can reach for the corresponding features whenever\nnecessary and appropriate. Once in a while, I will even reach for some\nC++20 features (in particular C++20 concepts). However , as the focus is on\nsoftware design, I will rarely dwell on explaining a particular feature, so if a\nfeature is unknown to you, please consult your favorite C++ language\nreference. Only occasionally will I add some reminders, mostly about\ncommon C++ idioms (such as the Rule of 5 ).\nHow This Book Is Structured\nThis book is or ganized into chapters, each containing several guidelines.\nEach guideline focuses on one key aspect of maintainable software or one\nparticular design pattern. Hence, the guidelines represent the major\ntakeaways, the aspects that I hope bring the most value to you. They’re\nwritten such that you can read all of them from front to back, but since\nthey’re only loosely coupled, they enable you to also start with the\nguideline that attracts your attention. Still, they’re not independent.\nTherefore, each guideline contains the necessary cross-references to other\nguidelines to show you that everything is connected.\nConventions Used in This Book\nThe following typographical conventions are used in this book:\nItalic\nIndicates new terms, URLs, email addresses, filenames, and file\nextensions.\nConstant width\nUsed for program listings, as well as within paragraphs to refer to\nprogram elements such as variable or function names, databases, data\ntypes, environment variables, statements, and keywords.\nConstant width bold\nShows commands or other text that should be typed literally by the user .\nConstant width italic\nShows text that should be replaced with user -supplied values or by\nvalues determined by context.\nTIP\nThis element signifies a tip or suggestion.\nNOTE\nThis element signifies a general note.\nUsing Code Examples\nSupplemental material  (code examples, exercises, etc.) is available for\ndownload at https://github.com/igl42/cpp_softwar e_design .\nIf you have a technical question or a problem using the code examples,\nplease send email to bookquestions@or eilly.com .\nThis book is here to help you get your job done. In general, if example code\nis offered with this book, you may use it in your programs and\ndocumentation. Y ou do not need to contact us for permission unless you’re\nreproducing a significant portion of the code. For example, writing a\nprogram that uses several chunks of code from this book does not require\npermission. Selling or distributing examples from O’Reilly books does\nrequire permission. Answering a question by citing this book and quoting\nexample code does not require permission. Incorporating a significant\namount of example code from this book into your product’ s documentation\ndoes require permission .\nWe appreciate, but generally do not require, attribution. An attribution\nusually includes the title, author , publisher , and ISBN. For example: “ C++\nSoftwar e Design  by Klaus Iglber ger (O’Reilly). Copyright 2022 Klaus\nIglber ger, 978-1-098-1 1316-2.”\nIf you feel your use of code examples falls outside fair use or the\npermission given above, feel free to contact us at permissions@or eilly.com .",3836
05-Acknowledgments.pdf,05-Acknowledgments,"O’Reilly Online Learning\nNOTE\nFor more than 40 years, O’Reilly Media  has provided technology and business training,\nknowledge, and insight to help companies succeed.\nOur unique network of experts and innovators share their knowledge and\nexpertise through books, articles, and our online learning platform.\nO’Reilly’ s online learning platform gives you on-demand access to live\ntraining courses, in-depth learning paths, interactive coding environments,\nand a vast collection of text and video from O’Reilly and 200+ other\npublishers. For more information, visit http://or eilly.com .\nHow to Contact Us\nPlease  address comments and questions concerning this book to the\npublisher:\nO’Reilly Media, Inc.\n1005 Gravenstein Highway North\nSebastopol, CA 95472\n800-998-9938 (in the United States or Canada)\n707-829-0515 (international or local)\n707-829-0104 (fax)\nWe have a web page for this book, where we list errata, examples, and any\nadditional information. Y ou can access this page at https://or eil.ly/c-plus-\nplus.\nEmail bookquestions@or eilly.com  to comment or ask technical questions\nabout this book.\nFor news and information about our books and courses, visit\nhttp://or eilly.com .\nFind us on LinkedIn: https://linkedin.com/company/or eilly-media .\nFollow us on T witter: http://twitter .com/or eillymedia .\nWatch us on Y ouTube: http://youtube.com/or eillymedia .\nAcknowledgments\nA book such as this is never the achievement of a single individual. On the\ncontrary , I have to explicitly thank many people who helped me in dif ferent\nways to make this book a reality . First and foremost, I want to express my\ndeep gratitude to my wife, Stef fi, who read through the entire book without\neven knowing C++. And who took care of our two kids to give me the\nnecessary calm to bring all of this information to paper (I am still not sure\nwhich of these two was the bigger sacrifice).\nA special thank-you goes to my reviewers, Daniela Engert, Patrice Roy ,\nStefan W eller, Mark Summerfield, and Jacob Bandes-Storch, for investing\ntheir valuable time to make this a better book by constantly challenging my\nexplanations and examples.\nA big thank-you also goes to Arthur O’Dwyer , Eduardo Madrid, and Julian\nSchmidt for their input and feedback about the T ype Erasure design pattern,\nand to Johannes Gutekunst for the discussions on software architecture and\ndocumentation.\nFurthermore, I want to say thank you to my two cold readers, Matthias\nDörfel and V ittorio Romeo, who helped catch many last-second mistakes\n(and indeed they did).\nLast, but definitely not least, a big thank-you goes to my editor , Shira\nEvans, who has spent many hours giving invaluable advice about making\nthe book more consistent and more fun to read.\n1 John Lakos, Large-Scale C++ Softwar e Design  (Addison-W esley , 1996).\n2 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e\n(Addison-W esley , 1994).",2966
06-Guideline 1 Understand the Importance of Software Design.pdf,06-Guideline 1 Understand the Importance of Software Design,"Chapter 1. The Art of Software\nDesign\nWhat  is software design? And why should you care about it? In this chapter ,\nI will set the stage for this book on software design. I will explain software\ndesign in general, help you understand why it is vitally important for the\nsuccess of a project, and why it is the one thing you should get right. But\nyou will also see that software design is complicated. V ery complicated. In\nfact, it is the most complicated part of software development. Therefore, I\nwill also explain several software design principles that will help you to\nstay on the right path.\nIn “Guideline 1: Understand the Importance of Software Design ”, I will\nfocus on the big picture and explain that software is expected to change.\nConsequently , software should be able to cope with change. However , that\nis much easier said than done, since in reality , coupling and dependencies\nmake our life as a developer so much harder . That problem is addressed by\nsoftware design. I will introduce software design as the art of managing\ndependencies and abstractions—an essential part of software engineering.\nIn “Guideline 2: Design for Change” , I will explicitly address coupling and\ndependencies and help you understand how to design for change and how to\nmake software more adaptable. For that purpose, I will introduce both the\nSingle-Responsibility Principle (SRP)  and the Don’ t Repeat Y ourself (DR Y)\nprinciple, which help you to achieve this goal.\nIn “Guideline 3: Separate Interfaces to A void Artificial Coupling ”, I will\nexpand the discussion about coupling and specifically address coupling via\ninterfaces. I will also introduce the Interface Segr egation Principle (ISP)  as\na means to reduce artificial coupling induced by interfaces.\nIn “Guideline 4: Design for T estability” , I will focus on testability issues\nthat arise as a result of artificial coupling. In particular , I will raise the",1945
07-Software Design The Art of Managing Dependencies and Abstractions.pdf,07-Software Design The Art of Managing Dependencies and Abstractions,"question of how to test a private member function and demonstrate that the\none true solution is a consequent application of separation of concerns.\nIn “Guideline 5: Design for Extension” , I will address an important kind of\nchange: extensions. Just as code should be easy to change, it should also be\neasy to extend. I will give you an idea how to achieve that goal, and I will\ndemonstrate the value of the Open-Closed Principle (OCP) .\nGuideline 1: Understand the Importance of\nSoftware Design\nIf I were to ask you which code properties are most important to you, you\nwould, after some thinking, probably say things like readability , testability ,\nmaintainability , extensibility , reusability , and scalability . And I would\ncompletely agree. But now , if I were to ask you how to achieve these goals,\nthere is a good chance that you would start to list some C++ features: RAII,\nalgorithms, lambdas, modules, and so on.\nFeatures Are Not Software Design\nYes, C++ of fers a lot of features. A lot! Approximately  half of the almost\n2,000 pages of the printed C++ standard are devoted to explaining language\nmechanics and features.  And since the release of C++1 1, there is the\nexplicit promise that there will be more: every three years, the C++\nstandardization committee blesses us with a new C++ standard that ships\nwith additional, brand-new features. Knowing that, it doesn’ t come as a big\nsurprise that in the C++ community there’ s a very strong emphasis on\nfeatures and language mechanics. Most books, talks, and blogs are focused\non features, new libraries, and language details.\nIt almost feels as if features are the most important thing about\nprogramming in C++, and crucial for the success of a C++ project. But\nhonestly , they are not. Neither the knowledge about all the features nor the\nchoice of the C++ standard is responsible for the success of a project. No,\nyou should not expect features to save your project. On the contrary: a1\n2\nproject can be very successful even if it uses an older C++ standard, and\neven if only a subset of the available features are used. Leaving aside the\nhuman aspects of software development, much more important for the\nquestion about success or failure of a project is the  overall structur e of the\nsoftware. It is the structure that is ultimately responsible for maintainability:\nhow easy is it to change code, extend code, and test code? W ithout the\nability to easily change code, add new functionality , and have confidence in\nits correctness due to tests, a project is at the end of its lifecycle. The\nstructure is also responsible for the scalability of a project: how lar ge can\nthe project grow before it collapses under its own weight? How many\npeople can work on realizing the vision of the project before they step on\none another ’s toes?\nThe overall structure is the design of a project. The design plays a much\nmore central role in the success of a project than any feature could ever do.\nGood software is not primarily about the proper use of any feature; rather , it\nis about solid architecture and design. Good software design can tolerate\nsome bad implementation decisions, but bad software design cannot be\nsaved by the heroic use of features (old or new) alone.\nSoftware Design: The Art of Managing Dependencies\nand Abstractions\nWhy  is software design so important for the quality of a project? W ell,\nassuming everything works perfectly right now , as long as nothing changes\nin your software and as long as nothing needs to be added, you are fine.\nHowever , that state will likely not last for long. It’ s reasonable to expect\nthat something will change. After all, the one constant in software\ndevelopment is change. Change is the driving force behind all our problems\n(and also most of our solutions). That’ s why software is called software:\nbecause in comparison to hardware, it is soft and malleable. Y es, software is\nexpected to be easily adapted to the ever -changing requirements. But as you\nmay know , in reality this expectation might not always be true.\nTo illustrate this point, let’ s imagine that you select an issue from your issue\ntracking system that the team has rated with an expected ef fort of 2.\nWhatever a 2 means in your own project(s), it most certainly does not\nsound like a big task, so you are confident that this will be done quickly . In\ngood faith, you first take some time to understand what is expected, and\nthen you start by making a change in some entity A. Because of immediate\nfeedback from your tests (you are lucky to have tests!), you are quickly\nreminded that you also have to address the issue in entity B. That is\nsurprising! Y ou did not expect that B was involved at all. Still, you go ahead\nand adapt B anyway . However , again unexpectedly , the nightly build reveals\nthat this causes C and D to stop working. Before continuing, you now\ninvestigate the issue a little deeper and find that the roots of the issue are\nspread through a lar ge portion of the codebase. The small, initially\ninnocent-looking task has evolved into a lar ge, potentially risky code\nmodification.  Your confidence in resolving the issue quickly is gone. And\nyour plans for the rest of the week are as well.\nMaybe this story sounds familiar to you. Maybe you can even contribute a\nfew war stories of your own. Indeed, most developers have similar\nexperiences. And most of these experiences have the same source of\ntrouble. Usually the problem can be reduced to a single word:\ndependencies . As Kent Beck has expressed in his book on test-driven\ndevelopment:\nDependency is the key pr oblem in softwar e development at all scales.\nDependencies are the bane of every software developer ’s existence. “But of\ncourse there are dependencies,” you ar gue. “There will always be\ndependencies. How else should dif ferent pieces of code work together?”\nAnd of course, you are correct. Dif ferent pieces of code need to work\ntogether , and this interaction will always create some form of coupling.\nHowever , while there are necessary , unavoidable dependencies, there are\nalso artificial dependencies that we accidentally introduce because we lack\nan understanding of the underlying problem, don’ t have a clear idea of the\nbigger picture, or just don’ t pay enough attention. Needless to say , these\nartificial dependencies hurt. They make it harder to understand our\nsoftware, change software, add new features, and write tests. Therefore, one3\n4\nof the primary tasks, if not the primary task, of a software developer is to\nkeep artificial dependencies at a minimum.\nThis minimization of dependencies is the goal of software architecture and\ndesign. To state it in the words of Robert C. Martin:\nThe goal of softwar e architectur e is to minimize the human r esour ces\nrequir ed to build and maintain the r equir ed system.\nArchitecture and design are the tools needed to minimize the work ef fort in\nany project. They deal with dependencies and reduce the complexity via\nabstractions. In my own words:\nSoftwar e design  is the art of managing inter dependencies between\nsoftwar e components. It aims at minimizing artificial (technical)\ndependencies and intr oduces the necessary abstractions and\ncompr omises.\nYes, software design is an art. It’ s not a science, and it doesn’ t come with a\nset of easy and clear answers.  Too often the big picture of design eludes us,\nand we are overwhelmed by the complex interdependencies of software\nentities. But we are trying to deal with this complexity and reduce it by\nintroducing the right kind of abstractions. This way , we keep the level of\ndetail at a reasonable level. However , too often individual developers on the\nteam may have a dif ferent idea of the architecture and the design. W e might\nnot be able to implement our own vision of a design and be forced to make\ncompromises in order to move forward.\nTIP\nThe term abstraction  is used in dif ferent contexts. It’ s used for the or ganization of\nfunctionality and data items into data types and functions. But it’ s also used to describe\nthe modeling of common behavior and the representation of a set of requirements and\nexpectations. In this book on software design, I will primarily use the term for the latter\n(see in particular Chapter 2 ).5\n6\n7",8373
08-The Three Levels of Software Development.pdf,08-The Three Levels of Software Development,"Note that the words architectur e and design  can be interchanged in the\npreceding quotes, since they’re very similar and share the same goals. Y et\nthey aren’ t the same. The similarities, but also dif ferences, become clear if\nyou take a look at the three levels of software development.\nThe Three Levels of Software Development\nSoftwar e Architectur e and Softwar e Design  are just two of the three levels\nof software development. They are complemented by the level of\nImplementation Details . Figure 1-1  gives an overview of these three levels.\nTo give you a feeling for these three levels, let’ s start with a real-world\nexample of the relationship among architecture, design, and implementation\ndetails. Consider yourself to be in the role of an architect. And no, please\ndon’t picture yourself in a comfy chair in front of a computer with a hot\ncoffee next to you, but picture yourself outside at a construction site. Y es,\nI’m talking about an architect for buildings.  As such an architect, you\nwould be in char ge of all the important properties of a house: its integration\ninto the neighborhood, its structural integrity , the arrangement of rooms,\nplumbing, etc. Y ou would also take care of a pleasing appearance and\nfunctional qualities—perhaps a lar ge living room, easy access between the\nkitchen and the dining room, and so on. In other words, you would be\ntaking care of the overall architecture , the things that would be hard to\nchange later , but you would also deal with the smaller design aspects\nconcerning the building. However , it’s hard to tell the dif ference between\nthe two: the boundary between architecture and design appears to be fluid\nand is not clearly separated.8\nFigur e 1-1. The thr ee levels of softwar e development: Softwar e Architectur e, Softwar e Design , and\nImplementation Details . Idioms  can be design or implementation patterns.\nThese decisions would be the end of your responsibility , however . As an\narchitect, you wouldn’ t worry about where to place the refrigerator , the TV ,\nor other furniture. Y ou wouldn’ t deal with all the nifty details about where\nto place pictures and other pieces of decoration. In other words, you\nwouldn’ t handle the details; you would just make sure that the homeowner\nhas the necessary structure to live well.\nThe furniture and other “nifty details” in this metaphor correspond to the\nlowest and most concrete level of software development, the\nimplementation details. This level handles how a solution is implemented.\nYou choose the necessary (and available) C++ standard or any subset of it,\nas well as the appropriate features, keywords, and language specifics to use,\nand deal with aspects such as memory acquisition, exception safety ,\nperformance, etc. This  is also the level of implementation patterns , such as\nstd::make_unique() as a factory function , std::enable_if as a\nrecurring solution to explicitly benefit from  SFINAE, etc.\nIn software design, you start to focus on the big picture. Questions about\nmaintainability , changeability , extensibility , testability , and scalability are\nmore pronounced on this level. Software design primarily deals with the\ninteraction of software entities, which in the previous metaphor are\nrepresented by the arrangement of rooms, doors, pipes, and cables. At this\nlevel, you handle the physical and logical dependencies of components\n(classes, function, etc.).  It’s the level of design patterns such as V isitor ,\nStrategy , and Decorator that define a dependency structure among software\nentities, as explained in Chapter 3 . These patterns, which usually are\ntransferable from language to language, help you break down complex\nthings into digestible pieces.\nSoftwar e Architectur e is the fuzziest of the three levels, the hardest to put\ninto words. This is because there is no common, universally accepted\ndefinition of software architecture. While there may be many dif ferent\nviews on what exactly an architecture is, there is one aspect that everyone\nseems to agree on: architecture usually entails the big decisions, the aspects\nof your software that are among the hardest things to change in the future:\nArchitectur e is the decisions that you wish you could get right early in a\nproject, but that you ar e not necessarily mor e likely to get them right than\nany other .\n—Ralph Johnson\nIn Software Architecture, you use  architectural patterns such  as client-\nserver ar chitectur e, microservices , and so on.  These patterns also deal9\n10\n1 1\n12\nwith the question of how to design systems, where you can change one part\nwithout af fecting any other parts of your software. Similar to Softwar e\ndesign  patterns, they define and address the structure and interdependencies\namong software entities. In contrast to design patterns, though, they usually\ndeal with the key players, the big entities of your software (e.g., modules\nand components instead of classes and functions).\nFrom this perspective, Software Architecture represents the overall strategy\nof your software approach, whereas Software Design is the tactics to make\nthe strategy work. The problem with this picture is that there is no\ndefinition of “big.” Especially with the advent of microservices, it becomes\nmore and more dif ficult to draw a clear line between small and big\nentities.\nThus, architecture is often described as what expert developers in a project\nperceive as the key decisions.\nWhat  makes the separation between architecture, design, and details a little\nmore dif ficult is the concept of an idiom . An idiom  is a commonly used but\nlanguage-specific solution for a recurring problem. As such, an idiom also\nrepresents a pattern, but it could be either an implementation pattern  or a\ndesign pattern . More loosely speaking, C++ idioms are the best practices\nof the C++ community for either design or implementation. In C++, most\nidioms fall into the category of implementation details. For instance, there\nis the copy-and-swap idiom  that you may know from the implementation of\na copy assignment operator , and the  RAII idiom  (Resource  Acquisition Is\nInitialization—you should definitely be familiar with this; if not, please see\nyour second-favorite C++ book ). None of these idioms introduce an\nabstraction, and none of them help to decouple. Still, they are indispensable\nto implement good C++ code.\nI hear you ask, “Could you be a little more specific, please? Isn’ t RAII also\nproviding some form of decoupling? Doesn’ t it decouple resource\nmanagement from business logic?” Y ou’re correct: RAII separates resource\nmanagement and business logic. However , it doesn’ t achieve this by means\nof decoupling, i.e., abstraction, but by means of encapsulation. Both13\n14\n15",6818
09-An Example of Artificial Coupling.pdf,09-An Example of Artificial Coupling,"abstraction and encapsulation help you make complex systems easier to\nunderstand and change, but while abstraction solves the problems and\nissues that arise at the Software Design level, encapsulation solves the\nproblems and issues that arise at the Implementation Details level. T o quote\nWikipedia :\nThe advantages of RAII as a r esour ce management technique ar e that it\nprovides encapsulation, exception safety […], and locality […].\nEncapsulation is pr ovided because r esour ce management logic is defined\nonce in the class, not at each call site.\nWhile most idioms fall into the category of Implementation Details, there\nare also idioms that fall into the category of Software Design. T wo\nexamples are the Non-V irtual Interface (NVI) idiom  and the Pimpl idiom .\nThese two idioms are based on two classic design patterns: the  Template\nMethod  design pattern and the Bridge  design pattern , respectively . They\nintroduce an abstraction and help decouple and design for change and\nextensions.\nThe Focus on Features\nIf software architecture and software design are of such importance, then\nwhy are we in the C++ community focusing so strongly on features? Why\ndo we create the illusion that C++ standards, language mechanics, and\nfeatures are decisive for a project? I think there are three strong reasons for\nthat. First, because there are so many features, with sometimes complex\ndetails, we need to spend a lot of time talking about how to use all of them\nproperly . We need to create a common understanding on which use is good\nand which use is bad. W e as a community need to develop a sense of\nidiomatic C++.\nThe second reason is that we might put the wrong expectations on features.\nAs an example, let’ s consider C++20 modules. W ithout going into details,\nthis feature may indeed be considered the biggest technical revolution since\nthe beginning of C++. Modules may at last put the questionable and\ncumbersome practice of including header files into source files to an end.16\nDue to this potential, the expectations for that feature are enormous. Some\npeople even expect modules to save their project by fixing their structural\nissues. Unfortunately , modules will have a hard time satisfying these\nexpectations: modules don’ t improve the structure or design of your code\nbut can merely represent the current structure and design. Modules don’ t\nrepair your design issues, but they may be able to make the flaws visible.\nThus, modules simply cannot save your project. So indeed, we may be\nputting too many or the wrong expectations on features.\nAnd last, but not least, the third reason is that despite the huge amount of\nfeatures and their complexity , in comparison to the complexity of software\ndesign, the complexity of C++ features is small. It’ s much easier to explain\na given set of rules for features, regardless of how many special cases they\ncontain, than it is to explain the best way to decouple software entities.\nWhile there is usually a good answer to all feature-related questions, the\ncommon answer in software design is “It depends.” That answer might not\neven be evidence of inexperience, but of the realization that the best way to\nmake code more maintainable, changeable, extensible, testable, and\nscalable heavily depends on many project-specific factors. The decoupling\nof the complex interplay between many entities may indeed be one of the\nmost challenging endeavors that mankind has ever faced:\nDesign and pr ogramming ar e human activities; for get that and all is\nlost.\nTo me, a combination of these three reasons is why we focus on features so\nmuch. But please, don’ t get me wrong. That’ s not to say that features are\nnot important. On the contrary , features are important. And yes, it’ s\nnecessary to talk about features and learn how to use them correctly , but\nonce again, they alone do not save your project.\nThe Focus on Software Design and Design Principles\nWhile  features are important, and while it is of course good to talk about\nthem, software design is more important. Software design is essential. I\nwould even ar gue that it’ s the foundation of the success of our projects.17\nTherefore, in this book I will make the attempt to truly focus on software\ndesign and design principles instead of features. Of course I will still show\ngood and up-to-date C++ code, but I won’ t force the use of the latest and\ngreatest language additions.  I will make use of some new features when it\nis reasonable and beneficial, such as C++20 concepts, but I will not pay\nattention to noexcept, or use constexpr everywhere.  Instead I will try to\ntackle the dif ficult aspects of software. I will, for the most part, focus on\nsoftware design, the rationale behind design decisions, design principles,\nmanaging dependencies, and dealing with abstractions.\nIn summary , software design is the critical part of writing software.\nSoftware developers should have a good understanding of software design\nto write good, maintainable software. Because after all, good software is\nlow-cost, and bad software is expensive.\nGUIDELINE 1: UNDERSTAND THE IMPORTANCE OF\nSOFTWARE DESIGN\nTreat software design as an essential part of writing software.\nFocus less on C++ language details and more on software design.\nAvoid unnecessary coupling and dependencies to make software\nmore adaptable to frequent changes.\nUnderstand software design as the art of managing dependencies\nand abstractions .\nConsider the boundary between software design and software\narchitecture as fluid.\nGuideline 2: Design for Change\nOne of the essential expectations for good software is its ability to change\neasily . This expectation is even part of the word software. Software, in18\n19\ncontrast to hardware, is expected to be able to adapt easily to changing\nrequirements (see also “Guideline 1: Understand the Importance of\nSoftware Design ”). However , from your own experience you may be able to\ntell that often it is not easy to change code. On the contrary , sometimes a\nseemingly simple change turns out to be a week-long endeavor .\nSeparation of Concerns\nOne of the best and proven solutions to reduce artificial dependencies and\nsimplify change is to separate concerns. The core of the idea is to split,\nsegregate, or extract pieces of functionality:\nSystems that ar e broken up into small, well-named, understandable\npieces enable faster work.\nThe intent behind separation of concerns is to better understand and manage\ncomplexity and thus design more modular software. This idea is probably as\nold as software itself and hence has been given many dif ferent names. For\ninstance, the same idea is called  orthogonality  by the Pragmatic\nProgrammers.  They advise separating orthogonal aspects of software.\nTom DeMarco  calls it cohesion :\nCohesion is a measur e of the str ength of association of the elements\ninside a module. A highly cohesive module is a collection of statements\nand data items that should be tr eated as a whole because they ar e so\nclosely r elated. Any attempt to divide them up would only r esult in\nincreased coupling and decr eased r eadability .\nIn the SOLID  principles,  one of the most established sets of design\nprinciples, the idea is known as the  Single-Responsibility Principle (SRP) :\nA class should have only one r eason to change.\nAlthough the concept is old and is commonly known under many names,\nmany attempts to explain separation of concerns raise more questions than\nanswers. This is particularly true for the SRP . The name of this design\nprinciple alone raises questions: what is a responsibility? And what is a20\n21\n22\n23\n24\nsingle  responsibility? A common attempt to clarify the vagueness about\nSRP is the following:\nEverything should do just one thing.\nUnfortunately this explanation is hard to outdo in terms of vagueness. Just\nas the word responsibility  doesn’ t carry a lot of meaning, just one thing\ndoesn’ t help to shed any more light on it.\nIrrespective of the name, the idea is always the same: group only those\nthings that truly belong together , and separate everything that does not\nstrictly belong. Or in other words: separate those things that change for\ndifferent reasons. By doing this, you reduce  artificial coupling between\ndifferent aspects of your code and it helps you make your software more\nadaptable to change. In the best case, you can change a particular aspect of\nyour software in exactly one place.\nAn Example of Artificial Coupling\nLet’s shed some light on separation of concerns by means of a code\nexample. And I do have a great example indeed: I present to you the\nabstract Document class:\n \n//#include <some_json_library.h>  // Potential physical dependency \n \nclass Document \n{ \n public: \n   // ... \n   virtual ~Document() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0;  \n \n   virtual void serialize( ByteStream&, /*...*/ ) const = 0;  \n \n   // ... \n}; \nThis sounds like a very useful base class for all kinds of documents, doesn’ t\nit? First, there is the exportToJSON() function (\n ). All deriving classes will\nhave to implement the exportToJSON() function in order to produce a\nJSON file  from the document. That will prove to be pretty useful: without\nhaving to know about a particular kind of document (and we can imagine\nthat we will eventually have PDF documents, W ord documents, and many\nmore), we can always export in JSON format. Nice! Second, there is a\nserialize() function (\n ). This function lets you transform a Document\ninto bytes via a ByteStream. You can store these bytes in some persistent\nsystem, like a file or a database. And of course we can expect that there are\nmany other , useful functions available that will allow us to pretty much use\nthis document for everything.\nHowever , I can see the frown on your face. No, you don’ t look particularly\nconvinced that this is good software design. It may be because you’re just\nvery suspicious about this example (it simply looks too good to be true). Or\nit may be that you’ve learned the hard way that this kind of design\neventually leads to trouble. Y ou may have experienced that using the\ncommon object-oriented design principle to bundle the data and the\nfunctions that operate on them may easily lead to unfortunate coupling. And\nI agree: despite the fact that this base class looks like a great all-in-one\npackage, and even looks like it has everything that we might ever need, this\ndesign will soon lead to trouble.\nThis is bad design because it contains many dependencies. Of course there\nare the obvious, direct dependencies, as for instance the dependency on the\nByteStream class. However , this design also favors the introduction of\nartificial dependencies, which will make subsequent changes harder . In this\ncase, there are three kinds of artificial dependencies. T wo of these are\nintroduced by the exportToJSON() function, and one by the serialize()\nfunction.\nFirst, exportToJSON() needs to be implemented in the derived classes.\nAnd yes, there is no choice, because it is a pure virtual function  (denoted by\nthe sequence = 0, the so-called pure specifier ). Since derived classes will\nvery likely not want to carry the burden of implementing JSON exports\nmanually , they will rely on an external, third-party JSON library: json,\nrapidjson , or simdjson . Whatever library you choose for that purpose,\nbecause of the exportToJSON() member function, deriving documents\nwould suddenly depend on this library . And, very likely , all deriving classes\nwould depend on the same library , for consistency reasons alone. Thus, the\nderiving classes are not really independent; they are artificially coupled to a\nparticular design decision.  Also, the dependency on a specific JSON\nlibrary would definitely limit the reusability of the hierarchy , because it\nwould no longer be lightweight. And switching to another library would\ncause a major change because all deriving classes would have to be\nadapted.\nOf course, the same kind of artificial dependency is introduced by the\nserialize() function. It’ s likely that serialize() will also be\nimplemented in terms of a third-party library , such as protobuf  or\nBoost.serialization . This considerably worsens the dependency situation\nbecause it introduces a coupling between two orthogonal, unrelated design\naspects (i.e., JSON export and serialization). A change to one aspect might\nresult in changes to the other aspect.\nIn the worst case, the exportToJSON() function might introduce a second\ndependency . The ar guments expected in the exportToJSON() call might\naccidentally reflect some of the implementation details of the chosen JSON\nlibrary . In that case, eventually switching to another library might result in a\nchange of the signature of the exportToJSON() function, which would\nsubsequently cause changes in all callers. Thus, the dependency on the\nchosen JSON library might accidentally be far more widespread than\nintended.\nThe third kind of dependency is introduced by the serialize() function.\nDue to this function, the classes deriving from Document depend on global\ndecisions on how documents are serialized. What format do we use? Do we\nuse little endian or big endian? Do we have to add the information that the\nbytes represent a PDF file or a W ord file? If yes (and I assume that is very\nlikely), how do we represent such a document? By means of an integral\nvalue? For instance, we could use an enumeration for this purpose:\nenum class DocumentType \n{ \n   pdf, 25\n26\n27\n   word, \n   // ... Potentially many more document types \n};\nThis approach is very common for serialization. However , if this low-level\ndocument representation is used within the implementations of the\nDocument classes, we would accidentally couple all the dif ferent kinds of\ndocuments. Every deriving class would implicitly know about all the other\nDocument types. As a result, adding a new kind of document would directly\naffect all existing document types. That would be a serious design flaw ,\nsince, again, it will make change harder .\nUnfortunately , the Document class promotes many dif ferent kinds of\ncoupling. So no, the Document class is not a great example of good class\ndesign, since it isn’ t easy to change. On the contrary , it is hard to change\nand thus a great example of a violation of the SRP: the classes deriving\nfrom Document and users of the Document class change for many reasons\nbecause we have created a strong coupling between several orthogonal,\nunrelated aspects. T o summarize, deriving classes and users of documents\nmay change for any of the following reasons:\nThe implementation details of the exportToJSON() function change\nbecause of a direct dependency on the used JSON library\nThe signature of the exportToJSON() function changes because the\nunderlying implementation changes\nThe Document class and the serialize() function change because of\na direct dependency on the ByteStream class\nThe implementation details of the serialize() function change\nbecause of a direct dependency on the implementation details\nAll types of documents change because of the direct dependency on\nthe DocumentType enumeration\nObviously , this design promotes more changes, and every single change\nwould be harder . And of course, in the general case, there is the danger that",15490
10-Logical Versus Physical Coupling.pdf,10-Logical Versus Physical Coupling,"additional orthogonal aspects are artificially coupled inside documents,\nwhich would further increase the complexity of making a change. In\naddition, some of these changes are definitely not restricted to a single place\nin the codebase. In particular , changes to the implementation details of\nexportToJSON() and serialize() would not be restricted to only one\nclass, but likely all kinds of documents (PDF , Word, and so on). Therefore,\na change would af fect a significant number of places all over the codebase,\nwhich poses a maintenance risk.\nLogical V ersus Physical Coupling\nThe coupling isn’ t limited to logical coupling but also extends to physical\ncoupling. Figure 1-2  illustrates that coupling. Let’ s assume that there is a\nUser class on the low level of our architecture that needs to use documents\nthat reside on a higher level of the architecture. Of course the User class\ndepends directly on the Document class, which is a necessary dependency—\nan intrinsic dependency of the given problem. Thus, it should not be a\nconcern for us. However , the (potential) physical dependency of Document\non the selected JSON library and the direct dependency on the ByteStream\nclass cause an indirect, transitive dependency of User to the JSON library\nand ByteStream, which reside on the highest level of our architecture. In\nthe worst case, this means that changes to the JSON library or the\nByteStream class have an ef fect on User. Hopefully it’ s easy to see that\nthis is an artificial, not an intentional, dependency: a User shouldn’ t have to\ndepend on JSON or serialization.\nNOTE\nI should explicitly state that there is a potential  physical dependency of Document on the\nselect JSON library . If the <Document.h> header file includes any header from the\nJSON library of choice (as indicated in the code snippet at the beginning of “An\nExample of Artificial Coupling” ), for instance because the exportToJSON() function\nexpects some ar guments based on that library , then there is a clear dependency on that\nlibrary . However , if the interface can properly abstract from these details and the\n<Document.h> header doesn’ t include anything from the JSON library , the physical\ndependency might be avoided. Thus, it depends on how well the dependencies can be\n(and are) abstracted.\nFigur e 1-2. The str ong transitive, physical coupling between User and orthogonal aspects like JSON\nand serialization.\n“High level, low level—now I’m confused,” you complain. Y es, I know that\nthese two terms usually cause some confusion. So before we move on, let’ s\nagree on the terminology for high level and low level. The  origin of these\ntwo terms relates to the way we draw diagrams in the Unified Modeling\nLanguage (UML) : functionality that we consider to be stable appears on the\ntop, on a high level. Functionality that changes more often and is therefore\nconsidered to be volatile or malleable appears on the bottom, the low level.\nUnfortunately , when we draw architectures, we often try to show how\nthings build on one another , so the most stable parts appear at the bottom of\nan architecture. That, of course, causes some confusion. Independent of\nhow things are drawn, just remember these terms: high level  refers to stable\nparts of your architecture, and low level  refers to the aspects that change\nmore often or are more likely to change.\nBack to the problem: the SRP advises that we should separate concerns and\nthe things that do not truly belong, i.e., the noncohesive (adhesive) things.\nIn other words, it advises us to separate the things that change for dif ferent\nreasons into variation points . Figure 1-3  shows the coupling situation if we\nisolate the JSON and serialization aspects into separate concerns.\nFigur e 1-3. Adher ence to the SRP resolves the artificial coupling between User and JSON and\nserialization.\nBased on this advice, the Document class is refactored in the following way:\nclass Document \n{ \n public: \n   // ... \n   virtual ~Document() = default; \n \n   // No more 'exportToJSON()' and 'serialize()' functions. \n   // Only the very basic document operations, that do not \n   // cause strong coupling, remain. \n   // ... \n};\nThe JSON and serialization aspects are just not part of the fundamental\npieces of functionality of a Document class. The Document class should\nmerely represent the very basic operations of dif ferent kinds of documents.\nAll orthogonal aspects should be separated. This will make changes\nconsiderably easier . For instance, by isolating the JSON aspect into a\nseparate variation point and into the new JSON component, switching from\none JSON library to another will af fect only this one component. The\nchange could be done in exactly one place and would happen in isolation\nfrom all the other , orthogonal aspects. It would also be easier to support the\nJSON format by means of several JSON libraries. Additionally , any change\nto how documents are serialized would af fect only one component in the\ncode: the new Serialization component. Also, Serialization would\nact as a variation point that enables isolated, easy change. That would be the\noptimal situation.\nAfter your initial disappointment with the Document example, I can see\nyou’re looking happier again. Perhaps there’ s even an “I knew it!” smile on\nyour face. However , you’re not entirely satisfied yet: “Y es, I agree with the\ngeneral idea of separating concerns. But how do I have to structure my\nsoftware to separate concerns? What do I have to do to make it work?” That\nis an excellent question, but one with many answers that I’ll address in the\nupcoming chapters. The first and most important point, however , is the\nidentification of a variation point, i.e., some aspect in your code where\nchanges are expected. These variation points should be extracted, isolated,\nand wrapped, such that there are no longer any dependencies on these\nvariations. That will ultimately help make changes easier .\n“But that is still only superficial advice!” I hear you say . And you’re\ncorrect. Unfortunately , there is no single answer and there is no simple\nanswer . It depends. But I promise to give many concrete answers for how to",6248
11-Dont Repeat Yourself.pdf,11-Dont Repeat Yourself,"separate concerns in the upcoming chapters. After all, this is a book on\nsoftware design, i.e., a book on managing dependencies. As a little teaser , in\nChapter 3  I will introduce a general and practical approach to this problem:\ndesign patterns. W ith this general idea in mind, I will show you how to\nseparate concerns using dif ferent design patterns. For instance, the Visitor ,\nStrategy , and External Polymorphism  design patterns come to mind. All of\nthese patterns have dif ferent strengths and weaknesses, but they share the\nproperty of introducing some kind of abstraction to help you to reduce\ndependencies. Additionally , I promise to take a close look at how to\nimplement these design patterns in modern C++.\nTIP\nI will introduce the V isitor design pattern in “Guideline 16: Use V isitor to Extend\nOperations” , and the Strategy design pattern in “Guideline 19: Use Strategy to Isolate\nHow Things Are Done” . The External Polymorphism design pattern will be the topic of\n“Guideline 31: Use External Polymorphism for Nonintrusive Runtime Polymorphism” .\nDon’t Repeat Y ourself\nThere  is a second, important aspect to changeability . To explain this aspect,\nI will introduce another example: a hierarchy of items. Figure 1-4  gives an\nimpression of this hierarchy .\nFigur e 1-4. The Item class hierar chy.\nAt the top of that hierarchy is the Item base class:\n//---- <Money.h> ---------------- \n \nclass Money { /*...*/ }; \n \nMoney operator*( Money money, double factor ); \nMoney operator+( Money lhs, Money rhs ); \n \n \n//---- <Item.h> ---------------- \n \n#include <Money.h> \n \nclass Item \n{ \n public: \n   virtual ~Item() = default; \n   virtual Money price() const = 0; \n};\nThe Item base class represents an abstraction for any kind of item that has a\nprice tag (represented by the Money class). Via the price() function, you\ncan query for that price. Of course there are many possible items, but for\nillustration purposes, we restrict ourselves to CppBook and\nConferenceTicket:\n \n//---- <CppBook.h> ---------------- \n \n#include <Item.h> \n#include <Money.h> \n#include <string> \n \nclass CppBook : public Item \n{ \n public: \n   explicit CppBook( std::string title, std::string author, Money price )  \n \n      : title_( std::move(title) ) \n      , author_( std::move(author) ) \n      , priceWithTax_( price * 1.15 )  // 15% tax rate \n   {} \n \n   std::string const& title() const { return title_; }     \n \n   std::string const& author() const { return author_; }   \n \n \n   Money price() const override { return priceWithTax_; }  \n \n \n private: \n   std::string title_; \n   std::string author_; \n   Money priceWithTax_; \n}; \nThe constructor of the CppBook class expects a title and author in the form\nof strings and a price in the form of Money (\n). Apart from that, it only\nallows you to access the title, the author , and the price with the title(),\nauthor(), and price() functions (\n , \n, and \n ). However , the price()\nfunction is a little special: obviously , books are subject to taxes. Therefore,\nthe original price of the book needs to be adapted according to a given tax\nrate. In this example, I assume an imaginary tax rate of 15%.\nThe ConferenceTicket class is the second example of an Item:28\n \n//---- <ConferenceTicket.h> ---------------- \n \n#include <Item.h> \n#include <Money.h> \n#include <string> \n \nclass ConferenceTicket : public Item \n{ \n public: \n   explicit ConferenceTicket( std::string name, Money price )  \n \n      : name_( std::move(name) ) \n      , priceWithTax_( price * 1.15 )  // 15% tax rate \n   {} \n \n   std::string const& name() const { return name_; } \n \n   Money price() const override { return priceWithTax_; } \n \n private: \n   std::string name_; \n   Money priceWithTax_; \n}; \nConferenceTicket is very similar to the CppBook class, but expects only\nthe name of the conference and the price in the constructor (\n ). Of course,\nyou can access the name and the price with the name() and price()\nfunctions, respectively . Most importantly , however , the price for a C++\nconference is also subject to taxes. Therefore, we again adapt the original\nprice according to the imaginary tax rate of 15%.\nWith this functionality available, we can go ahead and create a couple of\nItems in the main() function:\n#include <CppBook.h> \n#include <ConferenceTicket.h> \n#include <algorithm> \n#include <cstdlib> \n#include <memory> \n#include <vector> \n \nint main() \n{ \n   std::vector<std::unique_ptr<Item>> items{}; \n \n   items.emplace_back( std::make_unique<CppBook>(""Effective C++"", 19.99) ); \n   items.emplace_back( std::make_unique<CppBook>(""C++ Templates"", 49.99) ); \n   items.emplace_back( std::make_unique<ConferenceTicket>(""CppCon"", 999.0) ); \n   items.emplace_back( std::make_unique<ConferenceTicket>(""Meeting C++"", \n699.0) ); \n   items.emplace_back( std::make_unique<ConferenceTicket>(""C++ on Sea"", 499.0) \n); \n \n   Money const total_price = \n      std::accumulate( begin(items), end(items), Money{}, \n         []( Money accu, auto const& item ){ \n            return accu + item->price(); \n         } ); \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\nIn main(), we create a couple of items (two books and three conferences)\nand compute the total price of all items.  The total price will, of course,\ninclude the imaginary tax rate of 15%.\nThat sounds like a good design. W e have separated the specific kinds of\nitems and are able to change how the price of each item is computed in\nisolation. It seems that we have fulfilled the SRP and extracted and isolated\nthe variation points. And of course, there are more items. Many more. And\nall of them will make sure that the applicable tax rate is properly taken into\naccount. Great! Now , while this Item hierarchy will make us happy for\nsome time, the design unfortunately has a significant flaw . We might not\nrealize it today , but there’ s always a looming shadow in the distance, the\nnemesis of problems in software: change.\nWhat happens if for some reason the tax rate changes? What if the 15% tax\nrate is lowered to 12%? Or raised to 16%? I can still hear the ar guments\nfrom the day the initial design was committed into the codebase: “No, that\nwill never happen!” Well, even the most unexpected thing may happen. For\ninstance, in Germany , the tax rate was lowered from 19% to 16% for half a\nyear in 2021. This, of course, would mean that we have to change the tax\nrate in our codebase. Where do we apply the change? In the current29",6577
12-Avoid Premature Separation of Concerns.pdf,12-Avoid Premature Separation of Concerns,"situation, the change would pretty much af fect every class deriving from the\nItem class. The change would be all over the codebase!\nJust as much as the SRP advises separating variation points, we should take\ncare not to duplicate information throughout the codebase. As much as\neverything should have a single responsibility (a single reason to change),\nevery responsibility should exist only once in the system. This idea is\ncommonly called the Don’ t Repeat Y ourself  (DR Y) principle. This principle\nadvises us to not duplicate some key information in many places—but to\ndesign the system such that we can make the change in only one place. In\nthe optimal case, the tax rate(s) should be represented in exactly one place\nto enable you to make an easy change.\nUsually the SRP and the DR Y principles work together very nicely .\nAdhering the SRP will often lead to adhering to DR Y as well, and vice\nversa. However , sometimes adhering to both requires some extra steps. I\nknow you’re eager to learn what these extra steps are and how to solve the\nproblem, but at this point, it’ s sufficient to point out the general idea of SRP\nand DR Y. I promise to revisit this problem and to show you how to solve it\n(see “Guideline 35: Use Decorators to Add Customization Hierarchically” ).\nAvoid Premature Separation of Concerns\nAt this point, I’ve hopefully convinced you that adhering to SRP and DR Y\nis a very reasonable idea. Y ou might even be so committed that you plan to\nseparate everything—all classes and functions—into the most tiny units of\nfunctionality . After all, that’ s the goal, right? If this is what you’re thinking\nright now , please stop! T ake a deep breath. And one more. And then please\nlisten carefully to the wisdom of Katerina T rajchevska:\nDon’ t try to achieve SOLID, use SOLID to achieve maintainability .\nBoth SRP and DR Y are your tools for achieving better maintainability and\nsimplifying change. They are not your goals. While both are of utmost\nimportance in the long run, it can be very counterproductive to separate\nentities without a clear idea about what kind of change will af fect you.\nDesigning for change usually favors one specific kind of change but might30\nunfortunately make other kinds of change harder . This  philosophy is part of\nthe commonly known YAGNI  principle  (You Aren’ t Gonna Need It), which\nwarns you about overengineering (see also “Guideline 5: Design for\nExtension” ). If you have a clear plan, if you know what kind of change to\nexpect, then apply SRP and DR Y to make that kind of change simple.\nHowever , if you don’ t know what kind of change to expect, then don’ t\nguess—just  wait. W ait until you have a clear idea about what kind of\nchange to expect and then refactor to make the change as easy as possible.\nTIP\nJust don’ t forget that one aspect of easily changing things is having  unit tests in place\nthat give you confirmation that the change did not break the expected behavior .\nIn summary , change is expected in software and therefore it’ s vital to design\nfor change. Separate concerns and minimize duplication to enable you to\neasily change things without being afraid to break other , orthogonal aspects.",3228
13-Segregate Interfaces to Separate Concerns.pdf,13-Segregate Interfaces to Separate Concerns,"GUIDELINE 2: DESIGN FOR CHANGE\nExpect change in software.\nDesign for easy change and make software more adaptable.\nAvoid combining unrelated, orthogonal aspects to prevent\ncoupling.\nUnderstand that coupling increases the likelihood for change and\nmakes changes harder .\nAdhere to the Single-Responsibility Principle (SRP) to separate\nconcerns.\nFollow the Don’ t Repeat Y ourself (DR Y) principle to minimize\nduplication.\nAvoid premature abstraction if you are not sure about the next\nchange.\nGuideline 3: Separate Interfaces to Avoid\nArtificial Coupling\nLet’s revisit the Document example from “Guideline 2: Design for Change” .\nI know , by now you probably feel like you’ve seen enough documents, but\nbelieve me, we’re not done yet. There’ s still an important coupling aspect to\naddress. This time we don’ t focus on the individual functions in the\nDocument class but on the interface as a whole:\nclass Document \n{ \n public: \n   // ... \n   virtual ~Document() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0; \n   virtual void serialize( ByteStream& bs, /*...*/ ) const = 0; \n   // ... \n};\nSegregate Interfaces to Separate Concerns\nThe Document requires deriving classes to handle both JSON exports and\nserialization. While, from the point of view of a document, this may seem\nreasonable (after all, all documents should be exportable into JSON and\nserializable), it unfortunately causes another kind of coupling. Imagine the\nfollowing user code:\nvoid exportDocument( Document const& doc ) \n{ \n   // ... \n   doc.exportToJSON( /* pass necessary arguments */ ); \n   // ... \n}\nThe exportDocument() function is solely interested in exporting a given\ndocument to JSON. In other words, the exportDocument() function is not\nconcerned with serializing a document or with any other aspect that\nDocument has to of fer. Still, as a result of the definition of the Document\ninterface, due to coupling many orthogonal aspects together , the\nexportDocument() function depends on much more than just the JSON\nexport. All of these dependencies are unnecessary and artificial. Changing\nany of these—for instance, the ByteStream class or the signature of the\nserialize() function—has an ef fect on all users of Document, even those\nthat do not require serialization. For any change, all the users, including the\nexportDocument() function, would need to be recompiled, retested, and, in\nthe worst case, redeployed (for instance, if delivered in a separate library).\nThe same thing happens, however , if the Document class is extended by\nanother function—for instance, an export to another document type. The\nproblem gets bigger the more orthogonal functionality is coupled in\nDocument: any change carries the risk of causing a rippling ef fect\nthroughout the codebase. Which is sad indeed, as interfaces should help to\ndecouple, not introduce artificial coupling.\nThis coupling is caused by a violation of the Interface Segregation Principle\n(ISP), which is the I in the SOLID  acronym:\nClients should not be for ced to depend on methods that they do not use.\nThe ISP advises separating concerns by segregating (decoupling) interfaces.\nIn our case, there should be two separate interfaces representing the two\northogonal aspects of JSON export and serialization:\nclass JSONExportable \n{ \n public: \n   // ... \n   virtual ~JSONExportable() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0; \n   // ... \n}; \n \nclass Serializable \n{ \n public: \n   // ... \n   virtual ~Serializable() = default; \n \n   virtual void serialize( ByteStream& bs, /*...*/ ) const = 0; \n   // ... \n}; \n \nclass Document \n   : public JSONExportable \n   , public Serializable \n{ \n public: \n   // ... \n};\nThis separation does not make the Document class obsolete. On the\ncontrary , the Document class still represents the requirements posed on all\ndocuments. However , this separation of concerns now enables you to\nminimize dependencies to only the set of functions that is actually required:31",4069
14-Minimizing Requirements of Template Arguments.pdf,14-Minimizing Requirements of Template Arguments,"void exportDocument( JSONExportable const& exportable ) \n{ \n   // ... \n   exportable.exportToJSON( /* pass necessary arguments */ ); \n   // ... \n}\nIn this form, by depending only on the segregated JSONExportable\ninterface, the exportDocument() function no longer depends on the\nserialization functionality and thus no longer depends on the ByteStream\nclass. Thus, the segregation of interfaces has helped to reduce coupling.\n“But isn’ t that just a separation of concerns?” you ask. “Isn’ t that just\nanother example of the SRP?” Y es, indeed it is. I agree that we’ve\nessentially identified two orthogonal aspects, separated them, and thus\napplied the SRP to the Document interface. Therefore, we could say that\nISP and SRP are the same. Or at least that ISP is a special case of the SRP\nbecause of the focus of the ISP on interfaces. This attitude seems to be the\ncommon opinion in the community , and I agree. However , I still consider it\nvaluable  to talk about ISP . Despite the fact that ISP may only be a special\ncase, I would ar gue that it’ s an important special case. Unfortunately , it is\noften very tempting to aggregate unrelated, orthogonal aspects into an\ninterface. It might even happen to you that you couple separate aspects into\nan interface. Of course, I would never imply that you did this on purpose,\nbut unintentionally , accidentally . We often do not pay enough attention to\nthese details. Of course, you ar gue, “I would never do that.” However , in\n“Guideline 19: Use Strategy to Isolate How Things Are Done” , you’ll see\nan example that might convince you how easily this can happen. Since\nchanging interfaces later may be extremely dif ficult, I believe it pays of f to\nraise awareness of this problem with interfaces. For that reason, I didn’ t\ndrop the ISP but included it as an important and noteworthy case of the\nSRP.\nMinimizing Requirements of T emplate Arguments\nAlthough  it appears as if the ISP is applicable only to base classes, and\nalthough the ISP is mostly introduced by means of object-oriented\nprogramming, the general idea of minimizing the dependencies introduced\nby interfaces can also be applied to templates. Consider the std::copy()\nfunction, for instance:\ntemplate< typename InputIt, typename OutputIt > \nOutputIt copy( InputIt first, InputIt last, OutputIt d_first );\nIn C++20, we could apply concepts  to express the requirements:\ntemplate< std::input_iterator InputIt, std::output_iterator OutputIt > \nOutputIt copy( InputIt first, InputIt last, OutputIt d_first );\nstd::copy() expects a pair of input iterators as the range to copy from,\nand an output iterator to the tar get range. It explicitly requires input iterators\nand output iterators, since it does not need any other operation. Thus, it\nminimizes the requirements on the passed ar guments.\nLet’s assume that std::copy() requires std::forward_iterator instead\nof std::input_iterator and std::output_iterator:\ntemplate< std::forward_iterator ForwardIt, std::forward_iterator ForwardIt > \nOutputIt copy( ForwardIt first, ForwardIt last, ForwardIt d_first );\nThis would unfortunately limit the usefulness of the std::copy()\nalgorithm. W e would no longer be able to copy from input streams, since\nthey don’ t generally provide the multipass guarantee and do not enable us to\nwrite. That would be unfortunate. However , focusing on dependencies,\nstd::copy() would now depend on operations and requirements it doesn’ t\nneed. And iterators passed to std::copy() would be forced to provide\nadditional operations, so std::copy() would force dependencies on them.\nThis is only a hypothetical example, but it illustrates how important the\nseparation of concerns in interfaces is. Obviously , the solution is the\nrealization that input and output capabilities are separate aspects. Thus, after\nseparating concerns and after applying the ISP , the dependencies are\nsignificantly reduced.",3953
15-How to Test a Private Member Function.pdf,15-How to Test a Private Member Function,"GUIDELINE 3: SEPARATE INTERFACES TO AVOID\nARTIFICIAL COUPLING\nBe aware that coupling also af fects interfaces.\nAdhere to the Interface Segregation Principle (ISP) to separate\nconcerns in interfaces .\nConsider the ISP as a special case of the Single-Responsibility\nPrinciple (SRP).\nUnderstand that the ISP helps for both inheritance hierarchies and\ntemplates.\nGuideline 4: Design for Testability\nAs discussed in “Guideline 1: Understand the Importance of Software\nDesign ”, software changes. It’ s expected to change. But every time you\nchange something in your software, you run the risk of breaking something.\nOf course, not intentionally but accidentally , despite your best ef forts. The\nrisk is always there. As an experienced developer , however , you don’ t lose\nany sleep over that. Let there be risk—you  don’ t care. Y ou have something\nthat protects you from accidentally breaking things, something that keeps\nthe risk at a minimum: your tests.\nThe purpose of having tests is to be able to assert that all of your software\nfunctionality still works, despite constantly changing things. So obviously ,\ntests are your protection layer , your life vest. T ests are essential! However ,\nfirst of all, you have to write the tests. And in order to write tests and set up\nthis protective layer , your software needs to be testable: your software must\nbe written in a way that it is possible, and in the best case even easily\npossible, to add tests. Which brings us to the heart of this guideline:\nsoftware should be designed for testability .\nHow to T est a Private Member Function\n“Of course I have tests,” you ar gue. “Everyone should have tests. That’ s\ncommon knowledge, isn’ t it?” I completely agree. And I believe you that\nyour codebase is equipped with a reasonable test suite.  But surprisingly ,\ndespite everyone agreeing to the need for tests, not every piece of software\nis written with this awareness in mind.  In fact, a lot of code is hard to test.\nAnd sometimes this is simply because the code is not designed to be tested.\nTo give you an idea, I have a challenge for you. T ake a look at the following\nWidget class. Widget holds a collection of Blob objects, which once in a\nwhile need to be updated. For that purpose, Widget provides the\nupdateCollection() member function, which we now assume is so\nimportant that we need to write a test for it. And this is my challenge: how\nwould you test the updateCollection() member function?\nclass Widget \n{ \n   // ... \n private: \n   void updateCollection( /* some arguments needed to update the collection */ \n); \n \n   std::vector<Blob> blobs_; \n   /* Potentially other data members */ \n};\nI assume that you immediately see the real challenge: the\nupdateCollection() member function is declared in the private section of\nthe class. This means that there is no direct access from the outside and\ntherefore no direct way of testing it. So take a few seconds to think about\nthis…\n“It’s private, yes, but this is still not much of a challenge. There are multiple\nways I can do that,” you say . I agree, there are multiple ways you could try .\nSo please, go ahead. Y ou weigh your options, then you come up with your\nfirst idea: “W ell, the easiest approach would be to test the function via some\nother , public member function that internally calls the\nupdateCollection() function.” That sounds like an interesting first idea.32\n33\nLet’s assume that the collection needs to be updated when a new Blob is\nadded to it. Calling the addBlob() member function would trigger the\nupdateCollection() function:\nclass Widget \n{ \n public: \n   // ... \n   void addBlob( Blob const& blob, /*...*/ ) \n   { \n      // ... \n      updateCollection( /*...*/ ); \n      // ... \n   } \n \n private: \n   void updateCollection( /* some arguments needed to update the collection */ \n); \n \n   std::vector<Blob> blobs_; \n   /* Potentially other data members */ \n};\nAlthough this sounds like a reasonable thing to do, it’ s also something you\nshould avoid if possible. What  you are suggesting is a so-called white box\ntest. A white box test knows about the internal implementation details of\nsome function and tests based on that knowledge. This introduces a\ndependency of the test code on the implementation details of your\nproduction code. The problem with this approach is that software changes.\nCode changes. Details change. For instance, at some point in the future, the\naddBlob() function might be rewritten so it does not have to update the\ncollection anymore. If this happens, your test no longer performs the task it\nwas written to do. Y ou would lose your updateCollection() test,\npotentially without even realizing it. Therefore, a white box test poses a\nrisk. Just as much as you should avoid and reduce dependencies in your\nproduction code (see “Guideline 1: Understand the Importance of Software\nDesign ”), you should also avoid dependencies between your tests and the\ndetails of your production code.\nWhat  we really need is a black box test . A black box test does not make any\nassumptions about internal implementation details, but tests only for\nexpected behavior . Of course, this kind of test can also break if you change\nsomething, but it shouldn’ t break if some implementation details change—\nonly if the expected behavior changes.\n“OK, I get your point,” you say . “But you don’ t suggest making the update \nCol lec tion() function public, do you?” No, rest assured that isn’ t what\nI’m suggesting. Of course, sometimes this may be a reasonable approach.\nBut in our case, I doubt that this would be a wise move. The\nupdateCollection() function should not be called just for fun. It should\nbe called only for a good reason, only at the right time, and probably to\npreserve some kind of invariant. This is something we should not entrust a\nuser with. So no, I don’ t think that the function would be a good candidate\nfor the public section.\n“OK, good, just checking. Then let’ s simply make the test a friend of the\nWidget class. This way it would have full access and could call the\nprivate member function unhindered”:\nclass Widget \n{ \n   // ... \n private: \n   friend class TestWidget; \n \n   void updateCollection( /* some arguments needed to update the collection */ \n); \n \n   std::vector<Blob> blobs_; \n   /* Potentially other data members */ \n};\nYes, we could add a friend. Let’ s assume that there is the TestWidget test\nfixture, containing all the tests for the Widget class. W e could make this test\nfixture a friend of the Widget class. Although this may sound like another\nreasonable approach, I unfortunately have to be the spoilsport again. Y es,\ntechnically this would solve the problem, but from a design perspective,\nwe’ve just introduced an artificial dependency again. By actively changing\nthe production code to introduce the friend declaration, the production\ncode now knows about the test code. And while the test code should of\ncourse know about the production code (that’ s the point of the test code),\nthe production code should not have to know about the test code. This\nintroduces a cyclic dependency , which is an unfortunate and artificial\ndependency .\n“You sound like this is the worst thing in the world. Is it really that bad?”\nWell, sometimes this may actually be a reasonable solution. It definitely is a\nsimple and quick solution. However , since right now we have the time to\ndiscuss all of our options, there definitely must be something better than\nadding a friend.\nNOTE\nI don’ t want to make things worse, but in C++ we don’ t have a lot of friends. Yes, I\nknow , this sounds sad and lonely , but of course I mean the keyword friend: in C++,\nfriend is not your friend. The reason is that friends introduce coupling, mostly\nartificial coupling, and we should avoid coupling. Of course, exceptions can be made for\nthe good friends, the ones you cannot live without, such as hidden friends , or idiomatic\nuses of friend, such as the Passkey idiom . A test is more like a friend on social media,\nso declaring a test a friend does not sound like a good choice.\n“OK, then let’ s switch from private to protected and make the test\nderive from the Widget class,” you suggest. “This way , the test would gain\nfull access to the updateCollection() function”:\nclass Widget \n{ \n   // ... \n protected: \n   void updateCollection( /* some arguments needed to update the collection */ \n); \n \n   std::vector<Blob> blobs_; \n   /* Potentially other data members */ \n}; \n \nclass TestWidget : private Widget \n{ \n   // ... \n};\nWell, I have to admit that technically this approach would work. However ,\nthe fact that you’re suggesting inheritance to solve this issue tells me that\nwe definitely have to talk about the meaning of inheritance and how to use\nit properly . To quote the two pragmatic programmers:\nInheritance is rar ely the answer .\nSince we’ll be focusing on this topic fairly soon, let me just say that it feels\nlike we’re abusing inheritance for the sole reason of gaining access to\nnonpublic member functions . I’m pretty certain this isn’ t why inheritance\nwas invented. Using inheritance to gain access to the protected section of\na class is like the bazooka approach to something that should be very\nsimple. It is, after all, almost identical to making the function public,\nbecause everyone can easily gain access. It seems we really haven’ t\ndesigned the class to be easily testable.\n“Come on, what else could we do? Or do you really want me to use the\npreprocessor and define all private labels as public?”:\n#define private public \n \nclass Widget \n{ \n   // ... \n private: \n   void updateCollection( /* some arguments needed to update the collection */ \n); \n \n   std::vector<Blob> blobs_; \n   /* Potentially other data members */ \n};\nOK, let’ s take a deep breath. Although this last approach may seem funny ,\nkeep in mind that we have now left the range of reasonable ar guments.  If34\n35",10072
16-The True Solution Separate Concerns.pdf,16-The True Solution Separate Concerns,"we seriously consider using the preprocessor to hack our way into the\nprivate section of the Widget class, then all is lost.\nThe T rue Solution: Separate Concerns\n“OK  then, what should  I do to test the private member function? Y ou have\nalready discarded all the options.” No, not all the options. W e have not yet\ndiscussed the one design approach that I highlighted in “Guideline 2:\nDesign for Change” : separation of concerns. My approach would be to\nextract the private member function from the class and make it a separate\nentity in our codebase. My preferred solution in this case is to extract the\nmember function as a free function:\nvoid updateCollection( std::vector<Blob>& blobs \n                     , /* some arguments needed to update the collection */ ); \n \nclass Widget \n{ \n   // ... \n private: \n   std::vector<Blob> blobs_; \n   /* Potentially other data members */ \n};\nAll calls to the previous member function could be replaced with a call to\nthe free updateCollection() function by just adding blobs_ as the first\nfunction ar gument. Alternatively , if there is some state attached to the\nfunction, we extract it in the form of another class. Either way , we design\nthe resulting code such that it’ s easy , perhaps even trivial, to test:\nnamespace widgetDetails { \n \nclass BlobCollection \n{ \n public: \n   void updateCollection( /* some arguments needed to update the collection */ \n); \n \n private: \n   std::vector<Blob> blobs_; \n}; \n \n} // namespace widgetDetails \n \nclass Widget \n{ \n   // ... \n private: \n   widgetDetails::BlobCollection blobs_; \n   /* Other data members */ \n};\n“You cannot be serious!” you exclaim. “Isn’ t this the worst of all options?\nAren’ t we artificially separating two things that belong together? And isn’ t\nthe SRP telling us that we should keep the things that belong together close\nto one another?” W ell, I don’ t think so. On the contrary , I firmly believe that\nonly now are we adhering to the SRP: the SRP states that we should isolate\nthe things that do not belong together , the things that can change for\ndifferent reasons. Admittedly , at first sight, it may appear as if Widget and\nupdateCollection() belong together , since after all, the blob_ data\nmember needs to be updated once in a while. However , the fact that the\nupdate Col lection() function isn’ t properly testable is a clear indication\nthat the design does not fit yet: if anything that needs explicit testing can’ t\nbe tested, something is amiss. Why make our lives so much harder and hide\nthe function to test in the private section of the Widget class? Since\ntesting plays a vital role in the presence of change, testing represents just\nanother way to help decide which things belong together . If the\nupdateCollection() function is important enough that we want to test it\nin isolation, then apparently it changes for a reason other than Widget. This\nindicates that Widget and updateCollection() do not belong together .\nBased on the SRP , the updateCollection() function should be extracted\nfrom the class.\n“But isn’ t this against the idea of encapsulation?” you ask. “And don’ t you\ndare wave away encapsulation. I consider encapsulation to be very\nimportant!” I agree, it is very important, fundamentally so! However ,\nencapsulation  is just one more reason to separate concerns. As Scott Meyers\nclaims in his book, Effective C++ , extracting functions  from a class is a\nstep toward increasing encapsulation. According to Meyers, you should\ngenerally prefer nonmember non- friend functions to member functions. \nThis is because every member function has full access to every member of a\nclass, even the private members. However , in the extracted form, the\nupdateCollection() function is restricted to just the public interface of\nthe Widget class and is not able to access the private members. Therefore,\nthese private members become a little more encapsulated. Note that the\nsame ar gument holds true for extracting the BlobCollection class: the\nBlobCollection class is not able to touch the nonpublic members of the\nWidget class, and therefore Widget also becomes a little more\nencapsulated.\nBy separating concerns and extracting this piece of functionality , you now\ngain several advantages. First, as just discussed, the Widget class becomes\nmore encapsulated. Fewer members can access the private members.\nSecond, the extracted update Col lection() function is easily , even\ntrivially , testable. Y ou don’ t even need a Widget for that but instead can\neither pass std::vector<Blob> as the first ar gument (not the implicit first\nargument of any member function, the this pointer) or call the public\nmember function. Third, you don’ t have to change any other aspect in the\nWidget class: you simply pass the blobs_ member to the\nupdateCollection() function whenever you need to update the collection.\nNo need to add any other public getter . And, probably most importantly ,\nyou can now change the function in isolation, without having to deal with\nWidget. This indicates that you have reduced dependencies. While in the\ninitial setup the updateCollection() function was tightly coupled to the\nWidget class (yes, the this pointer), we have now severed these ties. The\nupdateCollection() function is now a separate service that might even be\nreused.\nI can see that you still have questions. Maybe you’re concerned that this\nmeans you shouldn’ t have any member functions anymore. No, to be clear ,\nI did not suggest that you should extract each and every member function\nfrom your classes. I merely suggested you take a closer look at those\nfunctions that need to be tested but are placed in the private section of36",5758
17-Guideline 5 Design for Extension.pdf,17-Guideline 5 Design for Extension,,0
18-The Open-Closed Principle.pdf,18-The Open-Closed Principle,"your class. Also, you might wonder how this works with virtual functions,\nwhich cannot be extracted in the form of a free function. W ell, there’ s no\nquick answer for that, but it’ s something that we will deal with in many\ndifferent ways throughout this book. My objective will always be to reduce\ncoupling and to increase testability , even by separating virtual functions.\nIn summary , do not hinder your design and testability with artificial\ncoupling and artificial boundaries. Design for testability . Separate concerns.\nFree your functions!\nGUIDELINE 4: DESIGN FOR TESTABILITY\nUnderstand that tests are your protection layer against accidentally\nbreaking things.\nKeep in mind that tests are essential, and so is testability .\nSeparate concerns for the sake of testability .\nConsider private member functions that need testing to be\nmisplaced.\nPrefer nonmember non- friend functions to member functions.\nGuideline 5: Design for Extension\nThere  is an important aspect about changing software that I haven’ t\nhighlighted yet: extensibility . Extensibility should be one of the primary\ngoals of your design. Because, frankly speaking, if you’re no longer able to\nadd new functionality to your code then your code has reached the end of\nits lifetime. Thus, adding new functionality—extending the codebase—is of\nfundamental interest. For that reason, extensibility should indeed be one of\nyour primary goals and a driving factor for good software design.\nThe Open-Closed Principle\nDesign  for extension is unfortunately not something that just falls into your\nlap or magically materializes. No, you will have to explicitly take\nextensibility into account when designing software. W e’ve already seen an\nexample of a naive approach of serializing documents in “Guideline 2:\nDesign for Change” . In that context, we used a Document base class with a\npure virtual serialize() function:\nclass Document \n{ \n public: \n   // ... \n   virtual ~Document() = default; \n \n   virtual void serialize( ByteStream& bs, /*...*/ ) const = 0; \n   // ... \n};\nSince serialize() is a pure virtual function, it needs to be implemented\nby all deriving classes, including the PDF class:\nclass PDF : public Document \n{ \n public: \n   // ... \n   void serialize( ByteStream& bs, /*...*/ ) const override; \n   // ... \n};\nSo far , so good. The interesting question is: how do we implement the\nserialize() member function? One requirement is that at a later point in\ntime we are able to convert the bytes back into a PDF instance (we want to\ndeserialize bytes back to a PDF). For that purpose, it is essential to store the\ninformation that the bytes represent. In “Guideline 2: Design for Change” ,\nwe accomplished this with an enumeration:\nenum class DocumentType \n{ \n   pdf, \n   word, \n   // ... Potentially many more document types \n};\nThis enumeration can now be used by all derived classes to put the type of\nthe document at the beginning of the byte stream. This way , during\ndeserialization, it’ s easy to detect which kind of document is stored. Sadly ,\nthis design choice turns out to be an unfortunate decision. With that\nenumeration, we have accidentally coupled all kinds of document: the PDF\nclass knows about the W ord format. And of course the corresponding Word\nclass would know about the PDF format. Y es, you are correct—they don’ t\nknow about the implementation details, but they are still aware of each\nother .\nThis coupling situation is illustrated in Figure 1-5 . From an architectural\npoint of view , the DocumentType enumeration resides on the same level as\nthe PDF and Word classes. Both types of documents use (and thus depend\non) the DocumentType enumeration.\nFigur e 1-5. Artificial coupling of differ ent document types via the DocumentType enumeration .\nThe problem with this becomes obvious if we try to extend the\nfunctionality . Next to PDF and W ord, we now also want to support a plain\nXML format. Ideally , all we should have to do is add the XML class as\nderiving from the Document class. But, unfortunately , we also have to adapt\nthe DocumentType enumeration:\nenum class DocumentType \n{ \n   pdf, \n   word, \n   xml,   // The new type of document \n   // ... Potentially many more document types \n};\nThis change will at least cause all the other document types (PDF , Word,\netc.) to recompile. Now you may just shrug your shoulders and think, “Oh\nwell! It just needs to recompile.” W ell, note that I said at least . In the worst\ncase, this design has significantly limited others to extend the code—i.e., to\nadd new kinds of documents—because not everyone is able to extend the\nDocumentType enumeration. No, this kind of coupling just doesn’ t feel\nright: PDF and Word should be entirely unaware of the new XML format.\nThey shouldn’ t see or feel a thing, not even a recompilation.\nThe problem in this example can be explained as a violation of the Open-\nClosed Principle (OCP). The OCP is the second of the SOLID principles. It\nadvises us to design software such that it is easy to make the necessary\nextensions:\nSoftwar e artifacts (classes, modules, functions, etc.) should be open for\nextension, but closed for modification.\nThe OCP tells us that we should be able to extend our software (open for\nextension). However , the extension should be easy and, in the best case,\npossible by just adding new code. In other words, we shouldn’ t have to\nmodify existing code (closed for modification).\nIn theory , the extension should be easy: we should only have to add the new\nderived class XML. This new class alone would not require any37\nmodifications in any other piece of code. Unfortunately , the serialize()\nfunction artificially couples the dif ferent kinds of documents and requires a\nmodification of the DocumentType enumeration. This modification, in turn,\nhas an impact on the other types of Document, which is exactly what the\nOCP advises against.\nLuckily , we’ve already seen a solution for how to achieve that for the\nDocument example. In this case, the right thing to do is to separate concerns\n(see Figure 1-6 ).\nBy separating concerns, by grouping the things that truly belong together ,\nthe accidental coupling between dif ferent kinds of documents is gone. All\ncode dealing with serialization is now properly grouped inside the\nSerialization component, which can logically reside on another level of\nthe architecture. Serialization depends on all types of documents (PDF ,\nWord, XML, etc.), but none of the document types depend on\nSerialization. In addition, none of the documents are aware of any other\ntype of document (as it should be).\nFigur e 1-6. Separation of concerns r esolves the violation of the OCP\n“Wait a second!” you say . “In the code for the serialization, we still need the\nenumeration, don’ t we? How else would I store the information about what\nthe stored bytes represent?” I’m glad you’re making this observation. Y es,\ninside the Serialization component we will still (very likely) need\nsomething like the DocumentType enumeration. However , by separating\nconcerns, we have properly resolved this dependency problem. None of the\ndifferent types of documents depends on the DocumentType enumeration\nanymore. All dependency arrows now go from the low level (the\nSerialization component) to the high level ( PDF and Word). And that\nproperty is essential for a proper , good architecture.\n“But what about adding a new type of document? Doesn’ t that require a\nmodification in the Serialization component?” Again, you are absolutely\ncorrect. Still, this is not a violation of OCP , which advises that we should\nnot have to modify existing code on the same architectural level or on\nhigher levels. However , there is no way you can control or prevent\nmodifications on the lower levels. Serialization must  depend on all types\nof documents and therefore must  be adapted for every new type of\ndocument. For that reason, Serialization must reside on a lower level\n(think depending  level) of our architecture.\nAs also discussed in “Guideline 2: Design for Change” , the solution in this\nexample is the separation of concerns. Thus, it appears as if the real solution\nis to adhere to the SRP . For that reason, there are some critical voices that\ndon’t consider the OCP a separate principle but the same as the SRP . I\nadmit that I understand this reasoning. V ery often the separation of concerns\nalready leads to the desired extensibility . It’s something we will experience\nmultiple times throughout this book, in particular  when we talk about\ndesign patterns. Thus, it stands to reason that SRP and OCP are related or\neven the same.\nOn the other hand, in this example we have seen that there are some\nspecific, architectural considerations about the OCP that we didn’ t take into\naccount while talking about the SRP . Also, as we will experience in\n“Guideline 15: Design for the Addition of Types or Operations ”, we will\noften have to make explicit decisions about what we want to extend and\nhow we want to extend it. That decision can significantly influence how we\napply the SRP and the way we design our software. Therefore, the OCP\nseems to be more about the awareness of extensions and conscious\ndecisions about extensions than the SRP . As such, it is perhaps a little more\nthan just an afterthought of the SRP . Or perhaps it just depends.38",9454
19-Compile-Time Extensibility.pdf,19-Compile-Time Extensibility,"Either way , this example indisputably demonstrates that extensibility should\nbe explicitly considered during software design, and that the desire for\nextending our software in a specific way is an excellent indication for the\nneed to separate concerns. It is important to understand how software will\nbe extended, to identify such  customization points , and to design so that this\nkind of extension can be performed easily .\nCompile-T ime Extensibility\nThe Document example may give the impression that all of these design\nconsiderations apply to runtime polymorphism. No, absolutely not: the\nsame considerations and the same ar guments also apply to compile-time\nproblems. T o illustrate this, I now reach for a couple of examples from the\nStandard Library . Of course, it is of utmost interest that you’re able to\nextend the Standard Library . Yes, you’re supposed to use the Standard\nLibrary , but you are also encouraged to build on it and add your own pieces\nof functionality . For that reason, the Standard Library is designed for\nextensibility . But interestingly , it isn’ t using base classes for that purpose,\nbut primarily builds on function overloading, templates, and (class)\ntemplate specialization.\nAn excellent example of extension by function overloading is the\nstd::swap() algorithm. Since C++1 1, std::swap() has been defined in\nthis way:\nnamespace std { \n \ntemplate< typename T > \nvoid swap( T& a, T& b ) \n{ \n   T tmp( std::move(a) ); \n   a = std::move(b); \n   b = std::move(tmp); \n} \n \n} // namespace std\nDue to the fact that std::swap() is defined as a function template, you can\nuse it for any type: fundamental types like int and double, Standard\nLibrary types like std::string, and, of course, your own types. However ,\nthere may be some types that require special attention, some types that\ncannot or should not be swapped by means of std::swap() (for instance,\nbecause they cannot be ef ficiently moved) but could still be swapped\nefficiently by dif ferent means. But still, it’ s expected that value types can be\nswapped, as it is also expressed by Core Guideline C.83 :\nFor value-like types, consider pr oviding a noexcept swap function.\nIn such a case, you can overload std::swap() for your own type:\nnamespace custom { \n \nclass CustomType \n{ \n   /* Implementation that requires a special form of swap */ \n}; \n \nvoid swap( CustomType& a, CustomType& b ) \n{ \n   /* Special implementation for swapping two instances of type 'CustomType' \n*/ \n} \n \n} // namespace custom\nIf swap() is used correctly , this custom function will perform a special kind\nof swap operation on two instances of CustomType:\ntemplate< typename T > \nvoid some_function( T& value ) \n{ \n   // ... \n   T tmp( /*...*/ ); \n \n   using std::swap;     // Enable the compiler to consider std::swap for the \n                        // subsequent call \n   swap( tmp, value );  // Swap the two values; thanks to the unqualified call \n                        // and thanks to ADL this would call 'custom::swap()' 39\n40\n   // ...               // in case 'T' is 'CustomType' \n}\nObviously , std::swap() is designed as a  customization point , allowing you\nto plug in new custom types and behavior . The same is true of all\nalgorithms in the Standard Library . Consider , for instance, std::find()\nand std::find_if():\ntemplate< typename InputIt, typename T > \nconstexpr InputIt find( InputIt first, InputIt last, T const& value ); \n \ntemplate< typename InputIt, typename UnaryPredicate > \nconstexpr InputIt find_if( InputIt first, InputIt last, UnaryPredicate p );\nBy means of the template parameters, and implicitly , the corresponding\nconcepts, std::find() and std::find_if() (just as all other algorithms)\nenable you to use your own (iterator) types to perform a search. In addition,\nstd::find_if() allows you to customize how the comparison of elements\nis handled. Thus, these functions are definitely designed for extension and\ncustomization.\nThe last kind of customization point  is template specialization. This\napproach is, for instance, used by the std::hash class template. Assuming\nthe CustomType from the std::swap() example, we can specialize\nstd::hash explicitly:\ntemplate<> \nstruct std::hash<CustomType> \n{ \n   std::size_t operator()( CustomType const& v ) const noexcept \n   { \n      return /*...*/; \n   } \n};\nThe design of std::hash puts you in a position to adapt its behavior for\nany custom type. Most noteworthy , you are not required to modify any\nexisting code; it’ s enough to provide this separate specialization to adapt to\nspecial requirements.",4657
20-Avoid Premature Design for Extension.pdf,20-Avoid Premature Design for Extension,"Almost the entire Standard Library is designed for extension and\ncustomization. This shouldn’ t come as a surprise, however , because the\nStandard Library is supposed to represent one of the highest levels in your\narchitecture. Thus, the Standard Library cannot depend on anything in your\ncode, but you depend entirely on the Standard Library .\nAvoid Premature Design for Extension\nThe C++ Standard Library is a great example of designing for extension.\nHopefully it gives you a feeling for how important extensibility really is.\nHowever , although extensibility is important, this doesn’ t mean that you\nshould automatically , without reflection, reach for either base classes or\ntemplates for every possible implementation detail just to guarantee\nextensibility in the future. Just as you shouldn’ t prematurely separate\nconcerns, you should also not prematurely design for extension. Of course,\nif you have a good idea about how your code will evolve, then by all means,\ngo ahead and design it accordingly . However , remember the Y AGNI\nprinciple: if you do not know how the code will evolve, then it may be wise\nto wait, instead of anticipating an extension that will never happen. Perhaps\nthe next extension will give you an idea about future extensions, which puts\nyou in a position to refactor the code such that subsequent extensions are\neasy. Otherwise you might run into the problem that favoring one kind of\nextension makes other kinds of extensions much more dif ficult (see, for\ninstance, “Guideline 15: Design for the Addition of Types or Operations ”).\nThat is something you should avoid, if possible.\nIn summary , designing for extension is an important part of design for\nchange. Therefore, explicitly keep an eye out for pieces of functionality that\nare expected to be extended and design the code so that extension is easy .\nGUIDELINE 5: DESIGN FOR EXTENSION\nFavor design that makes it easy to extend code.\nAdhere to the Open-Closed Principle (OCP) to keep code open for\nextension but closed for modification.\nDesign for code additions by means of base classes, templates,\nfunction overloading, or template specialization.\nAvoid premature abstraction if you are not sure about the next\naddition.\n1 But of course you would never even try to print the current C++ standard. Y ou would either\nuse a PDF of the official C++ standard  or use the current working draft . For most of your daily\nwork, however , you might want to refer to the C++ reference site .\n2 Unfortunately , I can’ t present any numbers, as I can hardly say that I have a complete\noverview of the vast realm of C++. On the contrary , I might not even have a complete\noverview of the sources I’m aware of! So please consider this as my personal impression and\nthe way I perceive the C++ community . You may have a dif ferent impression.\n3 Whether or not the code modification is risky may very much depend on your test coverage.\nA good test coverage may actually absorb some of the damage bad software design may cause.\n4 Kent Beck, Test-Driven Development: By Example  (Addison-W esley , 2002).\n5 Robert C. Martin, Clean Ar chitectur e (Addison-W esley , 2017).\n6 These are indeed my own words, as there is no single, common definition of software design.\nConsequently , you may have your own definition of what software design entails and that is\nperfectly fine. However , note that this book, including the discussion of design patterns, is\nbased on my definition.\n7 Just to be clear: computer science is a science (it’ s in the name). Software engineering\nappears to be a hybrid form of science, craft, and art. And one aspect of the latter is software\ndesign .\n8 With this metaphor , I’m not trying to imply that architects for buildings work at the\nconstruction site all day . Very likely , such an architect spends as much time in a comfy chair\nand in front of a computer as people like you and me. But I think you get the point.\n9 Substitution Failure Is Not An Error (SFINAE) is a basic template mechanism commonly\nused as a substitute for C++20 concepts to constrain templates. For an explanation of SFINAE\nand std::enable_if in particular , refer to your favorite textbook about C++ templates. If you\ndon’t have any , a great choice is the C++ template bible: David V andevoorde, Nicolai Josuttis,\nand Douglas Gregor ’s C++ T emplates: The Complete Guide  (Addison-W esley).\n10 For a lot more information on physical and logical dependency management, see John\nLakos’ s “dam” book, Large-Scale C++ Softwar e Development: Pr ocess and Ar chitectur e\n(Addison-W esley).\n1 1 Martin Fowler , “Who Needs an Architect?” IEEE Softwar e, 20, no. 5 (2003), 1 1–13,\nhttps://doi.or g/10.1 109/MS.2003.1231 144.\n12 A very good introduction to microservices can be found in Sam Newman’ s book Building\nMicr oservices: Designing Fine-Grained Systems , 2nd ed. (O’Reilly).\n13 Mark Richards and Neal Ford, Fundamentals of Softwar e Architectur e: An Engineering\nAppr oach  (O’Reilly , 2020).\n14 The term implementation pattern  was first used in Kent Beck’ s book Implementation Patterns\n(Addison-W esley). In this book, I’m using that term to provide a clear distinction from the\nterm design pattern , since the term idiom  may refer to a pattern on either the Software Design\nlevel or the  Implementation Details level. I will use the term consistently to refer to commonly\nused solutions on the Implementation Details level.\n15 Second-favorite after this one, of course. If this is your only book, then you might refer to the\nclassic Effective C++: 55 Specific W ays to Impr ove Y our Pr ograms and Designs , 3rd ed., by\nScott Meyers (Addison-W esley).\n16 The T emplate Method and Bridge design patterns are 2 of the 23 classic design patterns\nintroduced in the so-called Gang of Four (GoF) book by Erich Gamma et al., Design Patterns:\nElements of Reusable Object-Oriented Softwar e. I won’ t go into detail about the T emplate\nMethod in this book, but you’ll find good explanations in various textbooks, including the GoF\nbook itself. I will, however , explain the Bridge design pattern in “Guideline 28: Build Bridges\nto Remove Physical Dependencies ”.\n17 Bjarne Stroustrup, The C++ Pr ogramming Language , 3rd ed. (Addison-W esley , 2000).\n18 Kudos to John Lakos, who ar gues similarly and uses C++98 in his book, Large-Scale C++\nSoftwar e Development: Pr ocess and Ar chitectur e (Addison-W esley).\n19 Yes, Ben and Jason, you have read correctly , I will not constexpr ALL the things. See Ben\nDeane and Jason T urner , “constexpr ALL the things” , CppCon 2017.\n20 Michael Feathers, Working Effectively with Legacy Code  (Addison-W esley , 2013).\n21 David Thomas and Andrew Hunt, The Pragmatic Pr ogrammer: Y our Journey to Mastery ,\n20th Anniversary Edition (Addison W esley , 2019).\n22 Tom DeMarco, Structur ed Analysis and System Specification  (Prentice Hall, 1979).\n23 SOLID is an acronym of acronyms, an abbreviation of the five principles described in the\nnext few guidelines: SRP , OCP , LSP , ISP, and DIP .\n24 The first book on the SOLID principles was Robert C. Martin’ s Agile Softwar e Development:\nPrinciples, Patterns, and Practices  (Pearson). A newer and much cheaper alternative is Clean\nArchitectur e, also from Robert C. Martin (Addison-W esley).\n25 Don’ t forget that the design decisions taken by that external library may impact your own\ndesign, which would obviously increase the coupling.\n26 That includes the classes that other people may have written, i.e., classes that you do not\ncontrol. And no, the other people won’ t be happy about the change. Thus, the change may be\nreally  difficult.\n27 An enumeration seems to be an obvious choice, but of course there are other options as well.\nIn the end, we need an agreed-upon set of values that represent the dif ferent document formats\nin the byte representation.\n28 You might be wondering about the explicit use of the explicit keyword for this constructor .\nThen you might also be aware that Core Guideline C.46  advises using explicit by default for\nsingle-ar gument constructors. This is really good and highly recommended advice, as it\nprevents unintentional, potentially undesirable conversions. While not as valuable, the same\nadvice is also reasonable for all the other constructors, except for the copy and move\nconstructors, which don’ t perform a conversion. At least it doesn’ t hurt.\n29 You might realize I’ve picked the names of the three conferences I regularly attend: CppCon ,\nMeeting C++ , and C++ on Sea . There are many more C++ conferences, though. T o give a few\nexamples: ACCU , Core C++ , pacific++ , CppNorth , emBO++ , and CPPP . Conferences are a\ngreat and fun way to stay up to date with C++. Make sure to check out the Standard C++\nFoundation home page  for any upcoming conferences.\n30 Katerina T rajchevska, “Becoming a Better Developer by Using the SOLID Design\nPrinciples” , Laracon EU, August 30–31, 2018.\n31 Robert C. Martin, Agile Softwar e Development: Principles, Patterns, and Practices .\n32 If you don’ t have a test suite in place, then you have work to do. Seriously . A very coherent\nreference to get started is Ben Saks’ s talk on unit tests, “Back to Basics: Unit T ests” , from\nCppCon 2020. A second, very good reference to wrap your mind around the whole topic of\ntesting and test-driven development in particular is Jef f Langr ’s book, Modern C{plus}{plus}\nProgramming with T est-Driven Development  (O’Reilly).\n33 I know , “everyone agrees” is unfortunately far from reality . If you need proof that the\nseriousness of tests has not yet reached every project and every developer , take a look at this\nissue  from the OpenFOAM issue tracker .\n34 David Thomas and Andrew Hunt, The Pragmatic Pr ogrammer: Y our Journey to Mastery .\n35 We may even have entered the scary realm of undefined behavior .\n36 You can find this compelling ar gument in item 23 of Scott Meyers’ s Effective C++ .\n37 Bertrand Meyer , Object-Oriented Softwar e Construction , 2nd ed. (Pearson, 2000).\n38 The answer “It depends!” will of course satisfy even the strongest critics of the OCP .\n39 The C++ Core Guidelines  are a community ef fort to collect and agree on a set of guidelines\nfor writing good C++ code. They best represent the common sense of what idiomatic C++ is.\nYou can find these guidelines on GitHub .\n40 The abbreviation ADL refers to Ar gument Dependent Lookup. See the CppReference  or my\nCppCon 2020 talk  for an introduction.",10566
21-Guideline 6 Adhere to the Expected Behavior of Abstractions.pdf,21-Guideline 6 Adhere to the Expected Behavior of Abstractions,"Chapter 2. The Art of Building\nAbstractions\nAbstractions  play a vital role in software design and software architecture.\nIn other words, good abstractions are the key to managing complexity .\nWithout them, good design and proper architecture are hard to imagine.\nStill, building good abstractions and using them well is surprisingly\ndifficult. As it turns out, building and using abstractions comes with a lot of\nsubtleties, and therefore feels more like an art than a science. This chapter\ngoes into detail about the meaning of abstractions and the art of building\nthem.\nIn “Guideline 6: Adhere to the Expected Behavior of Abstractions” , we will\ntalk about the purpose of abstractions. W e will also talk about the fact that\nabstractions represent a set of requirements and expectations and why it is\nso important to adhere to the expected behavior of abstractions. In that\ncontext I will introduce another design principle, the Liskov Substitution\nPrinciple  (LSP).\nIn “Guideline 7: Understand the Similarities Between Base Classes and\nConcepts ”, we will compare the two most commonly used abstractions:\nbase classes and concepts. You will understand that from a semantic point\nof view both approaches are very similar since both are able to express\nexpected behavior .\nIn “Guideline 8: Understand the Semantic Requirements of Overload Sets” ,\nI will extend the discussion about semantic requirements and talk about a\nthird kind of abstraction: function overloading. Y ou will understand that all\nfunctions, being part of an overload set, also have an expected behavior and\nthus also have to adhere to the LSP .\nIn “Guideline 9: Pay Attention to the Ownership of Abstractions” , I will\nfocus on the architectural meaning of abstractions. I will explain what an",1792
22-An Example of Violating Expectations.pdf,22-An Example of Violating Expectations,"architecture is and what we expect from the high and low levels of an\narchitecture. I will also show you that from an architectural point of view , it\nis not enough to just introduce an abstraction to resolve dependencies. T o\nexplain this, I will introduce the Dependency Inversion Principle  (DIP),\nvital advice on how to build an architecture by means of abstractions.\nIn “Guideline 10: Consider Creating an Architectural Document” , we will\ntalk about the benefits of an architectural document. Hopefully , this will be\nan incentive to create one in case this wasn’ t already on your radar .\nGuideline 6: Adhere to the Expected\nBehavior of Abstractions\nOne of the key aspects of decoupling software, and thus one of the key\naspects of software design, is the introduction of abstractions. For that\nreason, you would expect that this is a relatively straightforward, easy thing\nto do. Unfortunately , as it turns out, building abstractions is dif ficult.\nTo demonstrate what I mean, let’ s take a look at an example. I have selected\nthe classic example for that purpose. Chances are, you might already know\nthis example. If so, please feel free to skip it. However , if you’re not\nfamiliar with the example, then this may serve as an eye-opener .\nAn Example of V iolating Expectations\nLet’s start with a Rectangle base class:\n \nclass Rectangle \n{ \n public: \n   // ... \n   virtual ~Rectangle() = default;  \n \n \n   int getWidth() const;  \n \n   int getHeight() const; \n \n   virtual void setWidth(int);  \n \n   virtual void setHeight(int); \n \n   virtual int getArea() const;  \n \n   // ... \n \n private: \n   int width;  \n \n   int height; \n}; \nFirst of all, this class is designed as a base class, since it provides a virtual\ndestructor (\n ). Semantically , a Rectangle represents an abstraction for\ndifferent kinds of rectangles. And technically , you can properly destroy an\nobject of derived type via a pointer to Rectangle.\nSecond, the Rectangle class comes with two data members: width and\nheight (\n). That is to be expected, since a rectangle has two side lengths,\nwhich are represented by width and height. The getWidth() and\ngetHeight() member functions can be used to query the two side lengths (\n), and via the setWidth() and setHeight() member functions, we can\nset the width and height (\n). It’s important to note that I can set these two\nindependently; i.e., I can set the width without having to modify the\nheight.\nFinally , there is a getArea() member function (\n ). getArea() computes\nthe area of the rectangle, which is of course implemented by returning the\nproduct of width and height.\nOf course there may be more functionality , but the given members are the\nones that are important for this example. As it is, this seems to be a pretty\nnice Rectangle class. Obviously , we’re of f to a good start. But, of course\nthere’ s more. For instance, there is the Square class:\n \nclass Square : public Rectangle  \n \n{ \n public: \n   // ... \n   void setWidth(int) override;  \n \n   void setHeight(int) override;  \n \n \n   int getArea() const override;  \n \n   // ... \n}; \nThe Square class publicly inherits from the Rectangle class (\n ). And that\nseems pretty reasonable: from a mathematical perspective, a square appears\nto be a special kind of rectangle.\nA Square is special, in the sense that it has only one side length. But the\nRectangle base class comes with two lengths: width and height. For that\nreason, we have to make sure that the invariants of the Square are always\npreserved. In this given implementation with two data members and two\ngetter functions, we have to make sure that both data members always have\nthe same value. Therefore, we override the setWidth() member function to\nset both width and height (\n). We also override the setHeight() member\nfunction to set both width and height (\n).\nOnce we have done that, a Square will always have equal side lengths, and\nthe getArea() function will always return the correct area of a Square (\n).\nNice!\nLet’s put these two classes to good use. For instance, we could think about a\nfunction that transforms dif ferent kinds of rectangles:\n \nvoid transform( Rectangle& rectangle )  \n \n{ \n   rectangle.setWidth ( 7 );  \n \n   rectangle.setHeight( 4 );  \n \n \n   assert( rectangle.getArea() == 28 );  \n \n \n   // ... \n} \nThe transform() function takes any kind of Rectangle by means of a\nreference to non- const (\n). That’ s reasonable, because we want to change\nthe given rectangle. A first possible way to change the rectangle is to set the\nwidth via the setWidth() member function to 7 (\n). Then we could1\nchange the height of the rectangle to 4 via the setHeight() member\nfunction (\n ).\nAt this point, I would ar gue that you have an implicit assumption. I am\npretty certain that you assume that the area of the rectangle is 28, because,\nof course, 7 times 4 is 28. That is an assumption we can test via an assertion\n(\n).\nThe only thing missing is to actually call the transform() function. That’ s\nwhat we do in the main() function:\n \nint main() \n{ \n   Square s{};  \n \n   s.setWidth( 6 ); \n \n   transform( s );  \n \n \n   return EXIT_SUCCESS; \n} \nIn the main() function, we create a special kind of rectangle: a Square (\n). This square is passed to the transform() function, which of course\nworks, since a reference to a Square can be implicitly converted to a\nreference to a Rectangle (\n).\nIf I were to ask you, “What happens?” I’m pretty sure you would answer ,\n“The assert() fails!” Y es, indeed, the assert() will fail. The expression\npassed to the assert() will evaluate to false, and assert() will crash the\nprocess with a SIGKILL signal. W ell, that’ s certainly unfortunate. So let’ s do\na postmortem analysis: why does the assert() fail? Our expectation in the\ntransform() function is that we can change the width and height of a\nrectangle independently . This expectation is explicitly expressed with the\ntwo function calls to setWidth() and setHeight(). However ,\nunexpectedly , this special kind of rectangle does not allow that: to preserve\nits own invariants, the Square class must always make sure that both side\nlengths are equal. Thus, the Square class has to violate this expectation.\nThis violation of the expectation in an abstraction is a violation of the LSP .2",6405
23-The Liskov Substitution Principle.pdf,23-The Liskov Substitution Principle,"The Liskov Substitution Principle\nThe LSP is the third of the SOLID principles and is concerned with\nbehavioral subtyping , i.e., with the expected behavior of an abstraction.\nThis design principle is named after Barbara Liskov , who initially\nintroduced it in 1988 and clarified it with Jeannette Wing in 1994:\nSubtype Requir ement: Let φ(x) be a pr operty pr ovable about objects x of\ntype T . Then φ(y) should be true for objects y of type S wher e S is a\nsubtype of T .\nThis principle formulates what we commonly call an IS-A relationship. This\nrelationship, i.e., the expectations in an abstraction, must  be adhered to in a\nsubtype. That includes the following properties:\nPreconditions cannot be strengthened in a subtype: a subtype cannot\nexpect more in a function than what the super type expresses. That\nwould violate the expectations in the abstraction:\nstruct X \n{ \n   virtual ~X() = default; \n \n   // Precondition: the function accepts all 'i' greater than 0 \n   virtual void f( int i ) const \n   { \n      assert( i > 0 ); \n      // ... \n   } \n}; \n \nstruct Y : public X \n{ \n   // Precondition: the function accepts all 'i' greater than 10. \n   // This would strengthen the precondition; numbers between 1 and 10 \n   // would no longer be allowed. This is a LSP violation! \n   void f( int i ) const override \n   { \n      assert( i > 10 ); \n      // ... \n   } \n};3\nPostconditions cannot be weakened in a subtype: a subtype cannot\npromise less when leaving a function than the super type promises.\nAgain, that would violate the expectations in the abstraction:\nstruct X \n{ \n   virtual ~X() = default; \n \n   // Postcondition: the function will only return values larger than 0 \n   virtual int f() const \n   { \n      int i; \n      // ... \n      assert( i > 0 ); \n      return i; \n   } \n}; \n \nstruct Y : public X \n{ \n   // Postcondition: the function may return any value. \n   // This would weaken the postcondition; negative numbers and 0 would \n   // be allowed. This is a LSP violation! \n   int f( int i ) const override \n   { \n      int i; \n      // ... \n      return i; \n   } \n};\nFunction return types in a subtype must be  covariant : member\nfunctions of the subtype can return a type that is itself a subtype of the\nreturn type of the corresponding member function in the super type.\nThis property has direct language support in C++. However , the\nsubtype cannot return any super type of the return type of the\ncorresponding function in the super type:\nstruct Base { /*...some virtual functions, including destructor...*/ }; \nstruct Derived : public Base { /*...*/ }; \n \nstruct X \n{ \n   virtual ~X() = default; \n   virtual Base* f(); \n}; \n \nstruct Y : public X \n{ \n   Derived* f() override;  // Covariant return type \n};\nFunction parameters in a subtype must be  contravariant : in a member\nfunction, the subtype can accept a super type of the function parameter\nin the corresponding member function of the super type. This property\ndoes not have direct language support in C++:\nstruct Base { /*...some virtual functions, including destructor...*/ }; \nstruct Derived : public Base { /*...*/ }; \n \nstruct X \n{ \n   virtual ~X() = default; \n   virtual void f( Derived* ); \n}; \n \nstruct Y : public X \n{ \n   void f( Base* ) override;  // Contravariant function parameter; Not \n                              // supported in C++. Therefore the function \n                              // does not override, but fails to compile. \n};\nInvariants of the super type must be preserved in a subtype: any\nexpectation about the state of a super type must always be valid before\nand after all calls to any member function, including the member\nfunctions of the subtype:\nstruct X \n{ \n   explicit X( int v = 1 ) \n      : value_(v) \n   { \n      if( v < 1 || v > 10 ) throw std::invalid_argument( /*...*/ ); \n   } \n \n   virtual ~X() = default; \n \n   int get() const { return value_; } \n \n protected: \n   int value_;  // Invariant: must be within the range [1..10] \n}; \n \nstruct Y : public X \n{ \n public: \n   Y() \n      : X() \n   { \n      value_ = 11;  // Broken invariant: After the constructor, 'value_' \n                    // is out of expected range. One good reason to \n                    // properly encapsulate invariants and to follow \n                    // Core Guideline C.133: Avoid protected data. \n   } \n};\nIn our example, the expectation in a Rectangle is that we can change the\ntwo side lengths independently , or, more formally , that the result of\ngetWidth() does not change after setHeight() is called. This expectation\nis intuitive for any kind of rectangle. However , the Square class itself\nintroduces the invariant that all sides must always be equal, or else the\nSquare would not properly express our idea of a square. But by protecting\nits own invariants, the Square unfortunately violates the expectations in the\nbase class. Thus, the Square class doesn’ t fulfill the expectations in the\nRectangle class, and the hierarchy in this example doesn’ t express an IS-A\nrelationship. Therefore, a Square cannot be used in all the places a\nRectangle is expected.\n“But isn’ t a square a rectangle?” you ask. “Isn’ t that properly expressing the\ngeometrical relation?”  Yes, there may be a geometrical relation between\nsquares and rectangles, but in this example the inheritance relationship is\nbroken. This example demonstrates that the mathematical IS-A relationship\nis indeed dif ferent from the LSP IS-A  relationship. While in geometry a\nsquare is always a rectangle, in computer science it really depends on the\nactual interface and thus the expectations. As long as there are the two4",5756
24-Guideline 7 Understand the Similarities Between Base Classes and Concepts.pdf,24-Guideline 7 Understand the Similarities Between Base Classes and Concepts,"independent setWidth() and setHeight() functions, a Square will\nalways violate the expectations. “I understand,” you say . “Nobody would\nclaim that, geometrically , a square is still a square after changing its width,\nright?” Exactly .\nThe example also demonstrates that inheritance is not a natural or intuitive\nfeature, but a hard feature. As stated in the beginning, building abstractions\nis hard. Whenever you use inheritance, you must  make sure that all\nexpectations in the base class are fulfilled and that the derived type behaves\nas expected.\nCriticism of the Liskov Substitution Principle\nSome people ar gue that the LSP , as explained earlier , is in fact not what is\ndescribed in the conference paper “Data Abstraction and Hierarchy” by\nBarbara Liskov and that the notion of subtyping is flawed. And that is\ncorrect: we usually do not substitute derived objects for base objects, but we\nuse a derived object as a base object. However , this literal and strict\ninterpretation of Liskov’ s statements does not play any role in the kinds of\nabstractions that we build on a daily basis. In their 1994 paper “A\nBehavioral Notion of Subtyping,” Barbara Liskov and Jeannette W ing\nproposed the term  behavioral subtyping , which is the common\nunderstanding of the LSP  today .\nOther people ar gue that because of potential violations of the LSP , a base\nclass does not serve the purpose of an abstraction. The rationale is that\nusing code would also depend on the (mis-)behavior of derived types. This\nargument unfortunately turns the world upside down. A base class does\nrepresent an abstraction, because calling code can and should only and\nexclusively depend on the expected  behavior of this abstraction. It’ s that\ndependency that makes LSP violations programming errors. Unfortunately ,\nsometimes people try to fix LSP violations by introducing special\nworkarounds:\nclass Base { /*...*/ }; \nclass Derived : public Base { /*...*/ }; \nclass Special : public Base { /*...*/ }; \n// ... Potentially more derived classes \n \nvoid f( Base const& b ) \n{ \n   if( dynamic_cast<Special const*>(&b) ) \n   { \n      // ... do something ""special,"" knowing that 'Special' behaves \ndifferently \n   } \n   else \n   { \n      // ... do the expected thing \n   } \n}\nThis kind of workaround will indeed introduce a dependency in the\nbehavior of the derived types. And a very unfortunate dependency , indeed!\nThis should always be considered an LSP violation and very bad practice.\nIt doesn’ t serve as a general ar gument against the abstracting properties of a\nbase class.\nThe Need for Good and Meaningful Abstractions\nTo properly decouple software entities, it is fundamentally important that\nwe can count on our abstractions. W ithout meaningful abstractions that we,\nthe human readers of code, fully understand, we cannot write robust and\nreliable software. Therefore, adherence to the LSP is essential for the\npurpose of software design. However , a vital part is also the clear and\nunambiguous communication of the expectations of an abstraction. In the\nbest case, this happens by means of software itself  (self-documenting code ),\nbut it also entails a proper documentation of abstractions. As a good\nexample, I recommend the iterator concepts documentation  in the C++\nstandard, which clearly lists the expected behavior , including pre- and post-\nconditions.5\nGUIDELINE 6: ADHERE TO THE EXPECTED BEHAVIOR\nOF ABSTRACTIONS\nUnderstand that an abstraction represents a set of requirements and\nexpectations .\nFollow the Liskov Substitution Principle (LSP) to adhere to the\nexpected behavior of abstractions.\nMake sure that derived classes adhere to the expected behavior of\ntheir base classes.\nCommunicate the expectations of an abstraction.\nGuideline 7: Understand the Similarities\nBetween Base Classes and Concepts\nIn “Guideline 6: Adhere to the Expected Behavior of Abstractions” , I may\nhave created the impression that the LSP is concerned only with inheritance\nhierarchies and base classes. T o make sure that this impression doesn’ t\nstick, allow me to explicitly state that the LSP is not limited to dynamic\n(runtime) polymorphism and inheritance hierarchies. On the contrary , we\ncan apply the LSP just as well to static (compile-time) polymorphism and\ntemplated code.\nTo make the point, let me ask you a question: what’ s the dif ference between\nthe following two code snippets?\n//==== Code Snippet 1 ==== \n \nclass Document \n{ \n public: \n   // ... \n   virtual ~Document() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0; \n   virtual void serialize( ByteStream&, /*...*/ ) const = 0; \n   // ... \n}; \n \nvoid useDocument( Document const& doc ) \n{ \n   // ... \n   doc.exportToJSON( /*...*/ ); \n   // ... \n} \n \n \n//==== Code Snippet 2 ==== \n \ntemplate< typename T > \nconcept Document = \n   requires( T t, ByteStream b ) { \n      t.exportToJSON( /*...*/ ); \n      t.serialize( b, /*...*/ ); \n   }; \n \ntemplate< Document T > \nvoid useDocument( T const& doc ) \n{ \n   // ... \n   doc.exportToJSON( /*...*/ ); \n   // ... \n}\nI’m pretty sure your first answer is that the first code snippet shows a\nsolution using  dynamic polymorphism, and the second one shows  static\npolymorphism. Y es, great! What else? OK, yes, of course, the syntax is\ndifferent, too. OK, I see, I should ask my question a little more precisely: in\nwhich way do these two solutions dif fer semantically ?\nWell, if you think about it, then you might find that from a semantic point\nof view the two solutions are very similar indeed. In the first code snippet,\nthe useDocument() function works only with classes derived from the\nDocument base class. Thus, we can say that the function works only with\nclasses adhering to the expectations of the Document abstraction. In the\nsecond code snippet, the use Docu ment() function works only with classes\nthat implement the Document concept. In other words, the function works\nonly with classes adhering to the expectations of the Document abstraction.\nIf you now have the feeling of déjà vu, then my choice of words hopefully\nstruck a chord. Y es, in both code snippets, the useDocument() function\nworks only with classes adhering to the expectations of the Document\nabstraction. So despite the fact that the first code snippet is based on a\nruntime abstraction and the second function represents a compile-time\nabstraction, these two functions are very similar from a semantic point of\nview .\nBoth the base class and the concept represent a set of requirements\n(syntactic requirements, but also semantic requirements). As such, both\nrepresent a formal description of the expected behavior and thus are the\nmeans to express and communicate expectations for calling code. Thus,\nconcepts can be considered the equivalent, the static counterpart, of base\nclasses. And from this point of view , it makes perfect sense to also consider\nthe LSP for template code.\n“I’m not buying that,” you say . “I’ve heard that C++20 concepts cannot\nexpress semantics!”  Well, to this I can only respond with a definitive yes\nand no. Y es, C++20  concepts cannot fully express semantics, that’ s correct.\nBut on the other hand, concepts still express expected behavior . Consider ,\nfor instance, the C++20 form of the std::copy() algorithm:\ntemplate< typename InputIt, typename OutputIt > \nconstexpr OutputIt copy( InputIt first, InputIt last, OutputIt d_first ) \n{ \n   while( first != last ) { \n      *d_first++ = *first++; \n   } \n   return d_first; \n}\nThe std::copy() algorithm expects three ar guments. The  first two\narguments represent the range of elements that need to be copied (the input\nrange ). The third ar gument represents the first element we need to copy to6\n7\n(the output range ). A general expectation is that the output range  is big\nenough that all the elements from the input range  can be copied to it.\nThere are more expectations that are implicitly expressed via the names for\nthe iterator types: InputIt and OutputIt. InputIt represents a type of\ninput iterator . The C++ standard states all the expectations of such iterator\ntypes, such as the availability of an (in-)equality comparison, the ability to\ntraverse a range with a prefix and postfix increment ( operator++() and\noperator++(int)), and the ability to access elements with the dereference\noperator ( operator*()). OutputIt, on the other hand, represents  a type of\noutput iterator . Here, the C++ standard also explicitly states all expected\noperations.\nInputIt and OutputIt may not be C++20 concepts, but they represent the\nsame idea: these named template parameters don’ t just give you an idea\nabout what kind of type is required; they also express expected behavior .\nFor instance, we expect that subsequent increments of first will\neventually yield last. If any given concrete iterator type does not behave\nthis way , std::copy() will not work as expected. This would be a\nviolation of the expected behavior , and as such, a violation of the LSP .\nTherefore, both InputIt and OutputIt represent LSP abstractions.\nNote that since concepts represent an LSP abstraction, i.e., a set of\nrequirements and expectations, they are subject to the Interface Segr egation\nPrinciple  (ISP) as well (see “Guideline 3: Separate Interfaces to A void\nArtificial Coupling ”). Just as you should separate concerns in the definition\nof requirements in the form of base classes (say , “interface” classes), you\nshould separate concerns when defining a concept. The Standard Library\niterators do that by building on one another , thus allowing you to select the\ndesired level of requirements:\ntemplate< typename I > \nconcept input_or_output_iterator = \n  /* ... */; \n \ntemplate< typename I > \nconcept input_iterator = \n   std::input_or_output_iterator<I> && 8\n   /* ... */; \n \ntemplate< typename I > \nconcept forward_iterator = \n   std::input_iterator<I> && \n   /* ... */;\nSince both named template parameters and C++20 concepts serve the same\npurpose and since both represent LSP abstractions, from now on, in all\nsubsequent guidelines, I will use the term concept  to refer to both of them.\nThus, with the term concept , I will refer to any way to represent a set of\nrequirements (in most cases for template ar guments, but sometimes even\nmore generally). If I want to refer to either of these two specifically , I will\nmake it explicitly clear .\nIn summary , any kind of abstraction (dynamic and static) represents a set of\nrequirements with that expected behavior . These expectations need to be\nfulfilled by concrete implementations. Thus, the LSP clearly represents\nessential guidance for all kinds of IS-A relationships.\nGUIDELINE 7: UNDERSTAND THE SIMILARITIES\nBETWEEN BASE CLASSES AND CONCEPTS\nApply the Liskov Substitution Principle (LSP) to both dynamic\nand static polymorphism.\nConsider concepts (both the C++20 feature and pre-C++20 named\ntemplate ar guments) as the static equivalent of base classes.\nAdhere to the expected behavior of concepts when using\ntemplates.\nCommunicate the expectations of a concept (in particular for pre-\nC++20 named template ar guments).",11273
25-Guideline 8 Understand the Semantic Requirements of Overload Sets.pdf,25-Guideline 8 Understand the Semantic Requirements of Overload Sets,,0
26-The Power of Free Functions A Compile-Time Abstraction Mechanism.pdf,26-The Power of Free Functions A Compile-Time Abstraction Mechanism,"Guideline 8: Understand the Semantic\nRequirements of Overload Sets\nIn “Guideline 6: Adhere to the Expected Behavior of Abstractions” , I\nintroduced you to the LSP and hopefully made a strong ar gument: every\nabstraction represents a set of semantic requirements! In other words, an\nabstraction expresses expected behavior , which needs to be fulfilled.\nOtherwise, you (very likely) will have a problem.  In “Guideline 7:\nUnderstand the Similarities Between Base Classes and Concepts ”, I\nextended the LSP discussion to concepts and demonstrated that the LSP can\nand should  also be applied to static abstractions.\nThat’ s not the end of the story , though. As stated before: every  abstraction\nrepresents a set of requirements. There is one more kind of abstraction that\nwe have not yet taken into account, one that’ s unfortunately often\noverlooked, despite its power , and hence one that we should not for get in\nthe discussion: function overloading. “Function overloading? Y ou mean the\nfact that a class can have several functions with the same name?” Yes,\nabsolutely . You probably have experienced that this is indeed a pretty\npowerful feature. Think, for instance, about the two overloads of the\nbegin() member function inside the std::vector: depending on whether\nyou have a const or a non- const vector , the corresponding overload is\npicked. W ithout you even noticing. Pretty powerful! But honestly , this isn’ t\nreally much of an abstraction. While it’ s convenient and helpful to overload\nmember functions, I have a dif ferent kind of function overloading in mind,\nthe kind that truly represents a form of abstraction: free functions.\nThe Power of Free Functions: A Compile-T ime\nAbstraction Mechanism\nNext  to concepts, function overloading by means of free functions\nrepresents a second compile-time abstraction: based on some given types,\nthe compiler figures out which function to call from a set of identically\nnamed functions. This is what we call an overload set . This is an extremely\nversatile and powerful abstraction mechanism with many , many great\ndesign characteristics. First of all, you can add a free function to any type:\nyou can add one to an int, to std::string, and to any other type.\nNonintrusively . Try that with a member function, and you will realize that\nthis just does not work. Adding a member function is intrusive. Y ou can’ t\nadd anything to a type that cannot have a member function or to a type that\nyou cannot modify . Thus, a free function perfectly lives up to the spirit of\nthe Open-Closed Principle (OCP): you can extend the functionality by\nsimply adding code, without the need to modify already existing code.\nThis gives you a significant design advantage. Consider , for instance, the\nfollowing code example:\ntemplate< typename Range > \nvoid traverseRange( Range const& range ) \n{ \n   for( auto pos=range.begin(); pos!=range.end(); ++pos ) { \n      // ... \n   } \n}\nThe traverseRange() function performs a traditional, iterator -based loop\nover the given range. To acquire iterators, it calls the begin() and end()\nmember functions on the range. While this code will work for a lar ge\nnumber of container types, it will not work for a built-in array:\n#include <cstdlib> \n \nint main() \n{ \n   int array[6] = { 4, 8, 15, 16, 23, 42 }; \n \n   traverseRange( array );  // Compilation error! \n \n   return EXIT_SUCCESS; \n}\nThis code will not compile, as the compiler will complain about the missing\nbegin() and end() member functions for the given array type. “Isn’ t that\nwhy we should avoid using built-in arrays and use std::array instead?” I\ncompletely agree: you should use std::array instead. This is also very\nnicely explained by Core Guideline SL.con.1 :\nPrefer using STL array or vector instead of a C array .\nHowever , while this is good practice, let’ s not lose sight of the design issues\nof the traverseRange() function: traverseRange() is restricting itself by\ndepending on the begin() and end() member functions. Thus, it creates an\nartificial requirement on the Range type to support a member begin() and\na member end() function and, by that, limits its own applicability . There is\na simple solution, however , a simple way to make the function much more\nwidely applicable: build on the overload set of free begin() and end()\nfunctions:\ntemplate< typename Range > \nvoid traverseRange( Range const& range ) \n{ \n   using std::begin;  // using declarations for the purpose of calling \n   using std::end;    //   'begin()' and 'end()' unqualified to enable ADL \n \n   for( auto pos=begin(range); pos!=end(range); ++pos ) { \n      // ... \n   } \n}\nThis function is still doing the same thing as before, but in this form it\ndoesn’ t restrict itself by any artificial requirement. And indeed, there is no\nrestriction: any type can have a free begin() and end() function or , if it is\nmissing, can be equipped with one. Nonintrusively . Thus, this function\nworks with any kind of Range and doesn’ t have to be modified or\noverloaded if some type does not meet the requirement. It is more widely\napplicable. It is truly generic.\nFree functions have more advantages, though. As already discussed in\n“Guideline 4: Design for T estability” , free functions are a very elegant\ntechnique to separate concerns, fulfilling the Single-Responsibility\nPrinciple (SRP). By implementing an operation outside a class, you\nautomatically reduce the dependencies of that class to the operation.\nTechnically , this becomes immediately clear , since in contrast to member9\n10\nfunctions, free functions don’ t have an implicit first ar gument, the this\npointer . At the same time, this promotes the function to become a separate,\nisolated service, which can be used by many other classes as well. Thus,\nyou promote reuse and reduce duplication. This very , very nicely adheres to\nthe idea of the Don’ t Repeat Y ourself (DR Y) principle.\nThe beauty of this is wonderfully demonstrated in Alexander Stepanov’ s\nbrainchild, the Standard T emplate Library (STL).  One part of the STL\nphilosophy is to loosely couple the dif ferent pieces of functionality and\npromote reuse by separating concerns as free functions. That’ s why\ncontainers and algorithms are two separate concepts within the STL:\nconceptually , containers don’ t know about the algorithms, and algorithms\ndon’t know about containers. The abstraction between them is\naccomplished via iterators that allow you to combine the two in seemingly\nendless ways. A truly remarkable design. Or to say it in the words of Scott\nMeyers:\nThere was never any question that the [standar d template] library\nrepresented a br eakthr ough in efficient and extensible design.\n“But what about std::string? std::string comes with dozens of\nmember functions, including many algorithms.” Y ou’re making a good\npoint, but more in the sense of a counter example. T oday the community\nagrees that the design of std::string is not great. Its design promotes\ncoupling, duplication, and growth: in every new C++ standard, there are a\ncouple of new , additional member functions. And growth means\nmodifications and subsequently the risk of accidentally changing\nsomething. This is a risk that you want to avoid in your design. However , in\nits defense, std::string was not part of the original STL. It was not\ndesigned alongside the STL containers ( std::vector, std::list,\nstd::set, etc.) and was adapted to the STL design only later . That explains\nwhy it’ s different from the other STL containers and does not completely\nshare their beautiful design goal.1 1\n12",7659
27-The Problem of Free Functions Expectations on the Behavior.pdf,27-The Problem of Free Functions Expectations on the Behavior,"The Problem of Free Functions: Expectations on the\nBehavior\nApparently , free functions  are remarkably powerful and seriously important\nfor generic programming. They play a vital role in the design of the STL\nand the design of the C++ Standard Library as a whole, which builds on the\npower of this abstraction mechanism.  However , all of this power can only\nwork if a set of overload functions adheres to a set of rules and certain\nexpectations. It can only work if it adheres to the LSP .\nFor instance, let’ s imagine that you have written your own Widget type and\nwant to provide a custom swap() operation for it:\n//---- <Widget.h> ---------------- \n \nstruct Widget \n{ \n   int i; \n   int j; \n}; \n \nvoid swap( Widget& w1, Widget& w2 ) \n{ \n   using std::swap; \n   swap( w1.i, w2.i ); \n}\nYour Widget only needs to be a simple wrapper for int values, called i and\nj. You provide the corresponding swap() function as an accompanying free\nfunction. And you implement swap() by swapping only the i value, not the\nj value. Further imagine that your Widget type is used by some other\ndeveloper , maybe a kind coworker . At some point, this coworker calls the\nswap() function:\n#include <Widget.h> \n#include <cstdlib> \n \nint main() \n{ \n   Widget w1{ 1, 11 }; \n   Widget w2{ 2, 22 }; 13\n \n   swap( w1, w2 ); \n \n   // Widget w1 contains (2,11) \n   // Widget w2 contains (1,22) \n \n   return EXIT_SUCCESS; \n}\nCan you imagine the surprise of your coworker when after the swap()\noperation the content of w1 is not (2,22) but (2,11) instead? How\nunexpected is it that only part of the object is swapped? Can you imagine\nhow frustrated your coworker must be after an hour of debugging? And\nwhat would happen if this wasn’ t a kind coworker?\nClearly , the implementation of swap() doesn’ t fulfill the expectations of a\nswap() function. Clearly , anyone would expect that the entire observable\nstate of the object is swapped. Clearly , there are behavioral expectations.\nThus, if you buy into an overload set, you’re immediately and inevitably\nsubject to fulfill the expected behavior of the overload set. In other words,\nyou have to adhere to the LSP .\n“I see the problem, I get that. I promise to adhere to the LSP ,” you say .\nThat’ s great, and this is an honorable intention. The problem is that it might\nnot always be entirely clear what the expected behavior is, especially for an\noverload set that is scattered across a big codebase. Y ou might not know\nabout all the expectations and all the details. Thus sometimes, even if\nyou’re aware of this problem and pay attention, you might still not do the\n“right” thing. This is what several people in the community are worried\nabout: the unrestricted ability to add potentially LSP-violating functionality\ninto an overload set.  And as stated before, it’ s easy to do. Anyone,\nanywhere, can add free functions.\nAs always, every approach and every solution has advantages, and also\ndisadvantages. On the one hand, it is enormously beneficial to exploit the\npower of overload sets, but on the other hand, it is potentially very dif ficult\nto do the right thing. These two sides of the same coin are also expressed by\nCore Guideline C.162  and Core Guideline C.163 :14\nOverload operations that ar e roughly equivalent.\n—Core Guideline C.162\nOverload only for operations that ar e roughly equivalent.\n—Core Guideline C.163\nWhereas C.162 expresses the advantages of having the same name for\nsemantically equivalent functions, C.163 expresses the problem of having\nthe same name for semantically  different functions. Every C++ developer\nshould be aware of the tension between these two guidelines. Additionally ,\nto adhere to the expected behavior , every C++ developer is well advised to\nbe aware of existing overload sets ( std::swap(), std::begin(),\nstd::cbegin(), std::end(), std::cend(), std::data(), std::size(),\netc.) and to know about common naming conventions. For instance, the\nname find() should be used only for a function that performs a linear\nsearch over a range of elements. For any function that performs a binary\nsearch, the name find() would raise the wrong expectations and would not\ncommunicate the precondition that the range needs to be sorted. And then,\nof course, the names begin() and end() should always fulfill the\nexpectation to return a pair of iterators that can be used to traverse a range.\nThey should not start or end some kind of process. This task would be\nbetter performed by a start() and a stop() function.\n“Well, I agree with all these points,” you say . “However , I’m primarily\nusing virtual functions, and since these cannot be implemented in terms of\nfree functions, I can’ t really use all of this advice on overload sets, right?” It\nmay surprise you, but this advice still applies to you. Since the ultimate goal\nis to reduce dependencies, and since virtual functions may cause quite a\nsignificant amount of coupling, one of the goals will be to “free” these, too.\nIn fact, in many of the subsequent guidelines, and perhaps most\nprominently in “Guideline 19: Use Strategy to Isolate How Things Are\nDone”  and “Guideline 31: Use External Polymorphism for Nonintrusive\nRuntime Polymorphism” , I will tell the story of how to extract and separate\nvirtual  functions in the form of, but not limited to, free functions.15",5395
28-Guideline 9 Pay Attention to the Ownership of Abstractions.pdf,28-Guideline 9 Pay Attention to the Ownership of Abstractions,,0
29-The Dependency Inversion Principle.pdf,29-The Dependency Inversion Principle,"In summary , function overloading is a powerful compile-time abstraction\nmechanism that you should not underestimate. In particular , generic\nprogramming heavily exploits this power . However , don’ t take this power\ntoo lightly: remember that just as with base classes and concepts, an\noverload set represents a set of semantic requirements and thus is subject to\nthe LSP . The expected behavior of an overload set must be adhered to, or\nthings will not work well.\nGUIDELINE 8: UNDERSTAND THE SEMANTIC\nREQUIREMENTS OF OVERLOAD SETS\nBe aware that function overloading is a compile-time abstraction\nmechanism.\nKeep in mind that there are expectations on the behavior of\nfunctions within an overload set.\nPay attention to existing names and conventions.\nGuideline 9: Pay Attention to the Ownership\nof Abstractions\nAs stated in “Guideline 2: Design for Change” , change is the one constant\nin software development. Y our software should be prepared for change.\nOne of the essential ingredients for dealing with change is the introduction\nof abstractions (see also “Guideline 6: Adhere to the Expected Behavior of\nAbstractions” ). Abstractions help reduce dependencies and thus make it\neasier to change details in isolation. However , there is more to introducing\nabstractions than just adding base classes or templates.\nThe Dependency Inversion Principle\nThe need for abstractions is also expressed by Robert Martin:16\nThe most flexible systems ar e those in which sour ce code dependencies\nrefer only to abstractions, not to concr etions.\nThis piece of wisdom is commonly known as the Dependency Inversion\nPrinciple (DIP), which is the fifth of the SOLID principles. Simply stated, it\nadvises that for the sake of dependencies, you should depend on\nabstractions instead of concrete types or implementation details. Note that\nthis statement doesn’ t say anything about inheritance hierarchies but only\nmentions abstractions in general.\nLet’s take a look at the situation illustrated in Figure 2-1 . Imagine you are\nimplementing the logic for an automated teller machine (A TM). An A TM\nprovides several kinds of operations: you can withdraw money , deposit\nmoney , and transfer money . Since all of these operations deal with real\nmoney , they should either run to full completion or , in case of any kind of\nerror , be aborted and all changes rolled back. This kind of behavior (either\n100% success or a complete rollback) is what we commonly call a\ntransaction . Consequently , we can introduce an abstraction named\nTransaction. All abstractions ( Deposit, Withdrawal, and Transfer)\ninherit from the Transaction class (depicted by the UML inheritance\narrow).17\nFigur e 2-1. Initial str ong dependency r elationship between several transactions and a UI\nAll transactions are in need of input data entered by a bank customer via the\nuser interface.  This user interface is provided by the UI class, which\nprovides many dif ferent functions to query for the entered data:\nrequestDepositAmount(), request WithdrawalAmount(),\nrequestTransferAmount(), informInsufficientFunds(), and\npotentially more functions. All three abstractions directly call these\nfunctions whenever they need information. This relationship is depicted by\nthe little solid arrow , which indicates that the abstractions depend on the UI\nclass.\nWhile this setup may work for some time, your trained eye might have\nalready spotted a potential problem: what happens if something changes?\nFor instance, what happens if a new transaction is added to the system?\nLet’s assume that we must add a SpeedTransfer transaction for VIP\ncustomers. This might require us to change and extend the UI class with a\ncouple of new functions (for instance, requestSpeedTransferAmount()\nand requestVIPNumber()). That, in turn, also af fects all of the other\ntransactions, since they directly depend on the UI class. In the best case,\nthese transactions simply have to be recompiled and retested (still, this\ntakes time!); in the worst case, they might have to be redeployed in case\nthey are delivered in separate shared libraries.\nThe underlying reason for all of that extra ef fort is a broken architecture. All\ntransactions indirectly depend on one another via the concrete dependency\non the UI class. And that is a very unfortunate situation from an\narchitectural point of view: the transaction classes reside at the high level of\nour architecture, while the UI class resides at the low level. In this example,\nthe high level depends on the low level. And that is just wrong: in a proper\narchitecture, this dependency should be inverted.\nAll transactions indirectly depend on one another due to the dependency on\nthe UI class. Furthermore, the high level of our architecture depends on the\nlow level. This is a pretty unfortunate situation indeed, a situation that we\nshould resolve properly . “But that’ s simple!” you say . “We just introduce an18\nabstraction!” That’ s exactly what Robert Martin expressed in his statement:\nwe need to introduce an abstraction in order not to depend on the concrete\nimplementation in the UI class.\nHowever , a single abstraction wouldn’ t solve the problem. The three kinds\nof transactions would still be indirectly coupled. No, as Figure 2-2\nillustrates, we need three abstractions: one for each transaction.19\nFigur e 2-2. The r elaxed dependency r elationship between several transactions and a UI\nBy introducing the DepositUI, WithdrawalUI, and TransferUI classes,\nwe’ve broken the dependency among the three transactions. The three\ntransactions are no longer dependent on the concrete UI class, but on a\nlightweight abstraction that represents only those operations that the\nrelevant transaction truly requires. If we now introduce the SpeedTransfer\ntransaction, we can also introduce the SpeedTransferUI abstraction, so\nnone of the other transactions will be af fected by the changes introduced in\nthe UI class.\n“Oh, yes, I get it! This way we have fulfilled three design principles!” You\nsound impressed. “W e’ve introduced an abstraction to cut the dependency\non the implementation details of the user interface. That must be the DIP .\nAnd we’ve followed the ISP and removed the dependencies among the\ndifferent transactions. And as a bonus, we have also nicely grouped the\nthings that truly belong together . That’ s the SRP , right? That’ s amazing!\nLet’s celebrate!”\nWait, wait, wait…Before you go of f to uncork your best bottle of\nchampagne to celebrate solving this dependency problem, let’ s take a closer\nlook at the problem. So yes, you are correct, we follow the ISP  by\nseparating the concerns of the UI class. By segregating it into three client-\nspecific interfaces, we’ve resolved the dependency situation among the\nthree transactions. This is indeed the ISP . Very nice!\nUnfortunately , we haven’ t resolved our architectural problem yet, so no, we\ndo not follow the DIP (yet). But I get the misunderstanding: it does appear\nas if we have inverted the dependencies. Figure 2-3  shows that we have\nreally introduced an inversion of dependencies: instead of depending on the\nconcrete UI class, we now depend on abstractions.\nFigur e 2-3. The local inversion of dependencies by intr oduction of thr ee abstract UI classes\nHowever , what  we have introduced is a local  inversion of dependencies.\nYes, a local inversion only , not a global inversion. From an architectural\npoint of view , we still have a dependency from the high level (our\ntransaction classes) to the low level (our UI functionality). So no, it is not\nenough to just introduce an abstraction. It’ s also important to consider\nwher e to introduce the abstraction. Robert Martin expressed this with the\nfollowing two points:\n1. High-level modules should not depend on low-level modules. Both\nshould depend on abstractions.\n2. Abstractions should not depend on details. Details should depend on\nabstractions .\nThe first point clearly expresses an essential property of an architecture: the\nhigh level, i.e., the stable part(s) of our software, should not depend on the\nlow level, i.e., the implementation details. That dependency should be\ninverted, meaning that the low level should depend on the high level.\nLuckily , the second point gives us an idea how to achieve that: we assign\nthe three abstractions to the high level. Figure 2-4  illustrates the\ndependencies when we consider abstractions part of the high level.20",8516
30-Dependency Inversion in a Plug-In Architecture.pdf,30-Dependency Inversion in a Plug-In Architecture,"Figur e 2-4. Inversion of dependencies by assigning the abstractions to the high level\nBy assigning the abstractions to the high level and by making the high level\nthe owner of the abstractions, we truly follow the DIP: all arrows now run\nfrom the low level to the high level. Now we do have a proper architecture.\n“Wait a second!” Y ou look a little confused. “That’ s it? All we need is to\nperform a mental shift of the architectural boundary?” W ell, it may very\nwell be more than just a mental shift. This may result in moving the\ndependent header files for the UI classes from one module to another and\nalso completely rearranging the dependent include statements. It’ s not just a\nmental shift—it is a reassignment of ownership.\n“But now we no longer group the things that belong together ,” you ar gue.\n“The user interface functionality is now spread across both levels. Isn’ t that\na violation of the SRP?” No, it isn’ t. On the contrary , only after assigning\nthe abstractions to the high level do we now properly follow the SRP . It’s\nnot the UI classes that belong together; it’ s the transaction classes and the\ndependent UI abstractions that should be grouped together . Only in this way\ncan we steer the dependency in the right direction; only in this way do we\nhave an architecture. Thus, for a proper dependency inversion, the\nabstraction must  be owned by the high level.\nDependency Inversion in a Plug-In Architecture\nPerhaps  this fact makes more sense if we consider the situation depicted in\nFigure 2-5 . Imagine you have created the next-generation text editor . The\ncore of this new text editor is represented by the Editor class on the\nlefthand side. T o ensure that this text editor will be successful, you want to\nmake sure that the fan community can participate in the development.\nTherefore, one vital ingredient for your success is the ability of the\ncommunity to add new functionality in the form of plug-ins. However , the\ninitial setting is pretty flawed from an architectural point of view and will\nhardly satisfy your fan community: the Editor directly depends on the\nconcrete VimMode Plu gin class. Since the Editor class is part of the high\nlevel of the architecture, which you should consider as your own realm, the\nVimMode Plugin is part of the low level of the architecture, which is the\nrealm of your fan community . Since the Editor directly depends on the\nVimMode Plu gin, and because that essentially means that your community\ncan define their interfaces as they please, you would have to change the\neditor for every new plug-in. As much as you love to work on your\nbrainchild, there’ s only so much time you can devote to adapting to\ndifferent kinds of plug-ins. Unfortunately , your fan community will soon be\ndisappointed and move on to another text editor .\nFigur e 2-5. Broken plug-in ar chitectur e: the high-level Editor class depends on the low-level\nVimModePlugin class\nOf course, that shouldn’ t happen. In the given Editor example, it certainly\nisn’t a good idea to make the Editor class depend on all the concrete plug-\nins. Instead, you should reach for an abstraction, for instance, in the form of\na Plugin base class. The Plugin class now represents the abstraction for all\nkinds of plug-ins. However , it doesn’ t make sense to introduce the\nabstraction in the low level of the architecture (see Figure 2-6 ). Your\nEditor would still depend on the whims of your fan community .\nFigur e 2-6. Broken plug-in ar chitectur e: the high-level Editor class depends on the low-level\nPlugin class\nThis misdirected dependency also becomes apparent when looking at the\nsource code:\n//---- <thirdparty/Plugin.h> ---------------- \n \nclass Plugin { /*...*/ };  // Defines the requirements for plugins \n \n \n//---- <thirdparty/VimModePlugin.h> ---------------- \n \n#include <thirdparty/Plugin.h> \n \nclass VimModePlugin : public Plugin { /*...*/ }; \n \n \n//---- <yourcode/Editor.h> ---------------- \n \n#include <thirdparty/Plugin.h>  // Wrong direction of dependencies! \n \nclass Editor { /*...*/ };\nThe only way to build a proper plug-in architecture is to assign the\nabstraction to the high level. The abstraction must  belong to you, not to your\nfan community . Figure 2-7  demonstrates that this resolves the architectural\ndependency and frees your Editor class from the dependencies on plug-ins.\nThis resolves both the DIP , because the dependency is properly inverted,\nand the SRP , because the abstraction belongs to the high level.\nFigur e 2-7. Corr ect plug-in ar chitectur e: the low-level VimModePlugin class depends on the high-\nlevel Plugin class\nA look at the source code reveals that the direction of dependencies has\nbeen fixed: the VimModePlugin depends on your code, and not vice versa:\n//---- <yourcode/Plugin.h> ---------------- \n \nclass Plugin { /*...*/ };  // Defines the requirements for plugins \n \n \n//---- <yourcode/Editor.h> ---------------- \n \n#include <yourcode/Plugin.h> \n \nclass Editor { /*...*/ }; \n \n \n//---- <thirdparty/VimModePlugin.h> ----------------",5116
31-Dependency Inversion via Overload Sets.pdf,31-Dependency Inversion via Overload Sets,"#include <yourcode/Plugin.h>  // Correct direction of dependencies \n \nclass VimModePlugin : public Plugin { /*...*/ };\nAgain, to get a proper dependency inversion, the abstraction must be owned\nby the high level. In this context, the Plugin class represents the set of\nrequirements that needs to be fulfilled by all plug-ins (see again “Guideline\n6: Adhere to the Expected Behavior of Abstractions” ). The Editor defines\nand thus owns these requirements. It doesn’ t depend on them. Instead, the\ndifferent plug-ins depend on the requirements. That is dependency\ninversion. Hence, the DIP is not just about the introduction of an abstraction\nbut also about the ownership of that abstraction.\nDependency Inversion via T emplates\nSo far I might have given you the impression that the DIP is concerned with\nonly inheritance hierarchies and base classes. However , dependency\ninversion is also achieved with templates. In that context, however , the\nquestion of ownership is resolved automatically . As an example, let’ s\nconsider the std::copy_if() algorithm:\ntemplate< typename InputIt, typename OutputIt, typename UnaryPredicate > \nOutputIt copy_if( InputIt first, InputIt last, OutputIt d_first, \n                  UnaryPredicate pred );\nThis copy_if() algorithm also adheres to the DIP . The dependency\ninversion is achieved with the concepts InputIt, OutputIt, and\nUnaryPredicate. These three concepts represent the requirements on the\npassed iterators and predicates that need to be fulfilled by calling code. By\nspecifying these requirements through concepts, i.e., by owning these\nconcepts, std::copy_if() makes other code depend on itself and does not\nitself depend on other code. This dependency structure is depicted in\nFigure 2-8 : both containers and predicates depend on the requirements\nexpressed by the corresponding algorithm. Thus, if we consider the\narchitecture within the Standard Library , then std::copy_if() is part of\nthe high level of the architecture, and containers and predicates (function\nobjects, lambdas, etc.) are part of the low level of the architecture.\nFigur e 2-8. Dependency structur e of the STL algorithms\nDependency Inversion via Overload Sets\nInheritance hierarchies  and concepts are not the only means to invert\ndependencies. Any kind of abstraction is able to do so. Therefore, it\nshouldn’ t come as a surprise that overload sets also enable you to follow the\nDIP. As you have seen in “Guideline 8: Understand the Semantic\nRequirements of Overload Sets” , overload sets represent an abstraction and,\nas such, a set of semantic requirements and expectations. In comparison to\nbase classes and concepts, though, there is unfortunately no code that\nexplicitly describes the requirements. But if these requirements are owned\nby a higher level in your architecture, you can achieve dependency\ninversion. Consider , for instance, the following Widget class template:\n//---- <Widget.h> ---------------- \n \n#include <utility> \n \ntemplate< typename T > \nstruct Widget \n{ \n   T value; \n}; \n \ntemplate< typename T > \nvoid swap( Widget<T>& lhs, Widget<T>& rhs ) \n{ \n   using std::swap; \n   swap( lhs.value, rhs.value ); \n}\nWidget owns a data member of an unknown type T. Despite the fact that T\nis unknown, it is possible to implement a custom swap() function for\nWidget by building on the semantic expectations of the swap() function.\nThis implementation works, as long as the swap() function for T adheres to\nall expectations for swap() and follows the LSP:\n#include <Widget.h> \n#include <assert> \n#include <cstdlib> \n#include <string> \n \nint main() \n{ \n   Widget<std::string> w1{ ""Hello"" }; \n   Widget<std::string> w2{ ""World"" }; \n \n   swap( w1, w2 ); \n \n   assert( w1.value == ""World"" ); \n   assert( w2.value == ""Hello"" ); \n \n   return EXIT_SUCCESS; \n}\nIn consequence, the Widget swap() function itself follows the expectations\nand adds to the overload set, similar to what a derived class would do. The\ndependency structure for the swap() overload set is shown in Figure 2-9 .\nSince the requirements, or the expectations, for the overload set are part of21",4176
32-Guideline 10 Consider Creating an Architectural Document.pdf,32-Guideline 10 Consider Creating an Architectural Document,"the high level of the architecture, and since any implementation of swap()\ndepends on these expectations, the dependency runs from the low level\ntoward the high level. The dependency is therefore properly inverted.\nFigur e 2-9. Dependency structur e of the swap() overload set\nDependency Inversion Principle V ersus Single-\nResponsibility Principle\nAs we have seen, the DIP is fulfilled by properly assigning ownership and\nby properly grouping the things that truly belong. From that perspective, it\nsounds plausible to consider the DIP as just another special case of the SRP\n(similar to the ISP). However , hopefully you see that the DIP is more than\nthat. As the DIP , in contrast to the SRP , is very much concerned with the\narchitectural point of view , I consider it a vital piece of advice to build\nproper global dependency structures.\nTo summarize, in order to build a proper architecture with a proper\ndependency structure, it’ s essential to pay attention to the ownership of\nabstractions. Since abstractions represent requirements on the\nimplementations, they should be part of the high level to steer all\ndependencies toward the high level.\nGUIDELINE 9: PAY ATTENTION TO THE OWNERSHIP\nOF ABSTRACTIONS\nKeep in mind that in a proper architecture, low-level\nimplementation details depend on high-level abstractions.\nAdhere to the Dependency Inversion Principle (DIP), and assign\nabstractions to the high level of an architecture.\nMake sure abstractions are owned  by the high level, not by the low\nlevel.\nGuideline 10: Consider Creating an\nArchitectural Document\nLet’s chat a little about your architecture. Let me start with a very simple\nquestion: do you have an architectural document? Any plan or description\nthat summarizes the major points and fundamental decisions of your\narchitecture and that shows the high levels, the low levels, and the\ndependencies between them? If your answer is yes, then you’re free to skip\nthis guideline and continue with the next one. If your answer is no,\nhowever , then let me ask a few follow-up questions. Do you have a\nContinuous Integration  (CI) environment? Do you use automated tests? Do\nyou apply static code analysis tools? All yes? Good, there’ s still hope. The\nonly remaining question is: why don’ t you have an architectural document?\n“Oh, come on, don’ t turn a mosquito into an elephant. A missing\narchitectural document is not the end of the world! After all, we are Agile,\nwe can change things quickly!” Imagine my completely blank expression,\nfollowed by a long sigh. W ell, honestly , I was afraid this would be your\nexplanation. It’ s unfortunately what I hear far too often. There may be a\nmisunderstanding: the ability to quickly change things is not the point of an\nAgile methodology . Sadly , I also have to tell you that your answer doesn’ t\nmake any sense. Y ou could just as well have answered with “After all, we\nlike chocolate!” or “After all, we wear carrots around our necks!” T o\nexplain what I mean, I will quickly summarize the point of the Agile\nmethodology and then subsequently explain why you should invest in an\narchitectural document.\nThe expectation that Agile methods help to change things quickly is pretty\nwidespread. However , as several authors in the recent past have clarified,\nthe major , and probably only , point of the Agile methodology is to get quick\nfeedback.  In Agile methods, the entire software development process is\nbuilt around it: quick feedback due to business practices (such as planning,\nsmall releases, and acceptance tests), quick feedback due to team practices\n(e.g., collective ownership, CI, and stand-up meetings), and quick feedback\ndue to technical practices (such as test-driven development, refactoring, and\npair programming). However , contrary to popular belief, the quick feedback\ndoes not mean that you can change your software quickly and easily .\nThough quick feedback is, of course, key to quickly knowing that\nsomething has to be done, you gain the ability to quickly change your\nsoftware only with good software design and architecture. These two save\nyou the Herculean ef fort to change things; quick feedback only tells you\nsomething is broken.\n“OK, you’re right. I get your point—it is important to pay attention to good\nsoftware design and architecture. But what’ s the point of an architectural\ndocument?” I’m glad we agree. And that is an excellent question. I see we\nare making progress. T o explain the purpose of an architectural document,\nlet me give you another definition of architecture:\nIn most successful softwar e projects, the expert developers working on\nthat pr oject have a shar ed understanding of the system design. This\nshared understanding is called ‘ar chitectur e.’\n—Ralph Johnson22\n23\nRalph Johnson describes architectur e as the shared understanding of a\ncodebase—the global vision. Let’ s assume that there is no architectural\ndocument, nothing that summarizes the global picture—the global vision of\nyour codebase. Let’ s also assume that you believe you have a very clear\nidea of the architecture of your codebase. Then here are a few more\nquestions: how many developers are on your team? Are you certain that all\nof these developers are familiar with the architecture in your head? Are you\ncertain that all of them share the same vision? Are you certain that they all\nhelp you move forward in the same dir ection ?\nIf your answers are yes, then you might not have gotten the point yet. It is\nfairly certain that every developer has dif ferent experiences and a slightly\ndifferent terminology . It is also fairly certain that every developer sees the\ncode dif ferently and has a slightly dif ferent idea of the current architecture.\nAnd this slightly dif ferent view of the current state of af fairs may lead to a\nslightly dif ferent vision for the future. While this might not be immediately\nevident over a short period of time, there is a good chance that surprises\nwill happen in the long run. Misunderstandings. Misinterpretations. This is\nexactly the point of an architectural document: one common document that\nunifies the ideas, visions, and essential decisions in one place; helps\nmaintain and communicate the state of the architecture; and helps avoid any\nmisunderstandings.\nThis document also preserves ideas, visions, and decisions. Imagine that\none of your leading software architects, one of the brains behind the\narchitecture of your codebase, leaves the or ganization. W ithout a document\nwith the fundamental decisions, this loss of manpower will also cause a loss\nof essential information about your codebase. As a consequence, you will\nlose consistency in the vision of your architecture and also, more\nimportantly , some confidence to adapt or change architectural decisions. No\nnew hire will ever be able to replace that knowledge and experience, and no\none will be able to extract all that information from the code. Thus, the code\nwill become more rigid, more “legacy .” This promotes decisions to rewrite\nlarge parts of the code, with questionable outcomes, as the new code will\ninitially lack a lot of the wisdom of the old code.  Thus, without an\narchitectural document, your long-term success is at stake.\nThe value in such an architectural document becomes obvious if we take a\nlook at how seriously architecture is taken at construction sites.\nConstruction is not even going to start without a plan. A plan that everyone\nagrees to. Or let’ s imagine what would happen if there was no plan: “Hey , I\nsaid the garage should be to the left of the house!” “But I built it to the left\nof the house.” “Y es, but I meant my left, not your left!”\nThis is exactly the kind of problem that can be avoided by investing time in\nan architectural document. “Y es, yes, you’re right,” you admit, “but such a\ndocument is soooo  much work. And all of this information is in the code\nanyway . It adapts with the code, while the document goes out of date soooo\nquickly!” W ell, not if you’re doing it properly . An architectural document\nshouldn’ t go out of date quickly because it should primarily reflect the big\npicture of your codebase. It shouldn’ t contain the little details that indeed\ncan change very often; instead, it should contain the overall structure, the\nconnections between key players, and the major technological decisions. All\nthese things are not expected to change (although we all agree that “not\nexpected to change” doesn’ t mean that they won’ t change; after all,\nsoftware is expected to change). And yes, you are correct: these details are,\nof course, also part of the code. After all, the code contains all the details\nand thus can be said to represent the ultimate truth. However , it doesn’ t help\nif the information is not easy to come by , is hidden from plain sight, and\nrequires an archaeological ef fort to extract.\nI am also aware that, in the beginning, the endeavor to create an\narchitectural document does sound like a lot of work. An enormous amount\nof work. All I can do is encourage you to get started somehow . Initially , you\ndo not have to document your architecture in all its glory , but maybe you\nstart with only the most fundamental structural decisions. Some tools can\nalready use this information to compare your assumed architectural state\nand its actual state.  Over time, more and more architectural information\ncan be added, documented, and maybe even tested by tools, which leads to24\n25\nmore and more commonly available, established wisdom for your entire\nteam.\n“But how do I keep this document up to date?” you ask. Of course, you’ll\nhave to maintain this document, integrate new decisions, update old\ndecisions, etc. However , since this document should only contain\ninformation about the aspects that do not often change, there should be no\nneed to constantly touch and refactor it. It should be enough to schedule a\nshort meeting of the senior developers every one or two weeks to discuss if\nand how the architecture has evolved. Thus, it is hard to imagine this\ndocument becoming a bottleneck in the development process. In this regard,\nconsider  this document a bank deposit safe: it is invaluable to have all of\nthe accumulated decisions of the past when you need them and to keep the\ninformation secure, but you wouldn’ t open it every single day .\nIn summary , the benefits of having an architectural document by far\noutweigh the risks and ef forts. The architectural document should be\nconsidered an essential part of any project and an integral part of the\nmaintenance and communication ef forts. It should be considered equally\nimportant as a CI environment or automated tests.\nGUIDELINE 10: CONSIDER CREATING AN\nARCHITECTURAL DOCUMENT\nUnderstand that an architectural document serves the purpose of\nmaintaining and communicating the current state of the\narchitecture.\nUse tools to support and help you test the current state of your\narchitecture against the expected state.\n1 In one of my training classes several years ago, I was “gently” reminded that from a\nmathematical perspective, a square is not a rectangle but a rhombus. My knees still shake when\nI think about that lecture. Therefore, I specifically say “appears to be” instead of “is” to denote\nthe naive impression that unaware people like me might have had.\n2 Not mathematically , but in this implementation.\n3 The LSP was first introduced by Barbara Liskov in the paper “Data Abstraction and\nHierarchy”  in 1988. In 1994, it was reformulated in the paper “A Behavioral Notion of\nSubtyping”  by Barbara Liskov and Jeannette W ing. For her work, Barbara Liskov received the\nTuring A ward in 2008.\n4 If you have a strong opinion about a square being a rhombus, please for give me!\n5 And yet, in a suf ficiently lar ge codebase, there’ s a good chance that you’ll find at least one\nexample of this kind of malpractice. In my experience, it’ s often the result of too little time to\nrethink and adapt the abstraction .\n6 This is indeed a very often discussed topic. Y ou’ll find a very good summary of this in\nfoonathan’ s blog .\n7 In C++20, std::copy() is finally constexpr but does not yet use the\nstd::input_iterator and std::output_iterator concepts. It is still based on the formal\ndescription of input and output iterators; see LegacyInputIterator  and LegacyOutputIterator .\n8 And no, it wouldn’ t be a compile-time error , unfortunately .\n9 The free begin() and end() functions are an example of the Adapter  design pattern; see\n“Guideline 24: Use Adapters to Standardize Interfaces”  for more details.\n10 That is why range-based for loops build on the free begin() and end() functions.\n1 1 Alexander Stepanov and Meng Lee, “The Standard T emplate Library” , October 1995.\n12 Scott Meyers, Effective STL: 50 Specific W ays to Impr ove Y our Use of the Standar d Template\nLibrary  (Addison-W esley Professional, 2001).\n13 Free functions are indeed a seriously valuable design tool. T o give one example of this, allow\nme to tell a short war story . You might know Martin Fowler ’s book Refactoring: Impr oving the\nDesign of Existing Code  (Addison-W esley), which may be considered one of the classics for\nprofessional software development. The first edition of the book was published in 2012 and\nprovided programming examples in Java. The second edition of the book was released in 2018,\nbut interestingly rewritten with JavaScript. One of the reasons for that choice was the fact that\nany language having a C-like syntax was considered easier to digest for a majority of readers.\nHowever , another important reason was the fact that JavaScript, unlike Java, provides free\nfunctions, which Martin Fowler considers a very important tool for decoupling and separating\nconcerns. W ithout this feature, you would be limited in your flexibility to achieve the\nrefactoring goal.\n14 A great discussion of this can be found in episode 83 of Cpp.Chat , where Jon Kalb, Phil\nNash, and Dave Abrahams discuss the lessons learned from C++ and how they were applied in\nthe development of the Swift programming language.\n15 As Kate Gregory would say , “Naming Is Hard: Let’ s Do Better .” This is the title of her highly\nrecommended talk from CppCon 2019 .\n16 Robert C. Martin, Clean Ar chitectur e (Addison-W esley , 2017).\n17 This example is taken from Robert Martin’ s book Agile Softwar e Development: Principles,\nPatterns, and Practices  (Prentice Hall, 2002). Martin used this example to explain the Interface\nSegregation Principle (ISP), and for that reason, he didn’ t go into detail about the question of\nownership of abstractions. I will try to fill this gap.\n18 If you ar gue that the Transaction base class could be on an even higher level, you are\ncorrect. Y ou’ve earned yourself a bonus point! But for the remainder of the example we won’ t\nneed this extra level, and therefore I will ignore it.\n19 If you’re wondering about the two informInsufficientFunds() functions: yes, it is\npossible to implement both virtual functions (i.e., the one from the WithdrawalUI and the one\nfrom the TransferUI) by means of a single implementation in the UI class. Of course, this\nworks well only as long as these two functions represent the same expectations and thus can be\nimplemented as one. However , if they represent dif ferent expectations, then you’re facing a\nSiamese T win Pr oblem  (see Item 26 in Herb Sutter ’s More Exceptional C++: 40 New\nEngineering Puzzles, Pr ogramming Pr oblems, and Solutions  (Addison-W esley). For our\nexample, let’ s assume that we can deal with these two virtual functions the easy way .\n20 Martin, Clean Ar chitectur e.\n21 I know what you’re thinking. However , it was just a matter of time until you encountered a\n“Hello W orld” example.\n22 The point is, for instance, made by Robert C. Martin, one of the signees of the Agile\nmanifesto, in his book Clean Agile: Back to Basics  (Pearson). A second good summary is\ngiven by Bertrand Meyer in Agile! The Good, the Hype and the Ugly  (Springer). Finally , you\ncan also consult the second edition of James Shore’ s book The Art of Agile Development\n(O’Reilly). A good talk on the misuse of the term Agile  is Dave Thomas’ s “Agile Is Dead”\npresentation  from GOT O 2015.\n23 Quoted in Martin Fowler , “Who Needs an Architect?” IEEE Softwar e 20, no. 5 (2003), 1 1–13,\nhttps://doi.or g/10.1 109/MS.2003.1231 144.\n24 Joel Spolsky , whom you may know as the author of the Joel on Softwar e blog , and also as one\nof the creators of Stack Overflow , named the decision to rewrite a lar ge piece of code from\nscratch “the single worst strategic mistake that any company can make” .\n25 One possible tool for this purpose is the Axivion Suite . You start by defining architectural\nboundaries between your modules, which can be used by the tool to check if the architectural\ndependencies are upheld. Another tool with such capabilities is the Sparx Systems Enterprise\nArchitect .",17093
33-Guideline 11 Understand the Purpose of Design Patterns.pdf,33-Guideline 11 Understand the Purpose of Design Patterns,"Chapter 3. The Purpose of\nDesign Patterns\nVisitor , Strategy , Decorator . These  are all names of design patterns that\nwe’ll deal with in the upcoming chapters. However , before taking a detailed\nlook at each of these design patterns, I should give you an idea about the\ngeneral purpose of a design pattern. Thus in this chapter , we will first take a\nlook at the fundamental properties of design patterns, why you would want\nto know about them and use them.\nIn “Guideline 1: Understand the Importance of Software Design ”, I already\nused the term design pattern  and explained on which level of software\ndevelopment you use them. However , I have not yet explained in detail\nwhat a design pattern is. That will be the topic of “Guideline 1 1:\nUnderstand the Purpose of Design Patterns” : you will understand that a\ndesign pattern has a name that expresses an intent, introduces an abstraction\nthat helps to decouple software entities, and has been proven over the years.\nIn “Guideline 12: Beware of Design Pattern Misconceptions” , I will focus\non several misconceptions about design patterns and explain what a design\npattern is not . I will try to convince you that design patterns are not about\nimplementation details and do not represent language-specific solutions to\ncommon problems. I will also do my best to show you that they are not\nlimited to object-oriented programming nor to dynamic polymorphism.\nIn “Guideline 13: Design Patterns Are Everywhere” , I will demonstrate that\nit’s hard to avoid design patterns. They are everywhere! Y ou will realize\nthat the C++ Standard Library in particular is full of design patterns and\nmakes good use of their strengths.\nIn “Guideline 14: Use a Design Pattern’ s Name to Communicate Intent” , I\nwill make the point that part of the strength of a design pattern is the ability\nto communicate intent by using its name. Thus I will show you how much",1926
34-A Design Pattern Introduces an Abstraction.pdf,34-A Design Pattern Introduces an Abstraction,"more information and meaning you can add to your code by using the name\nof a design pattern.\nGuideline 11: Understand the Purpose of\nDesign Patterns\nThere’ s a good chance that you have heard about design patterns before and\na fairly good chance that you’ve used some of them in your programming\ncareer . Design patterns are nothing new: they have been around at least\nsince the  Gang of Four (GoF) released their book on design patterns in\n1994.  And while there are always critics, their special value has been\nacknowledged throughout the software industry . Yet, despite the long\nexistence and importance of design patterns, despite all the knowledge and\naccumulated wisdom, there are many misconceptions about them,\nespecially in the C++ community .\nTo use design patterns productively , as a first step you need to understand\nwhat design patterns are. A design pattern:\nHas a name\nCarries an intent\nIntroduces an abstraction\nHas been proven\nA Design Pattern Has a Name\nFirst of all, a design pattern has a name. While this sounds very obvious and\nnecessary , it is indeed a fundamental property of a design pattern. Let’ s\nassume that the two of us are working on a project together and are tasked\nwith finding a solution to a problem. Imagine I told you, “I would use a\nVisitor  for that.”  Not only would this tell you what I understand to be the\nreal problem, but it would also give you a precise idea about the kind of\nsolution I’m proposing.1\n2\nThe name of a design pattern allows us to communicate on a very high level\nand to exchange a lot of information with very few words:\nME: I would use a V isitor for that.\nYOU: I don’ t know . I thought of using a Strategy .\nME: Y es, you may have a point ther e. But since we’ll have to extend\noperations fairly often, we pr obably should consider a Decorator as well.\nBy just using the names Visitor , Strategy , and Decorator , we’ve discussed\nthe evolution of the codebase, and described how we expect things to\nchange and to be extended in years to come.  Without these names, we\nwould have a much harder time expressing our ideas:\nME: I think we should cr eate a system that allows us to extend the\noperations without the need to modify existing types again and again.\nYOU: I don’ t know . Rather than new operations, I would expect new\ntypes to be added fr equently . So I pr efer a solution that allows me to add\ntypes easily . But to r educe coupling to the implementation details, which\nis to be expected, I would suggest a way to extract implementation details\nfrom existing types by intr oducing a variation point.\nME: Y es, you may have a point ther e. But since we’ll have to extend\noperations fairly often, we pr obably should consider designing the system\nin such a way that we can build on and r euse a given implementation\neasily .\nDo you see the dif ference? Do you feel the dif ference? W ithout names, we\nhave to talk about a lot more details explicitly . Obviously this kind of\nprecise communication is possible only if we share the same understanding\nof design patterns. That is why it’ s so important to know about design\npatterns and to talk about them.\nA Design Pattern Carries an Intent\nBy using the name of a design pattern, you can express your intent\nconcisely and limit possible misunderstandings. This leads to the second3\nproperty of a design pattern: an intent. The name  of a design pattern\nconveys its intent . If you use the name of a design pattern, you implicitly\nstate what you consider to be the problem and what you see as a solution.\nHopefully you realized that in our little conversion, we weren’ t talking\nabout any kind of implementation. W e didn’ t talk about implementation\ndetails, any features, or any particular C++ standard. W e didn’ t even talk\nabout any particular programming language. And please don’ t assume that\nby giving you the name of a design pattern I have implicitly told you how to\nimplement the solution. That is not what a design pattern is about. On the\ncontrary: the name should tell you about the structure that I propose, about\nhow I plan to manage dependencies and about how I expect the system to\nevolve. That is the intent.\nIn fact, many design patterns have a similar structure. In the GoF book,\nmany of the design patterns look very much alike, which, of course, raises a\nlot of confusion and questions. For instance, structurally , there appears to be\nalmost no dif ference between the Strategy , the Command , and the Bridge\ndesign patterns.  However , their intent is very dif ferent and you would\ntherefore use them to solve dif ferent problems. As you will see in various\nexamples in the following chapters, there are almost always many dif ferent\nimplementations you can choose from.\nA Design Pattern Introduces an Abstraction\nA design pattern always provides some way to reduce dependencies by\nintroducing some kind of abstraction. This means that a design pattern is\nalways concerned with managing the interaction between software entities\nand decoupling pieces of your software. For example, consider the  Strategy\ndesign pattern, one of the original GoF design patterns, in Figure 3-1 .\nWithout going into too much detail, the Strategy design pattern introduces\nan abstraction in the form of the Strategy base class. This base class\ndecouples the Strategy user (the Context class in the high level of your\narchitecture) from the implementation details of the concrete strategies\n(Concrete StrategyA and ConcreteStrategyB in the low level of your\narchitecture). As such, Strategy fulfills the properties of a design pattern.4\n5\nFigur e 3-1. The GoF Strategy design pattern\nA similar example is the Factory Method  design pattern (yet another GoF\ndesign pattern; see Figure 3-2 ). The intent of Factory Method  is to decouple\nfrom the creation of specific products. For that purpose, it introduces two\nabstractions in the form of the Product and Creator base classes, which\narchitecturally reside in the high level. The implementation details, given by\nmeans of the ConcreteProduct and Concrete Crea tor classes, reside on\nthe low level of the architecture. W ith this architectural structure, Factory\nMethod  also qualifies as a design pattern: it has a name, the intent to\ndecouple, and it introduces abstractions.\nFigur e 3-2. The GoF Factory Method  design pattern\nNote that the abstraction introduced by a design pattern is not necessarily\nintroduced by means of a base class. As I will show you in the following\nsections and chapters, this abstraction can be introduced in many dif ferent\nways, for instance, by means of templates or simply by function\noverloading. Again, a design pattern does not imply any specific\nimplementation.\nAs a counter example, let us consider the std::make_unique() function:\nnamespace std { \n \ntemplate< typename T, typename... Args > \nunique_ptr<T> make_unique( Args&&... args ); \n \n} // namespace std\nIn the C++ community , we often talk about the std::make_unique()\nfunction as a factory function . It’s important to note that although the term\nfactory function  gives the impression that std::make_unique() is one\nexample of the Factory Method  design pattern, this impression is incorrect.\nA design pattern helps you to decouple by introducing an abstraction, which\nallows you to customize and defer implementation details. In particular , the\nintent of the Factory Method  design pattern is to introduce a  customization\npoint  for the purpose of object instantiation. std::make_unique() does not\nprovide such a customization point : if you use std::make_unique(), you\nknow that you will get a std::unique_ptr to the type you are asking for\nand that the instance will be created by means of new:\n// This will create a 'Widget' by means of calling 'new' \nauto ptr = std::make_unique<Widget>( /* some Widget arguments */ );\nSince std::make_unique() doesn’ t provide you with any way to\ncustomize that behavior , it can’ t help to reduce coupling between entities,\nand thus it cannot serve the purpose of a design pattern.  Still,\nstd::make_unique() is a recurring solution for a specific problem. In\nother words, it is a pattern. However , it isn’ t a design pattern  but an\nimplementation pattern . It is a popular solution to encapsulate\nimplementation details (in this case, the generation of an instance of\nWidget), but it does not abstract from what you get or how it will be\ncreated. As such, it is part of the Implementation Details  level but not the\nSoftwar e Design  level (refer back to Figure 1-1 ).\nThe introduction of abstractions is the key to decoupling software entities\nfrom one another and to designing for change and extension. There is no\nabstraction in the std::make_unique() function template, and thus no way\nfor you to extend the functionality (you cannot even properly overload or\nspecialize). In contrast, the Factory Method  design pattern does provide an\nabstraction from what  is created and how this something is created\n(including actions before and after the instantiation). Due to that abstraction\nyou’ll be able to write new factories at a later point, without having to\nchange existing code. Therefore, the design pattern helps you decouple and6",9306
35-Guideline 12 Beware of Design Pattern Misconceptions.pdf,35-Guideline 12 Beware of Design Pattern Misconceptions,"extend your software, while std::make_unique() is only an\nimplementation pattern .\nA Design Pattern Has Been Proven\nLast but not least, a design pattern has been proven over the years. The\nGang of Four did not collect all possible solutions, only solutions that were\ncommonly used in dif ferent codebases to solve the same problem (although\npotentially with dif ferent implementations). Thus a solution has to\ndemonstrate its value several times before it emer ges as a pattern.\nTo summarize: a design pattern is a proven, named solution, which\nexpresses a very specific intent. It introduces some kind of abstraction,\nwhich helps to decouple software entities and thus helps to manage the\ninteraction between software entities. Just as we should use the term Design\nto denote the art of managing dependencies and decoupling (see “Guideline\n1: Understand the Importance of Software Design ”), we should use the term\nDesign Pattern  accurately and on purpose.\nGUIDELINE 11: UNDERSTAND THE PURPOSE OF\nDESIGN PATTERNS\nUnderstand that design patterns are proven, named solutions with\nan intent to decouple.\nRealize that design patterns introduce some kind of abstraction.\nKeep in mind that design patterns are tar geted at software design,\ni.e., help to manage dependencies.\nBe aware of the dif ference between design patterns and\nimplementation patterns.",1374
36-Design Patterns Are Not About Implementation Details.pdf,36-Design Patterns Are Not About Implementation Details,"Guideline 12: Beware of Design Pattern\nMisconceptions\nThe last section focused on explaining the purpose of a design pattern: the\ncombination of a name, an intent, and some form of abstraction to decouple\nsoftware entities. However , just as it’ s important to understand what a\ndesign pattern is, it’s important to understand what a design pattern is not .\nUnfortunately , there are several common misconceptions about design\npatterns:\nSome consider design patterns as a goal and as a guarantee for\nachieving good software quality .\nSome ar gue that design patterns are based on a particular\nimplementation and thus are language-specific idioms.\nSome say that design patterns are limited to object-oriented\nprogramming and dynamic polymorphism.\nSome consider design patterns outdated or even obsolete.\nThese misconceptions come as no surprise since we rarely talk about design\nbut instead focus on features and language mechanics (see “Guideline 1:\nUnderstand the Importance of Software Design ”). For that reason, I will\ndebunk the first three misconceptions in this guideline and will deal with\nthe fourth one in the next section.\nDesign Patterns Are Not a Goal\nSome developers love design patterns. They are so infatuated with them\nthat they try to solve all their problems by means of design patterns,\nwhether it is reasonable or not. Of course, this way of thinking potentially\nincreases the complexity of code and decreases comprehensibility , which\nmay prove to be counterproductive. Consequently , this overuse of design\npatterns may result in frustration in other developers, in a bad reputation of\ndesign patterns in general, or even in rejection of the general idea of\npatterns.\nTo spell it out: design patterns are not a goal. They are a means to achieve a\ngoal. They may be part of the solution. But they are not a goal. As V enkat\nSubramaniam would say: if you get up in the morning, thinking “What\ndesign pattern will I use today?”, then this is a telltale sign that you are\nmissing the purpose of design patterns.  There is no reward, no medal, for\nusing as many design patterns as possible. The use of a design pattern\nshouldn’ t create complexity but, on the contrary , decrease complexity . The\ncode should become simpler , more comprehensible, and easier to change\nand maintain, simply because the design pattern should help to resolve\ndependencies and create a better structure. If using a design pattern leads to\nhigher complexity and creates problems for other developers, it apparently\nisn’t the right solution.\nJust to be clear: I’m not telling you not to use design patterns. I’m merely\ntelling you not to overuse them, just as I would tell you not to overuse any\nother tool. It always depends on the problem. For instance, a hammer is a\ngreat tool, as long as your problem is nails. As soon as your problem\nchanges to screws, a hammer becomes a somewhat inelegant tool.  To\nproperly use design patterns, to know when to use them and when not to use\nthem, it’ s so important to have a firm grasp of them, to understand their\nintent and structural properties, and to apply them wisely .\nDesign Patterns Are Not About Implementation Details\nOne of the most common misconceptions about design patterns is that they\nare based on a specific implementation. This includes the opinion that\ndesign patterns are more or less language-specific idioms. This\nmisconception is easy to understand, as many design patterns, in particular\nthe GoF patterns, are usually presented in an  object-oriented setting and\nexplained by means of object-oriented examples. In such a context, it’ s easy\nto mistake the implementation details for a specific pattern and to assume\nthat both are the same.\nFortunately , it’s also easy to demonstrate that design patterns are not about\nimplementation details, any particular language feature, or any C++\nstandard. Let’ s take a look at dif ferent implementations of the same design7\n8\npattern. And yes, we will start with the classic, object-oriented version of\nthe design pattern.\nConsider the following scenario: we want to draw a given shape.  The code\nsnippet demonstrates this by means of a circle, but of course it could be any\nother kind of shape, like a square or a triangle. For the purpose of drawing,\nthe Circle class provides the draw() member function:\nclass Circle \n{ \n public: \n   void draw( /*...*/ );  // Implemented in terms of some graphics library \n   // ... \n};\nIt now appears self-evident that you need to implement the draw()\nfunction. W ithout further thought, you might do this by means of a common\ngraphics library such as OpenGL, Metal, Vulcan, or any other graphics\nlibrary . However , it would be a big design flaw if the Circle class provides\nan implementation of the draw() functionality itself: by implementing the\ndraw() function directly , you would introduce a strong coupling to your\nchosen graphics library . This comes with a couple of downsides:\nFor every possible application of Circle, you would always need the\ngraphics library to be available, even though you might not be\ninterested in graphics but only need it as a geometric primitive.\nEvery change to the graphics library might have an ef fect on the\nCircle class, resulting in necessary modifications, retesting,\nredeployment, etc.\nSwitching to another library in the future would mean everything but a\nsmooth transition.\nThese problems all have a common source: implementing the draw()\nfunction directly within the Circle class violates the Single-Responsibility\nPrinciple  (SRP; see “Guideline 2: Design for Change” ). The class wouldn’ t9\nchange for a single reason anymore and would strongly depend on that\ndesign decision.\nThe classic object-oriented solution for this problem is to extract the\ndecision about how to draw the circle and introduce an abstraction for that\nby means of a base class. Introducing such a  variation point  is the ef fect of\nthe Strategy design pattern (see Figure 3-3 ).\nFigur e 3-3. The Strategy  design pattern applied to drawing cir cles\nThe intent of the Strategy design pattern is to define a family of algorithms\nand encapsulate each one, therefore making them interchangeable. Strategy\nlets the algorithm vary independently from clients that use it. By\nintroducing the DrawStrategy base class, it becomes possible to easily vary\nthe draw() implementation of the given Circle. This also enables\neveryone, not just you, to implement a new drawing behavior without10\nmodifying existing code and to inject it from the outside into the Circle.\nThis is what we commonly call  dependency injection :\n#include <Circle.h> \n#include <OpenGLStrategy.h> \n#include <cstdlib> \n#include <utility> \n \nint main() \n{ \n   // ... \n \n   // Creating the desired drawing strategy for a circle. \n   auto strategy = \n      std::make_unique_ptr<OpenGLStrategy>( /* OpenGL-specific arguments */ ); \n \n   // Injecting the strategy into the circle; the circle does not have to know \n   // about the specific kind of strategy, but can with blissful ignorance use \n   // it via the 'DrawStrategy' abstraction. \n   Circle circle( 4.2, std::move(strategy) ); \n   circle.draw( /*...*/ ); \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\nThis approach vastly increases the flexibility with respect to dif ferent\ndrawing behavior: it factors out all dependencies on specific libraries and\nother implementation details and thus makes the code more changeable and\nextensible. For instance, it’ s now easily possible to provide a special\nimplementation for testing purposes (i.e., a TestStrategy). This\ndemonstrates that the improved flexibility has a very positive impact on the\ntestability of the design.\nThe Strategy design pattern is one of the classic GoF design patterns. As\nsuch, it is often referred to as an  object-oriented design pattern and is often\nconsidered to require a base class. However , the intent of Strategy is not\nlimited to object-oriented programming. Just as it’ s possible to use a base\nclass for the abstraction, it is just as easily possible to rely on a template\nparameter:",8184
37-Design Patterns Are Not Limited to Object-Oriented Programming or Dynamic Polymorphism.pdf,37-Design Patterns Are Not Limited to Object-Oriented Programming or Dynamic Polymorphism,"template< typename DrawStrategy > \nclass Circle \n{ \n public: \n   void draw( /*...*/ ); \n};\nIn this form, deciding how to draw the circle happens at compile time:\ninstead of writing a base class DrawStrategy and passing a pointer to a\nDrawStrategy at runtime, the implementation details for drawing are\nprovided by means of the DrawStrategy template ar gument. Note that\nwhile the template parameter allows you to inject the implementation\ndetails from the outside, the Circle is still not depending on any\nimplementation details. Therefore you have still decoupled the Circle class\nfrom the used graphics library . In comparison to the runtime approach,\nthough, you will have to recompile every time the DrawStrategy changes.\nWhile it’ s true that the template-based solution fundamentally changes the\nproperties of the example (i.e., no base class and no virtual functions, no\nruntime decisions, no single Circle class, but one Circle type for every\nconcrete DrawStrategy), it still implements the intent of the Strategy\ndesign pattern perfectly . Thus this demonstrates that a design pattern is not\nrestricted to a particular implementation or a specific form of abstraction.\nDesign Patterns Are Not Limited to Object-Oriented\nProgramming or Dynamic Polymorphism\nLet’s consider another use case for the Strategy design pattern: the Standard\nLibrary accumulate() function template from the <numeric> header:\nstd::vector<int> v{ 1, 2, 3, 4, 5 }; \nauto const sum = \n   std::accumulate( begin(v), end(v), int{0} );\nBy default, std::accumulate() sums up all elements in the given range.\nThe third ar gument specifies the initial value for the sum. Since\nstd::accumulate() uses the type of that ar gument as the return type, the\ntype of the ar gument is explicitly highlighted as int{0} instead of just 0 to\nprevent subtle misunderstandings. However , summing up elements is only\nthe tip of the iceber g: if you need to, you can specify how elements are\naccumulated by providing a fourth ar gument to std::accumulate(). For\ninstance, you could use std::plus or std::multiplies from the\n<functional> header:\nstd::vector<int> v{ 1, 2, 3, 4, 5 }; \nauto const sum = \n   std::accumulate( begin(v), end(v), int{0}, std::plus<>{} ); \nauto const product = \n   std::accumulate( begin(v), end(v), int{1}, std::multiplies<>{} );\nBy means of the fourth ar gument, std::accumulate() can be used for any\nkind of reduction operation,  and thus the fourth ar gument represents the\nimplementation of the reduction operation. As such, it enables us to vary\nthe implementation by injecting the details of how the reduction should\nwork from the outside. std::accumulate() therefore does not depend on a\nsingle, specific implementation but can be customized by anyone to a\nspecific purpose. This  represents exactly the intent of the Strategy design\npattern.\nstd::accumulate() draws its power from a generic form of the Strategy\ndesign pattern. Without the ability to change this behavior , it would be\nuseful in only a very limited number of use cases. Due to the Strategy\ndesign pattern, the number of possible uses is endless.\nThe example of std::accumulate() demonstrates that design patterns,\neven the classic GoF patterns, are not tied to one particular implementation\nand additionally are not limited to object-oriented programming. Clearly the\nintent of many of these patterns is also useful for other paradigms like\nfunctional or generic programming.  Therefore, design patterns are not\nlimited to dynamic polymorphism, either . On the contrary: design patterns\nwork equally well for static polymorphism and can therefore be used in\ncombination with C++ templates.1 1\n12\n13\nTo further emphasize the point and to show you an additional example of\nthe Strategy design pattern, consider the declarations for the std::vector\nand std::set class templates:\nnamespace std { \n \ntemplate< class T \n        , class Allocator = std::allocator<T> > \nclass vector; \n \ntemplate< class Key \n        , class Compare = std::less<Key> \n        , class Allocator = std::allocator<Key> > \nclass set; \n \n} // namespace std\nAll containers in the Standard Library (with the exception of std::array)\nprovide you with the opportunity to specify a custom allocator . In the case\nof std::vector it’s the second template ar gument, and for std::set it’s\nthe third ar gument. All memory requests from the container are handled via\nthe given allocator .\nBy exposing a template ar gument for the allocator , the Standard Library\ncontainers give you the opportunity to customize memory allocation from\nthe outside. They enable you to define a family of algorithms (in earlier\ncase, an algorithm for the memory acquisition) and encapsulate each one\nand therefore make them interchangeable. Consequently you’re able to vary\nthis algorithm independently from clients (in this case, the containers) that\nuse it.\nHaving read that description, you should recognize the Strategy design\npattern. In this example, Strategy is again based on static polymorphism and\nimplemented by means of a template ar gument. Clearly , Strategy is not\nlimited to dynamic polymorphism.\nWhile  it’s obviously true that design patterns in general aren’ t limited to\nobject-oriented programming or dynamic polymorphism, I should still\nexplicitly state that there are some design patterns whose intent is tar geted14\nto alleviate the usual problems in object-oriented programming (e.g., the\nVisitor  and Prototype  design patterns).  And of course there are also\ndesign patterns focused on functional programming or generic\nprogramming (e.g., the Curiously Recurring T emplate Pattern  [CRTP] and\nExpr ession T emplates ). While most design patterns are not paradigm\ncentric and their intention can be used in a variety of implementations,\nsome are more specific.\nIn the upcoming chapters, you’ll see examples for both categories. Y ou will\nsee design patterns that have a very general intent and are consequently of\ngeneral usefulness. Additionally , you will see some design patterns that are\nmore paradigm-specific and, due to that, will fail to be useful outside of\ntheir tar get domain. Still, they all have the main characteristics of design\npatterns in common: a name, an intent, and some form of abstraction.\nIn summary: design patterns are not limited to object-oriented\nprogramming, nor are they limited to dynamic polymorphism. More\nspecifically , design patterns are not about a particular implementation and\nthey are not language-specific idioms. Instead, they are focused entirely on\nthe intent to decouple software entities in a specific way .\nGUIDELINE 12: BEWARE OF DESIGN PATTERN\nMISCONCEPTIONS\nConsider design patterns as a tool to solve a design problem, not as\na goal.\nBe aware that design patterns are not limited to object-oriented\nprogramming.\nBear in mind that design patterns are not limited to dynamic\npolymorphism.\nUnderstand that design patterns are not language-specific idioms.15\n16",7061
38-Guideline 13 Design Patterns Are Everywhere.pdf,38-Guideline 13 Design Patterns Are Everywhere,"Guideline 13: Design Patterns Are\nEverywhere\nThe previous section has demonstrated that design patterns are not limited\nto object-oriented programming or dynamic polymorphism, that they are\nnot language-specific idioms, and that they are not about a particular\nimplementation. Still, due to these common misconceptions and because we\ndon’t consider C++ as solely object-oriented programming language\nanymore, some people even claim that design patterns are outdated or\nobsolete.\nI imagine you’re now looking a little skeptical. “Obsolete? Isn’ t that a little\nexaggerated?” you ask. W ell, unfortunately not. T o tell a little war story , in\nearly 2021 I had the honor of giving a virtual talk about design patterns in a\nGerman C++ user group. My main objective was to explain what design\npatterns are and that they are very much in use today . During the talk, I felt\ngood, invigorated in my mission to help people see all the benefits of design\npatterns, and I sure gave my best to make everybody see the light that\nknowledge about design patterns brings. Still, a few days after the\npublication of the talk on Y ouTube, a user commented on the talk with\n“Really? Design Patterns in 2021?”\nI very much hope that you are now shaking your head in disbelief. Y es, I\ncould not believe it either , especially after having shown that there are\nhundreds of examples for design patterns in the C++ Standard Library . No,\ndesign patterns are neither outdated nor obsolete. Nothing could be further\nfrom the truth. To prove that design patterns are still very much alive and\nrelevant, let’ s consider the updated allocators facility in the C++ Standard\nLibrary . Take a look at the following code example that uses allocators from\nthe std::pmr (polymorphic memory r esour ce) namespace:\n \n#include <array> \n#include <cstddef> \n#include <cstdlib> \n#include <memory_resource> \n#include <string> 17\n#include <vector> \n \nint main() \n{ \n   std::array<std::byte,1000> raw;  // Note: not initialized!  \n \n \n   std::pmr::monotonic_buffer_resource \n      buffer{ raw.data(), raw.size(), std::pmr::null_memory_resource() };  \n \n \n   std::pmr::vector<std::pmr::string> strings{ &buffer };  \n \n \n   strings.emplace_back( ""String longer than what SSO can handle"" ); \n   strings.emplace_back( ""Another long string that goes beyond SSO"" ); \n   strings.emplace_back( ""A third long string that cannot be handled by SSO"" \n); \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nThis example demonstrates how to use a\nstd::pmr::monotonic_buffer_resource  as allocator to redirect all\nmemory allocations into a predefined byte buf fer. Initially we are creating a\nbuffer of 1,000 bytes in the form of a std::array (\n). This buf fer is\nprovided as a source of memory to a\nstd::pmr::monotonic_buffer_resource  by means of passing a pointer\nto the first element (via raw.data()) and the size of the buf fer (via\nraw.size()) (\n).\nThe third ar gument to the monotonic_buffer_resource represents a\nbackup allocator , which is used in case the monotonic_buffer_resource\nruns out of memory . Since we don’ t need additional memory in this case,\nwe use the std::pmr::null _mem ory_resource()  function, which gives us\na pointer to the standard allocator that always fails to allocate. That means\nthat you can ask as nicely as you want, but the allocator returned by\nstd::pmr::null_memory_resource()  will always throw an exception\nwhen you ask for memory .\nThe created buf fer is passed as allocator to the strings vector , which will\nnow acquire all its memory from the initial byte buf fer (\n ). Furthermore,\nsince the vector forwards the allocator to its elements, even the three\nstrings, which we add by means of the emplace_back() function and\nwhich are all too long to rely on the  Small String Optimization (SSO) , will\nacquire all their memory from the byte buf fer. Thus, no dynamic memory is\nused in the entire example; all memory will be taken from the byte array .\nAt first glance, this example doesn’ t look like it requires any design pattern\nto work. However , the allocator functionality used in this example uses at\nleast four dif ferent design patterns: the T emplate Method design pattern, the\nDecorator design pattern, the Adapter design pattern, and (again) the\nStrategy design pattern.\nThere are even five design pattern if you count the Singleton  pattern: the\nnull _mem ory_resource() function (\n ) is implemented in terms of the\nSingleton  pattern:  it returns a pointer to a static storage duration object,\nwhich is used to guarantee that there is at most one instance of this\nallocator .\nAll C++ allocators from the pmr namespace, including the allocator\nreturned by null_memory_resource() and the\nmonotonic_buffer_resource, are derived from the\nstd::pmr::memory_resource base class. The first design pattern becomes\nvisible if you look at the memory_resource class definition:\nnamespace std::pmr { \n \nclass memory_resource \n{ \n public: \n   // ... a virtual destructor, some constructors and assignment operators \n \n   [[nodiscard]] void* allocate(size_t bytes, size_t alignment); \n   void deallocate(void* p, size_t bytes, size_t alignment); \n   bool is_equal(memory_resource const& other) const noexcept; \n \n private: \n   virtual void* do_allocate(size_t bytes, size_t alignment) = 0; \n   virtual void do_deallocate(void* p, size_t bytes, size_t alignment) = 0; \n   virtual bool do_is_equal(memory_resource const& other) const noexcept = 0; \n}; 18\n19\n \n} // namespace std::pmr\nYou may notice that the three functions in the public section of the class\nhave a virtual counterpart in the private section of the class. Whereas the\npublic allocate(), deallocate(), and is_equal() functions represent\nthe user -facing interface of the class, the do_allocate(),\ndo_deallocate(), and do_is_equal() functions represent the interface\nfor derived classes. This separation of concerns is an example of the Non-\nVirtual Interface (NVI)  idiom, which itself is an example of the  Template\nMethod  design pattern.\nThe second design pattern we implicitly use is the Decorator design\npattern.  Decorator helps you to build a hierarchical layer of allocators and\nto wrap and extend the functionality of one allocator to another . This idea\nbecomes clearer in this line:\nstd::pmr::monotonic_buffer_resource \n   buffer{ raw.data(), raw.size(), std::pmr::null_memory_resource() };\nBy passing the allocator returned by the null_memory_resource()\nfunction to the monotonic_buffer_resource, we decorate its\nfunctionality . Whenever we ask the monotonic_buffer_resource for\nmemory via the allocate() function, it may forward the call to its backup\nallocator . This way , we can implement many dif ferent kinds of allocators,\nwhich in turn can be easily assembled to form a complete memory\nsubsystem with dif ferent layers of allocation strategies. This kind of\ncombining and reusing pieces of functionality is the strength of the\nDecorator design pattern.\nYou may have noticed that in the example code we have used\nstd::pmr::vector and std::pmr::string. I assume you remember that\nstd::string is just a type alias to std::basic_string<char>. Knowing\nthat, it probably comes as no surprise that the two types in the pmr\nnamespace are also just type aliases:20\n21\nnamespace std::pmr { \n \ntemplate< class CharT, class Traits = std::char_traits<CharT> > \nusing basic_string = \n   std::basic_string< CharT, Traits, \n                      std::pmr::polymorphic_allocator<CharT> >; \n \ntemplate <class T> \nusing vector = \n   std::vector< T, std::pmr::polymorphic_allocator<T> >; \n \n} // namespace std::pmr\nThese type aliases still refer to the regular std::vector and\nstd::basic_string classes but do not expose a template parameter for an\nallocator anymore. Instead, they employ a\nstd::pmr::polymorphic_allocator  as allocator . This is an example of\nthe Adapter design pattern.  The intent of an Adapter is to help you to glue\ntwo nonfitting interfaces together . In this case, the\npolymorphic_allocator helps to transmit between the classic, static\ninterface required from the classic C++ allocators and the new , dynamic\nallocator interface required by std::pmr::memory_resource.\nThe fourth and last design pattern used in our example is, again, the\nStrategy design pattern. By exposing a template ar gument for the allocator ,\nStandard Library containers like std::vector and std::string give you\nthe opportunity to customize memory allocation from outside. This is a\nstatic form of the Strategy design pattern and has the same intent as\ncustomizing algorithms (see also “Guideline 12: Beware of Design Pattern\nMisconceptions” ).\nThis example impressively demonstrates, that design patterns are far from\nbeing obsolete. On closer examination, we see them everywhere: any kind\nof abstraction and any attempt to decouple software entities and introduce\nflexibility and extensibility is very likely based on some design pattern. For\nthat reason, it definitely helps to know about the dif ferent design patterns\nand to understand their intent to recognize them and apply them whenever it\nis necessary and appropriate.22",9252
39-Guideline 14 Use a Design Patterns Name to Communicate Intent.pdf,39-Guideline 14 Use a Design Patterns Name to Communicate Intent,"GUIDELINE 13: DESIGN PATTERNS ARE EVERYWHERE\nUnderstand that any kind of abstraction and any attempt to\ndecouple likely represents a known design pattern.\nLearn about the dif ferent design patterns and understand their\nintent to decouple.\nApply design patterns based on their intent whenever necessary .\nGuideline 14: Use a Design Pattern’s Name\nto Communicate Intent\nIn the last two sections, you learned what a design pattern is, what it’ s not,\nand that design patterns are everywhere. Y ou also learned that every design\npattern has a name, which expresses a clear , concise, and unambiguous\nintent. Hence, the name carries meaning.  By using the name of a design\npattern you can express what the problem is and which solution you’ve\nchosen to solve the problem, and you can describe how the code is expected\nto evolve.\nConsider , for instance, the Standard Library accumulate() function:\ntemplate< class InputIt, class T, class BinaryOperation > \nconstexpr T accumulate( InputIt first, InputIt last, T init, \n                        BinaryOperation op );\nThe third template parameter is named BinaryOperation. While this does\ncommunicate the fact that the passed callable is required to take two\narguments, the name does not communicate the intent of the parameter . To\nexpress the intent more clearly , consider calling it\nBinaryReductionStrategy:\ntemplate< class InputIt, class T, class BinaryReductionStrategy > \nconstexpr T accumulate( InputIt first, InputIt last, T init, 23\n                        BinaryReductionStrategy op );\nBoth the term Reduction  and the name Strategy  carry meaning for every\nC++ programmer . Therefore, you’ve now captured and expressed your\nintent much more clearly: the parameter enables dependency injection  of a\nbinary operation, which allows you to specify how the reduction operation\nworks. Therefore, the parameter solves the problem of customization. Still,\nas you will see in Chapter 5 , the Strategy design pattern communicates that\nthere are certain expectations for the operation. Y ou can only specify how\nthe reduction operation works; you cannot redefine what accumulate()\ndoes. If that’ s what you want to express, you should use the name of the\nCommand  design pattern:\ntemplate< class InputIt, class UnaryCommand > \nconstexpr UnaryCommand \n   for_each( InputIt first, InputIt last, UnaryCommand f );\nThe std::for_each() algorithm allows you to apply any kind of unary\noperation to a range of elements. T o express this intent, the second template\nparameter could be named UnaryCommand, which unambiguously expresses\nthat there are (nearly) no expectations for the operation.\nAnother example from the Standard Library shows how much value the\nname of a design pattern can bring to a piece of code:\n \n#include <cstdlib> \n#include <iostream> \n#include <string> \n#include <variant> \n \nstruct Print \n{ \n   void operator()(int i) const { \n      std::cout << ""int: "" << i << '\n'; \n   } \n   void operator()(double d) const { \n      std::cout << ""double: "" << d << '\n'; \n   } \n   void operator()(std::string const& s) const { 24\n      std::cout << ""string: "" << s << '\n'; \n   } \n}; \n \nint main() \n{ \n   std::variant<int,double,std::string> v{};  \n \n \n   v = ""C++ Variant example"";  \n \n \n   std::visit(Print{}, v);  \n \n \n   return EXIT_SUCCESS; \n} \nIn the main() function, we create a std::variant for the three alternatives\nint, double, and std::string (\n). In the next line, we assign a C-style\nstring literal, which will be converted to a std::string inside the variant (\n). Then we print the content of the variant via the std::visit() function\nand the Print function object (\n ).\nNotice the name of the std::visit() function. The name directly refers to\nthe Visitor  design pattern and therefore clearly expresses its intent: you’re\nable to apply any operation to the closed set of types contained in the\nvariant instance.  Also, you can extend the set of operations\nnonintrusively .\nYou see that using the name of a design pattern carries more information\nthan using an arbitrary name. Still, this shouldn’ t imply that naming is\neasy. A name should primarily help you understand the code in a specific\ncontext. If the name of a design pattern can help with that, then consider\nincluding the design pattern name to express your intent.25\n26\nGUIDELINE 14: USE A DESIGN PATTERN’S NAME TO\nCOMMUNICATE INTENT\nUse the name of a design pattern to communicate the intent of a\nsolution.\nUse the name of a design pattern to improve readability .\n1 The Gang of Four , or simply GoF , is a commonly used reference to the four authors Erich\nGamma, Richard Helm, Ralph E. Johnson, and John Vlissides and their book on design\npatterns: Design Patterns: Elements of Reusable Object-Oriented Softwar e (Prentice Hall). The\nGoF book still is, after several decades, the reference on design patterns. Throughout the rest of\nthis book, I will refer to either the GoF book, the GoF patterns, or the characteristic, object-\noriented GoF style.\n2 If you do not know the Visitor  design pattern yet, don’ t worry . I will introduce the pattern in\nChapter 4 .\n3 The Strategy design pattern will be explained in detail in Chapter 5 , the Decorator design\npattern in Chapter 9 .\n4 I mention only the design patterns that I will explain in later chapters (see the Strategy and\nCommand  design patterns in Chapter 5  and the Bridge  design pattern in “Guideline 28: Build\nBridges to Remove Physical Dependencies ”). There are a few more design patterns that share\nthe same structure.\n5 If you are unfamiliar with the Strategy design pattern, rest assured that Chapter 5  will provide\nmuch more information, including several code examples.\n6 This may be a controversial example. Since I know the C++ community , I know that you may\nhave a dif ferent opinion. However , I stand by mine: due to its definition, std::make_unique()\nis incapable of decoupling software entities and therefore does not play a role on the level of\nsoftware design. It’ s merely an implementation detail (but a valuable and useful one).\n7 Venkat Subramaniam and Andrew Hunt, Practices of an Agile Developer  (The Pragmatic\nProgrammers, LLC, 2017).\n8 Well, it works, in some definition of “works.”\n9 I know what you’re thinking: “Y ou cannot be serious! There is so many interesting examples\nout there, but you select the oldest and most boring example in the book!” OK, I admit that\nmight not be the most exciting example to pick. But, still, I have two good reasons to use this\nexample. First, the scenario is so well known that I can assume that no one has trouble\nunderstanding it. That means that everyone should be able to follow my ar guments about\nsoftware design. And second, let’ s agree that it’ s kind of a tradition in computer science to start\nwith a shape or an animal example. And, of course, I do not want to disappoint traditionalists.\n10 Chapter 5  will provide a complete and thorough introduction of the Strategy  design pattern.\n1 1 You may (correctly) observe that even without the fourth ar gument you could change how the\naccumulation works by providing a custom addition operator (i.e., operator+()) for the given\ntype. However , that is only of limited use. While you can provide a custom addition operator\nfor user -defined types, you cannot provide a custom addition operator for fundamental types\n(such as the int in the example). Also, it’ s very questionable to define operator+() for\nanything other than an addition operation (or related operations like the concatenation of\nstrings). Thus, relying on the addition operator would be limiting technically and semantically .\n12 In his CppCon 2016 talk “std::accumulate: Exploring an Algorithmic Empire” , Ben Deane\nhas impressively demonstrated how powerful std::accumulate() is thanks to that fourth\nargument.\n13 For more information about STL algorithms and their functional programming heritage, see\nIvan Cukic’ s excellent introduction to Functional Pr ogramming in C++  (Manning).\n14 Another commonly used name for that form of the Strategy design pattern is Policy-Based\nDesign ; see “Guideline 19: Use Strategy to Isolate How Things Are Done” .\n15 I will explain the Visitor  design pattern in Chapter 4  and the Prototype  design pattern in\n“Guideline 30: Apply Prototype for Abstract Copy Operations” .\n16 Again, I’m referring you to Ivan Cukic’ s introduction to Functional Pr ogramming in C++ .\nThe CRTP  design pattern will be the topic of “Guideline 26: Use CR TP to Introduce Static\nType Categories” . For information on Expr ession T emplates , a template-based pattern, refer to\nthe C++ template reference: David V andevoorde, Nicolai Josuttis, and Douglas Gregor ’s C++\nTemplates: The Complete Guide  (Addison-W esley).\n17 I would ar gue that C++ has been a multiparadigm programming language since the moment\nthe first implementation of templates was added to the language in 1989. The impact of\ntemplates on the language became clear with the addition of part of the Standard T emplate\nLibrary (STL) to the Standard Library in 1994. Since then, C++ has provided object-oriented,\nfunctional, and generic capabilities.\n18 The Small String Optimization (SSO)  is a common optimization for small strings. Instead of\nallocating dynamic memory on the heap via the provided allocator , the string would store the\nsmall number of characters directly into the stack part of the string. Since a string usually\noccupies between 24 and 32 bytes on the stack (which is not a C++ standard requirement but a\nproperty of common implementations of std::string), anything beyond 32 bytes will require\na heap allocation. That is the case with the three given strings.\n19 Singleton  is one of the original 23 GoF design patterns. But I will do my best in “Guideline\n37: T reat Singleton as an Implementation Pattern, Not a Design Pattern”  to convince you that\nSingleton  is not actually a  design pattern but an implementation detail. For that reason, I will\nrefer to Singleton  not as a design pattern but simply as an implementation pattern.\n20 Unfortunately , I won’ t cover the Template Method  design pattern in this book. This isn’ t\nbecause it’ s not important but simply due to a lack of available pages. Please refer to the GoF\nbook for more details.\n21 I will give a complete introduction of the  Decorator design pattern in Chapter 9 .\n22 The Adapter design pattern will be the topic of “Guideline 24: Use Adapters to Standardize\nInterfaces” .\n23 Good names always carry meaning. This is why they are so fundamentally important.\n24 I will explain the Command  design pattern alongside the Strategy design pattern in Chapter 5 .\n25 The Visitor  design pattern, including the modern implementation with std::variant, will be\nour focus in Chapter 4 .\n26 Naming is hard, as Kate Gregory aptly remarks in her highly recommended talk “Naming Is\nHard: Let’ s Do Better”  at CppCon 2019.",11050
40-Guideline 15 Design for the Addition of Types or Operations.pdf,40-Guideline 15 Design for the Addition of Types or Operations,"Chapter 4. The V isitor Design\nPattern\nThis entire chapter is focused on the Visitor  design pattern. If you’ve\nalready heard about the V isitor design pattern or even used it in your own\ndesigns, you might be wondering why I have chosen V isitor as the first\ndesign pattern to explain in detail. Y es, V isitor is definitely not one of the\nmost glamorous design patterns. However , it will definitely serve as a great\nexample to demonstrate the many options you have when implementing a\ndesign pattern and how dif ferent these implementations can be. It will also\nserve as an ef fective example of advertising the advantages of modern C++.\nIn “Guideline 15: Design for the Addition of Types or Operations ”, we first\ntalk about the fundamental design decision you’ll need to make when\nwalking in the realm of dynamic polymorphism: focus on either types or\noperations. In that guideline, we will also talk about the intrinsic strengths\nand weaknesses of programming paradigms.\nIn “Guideline 16: Use V isitor to Extend Operations” , I will introduce you to\nthe V isitor design pattern. I will explain its intent to extend operations\ninstead of types, and show you both the advantages and the shortcomings of\nthe classic V isitor pattern.\nIn “Guideline 17: Consider std::variant for Implementing V isitor ”, you will\nmake  the acquaintance of the modern implementation of the V isitor design\npattern. I will introduce you to std::variant and explain the many\nadvantages of that particular implementation.\nIn “Guideline 18: Beware the Performance of Acyclic V isitor” , I will\nintroduce you to the Acyclic V isitor . At first glance, this approach appears to\nresolve some fundamental problems of the V isitor pattern, but on closer\ninspection we will find that the runtime overhead may disqualify this\nimplementation.",1841
41-A Procedural Solution.pdf,41-A Procedural Solution,"Guideline 15: Design for the Addition of\nTypes or Operations\nTo you, the term dynamic polymorphism  may sound like a lot of freedom. It\nmay feel similar to when you were still a kid: endless possibilities, no\nlimitations! W ell, you have grown older and faced reality: you can’ t have\neverything, and there is always a choice to be made. Unfortunately , it’s\nsimilar with dynamic polymorphism. Despite the fact that it sounds like\ncomplete freedom, there is a limiting choice: do you want to extend types or\noperations?\nTo see what I mean, let’ s return to the scenario from Chapter 3 : we want to\ndraw a given shape.  We stick to dynamic polymorphism, and for our initial\ntry, we implement this problem with good old procedural programming.\nA Procedural Solution\nThe first header file Point.h provides a fairly simple Point class. This will\nmainly serve to make the code complete, but also gives us the idea that\nwe’re dealing with 2D shapes:\n//---- <Point.h> ---------------- \n \nstruct Point \n{ \n   double x; \n   double y; \n};\nThe second conceptual header file Shape.h proves to be much more\ninteresting:\n \n//---- <Shape.h> ---------------- \n \nenum ShapeType  \n \n{ \n   circle, \n   square 1\n}; \n \nclass Shape  \n \n{ \n protected: \n   explicit Shape( ShapeType type ) \n      : type_( type )  \n \n   {} \n \n public: \n   virtual ~Shape() = default;  \n \n \n   ShapeType getType() const { return type_; }  \n \n \n private: \n   ShapeType type_;  \n \n}; \nFirst, we introduce the enumeration ShapeType, which currently lists the\ntwo enumerators, circle and square (\n). Apparently , we are initially\ndealing with only circles and squares. Second, we introduce the class Shape\n(\n). Given the protected constructor and the virtual destructor (\n ), you can\nanticipate that Shape is supposed to work as a base class. But that’ s not the\nsurprising detail about Shape: Shape has a data member of type ShapeType\n(\n). This data member is initialized via the constructor (\n ) and can be\nqueried via the getType() member function (\n ). Apparently , a Shape stores\nits type in the form of the ShapeType enumeration.\nOne example of the use of the Shape base class is the Circle class:\n \n//---- <Circle.h> ---------------- \n \n#include <Point.h> \n#include <Shape.h> \n \nclass Circle : public Shape  \n \n{ \n public: \n   explicit Circle( double radius ) \n      : Shape( circle )  \n \n      , radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   double radius() const { return radius_; } \n   Point  center() const { return center_; } \n \n private: \n   double radius_; \n   Point center_{}; \n}; \nCircle publicly inherits from Shape (\n), and for that reason, and due to the\nlack of a default constructor in Shape, needs to initialize the base class (\n ).\nSince it’ s a circle, it uses the circle enumerator as an ar gument to the base\nclass constructor .\nAs stated before, we want to draw shapes. W e therefore introduce the\ndraw() function for circles. Since we don’ t want to couple too strongly to\nany implementation details of drawing, the draw() function is declared in\nthe conceptual header file DrawCircle.h and defined in the corresponding\nsource file:\n//---- <DrawCircle.h> ---------------- \n \nclass Circle; \n \nvoid draw( Circle const& ); \n \n \n//---- <DrawCircle.cpp> ---------------- \n \n#include <DrawCircle.h> \n#include <Circle.h> \n#include /* some graphics library */ \n \nvoid draw( Circle const& c ) \n{ \n   // ... Implementing the logic for drawing a circle \n}\nOf course, there are not only circles. As indicated by the square\nenumerator , there is also a Square class:\n \n//---- <Square.h> ---------------- \n \n#include <Point.h> \n#include <Shape.h> \n \nclass Square : public Shape  \n \n{ \n public: \n   explicit Square( double side ) \n      : Shape( square )  \n \n      , side_( side ) \n   { \n      /* Checking that the given side length is valid */ \n   } \n \n   double side  () const { return side_; } \n   Point  center() const { return center_; } \n \n private: \n   double side_; \n   Point center_{};  // Or any corner, if you prefer \n}; \n \n \n//---- <DrawSquare.h> ---------------- \n \nclass Square; \n \nvoid draw( Square const& ); \n \n \n//---- <DrawSquare.cpp> ---------------- \n \n#include <DrawSquare.h> \n#include <Square.h> \n#include /* some graphics library */ \n \nvoid draw( Square const& s ) \n{ \n   // ... Implementing the logic for drawing a square \n} \nThe Square class looks very similar to the Circle class (\n ). The major\ndifference is that a Square initializes its base class with the square\nenumerator (\n ).\nWith both circles and squares available, we now want to draw an entire\nvector of dif ferent shapes. For that reason, we introduce the\ndrawAllShapes() function:\n \n//---- <DrawAllShapes.h> ---------------- \n \n#include <memory> \n#include <vector> \nclass Shape; \n \nvoid drawAllShapes( std::vector<std::unique_ptr<Shape>> const& shapes );  \n \n \n \n//---- <DrawAllShapes.cpp> ---------------- \n \n#include <DrawAllShapes.h> \n#include <Circle.h> \n#include <Square.h> \n \nvoid drawAllShapes( std::vector<std::unique_ptr<Shape>> const& shapes ) \n{ \n   for( auto const& shape : shapes ) \n   { \n      switch( shape->getType() )  \n \n      { \n         case circle: \n            draw( static_cast<Circle const&>( *shape ) ); \n            break; \n         case square: \n            draw( static_cast<Square const&>( *shape ) ); \n            break; \n      } \n   } \n} \ndrawAllShapes() takes a vector of shapes in the form of\nstd::unique_ptr<Shape> (\n). The pointer to the base class is necessary to\nhold dif ferent kinds of concrete shapes, and the std::unique_ptr in\nparticular to automatically manage the shapes via the RAII idiom . Inside the\nfunction, we start by traversing the vector in order to draw every shape.\nUnfortunately , all we have at this point are Shape pointers. Therefore, we\nhave to ask every shape nicely by means of the getType() function (\n ):\nwhat kind of shape are you? If the shape replies with circle, we know that\nwe have to draw it as a Circle and perform the corresponding\nstatic_cast. If the shape replies with square, we draw it as a Square.\nI can feel that you’re not particularly happy about this solution. But before\ntalking about the shortcomings, let’ s consider the main() function:\n//---- <Main.cpp> ---------------- \n \n#include <Circle.h> \n#include <Square.h> \n#include <DrawAllShapes.h> \n#include <memory> \n#include <vector> \n \nint main() \n{ \n   using Shapes = std::vector<std::unique_ptr<Shape>>; \n \n   // Creating some shapes \n   Shapes shapes; \n   shapes.emplace_back( std::make_unique<Circle>( 2.3 ) ); \n   shapes.emplace_back( std::make_unique<Square>( 1.2 ) ); \n   shapes.emplace_back( std::make_unique<Circle>( 4.1 ) ); \n \n   // Drawing all shapes \n   drawAllShapes( shapes ); \n \n   return EXIT_SUCCESS; \n}\nIt works! W ith this main() function, the code compiles and draws three\nshapes (two circles and a square). Isn’ t that great? It is, but it won’ t stop\nyou from going into a rant: “What a primitive solution! Not only is the\nswitch a bad choice for distinguishing between dif ferent kinds of shapes,\nbut it also doesn’ t have a default case! And who had this crazy idea to\nencode the type of the shapes by means of an unscoped enumeration?”\nYou’re looking suspiciously in my direction…\nWell, I can understand your reaction. But let’ s analyze the problem in a\nlittle more detail. Let me guess: you remember “Guideline 5: Design for\nExtension” . And you now imagine what you would have to do to add a third2\nkind of shape. First, you would have to extend the enumeration. For\ninstance, we would have to add the new enumerator triangle (\n):\n \nenum ShapeType \n{ \n   circle, \n   square, \n   triangle  \n \n}; \nNote that this addition would have an impact not only on the switch\nstatement in the drawAllShapes() function (it is now truly incomplete),\nbut also on all classes derived from Shape (Circle and Square). These\nclasses depend on the enumeration since they depend on the Shape base\nclass and also use the enumeration directly . Therefore, changing the\nenumeration would result in a recompilation of all your source files.\nThat should strike you as a serious issue. And it is indeed. The heart of the\nproblem is the direct dependency of all shape classes and functions on the\nenumeration. Any change to the enumeration results in a ripple ef fect that\nrequires the dependent files to be recompiled. Obviously , this directly\nviolates the Open-Closed Principle (OCP) (see “Guideline 5: Design for\nExtension” ). This doesn’ t seem right: adding a Triangle shouldn’ t result in\na recompilation of the Circle and Square classes.\nThere is more, though. In addition to actually writing a Triangle class\n(something that I leave to your imagination), you have to update the switch\nstatement to handle triangles (\n ):\n \nvoid drawAllShapes( std::vector<std::unique_ptr<Shape>> const& shapes ) \n{ \n   for( auto const& shape : shapes ) \n   { \n      switch( shape->getType() ) \n      { \n         case circle: \n            draw( static_cast<Circle const&>( *shape ) ); \n            break;",9325
42-An Object-Oriented Solution.pdf,42-An Object-Oriented Solution,"case square: \n            draw( static_cast<Square const&>( *shape ) ); \n            break; \n         case triangle:  \n \n            draw( static_cast<Triangle const&>( *shape ) ); \n            break; \n      } \n   } \n} \nI can imagine your outcry: “Copy-and-paste! Duplication!” Y es, in this\nsituation it is very likely that a developer will use copy-and-paste to\nimplement the new logic. It’ s just so convenient because the new case is so\nsimilar to the previous two cases. And indeed, this is an indication that the\ndesign could be improved. However , I see a far more serious flaw: I would\nassume that in a lar ger codebase, this is not the only switch statement. On\nthe contrary , there will be others that need to be updated as well. How many\nare there? A dozen? Fifty? Over a hundred? And how do you find all of\nthese? OK, so you ar gue that the compiler would help you with this task.\nPerhaps with the switches, yes, but what if there are also if-else-if cascades?\nAnd then, after this update marathon, when you think you are done, how do\nyou guarantee that you have truly updated all the necessary sections?\nYes, I can understand your reaction and why you prefer not to have this\nkind of code: this explicit handling of types is a maintenance nightmare. T o\nquote Scott Meyers:\nThis kind of type-based pr ogramming has a long history in C, and one of\nthe things we know about it is that it yields pr ograms that ar e essentially\nunmaintainable.\nAn Object-Oriented Solution\nSo let me ask: what would you have done? How would you have\nimplemented the drawing of shapes? Well, I can imagine you would have\nused an object-oriented approach. That means you would scratch the\nenumeration and add a pure virtual draw() function to the Shape base class.\nThis way , Shape doesn’ t have to remember its type anymore:3\n//---- <Shape.h> ---------------- \n \nclass Shape \n{ \n public: \n   Shape() = default; \n \n   virtual ~Shape() = default; \n \n   virtual void draw() const = 0; \n};\nGiven this base class, derived classes now would have to implement only\nthe draw() member function (\n ):\n \n//---- <Circle.h> ---------------- \n \n#include <Point.h> \n#include <Shape.h> \n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   double radius() const { return radius_; } \n   Point  center() const { return center_; } \n \n   void draw() const override;  \n \n \n private: \n   double radius_; \n   Point center_{}; \n}; \n \n \n//---- <Circle.cpp> ---------------- \n \n#include <Circle.h> \n#include /* some graphics library */ \n \nvoid Circle::draw() const \n{ \n   // ... Implementing the logic for drawing a circle \n} \n \n \n//---- <Square.h> ---------------- \n \n#include <Point.h> \n#include <Shape.h> \n \nclass Square : public Shape \n{ \n public: \n   explicit Square( double side ) \n      : side_( side ) \n   { \n      /* Checking that the given side length is valid */ \n   } \n \n   double side  () const { return side_; } \n   Point  center() const { return center_; } \n \n   void draw() const override;  \n \n \n private: \n   double side_; \n   Point center_{}; \n}; \n \n \n//---- <Square.cpp> ---------------- \n \n#include <Square.h> \n#include /* some graphics library */ \n \nvoid Square::draw() const \n{ \n   // ... Implementing the logic for drawing a square \n} \nOnce the virtual draw() function is in place and implemented by all derived\nclasses, it can be used to refactor the drawAllShapes() function:\n//---- <DrawAllShapes.h> ---------------- \n \n#include <memory> \n#include <vector> \nclass Shape; \n \nvoid drawAllShapes( std::vector< std::unique_ptr<Shape> > const& shapes ); \n \n \n//---- <DrawAllShapes.cpp> ---------------- \n \n#include <DrawAllShapes.h> \n#include <Shape.h> \n \nvoid drawAllShapes( std::vector< std::unique_ptr<Shape> > const& shapes ) \n{ \n   for( auto const& shape : shapes ) \n   { \n      shape->draw(); \n   } \n}\nI can see you relax and start smiling again. This is so much nicer , so much\ncleaner . While I understand that you prefer this solution and that you would\nlike to stay in this comfort zone a little while longer , I unfortunately have to\npoint out a flaw . Yes, this solution might also come with a disadvantage.\nAs indicated in the introduction to this section, with an object-oriented\napproach, we are now able to add new types very easily . All we have to do\nis write a new derived class. W e don’ t have to modify or recompile any\nexiasting code (with the exception of the main() function). That  perfectly\nfulfills the OCP . However , did you notice that we are not able to easily add\noperations anymore? For instance, let’ s assume we need a virtual\nserialize() function to convert a Shape into bytes. How can we add this\nwithout modifying existing code? How can anyone easily add this operation\nwithout having to touch the Shape base class?\nUnfortunately , that isn’ t possible anymore. W e are now dealing with a\nclosed set  of operations, which means that we violate the OCP in relation to\naddition operations. T o add a virtual function, the base class needs to be\nmodified, and all derived classes (circles, squares, etc.) need to implement\nthe new function, even though the function might never be called. In",5399
43-Be Aware of the Design Choice in Dynamic Polymorphism.pdf,43-Be Aware of the Design Choice in Dynamic Polymorphism,"summary , the object-oriented solution fulfills the OCP with respect to\nadding types but violates it in relation to operations.\nI know you thought we left the procedural solution behind for good, but\nlet’s take a second look. In the procedural approach, adding a new operation\nwas actually very simple. New operations could be added in the form of\nfree functions or separate classes, for instance. It wasn’ t necessary to\nmodify the Shape base class or any of the derived classes. Thus in the\nprocedural solution, we have fulfilled the OCP with respect to adding\noperations. But as we’ve seen, the procedural solution violates the OCP in\nrelation to adding types. Thus, it appears to be an inversion of the object-\noriented solution, which is the other way around.\nBe A ware of the Design Choice in Dynamic\nPolymorphism\nThe takeaway of this example is that there is a design choice when using\ndynamic polymorphism: either you can add types easily by fixing the\nnumber of operations or you can add operations easily by fixing the number\nof types. Thus, the OCP has two dimensions: when designing software, you\nhave to make a conscious decision about which kind of extension you\nexpect.\nThe strength of object-oriented programming is the easy addition of new\ntypes, but its weakness is that the addition of operations becomes much\nmore dif ficult. The strength of procedural programming is the easy addition\nof operations, but adding types is a real pain ( Table 4-1 ). It depends on your\nproject: if you expect new types will be added frequently , rather than\noperations, you should strive for an OCP solution, which treats operations\nas a closed set  and types as an  open set . If you expect operations will be\nadded, you should strive for a procedural solution, which treats types as a\nclosed set  and operations as an open set . If you make the right choice, you\nwill economize your time and the time of your colleagues, and extensions\nwill feel natural and easy .4\nTable 4-1. Strengths and weaknesses of differ ent pr ogramming paradigms\nProgramming paradigm Strength Weakness\nProcedural programming Addition of operations Addition of (polymorphic) types\nObject-oriented programming Addition of (polymorphic) types Addition of operations\nBe aware of these strengths: based on your expectation on how a codebase\nwill evolve, choose the right approach to design for extensions. Do not\nignore the weaknesses, and do not put yourself in an unfortunate\nmaintenance hell.\nI assume that at this point you’re wondering if it’ s possible to have two\nopen sets . Well, to the best of my knowledge, this is not impossible but it’ s\nusually impractical. As an example, in “Guideline 18: Beware the\nPerformance of Acyclic V isitor” , I will show you that performance might\ntake a significant hit.\nSince you might be a fan of template-based programming and similar\ncompile time endeavors, I should also make the explicit note that static\npolymorphism does not have the same limitations. While in dynamic\npolymorphism, one of the design axes (types and operations) needs to be\nfixed, in static polymorphism, both pieces of information are available at\ncompile-time. Therefore, both aspects can be extended easily (if you do it\nproperly).5",3276
44-The Visitor Design Pattern Explained.pdf,44-The Visitor Design Pattern Explained,"GUIDELINE 15: DESIGN FOR THE ADDITION OF TYPES\nOR OPERATIONS\nBe aware of the strengths and weaknesses of dif ferent\nprogramming paradigms.\nExploit the strengths of a paradigm, but avoid the weaknesses.\nUnderstand the choice between the addition of types or operations\nin dynamic polymorphism.\nPrefer an object-oriented solution when you primarily want to add\ntypes.\nPrefer a procedural/functional solution when you primarily want to\nadd operations .\nGuideline 16: Use Visitor to Extend\nOperations\nIn the previous section, you saw that the strength of object-oriented\nprogramming (OOP) is the addition of types and its weakness is the\naddition of operations. Of course, OOP has an answer to that weakness: the\nVisitor design pattern.\nThe V isitor design pattern is one of the classic design patterns described by\nthe Gang of Four (GoF). Its focus is on allowing you to frequently add\noperations instead of types. Allow me to explain the V isitor design pattern\nusing the previous toy example: the drawing of shapes.\nIn Figure 4-1 , you see the Shape hierarchy . The Shape class is again the\nbase class for a certain number of concrete shapes. In this example, there\nare only the two classes, Circle and Square, but of course it’ s possible to\nhave more shapes. In addition, you might imagine Triangle, Rectangle,\nor Ellipse classes.\nFigur e 4-1. The UML r epresentation of a shape hierar chy with two derived classes ( Circle and\nSquare)\nAnalyzing the Design Issues\nLet’s assume you are certain that you already have all the shapes you’ll ever\nneed. That is, you consider the set of shapes a closed set . What you are\nmissing, though, are additional operations. For instance, you’re missing an\noperation to rotate the shapes. Also, you would like to serialize shapes, i.e.,\nyou would like to convert the instance of a shape into bytes. And of course,\nyou want to draw shapes. In addition, you want to enable anybody to add\nnew operations. Therefore, you expect an open set  of operations .\nEvery new operation now requires you to insert a new virtual function into\nthe base class. Unfortunately , that can be troublesome in dif ferent ways.\nMost obviously , not everyone is able to add a virtual function to the Shape6\nbase class. I, for instance, can’ t simply go ahead and change your code.\nTherefore, this approach would not meet the expectation that everyone can\nadd operations. While you can already see this as a final negative verdict,\nlet’s still analyze the problem of virtual functions in more detail.\nIf you decide to use a pure virtual function, you would have to implement\nthe function in every derived class. For your own derived types, you could\nshrug this of f as just a little bit of extra ef fort. But you might also cause\nextra work for other people who have created a shape by inheriting from the\nShape base class.  And that is very much expected, since this is the strength\nof OOP: anyone can add new types easily . Since this is to be expected, it\nmay be a reason to not use a pure virtual function.\nAs an alternative, you could introduce a regular virtual function, i.e., a\nvirtual function with a default implementation. While a default behavior for\na rotate() function sounds like a very reasonable idea, a default\nimplementation for a serialize() function doesn’ t sound easy at all. I\nadmit that I would have to think hard about how to implement such a\nfunction. Y ou might now suggest just throwing an exception as the default.\nHowever , this means that derived classes must again implement the missing\nbehavior , and it would be a pure virtual function in disguise, or a clear\nviolation of the Liskov Substitution Principle (see “Guideline 6: Adhere to\nthe Expected Behavior of Abstractions” ).\nEither way , adding a new operation into the Shape base class is dif ficult or\nnot even possible at all. The underlying reason is that adding virtual\nfunctions violates the OCP . If you really need to add new operations\nfrequently , then you should design so that the extension of operations is\neasy. That is what the V isitor design pattern tries to achieve.\nThe V isitor Design Pattern Explained\nThe intent of the V isitor design pattern is to enable the addition of\noperations.7\nTHE VISITOR DESIGN PATTERN\nIntent: “Represent  an operation to be performed on the elements of an object structure.\nVisitor lets you define a new operation without changing the classes of the elements on\nwhich it operates.”\nIn addition to the Shape hierarchy , I now introduce the ShapeVisitor\nhierarchy on the lefthand side of Figure 4-2 . The ShapeVisitor base class\nrepresents an abstraction  of shape operations. For that reason, you could\nargue that ShapeOperation might be a better name for that class. It is\nbeneficial, however , to apply “Guideline 14: Use a Design Pattern’ s Name\nto Communicate Intent” . The name Visitor will help others understand the\ndesign.8\nFigur e 4-2. The UML r epresentation of the V isitor design pattern\nThe ShapeVisitor base class comes with one pure virtual visit()\nfunction for every concrete shape in the Shape hierarchy:\n \nclass ShapeVisitor \n{ \n public: \n   virtual ~ShapeVisitor() = default; \n \n   virtual void visit( Circle const&, /*...*/ ) const = 0;  \n \n   virtual void visit( Square const&, /*...*/ ) const = 0;  \n \n   // Possibly more visit() functions, one for each concrete shape \n}; \nIn this example, there is one visit() function for Circle (\n) and one for\nSquare (\n). Of course, there could be more visit() functions—for\ninstance, one for Triangle, one for Rectangle, and one for Ellipse—\ngiven that these are also classes derived from the Shape base class.\nWith the ShapeVisitor base class in place, you can now add new\noperations easily . All you have to do to add an operation is add a new\nderived class. For instance, to enable rotating shapes, you can introduce the\nRotate class and implement all visit() functions. T o enable drawing\nshapes, all you have to do is introduce a Draw class:\nclass Draw : public ShapeVisitor \n{ \n public: \n   void visit( Circle const& c, /*...*/ ) const override; \n   void visit( Square const& s, /*...*/ ) const override; \n   // Possibly more visit() functions, one for each concrete shape \n};\nAnd you can think about introducing multiple Draw classes, one for each\ngraphics library you need to support. Y ou can do that easily , because you\ndon’t have to modify any existing code . It is only necessary to extend the\nShapeVisitor hierarchy by adding new code . Therefore, this design fulfills\nthe OCP with respect to adding operations.\nTo completely understand the software design characteristics of V isitor , it is\nimportant to understand why the V isitor design pattern is able to fulfill the\nOCP. The initial problem was that every new operation required a change to\nthe Shape base class. V isitor identifies the addition of operations as a\nvariation point . By extracting this variation point, i.e., by making this a\nseparate class, you follow the Single-Responsibility Principle (SRP): Shape\ndoes not have to change for every new operation. This avoids frequent\nmodifications of the Shape hierarchy and enables the easy addition of new\noperations. The SRP therefore acts as an enabler for the OCP .\nTo use visitors (classes derived from the ShapeVisitor base class) on\nshapes, you now have to add one last function to the Shape hierarchy: the\naccept() function (\n ): \n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n   virtual void accept( ShapeVisitor const& v ) = 0;  \n \n   // ... \n}; \nThe accept() function is introduced as a pure virtual function in the base\nclass and therefore has to be implemented in every derived class (\n  and \n ):\n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   void accept( ShapeVisitor const& v ) override { v.visit( *this ); }  \n \n \n   double radius() const { return radius_; } \n \n private: 9\n   double radius_; \n}; \n \n \nclass Square : public Shape \n{ \n public: \n   explicit Square( double side ) \n      : side_( side ) \n   { \n      /* Checking that the given side length is valid */ \n   } \n \n   void accept( ShapeVisitor const& v ) override { v.visit( *this ); }  \n \n \n   double side() const { return side_; } \n \n private: \n   double side_; \n}; \nThe implementation of accept() is easy; however , it merely needs to call\nthe corresponding visit() function on the given visitor based on the type\nof the concrete Shape. This is achieved by passing the this pointer as an\nargument to visit(). Thus, the implementation of accept() is the same in\neach derived class, but due to a dif ferent type of the this pointer , it will\ntrigger a dif ferent overload of the visit() function in the given visitor .\nTherefore, the Shape base class cannot provide a default implementation.\nThis accept() function can now be used where you need to perform an\noperation. For instance, the drawAllShapes() function uses accept() to\ndraw all shapes in a given vector of shapes:\nvoid drawAllShapes( std::vector<std::unique_ptr<Shape>> const& shapes ) \n{ \n   for( auto const& shape : shapes ) \n   { \n      shape->accept( Draw{} ); \n   } \n}",9385
45-Analyzing the Shortcomings of the Visitor Design Pattern.pdf,45-Analyzing the Shortcomings of the Visitor Design Pattern,"With the addition of the accept() function, you are now able to extend\nyour Shape hierarchy easily with operations. Y ou have now designed for an\nopen set  of operations. Amazing! However , there is no silver bullet, and\nthere is no design that always works. Every design comes with advantages,\nbut also disadvantages. So before you start to celebrate, I should tell you\nabout the shortcomings of the V isitor design pattern to give you the\ncomplete picture.\nAnalyzing the Shortcomings of the V isitor Design\nPattern\nThe Visitor design pattern is unfortunately far from perfect. This should be\nexpected, considering V isitor is a workaround for an intrinsic OOP\nweakness, instead of building on OOP strengths.\nThe first disadvantage is a low implementation flexibility . It becomes\nobvious if you consider the implementation of a Translate visitor . The\nTranslate visitor needs to move the center point of each shape by a given\noffset. For that, Translate needs to implement a visit() function for\nevery concrete Shape. Especially for Translate, you can imagine that the\nimplementation of these visit() functions would be very similar , if not\nidentical: there is nothing dif ferent about translating a Circle from\ntranslating a Square. Still, you will need to write all visit() functions. Of\ncourse, you would extract the logic from the visit() functions and\nimplement this in a third, separate function to minimize duplication\naccording to the DR Y principle.  But unfortunately , the strict requirements\nimposed by the base class do not give you the freedom to implement these\nvisit() functions as one. The result is some boilerplate code:\nclass Translate : public ShapeVisitor \n{ \n public: \n   // Where is the difference between translating a circle and translating \n   // a square? Still you have to implement all virtual functions... \n   void visit( Circle const& c, /*...*/ ) const override; \n   void visit( Square const& s, /*...*/ ) const override; 10\n   // Possibly more visit() functions, one for each concrete shape \n};\nA similar implementation inflexibility is the return type of the visit()\nfunctions. The decision on what the function returns is made in the\nShapeVisitor base class. Derived classes cannot change that. The usual\napproach is to store the result in the visitor and access it later .\nThe second disadvantage is that with the V isitor design pattern in place, it\nbecomes dif ficult to add new types. Previously , we made the assumption\nthat you’re certain you have all the shapes you will ever need. This\nassumption has now become a restriction. Adding a new shape in the Shape\nhierarchy would require the entire ShapeVisitor hierarchy to be updated:\nyou would have to add a new pure virtual function to the ShapeVisitor\nbase class, and this virtual function would have to be implemented by all\nderived classes. Of course, this comes with all the disadvantages we’ve\ndiscussed before. In particular , you would force other developers to update\ntheir operations.  Thus, the V isitor design pattern requires a closed set  of\ntypes and in exchange provides an open set  of operations.\nThe underlying reason for this restriction is that there is a cyclic\ndependency among the ShapeVisitor base class, the concrete shapes\n(Circle, Square, etc.), and the Shape base class (see Figure 4-3 ).1 1\nFigur e 4-3. Dependency graph for the V isitor design pattern\nThe ShapeVisitor base class depends on the concrete shapes, since it\nprovides a visit() function for each of these shapes. The concrete shapes\ndepend on the Shape base class, since they have to fulfill all the\nexpectations and requirements of the base class. And the Shape base class\ndepends on the ShapeVisitor base class due to the accept() function.\nBecause of this cyclic dependency , we are now able to add new operations\neasily (on a lower level of our architecture because of a dependency\ninversion), but we cannot add types easily anymore (because that would\nhave to happen on the high level of our architecture). For that reason, we\ncall the classic V isitor design pattern  Cyclic V isitor .\nThe third disadvantage is the intrusive nature of a visitor . To add a visitor to\nan existing hierarchy , you need to add the virtual accept() to the base class\nof that hierarchy . While this is often possible, it still suf fers from the usual\nproblem of adding a pure virtual function to an existing hierarchy (see\n“Guideline 15: Design for the Addition of Types or Operations ”). If,\nhowever , it’s not possible to add the accept() function, this form of V isitor\nis not an option. If that’ s the case, don’ t worry: we will see another ,\nnonintrusive form of the V isitor design pattern in “Guideline 17: Consider\nstd::variant for Implementing V isitor ”.\nA fourth, albeit admittedly more obscure, disadvantage is that the accept()\nfunction is inherited by deriving classes. If someone later adds another layer\nof derived classes (and that someone might be you) and for gets to override\nthe accept() function, the visitor will be applied to the wrong type. And\nunfortunately , you would not get any warning about this. This is just more\nevidence that adding new types has become more dif ficult. A possible\nsolution for this would be to declare the Circle and Square classes as\nfinal, which would, however , limit future extensions.\n“Wow, that’ s a lot of disadvantages. Are there any more?” Y es,\nunfortunately there are two more. The fifth disadvantage is obvious when\nwe consider that for every operation, we’re now required to call two virtual\nfunctions. Initially , we don’ t know about either the type of operation or the\ntype of shape. The first virtual function is the accept() function, which is\npassed an abstract ShapeVisitor. The accept() function now resolves the\nconcrete type of shape. The second virtual function is the visit() function,\nwhich is passed a concrete type of Shape. The visit() function now\nresolves the concrete type of the operation. This so-called double dispatch\nis unfortunately not free. On the contrary , performance-wise, you should\nconsider the Visitor design pattern as rather slow . I will provide some\nperformance numbers in the next guideline.\nWhile talking about performance, I should also mention two other aspects\nthat have a negative impact on performance. First, we usually allocate every\nsingle shape and visitor individually . Consider the following main()\nfunction:\n \nint main() \n{ \n   using Shapes = std::vector< std::unique_ptr<Shape> >; \n \n   Shapes shapes; \n \n   shapes.emplace_back( std::make_unique<Circle>( 2.3 ) );  \n \n   shapes.emplace_back( std::make_unique<Square>( 1.2 ) );  \n \n   shapes.emplace_back( std::make_unique<Circle>( 4.1 ) );  \n \n \n   drawAllShapes( shapes ); \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nIn this main() function, all allocations happen by means of\nstd::make_unique() (\n, \n, and \n ). These many , small allocations cost\nruntime on their own and will in the long run cause memory\nfragmentation.  Also, the memory may be laid out in an unfavorable,\ncache-unfriendly way . As a consequence, we usually use pointers to work\nwith the resulting shapes and visitors. The resulting indirections make it\nmuch harder for a compiler to perform any kind of optimization and will12\nshow up in performance benchmarks. However , to be honest, this is not a\nVisitor -specific problem, but these two aspects are quite common to OOP in\ngeneral.\nThe last disadvantage of the V isitor design pattern is that experience has\nproven this design pattern to be rather hard to fully understand and\nmaintain. This is a rather subjective disadvantage, but the complexity of the\nintricate interplay of the two hierarchies often feels more like a burden than\na real solution.\nIn summary , the V isitor design pattern is the OOP solution to allow for the\neasy extension of operations instead of types. That is achieved by\nintroducing an abstraction in the form of the ShapeVisitor base class,\nwhich enables you to add operations on another set of types. While this is a\nunique strength of V isitor , it unfortunately comes with several deficiencies:\nimplementation inflexibilities in both inheritance hierarchies due to a strong\ncoupling to the requirements of the base classes, rather bad performance,\nand the intrinsic complexity of V isitor make it a rather unpopular design\npattern.\nIf you’re now undecided whether or not to use a classic V isitor , take the\ntime to read the next section. I will show you a dif ferent way to implement\na Visitor—a solution that will much more likely be to your satisfaction.\nGUIDELINE 16: USE VISITOR TO EXTEND OPERATIONS\nKeep in mind that it’ s difficult to add a new operation in an\nexisting inheritance hierarchy .\nApply the V isitor design pattern with the intent of enabling the\neasy addition of operations.\nBe aware of the shortcomings of the V isitor design pattern.",9003
46-Guideline 17 Consider stdvariant for Implementing Visitor.pdf,46-Guideline 17 Consider stdvariant for Implementing Visitor,,0
47-Introduction to stdvariant.pdf,47-Introduction to stdvariant,"Guideline 17: Consider std::variant for\nImplementing Visitor\nIn “Guideline 16: Use V isitor to Extend Operations” , I introduced you to\nthe Visitor design pattern. I imagine that you did not immediately fall in\nlove: while Visitor most certainly has a couple of unique properties, it is\nalso a rather complex design pattern with some strong internal coupling and\nperformance deficiencies. No, definitely not love! However , don’ t worry ,\nthe classic form is not the only way you can implement the V isitor design\npattern. In this section, I would like to introduce you to a dif ferent way to\nimplement V isitor . And I am certain that this approach will be much more\nto your liking.\nIntroduction to std::variant\nAt the beginning of this chapter , we talked about the strengths and\nweaknesses of the dif ferent paradigms (OOP versus procedural\nprogramming). In particular , we talked about the fact that procedural\nprogramming was particularly good at adding new operations to an existing\nset of types. So instead of trying to find workarounds in OOP , how about\nwe exploit the strength of procedural programming? No, don’ t worry; of\ncourse I’m not suggesting a return to our initial solution. That approach was\njust too error prone. Instead I’m talking about std::variant:\n \n#include <cstdlib> \n#include <iostream> \n#include <string> \n#include <variant> \n \nstruct Print  \n \n{ \n   void operator()( int value ) const \n      { std::cout << ""int: "" << value << '\n'; } \n   void operator()( double value ) const \n      { std::cout << ""double: "" << value << '\n'; } \n   void operator()( std::string const& value ) const \n      { std::cout << ""string: "" << value << '\n'; } \n}; \n \nint main() \n{ \n   // Creates a default variant that contains an 'int' initialized to 0 \n   std::variant<int,double,std::string> v{};  \n \n \n   v = 42;        // Assigns the 'int' 42 to the variant  \n \n   v = 3.14;      // Assigns the 'double' 3.14 to the variant  \n \n   v = 2.71F;     // Assigns a 'float', which is promoted to 'double'  \n \n   v = ""Bjarne"";  // Assigns the string literal 'Bjarne' to the variant  \n \n   v = 43;        // Assigns the 'int' 43 to the variant  \n \n \n   int const i = std::get<int>(v);  // Direct access to the value  \n \n \n   int* const pi = std::get_if<int>(&v);  // Direct access to the value  \n \n \n   std::visit( Print{}, v );  // Applying the Print visitor  \n \n \n   return EXIT_SUCCESS; \n} \nSince you might not have had the pleasure of being introduced to the\nC++17 std::variant yet, allow me to give you an introduction in a\nnutshell, just in case. A  variant represents one of several alternatives. The\nvariant at the beginning of the main() function in the code example can\ncontain an int, a double, or an std::string (\n). Note that I said or: a\nvariant can contain only one of these three alternatives. It is never several of\nthem, and under usual circumstances, it should never contain nothing. For\nthat reason, we call a variant a sum type : the set of possible states is the sum\nof possible states of the alternatives.\nA default variant is also not empty . It is initialized to the default value of\nthe first alternative. In the example, a default variant contains an integer of\nvalue 0. Changing the value of a variant is simple: you can just assign new\nvalues. For instance, we can assign the value 42, which now means that the\nvariant stores an integer of value 42 (\n ). If we subsequently assign the\ndouble 3.14, then the variant will store a double of value 3.14 (\n ). If you\never want to assign a value of a type that is not one of the possible\nalternatives, the usual conversion rules apply . For instance, if you want to\nassign a float, based on the regular conversion rules it would be promoted\nto a double (\n).\nTo store the alternatives, the variant provides just enough internal buf fer to\nhold the lar gest of the alternatives. In our case, the lar gest alternative is the\nstd::string, which is usually between 24 and 32 bytes (depending on the\nused implementation of the Standard Library). Thus, when you assign the\nstring literal ""Bjarne"", the variant will first clean up the previous value\n(there isn’ t much to do; it’ s just a double) and then, since it is the only\nalternative that works, construct the std::string in place inside its own\nbuffer (\n ). When you change your mind and assign the integer 43 (\n ), the\nvariant will properly destroy the std::string by means of its destructor\nand reuse the internal buf fer for the integer . Marvelous, is it not? The\nvariant is type safe and always properly initialized. What more could we\nask for?\nWell, of course you want to do something with the values inside the variant.\nIt would not be of any use if we just store the value. Unfortunately , you\ncannot simply assign a variant to any other value, e.g., an int, to get your\nvalue back. No, accessing the value is a little more complicated. There are\nseveral ways to access the stored values, the most direct approach being\nstd::get() (\n). With std::get() you can query for a value of a particular\ntype. If the variant contains a value of that type, it returns a reference to it.\nIf it does not, it throws the std::bad_variant_exception. That seems to\nbe a pretty rude response, given that you have asked nicely . But we should\nprobably be happy that the variant does not pretend to hold some value\nwhen it indeed does not. At least it is honest. There is a nicer way in the\nform of std::get_if() (\n). In comparison to std::get(),\nstd::get_if() does not return a reference but a pointer . If you request a\ntype that the std::variant currently does not hold, it doesn’ t throw an\nexception but instead returns a nullptr. However , there is a third way , a\nway that is particularly interesting for our purposes: std::visit() (\n).\nstd::visit() allows you to perform any operation on the stored value. Or\nmore precisely , it allows you to pass a custom visitor to perform any\noperation on the stored value of a closed set  of types. Sound familiar?",6098
48-Refactoring the Drawing of Shapes as a Value-Based Nonintrusive Solution.pdf,48-Refactoring the Drawing of Shapes as a Value-Based Nonintrusive Solution,"The Print visitor (\n ) that we pass as the first ar gument must provide a\nfunction call operator ( operator()) for every possible alternative. In this\nexample, that is fulfilled by providing three operator()s: one for int, one\nfor double, and one for std::string. It is particularly noteworthy that\nPrint does not have to inherit from any base class, and it does not have any\nvirtual functions. Therefore, there is no strong coupling to any\nrequirements. If we wanted to, we could also collapse the function call\noperators for int and double into one, since an int can be converted to a\ndouble:\nstruct Print \n{ \n   void operator()( double value ) const \n      { std::cout << ""int or double: "" << value << '\n'; } \n   void operator()( std::string const& value ) const \n      { std::cout << ""string: "" << value << '\n'; } \n};\nWhile the question about which version we should prefer is not of particular\ninterest for us at this moment, you’ll notice that we have a lot of\nimplementation flexibility . There is only a very loose coupling based on the\nconvention that for every alternative there needs to be an operator(),\nregardless of the exact form. W e do not have a Visitor base class anymore\nthat forces us to do things in a very specific way . We also do not have any\nbase class for the alternatives: we are free to use fundamental types such as\nint and double, as well as arbitrary class types such as std::string. And\nperhaps most importantly , anyone can easily add new operations. No\nexisting code needs to be modified. W ith this, we can ar gue that this is a\nprocedural solution, just much more elegant than the initial enum-based\napproach, which used a base class to hold a discriminator .\nRefactoring the Drawing of Shapes as a V alue-Based,\nNonintrusive Solution\nWith these properties, std::variant is perfectly suited for our drawing\nexample. Let’ s re-implement the drawing of shapes with std::variant.\nFirst, we refactor the Circle and Square classes:\n//---- <Circle.h> ---------------- \n \n#include <Point.h> \n \nclass Circle \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   double radius() const { return radius_; } \n   Point  center() const { return center_; } \n \n private: \n   double radius_; \n   Point center_{}; \n}; \n \n \n//---- <Square.h> ---------------- \n \n#include <Point.h> \n \nclass Square \n{ \n public: \n   explicit Square( double side ) \n      : side_( side ) \n   { \n      /* Checking that the given side length is valid */ \n   } \n \n   double side  () const { return side_; } \n   Point  center() const { return center_; } \n \n private: \n   double side_; \n   Point center_{}; \n};\nBoth Circle and Square are significantly simplified: no more Shape base\nclass, no more need to implement any virtual functions—in particular the\naccept() function. Thus, this Visitor approach is nonintrusive: this form of\nVisitor can be easily added to existing types! And there is no need to\nprepare these classes for any upcoming operations. W e can focus entirely on\nimplementing these two classes as what they are: geometric primitives.\nThe most beautiful part of the refactoring, however , is the actual use of\nstd::variant:\n \n//---- <Shape.h> ---------------- \n \n#include <variant> \n#include <Circle.h> \n#include <Square.h> \n \nusing Shape = std::variant<Circle,Square>;  \n \n \n \n//---- <Shapes.h> ---------------- \n \n#include <vector> \n#include <Shape.h> \n \nusing Shapes = std::vector<Shape>;  \n \nSince our closed set  of types is a set of shapes, variant will now contain\neither a Circle or Square. And what is a good name for an abstraction of a\nset of types that represent shapes? W ell…Shape (\n). Instead of a base class\nthat abstracts from the actual type of shape, std::variant now acquires\nthis task. If this is the first time you’ve seen that, you are probably\ncompletely amazed. But wait, there is more: this also means that we can\nnow turn our back on std::unique_ptr. Remember: the only reason we\nused (smart) pointers was to enable us to store dif ferent kinds of shapes in\nthe same vector . But now that std::variant enables us to do the same, we\ncan simply store variant objects inside a single vector (\n ).\nWith this functionality in place, we can write custom operations on shapes.\nWe’re still interested in drawing shapes. For that purpose, we now\nimplement the Draw visitor :\n//---- <Draw.h> ---------------- \n \n#include <Shape.h> \n#include /* some graphics library */ \n \nstruct Draw \n{ \n   void operator()( Circle const& c ) const \n      { /* ... Implementing the logic for drawing a circle ... */ } \n   void operator()( Square const& s ) const \n      { /* ... Implementing the logic for drawing a square ... */ } \n};\nAgain, we are following the expectation to implement one operator() for\nevery alternative: one for Circle and one for Square. But this time we\nhave a choice. There is no need to implement any base class, and for that\nreason, no need to override any virtual function. Therefore, there is no need\nto implement exactly one operator() for every alternative. While in this\nexample it feels reasonable to have two functions, we have the option to\ncombine the two operator()s into one function. W e also have a choice\nwith respect to the return type of the operation. W e can locally decide what\nwe should return, and it is not a base class that, independent from the\nspecific operation, makes a global decision. Implementation flexibility .\nLoose coupling. Amazing!\nThe last piece of the puzzle is the drawAllShapes() function:\n//---- <DrawAllShapes.h> ---------------- \n \n#include <Shapes.h> \n \nvoid drawAllShapes( Shapes const& shapes ); \n \n \n//---- <DrawAllShapes.cpp> ---------------- \n \n#include <DrawAllShapes.h> \n \nvoid drawAllShapes( Shapes const& shapes ) \n{ \n   for( auto const& shape : shapes ) \n   { \n      std::visit( Draw{}, shape ); \n   } \n}\nThe drawAllShapes() function is refactored to make use of\nstd::visit(). In this function, we now apply the Draw visitor onto all\nvariants stored in a vector .\nThe job of std::visit() is to perform the necessary type dispatch for you.\nIf the given std::variant contains a Circle, it will call the\nDraw::operator() for circles. Otherwise it will call the\nDraw::operator() for squares. If you wanted to, you could manually\nimplement the same dispatch with std::get_if():\nvoid drawAllShapes( Shapes const& shapes ) \n{ \n   for( auto const& shape : shapes ) \n   { \n      if( Circle* circle = std::get_if<Circle>(&shape) ) { \n         // ... Drawing a circle \n      } \n      else if( Square* square = std::get_if<Square>(&shape) ) { \n         // ... Drawing a square \n      } \n   } \n}\nI know what you’re thinking: “Nonsense! Why would I ever want to do\nthat? That would result in the same maintenance nightmare as an enum-\nbased solution.” I completely agree with you: from a software design\nperspective, this would be a terrible idea. Still, and I have to say that this is\ndifficult to admit in the context of this book, there may be a good reason to\ndo that (sometimes): performance. I know , now I’ve piqued your interest,\nbut since we are almost ready to talk about performance anyway , allow me\nto defer this discussion for just a few paragraphs. I will come back to this, I\npromise!\nWith all of these details in place, we can finally refactor the main()\nfunction. But there isn’ t a lot of work to do: instead of creating circles and\nsquares by means of std::make_unique(), we simply create circles and\nsquares directly , and add them to the vector . This works thanks to the\nnonexplicit constructor of variant, which allows implicit conversion of any\nof the alternatives:\n//---- <Main.cpp> ---------------- \n \n#include <Circle.h> \n#include <Square.h> \n#include <Shapes.h> \n#include <DrawAllShapes.h> \n \nint main() \n{ \n   Shapes shapes; \n \n   shapes.emplace_back( Circle{ 2.3 } ); \n   shapes.emplace_back( Square{ 1.2 } ); \n   shapes.emplace_back( Circle{ 4.1 } ); \n \n   drawAllShapes( shapes ); \n \n   return EXIT_SUCCESS; \n}\nThe end result of this value-based solution is stunningly fascinating: no\nbase classes anywhere. No virtual functions. No pointers. No manual\nmemory allocations. Things are as straightforward as they could be, and\nthere is very little boilerplate code. Additionally , despite the fact that the\ncode looks very dif ferent from the previous solutions,  the architectural\nproperties are identical: everyone is able to add new operations without the\nneed to modify existing code  (see Figure 4-4 ). Therefore, we still fulfill the\nOCP in respect to adding operations.\nFigur e 4-4. Dependency graph for the std::variant solution\nAs already mentioned, this V isitor approach is nonintrusive. From an\narchitectural point of view , this gives you another , significant advantage\ncompared to the classic V isitor . If you compare the dependency graph of the\nclassic Visitor (see Figure 4-3 ) to the dependency graph of the\nstd::variant solution (see Figure 4-4 ), you will see that the dependency\ngraph for the std::variant solution has a second architectural boundary .\nThis means that there is no cyclic dependency between std::variant and\nits alternatives. I should repeat that to emphasize its significance: there is no\ncyclic dependency between std::variant and its alternatives! What may\nlook like a little detail is actually a huge architectural advantage. HUGE! As\nan example, you could create an abstraction based on std::variant on the\nfly:\n \n//---- <Shape.h> ---------------- \n \n#include <variant> \n#include <Circle.h> \n#include <Square.h> \n \nusing Shape = std::variant<Circle,Square>;  \n \n \n \n//---- <SomeHeader.h> ---------------- \n \n#include <Circle.h> \n#include <Ellipse.h> \n#include <variant> \n \nusing RoundShapes = std::variant<Circle,Ellipse>;  \n \n \n \n//---- <SomeOtherHeader.h> ---------------- \n \n#include <Square.h> \n#include <Rectangle.h> \n#include <variant> \n \nusing AngularShapes = std::variant<Square,Rectangle>;",10207
49-Performance Benchmarks.pdf,49-Performance Benchmarks,"In addition to the Shape abstraction we have already created (\n ), you can\ncreate the std::variant for all round shapes (\n ), and you can create a\nstd::variant for all angular shapes (\n ), both possibly far away from the\nShape abstraction. Y ou can easily do this because there is no need to derive\nfrom multiple V isitor base classes. On the contrary , the shape classes would\nbe unaf fected. Thus, the fact that the std::variant solution is nonintrusive\nis of the highest architectural value!\nPerformance Benchmarks\nI know how you feel right now . Yes, that’ s what love at first sight feels like.\nBut believe it or not, there’ s more. There is one topic that we haven’ t\ndiscussed yet, a topic that is dear to every C++ developer , and that is, of\ncourse, performance. While this is not really a book about performance, it’ s\nstill worth mentioning that you do not have to worry about the performance\nof std::variant. I can already promise you that it’ s fast.\nBefore I show you the benchmark results, however , allow me a couple of\ncomments about the benchmarks. Performance— sigh. Unfortunately ,\nperformance is always a dif ficult topic. There is always someone who\ncomplains about performance. For that reason, I would gladly just skip this\ntopic entirely . But then there are other people who complain about the\nmissing performance numbers. Sigh. Well, as it appears that there will\nalways be some complaints, and since the results are just too good to miss, I\nwill show you a couple of benchmark results. But there are two conditions:\nfirst, you will not consider them to be quantitative values that represent the\nabsolute truth but only qualitative values that point in the right direction.\nAnd second, you will not launch a protest in front of my house because I\ndidn’ t use your favorite compiler , or compilation flag, or IDE. Promise?\nYou: nodding and vowing to not complain about trivial things!\nOK, great, then Table 4-2  gives you the benchmark results.\nTable 4-2. Benchmark r esults for differ ent V isitor\nimplementations\nVisitor implementation GCC 1 1.1 Clang 1 1.1\nClassic V isitor design pattern 1.6161 s 1.8015 s\nObject-oriented solution 1.5205 s 1.1480 s\nEnum solution 1.2179 s 1.1200 s\nstd::variant (with std::visit())1.1992 s 1.2279 s\nstd::variant (with std::get_if())1.0252 s 0.6998 s\nTo make sense of these numbers, I should give you a little more\nbackground. To make the scenario a little more realistic, I used not only\ncircles and squares but also rectangles and ellipses. Then I ran 25,000\noperations on 10,000 randomly created shapes. Instead of drawing these\nshapes, I updated the center point by random vectors.  This is because this\ntranslate operation is very cheap and allows me to better show the intrinsic\noverhead of all these solutions (such as indirections and the overhead of\nvirtual function calls). An expensive operation, such as draw(), would\nobscure these details and might give the impression that all approaches are\npretty similar . I used both GCC 1 1.1 and Clang 1 1.1, and for both compilers\nI added only the -O3 and -DNDEBUG compilation flags. The platform I used\nwas macOS Big Sur (version 1 1.4) on an 8-Core Intel Core i7 with 3.8 GHz\nand 64 GB of main memory .\nThe most obvious takeaway from the benchmark results is that the variant\nsolution is far more ef ficient than the classic V isitor solution. This should\nnot come as a surprise: due to the double dispatch, the classic V isitor\nimplementation contains a lot of indirection and therefore is also hard to\noptimize. Also, the memory layout of the shape objects is perfect: in\ncomparison to all other solutions, including the enum-based solution, all\nshapes are stored contiguously in memory , which is the most cache-friendly\nlayout you could choose. The second takeaway is that std::variant is13",3870
50-Analyzing the Shortcomings of the stdvariant Solution.pdf,50-Analyzing the Shortcomings of the stdvariant Solution,"indeed pretty ef ficient, if not surprisingly ef ficient. However , it is surprising\nthat ef ficiency heavily depends on whether we use std::get_if() or\nstd::visit() (I promised to get back to this). Both GCC and Clang\nproduce much slower code when using std::visit(). I assume that\nstd::visit() is not perfectly implemented and optimized at that point.\nBut, as I said before, performance is always dif ficult, and I don’ t try to\nventure any deeper into this mystery .\nMost importantly , the beauty of std::variant is not messed up by bad\nperformance numbers. On the contrary: the performance results help\nintensify your newfound relationship with std::variant.\nAnalyzing the Shortcomings of the std::variant Solution\nWhile  I don’ t want to endanger this relationship, I consider it my duty to\nalso point out a couple of disadvantages that you will have to deal with if\nyou use the solution based on std::variant.\nFirst, I should again point out the obvious: as a solution similar to the\nVisitor design pattern and based on procedural programming,\nstd::variant is also focused on providing an open set  of operations. The\ndownside is that you will have to deal with a closed set  of types. Adding\nnew types will cause problems very similar to the problems we experienced\nwith the enum-based solution in “Guideline 15: Design for the Addition of\nTypes or Operations ”. First of all, you would have to update the variant\nitself, which might trigger a recompilation of all code using the variant type\n(remember updating the enum?). Also, you would have to update all\noperations and add the potentially missing operator() for the new\nalternative(s). The good thing is that the compiler would complain if one of\nthese operators is missing. The bad thing is that the compiler will not\nproduce a nice, legible error message, but something that is a little closer to\nthe mother of all template-related error messages. Altogether it really feels\npretty much like our previous experience with the enum-based solution.\nA second potential problem that you should keep in mind is that you should\navoid putting types of very dif ferent sizes inside a variant. If at least one of14\nthe alternatives is much bigger than the others, you might waste a lot of\nspace storing many of the small alternatives. This would negatively af fect\nperformance. A solution would be to not store lar ge alternatives directly but\nto store them behind pointers, via Proxy objects, or by using the Bridge\ndesign pattern.  Of course, this would introduce an indirection, which also\ncosts performance. Whether this is a disadvantage in terms of performance\nin comparison to storing values of dif ferent size is something that you will\nhave to benchmark.\nLast but not least, you should always be aware of the fact that a variant can\nreveal a lot of information. While it represents a runtime abstraction, the\ncontained types are still plainly visible. This can create physical\ndependencies on the variant, i.e., when modifying one of the alternative\ntypes, you might have to recompile any depending code. The solution\nwould, again, be to store pointers or Proxy objects instead, which would\nhide implementation details. Unfortunately , that would also impact\nperformance, since a lot of the performance gains come from the compiler\nknowing about the details and optimizing for them accordingly . Thus, there\nis always a compromise between performance and encapsulation.\nDespite these shortcomings, in summary , std::variant proves to be a\nwonderful replacement for the OOP-based V isitor design pattern. It\nsimplifies the code a lot, removes almost all boilerplate code and\nencapsulates the ugly and maintenance-intensive parts, and comes with\nsuperior performance. In addition, std::variant proves to be another\ngreat example of the fact that a design pattern is about an intent, not about\nimplementation details.15",3934
51-Guideline 18 Beware the Performance of Acyclic Visitor.pdf,51-Guideline 18 Beware the Performance of Acyclic Visitor,"GUIDELINE 17: CONSIDER STD::VARIANT FOR\nIMPLEMENTING VISITOR\nUnderstand the architectural similarity between the classic V isitor\nand std::variant.\nBe aware of the advantages of std::variant in comparison to an\nobject-oriented V isitor solution.\nUse the nonintrusive nature of std::variant to create\nabstractions on the fly .\nKeep in mind the shortcomings of std::variant and avoid it\nwhen it’ s not appropriate .\nGuideline 18: Beware the Performance of\nAcyclic Visitor\nAs you saw in “Guideline 15: Design for the Addition of Types or\nOperations ”, you have to make a decision when using dynamic\npolymorphism: you can support an open set of types  or an open set of\noperations . You cannot have both. W ell, I specifically said that, to my best\nknowledge, having both is not actually impossible  but usually impractical.\nTo demonstrate, allow me to introduce you to yet another variation of the\nVisitor design pattern: the Acyclic V isitor .\nIn “Guideline 16: Use V isitor to Extend Operations” , you saw that there is a\ncyclic dependency among the key players of the V isitor design pattern: the\nVisitor base class depends on the concrete types of shapes ( Circle,\nSquare, etc.), the concrete types of shapes depend on the Shape base class,\nand the Shape base class depends on the Visitor base class. Due to that\ncyclic dependency , which locks all those key players onto one level in the\narchitecture, it is hard to add new types to a V isitor . The idea of the Acyclic\nVisitor is to break this dependency .16\nFigure 4-5  shows a UML diagram for the Acyclic V isitor . In comparison to\nthe GoF V isitor , while there are only small dif ferences on the righthand side\nof the picture, there are some fundamental changes on the lefthand side.\nMost importantly , the Visitor base class has been split into several base\nclasses: the AbstractVisitor base class and one base class for each\nconcrete type of shape (in this example, Circle Visi tor and\nSquareVisitor). All visitors have to inherit from the AbstractVisitor\nbase class but now also have the option to inherit from the shape-specific\nvisitor base classes. If an operation wants to support circles, it inherits from\nthe Circle Visi tor base class and implements the visit() function for\nCircle. If it does not want to support circles, it simply does not inherit\nfrom CircleVisitor.\nFigur e 4-5. The UML r epresentation of an Acyclic V isitor\nThe following code snippet shows a possible implementation of the\nVisitor base classes:\n \n//---- <AbstractVisitor.h> ---------------- \n \nclass AbstractVisitor  \n \n{ \n public: \n   virtual ~AbstractVisitor() = default; \n}; \n \n \n//---- <Visitor.h> ---------------- \n \ntemplate< typename T > \nclass Visitor  \n \n{ \n protected: \n   ~Visitor() = default; \n \n public: \n   virtual void visit( T const& ) const = 0; \n}; \nThe AbstractVisitor base class is nothing but an empty base class with a\nvirtual destructor (\n ). No other function is necessary . As you will see,\nAbstractVisitor serves only as a general tag to identify visitors and\ndoesn’ t have to provide any operation itself. In C++ we tend to implement\nthe shape-specific visitor base classes in the form of a class template (\n ).\nThe Visitor class template is parameterized on a specific shape type and\nintroduces the pure virtual visit() for that particular shape.\nIn the implementation of our Draw visitor , we would now inherit from three\nbase classes: the AbstractVisitor, from Visitor<Circle> and\nVisitor<Square>, since we want to support both Circle and Square:\nclass Draw : public AbstractVisitor \n           , public Visitor<Circle> \n           , public Visitor<Square> \n{ \n public: \n   void visit( Circle const& c ) const override \n      { /* ... Implementing the logic for drawing a circle ... */ } \n   void visit( Square const& s ) const override \n      { /* ... Implementing the logic for drawing a square ... */ } \n};\nThis choice of implementation breaks the cyclic dependency . As Figure 4-6\ndemonstrates, the high level of the architecture does not depend on the\nconcrete shape types anymore. Both the shapes ( Circle and Square) and\nthe operations are now on the low level of the architectural boundary . We\ncan now add both types and operations.\nAt this point, you’re looking very suspiciously , almost accusingly , in my\ndirection. Didn’ t I say that having both would not be possible? Obviously , it\nis possible, right? W ell, once again, I didn’ t claim that it was impossible. I\nrather said that this might be impractical. Now that you’ve seen the\nadvantage of an Acyclic V isitor , let me show you the downsides of this\napproach.\nFigur e 4-6. Dependency graph for the Acyclic V isitor\nFirst, let’ s take a look at the implementation of the accept() function in\nCircle:\n \n//---- <Circle.h> ---------------- \n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   void accept( AbstractVisitor const& v ) override {  \n \n      if( auto const* cv = dynamic_cast<Visitor<Circle> const*>(&v) ) {  \n \n         cv->visit( *this );  \n \n      } \n   } \n \n   double radius() const { return radius_; } \n   Point  center() const { return center_; } \n \n private: \n   double radius_; \n   Point center_{}; \n}; \nYou might have noticed the one small change in the Shape hierarchy: the\nvirtual accept() function now accepts an AbstractVisitor (\n). You also\nremember that the AbstractVisitor does not implement any operation on\nits own. Therefore, instead of calling a visit() function on the\nAbstractVisitor, the Circle determines if the given visitor supports\ncircles by performing a dynamic_cast to Visitor<Circle> (\n). Note that\nit performs a pointer conversion, which means that the dynamic_cast\nreturns either a valid pointer to a Visitor<Circle> or a nullptr. If it\nreturns a valid pointer to a Visitor<Circle>, it calls the corresponding\nvisit() function (\n ).\nWhile this approach most certainly works and is part of breaking the cyclic\ndependency of the V isitor design pattern, a dynamic_cast always leaves a\nbad feeling. A  dynamic_cast should always feel a little suspicious,\nbecause, if used badly , it can break an architecture. That would happen if\nwe perform a cast from within the high level of the architecture to\nsomething that resides in the low level of the architecture.  In our case, it’ s\nactually OK to use it, since the use happens on the low level of our\narchitecture. Thus, we do not break the architecture by inserting knowledge\nabout a lower level into the high level.\nThe real deficiency lies in the runtime penalty . When running the same\nbenchmark as in “Guideline 17: Consider std::variant for Implementing\nVisitor ” for an Acyclic V isitor , you realize that the runtime is almost one\norder of magnitude above the runtime of a Cyclic V isitor (see Table 4-3 ).\nThe reason is that a dynamic_cast is slow . Very slow . And it is particularly\nslow for this application. What  we’re doing here is a cross-cast. W e aren’ t\nsimply casting down to a particular derived class, but we are casting into\nanother branch of the inheritance hierarchy . This cross cast, followed by a\nvirtual function call, is significantly more costly than a simple downcast.\nTable 4-3. Performance r esults for differ ent V isitor\nimplementations\nVisitor implementation GCC 1 1.1 Clang 1 1.1\nAcyclic V isitor 14.3423 s 7.3445 s\nCyclic V isitor 1.6161 s 1.8015 s\nObject-oriented solution 1.5205 s 1.1480 s\nEnum solution 1.2179 s 1.1200 s\nstd::variant (with std::visit())1.1992 s 1.2279 s\nstd::variant (with std::get()) 1.0252 s 0.6998 s17\nWhile architecturally , an Acylic V isitor is a very interesting alternative,\nfrom a practical point of view , these performance results might disqualify it.\nThis does not mean that you shouldn’ t use it, but at least be aware that the\nbad performance might be a very strong ar gument for another solution.\nGUIDELINE 18: BEWARE THE PERFORMANCE OF\nACYCLIC VISITOR\nUnderstand the architectural advantages of an Acyclic V isitor .\nBe aware of the significant performance disadvantages of that\nsolution.\n1 I can see you rolling your eyes! “Oh, that boring example again!” But do consider readers\nwho skipped Chapter 3 . They’re now happy that they can read this section without a lengthy\nexplanation about the scenario.\n2 Since C++1 1, we have scoped enumerations , sometimes also called class enumerations\nbecause of the syntax enum class, at our disposal. This would, for instance, help the compiler\nto better warn about incomplete switch statements. If you spotted this imperfection, you’ve\nearned yourself a bonus point!\n3 Scott Meyers, More Effective C++: 35 New W ays to Impr ove Y our Pr ograms and Designs ,\nItem 31 (Addison-W esley , 1995).\n4 Note that the mathematical notion of open and closed sets  is something completely different .\n5 As an example of design with static polymorphism, consider the algorithms from the Standard\nTemplate Library (STL). Y ou can easily add new operations, i.e., algorithms, but also easily\nadd new types that can be copied, sorted, etc.\n6 It’s always hard to make predictions. But we usually have a pretty good idea about how our\ncodebase will evolve. In case you have no idea how things will move along, you should wait\nfor the first change or extension, learn from that, and make a more informed decision. This\nphilosophy is part of the commonly known YAGNI principle , which warns you about\noverengineering; see also “Guideline 2: Design for Change” .\n7 I wouldn’ t be happy about it—perhaps I would even be seriously unhappy—but I probably\nwouldn’ t get angry . But your other colleagues? W orst case, you might be excluded from the\nnext team barbecue.\n8 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n9 accept() is the name used in the GoF book. It is the traditional name in the context of the\nVisitor design pattern. Of course, you are free to use any other name, such as apply(). But\nbefore you rename, consider the advice from “Guideline 14: Use a Design Pattern’ s Name to\nCommunicate Intent” .\n10 It really is advisable to extract the logic into a single function. The reason is change: if you\nhave to update the implementation later , you don’ t want to perform the change multiple times.\nThat is the idea of the DR Y (Don’ t Repeat Y ourself) principle. So please remember “Guideline\n2: Design for Change” .\n1 1 Consider the risk: this might exclude you from team barbecues for life!\n12 Memory fragmentation is much more likely when you use std::make_unique(), which\nencapsulates a call to new, instead of some special-purpose allocation schemes.\n13 I am indeed using random vectors, created by means of std::mt19937 and\nstd::uniform_real_distribution, but only after proving to myself that the performance\ndoes not change for GCC 1 1.1, and only slightly for Clang 1 1.1. Apparently , creating random\nnumbers is not particularly expensive in itself (at least on my machine). Since you promised to\nconsider these as qualitative results, we should be good.\n14 There are other open source alternative implementations of variant. The Boost library\nprovides two implementations: Abseil  provides a variant implementation, and it pays to take a\nlook at the implementation of Michael Park .\n15 The Proxy pattern is another one of the GoF design patterns, which I unfortunately do not\ncover in this book because of limited pages. I will, however , go into detail about the Bridge\ndesign pattern; see “Guideline 28: Build Bridges to Remove Physical Dependencies ”.\n16 For more information on the Acyclic V isitor pattern by its inventor , see Robert C. Martin,\nAgile Softwar e Development: Principles, Patterns, and Practices  (Pearson).\n17 Please refer to “Guideline 9: Pay Attention to the Ownership of Abstractions”  for a definition\nof the terms high level  and low level .",12104
52-Guideline 19 Use Strategy to Isolate How Things Are Done.pdf,52-Guideline 19 Use Strategy to Isolate How Things Are Done,"Chapter 5. The Strategy and\nCommand Design Patterns\nThis chapter is devoted to two of the most commonly used design patterns:\nthe Strategy design pattern and the Command  design pattern. Most\ncommonly used indeed: the C++ Standard Library itself uses both of them\ndozens of times, and it’ s very likely that you have used them many times\nyourself. Both of these can be considered fundamental tools for every\ndeveloper .\nIn “Guideline 19: Use Strategy to Isolate How Things Are Done” , I will\nintroduce you to the Strategy design pattern. I will demonstrate why this is\none of the most useful and most important design patterns and why you will\nfind it useful in many situations.\nIn “Guideline 20: Favor Composition over Inheritance” , we will take a look\nat inheritance and why so many people complain about it. Y ou will see that\nit’s not bad per se, but like everything else, it has its benefits as well as\nlimitations. Most importantly , however , I will explain that many of the\nclassic design patterns do not draw their power from inheritance but rather\nfrom composition.\nIn “Guideline 21: Use Command to Isolate What Things Are Done ”, I will\nintroduce  you to the Command design pattern. I will show you how to use\nthat design pattern productively , and also give you an idea of how\nCommand and Strategy compare.\nIn “Guideline 22: Prefer V alue Semantics over Reference Semantics ”, we\ntake a trip into the realm of reference semantics . However , we will find that\nthis realm is not particularly friendly and hospitable and makes us worry\nabout the quality of our code. Thus, we will resettle into the realm of value\nsemantics , which will welcome us with many benefits for our codebase.\nIn “Guideline 23: Prefer a V alue-Based Implementation of Strategy and\nCommand” , we will revisit the Strategy and Command patterns. I will\ndemonstrate how we can  apply the insight we gained in the realm of value\nsemantics and implement both design patterns based on std::function.\nGuideline 19: Use Strategy to Isolate How\nThings Are Done\nLet’s imagine that you and your team are about to implement a new 2D\ngraphics tool. Among other requirements, it needs to deal with simple\ngeometric primitives, such as circles, squares, and so on, which need to be\ndrawn  (see Figure 5-1 ).\nFigur e 5-1. The initial Shape inheritance hierar chy\nA couple of classes have already been implemented, such as a Shape base\nclass, a Circle class, and a Square class:\n \n//---- <Shape.h> ---------------- \n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n \n   virtual void draw( /*some arguments*/ ) const = 0;  \n \n}; \n \n \n//---- <Circle.h> ---------------- \n \n#include <Point.h> \n#include <Shape.h> \n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   double radius() const { return radius_; } \n   Point  center() const { return center_; } \n \n   void draw( /*some arguments*/ ) const override;  \n \n \n private: \n   double radius_; \n   Point center_{}; \n}; \n \n \n//---- <Circle.cpp> ---------------- \n \n#include <Circle.h> \n#include /* some graphics library */ \n \nvoid Circle::draw( /*some arguments*/ ) const \n{ \n   // ... Implementing the logic for drawing a circle \n} \n \n \n//---- <Square.h> ---------------- \n \n#include <Point.h> \n#include <Shape.h> \n \nclass Square : public Shape \n{ \n public: \n   explicit Square( double side ) \n      : side_( side ) \n   { \n      /* Checking that the given side length is valid */ \n   } \n \n   double side  () const { return side_; } \n   Point  center() const { return center_; } \n \n   void draw( /*some arguments*/ ) const override;  \n \n \n private: \n   double side_; \n   Point center_{}; \n}; \n \n \n//---- <Square.cpp> ---------------- \n \n#include <Square.h> \n#include /* some graphics library */ \n \nvoid Square::draw( /*some arguments*/ ) const \n{ \n   // ... Implementing the logic for drawing a square \n} \nThe most important aspect is the pure virtual draw() member function of\nthe Shape base class (\n ). While you were on vacation, one of your team\nmembers already implemented this draw() member function for both the\nCircle and the Square classes using OpenGL  (\n and \n ). The tool is",4368
53-Analyzing the Design Issues.pdf,53-Analyzing the Design Issues,"already able to draw circles and squares, and the entire team agrees that the\nresulting graphics look pretty neat. Everyone is happy!\nAnalyzing the Design Issues\nEveryone, except you, that is. Returning  from your vacation, you of course\nimmediately realize that the implemented solution violates the Single-\nResponsibility Principle (SRP).  As it is, the Shape hierarchy is not\ndesigned for change. First, it’ s not easy to change the way a shape is drawn.\nIn the current implementation, there is only one fixed way of drawing\nshapes, and it’ s not possible to change these details nonintrusively . Since\nyou already predict that the tool will have to support multiple graphic\nlibraries, this is definitely a problem.  And second, if you eventually\nperform the change, you need to change the behavior in multiple, unrelated\nplaces.\nBut there is more. Since the drawing functionality is implemented inside\nCircle and Square, the Circle and Square classes depend on the\nimplementation details of draw(), meaning they depend on OpenGL.\nDespite the fact that circles and squares should primarily be some simple\ngeometric primitives, these two classes now carry the burden of having to\nuse OpenGL everywhere they are used.\nWhen pointing this out to your colleagues, they are, at first, a little\ndumbfounded. And also a little annoyed, since they didn’ t expect you to\npoint out any flaws in their beautiful solution. However , you have a very\nnice way of explaining the problem, and eventually they agree with you and\nstart to think about a better solution.\nIt doesn’ t take them long to come up with a better approach. In the next\nteam meeting a few days later , they present their new idea: another layer in\nthe inheritance hierarchy  (see Figure 5-2 ).1\n2\nFigur e 5-2. The extended Shape inheritance hierar chy\nTo demonstrate the idea, they have already implemented the OpenGLCircle\nand OpenGLSquare classes:\n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n \nclass Circle : public Shape \n{ \n public: \n   // ... No implementation of the draw() member function anymore \n}; \n \n \n//---- <OpenGLCircle.h> ---------------- \n \n#include <Circle.h> \n \nclass OpenGLCircle : public Circle \n{ \n public: \n   explicit OpenGLCircle( double radius ) \n      : Circle( radius ) \n   {} \n \n   void draw( /*some arguments*/ ) const override; \n}; \n \n \n//---- <OpenGLCircle.cpp> ---------------- \n \n#include <OpenGLCircle.h> \n#include /* OpenGL graphics library headers */ \n \nvoid OpenGLCircle::draw( /*some arguments*/ ) const \n{ \n   // ... Implementing the logic for drawing a circle by means of OpenGL \n} \n \n \n//---- <Square.h> ---------------- \n \n#include <Shape.h> \n \nclass Square : public Shape \n{ \n public: \n   // ... No implementation of the draw() member function anymore \n}; \n \n \n//---- <OpenGLSquare.h> ---------------- \n \n#include <Square.h> \n \nclass OpenGLSquare : public Square \n{ \n public: \n   explicit OpenGLSquare( double side ) \n      : Square( side ) \n   {} \n \n   void draw( /*some arguments*/ ) const override; \n}; \n \n \n//---- <OpenGLSquare.cpp> ---------------- \n \n#include <OpenGLSquare.h> \n#include /* OpenGL graphics library headers */ \n \nvoid OpenGLSquare::draw( /*some arguments*/ ) const \n{ \n   // ... Implementing the logic for drawing a square by means of OpenGL \n}\nInheritance! Of course! By simply deriving from Circle and Square, and\nby moving the implementation of the draw() function further down the\nhierarchy , it is easily possible to implement the drawing in dif ferent ways.\nFor instance, there could be a MetalCircle and a VulkanCircle, assuming\nthat the Metal  and Vulkan  libraries need to be supported. Suddenly , change\nis easy , right?\nWhile your colleagues are still very proud about their new solution, you\nalready realize that this approach will not work well for long. And it is easy\nto demonstrate the shortcomings: all you have to do is consider another\nrequirement, for instance, a serialize() member function:\n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n \n   virtual void draw( /*some arguments*/ ) const = 0; \n   virtual void serialize( /*some arguments*/ ) const = 0;  \n \n}; \nThe serialize() member function (\n ) is supposed to transform a shape\ninto a byte sequence, which can be stored in a file or a database. From\nthere, it’ s possible to deserialize the byte sequence to re-create the exact\nsame shape. And just like the draw() member function, the serialize()\nmember function can be implemented in various ways. For instance, you\ncould reach for the protobuf  or Boost.serialization  libraries.\nUsing the same strategy of moving the implementation details down the\ninheritance hierarchy , this will quickly lead to a pretty complex and rather\nartificial hierarchy (see Figure 5-3 ). Consider the class names:\nOpenGLProtobufCircle, MetalBoostSerial Square, and so on.\nRidiculous, right? And how should we structure this: should we add another\nlayer in the hierarchy (see the Square branch)? That approach would\nquickly lead to a deep and complex hierarchy . Or should we rather flatten\nthe hierarchy out (as in the Circle branch of the hierarchy)? And what\nabout reusing implementation details? For instance, how would it be\npossible to reuse the OpenGL code between the OpenGLProtobufCircle\nand the OpenGLBoostSerialCircle classes?",5434
54-The Strategy Design Pattern Explained.pdf,54-The Strategy Design Pattern Explained,"Figur e 5-3. Adding the serialize() member function r esults in a deep and complex inheritance\nhierar chy\nThe Strategy Design Pattern Explained\nYou realize that your colleagues are just too enamored with inheritance, and\nthat it’ s up to you to save the day . They appear to need someone to show\nthem how to properly design for this kind of change and present them a\nproper solution to the problem. As the two pragmatic programmers\nremarked:\nInheritance is rar ely the answer .\nThe problem is still the violation of the SRP . Since you have to plan for\nchanging how the dif ferent shapes are drawn, you should identify the\ndrawing aspect as a variation point . With this realization, the correct\napproach is to design for change, follow the SRP , and thus extract the\nvariation point. That is the intent of the Strategy design pattern, one of the\nclassic GoF design patterns.\nTHE STRATEGY DESIGN PATTERN\nIntent: “Define  a family of algorithms, encapsulate each one, and make them\ninterchangeable. Strategy lets the algorithm vary independently from clients that use\nit.”\nInstead of implementing the virtual draw() function in a derived class, you\nintroduce another class for the purpose of drawing shapes. In the case of the\nclassic, object-oriented (OO) form of the Strategy design pattern, this is\nachieved by introducing the DrawStrategy base class  (see Figure 5-4 ).3\n4\nFigur e 5-4. The UML r epresentation of the Strategy  design pattern\nThe isolation of the drawing aspect now allows us to change the\nimplementation of drawing without having to modify the shape classes.\nThis fulfills the idea of the SRP . You are now also able to introduce new\nimplementations of draw() without modification of any other code. That\nfulfills the Open-Closed Principle (OCP). Once again, in this OO setting,\nSRP is the enabler of the OCP .\nThe following code snippet shows a naive implementation of the\nDrawStrategy base class:\n \n//---- <DrawStrategy.h> ---------------- \n \nclass Circle; \nclass Square; 5\n \nclass DrawStrategy \n{ \n public: \n   virtual ~DrawStrategy() = default; \n \n   virtual void draw( Circle const& circle, /*some arguments*/ ) const = 0;  \n \n   virtual void draw( Square const& square, /*some arguments*/ ) const = 0;  \n \n}; \nThe DrawStrategy class comes with a virtual destructor and two pure\nvirtual draw() functions, one for circles (\n ) and one for squares (\n ). For\nthis base class to compile, you need to forward declare the Circle and the\nSquare classes.\nThe Shape base class does not change due to the Strategy design pattern. It\nstill represents an abstraction for all shapes and thus of fers a pure virtual\ndraw() member function. Strategy aims at extracting implementation\ndetails and thus af fects only the derived classes:\n//---- <Shape.h> ---------------- \n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n \n   virtual void draw( /*some arguments*/ ) const = 0; \n   // ... Potentially other functions, e.g. a 'serialize()' member function \n};\nWhile the Shape base class does not change due to Strategy , the Circle and\nSquare classes are af fected:\n \n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n#include <DrawStrategy.h> \n#include <memory> \n#include <utility> \n \nclass Circle : public Shape 6\n{ \n public: \n   explicit Circle( double radius, std::unique_ptr<DrawStrategy> drawer )  \n \n      : radius_( radius ) \n      , drawer_( std::move(drawer) )  \n \n   { \n      /* Checking that the given radius is valid and that \n         the given std::unique_ptr instance is not nullptr */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_->draw( *this, /*some arguments*/ );  \n \n   } \n \n   double radius() const { return radius_; } \n \n private: \n   double radius_; \n   std::unique_ptr<DrawStrategy> drawer_;  \n \n}; \n \n \n//---- <Square.h> ---------------- \n \n#include <Shape.h> \n#include <DrawStrategy.h> \n#include <memory> \n#include <utility> \n \nclass Square : public Shape \n{ \n public: \n   explicit Square( double side, std::unique_ptr<DrawStrategy> drawer )  \n \n      : side_( side ) \n      , drawer_( std::move(drawer) )  \n \n   { \n      /* Checking that the given side length is valid and that \n         the given std::unique_ptr instance is not nullptr */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_->draw( *this, /*some arguments*/ );  \n \n   } \n \n   double side() const { return side_; }",4530
55-Analyzing the Shortcomings of the Naive Solution.pdf,55-Analyzing the Shortcomings of the Naive Solution,"private: \n   double side_; \n   std::unique_ptr<DrawStrategy> drawer_;  \n \n}; \nBoth Circle and Square are now expecting a unique_ptr to a\nDrawStrategy in their constructors (\n ). This allows us to configure the\ndrawing behavior from the outside, commonly called dependency injection .\nThe unique_ptr is moved (\n ) into a new data member of the same type (\n). It is also possible to provide corresponding setter functions , which would\nallow you to change the drawing behavior at a later point. The draw()\nmember function now doesn’ t have to implement the drawing itself but\nsimply has to call the draw() function for the given DrawStrategy (\n).\nAnalyzing the Shortcomings of the Naive Solution\nWonderful! W ith this implementation in place, you are now able to locally ,\nin isolation, change the behavior of how shapes are drawn, and you enable\neveryone to implement the new drawing behavior . However , as it is right\nnow, our Strategy implementation has a serious design flaw . To analyze this\nflaw, let’s assume that you have to add a new kind of shape, maybe a\nTriangle. This should be easy , because, as we have discussed in\n“Guideline 15: Design for the Addition of Types or Operations ”, the\nstrength of OOP is the addition of new types.\nAs you’re starting to introduce this Triangle, you realize that it’ s not as\neasy to add the new kind of shape as expected. First, you need to write the\nnew class. That is to be expected and not a problem at all. But then you\nhave to update the DrawStrategy base class to also enable the drawing of\ntriangles. This, in turn, will have an unfortunate impact on circles and\nsquares: both the Circle and Square classes need to be recompiled,\nretested, and potentially redeployed. More generally speaking, all shapes\nare af fected in this way . And that should strike you as problematic. Why\nshould circles and squares have to recompile if you add a Triangle class?\nThe technical reason is that via the DrawStrategy base class, all shapes\nimplicitly know about one another . Adding a new shape therefore af fects all7\nother shapes. The underlying design reason is a violation of the Interface\nSegregation Principle (ISP) (see “Guideline 3: Separate Interfaces to A void\nArtificial Coupling ”). By defining a single DrawStrategy base class, you\nhave artificially coupled circles, squares, and triangles together . Due to this\ncoupling, you have made it more dif ficult to add new types and thus have\nlimited the strength of OOP . In comparison, you have created a very similar\nsituation as we had when we talked about a procedural solution for the\ndrawing of shapes (see “Guideline 15: Design for the Addition of Types or\nOperations ”).\n“Didn’ t we unintentionally reimplement the V isitor design pattern?” you are\nwondering. I see your point: the DrawStrategy looks very similar to a\nVisitor indeed. But unfortunately , it does not fulfill the intent of a V isitor ,\nsince you cannot easily add other operations. T o do so, you would have to\nintrusively add a virtual member function  in the Shape hierarchy . “And it is\nnot a Strategy either , because we cannot add types, right?” Y es, correct. Y ou\nsee, from a design perspective, this is the worst kind of situation.\nTo properly implement the Strategy design pattern, you have to extract the\nimplementation details of each shape separately . You have to introduce one\nDrawStrategy class for each kind of shape:\n \n//---- <DrawCircleStrategy.h> ---------------- \n \nclass Circle; \n \nclass DrawCircleStrategy  \n \n{ \n public: \n   virtual ~DrawCircleStrategy() = default; \n \n   virtual void draw( Circle const& circle, /*some arguments*/ ) const = 0; \n}; \n \n \n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n#include <DrawCircleStrategy.h> \n#include <memory> \n#include <utility> \n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius, std::unique_ptr<DrawCircleStrategy> drawer \n) \n      : radius_( radius ) \n      , drawer_( std::move(drawer) ) \n   { \n      /* Checking that the given radius is valid and that \n         the given 'std::unique_ptr' is not a nullptr */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_->draw( *this, /*some arguments*/ ); \n   } \n \n   double radius() const { return radius_; } \n \n private: \n   double radius_; \n   std::unique_ptr<DrawCircleStrategy> drawer_; \n}; \n \n \n//---- <DrawSquareStrategy.h> ---------------- \n \nclass Square; \n \nclass DrawSquareStrategy  \n \n{ \n public: \n   virtual ~DrawSquareStrategy() = default; \n \n   virtual void draw( Square const& square, /*some arguments*/ ) const = 0; \n}; \n \n \n//---- <Square.h> ---------------- \n \n#include <Shape.h> \n#include <DrawSquareStrategy.h> \n#include <memory> \n#include <utility> \n \nclass Square : public Shape \n{ \n public: \n   explicit Square( double side, std::unique_ptr<DrawSquareStrategy> drawer ) \n      : side_( side ) \n      , drawer_( std::move(drawer) ) \n   { \n      /* Checking that the given side length is valid and that \n         the given 'std::unique_ptr' is not a nullptr */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_->draw( *this, /*some arguments*/ ); \n   } \n \n   double side() const { return side_; } \n \n private: \n   double side_; \n   std::unique_ptr<DrawSquareStrategy> drawer_; \n}; \nFor the Circle class, you have to introduce the DrawCircleStrategy base\nclass (\n ), and for the Square class, it is the DrawSquareStrategy (\n) base\nclass. And with the addition of a Triangle class, you will also have to add\na DrawTriangleStrategy base class. Only in this way can you properly\nseparate concerns and still allow everyone to add new types and new\nimplementations for the drawing of shapes.\nWith this functionality in place, you can easily implement new Strategy\nclasses for drawing circles, squares, and eventually triangles. As an\nexample, consider the OpenGLCircleStrategy, which implements the\nDrawCircleStrategy interface:\n//---- <OpenGLCircleStrategy.h> ---------------- \n \n#include <Circle.h> \n#include <DrawCircleStrategy.h> \n#include /* OpenGL graphics library */ \n \nclass OpenGLCircleStrategy : public DrawCircleStrategy \n{ \n public: \n   explicit OpenGLCircleStrategy( /* Drawing related arguments */ ); \n \n   void draw( Circle const& circle, /*...*/ ) const override; \n \n private: \n   /* Drawing related data members, e.g. colors, textures, ... */ \n};\nIn Figure 5-5  you can see the dependency graph for the Circle class. Note\nthat the Circle and DrawCircleStrategy classes are on the same\narchitectural level. Even more noteworthy is the cyclic dependency between\nthem: Circle depends on the DrawCircleStrategy, but the\nDrawCircleStrategy also depends on Circle. But don’ t worry: although\nthis may look like a problem at first sight, it isn’ t. It is a necessary\nrelationship that shows that Circle really owns the DrawCircleStrategy\nand by that creates the desired dependency inversion, as discussed in\n“Guideline 9: Pay Attention to the Ownership of Abstractions” .\n“Wouldn’ t it be possible to implement the dif ferent draw Strategy classes\nusing a class template? I’m imagining something similar to the V isitor class\nused for the Acyclic V isitor”:\n//---- <DrawStrategy.h> ---------------- \n \ntemplate< typename T > \nclass DrawStrategy \n{ \n public: \n   virtual ~DrawStrategy() = default; \n   virtual void draw( T const& ) const = 0; \n};8\nFigur e 5-5. Dependency graph for the Strategy  design pattern\nThis is a great idea and exactly what you should do. By means of this class\ntemplate, you can lift the DrawStrategy up into a higher architectural level,\nreuse code, and follow the DR Y principle (see Figure 5-6 ). Additionally , if\nwe would have used this approach from the start, we would not have fallen\ninto the trap of artificially coupling the dif ferent shape types. Y es, I really\nlike that!\nAlthough  this is how we would implement such a Strategy class, you still\nshould not expect that this will reduce the number of base classes (it’ s still\nthe same, just generated) or that it will save you a lot of work. The\nimplementations of DrawStrategy, such as the OpenGLCircleStrategy\nclass, represent most of the work and will hardly change:\n//---- <OpenGLCircleStrategy.h> ---------------- \n \n#include <Circle.h> \n#include <DrawStrategy.h> \n#include /* OpenGL graphics library */ \n \nclass OpenGLCircleStrategy : public DrawStrategy<Circle> \n{ \n   // ... \n};",8597
56-Analyzing the Shortcomings of the Strategy Design Pattern.pdf,56-Analyzing the Shortcomings of the Strategy Design Pattern,"Figur e 5-6. Updated dependency graph for the Strategy  design pattern\nAssuming a similar implementation for the OpenGLSquareStrategy, we\ncan now put everything together and draw shapes again but this time\nproperly decoupled with the Strategy design pattern:\n#include <Circle.h> \n#include <Square.h> \n#include <OpenGLCircleStrategy.h> \n#include <OpenGLSquareStrategy.h> \n#include <memory> \n#include <vector> \n \nint main() \n{ \n   using Shapes = std::vector<std::unique_ptr<Shape>>; \n \n   Shapes shapes{}; \n \n   // Creating some shapes, each one \n   //   equipped with the corresponding OpenGL drawing strategy \n   shapes.emplace_back( \n      std::make_unique<Circle>( \n         2.3, std::make_unique<OpenGLCircleStrategy>(/*...red...*/) ) ); \n   shapes.emplace_back( \n      std::make_unique<Square>( \n         1.2, std::make_unique<OpenGLSquareStrategy>(/*...green...*/) ) ); \n   shapes.emplace_back( \n      std::make_unique<Circle>( \n         4.1, std::make_unique<OpenGLCircleStrategy>(/*...blue...*/) ) ); \n \n   // Drawing all shapes \n   for( auto const& shape : shapes ) \n   { \n      shape->draw( /*some arguments*/ ); \n   } \n \n   return EXIT_SUCCESS; \n}\nComparison Between V isitor and Strategy\nAs you have now learned about both the V isitor and Strategy design\npatterns, you might wonder what the dif ference between the two is. After\nall, the implementation looks fairly similar . But while there are parallels in\nimplementation, the properties of the two design patterns are very dif ferent.\nWith the V isitor design pattern, we have identified the general  addition of\noperations as the  variation point . Therefore, we created an abstraction for\noperations in general, which in turn allowed everyone to add operations.\nThe unfortunate side ef fect was that it was no longer easy to add new shape\ntypes.\nWith the Strategy design pattern, we have identified the implementation\ndetails of a single  function as a variation point . After introducing an\nabstraction for these implementation details, we’re still able to easily add\nnew types of shapes, but we are not able to easily add new operations.\nAdding an operation would still require you to intrusively add a virtual\nmember function. Hence, the intent of the Strategy design pattern is the\nopposite of the intent of the V isitor design pattern.\nIt may sound promising to combine the two design patterns to gain the\nadvantages of both ideas (making it easy to add both types and operations).\nUnfortunately , this does not work: whichever of the two design patterns you\napply first will fix one of the two axes of freedom.  Therefore, you should\njust remember the strengths and weaknesses of these two design patterns\nand apply them based on your expectations of how your codebase will\nevolve.\nAnalyzing the Shortcomings of the Strategy Design\nPattern\nI have shown you the advantages of the Strategy design pattern: it allows\nyou to reduce the dependencies on a particular implementation detail by\nintroducing an abstraction for that detail. However , there is no silver bullet\nin software design, and every design comes with a number of drawbacks.\nThe Strategy design pattern is no exception, and it’ s important to also take\npotential disadvantages into account.\nFirst, while the implementation details of a certain operation have been\nextracted and isolated, the operation itself is still part of the concrete type.9\nThis fact is evidence of the aforementioned limitation that we are still not\nable to easily add operations. Strategy , in contrast to V isitor , preserves the\nstrength of OOP and enables you to easily add new types.\nSecond, it pays of f to identify such variation points early . Otherwise a lar ge\nrefactoring is required. Of course, this doesn’ t mean you should implement\neverything with Strategy up front, just in case, to avoid a refactoring. This\ncould quickly result in overengineering. But at the first indication that an\nimplementation detail might change, or that there is a desire to have\nmultiple implementations, you should rather quickly implement the\nnecessary modifications. The best, but of course a little insubstantial, advice\nis to keep things as simple  as possible (the KISS  principle ; Keep It Simple,\nStupid).\nThird, if you implement Strategy by means of a base class, the performance\nwill certainly take a hit by the additional runtime indirection. The\nperformance is also af fected by the many manual allocations (the\nstd::make_unique() calls), the resulting memory fragmentation, and the\nvarious indirections due to numerous pointers. This is to be expected, yet\nthe flexibility of your implementation and the opportunity for everyone to\nadd new implementations may outweigh this performance penalty . Of\ncourse, it depends, and you will have to decide on a case-by-case basis. If\nyou implement Strategy using templates (see the discussion about “Policy-\nBased Design” ), this disadvantage is of no concern.\nLast but not least, the major disadvantage of the Strategy design pattern is\nthat a single Strategy should deal with either a single operation or a small\ngroup of cohesive functions. Otherwise you would again violate the SRP . If\nthe implementation details of multiple operations need to be extracted, there\nwill have to be multiple Strategy base classes and multiple data members,\nwhich can be set via dependency injection . Consider , for instance, the\nsituation with an additional serialize() member function:\n//---- <DrawCircleStrategy.h> ---------------- \n \nclass Circle; \n \nclass DrawCircleStrategy \n{ \n public: \n   virtual ~DrawCircleStrategy() = default; \n \n   virtual void draw( Circle const& circle, /*some arguments*/ ) const = 0; \n}; \n \n \n//---- <SerializeCircleStrategy.h> ---------------- \n \nclass Circle; \n \nclass SerializeCircleStrategy \n{ \n public: \n   virtual ~SerializeCircleStrategy() = default; \n \n   virtual void serialize( Circle const& circle, /*some arguments*/ ) const = \n0; \n}; \n \n \n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n#include <DrawCircleStrategy.h> \n#include <SerializeCircleStrategy.h> \n#include <memory> \n#include <utility> \n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius \n                  , std::unique_ptr<DrawCircleStrategy> drawer \n                  , std::unique_ptr<SerializeCircleStrategy> serializer \n                  /* potentially more strategy-related arguments */ ) \n      : radius_( radius ) \n      , drawer_( std::move(drawer) ) \n      , serializer_( std::move(serializer) ) \n      // ... \n   { \n      /* Checking that the given radius is valid and that \n         the given std::unique_ptrs are not nullptrs */ \n   } \n \n   void draw( /*some arguments*/ ) const override",6836
57-Policy-Based Design.pdf,57-Policy-Based Design,"{ \n      drawer_->draw( *this, /*some arguments*/ ); \n   } \n \n   void serialize( /*some arguments*/ ) const override \n   { \n      serializer_->serialize( *this, /*some arguments*/ ); \n   } \n \n   double radius() const { return radius_; } \n \n private: \n   double radius_; \n   std::unique_ptr<DrawCircleStrategy> drawer_; \n   std::unique_ptr<SerializeCircleStrategy> serializer_; \n   // ... Potentially more strategy-related data members \n};\nWhile this leads to a very unfortunate proliferation of base classes and\nlarger instances due to multiple pointers, it also raises the question of how\nto design the class so that it’ s possible to conveniently assign multiple\ndifferent strategies. Therefore, the Strategy design pattern appears to be\nstrongest in situations where you need to isolate a small number of\nimplementation details. If you encounter a situation where you need to\nextract the details of many operations, it might be better to consider other\napproaches (see, for instance, the External Polymorphism design pattern in\nChapter 7  or the T ype Erasure design pattern in Chapter 8 ).\nPolicy-Based Design\nAs already demonstrated in previous chapters, the Strategy design pattern is\nnot limited to dynamic polymorphism. On the contrary , the intent of\nStrategy can be implemented perfectly in static polymorphism using\ntemplates. Consider , for instance, the following two algorithms from the\nStandard Library:\n \nnamespace std { \n \ntemplate< typename ForwardIt, typename UnaryPredicate > \nconstexpr ForwardIt \n   partition( ForwardIt first, ForwardIt last, UnaryPredicate p );  \n \n \ntemplate< typename RandomIt, typename Compare > \nconstexpr void \n   sort( RandomIt first, RandomIt last, Compare comp );  \n \n \n} // namespace std \nBoth the std::partition() and the std::sort() algorithm make use of\nthe Strategy design pattern. The UnaryPredicate argument of\nstd::partition() (\n) and the Compare argument of std::sort() (\n)\nrepresent a means to inject part of the behavior from outside. More\nspecifically , both ar guments allow you to specify how elements are ordered.\nHence, both algorithms extract a specific part of their behavior and provide\nan abstraction for it in the form of a concept (see “Guideline 7: Understand\nthe Similarities Between Base Classes and Concepts ”). This, in contrast to\nthe OO form of Strategy , does not incur any runtime performance penalty .\nA similar approach can be seen in the std::unique_ptr class template:\n \nnamespace std { \n \ntemplate< typename T, typename Deleter = std::default_delete<T> >  \n \nclass unique_ptr; \n \ntemplate< typename T, typename Deleter >  \n \nclass unique_ptr<T[], Deleter>; \n \n} // namespace std \nFor both the base template (\n ) and its specialization for arrays (\n ), it is\npossible to specify an explicit Deleter as the second template ar gument.\nWith this ar gument, you can decide whether you want to free the resource\nby means of delete, free(), or any other deallocation function. It’ s even\npossible to “abuse” std::unique_ptr to perform a completely dif ferent\nkind of cleanup.\nThis flexibility is also evidence for the Strategy design pattern. The\ntemplate ar gument allows you to inject some cleanup behavior into the\nclass. This form of Strategy is also called policy-based design , based on a\ndesign philosophy introduced by Andrei Alexandrescu in 2001.  The idea\nis the same: extract and isolate specific behavior of class templates to\nimprove changeability , extensibility , testability , and reusability . Thus,\npolicy-based design can be considered the static polymorphism form of the\nStrategy design pattern. And evidently , the design works really well, as the\nmany applications of this idea in the Standard Library demonstrate.\nYou can also apply policy-based design to the shape-drawing example.\nConsider the following implementation of the Circle class:\n \n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n#include <DrawCircleStrategy.h> \n#include <memory> \n#include <utility> \n \ntemplate< typename DrawCircleStrategy >  \n \nclass Circle : public Shape \n{ \n public: \n   explicit Circle( double radius, DrawCircleStrategy drawer ) \n      : radius_( radius ) \n      , drawer_( std::move(drawer) ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_( *this, /*some arguments*/ );  \n \n   } \n \n   double radius() const { return radius_; } \n \n private: \n   double radius_; \n   DrawCircleStrategy drawer_;  // Could possibly be omitted, if the given \n                                // strategy is presumed to be stateless. \n}; 10\nInstead of passing std::unique_ptr to a DrawCircleStrategy base class\nin the constructor , you could specify the Strategy with a template ar gument\n(\n). The biggest advantage would be the performance improvement due to\nfewer pointer indirections: instead of calling through std::unique_ptr,\nyou could directly call to the concrete implementation provided by the\nDrawCircleStrategy (\n). On the downside, you would lose the flexibility\nto adapt the drawing Strategy of a specific Circle instance at runtime.\nAlso, you wouldn’ t have a single Circle class anymore. Y ou would have\none instantiation of Circle for every drawing strategy . And last but not\nleast, you should keep in mind that class templates usually completely\nreside in header files. Y ou could therefore lose the opportunity to hide\nimplementation details in a source file. As always, there is no perfect\nsolution, and the choice of the “right” solution depends on the actual\ncontext.\nIn summary , the Strategy design pattern is one of the most versatile\nexamples in the catalog of design patterns. Y ou will find it useful in many\nsituations in the realm of dynamic as well as static polymorphism.\nHowever , it is not the ultimate solution for every problem—be aware of its\npotential disadvantages.\nGUIDELINE 19: USE STRATEGY TO ISOLATE HOW\nTHINGS ARE DONE\nUnderstand that inheritance is rarely the answer .\nApply the Strategy design pattern with the intent to extract the\nimplementation details of a cohesive set of functions.\nImplement one Strategy for each operation to avoid artificial\ncoupling.\nConsider policy-based design as the compile-time form of the\nStrategy design pattern.",6407
58-Guideline 20 Favor Composition over Inheritance.pdf,58-Guideline 20 Favor Composition over Inheritance,"Guideline 20: Favor Composition over\nInheritance\nAfter  the enormous sur ge of enthusiasm for OOP in the 90s and early\n2000s, OOP today is on the defensive. The voices that ar gue against OOP\nand highlight its disadvantages grow stronger and louder . This is not limited\nto the C++ communities but is also in other programming language\ncommunities. While OOP  in its entirety indeed has some limitations, let’ s\nfocus on the one feature that appears to generate most of the heat:\ninheritance. As Sean Parent remarked:\nInheritance is the base class of evil.\nWhile inheritance is sold as a very natural and intuitive way of modeling\nreal-world relations, it turns out to be much harder to use than promised.\nYou have already seen the subtle failures of using inheritance when we\ntalked about the Liskov Substitution Principle (LSP) in “Guideline 6:\nAdhere to the Expected Behavior of Abstractions” . But there are other\naspects of inheritance that are often misunderstood.\nFirst and foremost, inheritance is always described as simplifying\nreusability . This seems intuitive, since it appears obvious that you can reuse\ncode easily if you just inherit from another class. Unfortunately , that’ s not\nthe kind of reuse inheritance brings to you. Inheritance is not about reusing\ncode in a base class; instead, it is about being reused by other code that uses\nthe base class polymorphically . For instance, assuming a slightly extended\nShape base class, the following functions work for all kinds of shapes and\nthus can be reused by all implementations of the Shape base class:\n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n \n   virtual void translate( /*some arguments*/ ) = 0; \n   virtual void rotate( /*some arguments*/ ) = 0; \n 1 1\n   virtual void draw( /*some arguments*/ ) const = 0; \n   virtual void serialize( /*some arguments*/ ) const = 0; \n \n   // ... Potentially other member functions ... \n}; \n \nvoid rotateAroundPoint( Shape& shape );  \n \nvoid mergeShapes( Shape& s1, Shape& s2 );  \n \nvoid writeToFile( Shape const& shape );  \n \nvoid sendViaRPC( Shape const& shape );  \n \n// ... \nAll four functions (\n , \n, \n, and \n ) are built on the Shape abstraction. All of\nthese functions are coupled only to the common interface of all kinds of\nshapes but not to any specific shape. All kinds of shapes can be rotated\naround a point, mer ged, written to file, and sent via RPC. Every shape\n“reuses” this functionality .\nIt is the ability to express functionality by means of an abstraction that\ncreates the opportunity to reuse code. This functionality is expected to\ncreate a vast amount of code, in comparison to the small amount of code the\nbase class contains. Real reusability , therefore, is created by the\npolymorphic use of a type, not by polymorphic types.\nSecond, inheritance is said to help in decoupling software entities. While\nthat is most certainly true (remember , for instance, the discussion about the\nDependency Inversion Principle (DIP) in “Guideline 9: Pay Attention to the\nOwnership of Abstractions” ), it’s often not explained that inheritance also\ncreates coupling. Y ou’ve seen evidence of that before. While implementing\nthe V isitor design pattern, you experienced that inheritance forces certain\nimplementation details on you. In a classic V isitor , you have to implement\nthe pure virtual functions of a Visitor base class as they are required, even\nif this is not optimal for your application. Y ou also don’ t have a lot of\nchoices with respect to the function ar guments or return types. These things\nare fixed.\nYou also experienced this coupling at the beginning of the discussion on the\nStrategy design pattern. In this case, inheritance forced a structural coupling12\n13\nthat caused a deep(er) inheritance hierarchy , resulted in questionable\nnaming of classes, and impaired reuse.\nAt this point, you might get the impression that I’m trying to discredit\ninheritance completely . Well, to be honest, I am trying to make it look just a\nlittle bad, but only as much as necessary . To state it clearly: inheritance is\nnot bad, nor is it wrong to use it. On the contrary: inheritance is a very\npowerful feature, and if used properly you can do incredible things with it.\nHowever , of course you remember the Peter Parker Principle :\nWith gr eat power comes gr eat responsibility .\n—Peter Parker , aka Spider -Man\nThe problem is the “if used properly” part. Inheritance has proven to be\nhard to use properly (definitely harder than we are led to believe; see my\nprevious reasonings), and thus is misused unintentionally . It is also\noverused, as many developers have the habit of using it for every kind of\nproblem.  This overuse appears to be the source of many problems, as\nMichael Feathers remarks:\n[Programming by differ ence]  fell out of favor in the 1990s when many\npeople in the OO community noticed that inheritance can be rather\nproblematic if it is overused.\nIn many situations, inheritance is neither the right approach nor the right\ntool. Most of the time it is preferable to use composition instead. You\nshould not be surprised by that revelation, though, because you have\nalready seen it to be true. Composition is the reason the OO form of the\nStrategy design pattern works so well, not inheritance. It is the introduction\nof an abstraction and the aggregation of corresponding data members that\nmake the Strategy design pattern so powerful, not the inheritance-based\nimplementation of dif ferent strategies. In fact, you will find that many\ndesign patterns are firmly based on composition, not on inheritance.  All\nof these enable extension by means of inheritance but are themselves\nenabled by means of composition .14\n15\n16\n17",5796
59-The Command Design Pattern Explained.pdf,59-The Command Design Pattern Explained,"Delegate to Services: Has-A T rumps Is-A.\n—Andrew Hunt and David Thomas, The Pragmatic\nProgrammer\nThis is a general takeaway for many design patterns. I suggest you keep this\ninsight close at hand, as it will prove very useful in understanding the\ndesign patterns that you will see in the remainder of this book, and will\nimprove the quality of your implementations.\nGUIDELINE 20: FAVOR COMPOSITION OVER\nINHERITANCE\nUnderstand that inheritance is often overused and sometimes even\nmisused.\nKeep in mind that inheritance creates a tight coupling.\nRealize that many design patterns are enabled by composition, not\nby inheritance .\nGuideline 21: Use Command to Isolate What\nThings Are Done\nBefore  we get started with this guideline, let’ s try an experiment. Open your\npreferred email client and write an email to me. Add the following content:\n“I love your book! It keeps me up all night and makes me for get all my\ntroubles.” OK, great. Now click Send. Good job! Give me a second to\ncheck my emails…No, it’ s not here yet…No, still not here…Let’ s try again:\nClick Resend. No, nothing. Hmm, I guess some server must be down. Or all\nof my Commands simply failed: the WriteCommand, the SendCommand, the\nResendCommand, and so on. How unfortunate. But despite this failed\nexperiment, you now have a pretty good idea of another GoF design\npattern: the Command design pattern.\nThe Command Design Pattern Explained\nThe Command design pattern focuses on the abstraction and isolation of\nwork packages that (most often) are executed once and (usually)\nimmediately . For that purpose, it recognizes the existence of dif ferent kinds\nof work packages  as variation points  and introduces the corresponding\nabstraction that allows the easy implementation of new kinds of work\npackages.\nTHE COMMAND DESIGN PATTERN\nIntent: “Encapsulate  a request as an object, thereby letting you parameterize clients with\ndifferent requests, queue or log requests, and support undoable operations.”\nFigure 5-7  shows  the original UML formulation, taken from the GoF book.1 8\nFigur e 5-7. The UML r epresentation of the Command  design pattern\nIn this OO-based form, the Command pattern introduces an abstraction in\nthe form of the Command base class. This enables anyone to implement a\nnew kind of ConcreteCommand. That ConcreteCommand can do anything,\neven perform an action on some kind of Receiver. The ef fect of a\ncommand is triggered via the abstract base class by a particular kind of\nInvoker.\nAs a concrete example of the Command design pattern, let’ s consider the\nfollowing implementation of a calculator . The first code snippet shows the\nimplementation of a CalculatorCommand base class, which represents the\nabstraction of a mathematical operation on a given integer:\n \n//---- <CalculatorCommand.h> ---------------- \n \nclass CalculatorCommand \n{ \n public: \n   virtual ~CalculatorCommand() = default; \n \n   virtual int execute( int i ) const = 0;  \n \n   virtual int undo( int i ) const = 0;  \n \n}; \nThe CalculatorCommand class expects derived classes to implement both\nthe pure virtual execute() function (\n ) and the pure virtual undo()\nfunction (\n ). The expectation for undo() is that it implements the necessary\nactions to reverse the ef fect of the execute() function.\nThe Add and Subtract classes both represent possible commands for a\ncalculator and therefore implement the CalculatorCommand base class:\n \n//---- <Add.h> ---------------- \n \n#include <CalculatorCommand.h> \n \nclass Add : public CalculatorCommand \n{ \n public: \n   explicit Add( int operand ) : operand_(operand) {} \n \n   int execute( int i ) const override  \n \n   { \n      return i + operand_; \n   } \n   int undo( int i ) const override  \n \n   { \n      return i - operand_; \n   } \n \n private: \n   int operand_{}; \n}; \n \n \n//---- <Subtract.h> ---------------- \n \n#include <CalculatorCommand.h> \n \nclass Subtract : public CalculatorCommand \n{ \n public: \n   explicit Subtract( int operand ) : operand_(operand) {} \n \n   int execute( int i ) const override  \n \n   { \n      return i - operand_; \n   } \n   int undo( int i ) const override  \n \n   { \n      return i + operand_; \n   } \n \n private: \n   int operand_{}; \n}; \nAdd implements the execute() function using an addition operation (\n )\nand the undo() function using a subtraction operation (\n ). Subtract\nimplements the inverse (\n  and \n ).\nThanks to the CalculatorCommand hierarchy , the Calculator class itself\ncan be kept rather simple:\n \n//---- <Calculator.h> ---------------- \n \n#include <CalculatorCommand.h> \n#include <stack> \n \nclass Calculator \n{ \n public: \n   void compute( std::unique_ptr<CalculatorCommand> command );  \n \n   void undoLast();  \n \n \n   int result() const; \n   void clear(); \n \n private: \n   using CommandStack = std::stack<std::unique_ptr<CalculatorCommand>>; \n \n   int current_{};  \n \n   CommandStack stack_;  \n \n}; \n \n \n//---- <Calculator.cpp> ---------------- \n \n#include <Calculator.h> \n \nvoid Calculator::compute( std::unique_ptr<CalculatorCommand> command )  \n \n{ \n   current_ = command->execute( current_ ); \n   stack_.push( std::move(command) ); \n} \n \nvoid Calculator::undoLast()  \n \n{ \n   if( stack_.empty() ) return; \n \n   auto command = std::move(stack_.top()); \n   stack_.pop(); \n \n   current_ = command->undo(current_); \n} \n \nint Calculator::result() const \n{ \n   return current_; \n} \n \nvoid Calculator::clear() \n{ \n   current_ = 0; \n   CommandStack{}.swap( stack_ );  // Clearing the stack \n} \nThe only functions we need for the computing activities are compute() (\n)\nand undoLast() (\n). The compute() function is passed a\nCalculatorCommand instance, immediately executes it to update the current\nvalue (\n ), and stores it on the stack (\n ). The undoLast() function reverts\nthe last executed command by popping it from the stack and calling\nundo().\nThe main() function combines all of the pieces:\n \n//---- <Main.cpp> ---------------- \n \n#include <Calculator.h> \n#include <Add.h> \n#include <Subtract.h> \n#include <cstdlib> \n \nint main() \n{ \n   Calculator calculator{};  \n \n \n   auto op1 = std::make_unique<Add>( 3 );  \n \n   auto op2 = std::make_unique<Add>( 7 );  \n \n   auto op3 = std::make_unique<Subtract>( 4 );  \n \n   auto op4 = std::make_unique<Subtract>( 2 );  \n \n \n   calculator.compute( std::move(op1) );  // Computes 0 + 3, stores and \nreturns 3 \n   calculator.compute( std::move(op2) );  // Computes 3 + 7, stores and \nreturns 10 \n   calculator.compute( std::move(op3) );  // Computes 10 - 4, stores and \nreturns 6 \n   calculator.compute( std::move(op4) );  // Computes 6 - 2, stores and \nreturns 4 \n \n   calculator.undoLast();  // Reverts the last operation, \n                           // stores and returns 6 \n \n   int const res = calculator.result();  // Get the final result: 6 \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nWe first create a calculator (\n) and a series of operations (\n , \n, \n, and \n ),\nwhich we apply one after another . After that, we revert op4 by means of the\nundo() operation before we query the final result.\nThis design very nicely follows the SOLID principles.  It adheres to the\nSRP since the variation point  has already been extracted by means of the\nCommand design pattern. As a result, both compute() and undo() do not\nhave to be virtual functions. The SRP also acts as an enabler for the OCP ,19\nwhich allows us to add new operations without having to modify any\nexisting code. Last, but not least, if the ownership for the Command base\nclass is properly assigned to the high level, then the design also adheres to\nthe DIP  (see Figure 5-8 ).\nFigur e 5-8. Dependency graph for the Command  design pattern\nThere is a second example of the Command design pattern that belongs in\nthe category of classic examples: a thread pool . The purpose of a thread\npool is to maintain multiple threads waiting for tasks to be executed in\nparallel. This idea is implemented by the following ThreadPool class: it\nprovides a couple of member functions to of fload certain tasks to a specific\nnumber of available threads: \n \nclass Command  \n \n{ /* Abstract interface to perform and undo any kind of action. */ }; \n \nclass ThreadPool \n{ \n public: \n   explicit ThreadPool( size_t numThreads ); \n \n   inline bool   isEmpty() const; \n   inline size_t size()    const; \n   inline size_t active()  const; \n   inline size_t ready()   const; \n \n   void schedule( std::unique_ptr<Command> command );  \n \n \n   void wait(); \n \n   // ... \n}; \nMost importantly , the ThreadPool allows you to schedule a task via the\nschedule() function (\n ). This can be any task: the ThreadPool is not at all\nconcerned about what kind of work its threads will have to perform. W ith\nthe Command base class, it is completely decoupled from the actual kind of\ntask you schedule (\n ).\nBy simply deriving from Command, you can formulate arbitrary tasks:\n \nclass FormattingCommand : public Command  \n \n{ /* Implementation of formatting a disk */ }; \n \nclass PrintCommand : public Command  \n \n{ /* Implementation of performing a printer job */ } \n \nint main() \n{ 20\n   // Creating a thread pool with initially two working threads \n   ThreadPool threadpool( 2 ); \n \n   // Scheduling two concurrent tasks \n   threadpool.schedule( \n      std::make_unique<FormattingCommand>( /*some arguments*/ ) ); \n   threadpool.schedule( \n      std::make_unique<PrintCommand>( /*some arguments*/ ) ); \n \n   // Waiting for the thread pool to complete both commands \n   threadpool.wait(); \n \n   return EXIT_SUCCESS; \n} \nOne possible example of such a task is a FormattingCommand (\n). This\ntask would get the necessary information to trigger the formatting of a disk\nvia the operating system. Alternatively , you can imagine a PrintCommand\nthat receives all data to trigger a printer job (\n ).\nAlso in this ThreadPool example, you recognize the ef fect of the\nCommand design pattern: the dif ferent kinds of tasks are identified as a\nvariation point  and are extracted (which again follows the SRP), which\nenables you to implement dif ferent kinds of tasks without the need to\nmodify existing code (adherence to the OCP).\nOf course, there are also some examples from the Standard Library . For\ninstance, you will see the Command design pattern in action in the\nstd::for_each() (\n) algorithm:\n \nnamespace std { \n \ntemplate< typename InputIt, typename UnaryFunction > \nconstexpr UnaryFunction \n   for_each( InputIt first, InputIt last, UnaryFunction f );  \n \n \n} // namespace std \nWith the third ar gument, you can specify what  task the algorithm is\nsupposed to perform on all of the given elements. This can be any action,",10877
60-The Command Design Pattern Versus the Strategy Design Pattern.pdf,60-The Command Design Pattern Versus the Strategy Design Pattern,"ranging from manipulating the elements to printing them, and can be\nspecified by something as simple as a function pointer to something as\npowerful as a lambda:\n#include <algorithms> \n#include <cstdlib> \n \nvoid multBy10( int& i ) \n{ \n   i *= 10; \n} \n \nint main() \n{ \n   std::vector<int> v{ 1, 2, 3, 4, 5 }; \n \n   // Multiplying all integers with 10 \n   std::for_each( begin(v), end(v), multBy10 ); \n \n   // Printing all integers \n   std::for_each( begin(v), end(v), []( int& i ){ \n      std::cout << i << '\n'; \n   } ); \n \n   return EXIT_SUCCESS; \n}\nThe Command Design Pattern V ersus the Strategy\nDesign Pattern\n“Wait a second!” I  can hear you cry out. “Didn’ t you just explain that the\nalgorithms of the Standard Library are implemented by means of the\nStrategy design pattern? Isn’ t this a complete contradiction of the previous\nstatement?” Y es, you are correct. Just a few pages back, I did explain that\nthe std::partition() and std::sort() algorithms are implemented by\nmeans of the Strategy design pattern. And therefore, I admit that it appears\nas if I am now contradicting myself. However , I did not claim that all the\nalgorithms are based on Strategy . So let me explain.\nFrom a structural point of view , the Strategy and Command design patterns\nare identical: whether you’re using dynamic or static polymorphism, from\nan implementation point of view , there is no dif ference between Strategy\nand Command.  The dif ference lies entirely in the intent of the two design\npatterns. Whereas the Strategy design pattern  specifies how something\nshould be done, the Command design pattern specifies what  should be\ndone. Consider , for instance, the std::partition() and\nstd::for_each() algorithms:\n \nnamespace std { \n \ntemplate< typename ForwardIt, typename UnaryPredicate > \nconstexpr ForwardIt \n   partition( ForwardIt first, ForwardIt last, UnaryPredicate p );  \n \n \ntemplate< typename InputIt, typename UnaryFunction > \nconstexpr UnaryFunction \n   for_each( InputIt first, InputIt last, UnaryFunction f );  \n \n \n} // namespace std \nWhereas you can only control how to select elements in the\nstd::partition() algorithm (\n ), the std::for_each() algorithm gives\nyou control over what  operation is applied to each element in the given\nrange (\n ). And whereas in the shapes example you could only specify how\nto draw a certain kind of shape, in the ThreadPool example you are\ncompletely in char ge of deciding what  operation is scheduled.\nThere are two other indicators for the two design patterns you have applied.\nFirst, if you have an object and configure it using an action (you perform\ndependency injection ), then you are (most likely) using the Strategy design\npattern. If you don’ t use the action to configure an object, but if instead the\naction is performed directly , then you are (most likely) using the Command\ndesign pattern. In our Calculator example, we did not pass an action to\nconfigure the Calculator, but instead the action was evaluated\nimmediately . Therefore, we built on the Command pattern.\nAlternatively , we could also implement Calculator by means of Strategy:21\n22\n \n//---- <CalculatorStrategy.h> ---------------- \n \nclass CalculatorStrategy \n{ \n public: \n   virtual ~CalculatorStrategy() = default; \n \n   virtual int compute( int i ) const = 0; \n}; \n \n \n//---- <Calculator.h> ---------------- \n \n#include <CalculatorStrategy.h> \n \nclass Calculator \n{ \n public: \n   void set( std::unique_ptr<CalculatorStrategy> operation );  \n \n   void compute( int value );  \n \n \n   // ... \n \n private: \n   int current_{}; \n   std::unique_ptr<CalculatorStrategy> operation_;  // Requires a default! \n}; \n \n \n//---- <Calculator.cpp> ---------------- \n \n#include <Calculator.h> \n \nvoid set( std::unique_ptr<CalculatorStrategy> operation )  \n \n{ \n   operation_ = std::move(operation); \n} \n \nvoid Calculator::compute( int value )  \n \n{ \n   current_ = operation_.compute( value ); \n} \nIn this implementation of a Calculator, the Strategy is injected by means\nof a set() function (\n ). The compute() function uses the injected Strategy",4182
61-The Shortcomings of the GoF Style Reference Semantics.pdf,61-The Shortcomings of the GoF Style Reference Semantics,"to perform a computation (\n ). Note, however , that this approach makes it\nmore dif ficult to implement a reasonable undo mechanism.\nThe second indicator to see whether you are using Command or Strategy is\nthe undo() operation. If your action provides an undo() operation to roll\nback what  it has done and encapsulates everything that is needed to perform\nthe undo(), then you are—most likely—dealing with the Command design\npattern. If your action doesn’ t provide an undo() operation, because it’ s\nfocused on how something is done or because it lacks the information to roll\nback the operation, then you are—most likely—dealing  with the Strategy\ndesign pattern. However , I should explicitly point out that the lack of an\nundo() operation is not conclusive evidence of Strategy . It could still be an\nimplementation of Command if the intent is to specify what  should be done.\nFor instance, the std::for_each() algorithm still expects a Command,\ndespite the fact that there is no need for an undo() operation. The undo()\noperation should be considered an optional feature of the Command design\npattern, not a defining one. In my opinion, undo() is not a strength of the\nCommand design pattern but a pure necessity: if an action has complete\nfreedom to do whatever it desires, then only this action alone will be able to\nroll the operation back (of course, assuming that you don’ t want to store a\ncomplete copy of everything for every call to a Command).\nI admit there is no clear separation between these two patterns and that\nthere is a gray area between them. However , there’ s no point in ar guing\nabout whether something is a Command or a Strategy and losing a couple\nof friends in the process. More important than agreeing on which one of the\ntwo you are using is exploiting their ability to extract implementation\ndetails and separate concerns. Both design patterns help you isolate changes\nand extensions and thus help you follow the SRP and OCP . After all, this\nability may be the reason why there are so many examples of these two\ndesign patterns in the C++ Standard Library .\nAnalyzing the Shortcomings of the Command Design\nPattern\nThe advantages of the Command design pattern are similar to those of the\nStrategy design pattern: Command helps you decouple from the\nimplementation details of concrete tasks by introducing some form of\nabstraction (for instance, a base class or a concept). This abstraction allows\nyou to easily add new tasks. Thus, Command satisfies both the SRP and the\nOCP.\nHowever , the Command design pattern also has its disadvantages. In\ncomparison to the Strategy design pattern, the list of disadvantages is pretty\nshort, though. The only real disadvantage is the added runtime performance\noverhead due to the additional indirection if you implement Command by\nmeans of a base class (the classic GoF style). Again, it’ s up to you to decide\nwhether the increased flexibility outweighs the loss of runtime\nperformance.\nIn summary , just like the Strategy design pattern, the Command design\npattern is one of the most basic and useful ones in the catalog of design\npatterns. Y ou will encounter implementations of Command in many\ndifferent situations, both static and dynamic. Thus, understanding the intent,\nadvantages, and disadvantages of Command will prove useful many times.\nGUIDELINE 21: USE COMMAND TO ISOLATE WHAT\nTHINGS ARE DONE\nApply the Command design pattern with the intent to abstract and\nencapsulate an (possibly undoable) action.\nBe aware that the line between the Command and the Strategy\ndesign pattern is fluid.\nUse Command for both dynamic and static applications.\nGuideline 22: Prefer Value Semantics over\nReference Semantics\nIn “Guideline 19: Use Strategy to Isolate How Things Are Done”  and\n“Guideline 21: Use Command to Isolate What Things Are Done ”, I\nintroduced you to the Strategy and Command design pattern, respectively .\nIn both cases, the examples were firmly built on the classic GoF style: they\nused dynamic polymorphism by means of an inheritance hierarchy . With\nthat classic object-oriented style lacking a modern touch, I imagine that by\nnow all your nail-biting has gotten you in trouble with your manicurist. And\nyou might be wondering: “Isn’ t there another , better way to implement\nStrategy and Command? A more ‘modern’ approach?” Y es, rest assured;\nthere is. And this approach is so important for the philosophy of what we\ncommonly call “Modern C++” that it definitely justifies a separate\nguideline to explain the advantages. I’m pretty sure your manicurist will\nunderstand the reason for this little detour .\nThe Shortcomings of the GoF Style: Reference\nSemantics\nThe design patterns collected by the Gang of Four and presented in their\nbook were introduced as object-oriented design patterns. Almost all of the\n23 design patterns described in their book are using at least one inheritance\nhierarchy and thus are firmly rooted in the realm of OO programming.\nTemplates, the obvious second choice, did not play any part in the GoF\nbook. This pure OO style is what I refer to as the GoF style . From today’ s\nperspective, that style may appear to be an old, outdated way of doing\nthings in C++, but of course we need to remember that the book was\nreleased in October 1994. At that time, templates may already have been a\npart of the language (at least they were of ficially described in the Annotated\nRefer ence Manual (ARM) ), but we didn’ t have template-related idioms, and\nC++ was still commonly perceived as an OO programming language.\nHence, the common way to use C++ was to primarily use inheritance.\nToday we know that the GoF style comes with a number of disadvantages.\nOne of the most important, and usually one of the most-often mentioned, is\nperformance:23\n24\nVirtual functions increase the runtime overhead and diminish the\ncompiler ’s opportunities to optimize.\nMany allocations of small polymorphic objects cost extra runtime,\nfragment the memory , and lead to suboptimal cache usage.\nThe way data is arranged is often counterproductive with respect to\ndata access schemes.\nPerformance truly is not one of the strong aspects of the GoF style. W ithout\ngoing into a complete discussion about all the possible shortcomings of the\nGoF style, let’ s instead focus on one other disadvantage that I consider of\nparticular interest: the GoF style falls into what we today call reference\nsemantics  (or sometimes also  pointer semantics ). This style got its name\nbecause it works primarily with pointers and references. T o demonstrate\nterm reference semantics means and why it usually comes with a rather\nnegative connotation, let’ s take a look at the following code example using\nthe C++20 std::span class template:\n \n#include <cstdlib> \n#include <iostream> \n#include <span> \n#include <vector> \n \nvoid print( std::span<int> s )  \n \n{ \n   std::cout << "" (""; \n   for( int i : s ) { \n      std::cout << ' ' << i; \n   } \n   std::cout << "" )\n""; \n} \n \nint main() \n{ \n   std::vector<int> v{ 1, 2, 3, 4 };  \n \n \n   std::vector<int> const w{ v };  \n \n   std::span<int> const s{ v };  \n \n \n   w[2] = 99;  // Compilation error!  \n 25\n   s[2] = 99;  // Works!  \n \n \n   // Prints ( 1 2 99 4 ); \n   print( s );  \n \n \n   v = { 5, 6, 7, 8, 9 };  \n \n   s[2] = 99;  // Works!  \n \n \n   // Prints ? \n   print( s );  \n \n \n   return EXIT_SUCCESS; \n} \nThe print() function (\n ) demonstrates the purpose of std::span. The\nstd::span class template represents an abstraction for an array . The\nprint() function can be called with any kind of array (built-in arrays,\nstd::array, std::vector, etc.) without coupling to any specific type of\narray . In the demonstrated example of std::span with a dynamic extent\n(no second template ar gument representing the size of the array), a typical\nimplementation of std::span contains two data members: a pointer to the\nfirst element of the array , and the size of the array . For that reason,\nstd::span is considered easy to copy and is usually passed by value. Apart\nfrom that, print() simply traverses the elements of the std::span (in our\ncase, integers) and prints them via std::cout.\nIn the main() function, we first create the std::vector<int> v and\nimmediately fill it with the integers 1, 2, 3, and 4 (\n). Then we create\nanother std::vector w as a copy of v (\n) and the std::span s (\n). Both w\nand s are qualified with const. Directly after that, we try to modify both w\nand s at index 2. The attempt to change w fails with a compilation error: w is\ndeclared const, and for that reason it’ s not possible to change the contained\nelements (\n ). The attempt to change s, however , works fine. There will be\nno compilation error , despite the fact that s is declared const (\n).\nThe reason for this is that s is not a copy of v and does not represent a\nvalue. Instead, it represents a reference to v. It essentially acts as a pointer\nto the first element of v. Thus, the const qualifier semantically has the\nsame ef fect as declaring a pointer const:\nstd::span<int> const s{ v };  // s acts as pointer to the first element of v \nint* const ptr{ v.data() };   // Equivalent semantical meaning\nWhile the pointer ptr cannot be changed and will refer to the first element\nof v throughout its lifetime, the referenced integer can be easily modified.\nTo prevent an assignment to the integer , you would need to add an\nadditional const qualifier for the int:\nstd::span<int const> const s{v};   // s represents a const pointer to a const \nint \nint const* const ptr{ v.data() };  // Equivalent semantical meaning\nSince the semantics of a pointer and std::span are equivalent, std::span\nobviously falls into the category of reference semantics. And this comes\nwith a number of additional dangers, as demonstrated in the remainder of\nthe main() function. As a next step, we print the elements referred to by s (\n). Note that instead, you could also pass the vector v directly , as the\nstd::span provides the necessary conversion constructors to accept\nstd::vector. The print() function will correctly result in the following\noutput:\n( 1 2 99 4 )\nBecause we can (and because by now , the numbers 1 through 4 probably\nstart to sound a little boring), we now assign a new set of numbers to the\nvector v (\n). Admittedly , the choice of 5, 6, 7, 8, and 9 is neither\nparticularly creative nor entertaining, but it will serve its purpose. Directly\nafterward, we again write to the second index by means of s (\n) and again\nprint the elements referred to by s (\n). Of course, we expect the output to\nbe ( 5 6 99 8 9 ), but unfortunately that is not the case. W e might get\nthe following output:\n( 1 2 99 4 )\nMaybe this completely shocks you and you end up with a few more gray\nhairs.  Perhaps you are merely surprised. Or you knowingly smile and26\n27",10960
62-Reference Semantics A Second Example.pdf,62-Reference Semantics A Second Example,"nod: yes, of course, undefined behavior! When assigning new values to the\nstd::vector v, we haven’ t just changed the values but also the size of the\nvector . Instead of four values, it now needs to store five elements. For that\nreason, the vector has (possibly) performed a reallocation and has thus\nchanged the address of its first element. Unfortunately , the std::span s\ndidn’ t get the note and still firmly holds onto the address of the previous\nfirst element. Hence, when we try to write to v by means of s, we do not\nwrite into the current array of v but to an already discarded piece of\nmemory that used to be the internal array of v. Classic undefined behavior ,\nand a classic problem of reference semantics.\n“Hey , are you trying to discredit std::span?” you ask. No, I am not trying\nto suggest that std::span, and also std::string_view, are bad. On the\ncontrary , I actually like these two a lot since they provide remarkably\nsimple and cheap abstractions from all kinds of arrays and strings,\nrespectively . However , remember that every tool has advantages and\ndisadvantages. When I use them, I use them consciously , fully aware that\nany nonowning reference type requires careful attention to the lifetime of\nthe value it references. For instance, while I consider both to be very useful\ntools for function ar guments, I tend to not use them as data members. The\ndanger of lifetime issues is just too high.\nReference Semantics: A Second Example\n“Well, of course I knew that,” you  argue. “I also wouldn’ t store std::span\nfor a longer period of time. However , I’m still not convinced that references\nand pointers are a problem.” OK, if that first example wasn’ t startling\nenough, I have a second example. This time I use one of the STL\nalgorithms, std::remove(). The std::remove() algorithm takes three\narguments: a pair of iterators for the range that is traversed to remove all\nelements of a particular value, and a third ar gument that represents the\nvalue to be removed. In particular , note that the third ar gument is passed by\na reference-to- const:\ntemplate< typename ForwardIt, typename T > \nconstexpr ForwardIt remove( ForwardIt first, ForwardIt last, T const& value );\nLet’s take a look at the following code example:\n \nstd::vector<int> vec{ 1, -3, 27, 42, 4, -8, 22, 42, 37, 4, 18, 9 };  \n \n \nauto const pos = std::max_element( begin(vec), end(vec) );  \n \n \nvec.erase( std::remove( begin(vec), end(vec), *pos ), end(vec) );  \n \nWe start with the std::vector v, which is initialized with a few random\nnumbers (\n ). Now we are interested in removing all the elements that\nrepresent the greatest value stored in the vector . In our example, that is the\nvalue 42, which is stored in the vector twice. The first step in performing\nthe removal is to determine the greatest value using the\nstd::max_element() algorithm. std::max_element() returns an iterator\nto the greatest value. If several elements in the range are equivalent to the\ngreatest element, it returns the iterator to the first such element (\n ).\nThe second step in removing the greatest values is a call to std::remove()\n(\n). We pass the range of elements using begin(vec) and end(vec), and\nthe greatest value by dereferencing the pos iterator . Last but not least, we\nfinish the operation with a call to the erase() member function: we erase\nall the values between the position returned by the std::remove()\nalgorithm and the end of the vector . This  sequence of operations is\ncommonly known as the erase-r emove idiom .\nWe expect that both 42 values are removed from the vector , and therefore\nwe expect to get the following result:\n( 1 -3 27 4 -8 22 37 4 18 9 )\nUnfortunately , this expectation does not hold. Instead, the vector now\ncontains the following values:\n( 1 -3 27 4 -8 22 42 37 18 9 )\nNote that the vector still contains a 42 but is now missing a 4 instead. The\nunderlying reason for this misbehavior is, again, reference semantics: by\npassing the dereferenced iterator to the remove() algorithm, we implicitly\nstate that the value stored in that location should be removed. However ,\nafter removing the first 42, this location holds the value 4. The remove()\nalgorithm removes all elements with the value 4. Hence, the next value that\nis removed is not the next 42 but the next 4, and so on.\n“OK, I got it! But that problem is history! T oday we don’ t use the erase-\nremove idiom anymore. C++20 finally provided us with the free\nstd::erase() function!” W ell, I would love to agree with that statement,\nbut unfortunately I can only acknowledge the existence of the\nstd::erase() function:\ntemplate< typename T, typename Alloc, typename U > \nconstexpr typename std::vector<T,Alloc>::size_type \n   erase( std::vector<T,Alloc>& c, U const& value );\nThe std::erase() function also takes its second ar gument, the value that\nis to be removed, by means of a reference-to- const. Therefore, the problem\nthat I just described remains. The only way to resolve this problem is to\nexplicitly determine the greatest element and pass it to the std::remove()\nalgorithm (\n ):\n \nstd::vector<int> vec{ 1, -3, 27, 42, 4, -8, 22, 42, 37, 4, 18, 9 }; \n \nauto const pos = std::max_element( begin(vec), end(vec) ); \nauto const greatest = *pos;  \n \n \nvec.erase( std::remove( begin(vec), end(vec), greatest ), end(vec) ); \n“Are you seriously suggesting that we shouldn’ t use reference parameters\nanymore?” No, absolutely not! Of course you should use reference\nparameters, for instance, for performance reasons. However , I hope to have\nraised a certain awareness. Hopefully , you now understand the problem:\nreferences, and especially pointers, make our life so much harder . It’s\nharder to understand the code, and therefore it is easier to introduce bugs\ninto our code. And pointers in particular raise so many more questions: is it28",5918
63-The Modern C Philosophy Value Semantics.pdf,63-The Modern C Philosophy Value Semantics,"a valid pointer or a nullptr? Who owns the resource behind the pointer\nand manages the lifetime? Of course, lifetime issues are not much of an\nissue since we have expanded our toolbox and have smart pointers at our\ndisposal. As Core Guideline R.3  clearly states:\nA raw pointer (a T*) is non-owning.\nIn combination with knowing that smart pointers are taking on the\nresponsibility of ownership, this cleans up the semantics of pointers quite\nsignificantly . But still, despite the fact that smart pointers are of course an\nimmensely valuable tool and, for good reasons, are celebrated as a huge\nachievement of “Modern C++,” in the end they are only a fix for the holes\nthat reference semantics has torn in the fabric of our ability to reason about\ncode. Y es, reference semantics makes it harder to understand code and to\nreason about the important details, and thus is something we would like to\navoid.\nThe Modern C++ Philosophy: V alue Semantics\n“But wait,” I  can hear you object, “what other choice do we have? What\nshould we do? And how else should we cope with inheritance hierarchies?\nWe can’ t avoid pointers there, right?” If you’re thinking something along\nthese lines, then I have very good news for you: yes, there is a better\nsolution. A solution that makes your code easier to understand and easier to\nreason about, and might even have a positive impact on its performance\n(remember we also talked about the negative performance aspects of\nreference semantics). The solution is value semantics.\nValue semantics is nothing new in C++. The idea was already part of the\noriginal STL. Let’ s consider the most famous of the STL  containers,\nstd::vector:\n \nstd::vector<int> v1{ 1, 2, 3, 4, 5 }; \n \nauto v2{ v1 };  \n \n \nassert( v1 == v2 );  \n \nassert( v1.data() != v2.data() );  \n \n \nv2[2] = 99;  \n \n \nassert( v1 != v2 );  \n \n \nauto const v3{ v1 };  \n \n \nv3[2] = 99;  // Compilation error! \nWe start with a std::vector called v1, filled with five integers. In the next\nline, we create a copy of v1, called v2 (\n). Vector v2 is a real copy ,\nsometimes also referred to as a deep copy , which now contains its own\nchunk of memory and its own integers, and doesn’ t refer to the integers in\nv1. We can assert that by comparing the two vectors (they prove to be\nequal; see \n ), but the addresses of the first elements are different  (\n). And\nchanging one element in v2 (\n) has the ef fect that the two vectors are not\nequal anymore (\n ). Yes, both vectors have their own arrays. They do not\nshare their content, i.e., they do not try to “optimize” the copy operation.\nYou might have heard about such techniques, for instance, the copy-on-\nwrite  technique. And yes, you might even be aware that this was a common\nimplementation for std::string prior to C++1 1. Since C++1 1, however ,\nstd::string is no longer allowed to use copy-on-write  due to its\nrequirements  formulated in the C++ standard. The reason is that this\n“optimization” easily proves to be a pessimization in a multithreaded world.\nHence, we can count on the fact that copy construction creates a real copy .\nLast but not least, we create another copy called v3, which we declare as\nconst (\n). If we now try to change a value of v3, we will get a compilation\nerror . This shows that a const vector does not just prevent adding and\nremoving elements but that all elements are also considered to be const.\nFrom a semantic perspective, this means that std::vector, just as any\ncontainer in the STL, is considered to be a value. Y es, a value, like an int.\nIf we copy a value, we don’ t copy just a part of the value but the entire\nvalue. If we make a value const, it is not just partially const but\ncompletely const. That is the rationale of value semantics. And we’ve seen\na couple of advantages already: values are easier to reason about than29",3891
64-Value Semantics A Second Example.pdf,64-Value Semantics A Second Example,"pointers and references. For instance, changing a value does not have an\nimpact on some other value. The change happens locally , not somewhere\nelse. This is an advantage that compilers heavily exploit for their\noptimization ef forts. Also, values don’ t make us think about ownership. A\nvalue is in char ge of its own content. A value also makes it (much) easier to\nthink about threading issues. That does not mean that there are no problems\nanymore (you wish!), but the code is definitely easier to understand. V alues\njust don’ t leave us with a lot of questions.\n“OK, I get the point about code clarity ,” you ar gue, “but what about\nperformance? Isn’ t it super expensive to deal with copy operations all the\ntime?” W ell, you are correct; copy operations can be expensive. However ,\nthey are only expensive if they really happen. In real code, we can often\nrely on copy elision , move semantics, and well…pass-by-reference.  Also,\nwe have already seen that, from a performance point of view , value\nsemantics might give us a performance boost. Y es, of course I am referring\nto the std::variant example in “Guideline 17: Consider std::variant for\nImplementing V isitor ”. In that example, the use of values of type\nstd::variant has significantly improved our performance because of\nfewer indirections due to pointers and a much better memory layout and\naccess pattern.\nValue Semantics: A Second Example\nLet’s take a look at a second example. This time we consider the following\nto_int() function:\nint to_int( std::string_view );\nThis function parses the given string (and yes, I am using\nstd::string_view for the purpose of performance) and converts it to an\nint. The most interesting question for us now is how the function should\ndeal with errors, or in other words, what the function should do if the string\ncannot be converted to an int. The first option would be to return 0 for that\ncase. This approach, however , is questionable, because 0 is a valid return30\n31\nfrom the to_int() function. W e would not be able to distinguish success\nfrom failure.  Another possible approach would be to throw an exception.\nAlthough exceptions may be the C++ native tool to signal error cases, for\nthis particular problem, depending on your personal style and preferences,\nthis may appear as overkill to you. Also, knowing that exceptions cannot be\nused in a lar ge fraction of the C++ community , that choice might limit the\nusability of the function.\nA third possibility is change the signature by a little bit:\nbool to_int( std::string_view s, int& );\nNow the function takes a reference to a mutable int as the second\nparameter and returns a bool. If it succeeds, the function returns true and\nsets the passed integer; if it fails, the function returns false and leaves the\nint alone. While this may seem like a reasonable compromise to you, I\nwould ar gue that we have now strayed further into the realm of reference\nsemantics (including all potential misuse). At the same time, the clarity of\nthe code has diminished: the most natural way to return a result is via the\nreturn value, but now the result is produced by an output value. This, for\ninstance, prevents us from assigning the result to a const value. Therefore,\nI would rate this as the least favorable approach so far .\nThe fourth approach is to return by pointer:\nstd::unique_ptr<int> to_int( std::string_view );\nSemantically , this approach is pretty attractive: if it succeeds, the function\nreturns a valid pointer to an int; if it fails, it returns a nullptr. Hence,\ncode clarity is improved, as we can clearly distinguish between these two\ncases. However , we gain this advantage at the cost of a dynamic memory\nallocation, the need to deal with lifetime management using\nstd::unique_ptr, and we’re still lingering in the realm of reference\nsemantics. So the question is: how can we leverage the semantic advantages\nbut stick to value semantics? The solution comes in the form of\nstd::optional:32\n33\n34\nstd::optional<int> to_int( std::string_view );\nstd::optional is a value type, which represents any other value, in our\nexample, an int. Therefore, std::optional can take all the values that an\nint can take. The specialty of std::optional, however , is that it adds one\nmore state to the wrapped value, a state that represents no value. Thus, our\nstd::optional is an int that may or may not be present:\n#include <charconv> \n#include <cstdlib> \n#include <optional> \n#include <sstream> \n#include <string> \n#include <string_view> \n \nstd::optional<int> to_int( std::string_view sv ) \n{ \n   std::optional<int> oi{}; \n   int i{}; \n \n   auto const result = std::from_chars( sv.data(), sv.data() + sv.size(), i ); \n   if( result.ec != std::errc::invalid_argument ) { \n      oi = i; \n   } \n \n   return oi; \n} \n \nint main() \n{ \n   std::string value = ""42""; \n \n   if( auto optional_int = to_int( value ) ) \n   { \n      // ... Success: the returned std::optional contains an integer value \n   } \n   else \n   { \n      // ... Failure: the returned std::optional does not contain a value \n   } \n}\nSemantically , this is equivalent to the pointer approach, but we don’ t pay\nthe cost of dynamic memory allocation, and we don’ t have to deal with",5302
65-Prefer to Use Value Semantics to Implement Design Patterns.pdf,65-Prefer to Use Value Semantics to Implement Design Patterns,,0
66-Introduction to stdfunction.pdf,66-Introduction to stdfunction,"lifetime management.  This solution is semantically clear , understandable,\nand ef ficient.\nPrefer to Use V alue Semantics to Implement Design\nPatterns\n“And what about design patterns?” you ask. “Almost all GoF patterns are\nbased on inheritance hierarchies and therefore reference semantics. How\nshould we deal with this?” That is an excellent question. And it provides us\nwith a perfect bridge to the next guideline. T o give a short answer here: you\nshould prefer to implement design patterns using a value semantics\nsolution. Y es, seriously! These solutions usually lead to more\ncomprehensive, maintainable code and (often) better performance.\nGUIDELINE 22: PREFER VALUE SEMANTICS TO\nREFERENCE SEMANTICS\nBe aware that reference semantics make it harder to understand\ncode;\nPrefer the semantic clarity of value semantics.\nGuideline 23: Prefer a Value-Based\nImplementation of Strategy and Command\nIn “Guideline 19: Use Strategy to Isolate How Things Are Done” , I\nintroduced you to the Strategy design pattern, and in “Guideline 21: Use\nCommand to Isolate What Things Are Done ”, I introduced you to the\nCommand design pattern. I demonstrated that these two design patterns are\nessential decoupling tools in your daily toolbox. However , in “Guideline\n22: Prefer V alue Semantics over Reference Semantics ”, I gave you the idea\nthat it’ s preferable to use value semantics instead of reference semantics.\nAnd this of course raises the question: how can you apply that wisdom for35\nthe Strategy and Command design patterns? W ell, here is one possible value\nsemantics solution: draw on the abstracting power of std::function.\nIntroduction to std::function\nIn case you have not yet heard about std::function, allow me to\nintroduce you. std::function represents an abstraction for a callable (e.g.,\na function pointer , function  object, or lambda). The only requirement is that\nthe callable satisfies a specific function type, which is passed as the only\ntemplate parameter to std::function. The following code gives an\nimpression:\n \n#include <cstdlib> \n#include <functional> \n \nvoid foo( int i ) \n{ \n   std::cout << ""foo: "" << i << '\n'; \n} \n \nint main() \n{ \n   // Create a default std::function instance. Calling it results \n   // in a std::bad_function_call exception \n   std::function<void(int)> f{};  \n \n \n   f = []( int i ){  // Assigning a callable to 'f'  \n \n      std::cout << ""lambda: "" << i << '\n'; \n   }; \n \n   f(1);  // Calling 'f' with the integer '1'  \n \n \n   auto g = f;  // Copying 'f' into 'g'  \n \n \n   f = foo;  // Assigning a different callable to 'f'  \n \n \n   f(2);  // Calling 'f' with the integer '2'  \n \n   g(3);  // Calling 'g' with the integer '3'  \n \n \n   return EXIT_SUCCESS; \n} \nIn the main() function, we create an instance of std::function, called f (\n). The template parameter specifies the required function type. In our\nexample, this is void(int). “Function type…” you say . “Don’ t you mean\nfunction pointer  type?” W ell, since this is indeed something that you might\nhave rarely seen before, allow me to explain what a function type is and\ncontrast it with the thing you’ve probably seen more often: function\npointers. The following example uses both a function type and a function\npointer type:\nusing FunctionType        = double(double); \nusing FunctionPointerType = double(*)(double); \n// Alternatively: \n// using FunctionPointerType = FunctionType*;\nThe first line shows a function type. This type represents any function that\ntakes a double and returns a double. Examples for this function type are\nthe corresponding overloads of std::sin, std::cos, std::log, or\nstd::sqrt. The second line shows a function pointer type. Note the little\nasterisk in parentheses—that makes it a pointer type. This type represents\nthe address of one function of function type FunctionType. Hence, the\nrelationship between function types and function pointer types is pretty\nmuch like the relationship between an int and a pointer to an int: while\nthere are many int values, a pointer to an int stores the address of exactly\none int.\nBack to the std::function example: initially , the instance is empty ,\ntherefore you cannot call it. If you still try to do so, the std::function\ninstance will throw the std::bad_function_call exception at you. Better\nnot provoke it. Let’ s rather assign some callable that fulfills the function\ntype requirements, for instance, a (possibly stateful) lambda (\n ). The\nlambda takes an int and doesn’ t return anything. Instead, it prints that it\nhas been called by means of a descriptive output message (\n ):\nlambda: 1",4677
67-Refactoring the Drawing of Shapes.pdf,67-Refactoring the Drawing of Shapes,"OK, that worked well. Let’ s try something else: we now create another\nstd::function instance g by means of f (\n). Then we assign another\ncallable to f (\n). This time, we assign a pointer to the function foo().\nAgain, this callable fulfills the requirements of the std::function\ninstance: it takes an int and returns nothing. Directly after the assignment,\nyou call f with the int 2, which triggers the expected output (\n ):\nfoo: 2\nThat was probably an easy one. However , the next function call is much\nmore interesting. If you call g with the integer 3 (\n), the output\ndemonstrates that std::function is firmly based on value semantics:\nlambda: 3\nDuring the initialization of g, the instance f was copied. And it was copied\nas a value should be copied: it does not perform a “shallow copy ,” which\nwould result in g being af fected when f is subsequently changed, but it\nperforms a complete copy (deep copy), which includes a copy of the\nlambda.  Thus, changing f does not af fect g. That’ s the benefit of value\nsemantics: the code is easy and intuitive, and you don’ t have to be afraid\nthat you are accidentally breaking something anywhere else.\nAt this point, the functionality of std::function may feel a little like\nmagic: how is it possible that the std::function instance can take any\nkind of callable, including things like lambdas? How can it store any\npossible type, even types that it can’ t know , and even though these types\napparently have nothing in common? Don’ t worry: in Chapter 8 , I will give\nyou a thorough introduction to a technique called Type Erasur e, which is\nthe magic behind std::function.\nRefactoring the Drawing of Shapes\nstd::function provides  everything we need to refactor our shape-drawing\nexample from “Guideline 19: Use Strategy to Isolate How Things Are\nDone” : it represents the abstraction of a single callable, which is pretty36\nmuch exactly what we need to replace the DrawCircleStrategy and\nDrawSquareStrategy hierarchies, which each contain a single virtual\nfunction. Hence, we rely on the abstracting power of std::function:\n \n//---- <Shape.h> ---------------- \n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n   virtual void draw( /*some arguments*/ ) const = 0; \n}; \n \n \n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n#include <functional> \n#include <utility> \n \nclass Circle : public Shape \n{ \n public: \n   using DrawStrategy = std::function<void(Circle const&, /*...*/)>;  \n \n \n   explicit Circle( double radius, DrawStrategy drawer )  \n \n      : radius_( radius ) \n      , drawer_( std::move(drawer) )  \n \n   { \n      /* Checking that the given radius is valid and that \n         the given 'std::function' instance is not empty */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_( *this, /*some arguments*/ ); \n   } \n \n   double radius() const { return radius_; } \n \n private: \n   double radius_; \n   DrawStrategy drawer_;  \n \n}; \n \n \n//---- <Square.h> ---------------- \n \n#include <Shape.h> \n#include <functional> \n#include <utility> \n \nclass Square : public Shape \n{ \n public: \n   using DrawStrategy = std::function<void(Square const&, /*...*/)>;  \n \n \n   explicit Square( double side, DrawStrategy drawer )  \n \n      : side_( side ) \n      , drawer_( std::move(drawer) )  \n \n   { \n      /* Checking that the given side length is valid and that \n         the given 'std::function' instance is not empty */ \n   } \n \n   void draw( /*some arguments*/ ) const override \n   { \n      drawer_( *this, /*some arguments*/ ); \n   } \n \n   double side() const { return side_; } \n \n private: \n   double side_; \n   DrawStrategy drawer_;  \n \n}; \nFirst, in the Circle class, we add a type alias for the expected type of\nstd::function (\n). This std::function type represents any callable that\ncan take a Circle, and potentially several more drawing-related ar guments,\nand does not return anything. Of course, we also add the corresponding type\nalias in the Square class (\n ). In the constructors of both Circle and\nSquare, we now take an instance of type std::function (\n) as a\nreplacement for the pointer to a Strategy base class ( Draw Cir cleStrategy\nor DrawSquareStrategy). This instance is immediately moved (\n ) into the\ndata member drawer_, which is also of type DrawStrategy (\n).\n“Hey , why are you taking the std::function instance by value? Isn’ t that\nterribly inef ficient? Shouldn’ t we prefer to pass by reference-to- const?” In\nshort: no, passing by value is not inef ficient, but an elegant compromise to\nthe alternatives. I admit, though, that this may be surprising. Since this is\ndefinitely an implementation detail worth noting, let’ s take a closer look.\nIf we used a reference-to- const, we would experience the disadvantage that\nrvalues  would be unnecessarily copied. If we were passed an rvalue, this\nrvalue would bind to the ( lvalue ) reference-to- const. However , when\npassing this reference-to- const to the data member , it would be copied.\nWhich is not our intention: naturally we want it to be moved. The simple\nreason is that we cannot move from const objects (even when using\nstd::move). So, to ef ficiently deal with rvalues, we would have to provide\noverloads of the Circle and Square constructors that would take a\nDrawStrategy by means of an rvalue reference ( DrawStrategy&&). For the\nsake of performance, we would provide two constructors for both Circle\nand Square.\nThe approach to provide two constructors (one for lvalues, one for rvalues)\ndoes work and is ef ficient, but I would not necessarily call it elegant. Also,\nwe should probably save our colleagues the trouble of having to deal with\nthat.  For this reason, we exploit the implementation of std::function.\nstd::function provides both a copy constructor and a move constructor ,\nand so we know that it can be moved ef ficiently . When we pass a\nstd::function by value, either the copy constructor or the move\nconstructor will be called. If we are passed an lvalue, the copy constructor\nis called, copying the lvalue. Then we would move that copy into the data\nmember . In total, we would perform one copy and one move to initialize the\ndrawer_ data member . If we are passed an rvalue, the move constructor is\ncalled, moving the rvalue. The resulting ar gument strategy is then moved\ninto the data member drawer_. In total, we would perform two move\noperations to initialize the drawer_ data member . Therefore, this form\nrepresents a great compromise: it is elegant, and there is hardly any\ndifference in ef ficiency .37\n38\nOnce we’ve refactored the Circle and Square classes, we can implement\ndifferent drawing strategies in any form we like (in the form of a function, a\nfunction object, or a lambda). For instance, we can implement the following\nOpenGLCircleStrategy as a function object:\n \n//---- <OpenGLCircleStrategy.h> ---------------- \n \n#include <Circle.h> \n \nclass OpenGLCircleStrategy \n{ \n public: \n   explicit OpenGLCircleStrategy( /* Drawing related arguments */ ); \n \n   void operator()( Circle const& circle, /*...*/ ) const;  \n \n \n private: \n   /* Drawing related data members, e.g. colors, textures, ... */ \n}; \nThe only convention we need to follow is that we need to provide a call\noperator that takes a Circle and potentially several more drawing-related\narguments, and doesn’ t return anything (fulfill the function type\nvoid(Circle const&, /*…*/)) (\n).\nAssuming a similar implementation for an OpenGLSquareStrategy, we can\nnow create dif ferent kinds of shapes, configure them with the desired\ndrawing behavior , and finally draw them:\n#include <Circle.h> \n#include <Square.h> \n#include <OpenGLCircleStrategy.h> \n#include <OpenGLSquareStrategy.h> \n#include <memory> \n#include <vector> \n \nint main() \n{ \n   using Shapes = std::vector<std::unique_ptr<Shape>>; \n \n   Shapes shapes{}; \n \n   // Creating some shapes, each one \n   //   equipped with the corresponding OpenGL drawing strategy \n   shapes.emplace_back( \n      std::make_unique<Circle>( 2.3, OpenGLCircleStrategy(/*...red...*/) ) ); \n   shapes.emplace_back( \n      std::make_unique<Square>( 1.2, OpenGLSquareStrategy(/*...green...*/) ) \n); \n   shapes.emplace_back( \n      std::make_unique<Circle>( 4.1, OpenGLCircleStrategy(/*...blue...*/) ) ); \n \n   // Drawing all shapes \n   for( auto const& shape : shapes ) \n   { \n      shape->draw(); \n   } \n \n   return EXIT_SUCCESS; \n}\nThe main() function is very similar to the original implementation using\nthe classic Strategy implementation (see “Guideline 19: Use Strategy to\nIsolate How Things Are Done” ). However , this nonintrusive, base class–\nfree approach with std::function further reduces the coupling. This\nbecomes evident in the dependency  graph for this solution  (see Figure 5-9 ):\nwe can implement the drawing functionality in any form we want (as a free\nfunction, a function object, or a lambda) and we don’ t have to abide by the\nrequirements of a base class. Also, by means of std::function we have\nautomatically inverted the dependencies (see “Guideline 9: Pay Attention to\nthe Ownership of Abstractions” ).",9280
68-Analyzing the Shortcomings of the stdfunction Solution.pdf,68-Analyzing the Shortcomings of the stdfunction Solution,"Figur e 5-9. Dependency graph for the std::function solution\nPerformance Benchmarks\n“I like the flexibility , the freedom. This  is great! But what about\nperformance?” Y es, spoken like a true C++ developer . Of course\nperformance is important. Before showing you the performance results,\nthough, let me remind you of the benchmark scenario that we also used to\nget the numbers for Table 4-2  in “Guideline 16: Use V isitor to Extend\nOperations” . For the benchmark, I have implemented four dif ferent kinds of\nshapes (circles, squares, ellipses, and rectangles). Again, I’m running\n25,000 translate operations on 10,000 randomly created shapes. I use both\nGCC 1 1.1 and Clang 1 1.1, and for both compilers I’m adding only the -O3\nand -DNDEBUG compilation flags. The platform I’m using is macOS Big Sur\n(version 1 1.4) on an 8-Core Intel Core i7 with 3.8 GHz, 64 GB of main\nmemory .\nWith this information in mind, you are ready for the performance results.\nTable 5-1  shows the performance numbers for the Strategy-based\nimplementation of the drawing example and the resulting solution using\nstd::function.\nTable 5-1. Performance r esults for differ ent Strategy\nimplementations\nStrategy implementations GCC 1 1.1 Clang 1 1.1\nObject-oriented solution 1.5205 s 1.1480 s\nstd::function 2.1782 s 1.4884 s\nManual implementation of std::function1.6354 s 1.4465 s\nClassic Strategy 1.6372 s 1.4046 s\nFor reference purposes, the first line shows the performance of the object-\noriented solution from “Guideline 15: Design for the Addition of Types or\nOperations ”. As you can see, this solution gives the best performance. This\nis not unexpected, however: since the Strategy design pattern, irrespective\nof the actual implementation, introduces additional overhead, the\nperformance is anticipated to be reduced.\nWhat is not expected, though, is that the std::function implementation\nincurs a performance overhead (even a significant one in case of GCC). But\nwait, before you throw this approach into your mental trash can, consider\nthe third line. It shows a manual implementation of std::function using\nType Erasure, the technique I will explain in Chapter 8 . This\nimplementation performs much better , in fact as good (or nearly as good for\nClang) as a classic implementation of the Strategy design pattern (see the\nfourth line). This result demonstrates that the problem is not value\nsemantics but the specific implementation details of std::function. In\nsummary , a value semantics approach is not worse in terms of performance\nthan the classic approach, but instead, as shown before, it improves many\nimportant aspects of your code.\nAnalyzing the Shortcomings of the std::function\nSolution\nOverall, the  std::function implementation of the Strategy design pattern\nprovides a number of benefits. First, your code gets cleaner and more\nreadable since you don’ t have to deal with pointers and the associated\nlifetime management (for instance, using std::unique_ptr), and since you\ndon’t experience the usual problems with reference  semantics (see\n“Guideline 22: Prefer V alue Semantics over Reference Semantics ”).\nSecond, you promote loose coupling. V ery loose coupling, actually . In this\ncontext, std::function acts like a compilation firewall, which protects\nyou from the implementation details of the dif ferent Strategy\nimplementations but at the same time provides enormous flexibility for\ndevelopers on how to implement the dif ferent Strategy solutions.\nDespite these upsides, no solution comes without downsides—even the\nstd::function approach has its disadvantages. I have already pointed out\nthe potential performance disadvantage if you rely on the standard39\nimplementation. While there are solutions to minimize this ef fect (see\nChapter 8 ), it’s still something to consider in your codebase.\nThere is also a design-related issue. std::function can replace only a\nsingle virtual function. If you need to abstract multiple virtual functions,\nwhich could occur if you want to configure multiple aspects using the\nStrategy design pattern, or if you need an undo() function in the Command\ndesign pattern, you would have to use multiple std::function instances.\nThis would not only increase the size of a class due to the multiple data\nmembers, but also incur an interface burden due to the question of how to\nelegantly handle passing multiple std::function instances. For this\nreason, the std::function approach works best for replacing a single or a\nvery small number of virtual functions. Still, this does not mean that you\ncan’t use a value-based approach for multiple virtual functions: if you\nencounter that situation, consider generalizing the approach by applying the\ntechnique used for std::function directly to your type. I will explain how\nto do that in Chapter 8 .\nDespite these shortcomings, the value semantics approach proves to be a\nterrific choice for the Strategy design pattern. The same is true for the\nCommand design pattern. Therefore, keep this guideline in mind as an\nessential step towards modern C++.\nGUIDELINE 23: PREFER A VALUE-BASED\nIMPLEMENTATION OF STRATEGY AND COMMAND\nConsider using std::function to implement the Strategy or\nCommand design pattern.\nTake the performance disadvantages of std::function into\naccount.\nBe aware that T ype Erasure is a generalization of the value\nsemantics approach for Strategy and Command.\n1 See “Guideline 2: Design for Change” .\n2 You may correctly ar gue that there are multiple solutions for this problem: you could have\none source file per graphics library , you could rely on the preprocessor by sprinkling a couple\nof #ifdefs across the code, or you could implement an abstraction layer around the graphics\nlibraries. The first two options feel like technical workarounds to a flawed design. The latter\noption, however , is a reasonable, alternative solution to the one that I will propose. It’ s a\nsolution based on the Facade  design pattern, which, unfortunately , I don’ t cover in this book.\n3 David Thomas and Andrew Hunt, The Pragmatic Pr ogrammer .\n4 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n5 Please explicitly note that I said naive . Although the code example is didactically a little\nquestionable, I will show a common misconception before showing a proper implementation.\nMy hope is that this way you will never fall into this common trap.\n6 Although this is not a book about implementation details, please allow me to highlight one\nimplementation detail that I find to be the source of many questions in my training classes. I’m\ncertain you’ve heard about the Rule of 5—if not, please see the C++ Core Guidelines . Hence,\nyou realize that the declaration of a virtual destructor disables the move operations. Strictly\nspeaking, this is a violation of the Rule of 5. However , as Core Guideline C.21  explains, for\nbase classes this is not considered to be a problem, as long as the base class does not contain\nany data members.\n7 As I have referenced Core Guideline C.21 before, it is also worth mentioning that both the\nCircle and Square classes fulfill the Rule of 0 ; see Core Guideline C.20 . By not falling into\nthe habit of adding a destructor , the compiler itself generates all special member functions for\nboth classes. And yes, worry not—the destructor is still virtual since the base class destructor is\nvirtual.\n8 See “Guideline 18: Beware the Performance of Acyclic V isitor”  for a discussion about the\nAcyclic V isitor design pattern.\n9 I should explicitly state that it does not work in dynamic polymorphism. It does work in static\npolymorphism, even quite well. Consider , for instance, templates and function overloading.\n10 Andrei Alexandrescu, Modern C++ Design: Generic Pr ogramming and Design Patterns\nApplied  (Addison-W esley , 2001).\n1 1 Sean Parent, “Inheritance Is the Base Class Of Evil” , GoingNative, 2013.\n12 According to Sean Parent, there are no polymorphic types, only polymorphic usage of similar\ntypes; see “Better Code: Runtime Polymorphism”  from the NDC London conference in 2017.\nMy statement supports that opinion.\n13 Another example of inheritance creating coupling is discussed in Herb Sutter ’s Exceptional\nC++: 47 Engineering Puzzles, Pr ogramming Pr oblems, and Exception-Safety Solutions\n(Pearson Education).\n14 Are they really to blame for this habit? Since they’ve been taught that this is the way to go for\ndecades, who can blame them for thinking this way?\n15 Michael C. Feathers, Working Effectively with Legacy Code .\n16 Programming by dif ference is a rather extreme form of inheritance-based programming,\nwhere even small dif ferences are expressed by introducing a new derived class. See Michael’ s\nbook for more details.\n17 See, for instance, the Strategy design pattern in “Guideline 19: Use Strategy to Isolate How\nThings Are Done” , the Observer design pattern in “Guideline 25: Apply Observers as an\nAbstract Notification Mechanism” , the Adapter design pattern in “Guideline 24: Use Adapters\nto Standardize Interfaces” , the Decorator design pattern in “Guideline 35: Use Decorators to\nAdd Customization Hierarchically” , or the Bridge design pattern in “Guideline 28: Build\nBridges to Remove Physical Dependencies ”.\n18 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n19 Yes, it follows the SOLID principles, although of course by means of the classic form of the\nCommand design pattern. If you are right now biting your fingernails in frustration or simply\nwondering if there isn’ t a better way , then please be patient. I will demonstrate a much nicer ,\nmuch more “modern” solution in “Guideline 22: Prefer V alue Semantics over Reference\nSemantics ”.\n20 The given ThreadPool class is far from being complete and primarily serves as an illustration\nfor the Command design pattern. For a working, professional implementation of a thread pool,\nplease refer to Anthony W illiam’ s book C++ Concurr ency in Action , 2nd ed. (Manning).\n21 This is another example of my statement that design patterns are not about implementation\ndetails; see “Guideline 12: Beware of Design Pattern Misconceptions” .\n22 For the complete shape example, see “Guideline 19: Use Strategy to Isolate How Things Are\nDone” .\n23 Mar garet A. Ellis and Bjarne Stroustrup, The Annotated C++ Refer ence Manual  (Addison-\nWesley , 1990).\n24 To get an overview of C++ performance aspects in general and performance-related issues\nwith inheritance hierarchies in particular , refer to Kurt Guntheroth’ s book, Optimized C{plus}\n{plus}  (O’Reilly).\n25 A possible solution for that is to employ techniques from data-oriented design; see Richard\nFabian, Data-Oriented Design: Softwar e Engineering for Limited Resour ces and Short\nSchedules .\n26 Mark my choice of words: “W e might get the following output.” Indeed, we might get this\noutput but also something else. It depends, as we have inadvertently entered the realm of\nundefined behavior . Therefore, this output is my best guess, not a guarantee.\n27 Now not only your manicurist but also your hairdresser has work to do…\n28 More gray hairs, more work for your hairdresser .\n29 I should explicitly point out that the notion of a “deep copy” depends on the type T of\nelements in the vector: if T performs a deep copy , then so does the std::vector, but if T\nperforms a shallow copy , then semantically std::vector also performs a shallow copy .\n30 The best and most complete introduction to move semantics is Nicolai Josuttis’ s book on the\nsubject, C++ Move Semantics - The Complete Guide  (NicoJosuttis, 2020).\n31 See Patrice Roy’ s CppCon 2016 talk, “The Exception Situation” , for a similar example and\ndiscussion.\n32 Yet this is exactly the approach taken by the std::atoi() function .\n33 In his standard proposal P0709 , Herb Sutter explains that 52% of C++ developers have no or\nlimited access to exceptions.\n34 The experienced C++ developer also knows that C++23 will bless us with a very similar type\ncalled std::expected. In a few years, this might be the appropriate way to write the\nto_int() function.\n35 From a functional programming point of view , std::optional represents a monad . You’ll\nfind much more valuable information on monad s and functional programming in general in\nIvan Čukić’ s book, Functional Pr ogramming in C++ .\n36 In this example, the std::function object performs a deep copy , but generally speaking,\nstd::function copies the contained callable according to its copy semantics (“deep” or\n“shallow”). std::function has no way of forcing a deep copy .\n37 This implementation detail is explained thoroughly by Nicolai Josuttis in this CppCon 2017\ntalk, “The Nightmare of Move Semantics for T rivial Classes” .\n38 One more example of the KISS  principle .\n39 A discussion about the reasons for the performance deficiencies of some std::function\nimplementations would go beyond the scope and purpose of this book. Still, please keep this\ndetail in mind for performance-critical sections of your code.",13175
69-The Adapter Design Pattern Explained.pdf,69-The Adapter Design Pattern Explained,"Chapter 6. The Adapter ,\nObserver , and CRTP Design\nPatterns\nIn this chapter , we turn our attention to three must-know design patterns:\nthe two GoF design patterns, Adapter and Observer , and the Curiously\nRecurring T emplate Pattern (CRTP)  design pattern.\nIn “Guideline 24: Use Adapters to Standardize Interfaces” , we talk about\nmaking incompatible things fit together by adapting interfaces. T o achieve\nthis, I will show you the Adapter design pattern and its application in both\ninheritance hierarchies and generic programming. Y ou will also get an\noverview of dif ferent kinds of Adapters, including object, class, and\nfunction Adapters.\nIn “Guideline 25: Apply Observers as an Abstract Notification\nMechanism” , we will deal with how to observe state change and how to get\nnotified about it. In this context, I will introduce you to the Observer design\npattern, one of the most famous and most commonly used design patterns.\nWe will talk about the classic, GoF-style Observer , and also how to\nimplement the Observer in modern C++.\nIn “Guideline 26: Use CR TP to Introduce Static T ype Categories” , we will\nturn our attention to the CR TP. I will show you how to use CR TP to define a\ncompile-time relationship between a family of related types and how to\nproperly implement a CR TP base class.\nIn “Guideline 27: Use CR TP for Static Mixin Classes” , I will continue the\nCRTP story by showing you how CR TP can be used to create compile-time\nmixin classes. W e will also see the dif ference between semantic inheritance,\nwhere it is used to create an abstraction, and technical inheritance, where it\nis used as an implementation detail for technical elegance and convenience\nonly.\nGuideline 24: Use Adapters to Standardize\nInterfaces\nLet’s assume that you have implemented the Document example from\n“Guideline 3: Separate Interfaces to A void Artificial Coupling ”, and that,\nbecause you properly adhere to the Interface Segregation Principle (ISP),\nyou’re reasonably happy with the way it works:\nclass JSONExportable \n{ \n public: \n   // ... \n   virtual ~JSONExportable() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0; \n   // ... \n}; \n \nclass Serializable \n{ \n public: \n   // ... \n   virtual ~Serializable() = default; \n \n   virtual void serialize( ByteStream& bs, /*...*/ ) const = 0; \n   // ... \n}; \n \nclass Document \n   : public JSONExportable \n   , public Serializable \n{ \n public: \n   // ... \n};\nHowever , one day you’re required to introduce the Pages document\nformat.  Of course, it is similar to the W ord document that you already have1\nin place, but unfortunately , you’re not familiar with the details of the Pages\nformat. T o make things worse, you don’ t have a lot of time to get familiar\nwith the format, because you have way too many other things to do.\nLuckily , you know about a quite reasonable, open source implementation\nfor that format: the OpenPages class:\nclass OpenPages \n{ \n public: \n   // ... \n   void convertToBytes( /*...*/ ); \n}; \n \nvoid exportToJSONFormat( OpenPages const& pages, /*...*/ );\nOn the bright side, this class provides about everything you need for your\npurposes: a convertToBytes() member function to serialize the content of\nthe document, and the free exportToJSONFormat() function to convert the\nPages document into the JSON format. Unfortunately , it does not fit your\ninterface expectations: instead of the convertToBytes() member function,\nyou expect a serialize() member function. And instead of the free\nexportToJSONFormat() function, you expect the exportToJSON()\nmember function. Ultimately , of course, the third-party class does not\ninherit from your Document base class, which means that you can’ t easily\nincorporate the class into your existing hierarchy . However , there is a\nsolution to this problem: a seamless integration using the Adapter design\npattern.\nThe Adapter Design Pattern Explained\nThe Adapter design pattern is another one of the classic GoF design\npatterns. It’ s focused on standardizing interfaces and helping nonintrusively\nadd functionality into an existing inheritance hierarchy .\nTHE ADAPTER DESIGN PATTERN\nIntent: “Convert the interface of a class into another interface clients expect. Adapter\nlets classes work together that couldn’ t otherwise because of incompatible interfaces.”\nFigure 6-1  shows the UML diagram for your Adapter scenario: you already\nhave the Document base class in place (we ignore the JSONExportable and\nSerializable interfaces for a second) and have already implemented a\ncouple of dif ferent kinds of documents (for instance, with the Word class).\nThe new addition to this hierarchy is the Pages class.2\nFigur e 6-1. The UML r epresentation of the Adapter design pattern\nThe Pages class  acts as a wrapper to the third-party OpenPages class:\n \nclass Pages : public Document \n{ \n public: \n   // ... \n   void exportToJSON( /*...*/ ) const override \n   { \n      exportToJSONFormat(pages, /*...*/);  \n \n   }",5054
70-Object Adapters Versus Class Adapters.pdf,70-Object Adapters Versus Class Adapters,"void serialize( ByteStream& bs, /*...*/ ) const override \n   { \n      pages.convertToBytes(/*...*/);  \n \n   } \n   // ... \n \n private: \n   OpenPages pages;  // Example of an object adapter \n}; \nPages implements the Document interface by forwarding the calls to the\ncorresponding OpenPages functions: a call to exportToJSON() is\nforwarded to the free exportToJSONFormat() function (\n ), and the call to\nserialize() is forwarded to the convertToBytes() member function (\n ).\nWith the Pages class, you can easily integrate the third-party\nimplementation into your existing hierarchy . Very easily indeed: you can\nintegrate it without having to modify it in any way . This nonintrusive nature\nof the Adapter design pattern is what you should consider one of the\ngreatest strengths of the Adapter design pattern: anyone can add an Adapter\nto adapt an interface to another , existing interface.\nIn this context, the Pages class serves as an abstraction from the actual\nimplementation details in the OpenPages class. Therefore, the Adapter\ndesign pattern separates the concerns of the interface from the\nimplementation details. This nicely fulfills the Single-Responsibility\nPrinciple (SRP) and blends well with the intention of the Open-Closed\nPrinciple (OCP) (see “Guideline 2: Design for Change”  and “Guideline 5:\nDesign for Extension” ).\nIn a way , the Pages Adapter works as an indirection and maps from one set\nof functions to another one. Note that it is not strictly necessary to map\nfrom one function to exactly one other function. On the contrary , you have\ncomplete flexibility on how to map the expected set of functions onto the\navailable set of functions. Thus, Adapter does not necessarily represent a 1-\nto-1 relationship, but can also support a 1-to- N relationship.\nObject Adapters V ersus Class Adapters3\nThe Pages class is an example of a so-called  object adapter . This term\nrefers to the fact that you store an instance of the wrapped type.\nAlternatively , given that the wrapped type is part of an inheritance\nhierarchy , you could store a pointer to the base class of this hierarchy . This\nwould allow you to use the object adapter for all types that are part of the\nhierarchy , giving the object adapter a considerable boost in flexibility .\nIn contrast, there is also the option to implement a so-called  class adapter :\n \nclass Pages : public Document \n            , private OpenPages  // Example of a class adapter  \n \n{ \n public: \n   // ... \n   void exportToJSON( /*...*/ ) const override \n   { \n      exportToJSONFormat(*this, /*...*/); \n   } \n \n   void serialize( ByteStream& bs, /*...*/ ) const override \n   { \n      this->convertToBytes(/*...*/); \n   } \n   // ... \n}; \nInstead of storing an instance of the adapted type, you would inherit from it\n(if possible, nonpublicly) and implement the expected interface accordingly\n(\n). However , as discussed in “Guideline 20: Favor Composition over\nInheritance” , it is preferable to build on composition. In general, object\nadapters prove to be much more flexible than class adapters and thus should\nbe your favorite. There are only a few reasons why you would prefer a class\nadapter:\nIf you have to override a virtual function.\nIf you need access to a protected member function.\nIf you require the adapted type to be constructed befor e another base\nclass.",3400
71-Examples from the Standard Library.pdf,71-Examples from the Standard Library,"If you need to share a common virtual base class or override the\nconstruction of a virtual base class.\nIf you can draw significant  advantage from the Empty Base\nOptimization (EBO) .\nOtherwise, and this applies to most cases, you should prefer an object\nadapter .\n“I like this design pattern—it’ s powerful. However , I just remembered that\nyou recommended using the name of the design pattern in the code to\ncommunicate intent. Shouldn’ t the class be called PagesAdapter?” You\nmake an excellent point. And I’m happy that you remember “Guideline 14:\nUse a Design Pattern’ s Name to Communicate Intent” , in which I indeed\nargued that the name of the pattern helps to understand the code. I admit\nthat in this case, I’m open to both naming conventions. While I do see the\nadvantages of the name PagesAdapter, as this immediately communicates\nthat you built on the Adapter design pattern, I don’ t consider it a necessity\nto communicate the fact that this class represents an adapter . To me, the\nAdapter feels like an implementation detail in this situation: I do not need to\nknow that the Pages class doesn’ t implement all the details itself, but uses\nthe OpenPages class for that. That’ s why I said to “consider using the\nname.” Y ou should decide on a case-by-case basis.\nExamples from the Standard Library\nOne useful application of the Adapter design pattern is to standardize the\ninterface of dif ferent kinds of containers. Let’ s assume the following Stack\nbase class:\n \n//---- <Stack.h> ---------------- \n \ntemplate< typename T > \nclass Stack \n{ \n public: \n   virtual ~Stack() = default; 4\n   virtual T& top() = 0;  \n \n   virtual bool empty() const = 0;  \n \n   virtual size_t size() const = 0;  \n \n   virtual void push( T const& value ) = 0;  \n \n   virtual void pop() = 0;  \n \n}; \nThis Stack class provides the necessary interface to access the top element\nof the stack (\n ), check if the stack is empty (\n ), query the size of the stack (\n), push an element onto the stack (\n ), and remove the top element of the\nstack (\n ). This base class can now be used to implement dif ferent Adapters\nfor various data structures, such as std::vector:\n//---- <VectorStack.h> ---------------- \n \n#include <Stack.h> \n \ntemplate< typename T > \nclass VectorStack : public Stack<T> \n{ \n public: \n   T& top() override { return vec_.back(); } \n   bool empty() const override { return vec_.empty(); } \n   size_t size() const override { return vec_.size(); } \n   void push( T const& value ) override { vec_.push_back(value); } \n   void pop() override { vec_.pop_back(); } \n \n private: \n   std::vector<T> vec_; \n};\nYou worry , “Do you seriously suggest implementing a stack by an abstract\nbase class? Aren’ t you worried about the performance implications? For\nevery use of a member function, you have to pay with a virtual function\ncall!” No, of course I don’ t suggest that. Obviously , you are correct, and I\ncompletely agree with you: from a C++ perspective, this kind of container\nfeels strange and very inef ficient. Because of ef ficiency , we usually realize\nthe same idea via class templates. This is the approach taken by the C++\nStandard Library in the form of the three STL  classes called Container\nadaptors : std::stack, std::queue, and std::priority_queue:",3337
72-Function Adapters.pdf,72-Function Adapters,"template< typename T \n        , typename Container = std::deque<T> > \nclass stack; \n \ntemplate< typename T \n        , typename Container = std::deque<T> > \nclass queue; \n \ntemplate< typename T \n        , typename Container = std::vector<T> \n        , typename Compare = std::less<typename Container::value_type> > \nclass priority_queue;\nThese three class templates adapt the interface of a given Container type\nto a special purpose. For instance, the purpose of the std::stack class\ntemplate is to adapt the interface of a container to the stack operations\ntop(), empty(), size(), push(), emplace(), pop(), and swap(). By\ndefault, you’re able to use the three available sequence containers:\nstd::vector, std::list, and std::deque. For any other container type,\nyou are able to specialize the std::stack class template.\n“This feels so much more familiar ,” you say , visibly relieved. Again, I\nabsolutely agree. I also consider the Standard Library approach the more\nsuitable solution for the purpose of containers. But it’ s still interesting to\ncompare the two approaches. While there are many technical dif ferences\nbetween the Stack base class and the std::stack class template, the\npurpose and semantics of these two approaches are remarkably similar:\nboth provide the ability to adapt any data structure to a given stack\ninterface. And both serve as a variation point, allowing you to\nnonintrusively add new Adapters without having to modify existing code.\nComparison Between Adapter and Strategy\n“The three  STL classes seem to fulfill the intent of Adapters, but isn’ t this\nthe same way of configuring behavior as in the Strategy design pattern?\nIsn’t this similar to std::unique_ptr and its deleter?” you ask. And yes,\nyou’re correct. From a structural point of view , the Strategy and Adapter\ndesign patterns are very similar . However , as explained in “Guideline 1 1:5\nUnderstand the Purpose of Design Patterns” , the structure of design patterns\nmay be similar or even the same, but the intent is dif ferent. In this context,\nthe Container parameter specifies not just a single aspect of the behavior ,\nbut most of the behavior or even all of it. The class templates merely act as\na wrapper around the functionality of the given type—they mainly adapt the\ninterface. So the primary focus of an Adapter is to standardize interfaces\nand integrate incompatible functionality into an existing set of conventions;\nwhile on the other hand, the primary focus of the Strategy design pattern is\nto enable the configuration of behavior from the outside, building on and\nproviding an expected interface. Also, for an Adapter there is no need to\nreconfigure the behavior at any time.\nFunction Adapters\nAdditional  examples for the Adapter design pattern are the Standard\nLibrary’ s free functions begin() and end(). “Are you serious?” you ask,\nsurprised. “Y ou claim that free functions serve as an example of the Adapter\ndesign pattern? Isn’ t this a job for classes?” W ell, not necessarily . The\npurpose of the free begin() and end() functions is to adapt the iterator\ninterface of any type to the expected STL iterator interface. Thus, it maps\nfrom an available set of functions to an expected set of functions and serves\nthe same purpose as any other Adapter . The major dif ference is that in\ncontrast to object adapters or class adapters, which are based on either\ninheritance (runtime polymorphism) or templates (compile-time\npolymorphism), begin() and end() draw their power from function\noverloading, which is the second major compile-time polymorphism\nmechanism in C++. Still, some form of abstraction is at play .\nNOTE\nRemember that all kinds of abstractions represent a set of requirements and thus have to\nadhere to the Liskov Substitution Principle (LSP). This is also true for overload sets; see\n“Guideline 8: Understand the Semantic Requirements of Overload Sets” .\nConsider the following function template:\ntemplate< typename Range > \nvoid traverseRange( Range const& range ) \n{ \n   for( auto&& element : range ) { \n      // ... \n   } \n}\nIn the traverseRange() function, we iterate through all the elements\ncontained in the given range with a range-based for loop. The traversal\nhappens via iterators that the compiler acquires with the free begin() and\nend() functions. Hence, the preceding for loop is equivalent to the\nfollowing form of for:\ntemplate< typename Range > \nvoid traverseRange( Range const& range ) \n{ \n   { \n      using std::begin; \n      using std::end; \n \n      auto first( begin(range) ); \n      auto last ( end(range) ); \n      for( ; first!=last; ++first ) { \n         auto&& element = *first; \n         // ... \n      } \n   } \n}\nObviously , the range-based for loop is much more convenient to use.\nHowever , underneath the surface, the compiler generates code based on the\nfree begin() and end() functions. Note the two using declarations in their\nbeginning: the  purpose is to enable Argument-Dependent Lookup (ADL)  for\nthe given type of range. ADL is the mechanism that makes sure the\n“correct” begin() and end() functions are called, even if they are\noverloads that reside in a user -specific namespace. This means that you",5264
73-Analyzing the Shortcomings of the Adapter Design Pattern.pdf,73-Analyzing the Shortcomings of the Adapter Design Pattern,"have the opportunity to overload begin() and end() for any type and map\nthe expected interface to a dif ferent, special-purpose set of functions.\nThis kind of function adapter  was called a  shim  by Matthew W ilson in\n2004.  One valuable property of this technique is that it’ s completely\nnonintrusive: it is possible to add a free function to any type, even to types\nthat you could never adapt, such as types provided by third-party libraries.\nHence, any generic code written in terms of shims gives you the enormous\npower to adapt virtually any type to the expected interface. Thus, you can\nimagine that shims or function adapters are the backbone of generic\nprogramming.\nAnalyzing the Shortcomings of the Adapter Design\nPattern\nDespite  the value of the Adapter design pattern, there is one issue with this\ndesign pattern that I should explicitly point out. Consider the following\nexample, which I adopted from Eric Freeman and Elisabeth Robson:\n//---- <Duck.h> ---------------- \n \nclass Duck \n{ \n public: \n   virtual ~Duck() = default; \n   virtual void quack() = 0; \n   virtual void fly() = 0; \n}; \n \n \n//---- <MallardDuck.h> ---------------- \n \n#include <Duck.h> \n \nclass MallardDuck : public Duck \n{ \n public: \n   void quack() override { /*...*/ } \n   void fly() override { /*...*/ } \n};6\n7\nWe start with the abstract Duck class, which introduces the two pure virtual\nfunctions quack() and fly(). Indeed, this appears to be a pretty expected\nand natural interface for a Duck class and of course raises some\nexpectations: ducks make a very characteristic sound and can fly pretty\nwell. This interface is implemented by many possible kinds of Duck, such\nas the MallardDuck class. Now , for some reason we also have to deal with\nturkeys:\n//---- <Turkey.h> ---------------- \n \nclass Turkey \n{ \n public: \n   virtual ~Turkey() = default; \n   virtual void gobble() = 0;  // Turkeys don't quack, they gobble! \n   virtual void fly() = 0;     // Turkeys can fly (a short distance) \n}; \n \n \n//---- <WildTurkey.h> ---------------- \n \nclass WildTurkey : public Turkey \n{ \n public: \n   void gobble() override { /*...*/ } \n   void fly() override { /*...*/ } \n};\nTurkeys are represented by the abstract Turkey class, which of course is\nimplemented by many dif ferent kinds of specific Turkeys, like the\nWildTurkey. To make things worse, for some reason ducks and turkeys are\nexpected be used together . One possible way to make this work is to\npretend that a turkey is a duck. After all, a turkey is pretty similar to a duck.\nWell, OK, it doesn’ t quack, but it can gobble (the typical turkey sound), and\nit can also fly (not for a long distance, but yes, it can fly). So you could\nadapt turkeys to ducks with the TurkeyAdapter:\n//---- <TurkeyAdapter.h> ---------------- \n \n#include <memory> \n 8\nclass TurkeyAdapter : public Duck \n{ \n public: \n   explicit TurkeyAdapter( std::unique_ptr<Turkey> turkey ) \n      : turkey_{ std::move(turkey) } \n   {} \n \n   void quack() override { turkey_->gobble(); } \n   void fly() override { turkey_->fly(); } \n \n private: \n   std::unique_ptr<Turkey> turkey_;  // This is an example for an object \nadapter \n};\nWhile this is an amusing interpretation of duck typing , this example nicely\ndemonstrates that it’ s way too easy to integrate something alien into an\nexisting hierarchy . A Turkey is simply not a Duck, even if we want it to be.\nI would ar gue that likely both the quack() and the fly() function violate\nthe LSP . Neither functions really does what I would expect it to (at least I’m\npretty sure that I want a quacking, not gobbling, critter and that I want\nsomething that can really fly like a duck). Of course, it depends on the\nspecific context, but undeniably , the Adapter design pattern makes it very\neasy to combine things that do not belong together . Thus, it’ s very\nimportant that you consider the expected behavior and check for LSP\nviolations when applying this design pattern:\n#include <MallardDuck.h> \n#include <WildTurkey.h> \n#include <TurkeyAdapter.h> \n#include <memory> \n#include <vector> \n \nusing DuckChoir = std::vector<std::unique_ptr<Duck>>; \n \nvoid give_concert( DuckChoir const& duck_choir ) \n{ \n   for( auto const& duck : duck_choir ) { \n      duck->quack(); \n   } \n} \n \nint main() \n{ \n   DuckChoir duck_choir{}; \n \n   // Let's hire the world's best ducks for the choir \n   duck_choir.push_back( std::make_unique<MallardDuck>() ); \n   duck_choir.push_back( std::make_unique<MallardDuck>() ); \n   duck_choir.push_back( std::make_unique<MallardDuck>() ); \n \n   // Unfortunately we also hire a turkey in disguise \n   auto turkey = std::make_unique<WildTurkey>(); \n   auto turkey_in_disguise = std::make_unique<TurkeyAdapter>( \nstd::move(turkey) ); \n   duck_choir.push_back( std::move(turkey_in_disguise) ); \n \n   // The concert is going to be a musical disaster... \n   give_concert( duck_choir ); \n \n   return EXIT_SUCCESS; \n}\nIn summary , the Adapter design pattern can be considered one of the most\nvaluable design patterns for combining dif ferent pieces of functionality and\nmaking them work together . I promise that it will prove to be a valuable\ntool in your daily work. Still, do not abuse the power of Adapter in some\nheroic ef fort to combine apples and oranges (or even oranges and\ngrapefruits: they are similar but not the same). Always be aware of LSP\nexpectations.",5477
74-The Observer Design Pattern Explained.pdf,74-The Observer Design Pattern Explained,"GUIDELINE 24: USE ADAPTERS TO STANDARDIZE\nINTERFACES\nApply the Adapter design pattern with the intent to adapt\ninterfaces so that otherwise incompatible pieces can work together .\nBe aware that Adapter is useful for both dynamic and static\npolymorphism.\nDistinguish among object adapters, class adapters, and function\nadapters.\nUnderstand the dif ferences between the Adapter and Strategy\ndesign patterns.\nPay attention to LSP violations when using the Adapter design\npattern.\nGuideline 25: Apply Observers as an\nAbstract Notification Mechanism\nChances  are good that you’ve heard about observers before. “Oh, yes, of\ncourse I have—isn’ t this what the so-called social media platforms are\ndoing with us?” you ask. Well, not exactly what I was going for , but yes, I\nbelieve we could call these platforms observers. And yes, there is also a\npattern to what they do, even though it is not a design pattern. But I’m\nactually thinking about one of the most popular GoF design patterns, the\nObserver design pattern. Even if you are not familiar with the idea yet, you\nvery likely have some experience with helpful observers from real life. For\ninstance, you may have noticed that in some messenger apps the sender of a\ntext message is immediately informed once you’ve read a new text\nmessage. That means that the message is displayed as “read” instead of just\n“delivered.” This little service is essentially the work of a real-life\nObserver: as soon as the status of the new message changes, the sender is\nnotified, providing the opportunity to respond to the state change.\nThe Observer Design Pattern Explained\nIn many software situations it’ s desirable to get feedback as soon as some\nstate change occurs: a new job is added to a task queue, a setting is changed\nin some configuration object, a result is ready to be picked up, etc. But at\nthe same time, it would be highly undesirable to introduce explicit\ndependencies between the subject (the observed entity that changes) and its\nobservers (the callbacks that are notified based on a state change). On the\ncontrary , the subject should be oblivious to the potentially many dif ferent\nkinds of observers. And that’ s for the simple reason that any direct\ndependency would make the software harder to change and harder to\nextend. This decoupling between the subject and its potentially many\nobservers is the intent of the Observer design pattern.\nTHE OBSERVER DESIGN PATTERN\nIntent: “Define  a one-to-many dependency between objects so that when one object\nchanges state, all its dependents are notified and updated automatically .”\nAs with all design patterns, the Observer design pattern identifies one\naspect as a  variation point  (an aspect that changes or is expected to change)\nand extracts it in the form of an abstraction. It thus helps to decouple\nsoftware entities. In the case of the Observer , the need to introduce new\nobservers—the need to extend a one-to-many dependency—is recognized\nto be the variation point. As Figure 6-2  illustrates, this variation point is\nrealized in the form  of the Observer base class.9\nFigur e 6-2. The UML r epresentation of the Observer design pattern\nThe Observer class represents the abstraction for all possible\nimplementations of observers. These observers are attached to a specific\nsubject, represented by the ConcreteSubject class. T o reduce the coupling\nbetween observers and their subjects, or to simply reduce code duplication\nby providing all common services to attach() and detach() to dif ferent\nobservers, the Subject abstraction can be used. This Subject might also",3635
75-A Classic Observer Implementation.pdf,75-A Classic Observer Implementation,"notify() all attached observers about a state change and trigger their\ncorresponding update() functionality .\n“Isn’ t the introduction of the Observer base class another example of the\nSRP?” you ask. And yes, you’re 100% correct: extracting the Observer\nclass, extracting a variation point, is the SRP in action (see “Guideline 2:\nDesign for Change” ). Again, the SRP acts as an enabler for the OCP (see\n“Guideline 5: Design for Extension” ): by introducing the Observer\nabstraction, anyone is able to add new kinds of observers (e.g.,\nConcreteObserver) without the need to modify existing code. If you pay\nattention to the ownership of the Observer base class and make sure that\nthe Observer class lives in the high level of your architecture, then you also\nfulfill the Dependency Inversion Principle (DIP).\nA Classic Observer Implementation\n“Great, I get it! It’ s nice to see these design principles in action again, but I\nwould like to see a concrete Observer example.” I understand. So let’ s take\na look at a concrete implementation. However , I should clearly state the\nlimitations of the following example before we start to look at the code.\nYou might already be familiar with Observer, and therefore you might be\nlooking for help and deeper advice on many of the tricky implementation\ndetails of Observer: how to deal with the order of attaching and detaching\nobservers, attaching an observer multiple times, and especially using\nobservers in a concurrent environment. I should honestly state up front that\nit is not my intention to provide answers to these questions. That discussion\nwould be like opening a can of worms, quickly sucking us into the realm of\nimplementation details. No, although you may be disappointed, my\nintention is to mostly stay on the level of software design.\nLike for the previous design patterns, we start with a classic implementation\nof the Observer design pattern. The central element is the Observer base\nclass:\n \n//---- <Observer.h> ---------------- 10\n \nclass Observer \n{ \n public: \n   virtual ~Observer() = default; \n \n   virtual void update( /*...*/ ) = 0;  \n \n}; \nThe most important implementation detail of this class is the pure virtual\nupdate() function (\n ), which is called whenever the observer is notified of\nsome state change.  There are three alternatives for how to define the\nupdate() function, which provide a reasonable implementation and design\nflexibility . The first alternative is to push the updated state via one or even\nseveral update() functions:\nclass Observer \n{ \n public: \n   // ... \n   virtual void update1( /*arguments representing the updated state*/ ) = 0; \n   virtual void update2( /*arguments representing the updated state*/ ) = 0; \n   // ... \n};\nThis form of observer is commonly called a  push observer . In this form, the\nobserver is given all necessary information by the subject and therefore is\nnot required to pull any information from the subject on its own. This can\nreduce the coupling to the subject significantly and create the opportunity to\nreuse the Observer class for several subjects. Additionally , there is the\noption to use a separate overload for each kind of state change. In the\npreceding code snippet, there are two update() functions, one for each of\ntwo possible state changes. And since it’ s always clear which state changed,\nthe observer is not required to “search” for any state change, which proves\nto be ef ficient.\n“Excuse me,” you say , “but isn’ t this a violation of the ISP? Shouldn’ t we\nseparate concerns by separating the update() functions into several base\nclasses?” This is a great question! Obviously , you’re watching out for1 1\nartificial coupling. Very good! And you are correct: we could separate an\nObserver with several update() functions into smaller Observer classes:\nclass Observer1 \n{ \n public: \n   // ... \n   virtual void update1( /*arguments representing the updated state*/ ) = 0; \n   // ... \n}; \n \nclass Observer2 \n{ \n public: \n   // ... \n   virtual void update2( /*arguments representing the updated state*/ ) = 0; \n   // ... \n};\nIn theory , this approach could help reduce the coupling to a particular\nsubject and more easily reuse observers for dif ferent subjects. It might also\nhelp because dif ferent observers might be interested in dif ferent state\nchanges, and therefore it might be a violation of the ISP to artificially\ncouple all possible state changes. And of course this might result in an\nefficiency gain if a lot of unnecessary state change notifications can be\navoided.\nUnfortunately , a particular subject is not likely to distinguish among\ndifferent kinds of observers. First, because this would require it to store\ndifferent kinds of pointers (which is inconvenient to handle for the subject),\nand second, because it is possible that dif ferent state changes are linked in a\ncertain way . In that case, the subject will expect that observers are interested\nin all possible state changes. From that perspective it can be reasonable to\ncombine several update() functions into one base class. Either way , it’s\nvery likely that a concrete observer will have to deal with all kinds of state\nchanges. I know , it can be a nuisance to have to deal with several update()\nfunctions, even if only a small fraction of them are interesting. But still,\nmake sure that you’re not accidentally violating the Liskov Substitution\nPrinciple by not adhering to some expected behavior (if there is any).\nThere are several more potential downsides of a push observer . First, the\nobservers are always  given all the information, whether they need it or not.\nThus, this push style works well only if the observers need the information\nmost of the time. Otherwise, a lot of ef fort is lost on unnecessary\nnotifications. Second, pushing creates a dependency on the number and\nkind of ar guments that are passed to the observer . Any change to these\narguments requires a lot of subsequent changes in the deriving observer\nclasses.\nSome of these downsides are resolved by the second Observer alternative.\nIt’s possible to only pass a reference to the subject to the observer:\nclass Observer \n{ \n public: \n   // ... \n   virtual void update( Subject const& subject ) = 0; \n   // ... \n};\nDue to the lack of specific information passed to the observer , the classes\nderiving from the Observer base class are required to pull the new\ninformation from the subject on their own. For this reason, this form of\nobserver is commonly called a  pull observer . The advantage is the reduced\ndependency on the number and kinds of ar guments. Deriving observers are\nfree to query for any information, not just the changed state. On the other\nhand, this design creates a strong, direct dependency between the classes\nderiving from Observer and the subject. Hence, any change to the subject\neasily reflects on the observers. Additionally , observers might have to\n“search” for the state change if multiple details have changed. This might\nprove to be unnecessarily inef ficient.\nIf you consider only a single piece of information as the changing state, the\nperformance disadvantage might not pose a limitation for you. Still, please\nremember that software changes: a subject may grow , and with it the desire\nto notify about dif ferent kinds of changes. Adapting the observers in the12\nprocess would result in a lot of additional work. From that point of view ,\nthe push observer  appears to be a better choice.\nLuckily , there is a third alternative, which removes a lot of the previous\ndisadvantages and thus becomes our approach of choice: in addition to\npassing a reference to the subject, we pass a tag to provide information\nabout which property of a subject has changed:\n//---- <Observer.h> ---------------- \n \nclass Observer \n{ \n public: \n   virtual ~Observer() = default; \n \n   virtual void update( Subject const& subject \n                      , /*Subject-specific type*/ property ) = 0; \n};\nThe tag may help an observer to decide on its own whether some state\nchange is interesting or not. It’ s commonly represented by some subject-\nspecific enumeration type, which lists all possible state changes. This,\nunfortunately , increases the coupling of the Observer class to a specific\nsubject.\n“Wouldn’ t it be possible to remove the dependency on a specific Subject\nby implementing the Observer base class as a class template? T ake a look\nat the following code snippet:”\n \n//---- <Observer.h> ---------------- \n \ntemplate< typename Subject, typename StateTag >  \n \nclass Observer \n{ \n public: \n   virtual ~Observer() = default; \n \n   virtual void update( Subject const& subject, StateTag property ) = 0; \n}; \nThis is a great suggestion. By defining the Observer class in the form of a\nclass template (\n ), we can easily lift the Observer to a higher architectural\nlevel. In this form, the class does not depend on any specific subject and\nthus may be reused by many dif ferent subjects that want to define a one-to-\nmany relationship. However , you should not expect too much of this\nimprovement: the ef fect is limited to the Observer class. Concrete subjects\nwill expect concrete instantiations of this observer class, and in\nconsequence, concrete implementations of Observer will still strongly\ndepend on the subject.\nTo better understand why that is, let’ s take a look at a possible subject\nimplementation. After your initial comment about social media, I suggest\nthat we implement an Observer for persons. W ell, OK, this example may be\nmorally questionable, but it will serve its purpose, so let’ s go with that. At\nleast we know who is to blame for this.\nThe following Person class represents an observed person:\n \n//---- <Person.h> ---------------- \n \n#include <Observer.h> \n#include <string> \n#include <set> \n \nclass Person \n{ \n public: \n   enum StateChange \n   { \n      forenameChanged, \n      surnameChanged, \n      addressChanged \n   }; \n \n   using PersonObserver = Observer<Person,StateChange>;  \n \n \n   explicit Person( std::string forename, std::string surname ) \n      : forename_{ std::move(forename) } \n      , surname_{ std::move(surname) } \n   {} \n \n   bool attach( PersonObserver* observer );  \n \n   bool detach( PersonObserver* observer );  \n \n \n   void notify( StateChange property );  \n \n \n   void forename( std::string newForename );  \n \n   void surname ( std::string newSurname ); \n   void address ( std::string newAddress ); \n \n   std::string const& forename() const { return forename_; } \n   std::string const& surname () const { return surname_; } \n   std::string const& address () const { return address_; } \n \n private: \n   std::string forename_;  \n \n   std::string surname_; \n   std::string address_; \n \n   std::set<PersonObserver*> observers_;  \n \n}; \nIn this example, a Person is merely an aggregation of the three data\nmembers: forename_, surname_, and address_ (\n) (I know , this is a rather\nsimple representation of a person.) In addition, a person holds the std::set\nof registered observers (\n ). Please note that the observers are registered by\npointers to instances of PersonObserver (\n). This is interesting for two\nreasons: first, this demonstrates the purpose of the templated Observer\nclass: the Person class instantiates its own kind of observer from the class\ntemplate. And second, pointers prove to be very useful in this context, since\nthe address of an object is unique. Thus, it is common to use the address as\na unique identifier for an observer .\n“Shouldn’ t this be std::unique_ptr or std::shared_ptr?” you ask. No,\nnot in this situation. The pointers merely serve as handles to the registered\nobservers; they should not own the observers. Therefore, any owning smart\npointer would be the wrong tool in this situation. The only reasonable\nchoice would be std::weak_ptr, which would allow you to check for\ndangling pointers. However , std::weak_ptr is not a good candidate for a\nkey for std::set (not even with a custom comparator). Although there are\nways to still use std::weak_ptr, I will stick to raw pointers. But don’ t\nworry , this doesn’ t mean we are abandoning the benefits of modern C++.\nNo, using a raw pointer is perfectly valid in this situation. This is also\nexpressed in C++ Core Guideline F .7:\nFor the general use, take T* or T& arguments rather than smart pointers.\nWhenever you’re interested in getting a notification for a state change of a\nperson, you can register an observer via the attach() member function (\n ).\nAnd whenever you’re no longer interested in getting notifications, you can\nderegister an observer via the detach() member function (\n ). These two\nfunctions are an essential ingredient of the Observer design pattern and a\nclear indication of the application of the design pattern:\nbool Person::attach( PersonObserver* observer ) \n{ \n   auto [pos,success] = observers_.insert( observer ); \n   return success; \n} \n \nbool Person::detach( PersonObserver* observer ) \n{ \n   return ( observers_.erase( observer ) > 0U ); \n}\nYou have complete freedom to implement the attach() and detach()\nfunctions as you see fit. In this example, we allow an observer to be\nregistered only a single time with a std::set. If you try to register an\nobserver a second time, the function returns false. The same thing happens\nif you try to deregister an observer that is not registered. Note that the\ndecision to not allow multiple registrations is my choice for this example. In\nother scenarios, it might be desirable or even necessary to accept duplicate\nregistrations. Either way , the behavior and interface of the subject should of\ncourse be consistent in all cases.\nAnother core function of the Observer design pattern is the notify()\nmember function (\n ). Whenever some state change occurs, this function is\ncalled to notify all registered observers about the change:\nvoid Person::notify( StateChange property ) \n{ \n   for( auto iter=begin(observers_); iter!=end(observers_); ) \n   { \n      auto const pos = iter++; \n      (*pos)->update(*this,property); \n   } \n}\n“Why is the implementation of the notify() function so complicated?\nWouldn’ t a range-based for loop be completely suf ficient?” Y ou are\ncorrect; I should explain what’ s happening here. The given formulation\nmakes sure detach() operations can be detected during the iteration. This\nmay happen, for instance, if an observer decides to detach itself during the\ncall to the update() function. But I do not claim that this formulation is\nperfect: unfortunately it is not able to cope with attach() operations. And\ndon’t even start to ask about concurrency! So this is just one example why\nthe implementation details of observer can be so tricky .\nThe notify() function is called in all three setter functions (\n ). Note that\nin all three functions, we always pass a dif ferent tag to indicate which\nproperty has changed. This tag may be used by classes deriving from the\nObserver base class to determine the nature of the change:\nvoid Person::forename( std::string newForename ) \n{ \n   forename_ = std::move(newForename); \n   notify( forenameChanged ); \n} \n \nvoid Person::surname( std::string newSurname ) \n{ \n   surname_ = std::move(newSurname); \n   notify( surnameChanged ); \n} \n \nvoid Person::address( std::string newAddress ) \n{ \n   address_ = std::move(newAddress); \n   notify( addressChanged ); \n}\nWith these mechanics in place, you are now able to write new kinds of fully\nOCP-conforming observers. For instance, you could decide to implement a\nNameObserver and an AddressObserver:\n//---- <NameObserver.h> ---------------- \n \n#include <Observer.h> \n#include <Person.h> \n \nclass NameObserver : public Observer<Person,Person::StateChange> \n{ \n public: \n   void update( Person const& person, Person::StateChange property ) override; \n}; \n \n \n//---- <NameObserver.cpp> ---------------- \n \n#include <NameObserver.h> \n \nvoid NameObserver::update( Person const& person, Person::StateChange property \n) \n{ \n   if( property == Person::forenameChanged || \n       property == Person::surnameChanged ) \n   { \n      // ... Respond to changed name \n   } \n} \n \n \n//---- <AddressObserver.h> ---------------- \n \n#include <Observer.h> \n#include <Person.h> \n \nclass AddressObserver : public Observer<Person,Person::StateChange> \n{ \n public: \n   void update( Person const& person, Person::StateChange property ) override; \n}; \n \n//---- <AddressObserver.cpp> ---------------- \n \n#include <AddressObserver.h> \n \nvoid AddressObserver::update( Person const& person, Person::StateChange \nproperty ) \n{ \n   if( property == Person::addressChanged ) { \n      // ... Respond to changed address \n   } \n}\nEquipped with these two observers, you are now notified whenever either\nthe name or address of a person changes:\n#include <AddressObserver.h> \n#include <NameObserver.h> \n#include <Person.h> \n#include <cstdlib> \n \nint main() \n{ \n   NameObserver nameObserver; \n   AddressObserver addressObserver; \n \n   Person homer( ""Homer""     , ""Simpson"" ); \n   Person marge( ""Marge""     , ""Simpson"" ); \n   Person monty( ""Montgomery"", ""Burns""   ); \n \n   // Attaching observers \n   homer.attach( &nameObserver ); \n   marge.attach( &addressObserver ); \n   monty.attach( &addressObserver ); \n \n   // Updating information on Homer Simpson \n   homer.forename( ""Homer Jay"" );  // Adding his middle name \n \n   // Updating information on Marge Simpson \n   marge.address( ""712 Red Bark Lane, Henderson, Clark County, Nevada 89011"" \n); \n \n   // Updating information on Montgomery Burns \n   monty.address( ""Springfield Nuclear Power Plant"" ); \n \n   // Detaching observers \n   homer.detach( &nameObserver ); \n \n   return EXIT_SUCCESS; \n}\nAfter these many implementation details, let’ s take a step back and look at\nthe bigger picture again. Figure 6-3  shows the dependency graph for this\nObserver example.",18142
76-An Observer Implementation Based on Value Semantics.pdf,76-An Observer Implementation Based on Value Semantics,"Figur e 6-3. Dependency graph for the Observer design pattern\nDue to the decision to implement the Observer class in the form of a class\ntemplate, the Observer class resides on the highest level of our\narchitecture. This enables you to reuse the Observer class for multiple\npurposes, for instance, for the Person class. The Person class declares its\nown Observer<Person,Person::StateChange>  type and by that injects\nthe code into its own architectural level. Concrete person observers, e.g.,\nNameObserver and AddressObserver, can subsequently build on this\ndeclaration.\nAn Observer Implementation Based on V alue Semantics\n“I understand why you’ve started with a classic implementation, but since\nyou have made the point about favoring value semantics, how would the\nobserver look in a value semantics world?” That is an excellent question,\nsince this a very reasonable next step. As explained in “Guideline 22: Prefer\nValue Semantics over Reference Semantics ”, there are a lot of good reasons\nto avoid the realm of reference semantics. However , we won’ t entirely stray\nfrom the classic implementation: to register and deregister observers, we\nwill always be in need of some unique identifier for observers, and the\nunique address of an observer is just the easiest and most convenient way to\ntackle that problem. Therefore, we’ll stick to using a pointer to refer to a\nregistered observer . However , std::function is an elegant way to avoid\nthe inheritance hierarchy— std::function:\n \n//---- <Observer.h> ---------------- \n \n#include <functional> \n \ntemplate< typename Subject, typename StateTag > \nclass Observer \n{ \n public: \n   using OnUpdate = std::function<void(Subject const&,StateTag)>;  \n \n \n   // No virtual destructor necessary \n \n   explicit Observer( OnUpdate onUpdate )  \n \n      : onUpdate_{ std::move(onUpdate) } \n   { \n      // Possibly respond on an invalid/empty std::function instance \n   } \n \n   // Non-virtual update function \n   void update( Subject const& subject, StateTag property ) \n   { \n      onUpdate_( subject, property );  \n \n   } \n \n private: \n   OnUpdate onUpdate_;  \n \n}; \nInstead of implementing the Observer class as a base class, and thus\nrequiring deriving classes to inherit and implement the update() function\nin a very specific way , we separate concerns and instead build on\ncomposition (see “Guideline 20: Favor Composition over Inheritance” ).\nThe Observer class first provides a type alias called OnUpdate for the\nstd::function type for the expected signature of our update() function (\n). Via the constructor , you are passed an instance of std::function (\n),\nand you move it into your data member onUpdate_ (\n). The job of the\nupdate() function is now to forward the call, including the ar guments, to\nonUpdate_ (\n).\nThe flexibility gained with std::function is easily demonstrated with an\nupdated main() function:\n#include <Observer.h> \n#include <Person.h> \n#include <cstdlib> \n \nvoid propertyChanged( Person const& person, Person::StateChange property ) \n{ \n   if( property == Person::forenameChanged || \n       property == Person::surnameChanged ) \n   { \n      // ... Respond to changed name \n   } \n} \n \nint main() \n{ \n   using PersonObserver = Observer<Person,Person::StateChange>; \n \n   PersonObserver nameObserver( propertyChanged ); \n \n   PersonObserver addressObserver( \n      [/*captured state*/]( Person const& person, Person::StateChange property \n){ \n         if( property == Person::addressChanged ) \n         { \n            // ... Respond to changed address \n         } \n      } ); \n \n   Person homer( ""Homer""     , ""Simpson"" ); \n   Person marge( ""Marge""     , ""Simpson"" ); \n   Person monty( ""Montgomery"", ""Burns""   ); \n \n   // Attaching observers \n   homer.attach( &nameObserver ); \n   marge.attach( &addressObserver ); \n   monty.attach( &addressObserver ); \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\nThanks to choosing a less intrusive approach and to decoupling with\nstd::function, the choice of how to implement the update() function is\ncompletely up to the observer ’s implementer (stateless, stateful, etc.). For\nthe nameObserver, we build on the free function propertyChanged(),\nwhich itself is strongly decoupled because it’ s not bound to a class and\nmight be reused on several occasions. The addressObserver, on the other\nhand, chooses a lambda instead, which could possibly capture some state.\nEither way , the only convention that these two have to follow is to fulfill the\nrequired signature of the required std::function type.\n“Why do we still need the Observer class? Couldn’ t we just directly use\nstd::function?” Yes, it most certainly looks that way . From a\nfunctionality point of view , the Observer class doesn’ t add anything by",4838
77-Analyzing the Shortcomings of the Observer Design Pattern.pdf,77-Analyzing the Shortcomings of the Observer Design Pattern,"itself. However , as std::function is a true child of value semantics, we\ntend to copy or move std::function objects. But this is not desirable in\nthis situation: especially if you use a stateful observer , you don’ t want a\ncopy of your observer to be called. And although technically possible, it is\nnot particularly common to pass around pointers to std::function.\nTherefore, the Observer class may still be of value in the form of an\nAdapter for std::function (see “Guideline 24: Use Adapters to\nStandardize Interfaces” ).\nAnalyzing the Shortcomings of the Observer Design\nPattern\n“This  is not quite the value semantics solution I was expecting, but I still\nlike it!” Well, I’m glad you feel this way . Indeed, the value semantics\nadvantages, in combination with the benefits of the Observer design pattern\n(i.e., decoupling an event from the action taken for that event and the ability\nto easily add new kinds of observers), work really , really well.\nUnfortunately , there is no perfect design, and every design also comes with\ndisadvantages.\nFirst, I should explicitly spell out that the demonstrated std::function\napproach works well only for a  pull observer  with a single update()\nfunction. Since std::function can cope with only a single callable, any\napproach that would require multiple update() functions cannot be\nhandled by a single std::function. Therefore, std::function is usually\nnot the way to go for a  push observer  with multiple update() functions, or\nthe potential for a growing number of update() functions (remember , code\ntends to change!). However , it is possible to generalize the approach of\nstd::function. If the need arises, the design pattern of choice is T ype\nErasure (see Chapter 8 ).\nA second (minor) disadvantage, as you have seen, is that there is no pure\nvalue-based implementation. While we might be able to implement the\nupdate() functionality in terms of std::function to gain flexibility , we\nstill use a raw pointer to attach and detach Observers. And that is easy to\nexplain: the advantages of using a pointer as a unique identifier are just too\ngood to dismiss. Additionally , for a stateful Observer , we don’ t want to deal\nwith the copy of an entity . Still, this of course requires us to check for\nnullptr (which takes additional ef fort), and we always have to pay for the\nindirection that the pointer represents.  I personally would rate this as only\na minor point because of the many advantages of this approach.\nA far bigger disadvantage is the potential implementation issues with\nObservers : the order of registration and deregistration may matter a lot, in\nparticular if an observer is allowed to register multiple times. Also, in a\nmultithreaded environment, the thread-safe registration and deregistration\nof observers and handling of events are highly nontrivial topics. For\ninstance, an untrusted observer can freeze a server during a callback if it\nbehaves inappropriately , and implementing timeouts for arbitrary\ncomputations is very nontrivial. However , this topic is far outside the scope\nof this book.\nWhat is in the scope of this book, however , is the alleged danger that the\noveruse of observers can quickly and easily lead to a complex network of\ninterconnections. Indeed, if you are not careful, you can accidentally\nintroduce an infinite loop of callbacks! For that reason, developers are\nsometimes concerned about using Observers and are afraid that a single\nnotification may result in a huge, global response due to these\ninterconnections. While this danger exists, of course, a proper design should\nnot be severely af fected by this: if you have a proper architecture and if you\nhave properly implemented your observers, then any sequence of\nnotifications should always run along a  directed, acyclic graph (DAG)\ntoward the lower levels of your architecture. And that, of course, is the\nbeauty of good software design.\nIn summary , with the intent of providing a solution for notification of state\nchange, the Observer design pattern proves to be one of the most famous\nand most commonly used design patterns. Aside from the potentially tricky\nimplementation details, it is definitely one of the design patterns that should\nbe in every developer ’s toolbox.13",4304
78-Guideline 26 Use CRTP to Introduce Static Type Categories.pdf,78-Guideline 26 Use CRTP to Introduce Static Type Categories,,0
79-A Motivation for CRTP.pdf,79-A Motivation for CRTP,"GUIDELINE 25: APPLY OBSERVERS AS AN ABSTRACT\nNOTIFICATION MECHANISM\nApply the Observer design pattern with the intent to create a one-\nto-many relationship between a subject and its observers.\nUnderstand the trade-of fs between push observers and pull\nobservers.\nUtilize the advantages of a value semantics–based Observer\nimplementation.\nGuideline 26: Use CRTP to Introduce Static\nType Categories\nC++ really has a lot to of fer. It comes with lots of features, many syntactic\ncuriosities, and a lar ge number of amazing, utterly unpronounceable and\n(for the uninitiated) plainly cryptic acronyms: RAII, ADL, CT AD,\nSFINAE, NTTP , IFNDR, and SIOF . Oh, what fun! One of these cryptic\nacronyms is CR TP, short for the Curiously Recurring T emplate Pattern . If\nyou’re’ scratching your head because the name doesn’ t make any sense to\nyou, don’ t worry: as is so often in C++, the name was chosen randomly , but\nhas stuck and has never been reconsidered or changed. The pattern was\nnamed by James Coplien in the February 1995 issue of the C++ Report\nafter realizing that, curiously , this pattern was recurring in many dif ferent\nC++ codebases.  And curiously , this pattern, although building on\ninheritance and (potentially) serving as an abstraction, does not exhibit the\nusual performance drawbacks of many other classic design patterns. For\nthat reason, CR TP is definitely worth a look, as it may become a valuable,\nor should I say curious , addition to your design pattern toolbox.\nA Motivation for CRTP14\n15\nPerformance  is very important in C++. So important in fact, that in several\ncontexts the performance overhead of using virtual functions is considered\noutright unacceptable . Therefore, in performance-sensitive contexts, such as\ncertain parts of computer games or high-frequency trading, no virtual\nfunctions are used. The same is true for high-performance computing\n(HPC). In HPC, any kind of conditional or indirection, and this includes\nvirtual functions, is banned from the most performance-critical parts, such\nas the innermost loops of compute kernels. Using them would incur too\nmuch of a performance overhead.\nTo give an example of how and why this matters, let’ s consider the\nfollowing DynamicVector class template from a linear algebra (LA)\nlibrary:\n \n//---- <DynamicVector.h> ---------------- \n \n#include <numeric> \n#include <iosfwd> \n#include <iterator> \n#include <vector> \n// ... \n \ntemplate< typename T > \nclass DynamicVector \n{ \n public: \n   using value_type     = T;  \n \n   using iterator       = typename std::vector<T>::iterator; \n   using const_iterator = typename std::vector<T>::const_iterator; \n \n   // ... Constructors and special member functions \n \n   size_t size() const;  \n \n \n   T&       operator[]( size_t index );  \n \n   T const& operator[]( size_t index ) const; \n \n   iterator       begin();  \n \n   const_iterator begin() const; \n   iterator       end(); \n   const_iterator end() const; \n \n   // ... Many numeric functions \n \n private: \n   std::vector<T> values_;  \n \n   // ... \n}; \n \ntemplate< typename T > \nstd::ostream& operator<<( std::ostream& os, DynamicVector const<T>& vector )  \n \n{ \n   os << ""(""; \n   for( auto const& element : vector ) { \n      os << "" "" << element; \n   } \n   os << "" )""; \n \n   return os; \n} \n \ntemplate< typename T > \nauto l2norm( DynamicVector const<T>& vector )  \n \n{ \n   using std::begin, std::end; \n   return std::sqrt( std::inner_product( begin(vector), end(vector) \n                                       , begin(vector), T{} ) ); \n} \n \n// ... Many more \nDespite the name, DynamicVector does not represent a container but a\nnumerical vector for the purpose of LA computations. The Dynamic part of\nthe name implies that it allocates its elements of type T dynamically , in this\nexample, in the form of std::vector (\n). For that reason, it is suited for\nlarge LA problems (definitely in the range of several million elements).\nAlthough this class may be loaded with many numerical operations, from\nan interface point of view you might indeed be tempted to call it a\ncontainer: it provides the usual nested types ( value_type, iterator, and\nconst_iterator) (\n), a size() function to query the current number of\nelements (\n ), subscript operators to access individual elements by index\n(one for non- const and one for const vectors) (\n ), and begin() and end()\nfunctions to iterate over the elements (\n ). Apart from the member functions,\nit also provides an output operator (\n ) and, to show at least one LA\noperation, a function to compute the vector ’s Euclidean norm  (often also\ncalled the L2 norm , because it approximates the L2 norm for discrete\nvectors) (\n ).\nThe DynamicVector is not the only vector class, though. In our LA library ,\nyou will also find the following StaticVector class:\n \n//---- <StaticVector.h> ---------------- \n \n#include <array> \n#include <numeric> \n#include <iosfwd> \n#include <iterator> \n// ... \n \ntemplate< typename T, size_t Size > \nclass StaticVector \n{ \n public: \n   using value_type     = T;  \n \n   using iterator       = typename std::array<T,Size>::iterator; \n   using const_iterator = typename std::array<T,Size>::const_iterator; \n \n   // ... Constructors and special member functions \n \n   size_t size() const;  \n \n \n   T&       operator[]( size_t index );  \n \n   T const& operator[]( size_t index ) const; \n \n   iterator       begin();  \n \n   const_iterator begin() const; \n   iterator       end(); \n   const_iterator end() const; \n \n   // ... Many numeric functions \n \n private: \n   std::array<T,Size> values_;  \n \n   // ... \n}; \n \ntemplate< typename T, size_t Size > \nstd::ostream& operator<<( std::ostream& os,    \n \n                          StaticVector<T,Size> const& vector ) \n{ \n   os << ""(""; \n   for( auto const& element : vector ) { \n      os << "" "" << element; \n   } \n   os << "" )""; \n \n   return os; \n} \n \ntemplate< typename T, size_t Size > \nauto l2norm( StaticVector<T,Size> const& vector )  \n \n{ \n   using std::begin, std::end; \n   return std::sqrt( std::inner_product( begin(vector), end(vector) \n                                       , begin(vector), T{} ) ); \n} \n“Isn’ t this almost the same as the DynamicVector class?” you wonder . Yes,\nthese two classes are very similar indeed. The StaticVector class provides\nthe same interface as the DynamicVector, such as the nested types\nvalue_type, iterator, and const_iterator (\n); the size() member\nfunction (\n ); the subscript operators (\n ); and the begin() and end()\nfunctions (\n ). It also comes with an output operator (\n ) and a free\nl2norm() function (\n ). However , there is an important, performance-\nrelated dif ference between the two vector classes: as the Static in the\nname suggests, the StaticVector does not allocate its elements\ndynamically . Instead, it uses an in-class buf fer to store its elements, for\ninstance, with a std::array (\n). Thus, in contrast  to DynamicVector, the\nentire functionality of StaticVector is optimized for a small, fixed number\nof elements, such as 2D or 3D vectors.\n“OK, I understand that this is important for performance, but there’ s still a\nlot of code duplication, right?” Again, you are correct. If you take a close\nlook at the associated output operator of the two vector classes, you will\nfind that the implementation of these two functions is identical. This is\ndeeply undesirable: if anything changes, for instance, the way vectors are\nformatted (and remember: change is the one  constant in software\ndevelopment and needs to be expected; see “Guideline 2: Design for\nChange” ), then you would have to make the change in many places, not just\none. This is a violation of the Don’ t Repeat Y ourself (DR Y) principle: it’ s\neasy to for get or miss updating one of the many places, thus introducing an\ninconsistency or even a bug.\n“But isn’ t this duplication easily resolved with a slightly more general\nfunction template? For example, I can imagine the following output\noperator for all kinds of dense vectors:”\ntemplate< typename DenseVector > \nstd::ostream& operator<<( std::ostream& os, DenseVector const& vector ) \n{ \n   // ... as before \n}\nAlthough this seems like an adequate solution, I wouldn’ t accept this code\nin a pull request. This function template is indeed more general, but I would\ndefinitely not call it “slightly” more general; what you are suggesting is the\nmost general output operator one could possibly write. Y es, the name of the\nfunction template may suggest that it’ s written for only dense vectors\n(including DynamicVector and StaticVector), but this function template\nwill in fact accept any type: DynamicVector, StaticVector,\nstd::vector, std::string, and fundamental types such as int and\ndouble. It simply fails to specify any requirement or any kind of constraint.\nFor that reason it violates Core Guideline T .10:\nSpecify concepts for all template ar guments.\nWhile this output operator will work for all dense vectors and sequence\ncontainers, you would get a compilation error for all types that do not\nprovide the expected interface. Or even worse, you might subtly violate the\nimplicit requirements and expectations, and with that the LSP (see\n“Guideline 6: Adhere to the Expected Behavior of Abstractions” ). Of\ncourse, you wouldn’ t do this consciously , but likely accidentally: this output\noperator is a perfect match for any type and might be used even though you\ndon’t expect it. Therefore, this function template would be a very16\nunfortunate addition to the output operator overload set. What we need is a\ntotally new set of types, a new type category .\n“Isn’ t this what base classes are for? Couldn’ t we just formulate a\nDenseVector base class that defines the expected interface for all dense\nvectors? Consider the following sketch of a DenseVector base class:”\ntemplate< typename T >  // Type of the elements \nclass DenseVector \n{ \n public: \n   virtual ~DenseVector() = default; \n \n   virtual size_t size() const = 0; \n \n   virtual T&       operator[]( size_t index ) = 0; \n   virtual T const& operator[]( size_t index ) const = 0; \n \n   // ... \n}; \n \ntemplate< typename T > \nstd::ostream& operator<<( std::ostream& os, DenseVector<T> const& vector ) \n{ \n   // ... as before \n}\n“This should work, right? I’m just not sure how to declare the begin() and\nend() functions, as I don’ t know how to abstract from dif ferent iterator\ntypes, such as std::vector<T>::iterator and\nstd::array<T>::iterator.” I also have a feeling that this could be a\nproblem, and I admit that I also do not have a quick solution for that. But\nthere is something far more concerning: with this base class, we would turn\nall our member functions into virtual member functions. That would include\nthe begin() and end() functions but, most importantly , the two subscript\noperators. The consequences would be significant: with every access to an\nelement of the vector , we would now have to call a virtual function. Every\nsingle access! Therefore, with this base class, we could wave goodbye to\nhigh performance.",11259
80-The CRTP Design Pattern Explained.pdf,80-The CRTP Design Pattern Explained,"Still, the general idea of building an abstraction with a base class is good.\nWe just have to do it dif ferently . This is where we should take a closer look\nat the CR TP.\nThe CRTP Design Pattern Explained\nThe CRTP design pattern builds on the common idea of creating an\nabstraction using a base class. But instead of establishing a runtime\nrelationship between base and derived classes via virtual functions, it\ncreates a compile-time relationship.\nTHE CRTP DESIGN PATTERN\nIntent: “Define  a compile-time abstraction for a family of related types.”\nThe compile-time relationship between the DenseVector base class and the\nDynamicVector derived class is created by upgrading the base class to a\nclass template:\n \n//---- <DenseVector.h> ---------------- \n \ntemplate< typename Derived >  \n \nstruct DenseVector \n{ \n   // ... \n   size_t size() const { return static_cast<Derived const&>(*this).size(); }  \n \n   // ... \n}; \n \n \n//---- <DynamicVector.h> ---------------- \n \ntemplate< typename T > \nclass DynamicVector : public DenseVector<DynamicVector<T>>  \n \n{ \n public: \n   // ... \n   size_t size() const;  \n \n   // ... \n}; \nThe curious detail about CR TP is that the new template parameter of the\nDenseVector base class represents the type of the associated derived class (\n). Derived classes, for instance, the DynamicVector, are expected to\nprovide their own type to instantiate the base class (\n ).\n“Wow, wait a second—is that even possible?” you ask. It is. T o instantiate a\ntemplate, you do not need the complete definition of a type. It is suf ficient\nto use an incomplete type. Such an incomplete type is available after the\ncompiler has seen the class DynamicVector declaration. In essence, this\npiece of syntax works as a forward declaration. Therefore, the\nDynamicVector class can indeed use itself as a template ar gument to the\nDenseVector base class.\nOf course, you can name the template parameter of the base class however\nyou’d like (e.g., simply T), but as discussed in “Guideline 14: Use a Design\nPattern’ s Name to Communicate Intent” , it helps to communicate intent by\nusing the name of the design pattern or names commonly used for a pattern.\nFor that reason, you could name the parameter CRTP, which nicely\ncommunicates the pattern but unfortunately  only to the initiated. Everyone\nelse will be puzzled by the acronym. Therefore, the template parameter is\noften called Derived, which perfectly expresses its purpose and\ncommunicates its intent: it represents the type of the derived class.\nVia this template parameter , the base class is now aware of the actual type\nof the derived type. While it still represents an abstraction and the common\ninterface for all dense vectors, it is now able to access and call the concrete\nimplementation in the derived type. This happens, for instance, in the\nsize() member function (\n ): the DenseVector uses a static_cast to\nconvert itself into a reference to the derived class and calls the size()\nfunction on that. What at first glance may look like a recursive function call\n(calling the size() function within the size() function) is in fact a call of\nthe size() member function in the derived class (\n ).\n“So this is the compile-time relationship you were taking about. The base\nclass represents an abstraction from concrete derived types and\nimplementation details but still knows exactly where the implementation\ndetails are. So we really do not need any virtual function.” Correct. W ith\nCRTP, we are now able to implement a common interface and forward\nevery call to the derived class by simply performing a static_cast. And\nthere is no performance penalty for doing this. In fact, the base class\nfunction is very likely to be inlined, and if the DenseVector is the only or\nfirst base class, the static_cast will not even result in a single assembly\ninstruction. It merely tells the compiler to treat the object as an object of the\nderived type.\nTo provide a clean CR TP base class, we should update a couple of details,\nthough:\n \n//---- <DenseVector.h> ---------------- \n \ntemplate< typename Derived > \nstruct DenseVector \n{ \n protected: \n   ~DenseVector() = default;  \n \n \n public: \n   Derived&       derived()       { return static_cast<Derived&>( *this ); }  \n \n   Derived const& derived() const { return static_cast<Derived const&>( *this \n); } \n \n   size_t size() const { return derived().size(); } \n \n   // ... \n}; \nSince we want to avoid any virtual functions, we’re also not interested in a\nvirtual destructor . Therefore, we implement the destructor as a nonvirtual\nfunction in the protected section of the class (\n ). This perfectly adheres to\nCore Guideline C.35 :\nA base class destructor should be either public and virtual, or pr otected\nand non-virtual.\nKeep in mind, though, that this definition of the destructor keeps the\ncompiler from generating the two move operations. Since a CR TP base\nclass is usually empty with nothing  to move, this is not a problem; but still,\nalways be mindful about the Rule of 5 .\nWe should also avoid using a static_cast in every single member\nfunction of the base class. Although it would be correct, any cast should be\nconsidered suspicious, and casts should be minimized.  For that reason, we\nadd the two derived() member functions, which perform the cast and can\nbe used in the other member functions (\n ). This resulting code not only\nlooks cleaner and adheres to the DRY principle, but it also looks far less\nsuspicious.\nEquipped with the derived() functions, we can now go ahead and define\nthe subscript operators and the begin() and end() functions:\ntemplate< typename Derived > \nstruct DenseVector \n{ \n   // ... \n \n   ??? operator[]( size_t index )       { return derived()[index]; } \n   ??? operator[]( size_t index ) const { return derived()[index]; } \n \n   ??? begin()       { return derived().begin(); } \n   ??? begin() const { return derived().begin(); } \n   ??? end()         { return derived().end(); } \n   ??? end()   const { return derived().end(); } \n \n   // ... \n};\nHowever , these functions are not as straightforward as the size() member\nfunction. In particular , the return types prove to be a little harder to specify ,\nas these types depend on the implementation of the Derived class. “W ell,\nthat shouldn’ t be too hard,” you say . “This is why the derived types provide\na couple of nested types, such as value_type, iterator, and17\nconst_iterator, right?” Indeed, it appears to be intuitive to just ask\nnicely:\n \ntemplate< typename Derived > \nstruct DenseVector \n{ \n   // ... \n \n   using value_type     = typename Derived::value_type;  \n \n   using iterator       = typename Derived::iterator; \n   using const_iterator = typename Derived::const_iterator; \n \n   value_type&       operator[]( size_t index )       { return derived()\n[index]; } \n   value_type const& operator[]( size_t index ) const { return derived()\n[index]; } \n \n   iterator       begin()       { return derived().begin(); } \n   const_iterator begin() const { return derived().begin(); } \n   iterator       end()         { return derived().end(); } \n   const_iterator end()   const { return derived().end(); } \n \n   // ... \n}; \nWe query for the value_type, iterator, and const_iterator types in the\nderived class (don’ t forget the typename keyword) and use these to specify\nour return types (\n ). Easy , right? Y ou can almost bet that it’ s not that easy .\nIf you try this, the Clang compiler will complain with a seriously weird and\nbaffling error message:\nCRTP.cpp:29:41: error: no type named 'value_type' in 'DynamicVector<int>' \nusing value_type = typename Derived::value_type; \n                      ~~~~~~~~~~~~~~~~~~^~~~~~~~~~\n“No value_type in DynamicVector<int>—strange.” The first idea that\ncrosses your mind is that you messed up. It must be a typo. Of course! So\nyou go back to your code and check the spelling. However , it turns out that\neverything seems to be OK. There is no typo. Y ou check the\nDynamicVector class again: there it is, the nested value_type member .\nAnd everything is public, too. The error message just doesn’ t make any\nsense. Y ou reexamine everything, and again, and half an hour later you\nconclude, “The compiler has a bug!”\nNo, it isn’ t a bug in the compiler . Not in Clang or any other compiler . GCC\nprovides a dif ferent, still slightly puzzling, but a perhaps little more\nilluminating error message :\nCRTP.cpp:29:10: error: invalid use of incomplete type 'class \nDynamicVector<int>' \n   29 |    using value_type = typename Derived::value_type; \n      |          ^~~~~~~~~~\nThe Clang compiler is correct: there is no value_type in the\nDynamicVector class. Not yet! When you query for the nested types, the\ndefinition of the DynamicVector class hasn’ t been seen, and\nDynamicVector is still an incomplete type. That’ s because the compiler will\ninstantiate the DenseVector base class before the definition of the\nDynamicVector class. After all, syntactically , the base class is specified\nbefore the body of the class:\ntemplate< typename T > \nclass DynamicVector : public DenseVector<DynamicVector<T>> \n// ...\nIn consequence, there is no way that you can use the nested types of the\nderived class for the return types of the CR TP class. In fact, you can’ t use\nanything as long as the derived class is an incomplete type. “But why can I\ncall the member functions of the derived class? Shouldn’ t this result in the\nsame problem?” Luckily , this works (otherwise the CR TP pattern would not\nwork at all). But it only works because of a special property of class\ntemplates: member functions are only instantiated on demand, meaning\nwhen they are actually called. Since an actual call usually happens only\nafter the definition of the derived class is available, there is no problem with\na missing definition. At that point, the derived class is not an incomplete\ntype anymore.18\n“OK, I get it. But how do we specify the return types of the subscript\noperators and begin() and end() functions?” The most convenient way to\nhandle this is to use return type deduction. This is a perfect opportunity to\nuse the decltype(auto) return type:\ntemplate< typename Derived > \nstruct DenseVector \n{ \n   // ... \n \n   decltype(auto) operator[]( size_t index )       { return derived()[index]; \n} \n   decltype(auto) operator[]( size_t index ) const { return derived()[index]; \n} \n \n   decltype(auto) begin()       { return derived().begin(); } \n   decltype(auto) begin() const { return derived().begin(); } \n   decltype(auto) end()         { return derived().end(); } \n   decltype(auto) end()   const { return derived().end(); } \n};\n“Wouldn’ t it be enough to just use auto? For instance, we could define the\nreturn types like this:”\ntemplate< typename Derived > \nstruct DenseVector \n{ \n   // ... Note: this doesn't always work, whereas decltype(auto) always works \n \n   auto&       operator[]( size_t index )       { return derived()[index]; } \n   auto const& operator[]( size_t index ) const { return derived()[index]; } \n \n   auto begin()       { return derived().begin(); } \n   auto begin() const { return derived().begin(); } \n   auto end()         { return derived().end(); } \n   auto end()   const { return derived().end(); } \n};\nIt would be enough for this example, yes. However , as I keep emphasizing,\ncode changes. Eventually , there may be another , deriving vector class that\ndoes not store its values and returns references to its values but produces\nvalues and returns by value. And yes, this is easily conceivable: consider ,",11730
81-Analyzing the Shortcomings of the CRTP Design Pattern.pdf,81-Analyzing the Shortcomings of the CRTP Design Pattern,"for instance, a ZeroVector class, which represents the zero element  for\nvectors. Such a vector would not store all of its elements, as this would be\nwasteful, but would likely be implemented as an empty class, which returns\na zero by value every time an element is accessed. In that case, an auto&\nreturn type would be incorrect. Y es, the compiler would (hopefully) warn\nyou about that. But you could avoid the entire problem by just returning\nexactly  what the deriving class returns. And that kind of return type is\nrepresented by the decltype(auto) return.\nAnalyzing the Shortcomings of the CRTP Design Pattern\n“Wow, this  CRTP design pattern sounds amazing. So seriously , apart from\nthese slightly-more-complex-than-usual implementation details, isn’ t this\nthe solution to all performance issues with virtual functions? And isn’ t this\nthe key , the holy grail for all inheritance-related problems?” I can\nunderstand the enthusiasm! At first sight, CR TP most definitely looks like\nthe ultimate solution for all kinds of inheritance hierarchies. Unfortunately ,\nthat is an illusion. Remember: every design pattern comes with benefits but\nunfortunately also with drawbacks. And there are several pretty limiting\ndrawbacks to the CR TP design pattern.\nThe first, and one of the most restricting, drawbacks is the lack of a\ncommon base class.  I will repeat this to emphasize the gravity of the\nrepercussions: there is no common base class! Ef fectively , every single\nderived class has a dif ferent base class. For example, the\nDynamicVector<T> class has the DenseVector<Dynamic Vector<T>> base\nclass. The StaticVector<T,Size> class has the Dense Vector \n<StaticVector<T,Size>> base class  (see Figure 6-4 ). Thus, whenever a\ncommon base class is required, a common abstraction that can be used, for\ninstance, to store dif ferent types in a collection, the CR TP design pattern is\nnot the right choice.\nFigur e 6-4. Dependency graph for the CRTP design pattern\n“Oh, wow , I see that this could be a real limitation. But couldn’ t we just\nmake the CR TP base class derive from a common base class?” you ar gue.\nNo, not really , because this would require us to introduce virtual functions\nagain. “OK, I see. What about simulating a common base class using\nstd::variant?” Yes, that’ s an option. However , please remember that\nstd::variant is a representation of the Visitor  design pattern (see\n“Guideline 16: Use V isitor to Extend Operations” ). And since\nstd::variant needs to know about all its potential alternatives, this will\nlimit your freedom to add new types. So you see, even though you might\nnot like it, CR TP really is not a replacement for every inheritance hierarchy .\nThe second, also potentially very limiting drawback is that everything that\ncomes in touch with a CR TP base class becomes a template itself. That is\nparticularly true for all functions that work with such a base class. Consider ,\nfor instance, the upgraded output operator and the l2norm() function:\ntemplate< typename Derived > \nstd::ostream& operator<<( std::ostream& os, DenseVector<Derived> const& vector \n); \n \ntemplate< typename Derived > \nauto l2norm( DenseVector<Derived> const& vector );\nThese two functions should work with all classes deriving from the\nDenseVector CRTP class. And of course they should not depend on the\nconcrete types of the derived classes. Therefore, these two functions must\nbe function templates: the Derived type must be deduced. While in the\ncontext of a linear algebra library this is usually not an issue because almost\nall functionality is implemented in terms of templates anyway , this may be a\nbig downside in other contexts. It might be highly undesirable  to turn lots of\ncode into templates and move the definitions into header files, ef fectively\nsacrificing the encapsulation of source files. Y es, this may be a severe\ndrawback indeed!\nThird, CR TP is an intrusive design pattern. Deriving classes have to\nexplicitly opt in by inheriting from the CR TP base class. While this may be\na nonissue in our own code, you cannot easily add a base class to foreign\ncode. In such a situation, you would have to resort to the Adapter design\npattern (see “Guideline 24: Use Adapters to Standardize Interfaces” ). Thus,",4308
82-The Future of CRTP A Comparison Between CRTP and C20 Concepts.pdf,82-The Future of CRTP A Comparison Between CRTP and C20 Concepts,"CRTP does not provide the flexibility of nonintrusive design patterns (e.g.,\nthe V isitor design pattern implemented with std::variant, the Adapter\ndesign pattern, and so on).\nLast but not least, CR TP does not provide runtime polymorphism, only\ncompile-time polymorphism. Therefore, the pattern makes sense only if\nsome kind of static type abstraction is required. If not, it is again not a\nreplacement for all inheritance hierarchies .\nThe Future of CRTP: A Comparison Between CRTP and\nC++20 Concepts\n“I understand, you’re right. CR TP is pure compile-time polymorphism.\nHowever , this makes me wonder: wouldn’ t it be possible to build on C++20\nconcepts instead of CR TP? Consider the following code. W e could use a\nconcept to define the requirements for a set of types, and restrict functions\nand operators to only those types that provide the expected interface:”\ntemplate< typename T > \nconcept DenseVector = \n   requires ( T t, size_t index ) { \n      t.size(); \n      t[index]; \n      { t.begin() } -> std::same_as<typename T::iterator>; \n      { t.end() } -> std::same_as<typename T::iterator>; \n   } && \n   requires ( T const t, size_t index ) { \n      t[index]; \n      { t.begin() } -> std::same_as<typename T::const_iterator>; \n      { t.end() } -> std::same_as<typename T::const_iterator>; \n   }; \n \ntemplate< DenseVector VectorT > \nstd::ostream& operator<<( std::ostream& os, VectorT const& vector ) \n{ \n   // ... as before \n}\nYou are absolutely correct. I agree, this is a very reasonable alternative.\nIndeed, C++20  concepts are pretty similar to CR TP but represent an easier ,19\nnonintrusive alternative. Especially by being nonintrusive, if you have\naccess to C++20 concepts and it is possible to define the static set of types\nby a concept, you should prefer the concept over the CR TP.\nStill, I’m not entirely happy with this solution. While this formulation of the\noutput operator ef fectively constrains the function template to only those\ntypes that provide the expected interface, it does not completely restrict the\nfunction template to our set of dense vector types. It’ s still possible to pass\nstd::vector and std::string (std::string already has an output\noperator in the std namespace). Therefore, this concept is not specific\nenough. But if you run into this situation, don’ t worry: there is a solution\nusing a tag class:\n \nstruct DenseVectorTag {};  \n \n \ntemplate< typename T > \nconcept DenseVector = \n   // ... Definition of all requirements on a dense vector (as before) \n   && std::is_base_of_v<DenseVectorTag,T>; \n \ntemplate< typename T > \nclass DynamicVector : private DenseVectorTag  \n \n{ \n   // ... \n}; \nBy inheriting (preferably nonpublicly) from the DenseVectorTag class (\n ),\nclasses like DynamicVector can identify as being part of a certain set of\ntypes (\n ). Function and operator templates can therefore be ef fectively\nlimited to accept only those types that explicitly opt in to the set of types.\nUnfortunately , there’ s a catch: this approach is no longer nonintrusive. T o\novercome this limitation, we introduce a compile-time indirection by a\ncustomizable type trait class. In other words, we apply the SRP and separate\nconcerns:\n \nstruct DenseVectorTag {}; \n \ntemplate< typename T > \nstruct IsDenseVector  \n \n   : public std::is_base_of<DenseVectorTag,T> \n{}; \n \ntemplate< typename T > \nconstexpr bool IsDenseVector_v = IsDenseVector<T>::value;  \n \n \ntemplate< typename T > \nconcept DenseVector = \n   // ... Definition of all requirements on a dense vector (as before) \n   && IsDenseVector_v<T>;  \n \n \ntemplate< typename T > \nclass DynamicVector : private DenseVectorTag  \n \n{ \n   // ... \n}; \n \ntemplate< typename T, size_t Size > \nclass StaticVector \n{ \n   // ... \n}; \n \ntemplate< typename T, size_t Size > \nstruct IsDenseVector< StaticVector<T,Size> >  \n \n   : public std::true_type \n{}; \nThe IsDenseVector class template, along with its corresponding variable\ntemplate, indicates whether a given type is part of the set of dense vector\ntypes (\n  and \n ). Instead of directly querying a given type, the DenseVector\nconcept would ask indirectly via the IsDenseVector type trait (\n ). This\nopens up the opportunity for classes to either intrusively derive from the\nDenseVectorTag (\n) or to nonintrusively specialize the IsDenseVector\ntype trait (\n ). In this form, the concepts approach truly supersedes the\nclassic CR TP approach.\nIn summary , CRTP is an amazing design pattern for defining a compile-\ntime relationship between a family of related types. Most interestingly , it\nresolves all performance issues that you may have with inheritance\nhierarchies. However , CRTP comes with a couple of potentially limiting",4798
83-Guideline 27 Use CRTP for Static Mixin Classes.pdf,83-Guideline 27 Use CRTP for Static Mixin Classes,,0
84-A Strong Type Motivation.pdf,84-A Strong Type Motivation,"drawbacks, such as the lack of a common base class, the quick spreading of\ntemplate code, and the restriction to compile-time polymorphism. W ith\nC++20, consider replacing CR TP with concepts, which provide an easier\nand nonintrusive alternative. However , if you do not have access to C++20\nconcepts and if CR TP fits, it will prove immensely valuable to you.\nGUIDELINE 26: USE CRTP TO INTRODUCE STATIC\nTYPE CATEGORIES\nApply the CR TP design pattern to define a compile-time\nabstraction for a family of related types.\nBe aware of the limited access from the CR TP base class to the\nderived class.\nKeep in mind the restrictions of the CR TP design pattern, in\nparticular , the lack of a common base class.\nPrefer C++20 concepts to the CR TP design pattern when possible.\nGuideline 27: Use CRTP for Static Mixin\nClasses\nIn “Guideline 26: Use CR TP to Introduce Static T ype Categories” , I\nintroduced you to the CR TP design pattern. I may also have given you the\nimpression that CR TP is old hat, made obsolete by the advent of C++20\nconcepts. W ell, interestingly it is not. At least not entirely . That’ s because I\nhaven’ t told you the complete story yet. CR TP may still be of value: just not\nas a design pattern but as an implementation pattern . So let’ s take a detour\ninto the realm of implementation patterns and let me explain.\nA Strong T ype Motivation\nConsider  the following StrongType class template, which represents a\nwrapper around any other type for the purpose of creating a unique, named\ntype:\n//---- <StrongType.h> ---------------- \n \n#include <utility> \n \ntemplate< typename T, typename Tag > \nstruct StrongType \n{ \n public: \n   using value_type = T; \n \n   explicit StrongType( T const& value ) : value_( value ) {} \n \n   T&       get()       { return value_; } \n   T const& get() const { return value_; } \n \n private: \n   T value_; \n};\nThis class can, for instance, be used to define the types Meter, Kilometer,\nand Surname:\n//---- <Distances.h> ---------------- \n \n#include <StrongType.h> \n \ntemplate< typename T > \nusing Meter = StrongType<T,struct MeterTag>; \n \ntemplate< typename T > \nusing Kilometer = StrongType<T,struct KilometerTag>; \n \n// ... \n \n \n//---- <Person.h> ---------------- \n \n#include <StrongType.h> \n \nusing Surname = StrongType<std::string,struct SurnameTag>; 20\n21\n \n// ...\nThe use of alias templates for Meter and Kilometer enables you to choose,\nfor instance, long or double to represent a distance. However , although\nthese types are built on fundamental types or Standard Library types, such\nas std::string in the case of Surname, they represent distinct types\n(strong types) with semantic meaning that cannot be (accidentally)\ncombined in arithmetic operations, for example, addition :\n \n//---- <Main.cpp> ---------------- \n \n#include <Distances.h> \n#include <cstdlib> \n \nint main() \n{ \n   auto const m1 = Meter<long>{ 120L }; \n   auto const m2 = Meter<long>{  50L }; \n   auto const km = Kilometer<long>{ 30L }; \n   auto const surname1 = Surname{ ""Stroustrup"" }; \n   auto const surname2 = Surname{ ""Iglberger"" }; \n   // ... \n \n   m1 + km;              // Correctly does not compile!  \n \n   surname1 + surname2;  // Also correctly does not compile!  \n \n   m1 + m2;              // Inconveniently this does not compile either.  \n \n \n   return EXIT_SUCCESS; \n} \nAlthough both Meter and Kilometer are represented via long, it isn’ t\npossible to directly add Meter and Kilometer together (\n ). This is great: it\ndoesn’ t leave any opening for accidental bugs to crawl in. It’ s also not\npossible to add two Surnames, although std::string provides an addition\noperator for string concatenation (\n ). But this is also great: the strong type\neffectively restricts undesired operations of the underlying type.\nUnfortunately , this “feature” also prevents the addition of two Meter\ninstances (\n ). This operation would be desirable, though: it is intuitive,\nnatural, and since the result of the operation would again be of type Meter,",4084
85-Using CRTP as an Implementation Pattern.pdf,85-Using CRTP as an Implementation Pattern,"physically accurate. T o make this work, we could implement an addition\noperator for the Meter type. However , obviously , this would not remain the\nonly addition operator . We would also need one for all the other strong\ntypes, such as Kilometer, Mile, Foot, etc. Since all of these\nimplementations would look the same, this would be a violation of the DR Y\nprinciple. Therefore, it appears to be reasonable to extend the StrongType\nclass template with an addition operator:\ntemplate< typename T, typename Tag > \nStrongType<T,Tag> \n   operator+( StrongType<T,Tag> const& a, StrongType<T,Tag> const& b ) \n{ \n   return StrongType<T,Tag>( a.get() + b.get() ); \n}\nWhereas due to the formulation of this addition operator it is not possible to\nadd two dif ferent instantiations of StrongType together (e.g., Meter and\nKilometer), it would enable the addition of two instances of the same\ninstantiation of StrongType. “Oh, but I see a problem: while it would now\nbe possible to add two Meters or two Kilometers, it would also be possible\nto add two Surnames. We don’ t want that!” You are correct: this would be\nundesirable. What we need instead is a deliberate addition of operations to\nspecific instantiations of StrongType. This is where CR TP comes into play .\nUsing CRTP as an Implementation Pattern\nInstead  of directly equipping the StrongType class template with\noperations, we provide the operations via mixin  classes: base classes that\n“inject” the desired operations. These mixin classes are implemented in\nterms of the CR TP. Consider , for instance, the Addable class template,\nwhich represents the addition operation:\n \n//---- <Addable.h> ---------------- \n \ntemplate< typename Derived > \nstruct Addable \n{ \n   friend Derived& operator+=( Derived& lhs, Derived const& rhs ) {  \n \n      lhs.get() += rhs.get(); \n      return lhs; \n   } \n \n   friend Derived operator+( Derived const& lhs, Derived const& rhs ) {  \n \n      return Derived{ lhs.get() + rhs.get() }; \n   } \n}; \nThe name of the template parameters gives it away: Addable is a CR TP\nbase class. Addable provides only two functions, implemented as hidden\nfriends : an addition assignment operator (\n ) and an addition operator (\n ).\nBoth operators are defined for the specified Derived type and are injected\ninto the surrounding namespace.  Thus, any class deriving from this CR TP\nbase class will “inherit” two free addition operators:\n//---- <StrongType.h> ---------------- \n \n#include <stdlib> \n#include <utility> \n \ntemplate< typename T, typename Tag > \nstruct StrongType : private Addable< StrongType<T,Tag> > \n{ /* ... */ }; \n \n \n//---- <Distances.h> ---------------- \n \n#include <StrongType.h> \n \ntemplate< typename T > \nusing Meter = StrongType<T,struct MeterTag>; \n \n// ... \n \n \n//---- <Main.cpp> ---------------- \n \n#include <Distances.h> \n#include <cstdlib> \n \nint main() \n{ 22\n   auto const m1 = Meter<long>{ 100 }; \n   auto const m2 = Meter<long>{  50 }; \n \n   auto const m3 = m1 + m2;  // Compiles and results in 150 meters \n   // ... \n \n   return EXIT_SUCCESS; \n}\n“I understand the purpose of the mixin class, but in this form, all\ninstantiations of StrongType would inherit an addition operator , even the\nones where an addition is not required, right?” Y es, indeed. Therefore, we\naren’ t finished yet. What we want to do is to selectively add the mixin class\nto those StrongType instantiations that need the operation. Our solution of\nchoice is to provide the mixins in the form of optional template ar guments.\nFor that purpose, we extend the StrongType class template by a pack of\nvariadic template template parameters:\n \n//---- <StrongType.h> ---------------- \n \n#include <utility> \n \ntemplate< typename T, typename Tag, template<typename> class... Skills > \nstruct StrongType \n   : private Skills< StrongType<T,Tag,Skills...> >...  \n \n{ /* ... */ }; \nThis extension enables us to individually specify , for each single strong\ntype, which skills are desired. Consider , for instance, the two additional\nskills Printable and Swappable:\n//---- <Printable.h> ---------------- \n \ntemplate< typename Derived > \nstruct Printable \n{ \n   friend std::ostream& operator<<( std::ostream& os, const Derived& d ) \n   { \n      os << d.get(); \n      return os; \n   } 23\n}; \n \n \n//---- <Swappable.h> ---------------- \n \ntemplate< typename Derived > \nstruct Swappable \n{ \n   friend void swap( Derived& lhs, Derived& rhs ) \n   { \n      using std::swap;  // Enable ADL \n      swap( lhs.get(), rhs.get() ); \n   } \n};\nTogether with the Addable skill, we can now assemble strong types\nequipped with the required and desired skills:\n \n//---- <Distances.h> ---------------- \n \n#include <StrongType.h> \n \ntemplate< typename T > \nusing Meter = \n   StrongType<T,struct MeterTag,Addable,Printable,Swappable>;  \n \n \ntemplate< typename T > \nusing Kilometer = \n   StrongType<T,struct KilometerTag,Addable,Printable,Swappable>;  \n \n \n// ... \n \n \n//---- <Person.h> ---------------- \n \n#include <StrongType.h> \n#include <string> \n \nusing Surname = \n   StrongType<std::string,struct SurnameTag,Printable,Swappable>;  \n \n \n// ... \nBoth Meter and Kilometer can be added, printed, and swapped (see \n  and \n), while Surname is printable and swappable, but not addable (i.e., does\nnot receive the Addable mixin and therefore does not derive from it) (\n ).\n“That’ s great. I understand the purpose of the CR TP mixin class in this\ncontext. But how is this CR TP example dif ferent from previous examples?”\nVery good question. Y ou’re right, the implementation details are very\nsimilar . But there are a couple of distinctive dif ferences. Note that the CR TP\nbase class doesn’ t provide a virtual or protected destructor . Hence, in\ncontrast to previous examples, it is not designed as a polymorphic base\nclass. Also note that in this example it is suf ficient, and even preferable, to\nuse the CR TP base class as a private base class, not a public one (\n ).\nThus, in this context, the CR TP base class does not represent an abstraction\nbut only an implementation detail. Therefore, the CR TP does not fulfill the\nproperties of a design pattern, and it does not act as a design pattern. It’ s\nstill a pattern, no question there, but it merely acts as an implementation\npattern in this case.\nThe major dif ference in the implementation of the CR TP examples is the\nway we use inheritance. For the CR TP design pattern, we use inheritance as\nan abstraction according to the LSP: the base class represents the\nrequirements, and thus the available and expected behavior of the derived\nclass. User code directly accesses the operations via pointers or references\nto the base class, which in turn requires us to provide a virtual or\nprotected destructor . When implemented this way , CRTP becomes a true\nelement of software design—a design pattern.\nIn contrast, for the CR TP implementation pattern, we use inheritance for\ntechnical elegance and convenience. The base class becomes an\nimplementation detail and does not have to be known or used by calling\ncode. Therefore, it doesn’ t need a virtual or protected destructor . When\nimplemented this way , CRTP stays on the level of the implementation\ndetails and therefore is an implementation pattern. In this form, however ,\nCRTP does not compete with C++20 concepts. On the contrary: in this form\nCRTP is unchallenged, as it represents a unique technique to provide static\nmixin functionality . For that reason, CR TP is still in use today and\nrepresents a valuable addition to every C++ developer ’s toolbox.\nIn summary , CRTP is not obsolete, but its value has changed. In C++20,\nCRTP is replaced by concepts and therefore is stepping down as a design\npattern. However , it continues to be valuable as an implementation pattern\nfor mixin classes.\nGUIDELINE 27: USE CRTP FOR STATIC MIXIN\nCLASSES\nBe aware between the dif ference between using CR TP as a design\npattern and using it as an implementation pattern.\nUnderstand that CR TP base classes that represent an abstraction\nact as a design pattern.\nUnderstand that CR TP base classes that do not represent an\nabstraction act as an implementation pattern.\n1 The Pages format is Apple’ s equivalent to Microsoft’ s Word format.\n2 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n3 If you’re an expert on design patterns, you might realize that a 1-to- N Adapter has a certain\nsimilarity to the Facade design pattern. See the GoF book for more details.\n4 In C++20, you achieve a similar ef fect by applying the [[no_unique_address]] attribute to\na data member . If the data member is empty , it might not occupy any storage on its own.\n5 In this context, it’ s particularly interesting to note that std::stack doesn’ t allow you to\ntraverse the elements via iterators. As usual for a stack, you’re allowed to access only the\ntopmost element.\n6 Matthew W ilson, Imperfect C++: Practical Solutions for Real-Life Pr ogramming  (Addison-\nWesley , 2004).\n7 Eric Freeman and Elisabeth Robson, Head First Design Patterns: Building Extensible and\nMaintainable Object-Oriented Softwar e (O’Reilly , 2021).\n8 Of course, you know better than to try this at home, but let’ s assume this is one of those\nstrange, Monday-morning management decisions.\n9 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n10 Despite the fact that I don’ t venture into the thicket of Observer implementation details, I can\nstill give you a few references on how to implement Observers. A good overview on many of\nthe implementation aspects is V ictor Ciura’ s CppCon 2021 talk “Spooky Action at a Distance” .\nA very detailed discussion on how to deal with the concurrency issues of the Observer pattern\ncan be found in T ony V an Eerd’ s C++Now 2016 talk “Thread-Safe Observer Pattern—Y ou’re\nDoing It W rong” .\n1 1 If you’re aware of the Non-V irtual Interface (NVI)  idiom or the T emplate Method design\npattern, then please feel free to move this virtual function into the private section of the class\nand provide a public, nonvirtual wrapper function for it. Y ou can find more information about\nNVI in Herb Sutter ’s Guru of the W eek blog  or in the article “Virtuality”  from the C++ Users\nJournal , 19(9), September 2001.\n12 Alternatively , the observer could also remember the subject on its own.\n13 You can also choose to build on gsl::not_null<T> from the Guideline Support Library\n(GSL) .\n14 If you’re wondering what those others stand for: RAII: Resource Acquisition Is Initialization\n(which is ar gued to be the most valuable idea of C++, but at the same time is of ficially the\nworst acronym; it literally does not make any sense); ADL: Ar gument Dependent Lookup;\nCTAD: Class T emplate Ar gument Deduction; SFINAE: Substitution Failure Is Not An Error;\nNTTP: Non-T ype T emplate Parameter; IFNDR: Ill-Formed, No Diagnostic Required; SIOF:\nStatic Initialization Order Fiasco. For an overview of (almost) all C++ acronyms, see Arthur\nO’Dwyer ’s blog .\n15 Ah, the C++ Report —such glorious times! However , you may be one of the poor souls who\nnever had an opportunity to read an original C++ Report . If so, you should know that it was a\nbimonthly computer magazine published by the SIGS Publications Group between 1989 and\n2002. The original C++ Report  is hard to come by these days, but many of its articles have\nbeen collected in the book edited by Stanley Lippmann C++ Gems: Pr ogramming Pearls fr om\nthe C++ Report  (Cambridge University Press). This book includes James Coplien’ s article\n“Curiously Recurring T emplate Patterns.”\n16 If you can’ t use C++20 concepts yet, std::enable_if provides an alternative formulation.\nRefer to Core Guideline T .48: “If your compiler does not support concepts, fake them with\nenable_if.” See also your preferred C++ templates reference.\n17 Consider any kind of cast ( static_cast, reinterpret_cast, const_cast, dynamic_cast,\nand especially the old C-style casts) as adult features: you take full responsibility of your\nactions and the compiler will obey . Therefore, it is seriously advisable to reduce calls to cast\noperators (see also Core Guideline ES.48 : “Avoid casts”).\n18 This is a great example to demonstrate that it pays of f to be able to compile your codebase\nwith several major compilers (Clang, GCC, MSVC, etc.). Dif ferent error messages might help\nyou find the source of the problem. Using only one compiler should be considered a risk!\n19 If you aren’ t familiar with the idea or syntax of C++20 concepts yet, you can get a quick and\npainless introduction in Sándor Dar gó’s C++ Concepts , published at Leanpub .\n20 This implementation of a StrongType is inspired by Jonathan Boccara’ s Fluent C++ blog  and\nthe associated NamedT ype library . There are several more strong type libraries available,\nthough: alternatively you can use Jonathan Müller ’s type_safe  library , Björn Fahller ’s\nstrong_type  library , or Anthony W illiam’ s strong_typedef  library .\n21 The only technical oddity is the declaration of a tag class right in the template parameter list.\nYes, this works, and definitely helps create a unique type for the purpose of instantiating\ndistinct strong types.\n22 Many years ago, more specifically at the end of the ’90s, this kind of namespace injection was\ncalled the Barton-Nackman trick , named after John J. Barton and Lee R. Nackman. In the\nMarch 1995 issue of the C++ Report , they used namespace injection as a workaround for the\nlimitation that function templates could not be overloaded at the time. Surprisingly , today this\ntechnique has experienced a renaissance as the hidden friend idiom .\n23 In Jonathan Bocarra’ s blog , these optional, variadic ar guments are aptly called skills . I very\nmuch like this, so I adopt this naming convention.",14015
86-Guideline 28 Build Bridges to Remove Physical Dependencies.pdf,86-Guideline 28 Build Bridges to Remove Physical Dependencies,"Chapter 7. The Bridge,\nPrototype, and External\nPolymorphism Design Patterns\nIn this chapter , we will focus on two classic GoF design patterns: the Bridge\ndesign pattern and the Prototype design pattern. Additionally , we will study\nthe External Polymorphism  design pattern. At first glance, this selection\nmay appear as an illustrious, almost random choice of design patterns.\nHowever , I picked these patterns for two reasons: first, in my experience,\nthese three are among the most useful in the catalog of design patterns. For\nthat reason, you should have a pretty good idea about their intent,\nadvantages, and disadvantages. Second and equally important: they will all\nplay a vital role in Chapter 8 .\nIn “Guideline 28: Build Bridges to Remove Physical Dependencies ”, I will\nacquaint you with the Bridge design pattern and its simplest form, the Pimpl\nidiom . Most importantly , I will demonstrate how you can use Bridges to\nreduce physical coupling by decoupling an interface from implementation\ndetails.\nIn “Guideline 29: Be A ware of Bridge Performance Gains and Losses ”, we\nwill take an explicit look at the performance impact of Bridges. W e will run\nbenchmarks for an implementation without Bridge, a Bridge-based\nimplementation, and a “partial” Bridge.\nIn “Guideline 30: Apply Prototype for Abstract Copy Operations” , I will\nintroduce you to the art of cloning. That is to say , that we will talk about\ncopy operations and, in particular , abstract copy operations. The pattern of\nchoice for this intent will be the Prototype design pattern.\nIn “Guideline 31: Use External Polymorphism for Nonintrusive Runtime\nPolymorphism” , we continue the journey of separating concerns by",1718
87-A Motivating Example.pdf,87-A Motivating Example,"extracting the implementation details of a function from a class. T o further\nreduce dependencies, however , we will take this separation of concerns to a\nwhole new level: we will extract not only the implementation details of\nvirtual functions but also the complete functions themselves, with the\nExternal Polymorphism design pattern.\nGuideline 28: Build Bridges to Remove\nPhysical Dependencies\nAccording  to dictionaries, the term bridge  expresses a time, a place, or a\nmeans of connection or transition. If I were to ask what the term bridge\nmeans to you, I’m pretty certain you would have a similar definition. Y ou\nmight implicitly think about connecting two things, and thus bringing these\nthings closer together . For instance, you might think about a city divided by\na river . A bridge would connect the two sides of the city , bring them closer\ntogether , and save people a lot of time. Y ou might also think about\nelectronics, where a bridge connects two independent parts of a circuit.\nThere are bridges in music and many more examples from the real world,\nwhere bridges help connect things. Y es, intuitively the term bridge  suggests\nan increase in closeness and proximity . So naturally , the Bridge design\npattern is about the polar opposite: it  supports you in reducing physical\ndependencies and helps to decouple, i.e., it keeps two pieces of\nfunctionality that need to work together but shouldn’ t know too many\ndetails about each other , at arm’ s length.\nA Motivating Example\nTo explain what I have in mind, consider the following ElectricCar class:\n \n//---- <ElectricEngine.h> ---------------- \n \nclass ElectricEngine \n{ \n public: \n   void start(); \n   void stop(); \n \n private: \n   // ... \n}; \n \n \n//---- <ElectricCar.h> ---------------- \n \n#include <ElectricEngine.h> \n// ... \n \nclass ElectricCar \n{ \n public: \n   ElectricCar( /*maybe some engine arguments*/ ); \n \n   void drive(); \n   // ... \n private: \n   ElectricEngine engine_;  \n \n \n   // ... more car-specific data members (wheels, drivetrain, ...) \n}; \n \n \n//---- <ElectricCar.cpp> ---------------- \n \n#include <ElectricCar.h> \n \nElectricCar::ElectricCar( /*maybe some engine arguments*/ ) \n   : engine_{ /*engine arguments*/ } \n   // ... Initialization of the other data members \n{} \n \n// ... \nAs the name suggests, the ElectricCar class is equipped with an\nElectricEngine (\n). However , while in reality such a car may be pretty\nattractive, the current implementation details are concerning: because of the\nengine_ data member , the <ElectricCar.h> header file needs to include\nthe <ElectricEngine.h> header . The compiler needs to see the class\ndefinition of ElectricEngine, because otherwise it would not be able to\ndetermine the size of an ElectricCar instance. Including the\n<ElectricEngine.h> header , however , easily results in transitive, physical\ncoupling: every file that includes the <ElectricCar.h> header will\nphysically depend on the <ElectricEngine.h> header . Thus, whenever\nsomething in the header changes, the ElectricCar class and potentially\nmany more classes are af fected. They might have to be recompiled,\nretested, and, in the worst case, even redeployed… sigh.\nOn top of that, this design reveals all implementation details to everyone.\n“What do you mean? Isn’ t it the point of the private section of the class to\nhide and to encapsulate implementation details?” Y es, it may be private,\nbut the private label is merely an access label. It is not a visibility label.\nTherefore, everything in your class definition (and I mean everything ) is\nvisible to everyone who sees the ElectricCar class definition. This means\nthat you cannot change the implementation details of this class without\nanyone noticing. In particular , this may be a problem if you need to provide\nABI stability , i.e., if the in-memory representation of your class must not\nchange.\nA slightly better approach would be to only store a pointer to\nElectricEngine (\n):\n \n//---- <ElectricCar.h> ---------------- \n \n#include <memory> \n// ... \nstruct ElectricEngine;  // Forward declaration \n \nclass ElectricCar \n{ \n public: \n   ElectricCar( /*maybe some engine arguments*/ ); \n \n   void drive(); \n   // ... \n private: \n   std::unique_ptr<ElectricEngine> engine_;  \n \n \n   // ... more car-specific data members (wheels, drivetrain, ...) \n}; \n 1\n2\n \n//---- <ElectricCar.cpp> ---------------- \n \n#include <ElectricCar.h> \n#include <ElectricEngine.h>  \n \n \nElectricCar::ElectricCar( /*maybe some engine arguments*/ ) \n   : engine_{ std::make_unique<ElectricEngine>( /*engine arguments*/ ) } \n   // ... Initialization of the other data members \n{} \n \n// ... Other 'ElectricCar' member functions, using the pointer to an \n//     'ElectricEngine'. \nIn this case, it is suf ficient to provide only a forward declaration to the\nElectricEngine class, since the compiler doesn’ t need to know the class\ndefinition to be able to determine the size of an ElectricCar instance.\nAlso, the physical dependency is gone, since the <ElectricEngine.h>\nheader has been moved into the source file (\n ). Hence, from a dependency\npoint of view , this solution is much better . What still remains is the\nvisibility of the implementation details. Everyone is still able to see that the\nElectricCar builds on an ElectricEngine, and thus everyone is still\nimplicitly depending on these implementation details. Consequently , any\nchange to these details, such as an upgrade to the new PowerEngine, would\naffect any class that works with the <ElectricCar.h> header file. “And\nthat’s bad, right?” Indeed it is, because change is to be expected (see\n“Guideline 2: Design for Change” ). To get rid of this dependency and gain\nthe luxury of being able to easily change the implementation details at any\ntime without anyone noticing, we have to introduce an abstraction. The\nclassic form of abstraction is the introduction of an abstract class:\n \n//---- <Engine.h> ---------------- \n \nclass Engine  \n \n{ \n public: \n   virtual ~Engine() = default; \n   virtual void start() = 0; \n   virtual void stop() = 0; \n   // ... more engine-specific functions \n \n private: \n   // ... \n}; \n \n \n//---- <ElectricCar.h> ---------------- \n \n#include <Engine.h> \n#include <memory> \n \nclass ElectricCar \n{ \n public: \n   void drive(); \n   // ... \n private: \n   std::unique_ptr<Engine> engine_;  \n \n \n   // ... more car-specific data members (wheels, drivetrain, ...) \n}; \n \n \n//---- <ElectricEngine.h> ---------------- \n \n#include <Engine.h> \n \nclass ElectricEngine : public Engine \n{ \n public: \n   void start() override; \n   void stop() override; \n \n private: \n   // ... \n}; \n \n \n//---- <ElectricCar.cpp> ---------------- \n \n#include <ElectricCar.h> \n#include <ElectricEngine.h> \n \nElectricCar::ElectricCar( /*maybe some engine arguments*/ ) \n   : engine_{ std::make_unique<ElectricEngine>( /*engine arguments*/ ) }  \n \n   // ... Initialization of the other data members \n{}",7100
88-The Bridge Design Pattern Explained.pdf,88-The Bridge Design Pattern Explained,"// ... Other 'ElectricCar' member functions, primarily using the 'Engine' \n//     abstraction, but potentially also explicitly dealing with an \n//     'ElectricEngine'. \nWith the Engine base class in place (\n ), we can implement our\nElectricCar class using this abstraction (\n ). No one needs to be aware of\nthe actual type of engine that we use. And no one needs to know when we\nupgrade our engine. W ith this implementation, we can easily change the\nimplementation details at any time by only modifying the source file (\n ).\nTherefore, with this approach, we’ve truly minimized dependencies on the\nElectricEngine implementation. W e have made the knowledge about this\ndetail our own, secret implementation detail. And by doing that, we have\nbuilt ourselves a Bridge.\nNOTE\nAs stated in the introduction, counterintuitively , this Bridge isn’ t about bringing the\nElectricCar and Engine classes closer together . On the contrary , it’s about separating\nconcerns and about loose coupling. Another example that shows that naming is hard\ncomes from Kate Gregory’ s talk at CppCon.\nThe Bridge Design Pattern Explained\nThe Bridge design pattern is yet another one of the classic GoF design\npatterns introduced in 1994. The  purpose of a Bridge is to minimize\nphysical dependencies by encapsulating some implementation details\nbehind an abstraction. In C++, it acts as a compilation firewall, which\nenables easy change:\nTHE BRIDGE DESIGN PATTERN\nIntent: “Decouple  an abstraction from its implementation so that the two can vary\nindependently .”3\nIn this formulation of the intent, the Gang of Four talks about an\n“abstraction” and an “implementation.” In our example, the ElectricCar\nclass represents the “abstraction,” while the Engine class represents the\n“implementation”  (see Figure 7-1 ). Both of these should be able to vary\nindependently; i.e., changes to either one should have no ef fect on the other .\nThe impediments to easy change are the physical dependencies between the\nElectricCar class and its engines. Thus, the idea is to extract and isolate\nthese dependencies. By isolating them in the form of the Engine\nabstraction, separating concerns, and fulfilling the SRP , you gain the\nflexibility to change, tune, or upgrade the engine any way you want (see\n“Guideline 2: Design for Change” ). The change is no longer visible in the\nElectricCar class. As a consequence, it is now easily possible to add new\nkinds of engines without the “abstraction” noticing. This adheres to the idea\nof the OCP (see “Guideline 5: Design for Extension” ).\nFigur e 7-1. The UML r epresentation of the basic Bridge design pattern\nWhile this provides us the ability to easily apply changes, and implements\nthe idea of a Bridge, there is one more step that we can take to further\ndecouple and reduce duplication. Let’ s assume that we are not just\ninterested in electric cars but also in cars with combustion engines. So for\nevery kind of car that we plan to implement, we are interested in\nintroducing the same kind of decoupling from engine details, i.e., the same\nkind of Bridge. T o reduce the duplication and follow the DR Y principle, we\ncan extract the Bridge-related implementation details into the Car base class\n(see Figure 7-2 ).\nFigur e 7-2. The UML r epresentation of the full Bridge design pattern\nThe Car base class encapsulates the Bridge to the associated Engine:\n \n//---- <Car.h> ---------------- \n \n#include <Engine.h> \n#include <memory> \n#include <utility> \n \nclass Car \n{ \n protected: \n   explicit Car( std::unique_ptr<Engine> engine )  \n \n      : pimpl_( std::move(engine) ) \n   {} \n \n public: \n   virtual ~Car() = default; \n   virtual void drive() = 0; \n   // ... more car-specific functions \n \n protected: \n   Engine*       getEngine()       { return pimpl_.get(); }  \n \n   Engine const* getEngine() const { return pimpl_.get(); } \n \n private: \n   std::unique_ptr<Engine> pimpl_;  // Pointer-to-implementation (pimpl)  \n \n \n   // ... more car-specific data members (wheels, drivetrain, ...) \n}; \nWith the addition of the Car class, both the “abstraction” and the\n“implementation” of fer the opportunity for easy extension and can vary\nindependently . While the Engine base class still represents the\n“implementation” in this Bridge relation, the Car class now plays the role of\nthe “abstraction.” The first noteworthy detail about the Car class is the\nprotected constructor (\n ). This choice makes sure that only derived\nclasses are able to specify the kind of engine. The constructor takes\nstd::unique_ptr to an Engine and moves it to its pimpl_ data member (\n). This pointer data member is the one pointer -to-implementation for all\nkinds of Cars and is commonly called the pimpl . This  opaque pointer\nrepresents the Bridge to the encapsulated implementation details and\nessentially represents the Bridge design pattern as a whole. For this reason,\nit’s a good idea to use the name pimpl  in the code as an indication of your\nintentions (remember “Guideline 14: Use a Design Pattern’ s Name to\nCommunicate Intent” ).\nNote that pimpl_ is declared in the private section of the class, despite the\nfact that derived classes will have to use it. This choice is motivated by\nCore Guideline C.133 :\nAvoid protected data.\nIndeed, experience shows that protected data members are barely better\nthan public data members. Therefore, to grant access to the pimpl, the Car\nclass instead provides the protected getEngine() member functions (\n ).\nThe ElectricCar class is adapted accordingly:\n \n//---- <ElectricCar.h> ---------------- \n \n#include <Engine.h> \n#include <memory> \n \nclass ElectricCar : public Car  \n \n{ \n public: \n   explicit ElectricCar( /*maybe some engine arguments*/ ); \n \n   void drive() override; \n   // ... \n}; \n \n \n//---- <ElectricCar.cpp> ---------------- \n \n#include <ElectricCar.h> \n#include <ElectricEngine.h> \n \nElectricCar::ElectricCar( /*maybe some engine arguments*/ ) \n   : Car( std::make_unique<ElectricEngine>( /*engine arguments*/ ) )  \n \n{} \n \n// ... \nRather than implementing the Bridge itself, the ElectricCar class now\ninherits from the Car base class (\n ). This inheritance relationship introduces\nthe requirement of initializing the Car base by specifying an Engine. This\ntask is performed in the ElectricCar constructor (\n ).",6411
89-The Pimpl Idiom.pdf,89-The Pimpl Idiom,"The Pimpl Idiom\nThere  is a much simpler form of the Bridge design pattern that has been\nvery commonly and successfully used in both C and C++ for decades. T o\nsee an example, let’ s consider the following Person class:\nclass Person \n{ \n public: \n   // ... \n   int year_of_birth() const; \n   // ... Many more access functions \n \n private: \n   std::string forename_; \n   std::string surname_; \n   std::string address_; \n   std::string city_; \n   std::string country_; \n   std::string zip_; \n   int year_of_birth_; \n   // ... Potentially many more data members \n};\nA person consists of a lot of data members: forename, surname, the\ncomplete postal address, year_of_birth, and potentially many more.\nThere may be the need to add further data members in the future: a mobile\nphone number , a Twitter account, or the account information for the next\nsocial media fad. In other words, it stands to reason that the Person class\nneeds to be extended or changed over time, potentially even frequently .\nThis may come with a whole lot of inconveniences for users of this class:\nwhenever Person changes, the users of Person have to recompile their\ncode. Not to mention ABI stability: the size of a Person instance is going to\nchange!\nTo hide all changes to the implementation details of Person and gain ABI\nstability , you can use the Bridge design pattern. In this particular case,\nhowever , there is no need to provide an abstraction in the form of a base\nclass: there is one, and exactly one, implementation for Person. Therefore,\nall we do is introduce a private, nested class called Impl (\n):\n \n//---- <Person.h> ---------------- \n \n#include <memory> \n \nclass Person \n{ \n public: \n   // ... \n \n private: \n   struct Impl;  \n \n   std::unique_ptr<Impl> const pimpl_;  \n \n}; \n \n//---- <Person.cpp> ---------------- \n \n#include <Person.h> \n#include <string> \n \nstruct Person::Impl  \n \n{ \n   std::string forename; \n   std::string surname; \n   std::string address; \n   std::string city; \n   std::string country; \n   std::string zip; \n   int year_of_birth; \n   // ... Potentially many more data members \n}; \nThe sole task of the nested Impl class is to encapsulate the implementation\ndetails of Person. Thus, the only data member remaining in the Person\nclass is the std::unique_ptr to an Impl instance (\n ). All other data\nmembers, and potentially some non- virtual helper functions, are moved\nfrom the Person class into the Impl class. Note that the Impl class is only\ndeclared in the Person class but not defined. Instead, it is defined in the\ncorresponding source file (\n ). Only due to this, all details and all changes\nthat you apply to the details, such as adding or removing data members,\nchanging the type of data members, etc., are hidden from the users of\nPerson.\nThis implementation of Person uses the Bridge design pattern in its\nsimplest form: this local, nonpolymorphic form of Bridge is called the\nPimpl idiom . It comes with all the decoupling advantages of the Bridge\npattern but, despite its simplicity , it still results in a bit more complex\nimplementation of the Person class:\n \n//---- <Person.h> ---------------- \n \n//#include <memory> \n \nclass Person \n{ \n public: \n   // ... \n   Person();   \n \n   ~Person();  \n \n \n   Person( Person const& other );  \n \n   Person& operator=( Person const& other );  \n \n \n   Person( Person&& other );  \n \n   Person& operator=( Person&& other );  \n \n \n   int year_of_birth() const;  \n \n   // ... Many more access functions \n \n private: \n   struct Impl; \n   std::unique_ptr<Impl> const pimpl_; \n}; \n \n//---- <Person.cpp> ---------------- \n \n//#include <Person.h> \n//#include <string> \n \nstruct Person::Impl \n{ \n   // ... \n}; \n \nPerson::Person()  \n \n   : pimpl_{ std::make_unique<Impl>() } \n{} \n \nPerson::~Person() = default;  \n \n \nPerson::Person( Person const& other )  \n \n   : pimpl_{ std::make_unique<Impl>(*other.pimpl_) } \n{} \n \nPerson& Person::operator=( Person const& other )  \n \n{ \n   *pimpl_ = *other.pimpl_; \n   return *this; \n} \n \nPerson::Person( Person&& other )  \n \n   : pimpl_{ std::make_unique<Impl>(std::move(*other.pimpl_)) } \n{} \n \nPerson& Person::operator=( Person&& other )  \n \n{ \n   *pimpl_ = std::move(*other.pimpl_); \n   return *this; \n} \n \nint Person::year_of_birth() const  \n \n{ \n   return pimpl_->year_of_birth; \n} \n \n// ... Many more Person member functions \nThe Person constructor initializes the pimpl_ data member by\nstd::make_unique() (\n). This, of course, involves a dynamic memory\nallocation, which means that the dynamic memory needs to be cleaned up\nagain. “And that is why we use std::unique_ptr,” you say . Correct. But\nperhaps surprisingly , although we use std::unique_ptr for that purpose,\nit’s still necessary to manually deal with the destructor (\n ).\n“Why on earth do we have to do this? Isn’ t the point of std::unique_ptr\nthat we don’ t have to deal with cleanup?” W ell, we still have to. Let me\nexplain: if you don’ t write the destructor , the compiler feels obliged to\ngenerate the destructor for you. Unfortunately , it would generate the\ndestructor in the <Person.h> header file. The destructor of Person would\ntrigger the instantiation of the destructor of the std::unique_ptr data",5354
90-Comparison Between Bridge and Strategy.pdf,90-Comparison Between Bridge and Strategy,"member , which in turn would require the definition of the destructor of the\nImpl class. The definition of Impl, however , is not available in the header\nfile. On the contrary , it needs to be defined in the source file or it would\ndefeat the purpose of the Bridge. Thus, the compiler emits an error about\nthe incomplete type Impl. Fortunately , you do not have to let go of the\nstd::unique_ptr to resolve the issue (and in fact you should  not let go of\nit). The problem is rather simple to solve. All you have to do is move the\ndefinition of the Person destructor to the source file: you declare the\ndestructor in the class definition and define it via =default in the source\nfile.\nSince std::unique_ptr cannot be copied, you will have to implement the\ncopy constructor to preserve the copy semantics of the Person class (\n ).\nThe same is true for the copy assignment operator (\n ). Note that this\noperator is implemented under the assumption that every instance of\nPerson will always  have a valid pimpl_. This assumption explains the\nimplementation of the move constructor: instead of simply moving\nstd::unique_ptr, it performs a potentially failing, or throwing, dynamic\nmemory allocation with std::make_unique(). For that reason, it is not\ndeclared as noexcept (\n). This assumption also explains why the pimpl_\ndata member is declared as const. Once it’ s initialized, the pointer will not\nbe changed anymore, not even in the move operations, including the move\nassignment operator (\n ).\nThe last detail worth noting is that the definition of the year_of_birth()\nmember function is located in the source file (\n ). Despite the fact that this\nsimple getter function is a great inline candidate, the definition has to be\nmoved to the source file. The reason is that in the header file, Impl is an\nincomplete type . Which means that within the header file, you are not able\nto access any members (both data and functions). This is possible only in\nthe source file, or generally speaking, as soon as the compiler knows the\ndefinition of Impl.\nComparison Between Bridge and Strategy4\n“I have  a question,” you say . “I see a strong resemblance between the\nBridge and the Strategy design pattern. I know you said that design patterns\nare sometimes structurally very similar and that the only dif ference is their\nintent. But what exactly is the distinction between these two?”  I\nunderstand your question. The similarity between these two is truly a little\nconfusing. However , there is something you can use to tell them apart: how\nthe corresponding data member is initialized is a strong indicator about\nwhich one you’re using.\nIf a class does not want to know about some implementation detail, and if\nfor that reason it provides the opportunity to configure the behavior by\npassing in details from the outside (for instance, via a constructor or via a\nsetter function), then you are most likely dealing with the Strategy design\npattern. Because the flexible configuration of behavior , i.e., the reduction of\nlogical  dependencies, is its primary focus, Strategy falls into the category of\na behavioral design pattern . For instance, in the following code snippet, the\nconstructor of the Database class is a telltale sign:\n \nclass DatabaseEngine \n{ \n public: \n   virtual ~DatabaseEngine() = default; \n   // ... Many database-specific functions \n}; \n \nclass Database \n{ \n public: \n   explicit Database( std::unique_ptr<DatabaseEngine> engine ); \n   // ... Many database-specific functions \n \n private: \n   std::unique_ptr<DatabaseEngine> engine_; \n}; \n \n// The database is unaware of any implementation details and requests them \n//   via its constructor from outside -> Strategy design pattern \nDatabase::Database( std::unique_ptr<DatabaseEngine> engine )  \n \n   : engine_{ std::move(engine) } \n{} 5\nThe actual type of DatabaseEngine is passed in from the outside (\n ),\nmaking this a good example of the Strategy design pattern.\nFigure 7-3  shows the  dependency graph for this example. Most importantly ,\nthe Database class is on the same architectural level as the\nDatabaseEngine abstraction, thus providing others with the opportunity to\nimplement the behavior (e.g., in the form of the\nConcreteDatabaseEngine). Since Database is depending only on the\nabstraction, there is no dependency on any specific implementation.\nFigur e 7-3. Dependency graph for the Strategy design pattern\nIf, however , a class knows about the implementation details but primarily\nwants to reduce the physical  dependencies on these details, then you’re\nmost likely dealing with the Bridge design pattern. In that case, the class\ndoes not provide any opportunity to set the pointer from outside, i.e., the\npointer is an implementation detail and set internally . Since the Bridge\ndesign pattern primarily focuses on the physical dependencies of the\nimplementation details, not the logical dependencies, Bridge falls into the\ncategory of  structural design patterns . As an example, consider the\nfollowing code snippet:\n \nclass Database \n{ \n public: \n   explicit Database(); \n   // ... \n private: \n   std::unique_ptr<DatabaseEngine> pimpl_; \n}; \n \n// The database knows about the required implementation details, but does \n//   not want to depend too strongly on it -> Bridge design pattern \nDatabase::Database() \n   : pimpl_{ std::make_unique<ConcreteDatabaseEngine>( /*some arguments*/ ) }  \n \n{} \nAgain, there is a telltale sign for the application of the Bridge design\npattern: instead of accepting an engine from outside, the constructor of the\nDatabase class is aware of the ConcreteDatabaseEngine and sets it\ninternally (\n ).\nFigure 7-4  shows  the dependency graph for the Bridge implementation of\nthe Database example. Most notably , the Database class is on the same\narchitectural level as the ConcreteDatabaseEngine class and does not\nleave any opportunity for others to provide dif ferent implementations. This\nshows that in contrast to the Strategy design pattern, a Bridge is logically\ncoupled to a specific implementation but only physically decoupled via the\nDatabaseEngine abstraction.",6205
91-Analyzing the Shortcomings of the Bridge Design Pattern.pdf,91-Analyzing the Shortcomings of the Bridge Design Pattern,"Figur e 7-4. Dependency graph for the Bridge design pattern\nAnalyzing the Shortcomings of the Bridge Design\nPattern\n“I can  totally see why the Bridge design pattern is so popular in the\ncommunity . The decoupling properties are really great!” you exclaim.\n“However , you keep telling me that every design has its pros and cons. I\nexpect there is a performance penalty?” Good, you remember that there are\nalways some disadvantages. And of course this includes the Bridge design\npattern, although it proves to be very useful. And yes, you’re correct to\nassume that there is some performance overhead involved.\nThe first of five types of overhead results from the fact that Bridge\nintroduces an additional indirection: the pimpl pointer making all access to\nthe implementation details more expensive. However , how much of the\nperformance penalty this pointer causes is an issue that I will discuss\nseparately in “Guideline 29: Be A ware of Bridge Performance Gains and\nLosses ”. This is not the only source of performance overhead , though; there\nare more. Depending on whether you use an abstraction, you also might\nhave to pay for the virtual function call overhead. Additionally , you’ll have\nto pay more due to the lack of inlining of even the simplest function\naccessing data members. And, of course, you will have to pay for an\nadditional dynamic memory allocation whenever you create a new instance\nof a class implemented in terms of Bridge.  Last but not least, you should\nalso take into account the memory overhead caused by introducing the\npimpl pointer . So, yes, isolating the physical dependencies and hiding\nimplementation details is not free but results in a considerable overhead.\nStill, this shouldn’ t be a reason to generally discard the Bridge solution: it\nalways depends. For instance, if the underlying implementation performs\nslow, expensive tasks, such as system calls, then this overhead might not be\nmeasurable at all. In other words, whether or not to use a Bridge should be\ndecided on a case-by-case basis and backed up with performance\nbenchmarks.\nFurthermore, you have seen the implementation details and realized that the\ncode complexity has increased. Since simplicity and readability of code are\na virtue, this should be considered a downside. It’ s true that this af fects only\nthe internals of a class, not the user code. But still, some of the details (e.g.,6",2428
92-The Performance Impact of Bridges.pdf,92-The Performance Impact of Bridges,"the need to define the destructor in the source file) might be confusing for\nless-experienced developers.\nIn summary , the Bridge design pattern is one of the most valuable and most\ncommonly used solutions for reducing physical dependencies. Still, you\nshould be aware of the overhead and the complexity that a Bridge\nintroduces.\nGUIDELINE 28: BUILD BRIDGES TO REMOVE\nPHYSICAL DEPENDENCIES\nBe aware of physical dependencies introduced by data members or\nincludes.\nApply the Bridge design pattern with the intent to isolate physical\ndependencies from implementation details;\nPrefer using a pimpl data member to communicate the use of a\nBridge.\nUnderstand the strengths and the weaknesses of the Bridge design\npattern.\nKnow the dif ference between reducing physical dependencies\n(Bridge) and reducing logical dependencies (Strategy).\nGuideline 29: Be Aware of Bridge\nPerformance Gains and Losses\nIn “Guideline 28: Build Bridges to Remove Physical Dependencies ”, we\ntook a detailed look at the Bridge design pattern. While I imagine the\ndesign and decoupling aspect of Bridge left a positive impression on you, I\nmust make you aware that using this pattern may introduce a performance\npenalty . “Yes, and that worries me. Performance is important to me, and it\nsounds like a Bridge will create a massive performance overhead,” you say .\nAnd this is a pretty common expectation. Since performance matters, I\nreally should give you an idea of how much overhead you have to expect\nwhen using a Bridge. However , I should also demonstrate how to use\nBridges wisely to improve the performance of your code. Sounds\nunbelievable? W ell, let me show you how .\nThe Performance Impact of Bridges\nAs discussed in “Guideline 28: Build Bridges to Remove Physical\nDependencies ”, the performance of a Bridge implementation is influenced\nby many factors: access through an indirection, virtual function calls,\ninlining, dynamic memory allocations, etc. Because of these factors and the\nhuge amount of possible combinations, there is no definitive answer to how\nmuch performance a Bridge will cost you. There simply is no shortcut, no\nsubstitute for assembling a couple of benchmarks for your own code and\nrunning them to evaluate a definitive answer . What I want to demonstrate,\nthough, is that there is indeed a performance penalty of accessing through\nan indirection, but you can still use a Bridge to actually improve\nperformance.\nLet’s get started with giving you an idea about the benchmark. T o form an\nopinion on how costly the pointer indirection is, let’ s compare the following\ntwo implementations of a Person class:\n#include <string> \n \n//---- <Person1.h> ---------------- \n \nclass Person1 \n{ \n public: \n   // ... \n private \n   std::string forename_; \n   std::string surname_; \n   std::string address_; \n   std::string city_; \n   std::string country_; \n   std::string zip_; \n   int year_of_birth_; \n};\nThe Person1 struct represents a type that is not implemented in terms of a\nBridge. All seven data members (six std::strings and one int) are\ndirectly part of the struct itself. Altogether , and assuming a 64-bit machine,\nthe total size of one instance of Person1 is 152 bytes with Clang 1 1.1 and\n200 bytes with GCC 1 1.1.\nThe Person2 struct, on the other hand, is implemented with the Pimpl\nidiom:\n//---- <Person2.h> ---------------- \n \n#include <memory> \n \nclass Person2 \n{ \n public: \n   explicit Person2( /*...various person arguments...*/ ); \n   ~Person2(); \n   // ... \n \n private: \n   struct Impl; \n   std::unique_ptr<Impl> pimpl_; \n}; \n \n \n//---- <Person2.cpp> ---------------- \n \n#include <Person2.h> \n#include <string> \n \nstruct Person2::Impl \n{ \n   std::string forename; \n   std::string surname; \n   std::string address; \n   std::string city; \n   std::string country; \n   std::string zip; \n   int year_of_birth; \n}; 7\n \nPerson2::Person2( /*...various person arguments...*/ ) \n   : pimpl{ std::make_unique<Impl>( /*...various person arguments...*/ ) } \n{} \n \nPerson2::~Person2() = default;\nAll seven data members have been moved into the nested Impl struct and\ncan be accessed only via the pimpl pointer . While the total size of the\nnested Impl struct is identical to the size of Person1, the size of the\nPerson2 struct is only 8 bytes (again, assuming a 64-bit machine).\nNOTE\nVia the Bridge design, you can reduce the size of a type, sometimes even significantly .\nThis can prove to be very valuable, for instance, if you want to use the type as an\nalternative in std::variant (see “Guideline 17: Consider std::variant for Implementing\nVisitor ”).\nSo let me outline the benchmark: I will create two std::vectors of 25,000\npersons, one for each of the two Person implementations. This number of\nelements will make certain that we work beyond the size of the inner caches\nof the underlying CPU (i.e., we will use a total of 3.2 MB with Clang 1 1.1\nand 4.2 MB with GCC 1 1.1). All of these persons are given arbitrary names\nand addresses and a year of birth between 1957 and 2004 (at the time of\nwriting, this would represent a reasonable range of ages of employees in an\norganization). Then we will traverse both person vectors five thousand\ntimes, and each time determine the oldest person with\nstd::min_element(). The result will be fairly uninteresting due to the\nrepetitive nature of the benchmark. After one hundred iterations, you’ll be\ntoo bored to watch. The only thing that matters is seeing the performance\ndifference between accessing a data member directly ( Person1) or\nindirectly ( Person2). Table 7-1  shows the performance results, normalized\nto the performance of the Person1 implementation.",5744
93-Improving Performance with Partial Bridges.pdf,93-Improving Performance with Partial Bridges,"Table 7-1. Performance r esults for differ ent Person\nimplementations (normalized performance)\nPerson implementation GCC 1 1.1 Clang 1 1.1\nPerson1 (no pimpl) 1.0 1.0\nPerson2 (complete Pimpl idiom) 1.1099 1.1312\nIt’s fairly obvious that in this particular benchmark, the Bridge\nimplementation incurs a pretty significant performance penalty: 1 1.0% for\nGCC and 13.1% for Clang. This sounds like a lot! However , don’ t take\nthese numbers too seriously: clearly , the result heavily depends on the\nactual number of elements, the actual number and type of data members,\nthe system we’re running on, and the actual computation we perform in the\nbenchmark. If you change any of these details, the numbers will change as\nwell. Thus, these numbers only demonstrate that there is some, and\npotentially even some more, overhead due to the indirect access to data\nmembers.\nImproving Performance with Partial Bridges\n“OK, but  this is an expected result, right? What should I learn from that?”\nyou ask. Well, I admit that this benchmark is fairly specific and does not\nanswer all questions. However , it does provide us with the opportunity to\nactually use a Bridge to improve performance. If you take a closer look at\nthe implementation of Person1, you might realize that for the given\nbenchmark, the achievable performance is pretty limited: while the total\nsize of Person1 is 152 bytes (Clang 1 1.1) or 200 bytes (GCC 1 1.1),\nrespectively , we use only 4 bytes, i.e., a single int, out of the total data\nstructure. This proves to be rather wasteful and inef ficient: since in cache-\nbased architectures memory is always loaded as cache lines, a lot of the\ndata that we load from memory is actually not used at all. In fact, almost all\nof the data that we load from memory is not used at all: assuming a cache\nline length of 64 bytes, we only use approximately 6% of the loaded data.\nHence, despite the fact that we determine the oldest person based on the\nyear of birth of all persons, which sounds like a compute-bound operation,\nwe are in fact completely memory bound: the machine simply cannot\ndeliver data fast enough, and the integer unit will idle most of the time.\nThis setting gives us the opportunity to improve the performance with a\nBridge. Let’ s assume that we can distinguish between data that is used often\n(such as forename, surname, and year_of_birth) and data that is used\ninfrequently (for instance, the postal address). Based on this distinction, we\nnow arrange the data members accordingly: all data members that are used\noften are stored directly in the Person class. All data members that are used\ninfrequently are stored inside the Impl struct. This leads to the Person3\nimplementation:\n//---- <Person3.h> ---------------- \n \n#include <memory> \n#include <string> \n \nclass Person3 \n{ \n public: \n   explicit Person3( /*...various person arguments...*/ ); \n   ~Person3(); \n   // ... \n \n private: \n   std::string forename_; \n   std::string surname_; \n   int year_of_birth_; \n \n   struct Impl; \n   std::unique_ptr<Pimpl> pimpl_; \n}; \n \n \n//---- <Person3.cpp> ---------------- \n \n#include <Person3.h> \n \nstruct Person3::Impl \n{ \n   std::string address; \n   std::string city; \n   std::string country; \n   std::string zip; \n}; \n \nPerson3::Person3( /*...various person arguments...*/ ) \n   : forename_{ /*...*/ } \n   , surname_{ /*...*/ } \n   , year_of_birth_{ /*...*/ } \n   , pimpl_{ std::make_unique<Impl>( /*...address-related arguments...*/ ) } \n{} \n \nPerson3::~Person3() = default;\nThe total size of a Person3 instance is 64 bytes for Clang 1 1.1 (two 24-byte\nstd::strings, one integer , one pointer , and four padding bytes due to\nalignment restrictions) and 80 bytes on GCC 1 1.1 (two 32-byte\nstd::strings, one integer , one pointer , and some padding). Thus, a\nPerson3 instance is only approximately half as big as a Person1 instance.\nThis dif ference in size is measurable: Table 7-2  shows the performance\nresult for all Person implementations, including Person3. Again, the\nresults are normalized to the performance of the Person1 implementation.\nTable 7-2. Performance r esults for differ ent Person\nimplementations (normalized performance)\nPerson implementation GCC 10.3 Clang 12.0\nPerson1 (no pimpl) 1.0 1.0\nPerson2 (complete Pimpl idiom) 1.1099 1.1312\nPerson3 (partial Pimpl idiom) 0.8597 0.9353\nIn comparison to the Person1 implementation, the performance for\nPerson3 is improved by 14.0% for GCC 1 1.1 and 6.5% for Clang 1 1.1.\nAnd, as stated before, this is only because we reduced the size of the\nPerson3 implementation. “W ow, this was unexpected. I see, a Bridge is not\nnecessarily all bad for performance,” you say . Yes, indeed. Of course, it\nalways depends on the specific setup, but distinguishing between data\nmembers that are used frequently and those that are used infrequently , and\nreducing the size of a data structure by implementing a “partial” Bridge\nmay have a very positive impact on performance.\n“The performance gain is huge, that’ s great, but isn’ t that running against\nthe intention of a Bridge?” you ask. Indeed, you realize that there is a\ndichotomy between hiding implementation details and “inlining” data\nmembers for the sake of performance. As always, it depends: you will have\nto decide from case to case which aspect to favor . You hopefully also\nrealize that there is an entire range of solutions in between the two\nextremes: it is not necessary to hide all data members behind a Bridge. In\nthe end, you are the one to find the optimum for a given problem.\nIn summary , while Bridges in general will very likely incur a performance\npenalty , given the right circumstances, implementing a partial Bridge may\nhave a very positive ef fect on your performance. However , this is only one\nof many aspects that influence performance. Therefore, you should always\ncheck to see if a Bridge results in a performance bottleneck or if a partial\nBridge is addressing a performance issue. The best way to confirm this is\nwith a representative benchmark, based on the actual code and actual data\nas much as possible.\nGUIDELINE 29: BE AWARE OF BRIDGE PERFORMANCE\nGAINS AND LOSSES\nKeep in mind that Bridges can have a negative performance\nimpact.\nBe aware that a partial Bridge can have a positive impact on\nperformance when separating frequently used data from\ninfrequently used data.\nAlways confirm performance bottlenecks or improvements by\nrepresentative benchmarks; do not rely on your gut feeling.8",6576
94-Guideline 30 Apply Prototype for Abstract Copy Operations.pdf,94-Guideline 30 Apply Prototype for Abstract Copy Operations,,0
95-A Sheep-ish Example Copying Animals.pdf,95-A Sheep-ish Example Copying Animals,"Guideline 30: Apply Prototype for Abstract\nCopy Operations\nImagine  yourself sitting in a fancy Italian restaurant and studying the menu.\nOh my , they of fer so many great things; the lasagna sounds great. But the\nselection of pizza they of fer is also amazing. So hard to choose…However ,\nyour thoughts are interrupted as the waiter walks by carrying this\nincredible-looking dish. Unfortunately , it’s not meant for you but for\nsomeone at another table. Oh wow , the smell…At this moment, you know\nthat you no longer have to think about what you want to eat: you want the\nsame thing, no matter what it is. And so you order: “Ah, waiter , I’ll have\nwhatever they are having.”\nThe same problem may occur in your code. In C++ terms, what you are\nasking the waiter for is a copy of the other person’ s dish. Copying an object,\ni.e., creating an exact replica of an instance, is a fundamentally important\noperation in C++. So important that classes are, by default, equipped with a\ncopy constructor and a copy assignment operator—two of the so-called\nspecial member functions . However , when asking for a copy of the dish,\nyou are unfortunately not aware what dish it is. In C++ terms, all you have\nis a pointer -to-base (say , a Dish*). And unfortunately , trying to copy via\nDish* with the copy constructor or copy assignment operator usually\ndoesn’ t work. Still, you want an exact copy . The solution to this problem is\nanother classic GoF design pattern: the Prototype design pattern.\nA Sheep-ish Example: Copying Animals\nAs an example, let’ s consider the following Animal base class:\n//---- <Animal.h> ---------------- \n \nclass Animal \n{ \n public: \n   virtual ~Animal() = default; \n   virtual void makeSound() const = 0; 9\n   // ... more animal-specific functions \n};\nApart from the virtual destructor , which indicates that Animal is supposed\nto be a base class, the class provides only the makeSound() function, which\ndeals with printing cute animal sounds. One example of such an animal is\nthe Sheep class:\n//---- <Sheep.h> ---------------- \n \n#include <Animal.h> \n#include <string> \n \nclass Sheep : public Animal \n{ \n public: \n   explicit Sheep( std::string name ) : name_{ std::move(name) } {} \n \n   void makeSound() const override; \n   // ... more animal-specific functions \n \n private: \n   std::string name_; \n}; \n \n \n//---- <Sheep.cpp> ---------------- \n \n#include <Sheep.h> \n#include <iostream> \n \nvoid Sheep::makeSound() const \n{ \n   std::cout << ""baa\n""; \n}\nIn the main() function, we can now create a sheep and have it make\nsounds:\n#include <Sheep.h> \n#include <cstdlib> \n#include <memory> \n \nint main()",2689
96-The Prototype Design Pattern Explained.pdf,96-The Prototype Design Pattern Explained,"{ \n   // Creating the one and only Dolly \n   std::unique_ptr<Animal> const dolly = std::make_unique<Sheep>( ""Dolly"" ); \n \n   // Triggers Dolly's beastly sound \n   dolly->makeSound(); \n \n   return EXIT_SUCCESS; \n}\nDolly is great, right? And so cute! In fact, she’ s so much fun that we want\nanother Dolly . However , all we have is a pointer -to-base—an Animal*. We\ncan’t copy via the Sheep copy constructor or the copy assignment operator ,\nbecause we (technically) don’ t even know that we are dealing with a Sheep.\nIt could be any kind of animal (e.g., dog, cat, sheep, etc.). And we don’ t\nwant to copy just the Animal part of Sheep, as this is what we call  slicing .\nOh my , I just realized that this may be a particularly bad example for\nexplaining the Prototype design pattern. Slicing animals. This sounds bad.\nSo let’ s swiftly move on. Where were we? Ah yes, we want a copy of\nDolly , but we only have an Animal*. This is where the Prototype design\npattern comes into play .\nThe Prototype Design Pattern Explained\nThe Prototype design pattern is one of the five creational design patterns\ncollected by the Gang of Four . It is focused on providing an abstract way of\ncreating copies of some abstract entity .\nTHE PROTOTYPE DESIGN PATTERN\nIntent: “Specify  the kind of objects to create using a prototypical instance, and create\nnew objects by copying this prototype.”\nFigure 7-5  shows  the original UML formulation, taken from the GoF book.1 0\nFigur e 7-5. The UML r epresentation of the Pr ototype design pattern\nThe Prototype design pattern is commonly implemented by a virtual\nclone() function in the base class. Consider the updated Animal base\nclass:\n//---- <Animal.h> ---------------- \n \nclass Animal \n{ \n public: \n   virtual ~Animal() = default; \n   virtual void makeSound() const = 0; \n   virtual std::unique_ptr<Animal> clone() const = 0; // Prototype design \npattern \n};\nVia this clone() function, anyone can ask for an abstract copy of the given\n(prototype) animal, without having to know about any specific type of\nanimal (Dog, Cat, or Sheep). When the Animal base class is properly\nassigned to the high level of your architecture, it follows the DIP  (see\nFigure 7-6 ).\nFigur e 7-6. Dependency graph for the Pr ototype design pattern\nThe clone() function is declared as a pure virtual function, which means\nthat deriving classes are required to implement it. However , deriving classes\ncannot simply implement the function any way they want, but are expected\nto return an exact copy of themselves (any other result would violate the\nLSP; see “Guideline 6: Adhere to the Expected Behavior of Abstractions” ).\nThis copy is commonly created dynamically by new and returned by a\npointer -to-base. This, of course, results not only in a pointer but also in the\nneed to explicitly delete the copy again. Since manual  cleanup is\nconsidered to be very bad practice in Modern C++, the pointer is returned\nas the std::unique_ptr to Animal.\nThe Sheep class is updated accordingly:\n//---- <Sheep.h> ---------------- \n \n#include <Animal.h> \n \nclass Sheep : public Animal \n{ \n public: \n   explicit Sheep( std::string name ) : name_{ std::move(name) } {} \n \n   void makeSound() const override; \n   std::unique_ptr<Animal> clone() const override;  // Prototype design \npattern \n \n private: \n   std::string name_; \n}; \n \n \n//---- <Sheep.cpp> ---------------- \n \n#include <Sheep.h> \n#include <iostream> \n \nvoid Sheep::makeSound() const \n{ \n   std::cout << ""baa\n""; \n} \n 1 1",3566
97-Comparison Between Prototype and stdvariant.pdf,97-Comparison Between Prototype and stdvariant,"std::unique_ptr<Animal> Sheep::clone() const \n{ \n   return std::make_unique<Sheep>(*this);  // Copy-construct a sheep \n}\nThe Sheep class is now required to implement the clone() function and\nreturn an exact copy of the Sheep: Inside its own clone() function, it\nmakes use of the std::make_unique() function and its own copy\nconstructor , which is always assumed to do the right thing, even if the\nSheep class changes in the future. This approach helps avoid unnecessary\nduplication and thus follows the DR Y principle (see “Guideline 2: Design\nfor Change” ).\nNote that the Sheep class neither deletes nor hides its copy constructor and\ncopy assignment operator . Hence, if you have a sheep, you can still copy\nthe sheep with the special member functions. That is perfectly OK: the\nclone() merely adds one more way to create a copy—a way to perform\nvirtual copying.\nWith the clone() function in place, we can now create an exact copy of\nDolly . And we can do this so much easier than we could have back in 1996\nwhen they cloned the first Dolly:\n#include <Sheep.h> \n#include <cstdlib> \n#include <memory> \n \nint main() \n{ \n   std::unique_ptr<Animal> dolly = std::make_unique<Sheep>( ""Dolly"" ); \n   std::unique_ptr<Animal> dollyClone = dolly->clone(); \n \n   dolly->makeSound();       // Triggers the first Dolly's beastly sound \n   dollyClone->makeSound();  // The clone sounds just like Dolly \n \n   return EXIT_SUCCESS; \n}\nComparison Between Prototype and std::variant\nThe Prototype design pattern really is a classic, very OO-centric design\npattern, and since its publication in 1994, it is the go-to solution for\nproviding virtual copying. Because of this, the function name clone()\ncan almost be considered a keyword for identifying the Prototype design\npattern.\nBecause of the specific use case, there is no “modern” implementation\n(except perhaps for the slight update to use std::unique_ptr instead of a\nraw pointer). In comparison to other design patterns, there is also no value\nsemantics solution: as soon as we have a value, the most natural and\nintuitive solution would be to build on the two copy operations (the copy\nconstructor and the copy assignment operator).\n“Are you sure that there is no value semantics solution? Consider the\nfollowing example using std::variant:”\n#include <cstdlib> \n#include <variant> \n \nclass Dog {}; \nclass Cat {}; \nclass Sheep {}; \n \nint main() \n{ \n   std::variant<Dog,Cat,Sheep> animal1{ /* ... */ }; \n \n   auto animal2 = animal1;  // Creating a copy of the animal \n \n   return EXIT_SUCCESS; \n}\n“Aren’ t we performing an abstract copy operation in this case? And isn’ t\nthis copy operation performed by the copy constructor? So isn’ t this an\nexample of the Prototype design pattern but without the clone() function?”\nNo. Although it sounds like you have a compelling ar gument, this is not an\nexample of the Prototype design pattern. There is a very important\ndifference between our two examples: in your example, you have a closed\nset of types (typical of the V isitor design pattern). The std::variant",3113
98-The External Polymorphism Design Pattern Explained.pdf,98-The External Polymorphism Design Pattern Explained,"animal1 contains a dog, a cat, or a sheep, but nothing else. Therefore, it is\npossible to perform an explicit copy with the copy constructor . In my\nexample, I have an open set of types. In other words, I haven’ t the slightest\nclue what kind of animal I have to copy . It could be a dog, a cat, or a sheep,\nbut it could also be an elephant, a zebra, or a sloth. Anything is possible.\nTherefore, I can’ t build on the copy constructor but can only copy using a\nvirtual clone() function.\nAnalyzing the Shortcomings of the Prototype Design\nPattern\nYes, there  is no value semantics solution for the Prototype design pattern,\nbut it’ s a domestic beast from the realm of reference semantics. Hence,\nwhenever the need arises to apply the Prototype design pattern, we have to\nlive with the few drawbacks that come with it.\nArguably , the first disadvantage is the negative performance impact that\ncomes with the indirection due to pointers. However , since we only require\ncloning if we have an inheritance hierarchy , it would be unfair to consider\nthis a drawback of Prototype itself. It is rather a consequence of the basic\nsetup of the problem. Since it’ s also hard to imagine another\nimplementation without pointers and the associated indirections, it seems to\nbe an intrinsic property of the Prototype design pattern.\nThe second potential disadvantage is that, very often, the pattern is\nimplemented by dynamic memory . The allocation itself, and also the\npossible resulting fragmented memory , causes further performance\ndeficiencies. Dynamic memory is not a requirement, however , and you will\nsee in “Guideline 33: Be A ware of the Optimization Potential of T ype\nErasure”  that in certain contexts, you can also build on in-class memory .\nStill, this optimization applies to only a few special situations, and in most\ncases, the pattern builds on dynamic memory .\nIn comparison to the ability to perform an abstract copy operation, the few\ndownsides are easily acceptable. However , as discussed in “Guideline 22:\nPrefer V alue Semantics over Reference Semantics ”, our Animal hierarchy\nwould be simpler and more comprehensible if you could replace it with a\nvalue semantics approach and therefore avoid having to apply the reference\nsemantics–based Prototype design pattern. Still, whenever you encounter\nthe need to create an abstract copy , the Prototype design pattern with a\ncorresponding clone() function is the right choice.\nGUIDELINE 30: APPLY PROTOTYPE FOR ABSTRACT\nCOPY OPERATIONS\nApply the Prototype design pattern with the intent to create copies\nof abstract entities.\nPrefer building on the two copy operations for value types.\nKeep in mind the performance drawbacks resulting from pointer\nindirections and memory allocations.\nGuideline 31: Use External Polymorphism for\nNonintrusive Runtime Polymorphism\nIn “Guideline 2: Design for Change” , we saw the enormous benefits of the\nseparation of concerns design principle. In “Guideline 19: Use Strategy to\nIsolate How Things Are Done” , we used this power to extract the drawing\nimplementation details from a set of shapes with the Strategy design\npattern. However , although this has significantly reduced dependencies, and\ndespite the fact that we modernized the solution in “Guideline 23: Prefer a\nValue-Based Implementation of Strategy and Command”  with the help of\nstd::function, some disadvantages remained. In particular , the shape\nclasses were still forced to deal with the draw() operation, although for\ncoupling reasons, it is undesirable to deal with the implementation details.\nAdditionally , and most importantly , the Strategy approach proved to be a\nlittle impractical for extracting multiple, polymorphic operations. T o further\nreduce coupling and extract polymorphic operations from our shapes, we\nare now continuing this journey and taking the separation of concerns\nprinciple to a completely new , potentially unfamiliar level: we are\nseparating the polymorphic behavior as a whole. For that purpose, we will\napply the External Polymorphism design pattern.\nThe External Polymorphism Design Pattern Explained\nLet’s return to our example of drawing shapes and our latest version of our\nCircle class from “Guideline 23: Prefer a V alue-Based Implementation of\nStrategy and Command” :\n \n//---- <Shape.h> ---------------- \n \nclass Shape \n{ \n public: \n   virtual ~Shape() = default; \n \n   virtual void draw( /*some arguments*/ ) const = 0;  \n \n}; \n \n \n//---- <Circle.h> ---------------- \n \n#include <Shape.h> \n#include <memory> \n#include <functional> \n#include <utility> \n \nclass Circle : public Shape \n{ \n public: \n   using DrawStrategy = std::function<void(Circle const&, /*...*/)>;  \n \n \n   explicit Circle( double radius, DrawStrategy drawer ) \n      : radius_( radius ) \n      , drawer_( std::move(drawer) ) \n   { \n      /* Checking that the given radius is valid and that \n         the given 'std::function' instance is not empty */ \n   } \n \n   void draw( /*some arguments*/ ) const override  \n \n   { \n      drawer_( *this, /*some arguments*/ ); \n   } \n \n   double radius() const { return radius_; } \n \n private: \n   double radius_; \n   DrawStrategy drawer_; \n}; \nWith the Strategy design pattern, we have overcome the initial strong\ncoupling to the implementation details of the draw() member function (\n ).\nWe’ve also found a value semantics solution based on std::function (\n).\nHowever , the draw() member function is still part of the public interface of\nall classes deriving from the Shape base class, and all shapes inherit the\nobligation to implement it (\n ). This is a clear imperfection: ar guably , the\ndrawing functionality should be separate, an isolated aspect of shapes, and\nshapes in general should be oblivious to the fact that they can be drawn.\nThe fact that we have already extracted the implementation details\nconsiderably strengthens this ar gument.\n“Well, then, let’ s just extract the draw() member function, right?” you\nargue. And you’re right. Unfortunately , this appears to be a hard thing to do\nat first sight. I hope you remember “Guideline 15: Design for the Addition\nof Types or Operations ”, where we came to the conclusion that you should\nprefer an object-oriented solution when you primarily want to add types.\nFrom this perspective, it appears as if we are stuck with the virtual draw()\nfunction and the Shape base class, which represents the set of available\noperations of all shapes, i.e., the list of requirements.\nThere is a solution, though. A pretty astonishing one: we can extract the\ncomplete polymorphic behavior with the External Polymorphism design\npattern. The pattern was introduced in a paper by Chris Cleeland, Douglas\nC. Schmidt, and T imothy H. Harrison in 1996.  Its intent is to enable the\npolymorphic treatment of nonpolymorphic types (types without a single\nvirtual function).12\n13\nTHE EXTERNAL POLYMORPHISM DESIGN\nPATTERN\nIntent: “Allow  C++ classes unrelated by inheritance and/or having no virtual methods to\nbe treated polymorphically . These unrelated classes can be treated in a common manner\nby software that uses them.”\nFigure 7-7  gives  a first impression of how the design pattern achieves this\ngoal. One of the first striking details is that there is no Shape base class\nanymore. In the External Polymorphism design pattern, the dif ferent kinds\nof shapes ( Circle, Square, etc.) are assumed to be plain, nonpolymorphic\ntypes. Also, the shapes are not expected to know anything about drawing.\nInstead of requiring the shapes to inherit from a Shape base class, the\ndesign pattern introduces a separate inheritance hierarchy in the form of the\nShapeConcept and ShapeModel classes. This external hierarchy introduces\nthe polymorphic behavior for the shapes by introducing all the operations\nand requirements that are expected for shapes.\nFigur e 7-7. The UML r epresentation of the External Polymorphism  design pattern\nIn our simple example, the polymorphic behavior consists of only the\ndraw() function. However , the set of requirements could, of course, be\nlarger (e.g., rotate(), serialize(), etc.). This set of virtual functions has\nbeen moved into the abstract ShapeConcept class, which now takes the\nplace of the previous Shape base class. The major dif ference is that\nconcrete shapes are not required to know about ShapeConcept and, in\nparticular , are not expected to inherit from it. Thus, the shapes are\ncompletely decoupled from the set of virtual functions. The only class\ninheriting from ShapeConcept is the ShapeModel class template. This class\nis instantiated for a specific kind of shape ( Circle, Square, etc.) and acts\nas a wrapper for it. However , ShapeModel does not implement the logic of",8834
99-Drawing of Shapes Revisited.pdf,99-Drawing of Shapes Revisited,"the virtual functions itself but delegates the request to the desired\nimplementation.\n“Wow, that’ s amazing! I get the point: this external hierarchy extracts the\nwhole set of virtual functions and, by that, the entire polymorphic behavior\nof the shapes.” Y es, exactly . Again, this is an example of separation of\nconcerns and the SRP . In this case, the complete polymorphic behavior is\nidentified as a variation point  and extracted from the shapes. And again,\nSRP acts as an enabler for the OCP: with the ShapeModel class template,\nyou can easily add any new , nonpolymorphic shape type into the\nShapeConcept hierarchy . This works as long as the new type fulfills all of\nthe required operations.\n“I’m really impressed. However , I’m not certain what you mean by\nfulfilling all of the required operations. Could you please elaborate?”\nAbsolutely! I think the benefits will become clear when I show you a\nconcrete code example. So let’ s refactor the complete drawing of the shapes\nexample with the External Polymorphism design pattern.\nDrawing of Shapes Revisited\nLet’s start with the Circle and Square classes:\n//---- <Circle.h> ---------------- \n \nclass Circle \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   { \n      /* Checking that the given radius is valid */ \n   } \n \n   double radius() const { return radius_; } \n   /* Several more getters and circle-specific utility functions */ \n \n private: \n   double radius_; \n   /* Several more data members */ \n}; \n \n \n//---- <Square.h> ---------------- \n \nclass Square \n{ \n public: \n   explicit Square( double side ) \n      : side_( side ) \n   { \n      /* Checking that the given side length is valid */ \n   } \n \n   double side() const { return side_; } \n   /* Several more getters and square-specific utility functions */ \n \n private: \n   double side_; \n   /* Several more data members */ \n};\nBoth classes have been reduced to basic geometric entities. Both are\ncompletely nonpolymorphic, i.e., there is no base class anymore and not a\nsingle virtual function. Most importantly , however , the two classes are\ncompletely oblivious to any kind of operation, like drawing, rotating,\nserialization, etc., that could introduce an artificial dependency .\nInstead, all of this functionality is introduced in the ShapeConcept base\nclass and implemented by the ShapeModel class template:\n \n//---- <Shape.h> ---------------- \n \n#include <functional> \n#include <stdexcept> \n#include <utility> \n \nclass ShapeConcept \n{ \n public: \n   virtual ~ShapeConcept() = default; \n \n   virtual void draw() const = 0;  \n \n 14\n   // ... Potentially more polymorphic operations \n}; \n \n \ntemplate< typename ShapeT > \nclass ShapeModel : public ShapeConcept  \n \n{ \n public: \n   using DrawStrategy = std::function<void(ShapeT const&)>;  \n \n \n   explicit ShapeModel( ShapeT shape, DrawStrategy drawer ) \n      : shape_{ std::move(shape) } \n      , drawer_{ std::move(drawer) } \n   { \n      /* Checking that the given 'std::function' is not empty */ \n   } \n \n   void draw() const override { drawer_(shape_); }  \n \n \n   // ... Potentially more polymorphic operations \n \n private: \n   ShapeT shape_;  \n \n   DrawStrategy drawer_;  \n \n}; \nThe ShapeConcept class introduces a pure virtual draw() member function\n(\n). In our example, this one virtual function represents the entire set of\nrequirements for shapes. Despite the small size of the set, the\nShapeConcept class represents a classic abstraction in the sense of the LSP\n(see “Guideline 6: Adhere to the Expected Behavior of Abstractions” ). This\nabstraction is implemented within the Shape Model class template (\n ). It is\nnoteworthy that instantiations of ShapeModel are the only classes to ever\ninherit from ShapeConcept; no other class is expected to enter in this\nrelationship. The ShapeModel class template will be instantiated for every\ndesired type of shape, i.e., the ShapeT template parameter is a stand-in for\ntypes like Circle, Square, etc. Note that ShapeModel stores an instance of\nthe corresponding shape (\n ) (composition, not inheritance; remember\n“Guideline 20: Favor Composition over Inheritance” ). It acts as a wrapper\nthat augments the specific shape type with the required polymorphic\nbehavior (in our case, the draw() function).\nSince ShapeModel implements the ShapeConcept abstraction, it needs to\nprovide an implementation for the draw() function. However , it is not the\nresponsibility of the ShapeModel to implement the draw() details itself.\nInstead, it should forward a drawing request to the actual implementation.\nFor that purpose, we can again reach for the Strategy design pattern and the\nabstracting power of std::function (\n). This choice nicely decouples\nboth the implementation details of drawing and all the necessary drawing\ndata (colors, textures, transparency , etc.), which can be stored inside the\ncallable. Hence, ShapeModel stores an instance of DrawStrategy (\n) and\nuses that strategy whenever the draw() function is triggered (\n ).\nThe Strategy design pattern and the std::function are not your only\nchoices, though. W ithin the ShapeModel class template, you have complete\nflexibility to implement drawing as you see fit. In other words, within the\nShapeModel::draw() function, you define the actual requirements for the\nspecific shape types. For instance, you could alternatively forward to a\nmember function of the ShapeT shape (which does not have to be named\ndraw()!), or you could forward to a free function of the shape. You just\nneed to make sure that you do not impose artificial requirements on either\nthe ShapeModel or the ShapeConcept abstraction. Either way , any type\nused to instantiate ShapeModel must fulfill these requirements to make the\ncode compile.\nNOTE\nFrom a design perspective, building on a member function would introduce a more\nrestrictive requirement on the given type, and therefore introduce stronger coupling.\nBuilding on a free function, however , would enable you to invert dependencies, similar\nto the use of the Strategy design pattern (see “Guideline 9: Pay Attention to the\nOwnership of Abstractions” ). If you prefer the free function approach, just remember\n“Guideline 8: Understand the Semantic Requirements of Overload Sets” .\n“Isn’ t ShapeModel some kind of generalization of the initial Circle and\nSquare classes? The ones that were also holding the std::function\ninstance?” Y es, this is an excellent realization. Indeed, you could say that\nShapeModel is kind of a templated version of the initial shape classes. For\nthis reason it helps to reduce the boilerplate code necessary to introduce the\nStrategy behavior and improves the implementation with respect to the\nDRY principle (see “Guideline 2: Design for Change” ). However , you gain\na lot more: for instance, since ShapeModel is already a class template, you\ncan easily switch from the current runtime Strategy implementation to a\ncompile-time Strategy implementation (i.e., policy-based design; see\n“Guideline 19: Use Strategy to Isolate How Things Are Done” ):\n \ntemplate< typename ShapeT \n        , typename DrawStrategy >  \n \nclass ShapeModel : public ShapeConcept \n{ \n public: \n   explicit ShapeModel( ShapeT shape, DrawStrategy drawer ) \n      : shape_{ std::move(shape) } \n      , drawer_{ std::move(drawer) } \n   {} \n \n   void draw() const override { drawer_(shape_); } \n \n private: \n   ShapeT shape_; \n   DrawStrategy drawer_; \n}; \nInstead of building on std::function, you can pass an additional template\nparameter to the ShapeModel class template, which represents the drawing\nStrategy (\n ). This template parameter could even have a default:\nstruct DefaultDrawer \n{ \n   template< typename T > \n   void operator()( T const& obj ) const { \n      draw(obj); \n   } \n}; \n \ntemplate< typename ShapeT \n        , typename DrawStrategy = DefaultDrawer > \nclass ShapeModel : public ShapeConcept \n{ \n public: \n   explicit ShapeModel( ShapeT shape, DrawStrategy drawer = DefaultDrawer{} ) \n   // ... as before \n};\nIn comparison to applying policy-based design to the Circle and Square\nclasses directly , the compile-time approach in this context holds only\nbenefits and comes with no disadvantages. First, you gain performance due\nto fewer runtime indirections (the expected performance disadvantage of\nstd::function). Second, you do not artificially augment Circle, Square,\nand all the other shape classes with a template ar gument to configure the\ndrawing behavior . You now only do this for the wrapper , which augments\nthe drawing behavior , and you do this in exactly one place (which again\nvery nicely adheres to the DR Y principle). Third, you do not force\nadditional code into a header file by turning a regular class into a class\ntemplate. Only the slim ShapeModel class, which is already a class\ntemplate, needs to reside in a header file. Therefore, you avoid creating\nadditional dependencies.\n“Wow, this design pattern is getting better and better . This seriously is a\nvery compelling combination of inheritance and templates!” Y es, I\ncompletely agree. This is an exemplar  for combining runtime and compile-\ntime polymorphism: the ShapeConcept base class provides the abstraction\nfor all possible types, while the deriving ShapeModel class template\nprovides the code generation for shape-specific code. Most impressively ,\nhowever , this combination comes with huge benefits for the reduction of\ndependencies.\nTake a look at Figure 7-8 , which shows the dependency graph for our\nimplementation of the External Polymorphism design pattern. On the\nhighest level of our architecture are the ShapeConcept and ShapeModel\nclasses, which together represent the abstraction of shapes. Circle and\nSquare are possible implementations of this abstraction but are still\ncompletely independent: no inheritance relationship, no composition,\nnothing. Only the instantiation of the ShapeModel class template for a\nspecific kind of shape and a specific DrawStrategy implementation brings\nall aspects together . However , specifically note that all of this happens on\nthe lowest level of our architecture: the template code is generated at the\npoint where all dependencies are known and “injected” into the right level\nof our architecture. Thus, we truly have a proper architecture: all\ndependency connections run toward the higher levels with an almost\nautomatic adherence to  the DIP .\nFigur e 7-8. Dependency graph for the External Polymorphism  design pattern\nWith this functionality in place, we are now free to implement any desired\ndrawing behavior . For instance, we are free to use OpenGL again:\n \n//---- <OpenGLDrawStrategy.h> ---------------- \n \n#include <Circle> \n#include <Square> \n#include /* OpenGL graphics library headers */ \n \nclass OpenGLDrawStrategy \n{ \n public: \n   explicit OpenGLDrawStrategy( /* Drawing related arguments */ ); \n \n   void operator()( Circle const& circle ) const;  \n \n   void operator()( Square const& square ) const;  \n \n \n private: \n   /* Drawing related data members, e.g. colors, textures, ... */ \n}; \nSince OpenGLDrawStrategy does not have to inherit from any base class,\nyou are free to implement it as you see fit. If you want to, you can combine\nthe implementation of drawing circles and drawing squares into one class.\nThis does not create any artificial dependencies, similar to what we\nexperienced in “Guideline 19: Use Strategy to Isolate How Things Are\nDone” , where we combined these functionalities into the base class.\nNOTE\nNote that combining drawing circles and squares in one class represents the same thing\nas inheriting the class from two Strategy base classes. On that level of the architecture, it\ndoes not create any artificial dependencies and is merely an implementation detail.\nThe only convention you need to follow is to provide a function call\noperator for Circle (\n) and Square (\n), as this is the defined calling\nconvention in the ShapeModel class template.\nIn the main() function, we put all of the details together:\n \n#include <Circle.h> \n#include <Square.h> \n#include <Shape.h> \n#include <OpenGLDrawStrategy.h> \n#include <memory> \n#include <vector> \n \nint main() \n{ \n   using Shapes = std::vector<std::unique_ptr<ShapeConcept>>;  \n \n \n   using CircleModel = ShapeModel<Circle,OpenGLDrawStrategy>;  \n \n   using SquareModel = ShapeModel<Square,OpenGLDrawStrategy>;  \n \n \n   Shapes shapes{}; \n \n   // Creating some shapes, each one \n   //   equipped with an OpenGL drawing strategy \n   shapes.emplace_back( \n      std::make_unique<CircleModel>( \n         Circle{2.3}, OpenGLDrawStrategy(/*...red...*/) ) ); \n   shapes.emplace_back( \n      std::make_unique<SquareModel>( \n         Square{1.2}, OpenGLDrawStrategy(/*...green...*/) ) ); \n   shapes.emplace_back( \n      std::make_unique<CircleModel>( \n         Circle{4.1}, OpenGLDrawStrategy(/*...blue...*/) ) ); \n \n   // Drawing all shapes \n   for( auto const& shape : shapes ) \n   { \n      shape->draw(); \n   } \n \n   return EXIT_SUCCESS; \n} \nAgain, we first create an empty vector of shapes (this time a vector of\nstd::unique_ptrs of ShapeConcept) (\n) before we add three shapes.\nWithin the calls to std::make_unique(), we instantiate the ShapeModel\nclass for Circle and Square (called CircleModel (\n) and SquareModel (\n) to improve readability) and pass the necessary details (the concrete shape\nand the corresponding OpenGLDrawStrategy). After that, we are able to\ndraw all shapes in the desired way .\nAltogether , this approach gives you a lot of awesome advantages:\nDue to separating concerns and extracting the polymorphic behavior\nfrom the shape types, you remove all dependencies on graphics\nlibraries, etc. This creates a very loose coupling and beautifully\nadheres to the SRP.\nThe shape types become simpler and nonpolymorphic.\nYou’re able to easily add new kinds of shapes. These might even be\nthird-party types, as you are no longer required to intrusively inherit\nfrom a Shape base class or create an Adapter (see “Guideline 24: Use\nAdapters to Standardize Interfaces” ). Thus, you perfectly adhere to the\nOCP.\nYou significantly reduce the usual inheritance-related boilerplate code\nand implement it in exactly one place, which very nicely follows the\nDRY principle.\nSince the ShapeConcept and ShapeModel class belong together and\ntogether form the abstraction, it’ s much easier to adhere to the DIP .\nBy reducing the number of indirections by exploiting the available\nclass template, you can improve performance.\nThere is one more advantage, which I consider to be the most impressive\nbenefit of the External Polymorphism design pattern: you can,\nnonintrusively , equip any type with polymorphic behavior . Really , any type,\neven something as simple as an int. To demonstrate this, let’ s take a look at\nthe following code snippet, which assumes that ShapeModel is equipped\nwith a DefaultDrawer, which expects the wrapped type to provide a free\ndraw() function:",15204
100-Analyzing the Shortcomings of the External Polymorphism Design Pattern.pdf,100-Analyzing the Shortcomings of the External Polymorphism Design Pattern,"int draw( int i )  \n \n{ \n   // ... drawing an int, for instance by printing it to the command line \n} \n \nint main() \n{ \n   auto shape = std::make_unique<ShapeModel<int>>( 42 );  \n \n \n   shape->draw();  // Drawing the integer  \n \n \n   return EXIT_SUCCESS; \n} \nWe first provide a free draw() function for an int (\n). In the main()\nfunction, we now instantiate a ShapeModel for int (\n). This line will\ncompile, as the int satisfies all the requirements: it provides a free draw()\nfunction. Therefore, in the next line we can “draw” the integer (\n ).\n“Do you really want me to do something like this?” you ask, frowning. No,\nI do not want you to do this at home. Please consider this a technical\ndemonstration, not a recommendation. But nonetheless, this is impressive:\nwe have just nonintrusively equipped an int with polymorphic behavior .\nReally impressive indeed!\nComparison Between External Polymorphism and\nAdapter\n“Since you  just mentioned the Adapter design pattern, I feel like it’ s very\nsimilar to the External Polymorphism design pattern. What is the dif ference\nbetween the two?” Excellent point! Y ou address an issue that the original\npaper by Cleeland, Schmidt, and Harrison also addresses. Y es, these two\ndesign patterns are indeed pretty similar , yet there is a very distinctive\ndifference: while the Adapter design pattern is focused on standardizing\ninterfaces and adapts a type or function to an existing interface, the External\nPolymorphism design pattern creates a new , external hierarchy to abstract\nfrom a set of related, nonpolymorphic types. So if you adapt something to\nan existing interface, you (most probably) apply the Adapter design pattern.\nIf, however , you create a new abstraction for the purpose of treating a set of\nexisting types polymorphically , then you (most likely) apply the External\nPolymorphism design pattern.\nAnalyzing the Shortcomings of the External\nPolymorphism Design Pattern\n“I get  the feeling that you like the External Polymorphism design pattern a\nlot, am I right?” you wonder . Oh yes, indeed, I’m amazed by this design\npattern. From my point of view , this design pattern is key to loose coupling,\nand it’ s a shame that it is not more widely known. Perhaps this is because\nmany developers have not fully embraced the separation of concerns and\ntend to put everything into only a few classes. Still, despite my enthusiasm,\nI do not want to create the impression that everything about External\nPolymorphism is perfect. No, as stated many times before, every design has\nits advantages and its disadvantages. The same is true for the External\nPolymorphism design pattern.\nThere is only one major disadvantage, though: the External Polymorphism\ndesign pattern does not really fulfill the expectations of a clean and simple\nsolution, and definitely not the expectations of a value semantics–based\nsolution. It does not help to reduce pointers, does not reduce the number of\nmanual allocations, does not lower the number of inheritance hierarchies,\nand does not help to simplify user code. On the contrary , since it is\nnecessary to explicitly instantiate the ShapeModel class, user code has to be\nrated as slightly more complicated. However , if you consider this a severe\ndrawback, or if you’re thinking something along the lines of “This should\nbe automated somehow ,” I have very good news for you: in “Guideline 32:\nConsider Replacing Inheritance Hierarchies with T ype Erasure” , we will\ntake a look at the modern C++ solution that will elegantly resolve this issue.\nApart from that, I have only two reminders that you should consider as\nwords of caution. The first point to keep in mind is that the application of\nExternal Polymorphism does not save you from thinking about a proper\nabstraction. The ShapeConcept base class is just as much subject to the ISP\nas any other base class. For instance, we could easily apply External\nPolymorphism to the Document example from “Guideline 3: Separate\nInterfaces to A void Artificial Coupling ”:\nclass DocumentConcept \n{ \n public: \n   // ... \n   virtual ~Document() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0; \n   virtual void serialize( ByteStream& bs, /*...*/ ) const = 0; \n   // ... \n}; \n \ntemplate< typename DocumentT > \nclass DocumentModel \n{ \n public: \n   // ... \n   void exportToJSON( /*...*/ ) const override; \n   void serialize( ByteStream& bs, /*...*/ ) const override; \n   // ... \n \n private: \n   DocumentT document_; \n};\nThe DocumentConcept class takes the role of the ShapeConcept base class,\nwhile the DocumentModel class template takes the role of the ShapeModel\nclass template. However , this externalized hierarchy exhibits the same\nproblem as the original hierarchy: for all code requiring only the\nexportToJSON() functionality , it introduces the artificial dependency on\nByteStream:\nvoid exportDocument( DocumentConcept const& doc ) \n{ \n   // ... \n   doc.exportToJSON( /* pass necessary arguments */ ); \n   // ... \n}\nThe correct approach would be to separate concerns by segregating the\ninterface into the two orthogonal aspects of JSON export and serialization:\nclass JSONExportable \n{ \n public: \n   // ... \n   virtual ~JSONExportable() = default; \n \n   virtual void exportToJSON( /*...*/ ) const = 0; \n   // ... \n}; \n \nclass Serializable \n{ \n public: \n   // ... \n   virtual ~Serializable() = default; \n \n   virtual void serialize( ByteStream& bs, /*...*/ ) const = 0; \n   // ... \n}; \n \ntemplate< typename DocumentT > \nclass DocumentModel \n   : public JSONExportable \n   , public Serializable \n{ \n public: \n   // ... \n   void exportToJSON( /*...*/ ) const override; \n   void serialize( ByteStream& bs, /*...*/ ) const override; \n   // ... \n \n private: \n   DocumentT document_; \n};\nAny function exclusively interested in JSON export can now specifically\nask for that functionality:\nvoid exportDocument( JSONExportable const& exportable ) \n{ \n   // ... \n   exportable.exportToJSON( /* pass necessary arguments */ ); \n   // ... \n}\nSecond, be aware that External Polymorphism, just as the Adapter design\npattern, makes it very easy to wrap types that do not fulfill the semantic\nexpectations. Similar to the duck typing example in “Guideline 24: Use\nAdapters to Standardize Interfaces” , where we pretended that a turkey is a\nduck, we also pretended that an int is a shape. All we had to do to fulfill\nthe requirements was provide a free draw() function. Easy . Perhaps too\neasy. Therefore, keep in mind that the classes used to instantiate the\nShapeModel class template (e.g., Circle, Square, etc.) have  to adhere to\nthe LSP . After all, the ShapeModel class acts just as a wrapper and passes\non the requirements defined by the ShapeConcept class to the concrete\nshapes. Thus, the concrete shapes take the responsibility to properly\nimplement the expected behavior (see “Guideline 6: Adhere to the Expected\nBehavior of Abstractions” ). Any failure to completely fulfill the\nexpectations may lead to (potentially subtle) misbehavior . Unfortunately ,\nbecause these requirements have been externalized, it is a little harder to\ncommunicate the expected behavior .\nHowever , in the int example it was maybe our own fault to be honest.\nPerhaps the ShapeConcept base class doesn’ t really represent an\nabstraction of a shape. It is reasonable to ar gue that shapes are more than\njust drawing. Perhaps we should have named the abstraction Drawable, and\nthe LSP would have been satisfied. Perhaps not. So in the end, it all comes\ndown to the choice of abstraction. Which brings us back to the title of\nChapter 2 : “The Art of Building Abstractions.” No, it isn’ t easy , but perhaps\nthese examples demonstrate that it is important. V ery important. It may be\nthe essence of software design.\nIn summary , although the External Polymorphism design pattern may not\nsatisfy your expectation in a simple or value-based solution, it must be\nconsidered a very important step toward decoupling software entities. From\nthe perspective of reducing dependencies, this design pattern appears to be\na key ingredient to loose coupling, and is a marvelous example of the power\nof separation of concerns. It also gives us one key insight: using this design\npattern, you can nonintrusively equip any type with polymorphic behavior ,\ne.g., virtual functions, so any type can behave polymorphically , even a\nsimple value type such as int. This realization opens up a completely new ,\nexciting design space, which we will continue to explore in the next\nchapter .\nGUIDELINE 31: USE EXTERNAL POLYMORPHISM FOR\nNONINTRUSIVE RUNTIME POLYMORPHISM\nApply the External Polymorphism design pattern with the intent to\nenable the polymorphic treatment of nonpolymorphic types.\nConsider the External Polymorphism design pattern as a key\nplayer to achieve loose coupling.\nExploit the design flexibilities of the externalized inheritance\nhierarchy .\nUnderstand the dif ferences between External Polymorphism and\nAdapter .\nPrefer nonintrusive solutions to intrusive solutions.\n1 ABI stability is an important and often debated topic in the C++ community , in particular just\nbefore the release of C++20. If this sounds interesting to you, I recommend the CppCast\ninterviews with Titus W inters  and Marshall Clow  to get an impression of both sides.\n2 Remember that std::unique_ptr cannot be copied. Thus, switching from ElectricEngine\nto std::unique_ptr<ElectricEngine> renders your class noncopyable. T o preserve copy\nsemantics, you have to implement the copy operations manually . When doing this, please keep\nin mind that the copy operations disable the move operations. In other words, prefer to stick to\nthe Rule of 5 .\n3 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n4 Usually , the move operations are expected to be noexcept. This is explained by Core\nGuideline C.66 . However , sometimes this might not be possible, for instance, under the\nassumption that some std::unique_ptr data member is never nullptr.\n5 See “Guideline 1 1: Understand the Purpose of Design Patterns”  for my statement about the\nstructural similarity of design patterns.\n6 If this dynamic allocation turns out to be a severe impediment or a reason not to use a Bridge,\nyou might look into the Fast-Pimpl idiom, which is based on in-class memory . For that, you\nmight refer to Herb Sutter ’s first book: Exceptional C++: 47 Engineering Puzzles,\nProgramming Pr oblems, and Exception-Safety Solutions  (Pearson).\n7 The dif ference in size of Person1 is easily explained by the dif ferent sizes of std::string\nimplementations for dif ferent compilers. Since compiler vendors optimize std::string for\ndifferent use cases, on Clang 1 1.1, a single std::string occupies 24 bytes, and on GCC 1 1.1,\nit occupies 32 bytes. Therefore, the total size of one instance of Person1 is 152 bytes with\nClang 1 1.1 (six 24-byte std::strings, plus one 4-byte int, plus 4 bytes of padding) or 200\nbytes with GCC 1 1.1 (six 32-byte std::strings, plus one 4-byte int, plus 4 bytes of\npadding ).\n8 You may be aware that we are still far away from optimal performance. T o move in the\ndirection of optimal performance, we could arrange the data based on how it is used. For this\nbenchmark, this would mean to store all year_of_birth values from all persons in one big\nstatic vector of integers. This kind of data arrangement would move us in the direction of data-\noriented design . For more information on this paradigm, see for instance Richard Fabian’ s\nbook on the subject, Data-Oriented Design: Softwar e Engineering for Limited Resour ces and\nShort Schedules .\n9 The rules when a compiler will generate these two copy operations are beyond the scope of\nthis book, but here is a short summary: every  class has these two operations, meaning they\nalways exist. They have been generated by the compiler , or you have explicitly declared or\neven defined them (potentially in the private section of the class or via =delete), or they are\nimplicitly deleted. Note that deleting these functions does not mean that they’re gone, but\n=delete serves as a definition. As these two functions are always  part of a class, they will\nalways  participate in overload resolution.\n10 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n1 1 Core Guideline R.3  clearly states that a raw pointer (a T*) is nonowning. From this\nperspective, it would even be incorrect to return a raw pointer -to-base. However , this means\nthat you cannot directly exploit the language feature of covariant return types anymore. If this\nis desirable or required, a common solution would be to follow the T emplate Method design\npattern and split the clone() function into a private virtual function returning a raw\npointer , and a public non-virtual function calling the private function and returning\nstd::unique_ptr.\n12 See “Guideline 2: Design for Change”  for a similar example with dif ferent kinds of\ndocuments.\n13 Chris Cleeland, Douglas C. Schmidt, and T imothy H. Harrison, “External Polymorphism—\nAn Object Structural Pattern for T ransparently Extending C++ Concrete Data T ypes,”\nProceedings of the 3rd Pattern Languages of Programming Conference, Allerton Park, Illinois,\nSeptember 4–6, 1996.\n14 The names Concept and Model are chosen based on the common terminology in the T ype\nErasure design pattern, where External Polymorphism plays a major role; see Chapter 8 .",13633
101-Guideline 32 Consider Replacing Inheritance Hierarchies with Type Erasure.pdf,101-Guideline 32 Consider Replacing Inheritance Hierarchies with Type Erasure,"Chapter 8. The T ype Erasure\nDesign Pattern\nSeparation  of concerns and value semantics are two of the essential\ntakeaways from this book that I have mentioned a couple of times by now .\nIn this chapter , these two are beautifully combined into one of the most\ninteresting modern C++ design patterns: T ype Erasure. Since this pattern\ncan be considered one of the hottest irons in the fire, in this chapter I will\ngive you a very thorough, in-depth introduction to all aspects of T ype\nErasure. This, of course, includes all design-specific aspects and a lot of\nspecifics about implementation details.\nIn “Guideline 32: Consider Replacing Inheritance Hierarchies with T ype\nErasure” , I will introduce you to T ype Erasure and give you an idea why\nthis design pattern is such a great combination of dependency reduction and\nvalue semantics. I will also give you a walkthrough of a basic, owning T ype\nErasure implementation.\n“Guideline 33: Be A ware of the Optimization Potential of T ype Erasure”  is\nan exception: despite the fact that in this book I primarily focus on\ndependencies and design aspects, in this one guideline I will entirely focus\non performance-related implementation details. I will show you how to\napply the Small Buffer Optimization (SBO)  and how to implement a manual\nvirtual dispatch to speed up your T ype Erasure implementation.\nIn “Guideline 34: Be A ware of the Setup Costs of Owning Type Erasure\nWrappers ”, we will investigate the setup costs of the owning T ype Erasure\nimplementation. W e will find that there is a cost associated with value\nsemantics that sometimes we may not be willing to pay . For this reason, we\ndare to take a step into the realm of reference semantics and implement a\nform of nonowning T ype Erasure.",1783
102-The History of Type Erasure.pdf,102-The History of Type Erasure,"Guideline 32: Consider Replacing\nInheritance Hierarchies with Type Erasure\nThere  are a couple of  recurring pieces of advice throughout this book:\nMinimize dependencies.\nSeparate concerns.\nPrefer composition to inheritance.\nPrefer nonintrusive solutions.\nPrefer value semantics over reference semantics.\nUsed on their own, all of these have very positive ef fects on the quality of\nyour code. In combination, however , these guidelines prove to be so much\nbetter . This is what you have experienced in our discussion about the\nExternal Polymorphism design pattern in “Guideline 31: Use External\nPolymorphism for Nonintrusive Runtime Polymorphism” . Extracting the\npolymorphic behavior turned out to be extremely powerful and unlocked an\nunprecedented level of loose coupling. Still, probably disappointingly , the\ndemonstrated implementation of External Polymorphism did not strike you\nas a very modern way of solving things. Instead of following the advice to\nprefer value semantics, the implementation was firmly built on reference\nsemantics: many pointers, many manual allocations, and manual lifetime\nmanagement.  Hence, the missing detail you’re waiting for is a value\nsemantics–based implementation of the External Polymorphism design\npattern. And I will not keep you waiting anymore: the resulting solution is\ncommonly called Type Erasur e.\nThe History of T ype Erasure\nBefore  I give you a detailed introduction, let’ s quickly talk about the history\nof Type Erasure. “Come on,” you ar gue. “Is this really necessary? I’m\ndying to finally see how this stuf f works.” W ell, I promise to keep it short.\nBut yes, I feel this is a necessary detail of this discussion for two reasons.1\n2\nFirst, to demonstrate that we as a community , aside from the circle of the\nmost experienced C++ experts, may have overlooked and ignored this\ntechnique for too long. And second, to give some well-deserved credit to\nthe inventor of the technique.\nThe T ype Erasure design pattern is very often attributed to one of the first\nand therefore most famous presentations of this technique. At the\nGoingNative 2013 conference, Sean Parent gave a talk called “Inheritance\nIs the Base Class of Evil.”  recapped his experiences with the development\nof Photoshop and talked about the dangers and disadvantages of\ninheritance-based implementations. However , he also presented a solution\nto the inheritance problem, which later came to be known as T ype Erasure.\nDespite Sean’ s talk being one of the first recorded, and for that reason\nprobably the most well-known resource about T ype Erasure, the technique\nwas used long before that. For instance, T ype Erasure was used in several\nplaces in the Boost  libraries , for example, by Douglas Gregor for\nboost::function. Still, to my best knowledge, the technique was first\ndiscussed in a paper by Kevlin Henney in the July-August 2000 edition of\nthe C++ Report . In this paper , Kevlin demonstrated T ype Erasure with a\ncode example that later evolved into what we today know as C++17’ s\nstd::any. Most importantly , he was the first to elegantly combine several\ndesign patterns to form a value semantics–based implementation around a\ncollection of unrelated, nonpolymorphic types.\nSince then, a lot of common types have acquired the technique to provide\nvalue types for various applications. Some of these types have even found\ntheir way into the Standard Library . For instance, we have already seen\nstd::function, which represents a value-based abstraction of a callable.\nI’ve already mentioned std::any, which represents an abstract container -\nlike value for virtually anything (hence the name) but without exposing any\nfunctionality:\n#include <any> \n#include <cstdlib> \n#include <string> \nusing namespace std::string_literals; 3\n4\n5\n \nint main() \n{ \n   std::any a;          // Creating an empty 'any' \n   a = 1;               // Storing an 'int' inside the 'any'; \n   a = ""some string""s;  // Replacing the 'int' with a 'std::string' \n \n   // There is nothing we can do with the 'any' except for getting the value \nback \n   std::string s = std::any_cast<std::string>( a ); \n \n   return EXIT_SUCCESS; \n}\nAnd then there is std::shared_ptr, which uses T ype Erasure to store the\nassigned deleter:\n#include <cstdlib> \n#include <memory> \n \nint main() \n{ \n   { \n      // Creating a 'std::shared_ptr' with a custom deleter \n      //   Note that the deleter is not part of the type! \n      std::shared_ptr<int> s{ new int{42}, [](int* ptr){ delete ptr; } }; \n   } \n   // The 'std::shared_ptr' is destroyed at the end of the scope, \n   //   deleting the 'int' by means of the custom deleter. \n \n   return EXIT_SUCCESS; \n}\n“It appears to be simpler to just provide a second template parameter for the\ndeleter as std::unique_ptr does. Why isn’ t std::shared_ptr\nimplemented in the same way?” you inquire. W ell, the designs of\nstd::shared_ptr and std::unique_ptr are dif ferent for very good\nreasons. The philosophy of std::unique_ptr is to represent nothing but\nthe simplest possible wrapper around a raw pointer: it should be as fast as a\nraw pointer , and it should have the same size as a raw pointer . For that\nreason, it is not desirable to store the deleter alongside the managed pointer .\nConsequently , std::unique_ptr is designed such that for stateless",5390
103-The Type Erasure Design Pattern Explained.pdf,103-The Type Erasure Design Pattern Explained,"deleters, any size overhead can be avoided. However , unfortunately , this\nsecond template parameter is easily overlooked and causes artificial\nrestrictions:\n// This function takes only unique_ptrs that use the default deleter, \n//   and thus is artificially restricted \ntemplate< typename T > \nvoid func1( std::unique_ptr<T> ptr ); \n \n// This function does not care about the way the resource is cleaned up, \n//   and thus is truly generic \ntemplate< typename T, typename D > \nvoid func2( std::unique_ptr<T,D> ptr );\nThis kind of coupling is avoided in the design of std::shared_ptr. Since\nstd::shared_ptr has to store many more data items in its so-called\ncontrol block (that includes the reference count, the weak count, etc.), it has\nthe opportunity to use T ype Erasure to literally erase the type of the deleter ,\nremoving any kind of possible dependency .\nThe T ype Erasure Design Pattern Explained\n“Wow, that  truly sounds intriguing. This makes me even more excited to\nlearn about T ype Erasure.” OK then, here we go. However , please don’ t\nexpect any magic or revolutionary new ideas. T ype Erasure is nothing but a\ncompound design pattern, meaning that it is a very clever and elegant\ncombination of three other design patterns. The three design patterns of\nchoice are External Polymorphism (the key ingredient for achieving the\ndecoupling ef fect and the nonintrusive nature of T ype Erasure; see\n“Guideline 31: Use External Polymorphism for Nonintrusive Runtime\nPolymorphism” ), Bridge (the key to creating a value semantics–based\nimplementation; see “Guideline 28: Build Bridges to Remove Physical\nDependencies ”), and (optionally) Prototype (required to deal with the copy\nsemantics of the resulting values; see “Guideline 30: Apply Prototype for\nAbstract Copy Operations” ). These three design patterns form the core of\nType Erasure, but of course, keep in mind that dif ferent interpretations and\nimplementations exist, mainly to adapt to specific contexts. The point of\ncombining these three design patterns is to create a wrapper type, which\nrepresents a loosely coupled, nonintrusive abstraction.\nTHE TYPE ERASURE COMPOUND DESIGN\nPATTERN\nIntent: “Provide  a value-based, non-intrusive abstraction for an extendable set of\nunrelated, potentially non-polymorphic types with the same semantic behavior .”\nThe purpose of this formulation is to be as short as possible, and as precise\nas necessary . However , every detail of this intent carries meaning. Thus, it\nmay be helpful to elaborate:\nValue-based\nThe intent of T ype Erasure is to create value types that may be\ncopyable, movable, and most importantly , easily reasoned about.\nHowever , such a value type is not of the same quality as a regular  value\ntype; there are some limitations. In particular , Type Erasure works best\nfor unary operations but has its limits for binary operations.\nNonintrusive\nThe intent of T ype Erasure is to create an external, nonintrusive\nabstraction based on the example set by the External Polymorphism\ndesign pattern. All types providing the behavior expected by the\nabstraction are automatically supported, without the need to apply any\nmodifications to them.\nExtendable, unr elated set of types\nType Erasure  is firmly based on object-oriented principles, i.e., it\nenables you to add types easily . These types, though, should not be\nconnected in any way . They do not have to share common behavior via\nsome base class. Instead, it should be possible to add any fitting type,\nwithout any intrusive measure, to this set of types.\nPotentially nonpolymorphic\nAs demonstrated with the External Polymorphism design pattern, types\nshould not have to buy into the set by inheritance. They should also not\nhave to provide virtual functionality on their own, but they should be\ndecoupled from their polymorphic behavior . However , types with base\nclasses or virtual functions are not excluded.\nSame semantic behavior\nThe goal is not to provide an abstraction for all possible types but to\nprovide a semantic abstraction for a set of types that provide the same\noperations (including same syntax) and adhere to some expected\nbehavior , according to the LSP (see “Guideline 6: Adhere to the\nExpected Behavior of Abstractions” ). If possible, for any type that does\nnot provide the expected functionality , a compile-time error should be\ncreated.\nWith this formulation of the intent in mind, let’ s take a look at the\ndependency graph of T ype Erasure (see Figure 8-1 ). The graph should look\nvery familiar , as the structure of the pattern is dominated by the inherent\nstructure of the External Polymorphism design pattern (see Figure 7-8 ). The\nmost important dif ference and addition is the Shape class on the highest\nlevel of the architecture. This class serves as a wrapper around the external\nhierarchy introduced by External Polymorphism. Primarily , since this\nexternal hierarchy will not be used directly anymore, but also to reflect the\nfact that ShapeModel is storing, or “owning,” a concrete type, the name of\nthe class template has been adapted  to OwningShapeModel.",5160
104-An Owning Type Erasure Implementation.pdf,104-An Owning Type Erasure Implementation,"Figur e 8-1. Dependency graph for the T ype Erasur e design pattern\nAn Owning T ype Erasure Implementation\nOK, but  now , with the structure of T ype Erasure in mind, let’ s take a look at\nits implementation details. Still, despite the fact that you’ve seen all the\ningredients in action before, the implementation details are not particularly\nbeginner -friendly and are not for the fainthearted. And that is despite the\nfact that I have picked the simplest Type Erasure implementation I’m aware\nof. Therefore, I will try to keep everything at a reasonable level and not\nstray too much into the realm of implementation details. Among other\nthings, this means that I won’ t try to squeeze out every tiny bit of\nperformance. For instance, I won’ t use forwar ding r eferences  or avoid\ndynamic memory allocations. Also, I will favor readability and code clarity .\nWhile this may be a disappointment to you, I believe that will save us a lot\nof headache. However , if you want to dig deeper into the implementation\ndetails and optimization options, I recommend taking a look at “Guideline\n33: Be A ware of the Optimization Potential of T ype Erasure” .\nWe again start with the Circle and Square classes:\n//---- <Circle.h> ---------------- \n \nclass Circle \n{ \n public: \n   explicit Circle( double radius ) \n      : radius_( radius ) \n   {} \n \n   double radius() const { return radius_; } \n   /* Several more getters and circle-specific utility functions */ \n \n private: \n   double radius_; \n   /* Several more data members */ \n}; \n \n \n//---- <Square.h> ---------------- \n \nclass Square \n{ \n public: \n   explicit Square( double side ) \n      : side_( side ) \n   {} \n \n   double side() const { return side_; } \n   /* Several more getters and square-specific utility functions */ \n \n private: \n   double side_; \n   /* Several more data members */ \n};\nThese two classes have not changed since we last encountered them in the\ndiscussion of External Polymorphism. But it still pays of f to again stress\nthat these two are completely unrelated, do not know about each other , and\n—most importantly—are nonpolymorphic, meaning that they do not inherit\nfrom any base class or introduce virtual function on their own.\nWe have also seen the ShapeConcept and OwningShapeModel classes\nbefore, the latter under the name ShapeModel:\n \n//---- <Shape.h> ---------------- \n \n#include <memory> \n#include <utility> \n \nnamespace detail { \n \nclass ShapeConcept  \n \n{ \n public: \n   virtual ~ShapeConcept() = default; \n   virtual void draw() const = 0;  \n \n   virtual std::unique_ptr<ShapeConcept> clone() const = 0;  \n \n}; \n \ntemplate< typename ShapeT \n        , typename DrawStrategy > \nclass OwningShapeModel : public ShapeConcept  \n \n{ \n public: \n   explicit OwningShapeModel( ShapeT shape, DrawStrategy drawer )  \n \n      : shape_{ std::move(shape) } \n      , drawer_{ std::move(drawer) } \n   {} \n \n   void draw() const override { drawer_(shape_); }  \n \n \n   std::unique_ptr<ShapeConcept> clone() const override \n   { \n      return std::make_unique<OwningShapeModel>( *this );  \n \n   } \n \n private: \n   ShapeT shape_;  \n \n   DrawStrategy drawer_;  \n \n}; \n \n} // namespace detail \nNext to the name change, there are a couple of other , important dif ferences.\nFor instance, both classes have been moved to the detail namespace. The\nname of the namespace indicates that these two classes are now becoming\nimplementation details, i.e., they are not intended for direct use anymore.\nThe ShapeConcept class (\n ) still introduces the pure virtual function\ndraw() to represent the requirement for drawing a shape (\n ). In addition,\nShapeConcept now also introduces a pure virtual clone() function (\n ). “I\nknow what this is, this is the Prototype design pattern!” you exclaim. Y es,\ncorrect. The name clone() is very strongly connected to Prototype and is a\nstrong indication of this design pattern (but not a guarantee). However ,\nalthough the choice of the function name is very reasonable and canonical,\nallow me to point out explicitly that the choice of the function name for\nclone(), and also for draw(), is our own: these names are now\nimplementation details and do not have any relationship to the names that\nwe require from our ShapeT types. W e could as well name them do_draw()\nand do_clone(), and it would not have any consequence on the ShapeT\ntypes. The real requirement on the ShapeT types is defined by the\nimplementation  of the draw() and clone() functions.6\nAs ShapeConcept is again the base class for the external hierarchy , the\ndraw() function, the clone() function, and the destructor represent the set\nof requirements for all kinds of shapes. This means that all shapes must\nprovide some drawing behavior—they  must be copyable and destructible.\nNote that these three functions are only requirement choices for this\nexample. In particular , copyability is not a general requirement for all\nimplementations of T ype Erasure.\nThe OwningShapeModel class (\n ) again represents the one and only\nimplementation of the ShapeConcept class. As before, OwningShapeModel\ntakes a concrete shape type and a drawing Strategy in its constructor (\n )\nand uses these to initialize its two data members (\n  and \n ). Since\nOwningShapeModel inherits from ShapeConcept, it must implement the\ntwo pure virtual functions. The draw() function is implemented by\napplying the given drawing Strategy (\n ), while the clone() function is\nimplemented to return an exact copy of the corresponding\nOwningShapeModel (\n).\nNOTE\nIf you’re right now thinking, “Oh no, std::make_unique(). That means dynamic\nmemory . Then I can’ t use that in my code!”—don’ t worry . std::make_unique() is\nmerely an implementation detail, a choice to keep the example simple. In “Guideline 33:\nBe A ware of the Optimization Potential of T ype Erasure” , you will see how  to avoid\ndynamic memory with the SBO.\n“I’m pretty unimpressed so far . We’ve barely moved beyond the\nimplementation of the External Polymorphism design pattern.” I completely\nunderstand the criticism. However , we are just one step away from turning\nExternal Polymorphism into T ype Erasure, just one step away from\nswitching from reference semantics to value semantics. All we need is a\nvalue type, a wrapper around the external hierarchy introduced by\nShapeConcept and OwningShapeModel, that handles all the details that we\ndon’t want to perform manually: the instantiation of the OwningShapeModel\nclass template, managing pointers, performing allocations, and dealing with\nlifetime. This wrapper is given in the form of the Shape class:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nclass Shape \n{ \n public: \n   template< typename ShapeT \n           , typename DrawStrategy > \n   Shape( ShapeT shape, DrawStrategy drawer )  \n \n   { \n      using Model = detail::OwningShapeModel<ShapeT,DrawStrategy>;  \n \n      pimpl_ = std::make_unique<Model>( std::move(shape)  \n \n                                      , std::move(drawer) ); \n   } \n \n   // ... \n \n private: \n   // ... \n \n   std::unique_ptr<detail::ShapeConcept> pimpl_;  \n \n}; \nThe first, and perhaps most important, detail about the Shape class is the\ntemplated constructor (\n ). As the first ar gument, this constructor takes any\nkind of shape (called ShapeT), and as the second ar gument, the desired\nDrawStrategy. To simplify the instantiation of the corresponding\ndetail::OwningShapeModel class template, it proves to be helpful to use a\nconvenient type alias (\n ). This alias is used to instantiate the required model\nby std::make_unique() (\n). Both the shape and the drawing Strategy are\npassed to the new model.\nThe newly created model is used to initialize the one data member of the\nShape class: the pimpl_ (\n). “I recognize this one, too; this is a Bridge!”\nyou happily announce. Y es, correct again. This is an application of the\nBridge design pattern. In the construction, we create a concrete\nOwningShapeModel based on the actual given types ShapeT and\nDrawStrategy, but we store it as a pointer to ShapeConcept. By doing this\nyou create a Bridge to the implementation details, a Bridge to the real shape\ntype. However , after the initialization of pimpl_, after the constructor is\nfinished, Shape doesn’ t remember the actual type. Shape does not have a\ntemplate parameter or any member function that would reveal the concrete\ntype it stores, and there is no data member that remembers the given type.\nAll it holds is a pointer to the ShapeConcept base class. Thus, its memory\nof the real shape type has been erased. Hence the name of the design\npattern: T ype Erasure.\nThe only thing missing in our Shape class is the functionality required for a\ntrue value type:  the copy and move operations. Luckily , due to the\napplication of std::unique_ptr, our ef fort is pretty limited. Since the\ncompiler -generated destructor and the two move operations will work, we\nonly need to deal with the two copy operations:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nclass Shape \n{ \n public: \n   // ... \n \n   Shape( Shape const& other )  \n \n      : pimpl_( other.pimpl_->clone() ) \n   {} \n \n   Shape& operator=( Shape const& other )  \n \n   { \n      // Copy-and-Swap Idiom \n      Shape copy( other ); \n      pimpl_.swap( copy.pimpl_ ); \n      return *this; \n   } \n \n   ~Shape() = default; \n   Shape( Shape&& ) = default; \n   Shape& operator=( Shape&& ) = default; \n \n private: \n   friend void draw( Shape const& shape )  \n \n   { \n      shape.pimpl_->draw(); \n   } \n \n   // ... \n}; \nThe copy constructor (\n ) could be a very dif ficult function to implement,\nsince we do not know the concrete type of shape stored in the other Shape.\nHowever , by providing the clone() function in the ShapeConcept base\nclass, we can ask for an exact copy without needing to know anything about\nthe concrete type. The shortest, most painless, and most convenient way to\nimplement the copy assignment operator (\n ) is to build on the Copy-and-\nSwap idiom .\nIn addition, the Shape class provides a so-called hidden friend called\ndraw() (\n). This friend function is called a hidden friend , since although\nit’s a free function, it is defined within the body of the Shape class. As a\nfriend, it’s granted full access to the private data member and will be\ninjected into the surrounding namespace.\n“Didn’ t you say that friends are bad?” you ask. I admit, that’ s what I said\nin “Guideline 4: Design for T estability” . However , I also explicitly stated\nthat hidden friends are OK. In this case, the draw() function is an integral\npart of the Shape class and definitely a real friend (almost part of the\nfamily). “But then it should be a member function, right?” you ar gue.\nIndeed, that would be a valid alternative. If you like this better , go for it. In\nthis case, my preference is to use a free function, since one of our goals was\nto reduce dependencies by extracting the draw() operation. This goal\nshould also be reflected in the Shape implementation. However , since the\nfunction requires access to the pimpl_ data member , and in order to not\nincrease the overload set of draw() functions, I implement it as a hidden\nfriend.\nThis is it. All of it. Let’ s take a look at how beautifully the new\nfunctionality works:\n \n//---- <Main.cpp> ---------------- \n \n#include <Circle.h> \n#include <Square.h> \n#include <Shape.h> \n#include <cstdlib> \n \nint main() \n{ \n   // Create a circle as one representative of a concrete shape type \n   Circle circle{ 3.14 }; \n \n   // Create a drawing strategy in the form of a lambda \n   auto drawer = []( Circle const& c ){ /*...*/ }; \n \n   // Combine the shape and the drawing strategy in a 'Shape' abstraction \n   // This constructor call will instantiate a 'detail::OwningShapeModel' for \n   // the given 'Circle' and lambda types \n   Shape shape1( circle, drawer ); \n \n   // Draw the shape \n   draw( shape1 );  \n \n \n   // Create a copy of the shape by means of the copy constructor \n   Shape shape2( shape1 ); \n \n   // Drawing the copy will result in the same output \n   draw( shape2 );  \n \n \n   return EXIT_SUCCESS; \n} \nWe first create shape1 as an abstraction for a Circle and an associated\ndrawing Strategy . This feels easy , right? There’ s no need to manually\nallocate and no need to deal with pointers. W ith the draw() function, we’re\nable to draw this Shape (\n). Directly afterward, we create a copy of the\nshape. A real copy—a “deep copy ,” not just the copy of a pointer . Drawing\nthe copy with the draw() function will result in the same output (\n ). Again,\nthis feels good: you can rely on the copy operations of the value type (in\nthis case, the copy constructor), and you do not have to clone() manually .\nPretty amazing, right? And definitely much better than using External\nPolymorphism manually . I admit that after all these implementation details,\nit may be a little hard to see it right away , but if you step through the jungle\nof implementation details, I hope you realize the beauty of this approach:\nyou no longer have to deal with pointers, there are no manual allocations,\nand you don’ t have to deal with inheritance hierarchies anymore. All of\nthese details are there, yes, but all evidence is nicely encapsulated within\nthe Shape class. Still, you didn’ t lose any of the decoupling benefits: you\nare still able to easily add new types, and the concrete shape types are still\noblivious about the drawing behavior . They are only connected to the\ndesired functionality via the Shape constructor .\n“I’m wondering,” you begin to ask, “Couldn’ t we make this much easier? I\nenvision a main() function that looks like this”:\n//---- <YourMain.cpp> ---------------- \n \nint main() \n{ \n   // Create a circle as one representative of a concrete shape type \n   Circle circle{ 3.14 }; \n \n   // Bind the circle to some drawing functionality \n   auto drawingCircle = [=]() { myCircleDrawer(circle); }; \n \n   // Type-erase the circle equipped with drawing behavior \n   Shape shape( drawingCircle ); \n \n   // Drawing the shape \n   draw( shape ); \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\nThat is a great idea. Remember , you are in char ge of all the implementation\ndetails of the T ype Erasure wrapper and how to bring together types and",14515
105-Comparing Two Type Erasure Wrappers.pdf,105-Comparing Two Type Erasure Wrappers,"their operation implementation. If you like this form better , go for it!\nHowever , please do not for get that in our Shape example, for the sake of\nsimplicity and code brevity , I have deliberately used only a single\nfunctionality with external dependencies (drawing). There could be more\nfunctions that introduce dependencies, such as the serialization of shapes. In\nthat case, the lambda approach would not work, as you would need\nmultiple, named functions (e.g., draw() and serialize()). So, ultimately ,\nit depends. It depends on what kind of abstraction your T ype Erasure\nwrapper represents. But whatever implementation you prefer , just make\nsure that you do not introduce artificial dependencies  between the dif ferent\npieces of functionality and/or code duplication. In other words, remember\n“Guideline 2: Design for Change” ! That is the reason I favored the solution\nbased on the Strategy design pattern, which you, however , shouldn’ t\nconsider the true and only solution. On the contrary , you should strive to\nfully exploit the potential of the loose coupling of T ype Erasure.\nAnalyzing the Shortcomings of the T ype Erasure Design\nPattern\nDespite  the beauty of T ype Erasure and the lar ge number of benefits that\nyou acquire, especially from a design perspective, I don’ t pretend that there\nare no downsides to this design pattern. No, it wouldn’ t be fair to keep\npotential disadvantages from you.\nThe first, and probably most obvious, drawback for you might be the\nimplementation complexity of this pattern. As stated before, I have\nexplicitly kept the implementation details at a reasonable level, which\nhopefully helped you to get the idea. I hope I have also given you the\nimpression that it is not so difficult after all: a basic implementation of T ype\nErasure can be realized within approximately 30 lines of code. Still, you\nmight feel that it is too complex. Also, as soon as you start to go beyond the\nbasic implementation and consider performance, exception safety , etc., the\nimplementation details indeed become quite tricky very quickly . In these\ncases, your safest and most convenient option is to use a third-party library\ninstead of dealing with all of these details yourself. Possible libraries\ninclude the dyno  library  from Louis Dionne, the zoo library  from Eduardo\nMadrid, the erasur e library  from Gašper Ažman, and the Boost T ype\nErasur e library from Steven W atanabe.\nIn the explanation of the intent of T ype Erasure, I mentioned the second\ndisadvantage, which is much more important and limiting: although we are\nnow dealing with values that can be copied and moved, using T ype Erasure\nfor binary operations is not straightforward. For instance, it is not easily\npossible to do an equality comparison on these values, as you would expect\nfrom regular values:\nint main() \n{ \n   // ... \n \n   if( shape1 == shape2 ) { /*...*/ }  // Does not compile! \n \n   return EXIT_SUCCESS; \n}\nThe reason is that, after all, Shape is only an abstraction from a concrete\nshape type and only stores a pointer -to-base. As you would deal with\nexactly the same problem if you used External Polymorphism directly , this\nis definitely not a new problem in T ype Erasure, and you might not even\ncount this as a real disadvantage. Still, while equality comparison is not an\nexpected operation when you’re dealing with pointers-to-base, it usually is\nan expected operation on values.\nComparing T wo T ype Erasure W rappers\n“Isn’ t this just a question of exposing the necessary functionality in the\ninterface of Shapes?” you wonder . “For instance, we could simply add an\narea() function to the public interface of shapes and use it to compare\ntwo items”:\nbool operator==( Shape const& lhs, Shape const& rhs ) \n{ \n   return lhs.area() == rhs.area(); \n}\n“This is easy to do. So what am I missing?” I agree that this might be all\nyou need: if two objects are equal if some public properties are equal, then\nthis operator will work for you. In general, the answer would have to be “it\ndepends.” In this particular case, it depends on the semantics of the\nabstraction that the Shape class represents. The question is: when are two\nShapes equal? Consider the following example with a Circle and a\nSquare:\n#include <Circle.h> \n#include <Square.h> \n#include <cstdlib> \n \nint main() \n{ \n   Shape shape1( Circle{3.14} ); \n   Shape shape2( Square{2.71} ); \n \n   if( shape1 == shape2 ) { /*...*/ } \n \n   return EXIT_SUCCESS; \n}\nWhen are these two Shapes equal? Are they equal if their areas are equal, or\nare they equal if the instances behind the abstraction are equal, meaning that\nboth Shapes are of the same type and have the same properties? It depends.\nIn the same spirit, I could ask the question, when are two Persons equal?\nAre they equal if their first names are equal? Or are they equal if all of their\ncharacteristics are equal? It depends on the desired semantics. And while\nthe first comparison is easily done, the second one is not. In a general case,\nI assume that the second situation is far more likely to be the desired\nsemantics, and therefore I ar gue that using T ype Erasure for equality\ncomparison and more generally for binary operations is not straightforward.\nNote, however , that I did not say that equality comparison is impossible.\nTechnically , you can make it work, although it turns out to be a rather ugly\nsolution. Therefore, you have to promise not to tell anyone that you got this\nidea from me. “Y ou just made me even more curious,” you smile\nwhimsically . OK, so here it is:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nnamespace detail { \n \nclass ShapeConcept \n{ \n public: \n   // ... \n   virtual bool isEqual( ShapeConcept const* c ) const = 0; \n}; \n \ntemplate< typename ShapeT \n        , typename DrawStrategy > \nclass OwningShapeModel : public ShapeConcept \n{ \n public: \n   // ... \n \n   bool isEqual( ShapeConcept const* c ) const override \n   { \n      using Model = OwningShapeModel<ShapeT,DrawStrategy>; \n      auto const* model = dynamic_cast<Model const*>( c );  \n \n      return ( model && shape_ == model->shape_ ); \n   } \n \n private: \n   // ... \n}; \n \n} // namespace detail \n \n \nclass Shape \n{ \n   // ... \n \n private: \n   friend bool operator==( Shape const& lhs, Shape const& rhs ) \n   { \n      return lhs.pimpl_->isEqual( rhs.pimpl_.get() ); \n   } \n \n   friend bool operator!=( Shape const& lhs, Shape const& rhs ) \n   { \n      return !( lhs == rhs ); \n   } \n \n   // ... \n}; \n \n \n//---- <Circle.h> ---------------- \n \nclass Circle \n{ \n   // ... \n}; \n \nbool operator==( Circle const& lhs, Circle const& rhs ) \n{ \n   return lhs.radius() == rhs.radius(); \n} \n \n \n//---- <Square.h> ---------------- \n \nclass Square \n{ \n   // ... \n}; \n \nbool operator==( Square const& lhs, Square const& rhs ) \n{ \n   return lhs.side() == rhs.side(); \n} \nTo make equality comparison work, you could use a dynamic_cast (\n).\nHowever , this implementation of equality comparison holds two severe\ndisadvantages. First, as you saw in “Guideline 18: Beware the Performance\nof Acyclic V isitor” , a dynamic_cast does most certainly not count as a fast\noperation. Hence, you would have to pay a considerable runtime cost for\nevery comparison. Second, in this implementation, you can only\nsuccessfully compare two Shapes if they are equipped with the same\nDrawStrategy. While this might be reasonable in one context, it might also",7558
106-Performance Benchmarks.pdf,106-Performance Benchmarks,"be considered an unfortunate limitation in another context. The only\nsolution I am aware of is to return to std::function to store the drawing\nStrategy , which, however , would result in another performance penalty . In\nsummary , depending on the context, equality comparison may be possible,\nbut it’ s usually neither easy nor cheap to accomplish. This is evidence to my\nearlier statement that T ype Erasure doesn’ t support binary operations.\nInterface Segregation of T ype Erasure W rappers\n“What about  the Interface Segregation Principle (ISP)?” you ask. “While\nusing External Polymorphism, it was easy to separate concerns in the base\nclass. It appears we’ve lost this ability , right?” Excellent question. So you\nremember my example with the JSONExportable and Serializable base\nclasses in “Guideline 31: Use External Polymorphism for Nonintrusive\nRuntime Polymorphism” . Indeed, with T ype Erasure we are no longer able\nto use the hidden base class, only the abstracting value type. Therefore, it\nmay appear as if the ISP is out of reach:\nclass Document  // Type-erased 'Document' \n{ \n public: \n   // ... \n   void exportToJSON( /*...*/ ) const; \n   void serialize( ByteStream& bs, /*...*/ ) const; \n   // ... \n}; \n \n// Artificial coupling to 'ByteStream', although only the JSON export is \nneeded \nvoid exportDocument( Document const& doc ) \n{ \n   // ... \n   doc.exportToJSON( /* pass necessary arguments */ ); \n   // ... \n}\nHowever , fortunately , this impression is incorrect. Y ou can easily adhere to\nthe ISP  by providing several type-erased abstractions:7\n8\nDocument doc = /*...*/;  // Type-erased 'Document' \ndoc.exportToJSON( /* pass necessary arguments */ ); \ndoc.serialize( /* pass necessary arguments */ ); \n \nJSONExportable jdoc = doc;  // Type-erased 'JSONExportable' \njdoc.exportToJSON( /* pass necessary arguments */ ); \n \nSerializable sdoc = doc;  // Type-erased 'Serializable' \nsdoc.serialize( /* pass necessary arguments */ );\nBefore considering this, take a look at “Guideline 34: Be A ware of the\nSetup Costs of Owning Type Erasure W rappers ”.\n“Apart from the implementation complexity and the restriction to unary\noperations, there seem to be no disadvantages. W ell, then, I have to say this\nis amazing stuf f indeed! The benefits clearly outweigh the drawbacks.”\nWell, of course it always depends, meaning that in a specific context some\nof these issues might cause some pain. But I agree that, altogether , Type\nErasure proves to be a very valuable design pattern. From a design\nperspective, you’ve gained a formidable level of decoupling, which will\ndefinitely lead to less pain when changing or extending your software.\nHowever , although this is already fascinating, there’ s more. I’ve mentioned\nperformance  a couple of times but haven’ t yet shown any performance\nnumbers. So let’ s take a look at the performance results.\nPerformance Benchmarks\nBefore  showing you the performance results for T ype Erasure, let me\nremind you about the benchmark scenario that we also used to benchmark\nthe V isitor and Strategy solutions (see Table 4-2  in “Guideline 16: Use\nVisitor to Extend Operations”  and Table 5-1  in “Guideline 23: Prefer a\nValue-Based Implementation of Strategy and Command” ). This time I have\nextended the benchmark with a T ype Erasure solution based on the\nOwningShapeModel implementation. For the benchmark, we are still using\nfour dif ferent kinds of shapes (circles, squares, ellipses, and rectangles).\nAnd again, I’m running 25,000 translate operations on 10,000 randomly\ncreated shapes. I use both GCC 1 1.1 and Clang 1 1.1, and for both\ncompilers, I’m adding only the -O3 and -DNDEBUG compilation flags. The\nplatform I’m using is macOS Big Sur (version 1 1.4) on an 8-Core Intel\nCore i7 with 3.8 GHz, 64 GB of main memory .\nTable 8-1  shows the performance numbers. For your convenience, I\nreproduced the performance results from the Strategy benchmarks. After\nall, the Strategy design pattern is the solution that is aiming at the same\ndesign space. The most interesting line, though, is the last line. It shows the\nperformance result for the Type Erasure design pattern.\nTable 8-1. Performance r esults for the T ype Erasur e\nimplementations\nType Erasure implementation GCC 1 1.1 Clang 1 1.1\nObject-oriented solution 1.5205 s 1.1480 s\nstd::function 2.1782 s 1.4884 s\nManual implementation of std::function1.6354 s 1.4465 s\nClassic Strategy 1.6372 s 1.4046 s\nType Erasure 1.5298 s 1.1561 s\n“Looks very interesting. T ype Erasure seems to be pretty fast. Apparently\nonly the object-oriented solution is faster .” Yes. For Clang, the performance\nof the object-oriented solution is a little better . But only a little. However ,\nplease remember that the object-oriented solution does not decouple\nanything: the draw() function is implemented as a virtual member function\nin the Shape hierarchy , and thus you experience heavy coupling to the\ndrawing functionality . While this may come with little performance\noverhead, from a design perspective, this is a worst-case scenario. Taking\nthis into account, the performance numbers of T ype Erasure are truly\nmarvelous: it performs between 6% and 20% better than any Strategy\nimplementation. Thus, T ype Erasure not only provides the strongest\ndecoupling but also performs better than all the other attempts to reduce\ncoupling.9",5428
107-Small Buffer Optimization.pdf,107-Small Buffer Optimization,"A Word About T erminology\nIn summary , Type Erasure is an amazing approach to achieve both ef ficient\nand loosely coupled code. While it may have a few limitations and\ndisadvantages, the one thing you probably cannot ignore easily is the\ncomplex implementation details. For that reason, many people, including\nme and Eric Niebler , feel that T ype Erasure should become a language\nfeature:\nIf I could go back in time and had the power to change C++, rather than\nadding virtual functions, I would add language support for type erasur e\nand concepts. Define a single-type concept, automatically generate a\ntype-erasing wrapper for it.\nThere is more to be done, though, to establish T ype Erasure as a real design\npattern. I have introduced T ype Erasure as a compound design pattern built\nfrom External Polymorphism, Bridge, and Prototype. I’ve introduced it as a\nvalue-based technique for providing strong decoupling of a set of types\nfrom their associated operations. However , unfortunately , you might see\nother “forms” of T ype Erasure: over time, the term Type Erasur e has been\nmisused and abused for all kinds of techniques and concepts. For instance,\nsometimes people refer to a void* as Type Erasure. Rarely , you also hear\nabout T ype Erasure in the context of inheritance hierarchies, or more\nspecifically a pointer -to-base. And finally , you also might hear about T ype\nErasure in the context of std::variant.\nThe std::variant example especially demonstrates how deeply flawed\nthis overuse of the term Type Erasur e really is. While External\nPolymorphism, the main design pattern behind T ype Erasure, is about\nenabling you to add new types, the V isitor design pattern and its modern\nimplementation as std::variant are about adding new operations (see\n“Guideline 15: Design for the Addition of Types or Operations ”). From a\nsoftware design perspective, these two solutions are completely orthogonal\nto each other: while T ype Erasure truly decouples from concrete types and\nerases type information, the template ar guments of std::variant reveal all\npossible alternatives and therefore make you depend on these types. Using10\n1 1\nthe same term for both of them results in exactly zero information conveyed\nwhen using the term Type Erasur e and generates these types of comments:\n“I would suggest we use T ype Erasure to solve this problem.” “Could you\nplease be more specific? Do you want to add types or operations?” As such,\nthe term would not fulfill the qualities of a design pattern; it wouldn’ t carry\nany intent. Therefore, it would be useless.\nTo give T ype Erasure its well-earned place in the hall of design patterns and\nto give it any meaning, consider using the term only for the intent discussed\nin this guideline.\nGUIDELINE 32: CONSIDER REPLACING INHERITANCE\nHIERARCHIES WITH TYPE ERASURE\nApply the T ype Erasure design pattern with the intent to provide a\nvalue-based, nonintrusive abstraction for an extendable set of\nunrelated, potentially nonpolymorphic types with the same\nsemantic behavior .\nConsider T ype Erasure as a compound design pattern, built from\nthe External Polymorphism, Bridge, and Prototype design patterns.\nUnderstand the advantages of T ype Erasure, but also keep in mind\nits limitations.\nUse the term T ype Erasure only to communicate its intent as a\ndesign pattern that allows the easy addition of types supporting a\nfixed set of operations.\nGuideline 33: Be Aware of the Optimization\nPotential of Type Erasure\nThe primary focus of this book is software design. Therefore, all this talk\nabout structuring software, about design principles, about tools for\nmanaging dependencies and abstractions, and, of course, all the information\non design patterns is at the center of interest. Still, I’ve mentioned a few\ntimes that performance is important. Very important! After all, C++ is a\nperformance-centric programming language. Therefore, I now make an\nexception: this guideline is devoted to performance. Y es, I’m serious: no\ntalk about dependencies, (almost) no examples for separation of concerns,\nno value semantics. Just performance. “Finally , some performance stuf f—\ngreat!” you cheer . However , be aware of the consequences: this guideline is\npretty heavy on implementation details. And as it is in C++, mentioning one\ndetail requires you to also deal with two more details, and so you are pretty\nquickly sucked into the realm of implementation details. T o avoid that (and\nto keep my publisher happy), I will not elaborate on every implementation\ndetail or demonstrate all the alternatives. I will, however , give additional\nreferences that should help you to dig deeper .\nIn “Guideline 32: Consider Replacing Inheritance Hierarchies with T ype\nErasure” , you saw great performance numbers for our basic, unoptimized\nType Erasure implementation. However , since we are now in possession of\na value type and a wrapper class, not just a pointer , we have gained a\nmultitude of opportunities to speed up performance. This is why we will\ntake a look at two options to improve performance: the SBO and manual\nvirtual dispatch.\nSmall Buffer Optimization\nLet’s start our quest to speed up the performance of our T ype Erasure\nimplementation. One of the first things that usually comes to mind when\ntalking about performance is optimizing memory allocations. This is\nbecause acquiring and freeing dynamic memory can be very slooowww  and\nnondeterministic. And for real: optimizing memory allocations can make all\nthe dif ference between slow and lightning fast.\nHowever , there is a second reason to look into memory . In “Guideline 32:\nConsider Replacing Inheritance Hierarchies with T ype Erasure” , I might\nhave accidentally given you the impression that we need dynamic memory\nto pull of f Type Erasure. Indeed, one of the initial implementation details in12\nour first Shape class was the unconditional dynamic memory allocation in\nthe constructor and clone() function, independent of the size of the given\nobject, so for both small and lar ge objects, we would always perform a\ndynamic memory allocation with std::make_unique(). This choice is\nlimiting, not just because of performance, in particular for small objects, but\nalso because in certain environments dynamic memory is not available.\nTherefore, I should demonstrate to you that there’ s a lot you can do with\nrespect to memory . In fact, you are in full control of memory management!\nSince you are using a value type, a wrapper , you can deal with memory in\nany way you see fit. One of the many options is to completely rely on in-\nclass memory and emit a compile-time error if objects are too lar ge.\nAlternatively , you might switch between in-class and dynamic memory ,\ndepending on the size of the stored object. Both of these are made possible\nby the SBO.\nTo give you an idea of how SBO works, let’ s take a look at a Shape\nimplementation that never allocates dynamically but uses only in-class\nmemory:\n \n#include <array> \n#include <cstdlib> \n#include <memory> \n \ntemplate< size_t Capacity = 32U, size_t Alignment = alignof(void*) >  \n \nclass Shape \n{ \n public: \n   // ... \n \n private: \n   // ... \n \n   Concept* pimpl()  \n \n   { \n      return reinterpret_cast<Concept*>( buffer_.data() ); \n   } \n \n   Concept const* pimpl() const  \n \n   { \n      return reinterpret_cast<Concept const*>( buffer_.data() ); \n   } \n \n   alignas(Alignment) std::array<std::byte,Capacity> buffer_;  \n \n}; \nThis Shape class does not store std::unique_ptr anymore, but instead\nowns an array of properly aligned bytes (\n ). To give users of Shape the\nflexibility to adjust both the capacity and the alignment of the array , you\ncan provide the two nontype template parameters, Capacity and\nAlignment, to the Shape class (\n ). While this improves the flexibility to\nadjust to dif ferent circumstances, the disadvantage of that approach is that\nthis turns the Shape class into a class template. As a consequence, all\nfunctions that use this abstraction will likely turn into function templates.\nThis may be undesirable, for instance, because you might have to move\ncode from source files into header files. However , be aware that this is just\none of many possibilities. As stated before, you are in full control.\nTo conveniently work with the std::byte array , we add a pair of pimpl()\nfunctions (named based on the fact that this still realizes the Bridge design\npattern, just using in-class memory) (\n  and \n ). “Oh no, a\nreinterpret_cast!” you say . “Isn’ t this super dangerous?” Y ou are\ncorrect; in general, a reinterpret_cast should be considered potentially\ndangerous. However , in this particular case, we are backed up by the C++\nstandard , which explains that what we are doing here is perfectly safe.\nAs you probably expect by now , we also need to introduce an external\ninheritance hierarchy based on the External Polymorphism design pattern.\nThis time we realize this hierarchy in the private section of the Shape\nclass. Not because this is better or more suited for this Shape\nimplementation, but for the sole reason to show you another alternative:\n \ntemplate< size_t Capacity = 32U, size_t Alignment = alignof(void*) > \nclass Shape \n{ \n public: \n   // ... \n \n private: 13\n14\n   struct Concept \n   { \n      virtual ~Concept() = default; \n      virtual void draw() const = 0; \n      virtual void clone( Concept* memory ) const = 0;  \n \n      virtual void move( Concept* memory ) = 0;  \n \n   }; \n \n   template< typename ShapeT, typename DrawStrategy > \n   struct OwningModel : public Concept \n   { \n      OwningModel( ShapeT shape, DrawStrategy drawer ) \n         : shape_( std::move(shape) ) \n         , drawer_( std::move(drawer) ) \n      {} \n \n      void draw() const override \n      { \n         drawer_( shape_ ); \n      } \n \n      void clone( Concept* memory ) const override  \n \n      { \n         std::construct_at( static_cast<OwningModel*>(memory), *this ); \n \n         // or: \n         // auto* ptr = \n         //    const_cast<void*>(static_cast<void const volatile*>(memory)); \n         // ::new (ptr) OwningModel( *this ); \n      } \n \n      void move( Concept* memory ) override  \n \n      { \n         std::construct_at( static_cast<OwningModel*>(memory), \nstd::move(*this) ); \n \n         // or: \n         // auto* ptr = \n         //    const_cast<void*>(static_cast<void const volatile*>(memory)); \n         // ::new (ptr) OwningModel( std::move(*this) ); \n      } \n \n      ShapeT shape_; \n      DrawStrategy drawer_; \n   }; \n \n   // ... \n \n   alignas(Alignment) std::array<std::byte,Capacity> buffer_; \n}; \nThe first interesting detail in this context is the clone() function (\n ). As\nclone() carries the responsibility of creating a copy , it needs to be adapted\nto the in-class memory . So instead of creating a new Model via\nstd::make_unique(), it creates a new Model in place via\nstd::construct_at(). Alternatively , you could use a placement new to\ncreate the copy at the given memory location.\n“Wow, wait a second! That’ s a pretty tough piece of code to swallow .\nWhat’ s with all these casts? Are they really necessary?” I admit, these lines\nare a little challenging. Therefore, I should explain them in detail. The good\nold approach to creating an instance in place is via placement new.\nHowever , using new always carries the danger of someone (inadvertently or\nmaliciously) providing a replacement for the class-specific new operator . To\navoid any kind of problem and reliably construct an object in place, the\ngiven address is first converted to void const volatile* via a\nstatic_cast and then to void* via a const_cast. The resulting address is\npassed to the global placement new operator . Indeed, not the most obvious\npiece of code. Therefore, it is advisable to use the C++20 algorithm\nstd::construct_at(): it provides you with exactly the same functionality\nbut with a significantly nicer syntax.\nHowever , we need one more function: clone() is concerned only with\ncopy operations. It doesn’ t apply to move operations. For that reason, we\nextend the Concept with a pure virtual move() function and consequently\nimplement it in the OwningModel class template (\n ).\n“Is this really necessary? W e’re using in-class memory , which cannot be\nmoved  to another instance of Shape. What’ s the point of that move()?”\nWell, you are correct that we can’ t move the memory itself from one object\nto another , but we can still move the shape stored inside. Thus, the move()\nfunction moves an OwningModel from one buf fer to another instead of\ncopying it.15\nThe clone() and move() functions are used in the copy constructor (\n ), the\ncopy assignment operator (\n ), the move constructor (\n ), and the move\nassignment operator of Shape (\n):\n \ntemplate< size_t Capacity = 32U, size_t Alignment = alignof(void*) > \nclass Shape \n{ \n public: \n   // ... \n \n   Shape( Shape const& other ) \n   { \n      other.pimpl()->clone( pimpl() );  \n \n   } \n \n   Shape& operator=( Shape const& other ) \n   { \n      // Copy-and-Swap Idiom \n      Shape copy( other );  \n \n      buffer_.swap( copy.buffer_ ); \n      return *this; \n   } \n \n   Shape( Shape&& other ) noexcept \n   { \n      other.pimpl()->move( pimpl() );  \n \n   } \n \n   Shape& operator=( Shape&& other ) noexcept \n   { \n      // Copy-and-Swap Idiom \n      Shape copy( std::move(other) );  \n \n      buffer_.swap( copy.buffer_ ); \n      return *this; \n   } \n \n   ~Shape()  \n \n   { \n      std::destroy_at( pimpl() ); \n      // or: pimpl()->~Concept(); \n   } \n \n private: \n   // ... \n \n   alignas(Alignment) std::array<std::byte,Capacity> buffer_; \n}; \nDefinitely noteworthy to mention is the destructor of Shape (\n). Since we\nmanually create an OwningModel within the byte buf fer by\nstd::construct_at() or a placement new, we are also responsible for\nexplicitly calling a destructor . The easiest and most elegant way of doing\nthat is to use the C++17 algorithm std::destroy_at(). Alternatively , you\ncan explicitly call the Concept destructor .\nThe last, but essential, detail of Shape is the templated constructor:\ntemplate< size_t Capacity = 32U, size_t Alignment = alignof(void*) > \nclass Shape \n{ \n public: \n   template< typename ShapeT, typename DrawStrategy > \n   Shape( ShapeT shape, DrawStrategy drawer ) \n   { \n      using Model = OwningModel<ShapeT,DrawStrategy>; \n \n      static_assert( sizeof(Model) <= Capacity, ""Given type is too large"" ); \n      static_assert( alignof(Model) <= Alignment, ""Given type is misaligned"" \n); \n \n      std::construct_at( static_cast<Model*>(pimpl()) \n                       , std::move(shape), std::move(drawer) ); \n      // or: \n      // auto* ptr = \n      //    const_cast<void*>(static_cast<void const volatile*>(pimpl())); \n      // ::new (ptr) Model( std::move(shape), std::move(drawer) ); \n   } \n \n   // ... \n \n private: \n   // ... \n};\nAfter a pair of compile-time checks that the required OwningModel fits into\nthe in-class buf fer and adheres to the alignment restrictions, an\nOwningModel is instantiated into the in-class buf fer by\nstd::construct_at().\nWith this implementation in hand, we now adapt and rerun the performance\nbenchmark from “Guideline 32: Consider Replacing Inheritance\nHierarchies with T ype Erasure” . We run exactly the same benchmark, this\ntime without allocating dynamic memory inside Shape and without\nfragmenting the memory with many , tiny allocations. As expected, the\nperformance results are impressive  (see Table 8-2 ).\nTable 8-2. Performance r esults for the T ype Erasur e\nimplementations with SBO\nType Erasure implementation GCC 1 1.1 Clang 1 1.1\nObject-oriented solution 1.5205 s 1.1480 s\nstd::function 2.1782 s 1.4884 s\nManual implementation of std::function1.6354 s 1.4465 s\nClassic Strategy 1.6372 s 1.4046 s\nType Erasure 1.5298 s 1.1561 s\nType Erasure (SBO) 1.3591 s 1.0348 s\n“Wow, this is fast. This is…well, let me do the math…amazing, roughly\n20% faster than the fastest Strategy implementation, and even faster than\nthe object-oriented solution.” It is, indeed. V ery impressive, right? Still, you\nshould remember that these are the numbers that I got on my system. Y our\nnumbers will be dif ferent, almost certainly . But even though your numbers\nmight not be the same, the general takeaway is that there is a lot of potential\nto optimize performance by dealing with memory allocations.\nHowever , while the performance is extraordinary , we’ve lost a lot of\nflexibility: only OwningModel instantiations that are smaller or equal to the\nspecified Capacity can be stored inside Shape. Bigger models are\nexcluded. This brings me back to the idea that we could switch between in-\nclass and dynamic memory depending on the size of the given shape: small\nshapes are stored inside an in-class buf fer, while lar ge shapes are allocated\ndynamically . You could now go ahead and update the implementation of\nShape to use both kinds of memory . However , at this point it’ s probably a\ngood idea to point out one of our most important design principles again:\nseparation of concerns. Instead of squeezing all logic and functionality into\nthe Shape class, it would be easier and (much) more flexible to separate the\nimplementation details and implement Shape with policy-based design (see\n“Guideline 19: Use Strategy to Isolate How Things Are Done” ):\ntemplate< typename StoragePolicy > \nclass Shape;\nThe Shape class template is rewritten to accept a StoragePolicy. Via this\npolicy , you would be able to specify from outside how the class should\nacquire memory . And of course, you would perfectly adhere to SRP and\nOCP. One such storage policy could be the DynamicStorage policy class:\n#include <utility> \n \nstruct DynamicStorage \n{ \n   template< typename T, typename... Args > \n   T* create( Args&&... args ) const \n   { \n      return new T( std::forward<Args>( args )... ); \n   } \n \n   template< typename T > \n   void destroy( T* ptr ) const noexcept \n   { \n      delete ptr; \n   } \n};\nAs the name suggests, DynamicPolicy would acquire memory\ndynamically , for instance via new. Alternatively , if you have stronger\nrequirements, you could build on std::aligned_alloc() or similar\nfunctionality to provide dynamic memory with a specified alignment.\nSimilarly to DynamicStorage, you could provide an InClass Stor age\npolicy:\n#include <array> \n#include <cstddef> \n#include <memory> \n#include <utility> \n \ntemplate< size_t Capacity, size_t Alignment > \nstruct InClassStorage \n{ \n   template< typename T, typename... Args > \n   T* create( Args&&... args ) const \n   { \n      static_assert( sizeof(T) <= Capacity, ""The given type is too large"" ); \n      static_assert( alignof(T) <= Alignment, ""The given type is misaligned"" \n); \n \n      T* memory = const_cast<T*>(reinterpret_cast<T const*>(buffer_.data())); \n      return std::construct_at( memory, std::forward<Args>( args )... ); \n \n      // or: \n      // void* const memory = static_cast<void*>(buffer_.data()); \n      // return ::new (memory) T( std::forward<Args>( args )... ); \n   } \n \n   template< typename T > \n   void destroy( T* ptr ) const noexcept \n   { \n      std::destroy_at(ptr); \n      // or: ptr->~T(); \n   } \n \n   alignas(Alignment) std::array<std::byte,Capacity> buffer_; \n};\nAll of these policy classes provide the same interface: a create() function\nto instantiate an object of type T and a destroy() function to do whatever\nis necessary to clean up. This interface is used by the Shape class to trigger\nconstruction and destruction, for instance, in its templated constructor (\n )\nand in the destructor (\n ):\n \ntemplate< typename StoragePolicy > \nclass Shape \n{ \n public: \n   template< typename ShapeT > 16\n   Shape( ShapeT shape ) \n   { \n      using Model = OwningModel<ShapeT>; \n      pimpl_ = policy_.template create<Model>( std::move(shape) )  \n \n   } \n \n   ~Shape() { policy_.destroy( pimpl_ ); }  \n \n \n   // ... All other member functions, in particular the \n   //     special members functions, are not shown \n \n private: \n   // ... \n   [[no_unique_address]] StoragePolicy policy_{};  \n \n   Concept* pimpl_{}; \n}; \nThe last detail that should not be left unnoticed is the data members (\n ): the\nShape class now stores an instance of the given StoragePolicy and, do not\nbe alarmed, a raw pointer to its Concept. Indeed, there is no need to store\nstd::unique_ptr anymore, since we are manually destroying the object in\nour own destructor again. Y ou might also notice the\n[[no_unique_address]] attribute  on the storage policy . This C++20\nfeature gives you the opportunity to save the memory for the storage policy .\nIf the policy is empty , the compiler is now allowed to not reserve any\nmemory for the data member . Without this attribute, it would be necessary\nto reserve at least a single byte for policy_, but likely more bytes due to\nalignment restrictions.\nIn summary , SBO is an ef fective and one of the most interesting\noptimizations for a T ype Erasure implementation. For that reason, many\nstandard types, such as std::function and std::any, use some form of\nSBO. Unfortunately , the C++ Standard Library specification doesn’ t requir e\nthe use of SBO. This is why you can only hope that SBO is used; you can’ t\ncount on it. However , because performance is so important and because\nSBO plays such a decisive role, there are already proposals out there that\nalso suggest standardizing the types inplace_function and inplace_any.\nTime will tell if these find their way into the Standard Library .",21839
108-Manual Implementation of Function Dispatch.pdf,108-Manual Implementation of Function Dispatch,"Manual Implementation of Function Dispatch\n“Wow, this  will prove useful. Is there anything else I can do to improve the\nperformance of my T ype Erasure implementation?” you ask. Oh yes, you\ncan do more. There is a second potential performance optimization. This\ntime we try to improve the performance of the virtual functions. And yes,\nI’m talking about the virtual functions that are introduced by the external\ninheritance hierarchy , i.e., by the External Polymorphism design pattern.\n“How should we be able to optimize the performance of virtual functions?\nIsn’t this something that is completely up to the compiler?” Absolutely ,\nyou’re correct. However , I am not talking about fiddling with backend,\ncompiler -specific implementation details, but about replacing the virtual\nfunctions with something more ef ficient. And that is indeed possible.\nRemember that a virtual function is nothing but a function pointer that is\nstored inside a virtual function table. Every type with at least one virtual\nfunction has such a virtual function table. However , there is only one virtual\nfunction table for each type. In other words, this table is not stored inside\nevery instance. So in order to connect the virtual function table with every\ninstance of that type, the class stores an additional, hidden data member ,\nwhich we commonly call the vptr and which is a raw pointer to the virtual\nfunction table.\nWhen you call a virtual function, you first go through the vptr to fetch the\nvirtual function table. Once you’re there, you can grab the corresponding\nfunction pointer from the virtual function table and call it. Therefore, in\ntotal, a virtual function call entails two indirections: the vptr and the\npointer to the actual function. For that reason,  roughly speaking, a virtual\nfunction call is twice as expensive as a regular , noninline  function call.\nThese two indirections provide us with the opportunity for optimization: we\ncan in fact reduce the number of indirections to just one. T o achieve that,\nwe will employ an optimization strategy that works fairly often: we’ll trade\nspace for speed. What we will do is implement the virtual dispatch\nmanually by storing the virtual function pointers inside the Shape class. The\nfollowing code snippet already gives you a pretty good idea of the details:\n \n//---- <Shape.h> ---------------- \n \n#include <cstddef> \n#include <memory> \n \nclass Shape \n{ \n public: \n   // ... \n \n private: \n   // ... \n \n   template< typename ShapeT \n           , typename DrawStrategy > \n   struct OwningModel  \n \n   { \n      OwningModel( ShapeT value, DrawStrategy drawer ) \n         : shape_( std::move(value) ) \n         , drawer_( std::move(drawer) ) \n      {} \n \n      ShapeT shape_; \n      DrawStrategy drawer_; \n   }; \n \n   using DestroyOperation = void(void*);   \n \n   using DrawOperation    = void(void*);   \n \n   using CloneOperation   = void*(void*);  \n \n \n   std::unique_ptr<void,DestroyOperation*> pimpl_;  \n \n   DrawOperation*  draw_ { nullptr };               \n \n   CloneOperation* clone_{ nullptr };               \n \n}; \nSince we are replacing all virtual functions, even the virtual destructor ,\nthere’ s no need for a Concept base class anymore. Consequently , the\nexternal hierarchy is reduced to just the OwningModel class template (\n ),\nwhich still acts as storage for a specific kind of shape ( ShapeT) and\nDrawStrategy. Still, it meets the same fate: all virtual functions are\nremoved. The only remaining details are the constructor and the data\nmembers.\nThe virtual functions are replaced by manual function pointers. Since the\nsyntax for function pointers is not the most pleasant to use, we add a couple\nof function type aliases for our convenience:  DestroyOperation\nrepresents the former virtual destructor (\n ), DrawOperation represents the\nformer virtual draw() function (\n ), and CloneOperation represents the\nformer virtual clone() function (\n ). Destroy Operation is used to\nconfigure the Deleter of the pimpl_ data member (\n ) (and yes, as such it\nacts as a Strategy). The latter two, DrawOperation and CloneOperation,\nare used for the two additional function pointer data members, draw_ and\nclone_ (\n and \n ).\n“Oh no, void*s! Isn’ t that an archaic and super dangerous way of doing\nthings?” you gasp. OK, I admit that without explanation it looks very\nsuspicious. However , stay with me, I promise that everything will be\nperfectly fine and type safe. The key to making this work now lies in the\ninitialization of these function pointers. They are initialized in the templated\nconstructor of the Shape class:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nclass Shape \n{ \n public: \n   template< typename ShapeT \n           , typename DrawStrategy > \n   Shape( ShapeT shape, DrawStrategy drawer ) \n      : pimpl_(   \n \n            new OwningModel<ShapeT,DrawStrategy>( std::move(shape) \n                                                , std::move(drawer) ) \n          , []( void* shapeBytes ){  \n \n               using Model = OwningModel<ShapeT,DrawStrategy>; \n               auto* const model = static_cast<Model*>(shapeBytes);  \n \n               delete model;  \n \n            } ) \n      , draw_(  \n \n            []( void* shapeBytes ){ \n               using Model = OwningModel<ShapeT,DrawStrategy>; \n               auto* const model = static_cast<Model*>(shapeBytes); 17\n               (*model->drawer_)( model->shape_ ); \n            } ) \n      , clone_(  \n \n            []( void* shapeBytes ) -> void* { \n               using Model = OwningModel<ShapeT,DrawStrategy>; \n               auto* const model = static_cast<Model*>(shapeBytes); \n               return new Model( *model ); \n            } ) \n   {} \n \n   // ... \n \n private: \n   // ... \n}; \nLet’s focus on the pimpl_ data member . It is initialized both by a pointer to\nthe newly instantiated OwningModel (\n) and by a stateless lambda\nexpression (\n ). You may remember that a stateless lambda is implicitly\nconvertible to a function pointer . This language guarantee is what we use to\nour advantage: we directly pass the lambda as the deleter to the constructor\nof unique_ptr, force the compiler to apply the implicit conversion to a\nDestroyOperation*, and thus bind the lambda function to the\nstd::unique_ptr.\n“OK, I get the point: the lambda can be used to initialize the function\npointer . But how does it work? What does it do?” W ell, also remember that\nwe are creating this lambda inside the templated constructor . That means\nthat at this point we are fully aware of the actual type of the passed ShapeT\nand DrawStrategy. Thus, the lambda is generated with the knowledge of\nwhich type of OwningModel is instantiated and stored inside the pimpl_.\nEventually it will be called with a void*, i.e., by the address of some\nOwningModel. However , based on its knowledge about the actual type of\nOwningModel, it can first of all perform a static_cast from void* to\nOwningModel<ShapeT,DrawStrategy>*  (\n). While in most other contexts\nthis kind of cast would be suspicious and would likely be a wild guess, in\nthis context it is perfectly type safe: we can be certain about the correct type\nof OwningModel. Therefore, we can use the resulting pointer to trigger the\ncorrect cleanup behavior (\n ).\nThe initialization of the draw_ and clone_ data members is very similar (\nand \n ). The only dif ference is, of course, the action performed by the\nlambdas: they perform the correct actions to draw the shape and to create a\ncopy of the model, respectively .\nI know , this may take some time to digest. But we are almost done; the only\nmissing detail is the special member functions. For the destructor and the\ntwo move operations, we can again ask for the compiler -generated default.\nHowever , we have to deal with the copy constructor and copy assignment\noperator ourselves:\n//---- <Shape.h> ---------------- \n \n// ... \n \nclass Shape \n{ \n public: \n   // ... \n \n   Shape( Shape const& other ) \n      : pimpl_( clone_( other.pimpl_.get() ), other.pimpl_.get_deleter() ) \n      , draw_ ( other.draw_ ) \n      , clone_( other.clone_ ) \n   {} \n \n   Shape& operator=( Shape const& other ) \n   { \n      // Copy-and-Swap Idiom \n      using std::swap; \n      Shape copy( other ); \n      swap( pimpl_, copy.pimpl_ ); \n      swap( draw_, copy.draw_ ); \n      swap( clone_, copy.clone_ ); \n      return *this; \n   } \n \n   ~Shape() = default; \n   Shape( Shape&& ) = default; \n   Shape& operator=( Shape&& ) = default; \n \n private: \n   // ... \n};\nThis is all we need to do, and we’re ready to try this out. So let’ s put this\nimplementation to the test. Once again we update the benchmark from\n“Guideline 32: Consider Replacing Inheritance Hierarchies with T ype\nErasure”  and run it with our manual implementation of virtual functions. I\nhave even combined the manual virtual dispatch with the previously\ndiscussed SBO. Table 8-3  shows the  performance results.\nTable 8-3. Performance r esults for the T ype Erasur e\nimplementations with manual virtual dispatch\nType Erasure implementation GCC 1 1.1 Clang 1 1.1\nObject-oriented solution 1.5205 s 1.1480 s\nstd::function 2.1782 s 1.4884 s\nManual implementation of std::function 1.6354 s 1.4465 s\nClassic Strategy 1.6372 s 1.4046 s\nType Erasure 1.5298 s 1.1561 s\nType Erasure (SBO) 1.3591 s 1.0348 s\nType Erasure (manual virtual dispatch) 1.1476 s 1.1599 s\nType Erasure (SBO + manual virtual dispatch) 1.2538 s 1.2212 s\nThe performance improvement for the manual virtual dispatch is\nextraordinary for GCC. On my system, I get down to 1.1476 seconds,\nwhich is an improvement of 25% in comparison to the based, unoptimized\nimplementation of T ype Erasure. Clang, on the other hand, does not show\nany improvement in comparison to the basic, unoptimized implementation.\nAlthough this may be a little disappointing, the runtime is, of course, still\nremarkable.\nUnfortunately the combination of SBO and manual virtual dispatch does\nnot lead to an even better performance. While GCC shows a small\nimprovement in comparison to the pure SBO approach (which might be",10265
109-The Setup Costs of an Owning Type Erasure Wrapper.pdf,109-The Setup Costs of an Owning Type Erasure Wrapper,"interesting for environments without dynamic memory), on Clang this\ncombination does not work as well as you might have hoped for .\nIn summary , there is a lot of potential for optimizing the performance for\nType Erasure implementations. If you’ve been skeptical before about T ype\nErasure, this gain in performance should give you a strong incentive to\ninvestigate for yourself. While this is amazing and without doubt is pretty\nexciting, it is important to remember where this is coming from: only due to\nseparating the concerns of virtual behavior and encapsulating the behavior\ninto a value type have we gained these optimization opportunities. W e\nwouldn’ t have been able to achieve this if all we had was a pointer -to-base.\nGUIDELINE 33: BE AWARE OF THE OPTIMIZATION\nPOTENTIAL OF TYPE ERASURE\nUse SBO to avoid expensive copy operations for small objects.\nReduce the number of indirections by implementing virtual\ndispatch manually .\nGuideline 34: Be Aware of the Setup Costs of\nOwning Type Erasure Wrappers\nIn “Guideline 32: Consider Replacing Inheritance Hierarchies with T ype\nErasure”  and “Guideline 33: Be A ware of the Optimization Potential of\nType Erasure” , I guided you through the thicket of implementation details\nfor a basic T ype Erasure implementation. Y es, that was tough, but definitely\nworth the ef fort: you have emer ged stronger , wiser , and with a new ,\nefficient, and strongly decoupling design pattern in your toolbox. Great!\nHowever , we have to go back into the thicket. I see you are rolling your\neyes, but there is more. And I have to admit: I lied. At least a little. Not by\ntelling you something incorrect, but by omission. There is one more\ndisadvantage of T ype Erasure that you should know of. A big one. One that\nyou might not like at all. Sigh.\nThe Setup Costs of an Owning T ype Erasure W rapper\nAssume  for a second that Shape is a base class again, and Circle one of\nmany deriving classes. Then passing a Circle to a function expecting a\nShape const& would be easy and cheap (\n ):\n \n#include <cstdlib> \n \nclass Shape { /*...*/ };  // Classic base class \n \nclass Circle : public Shape { /*...*/ };  // Deriving class \n \nvoid useShape( Shape const& shape ) \n{ \n   shape.draw( /*...*/ ); \n} \n \nint main() \n{ \n   Circle circle{ 3.14 }; \n \n   // Automatic and cheap conversion from 'Circle const&' to 'Shape const&' \n   useShape( circle );  \n \n \n   return EXIT_SUCCESS; \n} \nAlthough the T ype Erasure Shape abstraction is a little dif ferent (for\ninstance, it always requires a drawing Strategy), this kind of conversion is\nstill possible:\n \n#include <cstdlib> \n \nclass Circle { /*...*/ };  // Nonpolymorphic geometric primitive \n \nclass Shape { /*...*/ };  // Type erasure wrapper class as shown before \n \nvoid useShape( Shape const& shape ) \n{ \n   draw(shape); \n} \n \nint main() \n{ \n   Circle circle{ 3.14 }; \n   auto drawStrategy = []( Circle const& c ){ /*...*/ }; \n \n   // Creates a temporary 'Shape' object, involving \n   //   a copy operation and a memory allocation \n   useShape( { circle, drawStrategy } );  \n \n \n   return EXIT_SUCCESS; \n} \nUnfortunately , it is no longer cheap. On the contrary , based on our previous\nimplementations, which include both the basic one and optimized ones, the\ncall to the useShape() function would involve a couple of potentially\nexpensive operations (\n ):\nTo convert a Circle into a Shape, the compiler creates a temporary\nShape using the non- explicit, templated Shape constructor .\nThe call of the constructor results in a copy operation of the given\nshape (not expensive for Circle, but potentially expensive for other\nshapes) and the given draw Strategy (essentially free if the Strategy is\nstateless, but potentially expensive, depending on what is stored inside\nthe object).\nInside the Shape constructor , a new shape model is created, involving a\nmemory allocation (hidden in the call to std::make_unique() in the\nShape constructor and definitely expensive).\nThe temporary (rvalue) Shape is passed by reference-to- const to the\nuseShape() function.\nIt is important to point out that this is not a specific problem of our Shape\nimplementation. The same problem will hit you if, for instance, you use\nstd::function as a function ar gument:\n#include <cstdlib> \n#include <functional> \n \nint compute( int i, int j, std::function<int(int,int)> op ) \n{ \n   return op( i, j ); \n} \n \nint main() \n{ \n   int const i = 17; \n   int const j = 10; \n \n   int const sum = compute( i, j, [offset=15]( int x, int y ) { \n      return x + y + offset; \n   } ); \n \n   return EXIT_SUCCESS; \n}\nIn this example, the given lambda is converted into the std::function\ninstance. This conversion will involve a copy operation and might involve a\nmemory allocation. It entirely depends on the size of the given callable and\non the implementation of std::function. For that reason, std::function\nis a dif ferent kind of abstraction than, for instance, std::string_view and\nstd::span. std::string_view and std::span are nonowning\nabstractions that are cheap to copy because they consist of only a pointer to\nthe first element and a size. Because these two types perform a shallow\ncopy , they are perfectly suited as function parameters. std::function, on\nthe other hand, is an owning abstraction that performs a deep copy .\nTherefore, it is not the perfect type to be used as a function parameter .\nUnfortunately , the same is true for our Shape implementation.\n“Oh my , I don’ t like this. Not at all. That is terrible! I want my money\nback!” you exclaim. I have to agree that this may be a severe issue in your\ncodebase. However , you understand that the underlying problem is the\nowning semantics of the Shape class: on the basis of its value semantics\nbackground, our current Shape implementation  will always create a copy of\nthe given shape and will always own the copy . While this is perfectly in line\nwith all the benefits discussed in “Guideline 22: Prefer V alue Semantics18",6083
110-A Simple Nonowning Type Erasure Implementation.pdf,110-A Simple Nonowning Type Erasure Implementation,"over Reference Semantics ”, in this context it results in a pretty unfortunate\nperformance penalty . However , stay calm—there is something we can do:\nfor such a context, we can provide a nonowning T ype Erasure\nimplementation.\nA Simple Nonowning T ype Erasure Implementation\nGenerally  speaking, the value semantics–based T ype Erasure\nimplementation is beautiful and perfectly adheres to the spirit of modern\nC++. However , performance is important. It might be so important that\nsometimes you might not care about the value semantics part, but only\nabout the abstraction provided by T ype Erasure. In that case, you might\nwant to reach for a nonowning implementation of T ype Erasure, despite the\ndisadvantage that this pulls you back into the realm of reference semantics .\nThe good news is that if you desire only a simple T ype Erasure wrapper , a\nwrapper that represents a reference-to-base, that is nonowning and trivially\ncopyable, then the required code is fairly simple. That is particularly true\nbecause you have already seen how to manually implement the virtual\ndispatch in “Guideline 33: Be A ware of the Optimization Potential of T ype\nErasure” . With this technique, a simple, nonowning T ype Erasure\nimplementation is just a matter of a few lines of code:\n \n//---- <Shape.h> ---------------- \n \n#include <memory> \n \nclass ShapeConstRef \n{ \n public: \n   template< typename ShapeT, typename DrawStrategy > \n   ShapeConstRef( ShapeT& shape, DrawStrategy& drawer )  \n \n      : shape_{ std::addressof(shape) } \n      , drawer_{ std::addressof(drawer) } \n      , draw_{ []( void const* shapeBytes, void const* drawerBytes ){ \n           auto const* shape = static_cast<ShapeT const*>(shapeBytes); \n           auto const* drawer = static_cast<DrawStrategy const*>(drawerBytes); \n           (*drawer)( *shape ); \n        } } \n   {} \n \n private: \n   friend void draw( ShapeConstRef const& shape ) \n   { \n      shape.draw_( shape.shape_, shape.drawer_ ); \n   } \n \n   using DrawOperation = void( void const*,void const* ); \n \n   void const* shape_{ nullptr };    \n \n   void const* drawer_{ nullptr };   \n \n   DrawOperation* draw_{ nullptr };  \n \n}; \nAs the name suggests, the ShapeConstRef class represents a reference to a\nconst shape type. Instead of storing a copy of the given shape, it only holds\na pointer to it in the form of a void* (\n). In addition, it holds a void* to the\nassociated DrawStrategy (\n), and as the third data member , a function\npointer to the manually implemented virtual draw() function (\n ) (see\n“Guideline 33: Be A ware of the Optimization Potential of T ype Erasure” ).\nShapeConstRef takes its two ar guments, the shape and the drawing\nStrategy , both possibly cv qualified, by reference-to-non- const (\n). In\nthis form, it is not possible to pass rvalues to the constructor , which\nprevents any kind of lifetime issue with temporary values. This\nunfortunately does not protect you from all possible lifetime issues with\nlvalues but still provides a very reasonable protection.  If you want to\nallow rvalues, you should reconsider . And if you’re really , really  willing to\nrisk lifetime issues with temporaries, then you can simply take the\nargument(s) by reference-to- const. Just remember that you did not get this\nadvice from me!\nThis is it. This is the complete nonowning implementation. It is ef ficient,\nshort, simple, and can be even shorter and simpler if you do not need to\nstore any kind of associated data or Strategy object. With this functionality\nin place, you are now able to create cheap shape abstractions. This is\ndemonstrated in the following code example by the useShapeConstRef()\nfunction. This function enables you to draw any kind of shape ( Circles,19\n20",3797
111-A More Powerful Nonowning Type Erasure Implementation.pdf,111-A More Powerful Nonowning Type Erasure Implementation,"Squares, etc.) with any possible drawing implementation by simply using a\nShapeConstRef as the function ar gument. In the main() function, we call\nuseShapeConstRef() by a concrete shape and a concrete drawing Strategy\n(in this case, a lambda) (\n ):\n \n//---- <Main.cpp> ---------------- \n \n#include <Circle.h> \n#include <Shape.h> \n#include <cstdlib> \n \nvoid useShapeConstRef( ShapeConstRef shape ) \n{ \n   draw( shape ); \n} \n \nint main() \n{ \n   // Create a circle as one representative of a concrete shape type \n   Circle circle{ 3.14 }; \n \n   // Create a drawing strategy in the form of a lambda \n   auto drawer = []( Circle const& c ){ /*...*/ }; \n \n   // Draw the circle directly via the 'ShapeConstRef' abstraction \n   useShapeConstRef( { circle, drawer } );  \n \n \n   return EXIT_SUCCESS; \n} \nThis call triggers the desired ef fect, notably without any memory allocation\nor expensive copy operation, but only by wrapping polymorphic behavior\naround a set of pointers to the given shape and drawing Strategy .\nA More Powerful Nonowning T ype Erasure\nImplementation\nMost  of the time, this simple nonowning T ype Erasure implementation\nshould prove to be enough and fulfill all your needs. Sometimes, however ,\nand only sometimes, it might not be enough. Sometimes, you might be\ninterested in a slightly dif ferent form of Shape reference:\n \n#include <Cirlce.h> \n#include <Shape.h> \n#include <cstdlib> \n \nint main() \n{ \n   // Create a circle as one representative of a concrete shape type \n   Circle circle{ 3.14 }; \n \n   // Create a drawing strategy in the form of a lambda \n   auto drawer = []( Circle const& c ){ /*...*/ }; \n \n   // Combine the shape and the drawing strategy in a 'Shape' abstraction \n   Shape shape1( circle, drawer ); \n \n   // Draw the shape \n   draw( shape1 ); \n \n   // Create a reference to the shape \n   // Works already, but the shape reference will store a pointer \n   // to the 'shape1' instance instead of a pointer to the 'circle'. \n   ShapeConstRef shaperef( shape1 );  \n \n \n   // Draw via the shape reference, resulting in the same output \n   // This works, but only by means of two indirections! \n   draw( shaperef );  \n \n \n   // Create a deep copy of the shape via the shape reference \n   // This is _not_ possible with the simple nonowning implementation! \n   // With the simple implementation, this creates a copy of the 'shaperef' \n   // instance. 'shape2' itself would act as a reference and there would be \n   // three indirections... sigh. \n   Shape shape2( shaperef );  \n \n \n   // Drawing the copy will again result in the same output \n   draw( shape2 ); \n \n   return EXIT_SUCCESS; \n} \nAssuming that you have a type-erased circle called shape1, you might\nwant to convert this Shape instance to a ShapeConstRef (\n). With the\ncurrent implementation, this works, but the shaperef instance would hold a\npointer to the shape1 instance, instead of a pointer to the circle. As a\nconsequence, any use of the shaperef would result in two indirections (one\nvia the ShapeConstRef, and one via the Shape abstraction) (\n ).\nFurthermore, you might also be interested in converting a ShapeConstRef\ninstance to a Shape instance (\n ). In that case, you might expect that a full\ncopy of the underlying Circle is created and that the resulting Shape\nabstraction contains and represents this copy . Unfortunately , with the\ncurrent implementation, the Shape would create a copy of the\nShapeConstRef instance, and thus introduce a third indirection. Sigh.\nIf you need a more ef ficient interaction between owning and nonowning\nType Erasure wrappers, and if you need a real copy when copying a\nnonowning wrapper into an owning wrapper , then I can of fer you a working\nsolution. Unfortunately , it is more involved than the previous\nimplementation(s), but fortunately it isn’ t not overly complex. The solution\nbuilds on the basic T ype Erasure implementation from “Guideline 32:\nConsider Replacing Inheritance Hierarchies with T ype Erasure” , which\nincludes the ShapeConcept and OnwingShapeModel classes in the detail\nnamespace, and the Shape Type Erasure wrapper . You will see that it just\nrequires a few additions, all of which you have already seen before.\nThe first addition happens in the ShapeConcept base class:\n \n//---- <Shape.h> ---------------- \n \n#include <memory> \n#include <utility> \n \nnamespace detail { \n \nclass ShapeConcept \n{ \n public: \n   // ... \n   virtual void clone( ShapeConcept* memory ) const = 0;  \n \n}; \n \n// ... \n \n} // namespace detail \nThe ShapeConcept class is extended with a second clone() function (\n ).\nInstead of returning a newly instantiated copy of the corresponding model,\nthis function is passed the address of the memory location where the new\nmodel needs to be created.\nThe second addition is a new model class, the NonOwningShapeModel:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nnamespace detail { \n \n// ... \n \ntemplate< typename ShapeT \n        , typename DrawStrategy > \nclass NonOwningShapeModel : public ShapeConcept \n{ \n public: \n   NonOwningShapeModel( ShapeT& shape, DrawStrategy& drawer ) \n      : shape_{ std::addressof(shape) } \n      , drawer_{ std::addressof(drawer) } \n   {} \n \n   void draw() const override { (*drawer_)(*shape_); }  \n \n \n   std::unique_ptr<ShapeConcept> clone() const override  \n \n   { \n      using Model = OwningShapeModel<ShapeT,DrawStrategy>; \n      return std::make_unique<Model>( *shape_, *drawer_ ); \n   } \n \n   void clone( ShapeConcept* memory ) const override  \n \n   { \n      std::construct_at( static_cast<NonOwningShapeModel*>(memory), *this ); \n \n      // or: \n      // auto* ptr = \n      //    const_cast<void*>(static_cast<void const volatile*>(memory)); \n      // ::new (ptr) NonOwningShapeModel( *this ); \n   } \n \n private: \n   ShapeT* shape_{ nullptr };  \n \n   DrawStrategy* drawer_{ nullptr };  \n \n}; \n \n// ... \n \n} // namespace detail \nThe NonOwningShapeModel is very similar to the OwningShapeModel\nimplementation, but, as the name suggests, it does not store copies of the\ngiven shape and strategy . Instead, it stores only pointers (\n  and \n ). Thus,\nthis class represents the reference semantics version of the\nOwningShapeModel class. Also, NonOwningShapeModel needs to override\nthe pure virtual functions of the ShapeConcept class: draw() again\nforwards the drawing request to the given drawing Strategy (\n ), while the\nclone() functions perform a copy . The first clone() function is\nimplemented by creating a new OwningShapeModel and copying both the\nstored shape and drawing Strategy (\n ). The second clone() function is\nimplemented by creating a new NonOwningShapeModel at the specified\naddress by std::construct_at() (\n).\nIn addition, the OwningShapeModel class needs to provide an\nimplementation of the new clone() function:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nnamespace detail { \n \ntemplate< typename ShapeT \n        , typename DrawStrategy > \nclass OwningShapeModel : public ShapeConcept \n{ \n public: \n   // ... \n \n   void clone( ShapeConcept* memory ) const  \n \n   { \n      using Model = NonOwningShapeModel<ShapeT const,DrawStrategy const>; \n \n      std::construct_at( static_cast<Model*>(memory), shape_, drawer_ ); \n \n      // or: \n      // auto* ptr = \n      //    const_cast<void*>(static_cast<void const volatile*>(memory)); \n      // ::new (ptr) Model( shape_, drawer_ ); \n   } \n}; \n \n// ... \n \n} // namespace detail \nThe clone() function in OwningShapeModel is implemented similarly to\nthe implementation in the NonOwningShapeModel class by creating a new\ninstance of a NonOwningShapeModel by std::construct_at() (\n).\nThe next addition is the corresponding wrapper class that acts as a wrapper\naround the external hierarchy ShapeConcept and NonOwningShapeModel.\nThis wrapper should take on the same responsibilities as the Shape class\n(i.e., the instantiation of the NonOwningShapeModel class template and the\nencapsulation of all pointer handling) but should merely represent a\nreference to a const concrete shape, not a copy . This wrapper is again\ngiven in the form of the ShapeConstRef class:\n \n//---- <Shape.h> ---------------- \n \n#include <array> \n#include <cstddef> \n#include <memory> \n \n// ... \n \nclass ShapeConstRef \n{ \n public: \n   // ... \n \n private: \n   // ... \n \n   // Expected size of a model instantiation: \n   //     sizeof(ShapeT*) + sizeof(DrawStrategy*) + sizeof(vptr) \n   static constexpr size_t MODEL_SIZE = 3U*sizeof(void*);  \n \n \n   alignas(void*) std::array<std::byte,MODEL_SIZE> raw_;  \n \n}; \nAs you will see, the ShapeConstRef class is very similar to the Shape class,\nbut there are a few important dif ferences. The first noteworthy detail is the\nuse of a raw_ storage in the form of a properly aligned std::byte array (\n). That indicates that ShapeConstRef does not allocate dynamically , but\nfirmly builds on in-class memory . In this case, however , this is easily\npossible, because we can predict the size of the required\nNonOwningShapeModel to be equal to the size of three pointers (assuming\nthat the pointer to the virtual function table, the vptr, has the same size as\nany other pointer) (\n ).\nThe private section of ShapeConstRef also contains a couple of member\nfunctions:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nclass ShapeConstRef \n{ \n public: \n   // ... \n \n private: \n   friend void draw( ShapeConstRef const& shape ) \n   { \n      shape.pimpl()->draw(); \n   } \n \n   ShapeConcept* pimpl()  \n \n   { \n      return reinterpret_cast<ShapeConcept*>( raw_.data() ); \n   } \n \n   ShapeConcept const* pimpl() const  \n \n   { \n      return reinterpret_cast<ShapeConcept const*>( raw_.data() ); \n   } \n \n   // ... \n}; \nWe also add a draw() function as a hidden friend and, just as in the SBO\nimplementation in “Guideline 33: Be A ware of the Optimization Potential\nof Type Erasure” , we add a pair of pimpl() functions (\n  and \n ). This will\nenable us to work conveniently with the in-class std::byte array .\nThe second noteworthy detail is the signature function of every T ype\nErasure implementation, the templated constructor:\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nclass ShapeConstRef \n{ \n public: \n   // Type 'ShapeT' and 'DrawStrategy' are possibly cv qualified; \n   // lvalue references prevent references to rvalues \n   template< typename ShapeT \n           , typename DrawStrategy > \n   ShapeConstRef( ShapeT& shape \n                , DrawStrategy& drawer )  \n \n   { \n      using Model = \n         detail::NonOwningShapeModel<ShapeT const,DrawStrategy const>;  \n \n      static_assert( sizeof(Model) == MODEL_SIZE, ""Invalid size detected"" );  \n \n      static_assert( alignof(Model) == alignof(void*), ""Misaligned detected"" \n); \n \n      std::construct_at( static_cast<Model*>(pimpl()), shape_, drawer_ );  \n \n \n      // or: \n      // auto* ptr = \n      //    const_cast<void*>(static_cast<void const volatile*>(pimpl())); \n      // ::new (ptr) Model( shape_, drawer_ ); \n   } \n \n   // ... \n \n private: \n   // ... \n}; \nAgain, you have the choice to accept the ar guments by reference-to-non-\nconst to prevent lifetime issues with temporaries (very much\nrecommended!) (\n ). Alternatively , you accept the ar guments by reference-\nto-const, which would allow you to pass rvalues but puts you at risk of\nexperiencing lifetime issues with temporaries. Inside the constructor , we\nagain first use a convenient type alias for the required type of model (\n ),\nbefore checking the actual size and alignment of the model (\n ). If it does\nnot adhere to the expected MODEL_SIZE or pointer alignment, we create a\ncompile-time error . Then we construct the new model inside the in-class\nmemory by std::construct_at() (\n):\n \n//---- <Shape.h> ---------------- \n \n// ... \n \nclass ShapeConstRef \n{ \n public: \n   // ... \n \n   ShapeConstRef( Shape& other )       { other.pimpl_->clone( pimpl() ); }  \n \n   ShapeConstRef( Shape const& other ) { other.pimpl_->clone( pimpl() ); } \n \n   ShapeConstRef( ShapeConstRef const& other ) \n   { \n      other.pimpl()->clone( pimpl() ); \n   } \n \n   ShapeConstRef& operator=( ShapeConstRef const& other ) \n   { \n      // Copy-and-swap idiom \n      ShapeConstRef copy( other ); \n      raw_.swap( copy.raw_ ); \n      return *this; \n   } \n \n   ~ShapeConstRef() \n   { \n      std::destroy_at( pimpl() ); \n      // or: pimpl()->~ShapeConcept(); \n   } \n \n   // Move operations explicitly not declared  \n \n \n private: \n   // ... \n}; \nIn addition to the templated ShapeConstRef constructor , ShapeConstRef\noffers two constructors to enable a conversion from Shape instances (\n ).\nWhile these are not strictly required, as we could also create an instance of\na NonOwningShapeModel for a Shape, these constructors directly create a\nNonOwningShapeModel for the corresponding, underlying shape type, and\nthus shave of f one indirection, which contributes to better performance.\nNote that to make these constructors work, ShapeConstRef needs to\nbecome a friend of the Shape class. Don’ t worry , though, as this is a good\nexample for friendship: Shape and ShapeConstRef truly belong together ,\nwork hand in hand, and are even provided in the same header file.\nThe last noteworthy detail is the fact that the two move operations are\nneither explicitly declared nor deleted (\n ). Since we have explicitly defined\nthe two copy operations, the compiler neither creates nor deletes the two\nmove operations, thus they are gone. Completely gone in the sense that\nthese two functions never participate in overload resolution. And yes, this is\ndifferent from explicitly deleting them: if they were deleted, they would\nparticipate in overload resolution, and if selected, they would result in a\ncompilation error . But with these two functions gone, when you try to move\na ShapeConstRef, the copy operations would be used instead, which are\ncheap and ef ficient, since ShapeConstRef only represents a reference.\nThus, this class deliberately implements the Rule of 3 .\nWe are almost finished. The last detail is one more addition, one more\nconstructor in the Shape class:\n//---- <Shape.h> ---------------- \n \n// ... \n \nclass Shape \n{ \n public: \n   // ... \n \n   Shape( ShapeConstRef const& other ) \n      : pimpl_{ other.pimpl()->clone() } \n   {} \n \n private: \n   // ... \n}\nVia this constructor , an instance of Shape creates a deep copy of the shape\nstored in the passed ShapeConstRef instance. W ithout this constructor ,\nShape stores a copy of the ShapeConstRef instance and thus acts as a\nreference itself.\nIn summary , both nonowning implementations, the simple and the more\ncomplex one, give you all the design advantages of the T ype Erasure design\npattern but at the same time pull you back into the realm of reference\nsemantics, with all its deficiencies. Hence, utilize the strengths of this\nnonowning form of T ype Erasure, but also be aware of the usual lifetime\nissues. Consider it on the same level as std::string_view and\nstd::span. All of these serve as very useful tools for function ar guments,\nbut do not use them to store anything for a longer period, for instance in the\nform of a data member . The danger of lifetime-related issues is just too\nhigh.\nGUIDELINE 34: BE AWARE OF THE SETUP COSTS OF\nOWNING TYPE ERASURE WRAPPERS\nKeep in mind that the setup of owning T ype Erasure wrappers may\ninvolve copy operations and allocations.\nBe aware of nonowning T ype Erasure, but also understand its\nreference semantics deficiencies.\nPrefer simple T ype Erasure implementations, but know their limits.\nPrefer to use nonowning T ype Erasure for function ar guments but\nnot for data members or return types.\n1 Yes, I consider the manual use of std::unique_ptr manual lifetime management. But of\ncourse it could be much worse if we would not reach for the power of RAII.\n2 The term T ype Erasure is heavily overloaded, as it is used in dif ferent programming languages\nand for many dif ferent things. Even within the C++ community , you hear the term being used\nfor various purposes: you might have heard it being used to denote void*, pointers-to-base,\nand std::variant. In the context of software design, I consider this a very unfortunate issue. I\nwill address this issue at the end of this guideline.\n3 Sean Parent, “Inheritance Is the Base Class of Evil,” GoingNative 2013, YouTube.\n4 Kevlin Henney , “Valued Conversions,” C++ Report , July-August 2000, CiteSeer .\n5 For an introduction to std::function, see “Guideline 23: Prefer a V alue-Based\nImplementation of Strategy and Command” .\n6 The placement of ShapeConcept and OwningShapeModel in a namespace is purely an\nimplementation detail of this example implementation. Still, as you will see in “Guideline 34:\nBe A ware of the Setup Costs of Owning Type Erasure W rappers ”, this choice will come in\npretty handy . Alternatively , these two classes can be  implemented as nested classes. Y ou will\nsee examples of this in “Guideline 33: Be A ware of the Optimization Potential of T ype\nErasure” .\n7 Refer to “Guideline 31: Use External Polymorphism for Nonintrusive Runtime\nPolymorphism”  for the implementation based on std::function.\n8 Many thanks to Arthur O’Dwyer for providing this example.\n9 Again, please don’ t consider these performance numbers the perfect truth. These are the\nperformance results on my machine and my implementation. Y our results will dif fer for sure.\nHowever , the takeaway is that T ype Erasure performs really well and might perform even\nbetter if we take the many optimization options into account (see “Guideline 33: Be A ware of\nthe Optimization Potential of T ype Erasure” ).\n10 Eric Niebler on Twitter , June 19, 2020.\n1 1 For an introduction of std::variant, see “Guideline 17: Consider std::variant for\nImplementing V isitor ”.\n12 You should avoid going too deep, though, as you probably remember what happened to the\ndwarves of Moria who dug too deep…\n13 Alternatively , you could use an array of bytes, e.g., std::byte[Capacity] or\nstd::aligned_storage. The advantage of std::array is that it enables you to copy the\nbuffer (if that is applicable!).\n14 Note that the choice for the default ar guments for Capacity and Alignment are reasonable\nbut still arbitrary . You can, of course, use dif ferent defaults that best fit the properties of the\nexpected actual types.\n15 You might not have seen a placement new before. If that’ s the case, rest assured that this form\nof new doesn’ t perform any memory allocation, but only calls a constructor to create an object\nat the specified address. The only syntactic dif ference is that you provide an additional pointer\nargument to new.\n16 As a reminder , since you might not see this syntax often: the template keyword in the\nconstructor is necessary because we are trying to call a function template on a dependent name\n(a name whose meaning depends on a template parameter). Therefore, you have to make it\nclear to the compiler that the following is the beginning of a template ar gument list and not a\nless-than comparison.\n17 Some people consider function pointers to be the best feature of C++. In his lightning talk,\n“The V ery Best Feature of C++” , James McNellis demonstrates their syntactic beauty and\nenormous flexibility . Please do not take this too seriously , though, but rather as a humorous\ndemonstration of a C++ imperfection.\n18 At the time of writing, there is an active proposal  for the std::function_ref type, a\nnonowning version of std::function.\n19 The term cv qualified  refers to the const and volatile qualifiers.\n20 For a reminder about lvalues and rvalues, refer to Nicolai Josuttis’ s book on move semantics:\nC++ Move Semantics - The Complete Guide .",20062
112-9. The Decorator Design Pattern.pdf,112-9. The Decorator Design Pattern,,0
113-Your Coworkers Design Issue.pdf,113-Your Coworkers Design Issue,"Chapter 9. The Decorator\nDesign Pattern\nThis chapter is dedicated to another classic design pattern: the Decorator\ndesign pattern. Over the years, Decorator has proven to be one of the most\nuseful design patterns when it comes to combining and reusing dif ferent\nimplementations. So it doesn’ t come as a surprise that it is commonly used,\neven for one of the most impressive reworks of a C++ Standard Library\nfeature. My primary objective in this chapter will be to give you a very\ngood idea why , and when, Decorator is a great choice for designing\nsoftware. Additionally , I will show you the modern, more value-based\nforms of Decorator .\nIn “Guideline 35: Use Decorators to Add Customization Hierarchically” ,\nwe will dive into the design aspects of the Decorator design pattern. Y ou\nwill see when it is the right design choice and which benefits you’re gaining\nby using it. Additionally , you will learn about dif ferences compared to other\ndesign patterns and its potential shortcomings.\nIn “Guideline 36: Understand the T rade-of f Between Runtime and Compile\nTime Abstraction” , we will take a look at two more implementations of the\nDecorator design pattern. Although both implementations will be firmly\nrooted in the realm of value semantics, the first one will be based on static\npolymorphism, while the second one will be based on dynamic\npolymorphism. Even though both have the same intent and thus implement\nDecorator , the contrast between these two will give you an impression of\nthe vastness of the design space for design patterns.\nGuideline 35: Use Decorators to Add\nCustomization Hierarchically\nEver  since you solved the design problem of your team’ s 2D graphics tool\nby proposing a solution based on the Strategy design pattern (remember\n“Guideline 19: Use Strategy to Isolate How Things Are Done” ), your\nreputation as design pattern expert has spread across the company .\nTherefore, it does not come as a surprise that other teams are seeking you\nout for guidance. One day , two developers of your companies merchandise\nmanagement system come to your of fice and ask for your help.\nYour Coworkers’ Design Issue\nThe team of the two developers is dealing with a lot of dif ferent Items (see\nFigure 9-1 ). All of these items have one thing in common: they have a\nprice() tag. The two developers try to explain their problem by means of\ntwo items taken from the C++ merchandise shop: a class representing a\nC++ book (the CppBook class) and a C++ conference ticket (the\nConferenceTicket class).\nFigur e 9-1. The initial Item inheritance hierar chy\nAs the developers sketch their problem, you start to understand that their\nproblem appears to be the many dif ferent ways to modify a price. Initially ,\nthey tell you, they only had to take taxes into account. For that reason, the\nItem base class was equipped with a protected data member to represent\nthe tax rate:\n//---- <Money.h> ---------------- \n \nclass Money { /*...*/ }; \n \nMoney operator*( Money money, double factor ); \nMoney operator+( Money lhs, Money rhs ); \n \n \n//---- <Item.h> ---------------- \n \n#include <Money.h> \n \nclass Item \n{ \n public: \n   virtual ~Item() = default; \n \n   virtual Money price() const = 0; \n   // ... \n \n protected: \n   double taxRate_; \n};\nThis apparently worked well for some time, until one day , when they were\nasked to also take dif ferent rates of discount into account. This apparently\nrequired a lot of ef fort to refactor the lar ge amount of the existing classes\nfor their numerous dif ferent items. Y ou can easily imagine that this was\nnecessary because all derived classes were accessing the protected data\nmembers. “Y es, you should always design for change…” you think to\nyourself.\nThey continue by admitting to their unfortunate misdesign. Of course they\nshould have done a better job of encapsulating the tax rates in the Item base\nclass. However , along with this realization came the understanding that\nwhen representing price modifiers by data members in the base class, any\nnew kind of price modifier would always be an intrusive action and would\nalways directly af fect the Item class. For that reason, they started to think\nabout how to avoid this kind of major refactoring in the future and how to\nenable the easy addition of new modifiers. “That’ s the way to go!” you\nthink to yourself. Unfortunately , the first approach that came to their mind\nwas to factor out the dif ferent kinds of price modifiers by means of an\ninheritance hierarchy (see Figure 9-2 ).1\nFigur e 9-2. The extended Item inheritance hierar chy\nInstead of encapsulating the tax and discount values inside the base class,\nthese modifiers are factored out into derived classes, which perform the\nrequired price adaptation. “Uh-oh…” you start to think. Apparently your\nlook already gives away that you are not particularly fond of this idea, and\nso they are quick to tell you that they have already discarded the idea.\nObviously they have realized on their own that this would cause even more\nproblems: this solution would quickly cause an explosion of types and\nwould provide only poor reuse of functionality . Unfortunately , a lot of code\nwould be doubled, since for every specific Item, the code for taxes and\ndiscounts had to be duplicated. Most troublesome, however , would be the\nhandling of Items that are af fected both by tax and some sort of discount:\nthey neither liked the approach to provide classes to handle both, nor did\nthey want to introduce another layer in the inheritance hierarchy (see\nFigure 9-3 ).\nFigur e 9-3. The pr oblematic Item inheritance hierar chy\nApparently , and surprising for them, they couldn’ t deal with the price\nmodifiers in the base class or in the derived classes by means of direct\ninheritance. However , before you have the opportunity to make any\ncomments about separating concerns, they explain that they have recently\nheard about your Strategy solution. This finally gave them an idea how to\nproperly refactor the problem (see Figure 9-4 ).\nBy extracting the price modifiers into a separate hierarchy , and by\nconfiguring Items upon construction by means of a PriceStrategy, they\nhad finally found a working solution to nonintrusively add new price\nmodifiers, which will save them a lot of refactoring work. “W ell, this is the\nbenefit of separating concerns and favoring composition over inheritance,”\nyou think to yourself.  And aloud you ask, “This is great, I’m really happy\nfor you. Everything seems to work now , you’ve figured it out on your own!\nWhy exactly are you here?”2\nFigur e 9-4. The Strategy-based Item inheritance hierar chy\nThey tell you that your Strategy solution is by far the best approach they\nhave (thankful looks included). However , they admit that they are not\nentirely happy with the approach. From their point of view , two problems\nremain and, of course, they are hoping that you have an idea how to fix\nthem. The first issue they see is that every Item instance needs a Strategy\nclass, even if no price modifier applies. While they agree that this can be\nsolved by some kind of null object , they feel that there should be a simpler\nsolution:\nclass PriceStrategy \n{ \n public: \n   virtual ~PriceStrategy() = default; \n   virtual Money update( Money price ) const = 0; \n   // ... \n}; \n \nclass NullPriceStrategy : public PriceStrategy \n{ \n public: \n   Money update( Money price ) const override { return price; } \n};\nThe second problem they have appears to be a little more dif ficult to solve.\nObviously they are interested in combining dif ferent kinds of modifiers\n(e.g., Discount and Tax into DiscountAndTax). Unfortunately , they\nexperience some code duplication in their current implementation. For\ninstance, both the Tax and the DiscountAndTax classes contain tax-related\ncomputations. And while right now , with only the two modifiers, there are\nreasonable solutions at hand to cope with the duplication, they are\nanticipating problems when adding more modifiers and arbitrary\ncombinations of these. Therefore they are wondering if there is another ,\nbetter solution for dealing with dif ferent kinds of price modifiers.\nThis is indeed an intriguing problem, and you are happy to have taken the\ntime to help them. They are absolutely correct: the Strategy design pattern\nis not the right solution for this problem. While Strategy is a great solution\nto remove dependencies on the complete implementation details of a\nfunction and to handle dif ferent implementations gracefully , it does not\nenable the easy combination and reuse of dif ferent implementations.\nAttempting to do this would quickly result in an undesirably complex\nStrategy inheritance hierarchy .\nWhat they need for their problem appears to be more like a hierarchical\nform of Strategy , a form that decouples the dif ferent price modifiers but3",8953
114-The Decorator Design Pattern Explained.pdf,114-The Decorator Design Pattern Explained,"also allows for a very flexible combination of them. Hence, one key to\nsuccess is a consequent application of the separation of concerns: any rigid,\nmanually encoded combination in the spirit of a DiscountAndTax class\nwould be prohibitive. However , the solution should also be nonintrusive to\nenable them to implement new ideas at any time without the need to modify\nexisting code. And finally , it should not be necessary to handle a default\ncase by some artificial null object . Instead, it would be more reasonable to\nconsequently build on composition instead of inheritance and implement a\nprice modifier in the form of a wrapper . With this realization, you start to\nsmile. Yes, there is just the right design pattern for this purpose: what your\ntwo guests need is an implementation of the Decorator design pattern.\nThe Decorator Design Pattern Explained\nThe Decorator design pattern also originates from the GoF book. Its\nprimary focus is the flexible combination of dif ferent pieces of functionality\nthrough composition:\nTHE DECORATOR DESIGN PATTERN\nIntent: “Attach  additional responsibilities to an object dynamically . Decorators provide a\nflexible alternative to subclassing for extending functionality .”\nFigure 9-5  shows the UML diagram for the given Item problem. As before,\nthe Item base class represents the abstraction from all possible items. The\nderiving CppBook class, on the other hand, acts as a representative for\ndifferent implementations of Item. The problem in this hierarchy is the\ndifficult addition of new modifiers for the existing price() function(s). In\nthe Decorator design pattern, this addition of new “responsibilities” is\nidentified as a  variation point  and extracted in the form of the\nDecoratedItem class. This class is a separate, special implementation of\nthe Item base class and represents an added responsibility for any given\nitem. On the one hand, a DecoratedItem derives from Item and hence\nmust adhere to all expectations of the Item abstraction (see “Guideline 6:4\nAdhere to the Expected Behavior of Abstractions” ). On the other hand, it\nalso contains an Item (either through composition or aggregation). Due to\nthat, a DecoratedItem acts as a wrapper around each and every item,\npotentially one that itself can extend the functionality . For that reason, it\nprovides the foundation for a hierarchical application of modifiers. T wo\npossible modifiers are represented by the Discounted class, which\nrepresents a discount for a specific item, and the Taxed class, which\nrepresents some kind of tax.5\nFigur e 9-5. The UML r epresentation of the Decorator design pattern\nBy introducing the DecoratedItem class and separating the aspect that’ s\nrequired to change, you adhere to the SRP . By separating this concern and\ntherefore allowing the easy addition of new price modifiers, you also adhere\nto the Open-Closed Principle (OCP) . Due to the hierarchical, recursive\nnature of the DecoratedItem class, and due to the gained ability to reuse\nand combine dif ferent modifiers easily , you also follow the advice of the\nDon’ t Repeat Y ourself (DR Y) principle. Last but not least, because of the\nwrapper approach of Decorator , there’ s no need to define any default\nbehavior in the form of a null object . Any Item that does not require a\nmodifier can be used as is.\nFigure 9-6  illustrates the dependency graph of the Decorator design pattern.\nIn this figure, the Item class resides on the highest level of the architecture.\nAll other classes depend on it, including the DecoratedItem class, which\nresides one level below . Of course, this is not a requirement: it’ s perfectly\nacceptable if both the Item and the DecoratedItem are introduced on the\nsame architectural level. However , this example demonstrates that it’ s\nalways possible (anytime, anywhere) to introduce a new Decorator without\nneeding to modify existing code. The concrete types of Items are\nimplemented on the lowest level of the architecture. Note that there is no\ndependency between these items: all items, including modifiers like\nDiscounted, can be introduced independently by anyone at any time and,\ndue to the structure of Decorator , be flexibly and arbitrarily combined.",4259
115-A Classic Implementation of the Decorator Design Pattern.pdf,115-A Classic Implementation of the Decorator Design Pattern,"Figur e 9-6. Dependency graph for the Decorator design pattern\nA Classic Implementation of the Decorator Design\nPattern\nLet’s take a look at a complete, GoF-style implementation of the Decorator\ndesign pattern by means of the given Item example:\n//---- <Item.h> ---------------- \n \n#include <Money.h> \n \nclass Item \n{ \n public: \n   virtual ~Item() = default; \n   virtual Money price() const = 0; \n};\nThe Item base class represents the abstraction for all possible items. The\nonly requirement is defined by the pure virtual price() function, which\ncan be used to query for the price of the given item. The DecoratedItem\nclass represents one possible implementation of the Item class (\n ):\n \n//---- <DecoratedItem.h> ---------------- \n \n#include <Item.h> \n#include <memory> \n#include <stdexcept> \n#include <utility> \n \nclass DecoratedItem : public Item  \n \n{ \n public: \n   explicit DecoratedItem( std::unique_ptr<Item> item )  \n \n      : item_( std::move(item) ) \n   { \n      if( !item_ ) { \n         throw std::invalid_argument( ""Invalid item"" ); \n      } \n   } \n \n protected: \n   Item&       item()       { return *item_; }  \n \n   Item const& item() const { return *item_; } \n \n private: \n   std::unique_ptr<Item> item_;  \n \n}; \nA DecoratedItem derives from the Item class but also contains an item_ (\n). This item_ is specified via the constructor , which accepts any non-null\nstd::unique_ptr to another Item (\n). Note that this DecoratedItem class\nis still abstract, since the pure virtual price() function is not yet defined.\nDecoratedItem provides only the necessary functionality to store an Item\nand to access the Item via protected member functions (\n ).\nEquipped with these two classes, it’ s possible to implement concrete Items:\n \n//---- <CppBook.h> ---------------- \n \n#include <Item.h> \n#include <string> \n#include <utility> \n \nclass CppBook : public Item  \n \n{ \n public: \n   CppBook( std::string title, Money price ) \n      : title_{ std::move(title) } \n      , price_{ price } \n   {} \n \n   std::string const& title() const { return title_; } \n   Money price() const override { return price_; } \n \n private: \n   std::string title_{}; \n   Money price_{}; \n}; \n \n \n//---- <ConferenceTicket.h> ---------------- \n \n#include <Item.h> \n#include <string> \n#include <utility> \n \nclass ConferenceTicket : public Item  \n \n{ \n public: \n   ConferenceTicket( std::string name, Money price ) \n      : name_{ std::move(name) } \n      , price_{ price } \n   {} \n \n   std::string const& name() const { return name_; } \n   Money price() const override { return price_; } \n \n private: \n   std::string name_{}; \n   Money price_{}; \n}; \nThe CppBook and ConferenceTicket classes represent possible specific\nItem implementations (\n  and \n ). While a C++ book is represented by\nmeans of the title of the book, a C++ conference is represented by means of\nthe name of the conference. Most importantly , both classes override the\nprice() function by returning the specified price_.\nBoth CppBook and ConferenceTicket are oblivious to any kind of tax or\ndiscount. But obviously , both kinds of Item are potentially subject to both.\nThese price modifiers are implemented by means of the Discounted and\nTaxed classes:\n \n//---- <Discounted.h> ---------------- \n \n#include <DecoratedItem.h> \n \nclass Discounted : public DecoratedItem \n{ \n public: \n   Discounted( double discount, std::unique_ptr<Item> item )  \n \n      : DecoratedItem( std::move(item) ) \n      , factor_( 1.0 - discount ) \n   { \n      if( !std::isfinite(discount) || discount < 0.0 || discount > 1.0 ) { \n         throw std::invalid_argument( ""Invalid discount"" ); \n      } \n   } \n \n   Money price() const override \n   { \n      return item().price() * factor_;  \n \n   } \n \n private: \n   double factor_; \n}; \nThe Discounted class (\n ) is initialized by passing a std::unique_ptr to\nan Item and a discount value, represented by a double value in the range of\n0.0 to 1.0. While the given Item is immediately passed to the\nDecoratedItem base class, the given discount value is used to compute a\ndiscount factor_. This factor is used in the implementation of the price()\nfunction to modify the price of the given item (\n ). This can either be a\nspecific item like CppBook or ConferenceTicket or any Decorator like\nDiscounted, which in turn modifies the price of another Item. Thus, the\nprice() function is the point where the hierarchical structure of Decorator\nis fully exploited.\n \n//---- <Taxed.h> ---------------- \n \n#include <DecoratedItem.h> \n \nclass Taxed : public DecoratedItem \n{ \n public: \n   Taxed( double taxRate, std::unique_ptr<Item> item )  \n \n      : DecoratedItem( std::move(item) ) \n      , factor_( 1.0 + taxRate ) \n   { \n      if( !std::isfinite(taxRate) || taxRate < 0.0 ) { \n         throw std::invalid_argument( ""Invalid tax"" ); \n      } \n   } \n \n   Money price() const override \n   { \n      return item().price() * factor_; \n   } \n \n private: \n   double factor_; \n}; \nThe Taxed class is very similar to the Discounted class. The major\ndifference is the evaluation of a tax-related factor in the constructor (\n ).\nAgain, this factor is used in the price() function to modify the price of the\nwrapped Item.\nAll of this functionality is put together in the main() function:\n \n#include <ConferenceTicket.h> \n#include <CppBook.h> \n#include <Discounted.h> \n#include <Taxed.h> \n#include <cstdlib> \n#include <memory> \n \nint main() \n{ \n   // 7% tax: 19*1.07 = 20.33 \n   std::unique_ptr<Item> item1(  \n \n      std::make_unique<Taxed>( 0.07, \n         std::make_unique<CppBook>( ""Effective C++"", 19.0 ) ) ); \n \n   // 20% discount, 19% tax: (999*0.8)*1.19 = 951.05 \n   std::unique_ptr<Item> item2(  \n \n      std::make_unique<Taxed>( 0.19, \n         std::make_unique<Discounted>( 0.2, \n            std::make_unique<ConferenceTicket>( ""CppCon"", 999.0 ) ) ) ); \n \n   Money const totalPrice1 = item1->price();  // Results in 20.33 \n   Money const totalPrice2 = item2->price();  // Results in 951.05 \n \n   // ... \n \n   return EXIT_SUCCESS; \n}",6207
116-A Second Decorator Example.pdf,116-A Second Decorator Example,"As a first Item, we create a CppBook. Let’ s assume that this book is subject\nto a 7% tax, which is applied by means of wrapping a Taxed decorator\naround the item. The resulting item1 therefore represents a taxed C++ book\n(\n). As a second Item, we create a ConferenceTicket instance, which\nrepresents CppCon . We were lucky to get one of the early-bird tickets,\nwhich means that we are granted a discount of 20%. This discount is\nwrapped around the ConferenceTicket instance by means of the\nDiscounted class. The ticket is also subject to 19% tax, which, as before, is\napplied via the Taxed decorator . Hence, the resulting item2 represents a\ndiscounted and taxed C++ conference ticket (\n ).\nA Second Decorator Example\nAnother , impressive  example that shows the benefits of the Decorator\ndesign pattern can be found in the C++17 rework of the STL allocators.\nSince the allocators’ implementation is based on Decorator , it’s possible to\ncreate arbitrarily complex hierarchies of allocators, which fulfill even the\nmost special of memory requirements. Consider , for instance, the following\nexample using a std::pmr::monotonic_buffer_resource  (\n):\n \n#include <array> \n#include <cstddef> \n#include <cstdlib> \n#include <memory_resource> \n#include <string> \n#include <vector> \n \nint main() \n{ \n   std::array<std::byte,1000> raw;  // Note: not initialized! \n \n   std::pmr::monotonic_buffer_resource \n      buffer{ raw.data(), raw.size(), std::pmr::null_memory_resource() }; \n \n \n   std::pmr::vector<std::pmr::string> strings{ &buffer }; \n \n   strings.emplace_back( ""String longer than what SSO can handle"" ); \n   strings.emplace_back( ""Another long string that goes beyond SSO"" ); \n   strings.emplace_back( ""A third long string that cannot be handled by SSO"" \n); \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nThe std::pmr::monotonic_buffer_resource  is one of several available\nallocators in the  std::pmr namespace. In this example, it’ s configured such\nthat whenever the strings vector asks for memory , it will dispense only\nchunks of the given byte array raw. Memory requests that cannot be\nhandled, for instance because the buffer is out of memory , are dealt with\nby throwing a std::bad_alloc exception. This behavior is specified by\npassing a std::pmr::null_memory_resource during construction. There\nare many other possible applications for a\nstd::pmr::monotonic_buffer_resource , though. For instance, it would\nalso be possible to build on dynamic memory and to let it reallocate\nadditional chunks of memory via new and delete by means of\nstd::pmr::new_delete_resource()  (\n):\n \n// ... \n \nint main() \n{ \n   std::pmr::monotonic_buffer_resource \n      buffer{ std::pmr::new_delete_resource() };  \n \n \n   // ... \n} \nThis flexibility and hierarchical configuration of allocators is made possible\nby means of the  Decorator design pattern. The std::pmr:: \nmonotonic_buffer_resource is derived from the\nstd::pmr::memory_resource base class but, at the same time, also acts as\na wrapper around another allocator derived from\nstd::pmr::memory_resource. The upstream allocator , which is used\nwhenever the buffer goes out of memory , is specified on construction of a\nstd::pmr::monotonic_buffer_resource .\nMost impressive, however , is that you can easily and nonintrusively\ncustomize the allocation strategy . That might, for instance, be interesting to\nenable you to deal with requests for lar ge chunks of memory dif ferently\nthan requests for small chunks. All you have to do is to provide your own,\ncustom allocator . Consider the following sketch of a CustomAllocator:\n \n//---- <CustomAllocator.h> ---------------- \n \n#include <cstdlib> \n#include <memory_resource> \n \nclass CustomAllocator : public std::pmr::memory_resource  \n \n{ \n public: \n   CustomAllocator( std::pmr::memory_resource* upstream )  \n \n      : upstream_{ upstream } \n   {} \n \n private: \n   void* do_allocate( size_t bytes, size_t alignment ) override;  \n \n \n   void do_deallocate( void* ptr, [[maybe_unused]] size_t bytes,  \n \n                       [[maybe_unused]] size_t alignment ) override; \n \n   bool do_is_equal( \n      std::pmr::memory_resource const& other ) const noexcept override;  \n \n \n   std::pmr::memory_resource* upstream_{};  \n \n}; \nTo be recognized as a C++17 allocator , the CustomAllocator class derives\nfrom the std::pmr::memory_resource class, which represents the set of\nrequirements for all C++17  allocators (\n ). Coincidentally , the\nCustomAllocator also owns a pointer to a std::pmr::memory_resource\n(\n), which is initialized via its constructor (\n ).\nThe set of requirements for C++17 allocators consists of the virtual\nfunctions do_allocate(), do_deallocate(), and do_is_equal(). The\ndo_allocate() function is responsible for acquiring memory , potentially\nvia its upstream allocator (\n ), while the do_deallocate() function is",4953
117-Comparison Between Decorator Adapter and Strategy.pdf,117-Comparison Between Decorator Adapter and Strategy,"called whenever memory needs to be given back (\n ). Last but not least, the\ndo_is_equal() function is called whenever the equality of two allocators\nneeds to be checked (\n ).\nBy just introducing the CustomAllocator and without the need to change\nany other code, in  particular in the Standard Library , the new kind of\nallocator can be easily plugged in between the\nstd::pmr::monotonic_buffer_resource  and the\nstd::pmr::new_delete_resource()  (\n), thus allowing you to\nnonintrusively extend the allocation behavior:\n \n// ... \n#include <CustomAllocator.h> \n \nint main() \n{ \n   CustomAllocator custom_allocator{ std::pmr::new_delete_resource() }; \n \n   std::pmr::monotonic_buffer_resource buffer{ &custom_allocator };  \n \n \n   // ... \n} \nComparison Between Decorator , Adapter , and Strategy\nWith the names Decorator  and Adapter , these two design patterns sound\nlike they have a similar purpose. On closer examination, however , these two\npatterns are very dif ferent and hardly related at all. The intent of the\nAdapter design pattern is to adapt and change a given interface to an\nexpected interface. It is not concerned about adding any functionality but\nonly about mapping one set of functions onto another (see also “Guideline\n24: Use Adapters to Standardize Interfaces” ). The Decorator design pattern,\non the other hand, preserves a given interface and isn’ t at all concerned\nabout changing it. Instead, it provides the ability to add responsibilities and\nto extend and customize an existing set of functions.\nThe Strategy design pattern is much more like Decorator . Both patterns\nprovide the ability to customize functionality . However , both patterns are6\nintended for dif ferent applications and therefore provide dif ferent benefits.\nThe Strategy design pattern is focused on removing the dependencies on the\nimplementation details of a specific functionality and enables you to define\nthese details from the outside. Thus from this perspective, it represents the\ncore—the “guts”—of this functionality . This form makes it particularly\nsuited to represent dif ferent implementations and to switch between them\n(see “Guideline 19: Use Strategy to Isolate How Things Are Done” ). In\ncomparison, the Decorator design pattern is focused on removing the\ndependency between attachable pieces of implementation. Due to its\nwrapper form, Decorator represents the “skin” of a functionality . In this\nform, it is particularly well suited to combine dif ferent implementations,\nwhich enables you to augment and extend functionality , rather than\nreplacing it or switching between implementations.\nObviously , both Strategy and Decorator have their individual strengths and\nshould be selected accordingly . However , it’s also possible to combine these\ntwo design patterns to gain the best of both worlds. For instance, it would\nbe possible to implement Items in terms of the Strategy design patterns but\nallow for a more fine-grained configuration of Strategy by means of\nDecorator:\nclass PriceStrategy \n{ \n public: \n   virtual ~PriceStrategy() = default; \n   virtual Money update( Money price ) const = 0; \n   // ... \n}; \n \nclass DecoratedPriceStrategy : public PriceStrategy \n{ \n public: \n   // ... \n private: \n   std::unique_ptr<PriceStrategy> priceModifier_; \n}; \n \nclass DiscountedPriceStrategy : public DecoratedPriceStrategy \n{ \n public: 7",3425
118-Analyzing the Shortcomings of the Decorator Design Pattern.pdf,118-Analyzing the Shortcomings of the Decorator Design Pattern,"Money update( Money price ) const override; \n   // ... \n};\nThis combination of design patterns is particularly interesting if you already\nhave a Strategy implementation in place: while Strategy is intrusive and\nrequires the modification of a class, it’ s always possible to nonintrusively\nadd a Decorator such as the DecoratedPriceStrategy class. But of course\nit depends: whether or not this is the right solution is something you’ll have\nto decide on a case-by-case basis.\nAnalyzing the Shortcomings of the Decorator Design\nPattern\nWith its ability to hierarchically extend and customize behavior , the\nDecorator design pattern is clearly one of the most valuable and flexible\npatterns in the catalogue of design patterns. However , despite its benefits, it\nalso comes with a couple of disadvantages. First and foremost, the\nflexibility of a Decorator comes with a price: every level in a given\nhierarchy adds one level of indirection. As a specific example, in the object-\noriented implementation of the Item hierarchy , this indirection comes in the\nform of one virtual function call per Decorator . Thus an extensive use of\nDecorators may incur a potentially significant performance overhead.\nWhether or not this possible performance penalty poses a problem depends\non the context. Y ou’ll have to decide from case to case using benchmarks to\ndetermine whether the flexibility and the structural aspects of Decorator\noutweigh the performance problem.\nAnother shortcoming is the potential danger of combining Decorators in a\nnonsensical way . For instance, it’ s easily possible to wrap a Taxed\nDecorator around another Taxed Decorator or to apply a Discounted on an\nalready-taxed Item. Both scenarios would make your government happy\nbut still should never happen and therefore should be avoided by design.\nThis rational is nicely expressed by Scott Meyers’ s universal design\nprinciple:8\nMake interfaces easy to use corr ectly and har d to use incorr ectly.\nThus the enormous flexibility of Decorators is extraordinary , but can also\nbe dangerous (depending on the scenario, of course). Since in this scenario\ntaxes appear to play a special role, it seems to be very reasonable not to deal\nwith them as Decorator , but dif ferently . Since in reality taxes turn out to be\na rather complex topic, it appears to be reasonable to separate this concern\nvia the Strategy design pattern:\n \n//---- <TaxStrategy.h> ---------------- \n \n#include <Money.h> \n \nclass TaxStrategy  \n \n{ \n public: \n   virtual ~TaxStrategy() = default; \n   virtual Money applyTax( Money price ) const = 0; \n   // ... \n}; \n \n \n//---- <TaxedItem.h> ---------------- \n \n#include <Money.h> \n#include <TaxStrategy.h> \n#include <memory> \n \nclass TaxedItem \n{ \n public: \n   explicit TaxedItem( std::unique_ptr<Item> item \n                     , std::unique_ptr<TaxStrategy> taxer )  \n \n      : item_( std::move(item) ) \n      , taxer_( std::move(taxer) ) \n   { \n      // Check for a valid item and tax strategy \n   } \n \n   Money netPrice() const  // Price without taxes  \n \n   { \n      return price(); \n   } \n \n   Money grossPrice() const  // Price including taxes  \n \n   { \n      return taxer_.applyTax( item_.price() ); \n   } \n \n private: \n   std::unique_ptr<Item> item_; \n   std::unique_ptr<TaxStrategy> taxer_; \n}; \nThe TaxStrategy class represents the many dif ferent ways to apply taxes\nto an Item (\n). Such a TaxStrategy is combined with an Item in the\nTaxedItem class (\n ). Note that TaxedItem is not an Item itself and\ntherefore cannot be decorated by means of another Item. It therefore serves\nas a kind of terminating Decorator , which can only be applied as the very\nlast decorator . It also does not provide a price() function: instead, it\nprovides the netPrice() (\n) and grossPrice() (\n) functions to enable\nqueries for both the price including taxes and the original price of the\nwrapped Item.\nThe only other problem that you might see is the reference semantics–based\nimplementation of the Decorator design pattern: lots of pointers, including\nnullptr checks and the danger of dangling pointers, explicit lifetime\nmanagement by means of std::unique_ptr and std::make_unique(),\nand the many small, manual memory allocations. However , luckily you still\nhave an ace up your sleeve and can show them how to implement\nDecorators based on value semantics (see the following guideline).\nTo summarize, the Decorator design pattern is one of the essential design\npatterns and despite some drawbacks will prove to be a very valuable\naddition to your toolbox. Just make sure you’re not too excited about\nDecorator and start to use it for everything. After all, for every pattern there\nis a thin line between good use and overuse.9",4814
119-A Value-Based Compile Time Decorator.pdf,119-A Value-Based Compile Time Decorator,"GUIDELINE 35: USE DECORATORS TO ADD\nCUSTOMIZATION HIERARCHICALLY\nUnderstand that inheritance is rarely the answer .\nApply the Decorator design pattern with the intent to\nnonintrusively and hierarchically extend and customize behavior .\nConsider Decorators for combining and reusing independent\npieces of behavior .\nUnderstand the dif ference between the Decorator , Adapter , and\nStrategy design patterns.\nUtilize the extreme flexibility of Decorators, but know its\nshortcomings.\nAvoid nonsensical Decorators, but prefer design that is easy to use\ncorrectly .\nGuideline 36: Understand the Trade-off\nBetween Runtime and Compile Time\nAbstraction\nIn “Guideline 35: Use Decorators to Add Customization Hierarchically” , I\nintroduced you to the Decorator design pattern and hopefully gave you a\nstrong incentive to add this design pattern to your toolbox. However , so far\nI have illustrated Decorator only by means of classic, object-oriented\nimplementations and again not followed the advice of “Guideline 22: Prefer\nValue Semantics over Reference Semantics ”. Since I assume that you are\neagerly waiting to see how to implement Decorator based on value\nsemantics, it’ s time to show you two possible approaches. Y es, two\napproaches: I will make up for the deferral by demonstrating two very\ndifferent implementations. Both are firmly based on value semantics, but in\ncomparison, they are almost on opposite sides of the design space. While\nthe first approach will be an implementation based on static polymorphism,\nwhich enables you to exploit all compile-time information you may have,\nthe second approach will rather exploit all the runtime advantages of\ndynamic polymorphism. Both approaches have their merits but, of course,\nalso their characteristic demerits. Therefore, these examples will nicely\ndemonstrate the broadness of design choices available to you.\nA Value-Based Compile T ime Decorator\nLet’s start with the Decorator implementation based on static\npolymorphism. “I assume that this will again be very heavy on templates,\nright?” you ask. Y es, I will use templates as the primary abstraction\nmechanism, and yes, I will use a C++20 concept and even forwarding\nreferences. But no, I will try not to make it particularly heavy on templates.\nOn the contrary , the major focus still lies on the design aspects of the\nDecorator design pattern and the goal to make it easy to add new kinds of\nDecorators and new kinds of regular items. One such item is the\nConferenceTicket class:\n//---- <ConferenceTicket.h> ---------------- \n \n#include <Money.h> \n#include <string> \n#include <utility> \n \nclass ConferenceTicket \n{ \n public: \n   ConferenceTicket( std::string name, Money price ) \n      : name_{ std::move(name) } \n      , price_{ price } \n   {} \n \n   std::string const& name() const { return name_; } \n   Money price() const { return price_; } \n \n private: \n   std::string name_; \n   Money price_; \n};\nThe ConferenceTicket perfectly fulfills the expectations of a value type:\nthere is no base class involved and there are no virtual functions. This\nindicates that items are no longer decorated via pointer -to-base, but instead\nby means of composition, or alternatively , by means of direct non- public\ninheritance. T wo examples for this are the following implementations of the\nDiscounted and Taxed classes:\n \n//---- <PricedItem.h> ---------------- \n \n#include <Money.h> \n \ntemplate< typename T > \nconcept PricedItem =  \n \n   requires ( T item ) { \n      { item.price() } -> std::same_as<Money>; \n   }; \n \n \n//---- <Discounted.h> ---------------- \n \n#include <Money.h> \n#include <PricedItem.h> \n#include <utility> \n \ntemplate< double discount, PricedItem Item > \nclass Discounted  // Using composition  \n \n{ \n public: \n   template< typename... Args > \n   explicit Discounted( Args&&... args ) \n      : item_{ std::forward<Args>(args)... } \n   {} \n \n   Money price() const { \n      return item_.price() * ( 1.0 - discount ); \n   } \n \n private: \n   Item item_; \n}; \n \n \n//---- <Taxed.h> ---------------- \n \n#include <Money.h> \n#include <PricedItem.h> \n#include <utility> \n \ntemplate< double taxRate, PricedItem Item > \nclass Taxed : private Item  // Using inheritance  \n \n{ \n public: \n   template< typename... Args > \n   explicit Taxed( Args&&... args ) \n      : Item{ std::forward<Args>(args)... } \n   {} \n \n   Money price() const { \n      return Item::price() * ( 1.0 + taxRate ); \n   } \n}; \nBoth Discounted (\n) and Taxed (\n) serve as Decorators for other kinds of\nItems: the Discounted class represents a certain discount on a given item,\nand the Taxed class represents some kind of tax. This time, however , both\nare implemented in the form of class templates. The first template ar gument\nspecifies the discount and the tax rate, respectively , and the second template\nargument specifies the type of the decorated Item.\nMost noteworthy , however , is the PricedItem constraint on the second\ntemplate ar gument (\n ). This constraint represents the set of semantic\nrequirements, i.e. the expected behavior . Due to this constraint, you can\nonly provide types that represent items with a price() member function.\nUsing any other type would immediately result in a compilation error . Thus\nPricedItem plays the same role as the Item base class in the classic\nDecorator implementation in “Guideline 35: Use Decorators to Add\nCustomization Hierarchically” . For the same reason, it also represents the\nseparation of concerns based on the Single-Responsibility Principle (SRP) .\nFurthermore, if this constraint is owned by some high level in your\narchitecture, then you, as well as anyone else, are able to add new kinds of\nitems and new kinds of Decorators on any lower level. This feature10\nperfectly fulfills the Open-Closed Principle (OCP) , and due to the proper\nownership of the  abstraction, also the Dependency Inversion Principle\n(DIP)  (see Figure 9-7 ).1 1\nFigur e 9-7. Dependency graph for the compile time Decorator\nBoth the Discounted and Taxed class templates are very similar , except for\nthe way they handle the decorated Item: while the Discounted class\ntemplate stores the Item in the form of a data member and therefore follows\n“Guideline 20: Favor Composition over Inheritance” , the Taxed class\ntemplate privately inherits from the given Item class. Both approaches are\npossible, reasonable, and have their individual strengths, but you should\nconsider the composition approach taken by the Discounted class template\nas the more common approach. As explained in “Guideline 24: Use\nAdapters to Standardize Interfaces” , there are only five reasons to prefer\nnon-public inheritance to composition (some of them are very rare):\nIf you have to override a virtual function\nIf you need access to a protected member function\nIf you need the adapted type to be constructed befor e another base\nclass\nIf you need to share a common virtual base class or override the\nconstruction of a virtual base class\nIf you can draw significant  advantage from the Empty Base\nOptimization (EBO)\nArguably , for a lar ge number of adapters, EBO  may be a reason to favor\ninheritance, but you should make sure that your choice is backed up by\nnumbers (for instance, by means of representative benchmarks).\nWith these three classes in place, you’re able to specify a\nConferenceTicket with a discount of 20% and a tax of 15%:\n#include <ConferenceTicket.h> \n#include <Discounted.h> \n#include <Taxed.h> \n#include <cstdlib> \n \nint main() \n{ \n   // 20% discount, 15% tax: (499*0.8)*1.15 = 459.08 \n   Taxed<0.15,Discounted<0.2,ConferenceTicket>> item{ ""Core C++"", 499.0 }; \n \n   Money const totalPrice = item.price();  // Results in 459.08 \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\nThe biggest advantage of this compile-time approach is the significant\nperformance improvement: since there are no pointer indirections, and due\nto the possibility of inlining, the compiler is able to go all out on optimizing\nthe resulting code. Also, the resulting code is ar guably much shorter and not\nbloated with any boilerplate code, and therefore easier to read.\n“Could you be a little more specific about the performance results? In C++,\ndevelopers are bickering about a 1% performance dif ference and call it\nsignificant . So seriously: how much faster is the compile-time approach?” I\nsee, you seem familiar with the performance zeal of the C++ community .\nWell, as long as you promise me, again, that you won’ t consider my results\nthe definitive answer but only a single example, and if we agree that this\ncomparison won’ t evolve into a performance study , I can show you some\nnumbers. But before I do, let me quickly outline the benchmark that I will\nuse: I am comparing the classic object-oriented implementation from\n“Guideline 35: Use Decorators to Add Customization Hierarchically”  with\nthe described compile-time version. Of course, there is an arbitrary number\nof decorator combinations, but I am restricting myself to the following four\nitem types:\nusing DiscountedConferenceTicket = Discounted<0.2,ConferenceTicket>; \nusing TaxedConferenceTicket = Taxed<0.19,ConferenceTicket>; \nusing TaxedDiscountedConferenceTicket = \n   Taxed<0.19,Discounted<0.2,ConferenceTicket>>; \nusing DiscountedTaxedConferenceTicket = \n   Discounted<0.2,Taxed<0.19,ConferenceTicket>>;\nSince in the compile time solution these four types do not have a common\nbase class, I am filling four specific std::vectors with these. In12\ncomparison, for the classic runtime solution, I use a single std::vector of\nstd::unique_ptr<Item>s. In total, I am creating 10,000 items with\nrandom prices for both solutions and calling std::accumulate() 5,000\ntimes to compute the total price of all items.\nWith this background information, let’ s take a look at the performance\nresults ( Table 9-1 ). Again, I am normalizing the results, this time to the\nperformance of the runtime implementation.\nTable 9-1. Performance r esults for the compile-time\nDecorator implementation (normalized\nperformance)\nGCC 1 1.1 Clang 1 1.1\nClassic Decorator 1.0 1.0\nCompile-time Decorator 0.078067 0.080313\nAs stated before, the performance of the compile-time solution is\nsignificantly faster than the runtime solution: for both GCC and Clang, it\nonly takes approximately 8% of the time of the runtime solution, and is\ntherefore faster by more than one order of magnitude. I know , this sounds\namazing. However , while the performance of the compile-time solution is\nextraordinary , it comes with a couple of potentially severe limitations: due\nto the complete focus on templates, there is no runtime flexibility left. Since\neven the discount and tax rates are realized via template parameters, a new\ntype needs to be created for each dif ferent rate. This may lead to longer\ncompile times and more generated code (i.e., lar ger executables).\nAdditionally , it stands to reason that all class templates reside in header\nfiles, which again increases compile time and may reveal more\nimplementation details than desired. More importantly , changes to the\nimplementation details are widely visible and may cause massive\nrecompilations. However , the most limiting factor appears to be that the\nsolution can only be used in this form if all information is available at",11451
120-A Value-Based Runtime Decorator.pdf,120-A Value-Based Runtime Decorator,"compile time. Thus, you may be able to get to this performance level for\nonly a few special cases.\nA Value-Based Runtime Decorator\nSince  the compile time Decorator may be fast but very inflexible at runtime,\nlet’s turn our attention to the second value-based Decorator implementation.\nWith this implementation,  we will return to the realm of dynamic\npolymorphism, with all of its runtime flexibility .\nAs you now know the Decorator design pattern, you realize that we need to\nbe able to easily add new types: new kinds of Item, as well as new price\nmodifiers. Therefore the design pattern of choice to turn the Decorator\nimplementation from “Guideline 35: Use Decorators to Add Customization\nHierarchically”  into a value semantics–based implementation is T ype\nErasure.  The following Item class implements an owning T ype Erasure\nwrapper for our priced item example:\n \n//---- <Item.h> ---------------- \n \n#include <Money.h> \n#include <memory> \n#include <utility> \n \nclass Item \n{ \n public: \n   // ... \n \n private: \n   struct Concept  \n \n   { \n      virtual ~Concept() = default; \n      virtual Money price() const = 0; \n      virtual std::unique_ptr<Concept> clone() const = 0; \n   }; \n \n   template< typename T > \n   struct Model : public Concept  \n \n   { \n      explicit Model( T const& item ) : item_( item ) {} 13\n      explicit Model( T&& item ) : item_( std::move(item) ) {} \n \n      Money price() const override \n      { \n         return item_.price(); \n      } \n \n      std::unique_ptr<Concept> clone() const override \n      { \n         return std::make_unique<Model<T>>(*this); \n      } \n \n      T item_; \n   }; \n \n   std::unique_ptr<Concept> pimpl_; \n}; \nIn this implementation, the Item class defines a nested Concept base class\nin its private section (\n ). As usual, the Concept base class represents the\nset of requirements (i.e. the expected behavior) for the wrapped types,\nwhich are expressed by the price() and clone() member functions. These\nrequirements are implemented by the nested Model class template (\n ).\nModel implements the price() function by forwarding the call to the\nprice() member function of the stored item_ data member , and the\nclone() function by creating a copy of the stored item.\nThe public section of the Item class should look familiar:\n \n//---- <Item.h> ---------------- \n \n// ... \n \nclass Item \n{ \n public: \n   template< typename T > \n   Item( T item )  \n \n      : pimpl_( std::make_unique<Model<T>>( std::move(item) ) ) \n   {} \n \n   Item( Item const& item ) : pimpl_( item.pimpl_->clone() ) {} \n \n   Item& operator=( Item const& item ) \n   { \n      pimpl_ = item.pimpl_->clone(); \n      return *this; \n   } \n \n   ~Item() = default; \n   Item( Item&& ) = default; \n   Item& operator=( Item&& item ) = default; \n \n   Money price() const { return pimpl_->price(); }  \n \n \n private: \n   // ... \n}; \nNext to the usual implementation of the Rule of 5 , the class is again\nequipped with a templated constructor that accepts all kinds of items (\n ).\nLast but not least, the class provides a price() member function, which\nmimics the expected interface of all items (\n ).\nWith this wrapper class in place, you are able to add new items easily:\nneither any intrusive modification of existing code nor any use of a base\nclass is required. Any class that provides a price() member function and is\ncopyable will work. Luckily , this includes the ConferenceTicket class\nfrom our compile-time Decorator implementation,  which provides\neverything we need and is firmly based on value semantics. Unfortunately ,\nthis is not true for the Discounted and Taxed classes, since they expect\ndecorated items in the form of a template ar gument. Therefore, we re-\nimplement Discounted and Taxed for use in the T ype Erasure context:\n//---- <Discounted.h> ---------------- \n \n#include <Item.h> \n#include <utility> \n \nclass Discounted \n{ \n public: \n   Discounted( double discount, Item item ) \n      : item_( std::move(item) ) \n      , factor_( 1.0 - discount ) \n   {} \n \n   Money price() const \n   { \n      return item_.price() * factor_; \n   } \n \n private: \n   Item item_; \n   double factor_; \n}; \n \n \n//---- <Taxed.h> ---------------- \n \n#include <Item.h> \n#include <utility> \n \nclass Taxed \n{ \n public: \n   Taxed( double taxRate, Item item ) \n      : item_( std::move(item) ) \n      , factor_( 1.0 + taxRate ) \n   {} \n \n   Money price() const \n   { \n      return item_.price() * factor_; \n   } \n \n private: \n   Item item_; \n   double factor_; \n};\nIt’s particularly interesting to note that neither of these two classes are\nderived from any base class, yet both perfectly implement the Decorator\ndesign pattern. On the one hand, they implement the operations required by\nthe Item wrapper to count as an item (in particular , the price() member\nfunction and the copy constructor), but on the other hand, they own an\nItem. Therefore, both enable you to combine Decorators arbitrarily , as\ndemonstrated in the following main() function:\n#include <ConferenceTicket.h> \n#include <Discounted.h> \n#include <Taxed.h> \n \nint main() \n{ \n   // 20% discount, 15% tax: (499*0.8)*1.15 = 459.08 \n   Item item(Taxed(0.19, Discounted(0.2, ConferenceTicket{""Core \nC++"",499.0}))); \n \n   Money const totalPrice = item.price(); \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\n“Wow, this is beautiful: there are no pointers, no manual allocations, and it\nfeels very natural and intuitive. But at the same time, it’ s extremely flexible.\nThis is too good to be true—there must be a catch. What about the\nperformance?” you say . Well, you sound like you expect a total\nperformance breakdown. So let’ s benchmark this solution. Of course, I’m\nusing the same benchmark as for the compile-time version of Decorator and\njust adding the third solution based on T ype Erasure. The performance\nnumbers are shown in Table 9-2 .\nTable 9-2. Performance r esults for the T ype\nErasur e Decorator implementation (normalized\nperformance)\nGCC 1 1.1 Clang 1 1.1\nClassic Decorator 1.0 1.0\nCompile-time Decorator 0.078067 0.080313\nType Erasure Decorator 0.997510 0.971875\nAs you can see, the performance is not worse than the performance of the\nother , classic runtime solution. In fact, the performance even appears to be a\ntiny bit better , but although this is an average of many runs, I wouldn’ t put\ntoo much emphasis on that. However , remember that there are multiple\noptions to improve the performance of the T ype Erasure solution, as\ndemonstrated in “Guideline 33: Be A ware of the Optimization Potential of\nType Erasure” .\nWhile performance may not be the primary strength of the runtime\nsolution(s) (at least in comparison to a compile-time solution), it definitely\nshines when it comes to runtime flexibility . For instance, it is possible to\ndecide at runtime to wrap any Item in another Decorator (based on user\ninput, based on the result of a computation, …). This, of course, will again\nyield an Item, which, together with many other Items, can be stored in a\nsingle container . It indeed gives you an enormous runtime flexibility .\nAnother strength is the ability to hide implementation details in source files\nmore easily . While this may result in a loss of runtime performance, it will\nlikely result in better compile times. Most importantly: any modification to\nthe hidden code will not af fect any other code and thus save you a lot of\nrecompilations, because the implementation details are more strongly\nencapsulated.\nIn summary , both the compile-time and runtime solutions are value based\nand lead to simpler , more comprehensible user code. However , they also\ncome with individual strengths and weaknesses: while the runtime approach\noffers more flexibility , the compile-time approach dominates with respect to\nperformance. In reality , you will rarely end up with a pure compile time or\nruntime approach, but you will very often find yourself somewhere between\nthese two extremes. Make sure you know your options: weigh them against\neach other and find a compromise that perfectly combines the best of both\nworlds and fits your particular situation.\nGUIDELINE 36: UNDERSTAND THE TRADE-OFF\nBETWEEN RUNTIME AND COMPILE-TIME\nABSTRACTION\nBe aware of both runtime and compile-time implementations of\nthe Decorator design pattern.\nUnderstand that compile-time solutions usually perform better but\nlimit runtime flexibility and encapsulation.\nUnderstand that runtime solutions are more flexible and are good\nat hiding details but perform worse.\nPrefer a value semantics  solution to a reference semantics  solution.\n1 Remember “Guideline 2: Design for Change”  and Core Guideline C.133 : “Avoid protected\ndata.”\n2 See “Guideline 20: Favor Composition over Inheritance”  for a discussion on why so many\ndesign patterns draw their power from composition rather than inheritance.\n3 A null object  represents an object with neutral (null) behavior . As such, it can be seen as a\ndefault for a Strategy implementation.\n4 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n5 You may be wondering if this is the most reasonable approach for dealing with taxes. No,\nunfortunately it’ s not. That’ s because first, as usual, reality is so much more complex than this\nsimple, educational example, and second, because in this form it’ s easy to apply taxes\nincorrectly . While I can’ t help with the first point (I’m just a mere mortal), I will go into detail\nabout the second point at the end of this guideline.\n6 If you’re wondering about the incomplete implementation: the focus here is entirely on how\nto design  allocators, not on how to implement  an allocator . For a thorough introduction on how\nto implement a C++17 allocator , see Nicolai Josuttis’ s C++17 - The Complete Guide .\n7 The metaphor of Strategy being the guts of an object and Decorator being the skin originates\nfrom the GoF book.\n8 Scott Meyers, Effective C++ , 3rd ed. (Addison-W esley , 2005).\n9 If you’re thinking that the original price() function should be renamed netPrice() to\nreflect its true purpose, then I agree.\n10 Note that it is only possible to use floating-point values as non-type template parameters\n(NTTPs)  since C++20.  Alternatively , you could store the discount and tax rates in the form of\ndata members.\n1 1 Alternatively , in particular if you cannot use C++20 concepts yet, this is an opportunity to use\nthe Curiously Recurring T emplate Pattern (CRTP) ; see “Guideline 26: Use CR TP to Introduce\nStatic T ype Categories” .\n12 To avoid a visit from the tax collection of fice, I should explicitly state that I’m aware of the\nquestionable nature of the Discounted<0.2,Taxed<0.19,ConferenceTicket>> class (see\nalso the list of potential problems of Decorator at the end of “Guideline 35: Use Decorators to\nAdd Customization Hierarchically” ). In my defense: it’ s an obvious permutation of decorators,\nwhich is well suited for this benchmark.\n13 For a thorough overview of T ype Erasure, see Chapter 8  and in particular “Guideline 32:\nConsider Replacing Inheritance Hierarchies with T ype Erasure” .",11293
121-Guideline 37 Treat Singleton as an Implementation Pattern Not a Design Pattern.pdf,121-Guideline 37 Treat Singleton as an Implementation Pattern Not a Design Pattern,"Chapter 10. The Singleton\nPattern\nIn this chapter , we take a look at the (in-)famous Singleton  pattern. I know ,\nyou may already be acquainted with Singleton, and you may already have a\nstrong opinion about it. It is even possible that you consider Singleton an\nantipattern and thus ask yourself how I mustered the courage to include it in\nthis book. W ell, I am aware that Singleton is not particularly popular and in\nmany circles has a rather bad reputation, in particular because of the global\nnature of Singletons. From that perspective, however , it might be very\nsurprising to learn that there are a couple of “Singleton”-like instances in\nthe C++ Standard Library . Seriously! And, honestly , they work\nfantastically! Therefore, we should seriously talk about what  a Singleton is,\nwhen  Singleton works, and how to deal with Singleton properly .\nIn “Guideline 37: T reat Singleton as an Implementation Pattern, Not a\nDesign Pattern” , I will explain the Singleton pattern and demonstrate how it\nworks by a very  commonly used implementation, the so-called  Meyers’\nSingleton . I will, however , also make a strong ar gument to not treat\nSingleton as a design pattern but as an implementation pattern .\nIn “Guideline 38: Design Singletons for Change and T estability ”, we accept\nthe fact that sometimes we need a solution to represent the few global\naspects in our code. This is what the Singleton pattern is often used for .\nThis also means that we are confronted by the usual problems of\nSingletons: global state; many strong, artificial dependencies; and an\nimpeded changeability and testability . While these sound like excellent\nreasons to avoid Singleton after all, I will show you that by proper software\ndesign, you can combine the Singleton benefits with excellent changeability\nand testability .",1841
122-The Singleton Pattern Explained.pdf,122-The Singleton Pattern Explained,"Guideline 37: Treat Singleton as an\nImplementation Pattern, Not a Design Pattern\nLet me start by addressing the elephant in the room:\nSingleton is not a design pattern.\nIf you haven’ t heard about Singleton before, then this might not make any\nsense at all, but bear with me. I promise to explain Singleton shortly . If you\nhave  heard about Singleton before, then I assume you’re either nodding in\nagreement with a sympathizing “I know” look on your face, or you are\nutterly stunned and initially don’ t know what to say . “But why not?” you\neventually dare to ask. “Isn’ t it one of the original design patterns from the\nGang of Four book?” Y es, you’re correct: Singleton is one of the 23 original\npatterns documented in the GoF book. At the time of writing, Wikipedia\ncalls it a design pattern, and it is even listed as a design pattern in Steve\nMcConnell’ s bestseller Code Complete . Nevertheless, it still isn’ t a design\npattern, because it doesn’ t have the properties of a design pattern. Let me\nexplain.\nThe Singleton Pattern Explained\nSometimes  you may want to guarantee that there is only one, and exactly\none, instance of a particular class. In other words, you have a Highlander\nsituation: “There can be only one.”  This might make sense for the system-\nwide database, the one and only logger , the system clock, the system\nconfiguration, or , in short, any class that should not be instantiated multiple\ntimes, since it represents something that exists only once. That is the intent\nof the Singleton pattern.\nTHE SINGLETON PATTERN\nIntent: “Ensure  a class has only one instance, and provide a global point of access to\nit.”1\n2\n3\nThis intent is visualized by the Gang of Four with the UML diagram in\nFigure 10-1 , which introduces the instance() function as the global point\nof access to the unique instance.\nFigur e 10-1. The UML r epresentation of the Singleton  pattern\nThere  are multiple ways to restrict the number of instantiations to exactly\none. Definitely one of the most useful and therefore most commonly used\nforms of Singleton is the Meyers’ Singleton.  The following Database\nclass is implemented as a Meyers’ Singleton:\n \n//---- <Database.h> ---------------- \n \nclass Database final \n{ \n public: \n   static Database& instance()  \n \n   { \n      static Database db;  // The one, unique instance \n      return db; \n   } \n \n   bool write( /*some arguments*/ ); \n   bool read( /*some arguments*/ ) const; \n   // ... More database-specific functionality 4\n \n   // ... Potentially access to data members \n \n private: \n   Database() {}  \n \n   Database( Database const& ) = delete; \n   Database& operator=( Database const& ) = delete; \n   Database( Database&& ) = delete; \n   Database& operator=( Database&& ) = delete; \n \n   // ... Potentially some data members \n}; \nThe Meyers’ Singleton evolves around the fact that it’ s possible to access\nthe single instance of the Database class onlhy via the public, static\ninstance() function (\n ):\n#include <Database.h> \n#include <cstdlib> \n \nint main() \n{ \n   // First access, database object is created \n   Database& db1 = Database::instance(); \n   // ... \n \n   // Second access, returns a reference to the same object \n   Database& db2 = Database::instance(); \n   assert( &db1 == &db2 ); \n \n   return EXIT_SUCCESS; \n}\nIndeed, this function is the only way to get a Database: all functionality\nthat could possibly be used to create, copy , or move an instance is either\ndeclared in the private section or is explicitly deleted. Although this\nappears to be pretty straightforward, one implementation detail is of special\ninterest: note that the default constructor is explicitly defined and not\ndefaulted (\n ). The reason is if it were defaulted, up to C++17 , it would\nbe possible to create a Database with an empty set of braces, i.e., via value\ninitialization :5\n#include <cstdlib> \n \nclass Database \n{ \n public: \n   // ... As before \n \n private: \n   Database() = default;  // Compiler generated default constructor \n \n   // ... As before \n}; \n \nint main() \n{ \n   Database db;    // Does not compile: Default initialization \n   Database db{};  // Works, since value initialization results in aggregate \n                   //   initialization, because Database is an aggregate type \n \n   return EXIT_SUCCESS; \n}\nUp to C++17, the Database class counts as an  aggregate type , which means\nthat value initialization  would be performed via aggregate initialization .\nAggr egate initialization , in turn, ignores the default constructor , including\nthe fact that it is private, and simply performs a zero initialization  of the\nobject. Thus, value initialization enables you to still create an instance. If,\nhowever , you provide the default constructor , then the class does not count\nas an aggregate type, which prevents aggregate initialization.\nThe instance() function  is implemented in terms of a static local\nvariable . This means that the first time control passes through the\ndeclaration, the variable is initialized in a thread-safe way , and on all further\ncalls the initialization is skipped.  On every call, the first and all subsequent\ncalls, the function returns a reference to the static local variable.\nThe rest of the Database class is pretty much what you would expect from\na class representing a database: there are some public, database-related\nfunctions (e.g., write() and read()) and there could be some data\nmembers, including access functions. In other words, except for the6\n7",5598
123-Singleton Does Not Manage or Reduce Dependencies.pdf,123-Singleton Does Not Manage or Reduce Dependencies,"instance() member function and the special members, Database is just a\nnormal class.\nSingleton Does Not Manage or Reduce Dependencies\nNow , with  one possible implementation of a Singleton in mind, let’ s go\nback to my claim that Singleton is not a design pattern. First, let’ s remind\nourselves of the properties of a design pattern, which I defined in\n“Guideline 1 1: Understand the Purpose of Design Patterns” :\nA design pattern:\nHas a name\nCarries an intent\nIntroduces an abstraction\nHas been proven\nThe Singleton pattern definitely has a name, and it definitely has an intent.\nNo question there. I would also claim that it has been proven over the years\n(although there may be skeptical voices that point out that Singleton is\nrather infamous). However , there is no kind of abstraction: no base class, no\ntemplate parameters, nothing. Singleton  does not represent an abstraction\nitself, and it does not introduce an abstraction. In fact, it isn’ t concerned\nwith the structure of code or with the interaction and interdependencies of\nentities, and hence it isn’ t aiming at managing or reducing dependencies.\nThis, though, is what I defined to be an integral part of software design.\nInstead, Singleton is focused on restricting the number of instantiations to\nexactly one. Thus, Singleton is not a design pattern but merely an\nimplementation pattern.\n“Then why is it listed as a design pattern in so many important sources?”\nyou ask. This is a fair and good question. There may be three answers to\nthat. First, in other programming languages, in particular languages where\nevery class can automatically represent an abstraction, the situation may be\ndifferent. While I acknowledge this, I still believe that the intent of the8\nSingleton pattern is primarily tar geted for implementation details and not\nfor dependencies and decoupling.\nSecond, Singleton is very commonly used (although often also misused), so\nit is definitely a pattern. Since there are Singletons in many dif ferent\nprogramming languages, it does not appear to be just an idiom of the C++\nprogramming language. As a consequence, it appears reasonable to call it a\ndesign pattern. This chain of ar guments may sound plausible to you, but I\nfeel it falls short of distinguishing between software design and\nimplementation details. This is why in “Guideline 1 1: Understand the\nPurpose of Design Patterns” , I introduced the term implementation pattern\nto distinguish between dif ferent kinds of language-agnostic patterns such as\nSingleton .\nAnd third, I believe that we are still in the process of understanding\nsoftware design and design patterns. There is no common definition of\nsoftware design. For that reason, I came up with one in “Guideline 1:\nUnderstand the Importance of Software Design ”. There is no common\ndefinition of design patterns, either . This is why I came up with one in\n“Guideline 1 1: Understand the Purpose of Design Patterns” . I strongly\nbelieve that we must talk more about software design and more about\npatterns to come to a common understanding of the necessary terminology ,\nespecially in C++.\nIn summary , you do not use a Singleton to decouple software entities. So\ndespite the fact that it is described in the famous GoF book, or in Code\nComplete , or even listed as a design pattern on Wikipedia , it does not serve\nthe purpose of a design pattern. Singleton is merely dealing with\nimplementation details, and as such you should treat it as an\nimplementation pattern.9",3534
124-Singletons Impede Changeability and Testability.pdf,124-Singletons Impede Changeability and Testability,"GUIDELINE 37: TREAT SINGLETON AN\nIMPLEMENTATION PATTERN, NOT A DESIGN PATTERN\nThe goal of Singleton is not to decouple or manage dependencies,\nand thus it does not fulfill the expectations of a design pattern.\nApply the Singleton pattern with the intent to restrict the number\nof instances of a particular class to exactly one.\nGuideline 38: Design Singletons for Change\nand Testability\nSingleton  is indeed a rather infamous pattern: there are many voices out\nthere that describe Singleton as a general problem in code, as an antipattern,\nas dangerous, or even as evil. Therefore, there is a lot of advice out there to\navoid the pattern, among others, Core Guideline I.3 :\nAvoid singletons.\nOne of the primary reasons why people dislike Singleton is that it often\ncauses artificial dependencies and obstructs testability . As such, it runs\ncontrary to two of the most important and most general guidelines in this\nbook: “Guideline 2: Design for Change”  and “Guideline 4: Design for\nTestability” . From that perspective, Singleton indeed appears to be a\nproblem in code and should be avoided. However , despite all the good-\nintentioned warnings, the pattern is persistently used by many developers.\nThe reasons for that are manifold but probably mainly related to two facts:\nfirst, sometimes (and let’ s agree on sometimes ) it is desirable to express the\nfact that something exists only once and should be available for many\nentities in the code. Second, sometimes Singleton appears to be the proper\nsolution, as there are global aspects to represent.\nSo, let’ s do the following: instead of ar guing that Singleton is always bad\nand evil, let’ s focus on those few situations where we need to represent a10\nglobal aspect in our program  and discuss how to represent this aspect\nproperly , but still design for change and testability .\nSingletons Represent Global State\nSingletons  are mostly used to represent entities in a program that logically\nand/or physically exist only once and that should be used by many other\nclasses and functions.  Common examples are the system-wide database,\nlogger , clock, or configuration. These examples, including the term system-\nwide , give an indication of the nature of these entities: they commonly\nrepresent globally available functionality or data, i.e., global state. From\nthat perspective, the Singleton pattern appears to make sense: by preventing\neveryone from creating new instances, and by forcing everyone to use the\none instance, you can guarantee uniform and consistent access to this global\nstate across all using entities.\nThis representation and introduction of global state, however , explains why\nSingleton is commonly considered a problem. As Michael Feathers\nexpressed it:\nThe singleton pattern is one of the mechanisms people use to make global\nvariables. In general, global variables ar e a bad idea for a couple of\nreasons. One of them is opacity .\nGlobal variables are indeed a bad idea, particularly for one important\nreason: the term variable  suggests that we are talking about  mutable  global\nstate. And that kind of state can indeed cause a lot of headaches. T o be\nexplicit, mutable global state is frowned upon (in general, but especially in\na multithreaded environment), as it is dif ficult, costly , and likely both to\ncontrol access and guarantee correctness. Furthermore, global (mutable)\nstate is very hard to reason about, as read and write access to this state\nusually happens invisibly within some function, which, based on its\ninterface, does not reveal the fact that it uses the global state. And last but\nnot least, if you have several globals, whose lifetimes depend on one\nanother and that are distributed over several compilation units, you  might1 1\n12\nbe facing the static initialization or der fiasco  (SIOF ). Obviously , it is\nbeneficial to avoid global state as much as possible.\nThe problem of global state, however , is a problem that we can’ t resolve by\navoiding Singletons. It’ s a general problem, unrelated to any particular\npattern. The same problem, for instance, also exists for the  Monostate\npattern, which enforces a single, global state but allows for any number of\ninstantiations.  So on the contrary , Singleton can help deal with the global\nstate by constraining access to it. For instance, as Miško Hevery explains in\nhis 2008 article, Singletons that provide a unidirectional data flow to or\nfrom some global state are acceptable:  a Singleton implementing a logger\nwould only allow you to write data but not read it. A Singleton representing\na system-wide configuration or clock would only allow you to read the data\nbut not write it, thus representing a global constant . The restriction to\nunidirectional data flow helps avoid many of the usual problems with global\nstate. Or in the words of Miško Hevery (the emphasis being mine):\nAppr opriate  use of “Global” or semi-Global states can gr eatly simplify\nthe design of applications […].\nSingletons Impede Changeability and T estability\nGlobal state  is an intrinsic problem of Singletons. However , even if we feel\ncomfortable with representing global state with a Singleton, there are\nserious consequences: functions that use Singletons depend on the\nrepresented global data and thus become harder to change and harder to\ntest. T o better understand this, let’ s revive the Database Singleton from\n“Guideline 37: T reat Singleton as an Implementation Pattern, Not a Design\nPattern” , which is now actively used by a couple of arbitrary classes,\nnamely Widget and Gadget:\n//---- <Widget.h> ---------------- \n \n#include <Database.h> \n \nclass Widget \n{ 13\n14\n15\n16\n17\n public: \n   void doSomething( /*some arguments*/ ) \n   { \n      // ... \n      Database::instance().read( /*some arguments*/ ); \n      // ... \n   } \n}; \n \n \n//---- <Gadget.h> ---------------- \n \n#include <Database.h> \n \nclass Gadget \n{ \n public: \n   void doSomething( /*some arguments*/ ) \n   { \n      // ... \n      Database::instance().write( /*some arguments*/ ); \n      // ... \n   } \n};\nWidget and Gadget both require access to the system-wide Database. For\nthat reason, they call the Database::instance() function and\nsubsequently the read() and write() functions.\nSince they use the Database and thus depend on it, we would like them to\nreside in architecture levels below  the level of the Database Singleton. That\nis because, as you remember from “Guideline 2: Design for Change” , we\ncan call it a proper architecture only if all dependency arrows run toward\nthe high levels (see Figure 10-2 ).\nFigur e 10-2. The desir ed dependency graph for a Database implemented as a Singleton\nAlthough  this dependency structure may be desirable, unfortunately it is\nonly an illusion: the Database class is not an abstraction but a concrete\nimplementation, representing the dependency on a very specific database!\nTherefore, the real dependency structure is inverted and looks something\nlike Figure 10-3 .\nThe actual  dependency structure utterly fails the Dependency Inversion\nPrinciple (DIP) (see “Guideline 9: Pay Attention to the Ownership of\nAbstractions” ): all dependency arrows point toward the lower level. In other\nwords, right now there is no software architecture!\nFigur e 10-3. The actual  dependency graph for a Database implemented as a Singleton\nSince the Database is a concrete class and not an abstraction, there are\nstrong and unfortunately even invisible dependencies from all over the code\nto the specific implementation details and design choices of the Database\nclass. This may—in the worst case—include a dependency on vendor -\nspecific details that become visible throughout the code, manifest in many\ndifferent places, and later make changes excruciatingly hard or even\nimpossible. Due to that, the code becomes much more dif ficult to change.\nAlso consider how badly tests are af fected by this dependency . All tests that\nuse one of the functions depending on the Database Singleton become\nthemselves dependent on the Singleton. This means, for instance, that for\nevery test using the Widget::do Something() function, you would always\nhave to provide the one and only Database class. The unfortunate, but also\nsimple, reason is that none of these functions provide you with a way to\nsubstitute the Database with something else: any kind of stub, mock, or\nfake.  They all treat the Database Singleton as their shiny , precious secret.\nTestability is therefore severely impeded, and writing tests becomes so\nmuch harder that you might be tempted to not write them at all.\nThis example indeed demonstrates the usual problems with Singletons and\nthe unfortunate artificial dependencies they introduce. These dependencies\nmake the system more inflexible and more rigid, and thus harder to change\nand test. That, of course, should not be. On the contrary , it should be easy to\nreplace a database implementation with another one, and it should be easy\nto test functionality that uses a database. For these exact reasons, we must\nmake sure that the Database becomes a true implementation detail on the\nlow level of a proper architecture.\n“But wait a second, you just said that if the Database is an implementation\ndetail, there is no architecture, right?” Y es, I said that. And there is nothing\nwe can do as it is: the Database Singleton does not represent any\nabstraction and does not enable us to deal with dependencies at all.\nSingleton is just not a design pattern. So in order to remove the\ndependencies on the Database class and make the architecture work, we18\n19\n20",9693
125-Inverting the Dependencies on a Singleton.pdf,125-Inverting the Dependencies on a Singleton,"will have to design for change and testability by introducing an abstraction\nand using a real design pattern. T o achieve that, let’ s take a look at an\nexample with a good way to deal with global aspects, using Singletons from\nthe C++ Standard Library .\nInverting the Dependencies on a Singleton\nI’m returning to a true El Dorado of design patterns, which I have used\nseveral times to demonstrate dif ferent design patterns: the C++17\npolymorphic memory resources:\n \n#include <array> \n#include <cstddef> \n#include <cstdlib> \n#include <memory_resource> \n#include <string> \n#include <vector> \n// ... \n \nint main() \n{ \n   std::array<std::byte,1000> raw;  // Note: not initialized! \n \n   std::pmr::monotonic_buffer_resource \n      buffer{ raw.data(), raw.size(), std::pmr::null_memory_resource() };  \n \n \n   std::pmr::vector<std::pmr::string> strings{ &buffer }; \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nIn this example, we configure the\nstd::pmr::monotonic_buffer_resource , called buffer, to work only\nwith the static memory contained in the given std::array raw (\n). If this\nmemory is depleted, buffer will try to acquire new memory via its\nupstream allocator , which we specify to be std::pmr::null \n_memory_resource(). Allocating via this allocator will never return any\nmemory but will always fail with the std::bad_alloc() exception. Thus,\nbuffer is restricted to the 1,000 bytes provided by raw.\nWhile you should immediately remember and recognize this as an example\nof the Decorator design pattern, this also serves as an example of the\nSingleton pattern: the std::pmr::null_memory_resource()  function\nreturns a pointer to the same allocator every time the function is called and\nthus acts as a single point of access to the one and only instance of\nstd::pmr::null_memory_resource. Thus, the returned allocator acts as a\nSingleton. Although this Singleton does not provide a unidirectional flow of\ndata (after all, we can both allocate memory and give it back), Singleton\nstill feels like a reasonable choice, as it represents one kind of global state:\nmemory .\nIt is particularly interesting and important to note that this Singleton does\nnot make you depend on the specific implementation details of the\nallocator . Quite the opposite: the std::pmr::null_memory_resource()\nfunction returns a pointer to std::pmr::memory_resource. This class\nrepresents a base class for all kinds of allocators (at least in the realm of\nC++17), and thus serves as an abstraction. Still,\nstd::pmr::null_memory_resource()  represents a specific allocator , a\nspecific choice, which we now depend on. As this functionality is in the\nStandard Library , we tend to not recognize it as a dependency , but generally\nspeaking it is: we are not provided with an opportunity to replace the\nstandard-specific implementation.\nThis changes if we replace the call to\nstd::pmr::null_memory_resource()  with a call to\nstd::pmr::get_default_resource()  (\n):\n \n#include <memory_resource> \n// ... \n \nint main() \n{ \n   // ... \n \n   std::pmr::monotonic_buffer_resource \n      buffer{ raw.data(), raw.size(), std::pmr::get_default_resource() };  \n \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nThe std::pmr::get_default_resource()  function also returns a pointer\nto std::pmr::memory_resource, which represents an abstraction for the\nsystem-wide default allocator . By default, the returned allocator is returned\nby the std::new_delete_resource() function. However , amazingly , this\ndefault can be customized by the std::pmr::set_default_resource()\nfunction:\nnamespace std::pmr { \n \nmemory_resource* set_default_resource(memory_resource* r) noexcept; \n \n} // namespace std::pmr\nWith this function, we can define the\nstd::pmr::null_memory_resource()  as the new system-wide default\nallocator (\n ):\n \n// ... \n \nint main() \n{ \n   // ... \n \n   std::pmr::set_default_resource( std::pmr::null_memory_resource() );  \n \n \n   std::pmr::monotonic_buffer_resource \n      buffer{ raw.data(), raw.size(), std::pmr::get_default_resource() }; \n \n   // ... \n \n   return EXIT_SUCCESS; \n} \nWith std::pmr::set_default_resource() , you are able to customize the\nsystem-wide allocator . In other words, this function provides you with the\nability to inject the dependency on this allocator . Does this ring a bell? Does\nthis sound familiar? I very much hope this makes you think about another ,\nessential design pattern… drum r oll…yes, correct: the Strategy design\npattern.\nIndeed, this is a Strategy . Using this design pattern is a fantastic choice,\nbecause it has an amazing ef fect on the architecture. While\nstd::pmr::memory_resource represents an abstraction from all possible\nallocators and thus can reside on the high level of the architecture, any\nconcrete implementation of an allocator , including all (vendor -)specific\nimplementation details, can reside on the lowest level of the architecture.\nAs a demonstration, consider this sketch of the CustomAllocator class:\n//---- <CustomAllocator.h> ---------------- \n \n#include <memory_resource> \n \nclass CustomAllocator : public std::pmr::memory_resource \n{ \n public: \n   // There is no need to enforce a single instance \n   CustomAllocator( /*...*/ ); \n   // No explicitly declared copy or move operations \n \n private: \n   void* do_allocate( size_t bytes, size_t alignment ) override; \n \n   void do_deallocate( void* ptr, size_t bytes, \n                       size_t alignment ) override; \n \n   bool do_is_equal( \n      std::pmr::memory_resource const& other ) const noexcept override; \n \n   // ... \n};\nNote that CustomAllocator publicly inherits from\nstd::pmr::memory_resource in order to qualify as a C++17 allocator .\nDue to that, you can establish an instance of CustomAllocator as the new21\nsystem-wide default allocator with the\nstd::pmr::set_default_resource()  function (\n ):\n \n#include <CustomAllocator.h> \n \nint main() \n{ \n   // ... \n   CustomAllocator custom_allocator{ /*...*/ }; \n \n   std::pmr::set_default_resource( &custom_allocator );  \n \n   // ... \n} \nWhile the std::pmr::memory_resource base class resides on the highest\nlevel of the architecture, CustomAllocator is logically introduced on the\nlowest architectural level (see Figure 10-4 ). Thus, the Strategy pattern\ncauses an inversion of dependencies  (see “Guideline 9: Pay Attention to the\nOwnership of Abstractions” ): despite the Singleton-ness of the allocators,\ndespite representing global state, you depend on an abstraction instead of\nthe concrete implementation details.",6633
126-Applying the Strategy Design Pattern.pdf,126-Applying the Strategy Design Pattern,"Figur e 10-4. The dependency inversion achieved via the std::pmr::memory_resource abstraction\nAs a side note, it’ s worth pointing out that with this approach you can\ntrivially avoid any dependency on the order of initialization of globals (i.e.,\nSIOF), since you can explicitly manage the initialization order by creating\nall Singletons on the stack and in a single compilation unit:\nint main() \n{ \n   // The one and only system-wide clock has no lifetime dependencies. \n   // Thus it is created first \n   SystemClock clock{ /*...*/ }; \n \n   // The one and only system-wide configuration depends on the clock. \n   SystemConfiguration config{ &clock, /*...*/ }; \n \n   // ... \n}\nApplying the Strategy Design Pattern\nBased  on this previous example, you should now have an idea how to fix\nour Database example. As a reminder , the goal is to keep the Database\nclass as the default database implementation but to make it an\nimplementation detail, i.e., to remove all dependencies on the concrete\nimplementation. All you need to do is apply the Strategy  design pattern to\nintroduce an abstraction, alongside a global point of access and a global\npoint for  dependency injection , on the high level of our architecture. This\nwill enable anyone (and I really mean anyone, as you also follow the Open-\nClosed Principle (OCP); see “Guideline 5: Design for Extension” ) to\nintroduce a custom database implementation (both concrete\nimplementations as well as test stubs, mocks, or fakes) on the lowest level.\nSo let’ s introduce the following PersistenceInterface abstraction (\n ):\n \n//---- <PersistenceInterface.h> ---------------- \n \nclass PersistenceInterface  \n \n{ \n public: \n   virtual ~PersistenceInterface() = default; \n \n   bool read( /*some arguments*/ ) const  \n \n   { \n      return do_read( /*...*/ ); \n   } \n   bool write( /*some arguments*/ )  \n \n   { \n      return do_write( /*...*/ ); \n   } \n \n   // ... More database specific functionality \n \n private: \n   virtual bool do_read( /*some arguments*/ ) const = 0;  \n \n   virtual bool do_write( /*some arguments*/ ) = 0;  \n \n}; \n \nPersistenceInterface* get_persistence_interface();  \n \nvoid set_persistence_interface( PersistenceInterface* persistence );  \n \n \n// Declaration of the one 'instance' variable \nextern PersistenceInterface* instance;  \n \nThe PersistenceInterface base class provides the interface for all\npossible database implementations. For instance, it introduces a read() and\na write() function, split into the public interface part and the private\nimplementation part, based on the example set by the\nstd::pmr::memory_resource class (\n  and \n ). Of course, in reality it\nwould introduce a few more database-specific functions, but let read() and\nwrite() be suf ficient for this example.\nIn addition to the PersistenceInterface, you would also introduce a\nglobal point of access called get_persistence_interface() (\n) and a\nfunction to enable dependency injection  called\nset_persistence_interface() (\n). These two functions allow you to\naccess and set the global persistence system (\n ).\nThe Database class now inherits from the PersistenceInterface base\nclass and implements the required interface (hopefully adhering to the22\nLiskov Substitution Principle (LSP); see “Guideline 6: Adhere to the\nExpected Behavior of Abstractions” ):\n//---- <Database.h> ---------------- \n \nclass Database : public PersistenceInterface \n{ \n public: \n   // ... Potentially access to data members \n \n   // Make the class immobile by deleting the copy and move operations \n   Database( Database const& ) = delete; \n   Database& operator=( Database const& ) = delete; \n   Database( Database&& ) = delete; \n   Database& operator=( Database&& ) = delete; \n \n private: \n   bool do_read( /*some arguments*/ ) const override; \n   bool do_write( /*some arguments*/ ) override; \n   // ... More database-specific functionality \n \n   // ... Potentially some data members \n};\nIn our special setting, the Database class represents the default database\nimplementation. We need to create a default instance of the database, in\ncase no other persistence system is specified via the\nset_persistence_interface() function. However , if any other\npersistence system is established as the system-wide database before\nDatabase is created, we must not create an instance, as this would cause\nunnecessary and unfortunate overhead. This behavior is achieved by\nimplementing the get _persistence_interface() function with two\nstatic local variables  and an Immediately Invoked Lambda Expr ession\n(IILE)  (\n):\n \n//---- <PersistenceInterface.cpp> ---------------- \n \n#include <Database.h> \n \n// Definition of the one 'instance' variable \nPersistenceInterface* instance = nullptr; \n \nPersistenceInterface* get_persistence_interface() \n{ \n   // Local object, initialized by an \n   //   'Immediately Invoked Lambda Expression (IILE)' \n   static bool init = [](){  \n \n      if( !instance ) { \n         static Database db; \n         instance = &db; \n      } \n      return true;  // or false, as the actual value does not matter. \n   }();  // Note the '()' after the lambda expression. This invokes the \nlambda. \n \n   return instance; \n} \n \nvoid set_persistence_interface( PersistenceInterface* persistence ) \n{ \n   instance = persistence; \n} \nThe first time the execution flow enters the\nget_persistence_interface() function, the init static local variable is\ninitialized. If, at this point in time, the instance is already set, no\nDatabase is created. However , if it is not, the Database instance is created\nas another static local variable inside the lambda and bound to the\ninstance variable:\n#include <PersistenceInterface.h> \n#include <cstdlib> \n \nint main() \n{ \n   // First access, database object is created \n   PersistenceInterface* persistence = get_persistence_interface(); \n \n   // ... \n \n   return EXIT_SUCCESS; \n}\nThis implementation achieves the desired ef fect: Database becomes an\nimplementation detail, which no other code depends on and which can be\nreplaced at any time by a custom database implementation (see Figure 10-\n5). Thus, despite the Singleton-ness of Database, it does not introduce\ndependencies, and it can be easily changed and easily replaced for testing\npurposes.\nFigur e 10-5. The dependency graph for the r efactor ed, non- Singleton  Database\n“Wow, this  is a great solution. I bet I can use that in a few places in my own\ncodebase!” you say , with an impressed and appreciative look on your face.\n“But I see a potential problem: since I have to inherit from an interface\nclass, this is an intrusive solution. What should I do if I can’ t change a\ngiven Singleton class?” W ell, in that case you have two nonintrusive design\npatterns to choose from. Either you already have an inheritance hierarchy in\nplace, in which case you can introduce an Adapter to wrap the given\nSingleton (see “Guideline 24: Use Adapters to Standardize Interfaces” ), or\nyou don’ t have an inheritance hierarchy in place yet, in which case you can\nput the External Polymorphism design pattern to good use (see “Guideline\n31: Use External Polymorphism for Nonintrusive Runtime\nPolymorphism” ).\n“OK, but I see another , more serious problem: is this code truly thread-\nsafe?” Honestly , no, it is not. T o give one example for a possible problem: it\ncould happen that during the first call to get_persistence_interface(),\nwhich may take some time due to the setup of the Database instance, the\nset_persistence_interface() is called. In that case, either the\nDatabase is created in vain or the call to set_persistence_interface()\nis lost. However , perhaps surprisingly , this is not something that we need to\naddress. Here’ s why: remember that the instance represents global state. If\nwe assume that set_persistence_interface() can be called from\nanywhere in the code at any time, in general we can’ t expect that after\ncalling set_persistence_interface(), a call to\nget_persistence_interface() would return the set value. Hence, calling\nthe set_persistence_interface() function from anywhere in the code is\nlike pulling the rug from under somebody’ s feet. This is comparable to\ncalling std::move() on any lvalue:\ntemplate< typename T > \nvoid f( T& value ) \n{ \n   // ... \n   T other = std::move(value);  // Very bad move (literally)!",8471
127-Moving Toward Local Dependency Injection.pdf,127-Moving Toward Local Dependency Injection,"// ... \n}\nFrom this perspective, the set_persistence_interface() function\nshould be used at the very beginning of the program or at the beginning of a\nsingle test, not arbitrarily .\n“Shouldn’ t we make sure that the set_persistence_interface()\nfunction can be called only once?” you ask. W e most certainly could do\nthat, but this would artificially limit its use for testing purposes: we would\nnot be able to reset the persistence system at the beginning of every single\ntest.\nMoving T oward Local Dependency Injection\n“OK, I see. One  last question: since this solution involves global state that\ncan be changed, wouldn’ t it be better to use a more direct and more local\ndependency injection to the lower -level classes? Consider the following\nmodification of the Widget class, which is given its dependency upon\nconstruction:”\n//---- <Widget.h> ---------------- \n \n#include <PersistenceInterface.h> \n \nclass Widget \n{ \n public: \n   Widget( PersistenceInterface* persistence )  // Dependency injection \n      : persistence_(persistence) \n   {} \n \n   void doSomething( /*some arguments*/ ) \n   { \n      // ... \n      persistence_->read( /*some arguments*/ ); \n      // ... \n   } \n \n private: \n   PersistenceInterface* persistence_{}; \n};\nI completely agree with you. This may be the next step to address the\nproblem of global state. However , before we analyze this approach, keep in\nmind that this idea is only an option since we have already inverted the\ndependencies. Thanks to introducing an abstraction in the high level of our\narchitecture, we suddenly have choices and can talk about alternative\nsolutions. Hence, the first and most important step is to properly manage\nthe dependencies. But back to your suggestion: I really like the approach.\nThe interface of the Widget class becomes more “honest” and clearly\ndisplays all of its dependencies. And since the dependency is passed via the\nconstructor ar gument, the dependency injection becomes more intuitive and\nmore natural.\nAlternatively , you could pass the dependency on the\nWidget::doSomething() function directly:\n//---- <Widget.h> ---------------- \n \n#include <PersistenceInterface.h> \n \nclass Widget \n{ \n public: \n   void doSomething( PersistenceInterface* persistence, /*some arguments*/ ) \n   { \n      // ... \n      persistence->read( /*some arguments*/ ); \n      // ... \n   } \n};\nWhile this approach may not be the best for a member function, this may be\nyour only option for free functions. And again, the function becomes a little\nmore “honest” by explicitly stating its dependencies.\nHowever , there is a flip side to this direct dependency injection: this\napproach may quickly become unwieldy in lar ge call stacks. Passing a\ndependency through several levels of your software stack to make them\navailable at the point they are needed is neither convenient nor intuitive.\nAdditionally , especially in the presence of several Singletons, the solution\nquickly becomes cumbersome: passing, for instance, a\nPersistenceInterface, an Allocator, and the system-wide\nConfiguration through many layers of function calls just to be able to use\nthem on the lowest level truly is not the most elegant approach. For that\nreason, you may want to combine the ideas of providing a global access\npoint and a local dependency injection, for instance, by introducing a\nwrapper function:\n \n//---- <Widget.h> ---------------- \n \n#include <PersistenceInterface.h> \n \nclass Widget \n{ \n public: \n   void doSomething( /*some arguments*/ )  \n \n   { \n      doSomething( get_persistence_interface(), /*some arguments*/ ); \n   } \n \n   void doSomething( PersistenceInterface* persistence, /*some arguments*/ )  \n \n   { \n      // ... \n      persistence->read( /*some arguments*/ ); \n      // ... \n   } \n}; \nWhile we still provide the previous doSomething() function (\n ), we now\nadditionally provide an overload that accepts a PersistenceInterface as\na function ar gument (\n ). The second function does all the work, whereas\nthe first function now merely acts as a wrapper , which injects the globally\nset PersistenceInterface. In this combination, it’ s possible to make local\ndecisions and to locally inject the desired dependency , but at the same time\nit is not necessary to pass the dependency through many layers of function\ncalls.\nHowever , truth be told, while these solutions may work very well in this\ndatabase example and also in the context of managing memory , it might not\nbe the right approach for every single Singleton problem. So don’ t believe\nthat this is the only possible solution. After all, it depends. However , it is a\ngreat example of the general process of software design: identify the aspect\nthat changes or causes dependencies, then separate concerns by extracting a\nfitting abstraction. Depending on your intent, you will just have applied a\ndesign pattern. So consider naming your solution accordingly , and by that\nleave traces of your reasoning for others to pick up on.\nIn summary , the Singleton pattern certainly is not one of the glamorous\npatterns. It simply comes with too many disadvantages, most importantly\nthe usual flaws of global state. But still, despite the many negative aspects,\nif used judiciously , Singleton can be the right solution for representing the\nfew global aspects in your code in some situations. If it is, prefer Singletons\nwith unidirectional data flow , and design your Singletons for change and\ntestability by inverting the dependencies and enabling dependency injection\nwith the Strategy design pattern.\nGUIDELINE 38: DESIGN SINGLETONS FOR CHANGE\nAND TESTABILITY\nBe aware that Singleton represents global state, with all its flaws.\nAvoid global state as much as possible.\nUse Singleton judiciously and just for the few global aspects in\nyour code.\nPrefer Singletons with unidirectional data flow .\nUse the Strategy design pattern to invert dependencies on your\nSingleton to remove the usual impediments to changeability and\ntestability .\n1 Steve McConnell, Code Complete: A Practical Handbook of Softwar e Construction , 2nd ed.\n(Microsoft Press, 2004).\n2 “There can be only one” is the tagline of the 1986 movie Highlander  featuring Christopher\nLambert.\n3 Erich Gamma et al., Design Patterns: Elements of Reusable Object-Oriented Softwar e.\n4 The Meyers’ Singleton is explained in Item 4 of Scott Meyers’ s Effective C++ .\n5 I know that the explicit handling of the copy and move assignment operators appears to be\noverkill, but this gives me the opportunity to remind you about the Rule of 5 .\n6 This behavior has changed in C++20, since the declaration of any constructor by the user is\nnow enough to make a type nonaggregate.\n7 To be precise and to avoid complaints, if the static local variable is zero or constant\ninitialized, the initialization can happen before the function is entered. In our example, the\nvariable is indeed created in the first pass.\n8 In fact, a naive implementation of Singleton is creating lots of artificial dependencies itself;\nsee “Guideline 38: Design Singletons for Change and T estability ”.\n9 Without going into detail, I ar gue that there are several more so-called “design patterns” that\nfall in the category of implementation patterns, such as the  Monostate  pattern, the  Memento\npattern, and the  RAII idiom , which Wikipedia  lists as design patterns. While this might make\nsense in languages other than C++, the intent of RAII is most certainly not to reduce\ndependencies but to automate cleanup and encapsulate responsibility .\n10 Another such piece of advice is the CppCon 2020 talk by Peter Muldoon’ s “Retiring the\nSingleton Pattern: Concrete Suggestions for What to Use Instead” , which provides many useful\ntechniques for how to deal with Singletons in your codebase.\n1 1 If a Singleton is used for anything else, you should be very suspicious and consider it a\nmisuse of the Singleton pattern.\n12 Michael Feathers, Working Effectively with Legacy Code .\n13 The best summary of SIOF I’m aware of is given by Jonathan Müller in his accordingly\nnamed talk “Meeting C++ 2020” .\n14 “Globals are bad, m’kay?” as stated by Guy Davidson and Kate Gregory in Beautiful C++:\n30 Cor e Guidelines for W riting Clean, Safe, and Fast Code  (Addison-W esley).\n15 The Monostate pattern, to my best knowledge, was first mentioned in the September issue of\nthe 1996 C++ Report  in the article “Monostate Classes: The Power of One” by Steve Ball and\nJohn Crawford (see Stanley B. Lippmann, ed., More C++ Gems  (Cambridge University\nPress)). It is also described in Martin Reddy’ s API Design for C++  (Mor gan Kaufmann).\nMonostate, in contrast to Singleton, allows any number of instances of a type, but makes sure\nthat there is only a single state for all instances. As such, the pattern should not be confused\nwith std::monostate, which is used as a well-behaved empty alternative in std::variant.\n16 Miško Hevery , “Root Cause of Singletons” , The T estability Explor er (blog), August 2008.\n17 Ibid.\n18 For an explanation about the dif ferent kinds of test doubles, see Martin Fowler ’s article\n“Mocks Aren’ t Stubs” . For examples of how to use these in C++, refer to Jef f Langr ’s Modern\nC++ Pr ogramming with T est-Driven Development .\n19 But I am sure you won’ t be deterred from writing the tests anyway , despite it being dif ficult.\n20 This is also one of the strong ar guments in Robert C. Martin’ s Clean Ar chitectur e.\n21 For the design pattern experts, I should explicitly point out that the\nstd::pmr::get_default_resource() function itself fulfills the intent of another design\npattern: the Facade  design pattern. Unfortunately , I do not go into detail about Facade in this\nbook.\n22 The separation into a public interface and a private implementation is an example of the\nTemplate Method design pattern. Unfortunately , in this book I can’ t go into detail about the\nmany benefits of this design pattern .",10061
128-11. The Last Guideline.pdf,128-11. The Last Guideline,,0
129-Guideline 39 Continue to Learn About Design Patterns.pdf,129-Guideline 39 Continue to Learn About Design Patterns,"Chapter 1 1. The Last Guideline\nThere  is only one more guideline, one more piece of advice that I can\nbestow upon you. So here it is: the last guideline.\nGuideline 39: Continue to Learn About\nDesign Patterns\n“That’ s it? This is all you’ve got? Come on, there are so many more design\npatterns out there. We barely touched the surface!” you say . Well, honestly ,\nyou are completely correct; there is nothing I can add to that. But in my\ndefense, I was planning for many more patterns until reality struck me:\nthere is only so much information that you can fit into a book with 400\npages. But don’ t fret: in these 400 pages I’ve taken you on a journey\nthrough the  most important pieces of advice for any design that you will\nneed anywhere, anytime in your software development career:\nMinimize dependencies\nDealing with dependencies is the core of software design. And whatever\nkind of software you write, if you are seriously interested in making it\nlast, you will have to deal with dependencies: the necessary ones, but\nprimarily the artificial ones. Of course, your major goal is to reduce\ndependencies and hopefully even minimize them. To achieve this goal,\nyou will inevitably deal with design patterns.\nSeparate concerns\nThis may be the most important, central design guideline that you can\ntake away from this book. Separate concerns and your software\nstructures will detangle and become easier to understand, change, and\ntest. All design patterns, without exception, provide you with some way\nto separate concerns. The major dif ference between patterns is the way\nthey separate concerns, their intent . Although design patterns may be\nstructurally similar , their intent is always unique.\nPrefer composition to inheritance\nWhile inheritance is a powerful feature, the true strength of many\ndesign patterns stems from building on composition. For instance, the\nStrategy design pattern, one of the patterns that is used everywher e (and\nhopefully this has become obvious by now), primarily builds on\ncomposition to separate concerns, but then also of fers you the option to\nuse inheritance to extend the functionality . The same is true for Bridge,\nAdapter , Decorator , External Polymorphism, and Type Erasure.\nPrefer a nonintrusive design\nTrue flexibility and extendibility arise when it isn’ t necessary to modify\nexisting code but possible to just add new code. Therefore, any design\nthat is nonintrusive is preferable to design that intrusively modifies\nexisting code. Hence, design patterns such as Decorator , Adapter ,\nExternal Polymorphism, and Type Erasure are such valuable additions\nto your design pattern toolbox.\nPrefer value semantics  over reference semantics\nTo keep code simple, understandable, and away from dark corners such\nas nullptrs, dangling pointers, lifetime dependencies, etc., you should\nprefer to employ values instead of pointers and references. And C++ is a\nwonderful language to use for that purpose, as C++ takes value\nsemantics seriously . It allows you, the developer , to live a happy life in\nthe realm of value semantics. Surprisingly , as we have seen with\nstd::variant and Type Erasure, this philosophy does not necessarily\nhave a negative performance impact but may even increase\nperformance.\nIn addition to these general pieces of advice about software design, you\nhave gained insight into the purpose of design patterns. Now you know\nwhat a design pattern is.\nA design pattern:\nHas a name\nCarries an intent\nIntroduces an abstraction\nHas been proven\nEquipped  with this information, you will no longer fall for false claims\nabout some implementation detail being a design pattern (as I have been\nconfronted with multiple times in my career), for instance, the claim that\nsmart pointers ( std::unique_ptr, std::shared_ptr, etc.) or factory\nfunctions such as std::make_unique() are implementations of design\npatterns. Also, you are now familiar with several of the  most important and\nuseful design patterns, which will prove to be useful again and again:\nVisitor\nTo extend operations on a closed set of types, reach for the Visitor\ndesign pattern (possibly realized by std::variant).\nStrategy\nTo configure the behavior and “inject” it from outside, pick the Strategy\ndesign pattern (aka policy-based design).\nCommand\nTo abstract from dif ferent kinds of operations, possibly undoable\noperations, utilize the Command design pattern.\nObserver\nTo observe state change in some entities, choose the Observer design\npattern.\nAdapter\nTo adapt one interface to another one, nonintrusively , without changing\ncode, use the Adapter design pattern.\nCRTP\nFor a static abstraction, free of virtual functions (and you can’ t employ\nC++20 concepts yet), then apply the CR TP design pattern. CR TP might\nalso prove to be useful to create compile-time mixin classes.\nBridge\nTo hide implementation details and reduce physical dependencies, make\nuse of the Bridge design pattern.\nPrototype\nTo create a virtual copy , the Prototype design pattern is the right choice.\nExternal Polymorphism\nTo promote loose coupling by adding polymorphic behavior externally ,\nremember the External Polymorphism design pattern.\nType Erasur e\nFor the power of External Polymorphism in combination with the\nadvantages of value semantics, consider the T ype Erasure design\npattern.\nDecorator\nTo nonintrusively add responsibilities to an object, opt for the benefits\nof the Decorator design pattern.\nHowever , there are more  design patterns. Many more! Also a lot of\nimportant and useful design patterns. Therefore, you should continue to\nlearn about design patterns. And there are two ways to do that. First is\ngetting to know more patterns: learn about their intent and about their\nsimilarities and dif ferences compared to other design patterns . Also, don’ t\nforget that design patterns are about a dependency structure, not about\nimplementation details. Second, you should also get a better understanding\nabout each pattern and experience their advantages and shortcomings. For\nthat purpose, keep an eye out for design patterns used in the codebases you\nwork on. I promise you, you will find many of them: any attempt to manage\nand reduce dependencies is very likely proof of a design pattern. So yes,\ndesign patterns are everywhere !\nGUIDELINE 39: CONTINUE TO LEARN ABOUT DESIGN\nPATTERNS\nGet to know more design patterns and understand their intent.\nLearn more about the advantages and disadvantages of each design\npattern.\nFind design patterns in the wild to experience them hands-on.",6620
130-Index.pdf,130-Index,"About the Author\nKlaus Iglberger  is a freelance C++ trainer and consultant. He completed\nhis PhD in computer science in 2010 and has subsequently concentrated on\nlarge-scale C++ software design. He shares his expertise through popular\nC++ courses all around the world. He is also the creator and lead designer\nof the Blaze C++ math library , one of the or ganizers of the Munich C++\nuser group (MUC++) , and the (co-)or ganizer of the Back-to-Basics  and\nSoftware Design  tracks at CppCon .\nColophon\nThe animal on the cover of C++ Softwar e Development  is is the common\ncrane ( Grus grus , or “crane crane”). Also known as the Eurasian crane, the\ncommon crane is most often found throughout the Paleartic region, which\nspans northern Europe, northern Asia, and North Africa, though isolated\ngroups have been seen as far east as Ireland and as far west as Japan. The\nlargest nesting populations of common cranes can be found each year in\nRussia and Scandinavia.\nA lar ge, stately bird, the common crane is of medium size among crane\nspecies, with a body length of 39–51 inches and a wingspan of 71–94\ninches, and weighing 10–12 pounds on average. It has a slate-gray body\nwith a black face, a black-and-white neck, and a red crown. Every two\nyears or so, this migratory bird molts its feathers entirely , remaining\nflightless for six weeks while new feathers grow in. During migration,\nflocks of four hundred individuals or more may travel together . These\nflocks have been observed flying at altitudes of up to 33,000 feet, the\nsecond highest of any bird species.\nLike all cranes, the common crane is omnivorous, eating plant matter as\nwell as insects, amphibians, rodents, and other small animals. The cranes\ntypically forage in small groups on land or standing in shallow water ,\nprobing with their bills for food.\nCranes have featured in human art and iconography since ancient times,\nappearing in Aesop’ s Fables, inspiring traditional dances such as one\nperformed in Korea since 646 CE, and having association with gods in\nancient South Arabia and Greece, to share just a few examples. Several\nstyles of martial art, particularly kung fu, have taken inspiration from the\ngraceful movements of the crane, as popularized in the 1984 hit film The\nKarate Kid .\nWith a global population of around six hundred thousand as of 2014, the\ncommon crane has been classified by the IUCN as being of least concern,\nmaking it one of only four species of crane not considered threatened or\ndependent on conservation. Many of the animals on O’Reilly covers are\nendangered; all of them are important to the world.\nThe cover illustration is by Karen Montgomery , based on an antique line\nengraving from British Bir ds. The cover fonts are Gilroy Semibold and\nGuardian Sans. The text font is Adobe Minion Pro; the heading font is\nAdobe Myriad Condensed; and the code font is Dalton Maag’ s Ubuntu\nMono.",2934

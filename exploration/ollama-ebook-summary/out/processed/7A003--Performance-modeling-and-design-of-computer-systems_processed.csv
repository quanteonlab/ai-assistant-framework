Title,Text,Character Count
Contents,"Contents Preface xvii Acknowledgments xxiii I Introduction to Queueing 1 Motivating Examples of the Power of Analytical Modeling 3 1.1 What Is Queueing Theory? 3 1.2 Examples of the Power of Queueing Theory 5 2 Queueing Theory Terminology 13 2.1 Where We Are Heading 13 2.2 The Single-Server Network 13 2.3 Classiﬁcation of Queueing Networks 16 2.4 Open Networks 16 2.5 More Metrics: Throughput and Utilization 17 2.6 Closed Networks 20 2.6.1 Interactive (Terminal-Driven) Systems 21 2.6.2 Batch Systems 22 2.6.3 Throughput in a Closed System 23 2.7 Differences between Closed and Open Networks 24 2.7.1 A Question on Modeling 25 2.8 Related Readings 25 2.9 Exercises 26 II Necessary Probability Background 3 Probability Review 31 3.1 Sample Space and Events 31 3.2 Probability Deﬁned on Events 32 3.3 Conditional Probabilities on Events 33 3.4 Independent Events and Conditionally Independent Events 34 3.5 Law of Total Probability 35 3.6 Bayes Law 36 3.7 Discrete versus Continuous Random Variables 37 3.8 Probabilities and Densities 38 3.8.1 Discrete: Probability Mass Function 38 3.8.2 Continuous: Probability Density Function 41 3.9 Expectation and Variance 44 3.10 Joint Probabilities and Independence 47 vii viii contents 3.11 Conditional Probabilities and Expectations 49 3.12 Probabilities and Expectations via Conditioning 53 3.13 Linearity of Expectation 54 3.14 Normal Distribution 57 3.14.1 Linear Transformation Property 58 3.14.2 Central Limit Theorem 61 3.15 Sum of a Random Number of Random Variables 62 3.16 Exercises 64 4 Generating Random Variables for Simulation 70 4.1 Inverse-Transform Method 70 4.1.1 The Continuous Case 70 4.1.2 The Discrete Case 72 4.2 Accept-Reject Method 72 4.2.1 Discrete Case 73 4.2.2 Continuous Case 75 4.2.3 Some Harder Problems 77 4.3 Readings 78 4.4 Exercises 78 5 Sample Paths, Convergence, and Averages 79 5.1 Convergence 79 5.2 Strong and Weak Laws of Large Numbers 83 5.3 Time Average versus Ensemble Average 84 5.3.1 Motivation 85 5.3.2 Deﬁnition 86 5.3.3 Interpretation 86 5.3.4 Equivalence 88 5.3.5 Simulation 90 5.3.6 Average Time in System 90 5.4 Related Readings 91 5.5 Exercise 91 III The Predictive Power of Simple Operational Laws: “What-If” Questions and Answers 6 Little’s Law and Other Operational Laws 95 6.1 Little’s Law for Open Systems 95 6.2 Intuitions 96 6.3 Little’s Law for Closed Systems 96 6.4 Proof of Little’s Law for Open Systems 97 6.4.1 Statement via Time Averages 97 6.4.2 Proof 98 6.4.3 Corollaries 100 6.5 Proof of Little’s Law for Closed Systems 101 6.5.1 Statement via Time Averages 101 6.5.2 Proof 102 6.6 Generalized Little’s Law 102 contents ix 6.7 Examples Applying Little’s Law 103 6.8 More Operational Laws: The Forced Flow Law 106 6.9 Combining Operational Laws 107 6.10 Device Demands 110 6.11 Readings and Further Topics Related to Little’s Law 111 6.12 Exercises 111 7 Modiﬁcation Analysis: “What-If” for Closed Systems 114 7.1 Review 114 7.2 Asymptotic Bounds for Closed Systems 115 7.3 Modiﬁcation Analysis for Closed Systems 118 7.4 More Modiﬁcation Analysis Examples 119 7.5 Comparison of Closed and Open Networks 122 7.6 Readings 122 7.7 Exercises 122 IV From Markov Chains to Simple Queues 8 Discrete-Time Markov Chains 129 8.1 Discrete-Time versus Continuous-Time Markov Chains 130 8.2 Deﬁnition of a DTMC 130 8.3 Examples of Finite-State DTMCs 131 8.3.1 Repair Facility Problem 131 8.3.2 Umbrella Problem 132 8.3.3 Program Analysis Problem 132 8.4 Powers of P:n-Step Transition Probabilities 133 8.5 Stationary Equations 135 8.6 The Stationary Distribution Equals the Limiting Distribution 136 8.7 Examples of Solving Stationary Equations 138 8.7.1 Repair Facility Problem with Cost 138 8.7.2 Umbrella Problem 139 8.8 Inﬁnite-State DTMCs 139 8.9 Inﬁnite-State Stationarity Result 140 8.10 Solving Stationary Equations in Inﬁnite-State DTMCs 142 8.11 Exercises 145 9 Ergodicity Theory 148 9.1 Ergodicity Questions 148 9.2 Finite-State DTMCs 149 9.2.1 Existence of the Limiting Distribution 149 9.2.2 Mean Time between Visits to a State 153 9.2.3 Time Averages 155 9.3 Inﬁnite-State Markov Chains 155 9.3.1 Recurrent versus Transient 156 9.3.2 Inﬁnite Random Walk Example 160 9.3.3 Positive Recurrent versus Null Recurrent 162 9.4 Ergodic Theorem of Markov Chains 164 x contents 9.5 Time Averages 166 9.6 Limiting Probabilities Interpreted as Rates 168 9.7 Time-Reversibility Theorem 170 9.8 When Chains Are Periodic or Not Irreducible 171 9.8.1 Periodic Chains 171 9.8.2 Chains that Are Not Irreducible 177 9.9 Conclusion 177 9.10 Proof of Ergodic Theorem of Markov Chains∗178 9.11 Exercises 183 10 Real-World Examples: Google, Aloha, and Harder Chains∗190 10.1 Google’s PageRank Algorithm 190 10.1.1 Google’s DTMC Algorithm 190 10.1.2 Problems with Real Web Graphs 192 10.1.3 Google’s Solution to Dead Ends and Spider Traps 194 10.1.4 Evaluation of the PageRank Algorithm 195 10.1.5 Practical Implementation Considerations 195 10.2 Aloha Protocol Analysis 195 10.2.1 The Slotted Aloha Protocol 196 10.2.2 The Aloha Markov Chain 196 10.2.3 Properties of the Aloha Markov Chain 198 10.2.4 Improving the Aloha Protocol 199 10.3 Generating Functions for Harder Markov Chains 200 10.3.1 The z-Transform 201 10.3.2 Solving the Chain 201 10.4 Readings and Summary 203 10.5 Exercises 204 11 Exponential Distribution and the Poisson Process 206 11.1 Deﬁnition of the Exponential Distribution 206 11.2 Memoryless Property of the Exponential 207 11.3 Relating Exponential to Geometric via δ-Steps 209 11.4 More Properties of the Exponential 211 11.5 The Celebrated Poisson Process 213 11.6 Merging Independent Poisson Processes 218 11.7 Poisson Splitting 218 11.8 Uniformity 221 11.9 Exercises 222 12 Transition to Continuous-Time Markov Chains 225 12.1 Deﬁning CTMCs 225 12.2 Solving CTMCs 229 12.3 Generalization and Interpretation 232 12.3.1 Interpreting the Balance Equations for the CTMC 234 12.3.2 Summary Theorem for CTMCs 234 12.4 Exercises 234 contents xi 13 M/M/1 and PASTA 236 13.1 The M/M/1 Queue 236 13.2 Examples Using an M/M/1 Queue 239 13.3 PASTA 242 13.4 Further Reading 245 13.5 Exercises 245 V Server Farms and Networks: Multi-server, Multi-queue Systems 14 Server Farms: M/M/k and M/M/k/k 253 14.1 Time-Reversibility for CTMCs 253 14.2 M/M/k/k Loss System 255 14.3 M/M/k 258 14.4 Comparison of Three Server Organizations 263 14.5 Readings 264 14.6 Exercises 264 15 Capacity Provisioning for Server Farms 269 15.1 What Does Load Really Mean in an M/M/k? 269 15.2 The M/M/∞ 271 15.2.1 Analysis of the M/M/ ∞ 271 15.2.2 A First Cut at a Capacity Provisioning Rule for the M/M/k 272 15.3 Square-Root Stafﬁng 274 15.4 Readings 276 15.5 Exercises 276 16 Time-Reversibility and Burke’s Theorem 282 16.1 More Examples of Finite-State CTMC s 282 16.1.1 Networks with Finite Buffer Space 282 16.1.2 Batch System with M/M/2 I/O 284 16.2 The Reverse Chain 285 16.3 Burke’s Theorem 288 16.4 An Alternative (Partial) Proof of Burke’s Theorem 290 16.5 Application: Tandem Servers 291 16.6 General Acyclic Networks with Probabilistic Routing 293 16.7 Readings 294 16.8 Exercises 294 17 Networks of Queues and Jackson Product Form 297 17.1 Jackson Network Deﬁnition 297 17.2 The Arrival Process into Each Server 298 17.3 Solving the Jackson Network 300 17.4 The Local Balance Approach 301 17.5 Readings 306 17.6 Exercises 306 18 Classed Network of Queues 311 18.1 Overview 311 18.2 Motivation for Classed Networks 311 xii contents 18.3 Notation and Modeling for Classed Jackson Networks 314 18.4 A Single-Server Classed Network 315 18.5 Product Form Theorems 317 18.6 Examples Using Classed Networks 322 18.6.1 Connection-Oriented ATM Network Example 322 18.6.2 Distribution of Job Classes Example 325 18.6.3 CPU-Bound and I/O-Bound Jobs Example 326 18.7 Readings 329 18.8 Exercises 329 19 Closed Networks of Queues 331 19.1 Motivation 331 19.2 Product-Form Solution 333 19.2.1 Local Balance Equations for Closed Networks 333 19.2.2 Example of Deriving Limiting Probabilities 335 19.3 Mean Value Analysis (MV A) 337 19.3.1 The Arrival Theorem 338 19.3.2 Iterative Derivation of Mean Response Time 340 19.3.3 An MV A Example 341 19.4 Readings 343 19.5 Exercises 343 VI Real-World Workloads: High Variability and Heavy Tails 20 Tales of Tails: A Case Study of Real-World Workloads 349 20.1 Grad School Tales ...Process Migration 349 20.2 UNIX Process Lifetime Measurements 350 20.3 Properties of the Pareto Distribution 352 20.4 The Bounded Pareto Distribution 353 20.5 Heavy Tails 354 20.6 The Beneﬁts of Active Process Migration 354 20.7 Pareto Distributions Are Everywhere 355 20.8 Exercises 357 21 Phase-Type Distributions and Matrix-Analytic Methods 359 21.1 Representing General Distributions by Exponentials 359 21.2 Markov Chain Modeling of PH Workloads 364 21.3 The Matrix-Analytic Method 366 21.4 Analysis of Time-Varying Load 367 21.4.1 High-Level Ideas 367 21.4.2 The Generator Matrix, Q 368 21.4.3 Solving for R 370 21.4.4 Finding /vectorπ0 371 21.4.5 Performance Metrics 372 21.5 More Complex Chains 372 21.6 Readings and Further Remarks 376 21.7 Exercises 376 contents xiii 22 Networks with Time-Sharing (PS) Servers (BCMP) 380 22.1 Review of Product-Form Networks 380 22.2 BCMP Result 380 22.2.1 Networks with FCFS Servers 381 22.2.2 Networks with PS Servers 382 22.3 M/M/1/PS 384 22.4 M/Cox/1/PS 385 22.5 Tandem Network of M/G/1/PS Servers 391 22.6 Network of PS Servers with Probabilistic Routing 393 22.7 Readings 394 22.8 Exercises 394 23 The M/G/1 Queue and the Inspection Paradox 395 23.1 The Inspection Paradox 395 23.2 The M/G/1 Queue and Its Analysis 396 23.3 Renewal-Reward Theory 399 23.4 Applying Renewal-Reward to Get Expected Excess 400 23.5 Back to the Inspection Paradox 402 23.6 Back to the M/G/1 Queue 403 23.7 Exercises 405 24 Task Assignment Policies for Server Farms 408 24.1 Task Assignment for FCFS Server Farms 410 24.2 Task Assignment for PS Server Farms 419 24.3 Optimal Server Farm Design 424 24.4 Readings and Further Follow-Up 428 24.5 Exercises 430 25 Transform Analysis 433 25.1 Deﬁnitions of Transforms and Some Examples 433 25.2 Getting Moments from Transforms: Peeling the Onion 436 25.3 Linearity of Transforms 439 25.4 Conditioning 441 25.5 Distribution of Response Time in an M/M/1 443 25.6 Combining Laplace and z-Transforms 444 25.7 More Results on Transforms 445 25.8 Readings 446 25.9 Exercises 446 26 M/G/1 Transform Analysis 450 26.1 The z-Transform of the Number in System 450 26.2 The Laplace Transform of Time in System 454 26.3 Readings 456 26.4 Exercises 456 27 Power Optimization Application 457 27.1 The Power Optimization Problem 457 27.2 Busy Period Analysis of M/G/1 459 27.3 M/G/1 with Setup Cost 462 xiv contents 27.4 Comparing ON/IDLE versus ON/OFF 465 27.5 Readings 467 27.6 Exercises 467 VII Smart Scheduling in the M/G/1 28 Performance Metrics 473 28.1 Traditional Metrics 473 28.2 Commonly Used Metrics for Single Queues 474 28.3 Today’s Trendy Metrics 474 28.4 Starvation/Fairness Metrics 475 28.5 Deriving Performance Metrics 476 28.6 Readings 477 29 Scheduling: Non-Preemptive, Non-Size-Based Policies 478 29.1 FCFS, LCFS, and RANDOM 478 29.2 Readings 481 29.3 Exercises 481 30 Scheduling: Preemptive, Non-Size-Based Policies 482 30.1 Processor-Sharing (PS) 482 30.1.1 Motivation behind PS 482 30.1.2 Ages of Jobs in the M/G/1/PS System 483 30.1.3 Response Time as a Function of Job Size 484 30.1.4 Intuition for PS Results 487 30.1.5 Implications of PS Results for Understanding FCFS 487 30.2 Preemptive-LCFS 488 30.3 FB Scheduling 490 30.4 Readings 495 30.5 Exercises 496 31 Scheduling: Non-Preemptive, Size-Based Policies 499 31.1 Priority Queueing 499 31.2 Non-Preemptive Priority 501 31.3 Shortest-Job-First (SJF) 504 31.4 The Problem with Non-Preemptive Policies 506 31.5 Exercises 507 32 Scheduling: Preemptive, Size-Based Policies 508 32.1 Motivation 508 32.2 Preemptive Priority Queueing 508 32.3 Preemptive-Shortest-Job-First (PSJF) 512 32.4 Transform Analysis of PSJF 514 32.5 Exercises 516 33 Scheduling: SRPT and Fairness 518 33.1 Shortest-Remaining-Processing-Time (SRPT) 518 33.2 Precise Derivation of SRPT Waiting Time∗521 contents xv 33.3 Comparisons with Other Policies 523 33.3.1 Comparison with PSJF 523 33.3.2 SRPT versus FB 523 33.3.3 Comparison of All Scheduling Policies 524 33.4 Fairness of SRPT 525 33.5 Readings 529 Bibliography 531 Index 541",12343
Preface. The ad hoc World of Computer System Design. Outline of the Book,"Preface The ad hoc World of Computer System Design The design of computer systems is often viewed very much as an art rather than a science. Decisions about which scheduling policy to use, how many servers to run,what speed to operate each server at, and the like are often based on intuitions rather than mathematically derived formulas. Speciﬁc policies built into kernels are often riddled with secret “voodoo constants,” 1which have no explanation but seem to “work well” under some benchmarked workloads. Computer systems students are often told toﬁrst build the system and then make changes to the policies to improve system performance, rather than ﬁrst creating a formal model and design of the system on paper to ensure the system meets performance goals. Even when trying to evaluate the performance of an existing computer system, students are encouraged to simulate the system and spend many days running their simulation under different workloads waiting to see what happens. Given that the search space of possible workloads and input parameters is often huge, vast numbers of simulationsare needed to properly cover the space. Despite this fact, mathematical models of thesystem are rarely created, and we rarely characterize workloads stochastically. There isno formal analysis of the parameter space under which the computer system is likely toperform well versus that under which it is likely to perform poorly. It is no wonder thatcomputer systems students are left feeling that the whole process of system evaluationand design is very ad hoc. As an example, consider the trial-and-error approach to updating resource scheduling in the many versions of the Linux kernel. Analytical Modeling for Computer Systems But it does not have to be this way. These same systems designers could mathematically model the system, stochastically characterize the workloads and performance goals,and then analytically derive the performance of the system as a function of workload and input parameters. The ﬁelds of analytical modeling andstochastic processes have existed for close to a century, and they can be used to save systems designers huge numbers of hours in trial and error while improving performance. Analytical modelingcan also be used in conjunction with simulation to help guide the simulation, reducingthe number of cases that need to be explored. 1The term “voodoo constants” was coined by Prof. John Ousterhout during his lectures at the University of California, Berkeley. xvii xviii preface Unfortunately, of the hundreds of books written on stochastic processes, almost none deal with computer systems. The examples in those books and the material covered areoriented toward operations research areas such as manufacturing systems, or human operators answering calls in a call center, or some assembly-line system with differentpriority jobs. In many ways the analysis used in designing manufacturing systems is not all that different from computer systems. There are many parallels between a human operatorand a computer server: There are faster human operators and slower ones (just ascomputer servers); the human servers sometimes get sick (just as computer serverssometimes break down); when not needed, human operators can be sent home to savemoney (just as computer servers can be turned off to save power); there is a startupoverhead to bringing back a human operator (just as there is a warmup cost to turningon a computer server); and the list goes on.",3487
Preface. The ad hoc World of Computer System Design. Outline of the Book,"However, there are also many differences between manufacturing systems and com- puter systems. To start, computer systems workloads have been shown to have ex-tremely high variability in job sizes (service requirements), with squared coefﬁcientsof variation upward of 100. This is very different from the low-variability service timescharacteristic of job sizes in manufacturing workloads. This difference in variabilitycan result in performance differences of orders of magnitude. Second, computer work-loads are typically preemptible, and time-sharing (Processor-Sharing) of the CPU isextremely common. By contrast, most manufacturing workloads are non-preemptive(ﬁrst-come-ﬁrst-serve service order is the most common). Thus most books on stochas-tic processes and queueing omit chapters on Processor-Sharing or more advanced pre-emptive policies like Shortest-Remaining-Processing-Time, which are very much atthe heart of computer systems. Processor-Sharing is particularly relevant when analyz-ing server farms, which, in the case of computer systems, are typically composed ofProcessor-Sharing servers, not First-Come-First-Served ones. It is also relevant in anycomputing application involving bandwidth being shared between users, which typi- cally happens in a processor-sharing style, not ﬁrst-come-ﬁrst-serve order. Performance metrics may also be different for computer systems as compared with manufacturingsystems (e.g., power usage, an important metric for computer systems, is not mentionedin stochastic processes books). Closed-loop architectures, in which new jobs are notcreated until existing jobs complete, and where the performance goal is to maximizethroughput, are very common in computer systems, but are often left out of queueingbooks. Finally, the particular types of interactions that occur in disks, networking pro-tocols, databases, memory controllers, and other computer systems are very differentfrom what has been analyzed in traditional queueing books. The Goal of This Book Many times I have walked into a fellow computer scientist’s ofﬁce and was pleased toﬁnd a queueing book on his shelf. Unfortunately, when questioned, my colleague wasquick to answer that he never uses the book because “The world doesn’t look like anM/M/1 queue, and I can’t understand anything past that chapter.” The problem is that preface xix the queueing theory books are not “friendly” to computer scientists. The applications are not computer-oriented, and the assumptions used are often unrealistic for computersystems. Furthermore, these books are abstruse and often impenetrable by anyone whohas not studied graduate-level mathematics. In some sense this is hard to avoid: If onewants to do more than provide readers with formulas to “plug into,” then one has toteach them to derive their own formulas, and this requires learning a good deal of math. Fortunately, as one of my favorite authors, Sheldon Ross, has shown, it ispossible to teach a lot of stochastic analysis in a fun and simple way that does not require ﬁrst taking classes in measure theory and real analysis.",3092
Preface. The ad hoc World of Computer System Design. Outline of the Book,"My motive in writing this book is to improve the design of computer systems by intro- ducing computer scientists to the powerful world of queueing-theoretic modeling andanalysis. Personally, I have found queueing-theoretic analysis to be extremely valuablein much of my research including: designing routing protocols for networks, designingbetter scheduling algorithms for web servers and database management systems, diskscheduling, memory-bank allocation, supercomputing resource scheduling, and powermanagement and capacity provisioning in data centers. Content-wise, I have two goalsfor the book. First, I want to provide enough applications from computer systems tomake the book relevant and interesting to computer scientists. Toward this end, almost half the chapters of the book are “application” chapters. Second, I want to make the book mathematically rich enough to give readers the ability to actually develop new queueing analysis , not just apply existing analysis. As computer systems and their workloads continue to evolve and become more complex, it is unrealistic to assumethat they can be modeled with known queueing frameworks and analyses. As a designerof computer systems myself, I am constantly ﬁnding that I have to invent new queueingconcepts to model aspects of computer systems. How This Book Came to Be In 1998, as a postdoc at MIT, I developed and taught a new computer science class,which I called “Performance Analysis and Design of Computer Systems.” The classhad the following description: In designing computer systems one is usually constrained by certain performance goals (e.g., low response time or high throughput or low energy). On the other hand, one often has many choices: One fast disk, or two slow ones? What speed CPU will sufﬁce? Should we invest our money in more buffer space or a faster processor?How should jobs be scheduled by the processor? Does it pay to migrate active jobs? Which routing policy will work best? Should one balance load among servers? How can we best combat high-variability workloads? Often answers to these questions arecounterintuitive. Ideally, one would like to have answers to these questions before investing the time and money to build a system. This class will introduce students to analytic stochastic modeling, which allows system designers to answer questionssuch as those above. Since then, I have further developed the class via 10 more iterations taught within the School of Computer Science at Carnegie Mellon, where I taught versions of the xx preface class to both PhD students and advanced undergraduates in the areas of computer science, engineering, mathematics, and operations research. In 2002, the OperationsManagement department within the Tepper School of Business at Carnegie Mellon made the class a qualiﬁer requirement for all operations management students. As other faculty, including my own former PhD students, adopted my lecture notes in teaching their own classes, I was frequently asked to turn the notes into a book.",3025
Preface. The ad hoc World of Computer System Design. Outline of the Book,"This is“version 1” of that book. Outline of the Book This book is written in a question/answer style, which mimics the Socratic style that I use in teaching. I believe that a class “lecture” should ideally be a long sequenceof bite-sized questions, which students can easily provide answers to and which lead students to the right intuitions. In reading this book, it is extremely important to try to answer each question without looking at the answer that follows the question. The questions are written to remind the reader to “think” rather than just “read,” and toremind the teacher to ask questions rather than just state facts. There are exercises at the end of each chapter. The exercises are an integral part of the book and should not be skipped. Many exercises are used to illustrate the applicationof the theory to problems in computer systems design, typically with the purpose ofilluminating a key insight. All exercises are related to the material covered in thechapter, with early exercises being straightforward applications of the material andlater exercises exploring extensions of the material involving greater difﬁculty. The book is divided into seven parts, which mostly build on each other. Part Iintroduces queueing theory and provides motivating examples from computer systems design that can be answered using basic queueing analysis. Basic queueing terminology is introduced including closed and open queueing models and performance metrics. Part IIis a probability refresher. To make this book self-contained, we have included in these chapters all the probability that will be needed throughout the rest of the book. This includes a summary of common discrete and continuous random variables, theirmoments, and conditional expectations and probabilities. Also included is some mate-rial on generating random variables for simulation. Finally we end with a discussion ofsample paths, convergence of sequences of random variables, and time averages versus ensemble averages. Part IIIis about operational laws, or “back of the envelope” analysis. These are very simple laws that hold for all well-behaved queueing systems. In particular, they do not require that any assumptions be made about the arrival process or workload(like Poisson arrivals or Exponential service times). These laws allow us to quicklyreason at a high level (averages only) about system behavior and make design decisionsregarding what modiﬁcations will have the biggest performance impact. Applicationsto high-level computer system design are provided throughout. preface xxi Part IVis about Markov chains and their application toward stochastic analysis of computer systems. Markov chains allow a much more detailed analysis of systems by representing the full space of possible states that the system can be in. Whereas the operational laws in Part IIIoften allow us to answer questions about the overall mean number of jobs in a system, Markov chains allow us to derive the probability of exactly ijobs being queued at server jof a multi-server system. Part IVincludes both discrete-time and continuous-time Markov chains.",3125
Preface. The ad hoc World of Computer System Design. Outline of the Book,"Applications include Google’s PageRank algorithm, the Aloha (Ethernet) networking protocol, and an analysis of dropping probabilities in ﬁnite-buffer routers. Part Vdevelops the Markov chain theory introduced in Part IVto allow the analysis of more complex networks, including server farms. We analyze networks of queues with complex routing rules, where jobs can be associated with a “class” that determines their route through the network (these are known as BCMP networks). Part Valso derives theorems on capacity provisioning of server farms, such as the “square-rootstafﬁng rule,” which determines the minimum number of servers needed to providecertain delay guarantees. The fact that Parts IVandVare based on Markov chains necessitates that certain “Markovian” (memoryless) assumptions are made in the analysis. In particular, it is assumed that the service requirements (sizes) of jobs follow an Exponential distribu-tion and that the times between job arrivals are also Exponentially distributed. Manyapplications are reasonably well modeled via these Exponential assumptions, allowingus to use Markov analysis to get good insights into system performance. However,in some cases, it is important to capture the high-variability job size distributions orcorrelations present in the empirical workloads. Part VIintroduces techniques that allow us to replace these Exponential distributions with high-variability distributions. Phase-type distributions are introduced, which allow us to model virtually any general distribution by a mixture of Exponentials , leverag- ing our understanding of Exponential distributions and Markov chains from Parts IV andV. Matrix-analytic techniques are then developed to analyze systems with phase- type workloads in both the arrival process and service process. The M/G/1 queueis introduced, and notions such as the Inspection Paradox are discussed. Real-world workloads are described including heavy-tailed distributions. Transform techniquesare also introduced that facilitate working with general distributions. Finally, eventhe service order at the queues is generalized from simple ﬁrst-come-ﬁrst-served ser-vice order to time-sharing (Processor-Sharing) service order, which is more commonin computer systems. Applications abound: Resource allocation (task assignment) inserver farms with high-variability job sizes is studied extensively, both for server farmswith non-preemptive workloads and for web server farms with time-sharing servers. Power management policies for single servers and for data centers are also studied. Part VII, the ﬁnal part of the book, is devoted to scheduling. Smart scheduling is extremely important in computer systems, because it can dramatically improve system performance without requiring the purchase of any new hardware. Scheduling is at theheart of operating systems, bandwidth allocation in networks, disks, databases, memoryhierarchies, and the like. Much of the research being done in the computer systems xxii preface area today involves the design and adoption of new scheduling policies. Scheduling can be counterintuitive, however, and the analysis of even basic scheduling policies is farfrom simple. Scheduling policies are typically evaluated via simulation. In introducing the reader to analytical techniques for evaluating scheduling policies, our hope is that more such policies might be evaluated via analysis. We expect readers to mostly work through the chapters in order, with the following exceptions: First, any chapter or section marked with a star (*) can be skipped without disturbing the ﬂow. Second, the chapter on transforms, Chapter 25, is purposely moved to the end, so that most of the book does not depend on knowing transform analysis.However, because learning transform analysis takes some time, we recommend thatany teacher who plans to cover transforms introduce the topic a little at a time, startingearly in the course. To facilitate this, we have included a large number of exercises atthe end of Chapter 25that do not require material in later chapters and can be assigned earlier in the course to give students practice manipulating transforms. Finally, we urge readers to please check the following websites for new errors/software: http://www.cs.cmu.edu/ ∼harchol/PerformanceModeling/errata.html http://www.cs.cmu.edu/ ∼harchol/PerformanceModeling/software.html Please send any additional errors to harchol@cs.cmu.edu.",4443
Acknowledgments,"Acknowledgments Writing a book, I quickly realized, is very different from writing a research paper, even a very long one. Book writing actually bears much more similarity to teaching a class.That is why I would like to start by thanking the three people who most inﬂuenced myteaching. Manuel Blum, my PhD advisor, taught me the art of creating a lecture outof a series of bite-sized questions. Dick Karp taught me that you can cover an almostinﬁnite amount of material in just one lecture if you spend enough time in advancesimplifying that material into its cleanest form. Sheldon Ross inspired me by the depthof his knowledge in stochastic processes (a knowledge so deep that he never oncelooked at his notes while teaching) and by the sheer clarity and elegance of both hislectures and his many beautifully written books. I would also like to thank Carnegie Mellon University, and the School of Computer Science at Carnegie Mellon, which has at its core the theme of interdisciplinary re-search, particularly the mixing of theoretical and applied research. CMU has been theperfect environment for me to develop the analytical techniques in this book, all inthe context of solving hard applied problems in computer systems design. CMU hasalso provided me with a never-ending stream of gifted students, who have inspiredmany of the exercises and discussions in this book. Much of this book came from theresearch of my own PhD students, including Sherwin Doroudi, Anshul Gandhi, VarunGupta, Yoongu Kim, David McWherter, Takayuki Osogami, Bianca Schroeder, AdamWierman, and Timothy Zhu. In addition, Mark Crovella, Mike Kozuch, and particu- larly Alan Scheller-Wolf, all longtime collaborators of mine, have inspired much of my thinking via their uncanny intuitions and insights. A great many people have proofread parts of this book or tested out the book and provided me with useful feedback. These include Sem Borst, Doug Down, ErhunOzkan, Katsunobu Sasanuma, Alan Scheller-Wolf, Thrasyvoulos Spyropoulos, JarodWang, and Zachary Young. I would also like to thank my editors, Diana Gillooly andLauren Cowles from Cambridge University Press, who were very quick to answer myendless questions, and who greatly improved the presentation of this book. Finally, I amvery grateful to Miso Kim, my illustrator, a PhD student at the Carnegie Mellon Schoolof Design, who spent hundreds of hours designing all the fun ﬁgures in the book. On a more personal note, I would like to thank my mother, Irit Harchol, for making my priorities her priorities, allowing me to maximize my achievements. I did not knowwhat this meant until I had a child of my own. Lastly, I would like to thank myhusband, Andrew Young. He won me over by reading all my online lecture notes anddoing every homework problem – this was his way of asking me for a ﬁrst date. Hisability to understand it all without attending any lectures made me believe that mylecture notes might actually “work” as a book. His willingness to sit by my side everynight for many months gave me the motivation to make it happen. xxiii",3076
Part I Introduction to Queueing,"PART I Introduction to Queueing PartIserves as an introduction to analytical modeling. We begin in Chapter 1with a number of paradoxical examples that come up in the design of computer systems, showing off the power of analytical modeling in making design decisions. Chapter 2introduces the reader to basic queueing theory terminology and notation that is used throughout the rest of the book. Readers are introduced to both open and closed queueing networks and to standard performance metrics, such as response time,throughput, and the number of jobs in the system. 1",569
Chapter 1 Motivating Examples of the Power of Analytical Modeling. 1.1 What Is Queueing Theory,"CHAPTER 1 Motivating Examples of the Power of Analytical Modeling 1.1 What Is Queueing Theory? Queueing theory is the theory behind what happens when you have lots of jobs, scarce resources, and subsequently long queues and delays. It is literally the “theoryof queues”: what makes queues appear and how to make them go away. Imagine a computer system, say a web server, where there is only one job. The job arrives, it uses certain resources (some CPU, some I/O), and then it departs. Given thejob’s resource requirements, it is very easy to predict exactly when the job will depart.There is no delay because there are no queues. If every job indeed got to run on its own computer, there would be no need for queueing theory. Unfortunately, that is rarely thecase. Arrivin g customersServer Figure 1.1. Illustration of a queue, in which customers wait to be served, and a server. The picture shows one customer being served at the server and ﬁve others waiting in the queue. Queueing theory applies anywhere that queues come up (see Figure 1.1). We all have had the experience of waiting in line at the bank, wondering why there are not more tellers, or waiting in line at the supermarket, wondering why the express lane is for 8 items or less rather than 15 items or less, or whether it might be best to actually have two express lanes, one for 8 items or less and the other for 15 items or less. Queues are also at the heart of any computer system. Your CPU uses a time-sharing scheduler to servea queue of jobs waiting for CPU time. A computer disk serves a queue of jobs waitingto read or write blocks. A router in a network serves a queue of packets waiting to be routed. The router queue is a ﬁnite capacity queue, in which packets are dropped whendemand exceeds the buffer space. Memory banks serve queues of threads requestingmemory blocks. Databases sometimes have lock queues, where transactions wait toacquire the lock on a record. Server farms consist of many servers, each with its own queue of jobs. The list of examples goes on and on. The goals of a queueing theorist are twofold. The ﬁrst is predicting the system perfor- mance. Typically this means predicting mean delay or delay variability or the proba- bility that delay exceeds some Service Level Agreement (SLA). However, it can alsomean predicting the number of jobs that will be queueing or the mean number of servers 3 4 motivating examples of the power of analytical modeling being utilized (e.g., total power needs), or any other such metric. Although prediction is important, an even more important goal is ﬁnding a superior system design to im- prove performance. Commonly this takes the form of capacity planning, where one determines which additional resources to buy to meet delay goals (e.g., is it better tobuy a faster disk or a faster CPU, or to add a second slow disk). Many times, however, without buying any additional resources at all, one can improve performance just bydeploying a smarter scheduling policy or different routing policy to reduce delays.Given the importance of smart scheduling in computer systems, all of Part VIIof this book is devoted to understanding scheduling policies. Queueing theory is built on a much broader area of mathematics called stochastic modeling and analysis. Stochastic modeling represents the service demands of jobs and the interarrival times of jobs as random variables. For example, the CPU requirementsof UNIX processes might be modeled using a Pareto distribution [ 84], whereas the arrival process of jobs at a busy web server might be well modeled by a Poisson process with Exponentially distributed interarrival times. Stochastic models can alsobe used to model dependencies between jobs, as well as anything else that can berepresented as a random variable. Although it is generally possible to come up with a stochastic model that adequately represents the jobs or customers in a system and its service dynamics, these stochasticmodels are not always analytically tractable with respect to solving for performance.As we discuss in Part IV,Markovian assumptions , such as assuming Exponentially distributed service demands or a Poisson arrival process, greatly simplify the analysis; hence much of the existing queueing literature relies on such Markovian assumptions.In many cases these are a reasonable approximation. For example, the arrival process ofbook orders on Amazon might be reasonably well approximated by a Poisson process, given that there are many independent users, each independently submitting requests at a low rate (although this all breaks down when a new Harry Potter book comesout). However, in some cases Markovian assumptions are very far from reality; forexample, in the case in which service demands of jobs are highly variable or arecorrelated. While many queueing texts downplay the Markovian assumptions being made, this book does just the opposite. Much of my own research is devoted to demonstrating theimpact of workload assumptions on correctly predicting system performance. I havefound many cases where making simplifying assumptions about the workload can lead to very inaccurate performance results and poor system designs. In my own research, I therefore put great emphasis on integrating measured workload distributions into theanalysis. Rather than trying to hide the assumptions being made, this book highlights all assumptions about workloads. We will discuss speciﬁcally whether the workloadmodels are accurate and how our model assumptions affect performance and design,as well as look for more accurate workload models. In my opinion, a major reasonwhy computer scientists are so slow to adopt queueing theory is that the standardMarkovian assumptions often do not ﬁt. However, there are often ways to work aroundthese assumptions, many of which are shown in this book, such as using phase-typedistributions and matrix-analytic methods, introduced in Chapter 21.",5948
1.2 Examples of the Power of Queueing Theory,"1.2examples of the power of queueing theory 5 1.2 Examples of the Power of Queueing Theory The remainder of this chapter is devoted to showing some concrete examples of the power of queueing theory. Do notexpect to understand everything in the examples. The examples are developed in much greater detail later in the book. Terms like “Poisson process” that you may not be familiar with are also explained later in the book. Theseexamples are just here to highlight the types of lessons covered in this book. As stated earlier, one use of queueing theory is as a predictive tool , allowing one to predict the performance of a given system. For example, one might be analyzing a network, with certain bandwidths, where different classes of packets arrive at certainrates and follow certain routes throughout the network simultaneously. Then queueingtheory can be used to compute quantities such as the mean time that packets spendwaiting at a particular router i, the distribution on the queue buildup at router i, or the mean overall time to get from router ito router jin the network. We now turn to the usefulness of queueing theory as a design tool in choosing the best system design to minimize response time. The examples that follow illustrate that system design is often a counterintuitive process. Design Example 1 – Doubling Arrival Rate Consider a system consisting of a single CPU that serves a queue of jobs in First-Come- First-Served (FCFS) order, as illustrated in Figure 1.2. The jobs arrive according to some random process with some average arrival rate, say λ=3 jobs per second. Each job has some CPU service requirement, drawn independently from some distribution of job service requirements (we can assume any distribution on the job service requirements for this example). Let’s say that the average service rate is μ=5jobs per second (i.e., each job on average requires 1/5of a second of service). Note that the system is not in overload ( 3<5). LetE[T]denote the mean response time of this system, where response time is the time from when a job arrives until it completes service, a.k.a. sojourn time. λ = 3FCFS C PU µ = 5If λ 2λ,  by how m uch  should µ  increase ? Figure 1.2. A system with a single CPU that serves jobs in FCFS order. Question: Your boss tells you that starting tomorrow the arrival rate will double. You are told to buy a faster CPU to ensure that jobs experience the same mean response time,E[T]. That is, customers should not notice the effect of the increased arrival rate. By how much should you increase the CPU speed? (a) Double the CPU speed;(b) More than double the CPU speed; (c) Less than double the CPU speed. Answer: (c) Less than double. 6 motivating examples of the power of analytical modeling Question: Why not (a)? Answer: It turns out that doubling CPU speed together with doubling the arrival rate will generally result in cutting the mean response time in half. We prove this in Chapter 13. Therefore, the CPU speed does not need to double. Question: Can you immediately see a rough argument for this result that does not involve any queueing theory formulas?",3124
1.2 Examples of the Power of Queueing Theory,"What happens if we double the service rate and double the arrival rate? Answer: Imagine that there are two types of time: Federation time and Klingon time. Klingon seconds are faster than Federation seconds. In fact, each Klingon second is equivalent to a half-second in Federation time. Now, suppose that in the Federation,there is a CPU serving jobs. Jobs arrive with rate λjobs per second and are served at some rate μjobs per second. The Klingons steal the system specs and reengineer the same system in the Klingon world. In the Klingon system, the arrival rate is λjobs per Klingon second, and the service rate is μjobs per Klingon second. Note that both systems have the same mean response time, E[T], except that the Klingon system response time is measured in Klingon seconds, while the Federation system response time is measured in Federation seconds. Consider now that Captain Kirk is observingboth the Federation system and the Klingon reengineered system. From his perspective,the Klingon system has twice the arrival rate and twice the service rate; however, the mean response time in the Klingon system has been halved (because Klingon secondsare half-seconds in Federation time). Question: Suppose the CPU employs time-sharing service order (known as Processor- Sharing, or PS for short), instead of FCFS. Does the answer change? Answer: No. The same basic argument still works. Design Example 2 – Sometimes “Improvements” Do Nothing Consider the batch system shown in Figure 1.3. There are always N=6 jobs in this system (this is called the multiprogramming level). As soon as a job completes service, a new job is started (this is called a “closed” system). Each job must go through the“service facility.” At the service facility, with probability 1/2the job goes to server 1, and with probability 1/2it goes to server 2. Server 1 services jobs at an average rate of 1 job every 3 seconds. Server 2 also services jobs at an average rate of 1 job every 3 seconds. The distribution on the service times of the jobs is irrelevant for this problem. Response time is deﬁned as usual as the time from when a job ﬁrst arrives at the service facility (at the fork) until it completes service. N = 6 jobs ½ ½µ=⅓ Server 1 Server 2 µ=⅓  Figure 1.3. A closed batch system. 1.2examples of the power of queueing theory 7 Question: You replace server 1 with a server that is twice as fast (the new server services jobs at an average rate of 2 jobs every 3 seconds). Does this “improvement” affect the average response time in the system? Does it affect the throughput? (Assume that the routing probabilities remain constant at 1/2and1/2.) Answer: Not really. Both the average response time and throughput are hardly affected. This is explained in Chapter 7. Question: Suppose that the system had a higher multiprogramming level, N. Does the answer change? Answer: No. The already negligible effect on response time and throughput goes to zero as Nincreases. Question: Suppose the system had a lower value of N. Does the answer change? Answer: Yes.",3051
1.2 Examples of the Power of Queueing Theory,"If Nis sufﬁciently low, then the “improvement” helps. Consider, for example, the case N=1. Question: Suppose the system is changed into an open system, rather than a closed system, as shown in Figure 1.4, where arrival times are independent of service com- pletions. Now does the “improvement” reduce mean response time? Answer: Absolutely. ½ ½µ=⅓ Server 1 Server 2 µ=⅓  Figure 1.4. An open system. Design Example 3 – One Machine or Many? You are given a choice between one fast CPU of speed s,o rnslow CPUs each of speed s/n (see Figure 1.5). Your goal is to minimize mean response time. To start, assume that jobs are non-preemptible (i.e., each job must be run to completion). versusµ = 1 µ = 1 µ = 4 µ = 1 µ = 1 Figure 1.5. Which is better for minimizing mean response time: many slow servers or one fast server? 8 motivating examples of the power of analytical modeling Question: Which is the better choice: one fast machine or many slow ones? Hint: Suppose that I tell you that the answer is, “It depends on the workload.” What aspects of the workload do you think the answer depends on? Answer: It turns out that the answer depends on the variability of the job size distribu- tion, as well as on the system load. Question: Which system do you prefer when job size variability is high? Answer: When job size variability is high, we prefer many slow servers because we do not want short jobs getting stuck behind long ones. Question: Which system do you prefer when load is low? Answer: When load is low, not all servers will be utilized, so it seems better to go with one fast server.These observations are revisited many times throughout the book. Question: Now suppose we ask the same question, but jobs are preemptible ; that is, they can be stopped and restarted where they left off. When do we prefer many slow machines as compared to a single fast machine? Answer: If your jobs are preemptible, you could always use a single fast machine to simulate the effect of nslow machines. Hence a single fast machine is at least as good. The question of many slow servers versus a few fast ones has huge applicability in a wide range of areas, because anything can be viewed as a resource, including CPU, power, and bandwidth. For an example involving power management in data centers, consider the problem from [ 69] where you have a ﬁxed power budget Pand a server farm consisting of nservers. You have to decide how much power to allocate to each server, so as to minimize overall mean response time for jobs arriving at the server farm. There is a function that speciﬁes the relationship between the power allocated to a server and the speed (frequency) at which it runs – generally, the more power you allocate to a server, the faster it runs (the higher its frequency), subject to some maximumpossible frequency and some minimum power level needed just to turn the server on.To answer the question of how to allocate power, you need to think about whetheryou prefer many slow servers (allocate just a little power to every server) or a few fast ones (distribute all the power among a small number of servers).",3119
1.2 Examples of the Power of Queueing Theory,"In [ 69], queueing theory is used to optimally answer this question under a wide variety of parametersettings. As another example, if bandwidth is the resource, we can ask when it pays to partition bandwidth into smaller chunks and when it is better not to. The problem is alsointeresting when performance is combined with price. For example, it is often cheaper(ﬁnancially) to purchase many slow servers than a few fast servers. Yet in some cases,many slow servers can consume more total power than a few fast ones. All of thesefactors can further inﬂuence the choice of architecture. 1.2examples of the power of queueing theory 9 Design Example 4 – Task Assignment in a Server Farm Consider a server farm with a central dispatcher and several hosts. Each arriving job is immediately dispatched to one of the hosts for processing. Figure 1.6illustrates such a system. Host 1 Host 2 Host 3Dispatcher  (Load Balancer)Arrivals Figure 1.6. A distributed server system with a central dispatcher. Server farms like this are found everywhere. Web server farms typically deploy a front-end dispatcher like Cisco’s Local Director or IBM’s Network Dispatcher. Super-computing sites might use LoadLeveler or some other dispatcher to balance load and assign jobs to hosts. For the moment, let’s assume that all the hosts are identical (homogeneous) and that all jobs only use a single resource. Let’s also assume that once jobs are assigned to ahost, they are processed there in FCFS order and are non-preemptible. There are many possible task assignment policies that can be used for dispatching jobs to hosts. Here are a few: Random: Each job ﬂips a fair coin to determine where it is routed. Round-Robin: The ith job goes to host imodn, where nis the number of hosts, and hosts are numbered 0,1,...,n−1. Shortest-Queue: Each job goes to the host with the fewest number of jobs. Size-Interval-Task-Assignment (SITA): “Short” jobs go to the ﬁrst host, “medium” jobs go to the second host, “long” jobs go to the third host, etc., for some deﬁnition of “short,” “medium,” and “long.” Least-Work-Left (LWL): Each job goes to the host with the least total remaining work, where the “work” at a host is the sum of the sizes of jobs there. Central-Queue: Rather than have a queue at each host, jobs are pooled at one central queue. When a host is done working on a job, it grabs the ﬁrst job in the central queue to work on. Question: Which of these task assignment policies yields the lowest mean response time? 10 motivating examples of the power of analytical modeling Answer: Given the ubiquity of server farms, it is surprising how little is known about this question. If job size variability is low, then the LWL policy is best. If job size variability is high, then it is important to keep short jobs from getting stuck behind long ones, so a SITA-like policy, which affords short jobs isolation from long ones, can be far better. In fact, for a long time it was believed that SITA is always better than LWLwhen job size variability is high. However, it was recently discovered (see [ 90]) that SITA can be far worse than LWL even under job size variability tending to inﬁnity.",3168
1.2 Examples of the Power of Queueing Theory,"Itturns out that other properties of the workload, including load and fractional moments of the job size distribution, matter as well. Question: For the previous question, how important was it to know the size of jobs? For example, how does LWL, which requires knowing job size, compare with Central- Queue, which does not? Answer: Actually, most task assignment policies do not require knowing the size of jobs. For example, it can be proven by induction that LWL is equivalent to Central- Queue. Even policies like SITA, which by deﬁnition are based on knowing the job size,can be well approximated by other policies that do not require knowing the job size;see [82]. Question: Now consider a different model, in which jobs are preemptible. Speciﬁcally, suppose that the servers are Processor-Sharing (PS) servers, which time-share amongall the jobs at the server, rather than serving them in FCFS order. Which task assignmentpolicy is preferable now? Is the answer the same as that for FCFS servers? Answer: The task assignment policies that are best for FCFS servers are often a disaster under PS servers. For PS servers, the Shortest-Queue policy is near optimal ([79]), whereas that policy is pretty bad for FCFS servers if job size variability is high. There are many open questions with respect to task assignment policies. The case of server farms with PS servers, for example, has received almost no attention, and eventhe case of FCFS servers is still only partly understood. There are also many othertask assignment policies that have not been mentioned. For example, cycle stealing (taking advantage of a free host to process jobs in some other queue) can be combinedwith many existing task assignment policies to create improved policies. There are alsoother metrics to consider, like minimizing the variance of response time, rather thanmean response time, or maximizing fairness. Finally, task assignment can become evenmore complex, and more important, when the workload changes over time. Task assignment is analyzed in great detail in Chapter 24, after we have had a chance to study empirical workloads. Design Example 5 – Scheduling Policies Suppose you have a single server. Jobs arrive according to a Poisson process. Assume anything you like about the distribution of job sizes. The following are some possible service orders (scheduling orders) for serving jobs: First-Come-First-Served (FCFS): When the server completes a job, it starts working on the job that arrived earliest. 1.2examples of the power of queueing theory 11 Non-Preemptive Last-Come-First-Served (LCFS): When the server completes a job, it starts working on the job that arrived last. Random: When the server completes a job, it starts working on a random job. Question: Which of these non-preemptive service orders will result in the lowest mean response time? Answer: Believe it or not, they all have the same mean response time. Question: Suppose we change the non-preemptive LCFS policy to a Preemptive-LCFS policy (PLCFS), which works as follows: Whenever a new arrival enters the system, it immediately preempts the job in service.",3130
1.2 Examples of the Power of Queueing Theory,"How does the mean response time of thispolicy compare with the others? Answer: It depends on the variability of the job size distribution. If the job size distribution is at least moderately variable, then PLCFS will be a huge improvement. If the job size distribution is hardly variable (basically constant), then PLCFS policywill be up to a factor of 2 worse. We study many counterintuitive scheduling theory results toward the very end of the book, in Chapters 28through 33. More Design Examples There are many more questions in computer systems design that lend themselves to a queueing-theoretic solution. One example is the notion of a setup cost . It turns out that it can take both signiﬁcant time and power to turn ona server that is off. In designing an efﬁcient power management policy, we often want to leave servers off(to save power), but then we have to pay the setup cost to get them back on when jobs arrive. Given performance goals, both with respect to response time and power usage, an important question is whether it pays toturn a server off. If so, one can then ask exactly how many servers should be left on.These questions are discussed in Chapters 15and27. There are also questions involving optimal scheduling when jobs have priorities (e.g.,certain users have paid more for their jobs to have priority over other users’ jobs, orsome jobs are inherently more vital than others). Again, queueing theory is very usefulin designing the right priority scheme to maximize the value of the work completed. Figure 1.7. Example of a difﬁcult problem: The M/G/2 queue consists of a single queue and two servers. When a server completes a job, it starts working on the job at the head of the queue. Job sizes follow a general distribution, G. 12 motivating examples of the power of analytical modeling However, queueing theory (and more generally analytical modeling) is notcurrently all-powerful. There are lots of very simple problems that we can at best only analyze approximately. As an example, consider the simple two-server network shown in Figure 1.7, where job sizes come from a general distribution. No one knows how to derive mean response time for this network. Approximations exist, but they are quite poor, particularly when job size variability gets high [ 76]. We mention many such open problems in this book, and we encourage readers to attempt to solve these.",2394
Chapter 2 Queueing Theory Terminology. 2.1 Where We Are Heading. 2.2 The Single-Server Network,"CHAPTER 2 Queueing Theory Terminology 2.1 Where We Are Heading Queueing theory is the study of queueing behavior in networks and systems. Figure 2.1 shows the solution process. Real-world system with question: “Should we buy a faster disk or a faster CPU?” Translate backResultQueueing  networkModel as Analyze. Figure 2.1. Solution process. In Chapter 1, we looked at examples of the power of queueing theory as a design tool. In this chapter, we start from scratch and deﬁne the terminology used in queueing theory. 2.2 The Single-Server Network Aqueueing network is made up of servers . The simplest example of a queueing network is the single-server network , as shown in Figure 2.2. The discussion in this section is limited to the single-server network with First-Come-First-Served (FCFS) service order. You can think of the server as being a CPU. Arrivin g jobs λ = 3FCFS = 4 Figure 2.2. Single-server network. 13 14 queueing theory terminology There are several parameters associated with the single-server network: Service Order This is the order in which jobs will be served by the server. Unless otherwise stated, assume First-Come-First-Served (FCFS). Average Arrival Rate This is the average rate, λ, at which jobs arrive to the server (e.g.,λ=3jobs/sec). Mean Interarrival Time This is the average time between successive job arrivals (e.g.,1/λ=1 3sec). Service Requirement, Size The “size” of a job is typically denoted by the random variable S. This is the time it would take the job to run on this server if there were no other jobs around (no queueing). In a queueing model, the size (a.k.a. service requirement) is typically associated with the server (e.g., this job will take 5seconds on this server). Mean Service Time This is the expected value of S, namely the average time required to service a job on this CPU, where “service” does not include queueing time. InFigure 2.2, E[S]=1 4sec. Average Service Rate This is the average rate, μ, at which jobs are served (e.g., μ=4jobs/sec =1 E[S]). Observe that this way of speaking is different from the way we normally talk about servers in conversation. For example, nowhere have we mentioned the absolute speed of the CPU; rather we have only deﬁned the CPU’s speed in terms of the set of jobsthat it is working on. In normal conversation, we might say something like the following: rThe average arrival rate of jobs is 3 jobs per second. rJobs have different service requirements, but the average number of cycles re- quired by a job is 5,000 cycles per job. rThe CPU speed is 20,000 cycles per second. That is, an average of 15,000 cycles of work arrive at the CPU each second, and theCPU can process 20,000 cycles of work a second. In the queueing-theoretic way of talking, we would never mention the word “cycle.” Instead, we would simply say rThe average arrival rate of jobs is 3 jobs per second. rThe average rate at which the CPU can service jobs is 4 jobs per second. This second way of speaking suppresses some of the detail and thus makes the problem a little easier to think about. You should feel comfortable going back and forth between the two. We consider these common performance metrics in the context of a single-server system: Response Time, Turnaround Time, Time in System, or Sojourn Time ( T)We deﬁne a job’s response time by T=tdepart−tarrive, where tdepart is the time when the 2.2the single-server network 15 job leaves the system, and tarriveis the time when the job arrived to the system. We are interested in E[T], the mean response time; Var(T), the variance in response time; and the tail behavior of T,P{T>t}. Waiting Time or Delay ( TQ)This is the time that the job spends in the queue, not being served. It is also called the “time in queue” or the “wasted time.” Notice that E[T]=E[TQ]+E[S]. Under FCFS service order, waiting time can be deﬁned as the time from when a job arrives to the system until it ﬁrst receives service. Number of Jobs in the System ( N)This includes those jobs in the queue, plus the one being served (if any). Number of Jobs in Queue ( NQ)This denotes only the number of jobs waiting (in queue). There are some immediate observations that we can make about the single-server network. First, observe that as λ, the mean arrival rate, increases, all the performance metrics mentioned earlier increase (get worse). Also, as μ, the mean service rate, increases, all the performance metrics mentioned earlier decrease (improve). We require that λ≤μ(we always assume λ<μ ). Question: Ifλ>μ what happens? Answer: Ifλ>μ the queue length goes to inﬁnity over time. Question: Can you provide the intuition? Answer: Consider a large time t. Then, if N(t)is the number of jobs in the system at time t, andA(t)(respectively, D(t)) denotes the number of arrivals (respectively, departures) by time t, then we have: E[N(t)] =E[A(t)]−E[D(t)]≥λt−μt=t(λ−μ). (The inequality comes from the fact that the expected number of departures by time t is actually smaller than μt, because the server is not always busy). Now observe that if λ>μ , thent(λ−μ)→∞ ,a st→∞ . Throughout the book we assume λ<μ , which is needed for stability (keeping queue sizes from growing unboundedly). Situations where λ≥μare touched on in Chapter 9. Question: Given the previous stability condition ( λ<μ ), suppose that the interarrival distribution and the service time distribution are Deterministic (i.e., both are constants). What is TQ? What is T? Answer: TQ=0, andT=S. Therefore queueing (waiting) results from variability in service time and/or interarrival time distributions. Here is an example of how variability leads to queues: Let’s discretize time. Suppose at each time step, an arrival occurs with probability p=1/6. Suppose at each time step, a departure occurs with probability q=1/3. Then there is a non-zero probability that the queue will build up (temporarily) if several arrivals occur without a departure.",5916
2.3 Classification of Queueing Networks. 2.5 More Metrics Throughput and Utilization,"16 queueing theory terminology 2.3 Classiﬁcation of Queueing Networks Queueing networks can be classiﬁed into two categories: open networks andclosed networks . Stochastic processes books (e.g., [ 149,150]) usually limit their discussion to open networks. By contrast, the systems performance analysis books (e.g., [ 117, 125]) almost exclusively discuss closed networks. Open networks are introduced in Section 2.4. Closed networks are introduced in Section 2.6. 2.4 Open Networks An open queueing network has external arrivals and departures. Four examples of open networks are illustrated in this section. Example: The Single-Server System This was shown in Figure 2.2. Example: Network of Queues with Probabilistic RoutingThis is shown in Figure 2.3. Here server ireceives external arrivals (“outside arrivals”) with rate ri.S e r v e r ialso receives internal arrivals from some of the other servers. A packet that ﬁnishes service at server iis next routed to server jwith probability pij. We can even allow the probabilities to depend on the “class” of the packet, so that not all packets have to follow the same routing scheme. Server 1 µ1µ2 Server 3Server 2 µ3r2 r3r1p12p2,out p1,outp23 p31p13 Figure 2.3. Network of queues with probabilistic routing. Application: In modeling packet ﬂows in the Internet, for example, one could make the class of the packet (and hence its route) depend on its source and destination IP addresses. In modeling delays, each wire might be replaced by a server that would beused to model the wire latency. The goal might be to predict mean round-trip times forpackets on a particular route, given the presence of the other packets. We solve this problem in Chapter 18. 2.5more metrics: throughput and utilization 17 Example: Network of Queues with Non-Probabilistic Routing This is shown in Figure 2.4. Here all jobs follow a predetermined route: CPU to disk 1 to disk 2 to disk 1 to disk 2 to disk 1 and out. Arrivin g Jobs ( λ)CPU Disk 1 Disk 22X aro und (Disk 1,2,1,2,1) Figure 2.4. Network of queues with non-probabilistic routing. Example: Finite Buffer An example of a single-server network with ﬁnite buffer is shown in Figure 2.5.A n y arrival that ﬁnds no room is dropped. λCPU Space for 9 jobs plus 1 in serviceµCPU Figure 2.5. Single-server network with ﬁnite buffer capacity. 2.5 More Metrics: Throughput and Utilization We have already seen four performance metrics: E[N],E[T],E[NQ], andE[TQ]. Although these were applied to a single-server system, they can also be used to describe performance in a multi-server, multi-queue system. For example, E[T]would denote the mean time a job spends in the whole system, including all time spent in variousqueues and time spent receiving service at various servers, whereas E[TQ]refers to just the mean time the job “wasted” waiting in various queues. If we want to refer to just the ith queue in such a system, we typically write E[Ni]to denote the expected number of jobs both queueing and in service at server i, andE[Ti]to denote the expected time a job spends queueing and in service at server i. Now we introduce two new performance metrics: throughput and utilization. Through- put is arguably the performance metric most used in conversation. Everyone wantshigher throughput. Let’s see why. Question: How does maximizing throughput relate to minimizing response time? For example, in Figure 2.6, which system has higher throughput? 18 queueing theory terminology versusµ=⅓ λ =  = λ =  Figure 2.6. Comparing throughput of two systems. Answer: We will see soon. Let’s start by deﬁning utilization.Device Utilization ( ρi)is the fraction of time device iis busy . Note our current deﬁnition of utilization applies only to a single device (server). When the device isimplied, we simply write ρ(omitting the subscript). Suppose we watch a device ifor a long period of time. Let τdenote the length of the observation period. Let Bdenote the total time during the observation period that the device is non-idle (busy). Then ρi=B τ. Device Throughput ( Xi)is the rate of completions at device i(e.g., jobs/sec). The throughput (X)of the system is the rate of job completions in the system. LetCdenote the total number of jobs completed at device iduring time τ. Then Xi=C τ. So how does Xirelate to ρi? Well, C τ=/parenleftbiggC B/parenrightbigg ·B τ. Question: So what isC B? Answer: Well,B C=E[S].S oC B=1 E[S]=μi. So we have Xi=μi·ρi. Here is another way to derive this expression by conditioning: Xi=Mean rate of completion at server i =E[Rate of completion at server i|server iis busy ]·P{server iis busy} +E[Rate of completion at server i|server iis idle]·P{server iis idle} =μi·P{server iis busy}+0 =μi·ρi 2.5more metrics: throughput and utilization 19 Or, equivalently, ρi=Xi·E[S]. This latter formulation has a name: the Utilization Law . Example: Single-Server Network: What Is the Throughput? In Figure 2.7we have a single-server system. =⅓ λ = FCFS Figure 2.7. Single-server model. Question: What is X? Answer: X=ρ·μ. But what is ρ? In Chapter 6, we will prove that ρ=λ μ. For now here is a hand-wavy but intuitive way to see this, but nota proof.. ρ=Fraction of time server is busy =Average service time required by a job Average time between arrivals =1/μ 1/λ =λ μ. So, this leaves us with X=ρ·μ=λ μ·μ=λ. So the throughput does not depend on the service rate whatsoever.In particular, in the example shown in Figure 2.6, repeated again in Figure 2.8, both systems have the same throughput of 1/6jobs/sec. In the case of the faster processor, the response time drops and the queue length drops, but Xdoes not change. Therefore lower response time is notrelated to higher throughput. versus=⅓ λ =  = λ =  Figure 2.8. Same model, but different values of μ. Throughput, X, is the same in both. Question: Explain why Xdoes not change. Answer: No matter how high we make μ, the completion rate is still bounded by the arrival rate: “rate in =rate out.” Changing μaffects the maximum possible X,b u t",5999
2.6 Closed Networks,"20 queueing theory terminology not the actual X. Note that because we assume a stable system, then, for large t, the number of arrivals during tis approximately the number of completions during t. Example: Probabilistic Network of Queues: What is the Throughput? For Figure 2.3,ridenotes the average outside arrival rate into server i, andμidenotes the average service rate at server i. Question: What is the system throughput, X, in Figure 2.3? Answer: X=/summationtext iri. Question: What is the throughput at server i,Xi? Answer: Letλidenote the total arrival rate into server i. Then Xi=λi. But to get λi we need to solve these simultaneous equations: λi=ri+/summationdisplay jλjPji (2.1) Question: How are the ri’s constrained in these equations? Answer: For the network to reach “equilibrium” (ﬂow into server = ﬂow out of server), we must have λi<μ i,∀i, and this constrains the ri’s (see Exercise 2.1). Example: Network of Queues with Non-Probabilistic Routing: What is the Throughput? Question: What is Xin Figure 2.4? Answer: X=λ. Question: What are XDisk1 andXDisk2? Answer: XDisk1=3λandXDisk2=2λ. Example: Finite Buffer: What is the Throughput? For Figure 2.5, the outside arrival rate is λand the service rate is μ. Question: What is X? Answer: X=ρμ. But we need stochastic analysis to determine ρbecause it is no longer simply λ/μ. Observe that X<λ because some arrivals get dropped. 2.6 Closed Networks Closed queueing networks have no external arrivals or departures. They can be classiﬁed into two categories as shown in Figure 2.9. Closed networks Interactive (terminal-driven)Batch system Figure 2.9. Closed network categories. 2.6closed networks 21 2.6.1 Interactive (Terminal-Driven) Systems An example of an interactive (terminal-driven) system is shown in Figure 2.10.T e r - minals represent users who each send a job to the “central subsystem” and then wait for a response. The central subsystem is a network of queues. A user cannot submit her next job before her previous job returns. Thus, the number of jobs in the system is ﬁxed (equal to the number of terminals). This number is sometimes called the load or MPL (multiprogramming level), not to be confused with device utilization. Central s ubsystemN user terminals tuo ni Figure 2.10. Interactive system. There is a think time ,Z, which is a random variable representing the time at each terminal between receiving the result of one job and sending out the next job. Note that the number of jobs in the central subsystem is at most the number of terminals, because some users might be in the “thinking” state. An example of an interactive system such as the one shown in Figure 2.10 is a data- entry application. Nusers each sit at terminals ﬁlling out the entries on their screens. Several ﬁelds of the screen must be ﬁlled out, and then the whole screen is submitted to the central subsystem for appropriate processing and database update. A new screen cannot be ﬁlled out until the previous update is performed. The “think time,” Z, is the time to key data to the screen. An individual user (terminal) oscillates between the think state and the submitted state as shown in Figure 2.11. Think state Think state Think state Submitted state in o utSubmitted state Figure 2.11. The user alternates between thinking and waiting for the submitted job to return. 22 queueing theory terminology Question: How would you deﬁne the response time for the interactive system? Answer: Response time is the time it takes a job to go between “in” and “out” in Figures 2.10 and 2.11. We denote the average time to get from “in” to “out” by E[Response Time ]orE[R]to differentiate it from E[T], which is deﬁned as E[T]=E[R]+E[Z] Important: Although “response time” in open systems is denoted by the random variable (r.v.) T, for closed interactive systems, we refer to Tas the system time (or “time in system”) and reserve the r.v. Rforresponse time . Goal: The goal in an interactive system is to ﬁnd a way to allow as many users as possible to get onto the system at once, so they can all get their work done, while keeping E[R]low enough. Note that interactive systems are very different from open systems in that a small change in Nhas a profound effect on the system behavior. The typical questions asked by systems designers are: rGiven the original system, how high can I make Nwhile keeping E[R]below some threshold? That is, how does E[R]rise with N? rAssume a ﬁxed multiprogramming level, N. Given that we can make changes to the central subsystem (i.e., make certain devices faster), which changes will improve E[R]the most? Question: Say we are modeling performance at a website. Would you model the website as a closed interactive system or an open system? Answer: The jury is still out. There are research papers of both types. On the one hand, once a user clicks on a link (submits a job), he typically waits to receive the result before clicking on another link. Thus users behave as if the website is a closed system.On the other hand, a website may have a huge number of users, each of whom is very transient in his or her use of the website. In this respect, the website might behave morelike an open system. Schroeder et al. [ 165] proposes the idea of a “partly-open” system. Here users arrive from outside as in an open system, but make krequests to the system when they arrive, where each request can only be made when the previous request completes (as in a closed system). 2.6.2 Batch Systems An example of a batch system is shown in Figure 2.12. A batch system looks like an interactive system with a think time of zero. However, the goals are somewhat differentfor batch systems. In a batch system, typically one is running many jobs overnight. As soon as one job completes, another one is started. So there are always Njobs in the central subsystem. The MPL is usually predetermined and ﬁxed. For example the MPL might be the number of jobs that ﬁt into memory. 2.6closed networks 23 Central s ubsystemN user terminals Figure 2.12. Batch system. Goal: For a batch system, the goal is to obtain high throughput , so that as many jobs as possible are completed overnight. The typical question asked by systems designers is, “How can we improve the central subsystem so as to maximize throughput?” Note that we are typically constrained by some ﬁxed maximum MPL (because only so many jobs ﬁt into memory or for some other reason). Thus the only method we have for increasing throughput is changing the central subsystem, either by changing therouting or by speeding up some device. Observe that in the batch system we are notconcerned with response times because the jobs are running overnight. Question: What does Xmean in a closed system? Answer: Xis the number of jobs crossing “out” per second. Note that “in” = “out” for the batch system. 2.6.3 Throughput in a Closed System Let’s look at some examples. Example: Single Server Figure 2.13 shows a closed network consisting of a single server. MPL = N µ Figure 2.13. Single-server closed network. Question: What is the throughput, X, in Figure 2.13? Answer: X=μ. Observe that this is very different from the case of the open network where throughput was independent of service rate.",7229
2.9 Exercises,"24 queueing theory terminology Question: What is the mean response time, E[R], in Figure 2.13? Answer: For a closed batch system, E[R]=E[T], namely the response time and time in system are the same. For Figure 2.13,E[T]=N/μ , because every “arrival” waits behind N−1jobs and then runs. Note that XandE[R]are inversely related. Example: Tandem Servers Now consider the example of a more complicated closed network, as shown in Fig- ure2.14. MPL = N µ2 µ1 Figure 2.14. Tandem servers closed network. Question: What is the throughput? Answer: We would like to say X=m i n ( μ1,μ2)... Question: Why is this previous answer not necessarily correct? Answer: The previous answer is correct if we know that the slower server is always busy, but that is not necessarily the case. Imagine N=1. Then it is certainly not the case that the slower server is always busy. Question: OK, but what happens when N=2. Now it appears that there is always at least one job at the slow server, doesn’t it? Answer: Nope, the slower server is still not always busy. What we’re missing here is the fact that sometimes the slow server is faster than the fast server – because these service rates are just averages. So do we in fact need to take the job size distributioninto account to get the exact answer? Does the job size distribution really affect the answer very much? We will answer these questions soon enough ...F o rn o w , let’s sum up the differences between the behavior of open and closed networks and why we need to consider both. 2.7 Differences between Closed and Open Networks Open Systems rThroughput, X, is independent of the μi’s rXis not affected by doubling the μi’s. rThroughput and response time are notrelated. 2.8related readings 25 Closed Systems rXdepends on μi’s. rIf we double all the μi’s while holding Nconstant, then Xchanges. rIn fact we see in Chapter 6that for closed systems, Higher throughput ⇐⇒ Lower avg. response time . 2.7.1 A Question on Modeling Here is a ﬁnal question: A few years ago I got a call from some folks at IBM. They were trying to model their blade server as a single-server queue. They knew the arrival rate into the server, λ, in jobs/sec. However they were wondering how to get E[S], the mean job size. Question: How do you obtain E[S]in practice for your single-server system? Answer: At ﬁrst glance, you might reason that because E[S]is the mean time required for a job in isolation, you should just send a single job into the system and measure its response time, repeating that experiment a hundred times to get an average. This makes sense in theory, but does not work well in practice, because cache conditions and other factors are very different for the scenario of just a single job compared withthe case when the system has been loaded for some time. A better approach is to recall that E[S]=1 μ, so it sufﬁces to think about the service rate of the server in jobs/second. To get μ, assuming an open system, we can make λ higher and higher, which will increase the completion rate, until the completion rate levels off at some value, which will be rate μ. An even better idea is to put our server into a closed system, with zero think time. This way the server is guaranteed to always be occupied with work. Now, if we measure thecompletion rate at the server (jobs completing per second), then that will give us μfor the server. E[S]is then the reciprocal of μ. 2.8 Related Readings Especially helpful in understanding closed queueing networks are Lazowska (pp. 58– 59) [ 117] and Menasc ´e (pp. 84–87) [ 125]. Both of these are wonderful books. There is surprisingly very little known in the literature on how closed systems compare to open systems. For example, consider a closed interactive single-server system withload ρ, versus the corresponding open system with load ρ. How do these compare to each other with respect to their mean response time? How does variability in service time affect closed systems versus open ones? These questions and many others are considered in [ 186] and [ 24], as well as in Exercises 7.2,7.5,13.7, and 13.8. Another question is how the scheduling policy (service order) at the server affects closed systems versus open systems. This question was not really discussed until 2006 [ 165]. For a 26 queueing theory terminology more recent discussion of the open versus closed topic, we recommend the book by Y. C . Ta y [ 173]. In this chapter, we have mentioned several times that ensuring that the arrival rate is less than the service rate ( λ<μ )i snecessary for stability. This condition will also be sufﬁcient to ensure stability of the networks we consider in this book. However, it is not generally a sufﬁcient condition for stability in more complex queueing networks. To understand why, we recommend the papers of Maury Bramson (see [ 29]). 2.9 Exercises 2.1 Maximum Outside Arrival Rate For the network-of-queues with probabilistic routing given in Figure 2.3, sup- pose that each server serves at an average rate of 10 jobs/sec; that is, μi=1 0 ,∀i. Suppose that r2=r3=1. Suppose that p12=p2,out=0.8,p23=p13=0.2, p1,out=0, andp31=1. What is the maximum allowable value of r1to keep this system stable? 2.2 Slowdown (a) Jobs arrive at a server that services them in FCFS order: FCFS The average arrival rate is λ=1 2job/sec. The job sizes (service times) are independently and identically distributed according to random variable S where S=/braceleftbigg 1with probability 3/4 2otherwise. You have measured the mean response time: E[T]=29 12. Based on this information, compute the mean slowdown, E[Slowdown ], where the slowdown of job jis deﬁned as Slowdown (j)=T(j) S(j), where T(j)is the response time of job jandS(j)is the size of job j. (b) If the service order in part (a) had been Shortest-Job-First (SJF), would the same technique have worked for computing mean slowdown? 2.3 Scheduling Orders (a) For a single-server CPU, where jobs arrive according to some process, let SRPT denote the preemptive scheduling policy that always serves the job with the currently Shortest-Remaining-Processing-Time (assume one knows this information). It is claimed that for any arrival sequence , con- sisting of the arrival time and size of every job, SRPT scheduling mini- mizes mean response time over that arrival sequence. Prove or disprove thisclaim. 2.9exercises 27 (b) The slowdown of a job is deﬁned as the job’s response time divided by its service requirement. (i) Mean slowdown is thought by many to be amore important performance metric than mean response time. Why do youthink this is? (ii) It seems intuitive that the SRPT scheduling policy shouldminimize mean slowdown. Prove or disprove this hypothesis.",6704
Part II Necessary Probability Background,"PART II Necessary Probability Background Probability is an important part of analytical modeling. Part IIprovides all the prob- ability that we will need throughout this book. Chapter 3provides a quick review of undergraduate probability. Chapter 4reviews two methods for generating random vari- ables, which will be important in simulating queues. Finally, Chapter 5discusses more advanced topics, like sample paths, convergence of sequences of random variables, and different types of averages, such as time averages and ensemble averages. Theseconcepts are important and are referred to throughout the book; however they are alsodifﬁcult, and it is reasonable that a reader might want to skim Chapter 5during a ﬁrst reading and return to the chapter for a more in-depth reading after covering Markovchains in Chapters 8and9. 29",830
Chapter 3 Probability Review. 3.8 Probabilities and Densities,"CHAPTER 3 Probability Review In this book, we assume a knowledge of undergraduate probability, including both discrete and continuous random variables. The ﬁrst three chapters (about 180 pages)of Sheldon Ross’s book, Introduction to Probability Models [150], provide excellent coverage of these topics, and we encourage readers to look there. In this chapter we provide a brief review of the speciﬁc probabilistic concepts that we will need in thisbook, by way of some simple illustrative examples. We start with a discussion ofprobability on events and then move on to random variables. Working through theseexamples, plus the exercises at the end of this chapter, should sufﬁce as a review of undergraduate probability for the purposes of this book. 3.1 Sample Space and Events Probability is typically deﬁned in terms of some experiment . The sample space ,Ω, of the experiment is the set of all possible outcomes of the experiment. Deﬁnition 3.1 Anevent ,E, is any subset of the sample space, Ω. For example, in an experiment where two dice are rolled, each outcome (a.k.a. sample point) is denoted by the pair (i,j), where iis the ﬁrst roll and jis the second roll. There are 36 sample points. We can consider the event E={(1,3)or(2,2)or(3,1)} that the sum of the dice rolls is 4. In general, the sample space may be discrete , meaning that the number of outcomes is ﬁnite, or at least countably inﬁnite, or continuous , meaning that the number of outcomes is uncountable.One can talk of unions and intersections of events, because they are also sets (e.g., E∪F,E∩F, andEC, where EandFare events and EC, the complement of E, denotes the set of points in Ωbut not in E). Question: For the dice-rolling experiment, consider events E1andE2deﬁned on Ωin Figure 3.1. Do you think that E1andE2are independent? Answer: No, they are not independent. We get to this later when we deﬁne indepen- dence. We say instead that E1andE2are mutually exclusive. 31 32 probability review (1,1)      (1,2)      (1,3)      (1,4)      (1,5)      (1,6)    (2,1)      (2,2)      (2,3)      (2,4)      (2,5)      (2,6)   (3,1)      (3,2)      (3,3)      (3,4)      (3,5)      (3,6)    (4,1)      (4,2)      (4,3)      (4,4)      (4,5)      (4,6)    (5,1)      (5,2)      (5,3)      (5,4)      (5,5)      (5,6)    (6,1)      (6,2)      (6,3)      (6,4)      (6,5)      (6,6)   Ω =E2 E1 Figure 3.1. Illustration of two events in sample space Ω. Deﬁnition 3.2 IfE1∩E2=∅, thenE1andE2aremutually exclusive . Deﬁnition 3.3 IfE1,E2,...,Enare events such that Ei∩Ej=∅,∀i, j, and such that/uniontextn i=1Ei=F, then we say that events E1,E2,...,Enpartition setF. 3.2 Probability Deﬁned on Events Probability is deﬁned on events. P{E}=probability of event Eoccurring. We can think of each sample point as having some probability of occurring, and the probability that event Eoccurs is the sum of the probabilities of the sample points inE. For example, in the two-dice example, each sample point (an ordered pair of numbers) occurs with a probability of1 36.",3027
Chapter 3 Probability Review. 3.8 Probabilities and Densities,"Importantly the probability of Ω, where Ωis the sample space, is deﬁned to be 1. Deﬁnition 3.4 The probability of the union of two events is deﬁned as follows: P{E∪F}=P{E}+P{F}−P{E∩F} This should make sense if we think of events as sets as shown in Figure 3.2. Observe that the subtraction of the P{E∩F}term is necessary so that those sample points are not counted twice. = Sample poin tEF Figure 3.2. Venn diagram. 3.3conditional probabilities on events 33 Theorem 3.5 P{E∪F}≤P{E}+P{F}. Proof This follows immediately from Deﬁnition 3.4. Question: When is Theorem 3.5an equality? Answer: When EandFare mutually exclusive. Question: Suppose your experiment involves throwing a dart, which is equally likely to land anywhere in the interval [0,1]. What is the probability that the dart lands at exactly 0.3? Answer: The probability of landing at exactly 0.3is deﬁned to be 0. To see this, suppose that the probability were strictly greater than 0, say/epsilon1>0. Then the probability of landing at 0.5would also be /epsilon1, as would the probability of landing at any rational point. But these different landing outcomes are mutually exclusive events, so their probabilities add. Thus the probability of landing in the interval [0,1]would be greater than1, which is not allowed, because P{Ω}=1. While the probability of landing at exactly 0.3is deﬁned to be 0, the probability of landing in the interval [0,0.3]is deﬁned to be 0.3. 3.3 Conditional Probabilities on Events Deﬁnition 3.6 The conditional probability of event Egiven event Fis written as P{E|F}and is given by the following, where we assume P{F}>0: P{E|F}=P{E∩F} P{F}(3.1) P{E|F}should be thought of as the probability that event Eoccurs, given that we have narrowed our sample space to points in F. To see this, consider Figure 3.3, where P{E}=8 42andP{F}=10 42. EΩ F Figure 3.3. Sample space with 42 sample points. If we imagine that we narrow our space to the 10 points in F, then the probability of being in set E, given we are in set F, should be 2out of 10. Indeed, P{E|F}=2 10=2 42 10 42=P{E∩F} P{F}. 34 probability review Example: Table 3.1shows my sandwich choices each day. We deﬁne the “ﬁrst half of the week” to be Monday through Wednesday (inclusive), and the “second half of the week” to be Thursday through Sunday (inclusive). Table 3.1. My sandwich choices Mon Tue Wed Thu Fri Sat Sun Jelly Cheese Turkey Cheese Turkey Cheese None Question: What is P{Cheese|Second half of week }? Answer: This is asking for the fraction of days in the second half of the week when I eat a cheese sandwich. The answer is clearly 2out of 4,o r2 4. Alternatively, we can use ( 3.1) as follows: P{Cheese|Second half of week }=P{Cheese &Second half} P{Second half}=2 7 4 7=2 4. 3.4 Independent Events and Conditionally Independent Events Deﬁnition 3.7 Events EandFareindependent if P{E∩F}=P{E}·P{F}. Question: IfEandFare independent, what is P{E|F}? Answer: Assuming P{F}>0,w eh a v e P{E|F}=P{E∩F} P{F}indpt=P{E}·P{F} P{F}=P{E}. That is, P{E}is not affected by whether Fis true or not.",3045
Chapter 3 Probability Review. 3.8 Probabilities and Densities,"Question: Can two mutually exclusive (non-null) events ever be independent? Answer: No. In this case, P{E|F}=0/negationslash=P{E}. Question: Suppose one is rolling two dice. Which of these pairs of events are inde- pendent? 1.E1=“First roll is 6” and E2=“Second roll is 6” 2.E1=“Sum of the rolls is 7” and E2=“Second roll is 4” Answer: They are both independent. Question: Suppose we had deﬁned: E1=“Sum of the rolls is 8” and E2=“Second roll is 4.” Are they independent now? Answer: No. A different notion of independence that comes up frequently in problems (see for example, Exercise 3.20) is that of conditional independence. 3.5law of total probability 35 Deﬁnition 3.8 Two events EandFare said to be conditionally independent given eventG, where P{G}>0,i f P{E∩F|G}=P{E|G}·P{F|G}. Independence does not imply conditional independence and vice versa. 3.5 Law of Total Probability Observe that the set Ecan be expressed as E=(E∩F)∪/parenleftbig E∩FC/parenrightbig . That is, Eis the union of the set E∩Fand the set E∩FC, because any point in E is either also in For also notinF. Now observe that E∩FandE∩FCare mutually exclusive. Thus, P{E}=P{E∩F}+P/braceleftbig E∩FC/bracerightbig =P{E|F}P{F}+P/braceleftbig E|FC/bracerightbig P/braceleftbig FC/bracerightbig whereP{FC}=1−P{F}. Theorem 3.9 is a generalization. Theorem 3.9 (Law of Total Probability) LetF1,F2,...,F npartition the state spaceΩ. Then, P{E}=n/summationdisplay i=1P{E∩Fi} =n/summationdisplay i=1P{E|Fi}·P{Fi}. Proof E=n/uniondisplay i=1(E∩Fi). Now, because the events E∩Fi,i=1,...,n , are mutually exclusive, we have that P{E}=n/summationdisplay i=1P{E∩Fi}=n/summationdisplay i=1P{E|Fi}·P{Fi}. Question: Suppose we are interested in the probability that a certain type of transaction fails. We know that if there is a caching failure, then the transaction will fail withprobability 5/6. We also know that if there is a network failure then the transaction will fail with probability 1/4. Suppose that the network fails with probability 1/100, 36 probability review and the cache fails with probability 1/100. Is this enough to tell us the probability that the transaction will fail? Answer: It is tempting to write (WRONG) P{transaction fails }=P{transaction fails |caching failure }·1 100 +P{transaction fails |network failure }·1 100 =5 6·1 100+1 4·1 100. Question: What is wrong with that solution? Answer: The two events we conditioned on – a network failure and a caching failure – do not necessarily partition the space. The sum of the probabilities of these events isclearly <1. Furthermore, there may be a non-zero probability that both failures occur. One needs to be very careful that the events are both (i) mutually exclusive and (ii) sum to the whole sample space. 3.6 Bayes Law Sometimes, one needs to know P{F|E}, but all one knows is the reverse direction: P{E|F}. Is it possible to get P{F|E}fromP{E|F}? It turns out that it is, assuming that we also know P{E}andP{F}. Theorem 3.10 (Bayes Law) P{F|E}=P{E|F}·P{F} P{E} Proof P{F|E}=P{E∩F} P{E}=P{E|F}·P{F} P{E} The Law of Total Probability can be combined with Bayes Law as follows: LetF1,F2,...,F npartition Ω. Then we can write: P{E}=/summationtextn j=1P{E|Fj}· P{Fj}.",3204
Chapter 3 Probability Review. 3.8 Probabilities and Densities,"This yields the following: Theorem 3.11 (Extended Bayes Law) LetF1,F2,...,F npartition Ω. Then P{F|E}=P{E|F}·P{F} P{E}=P{E|F}·P{F}/summationtextn j=1P{E|Fj}P{Fj} 3.7discrete versus continuous random variables 37 Example: A test is used to diagnose a rare disease. The test is only 95 percent accurate, meaning that, in a person who has the disease it will report “positive” with probability 95 percent (and negative otherwise), and in a person who does not have the disease, it will report “negative” with probability 95 percent (and positive otherwise). Suppose that 1 in 10,000 children get the disease. Question: A mom brings in her child to be tested. Given that the test comes back positive, how worried should the mom be? Answer: P{Child has disease |Test positive} =P{Test Positive|Disease}·P{Disease} P{Test positive|Disease}·P{Disease}+P{Test positive|Healthy}·P{Healthy} =0.95·1 10000 0.95·1 10000+0.05·9999 10000 =0.0019 Thus the probability that the child has the disease is only about 2 out of 1,000. 3.7 Discrete versus Continuous Random Variables Consider an experiment, such as rolling two dice. Suppose that we are interested in the sum of the two rolls. That sum could range anywhere from 2to12, with each of these events having a different probability. A random variable, X, associated with this experiment, is a way to represent the value of the experiment (in this case the sum ofthe rolls). Speciﬁcally, when we write X, it is understood that Xhas many instances, ranging from 2to12and that different instances occur with different probabilities (e.g., P{X=3}=2 36). Deﬁnition 3.12 Arandom variable (r.v.) is a real-valued function of the outcome of an experiment. Deﬁnition 3.13 Adiscrete random variable can take on at most a countably inﬁnite number of possible values, whereas a continuous random variable can take on an uncountable set of possible values. Question: Which of these random variables is discrete and which is continuous? 1.The sum of the rolls of two dice 2.The number of arrivals at a website by time t 3.The time until the next arrival at a website 4.The CPU requirement of an HTTP request 38 probability review Answer: The ﬁrst of these can take on only a ﬁnite number of values – those between 2 and 12 – so it clearly is a discrete r.v. The number of arrivals at a website can takeon the values: 0,1,2,3,... namely a countable set; hence this is discrete as well. Time, in general, is modeled as a continuous quantity, even though there is a non-zerogranularity in our ability to measure time via a computer. Thus quantities three andfour above are continuous r.v.’s. We use capital letters to denote random variables. For example, we might deﬁne Xto be a random variable equal to the sum of two dice. Then, P{X=7}=P{(1,6)or(2,5)or(3,4),..., or(6,1)}=1 6. Important: Because the “outcome of the experiment” is just an event, all the theorems that we learned about events apply to random variables as well. In particular, the Law of Total Probability holds. For example, if Ndenotes the number of arrivals at a website by time t, thenN>10is an event. We can then use conditioning on events to get P{N>10}=P{N>10|weekday}·5 7+P{N>10|weekend}·2 7.",3190
Chapter 3 Probability Review. 3.8 Probabilities and Densities,"All of this will become more concrete once we study examples of common random variables next. 3.8 Probabilities and Densities 3.8.1 Discrete: Probability Mass Function Discrete random variables take on a countable number of values, each with some probability. Deﬁnition 3.14 LetXbe a discrete r.v. Then the probability mass function (p.m.f.) , pX(·)ofX, is deﬁned as follows: pX(a)=P{X=a},where/summationdisplay xpX(x)=1 The cumulative distribution function ofXis deﬁned as FX(a)=P{X≤a}=/summationdisplay x≤apX(x). We also write FX(a)=P{X>a}=/summationdisplay x>apX(x)=1−FX(a). Common discrete distributions include the Bernoulli, the Binomial, the Geometric, and the Poisson, all of which are discussed next. Bernoulli( p)represents the result of a single coin ﬂip, where the coin has probability pof coming up heads (we map this event to the value 1) and 1−pof coming up tails 3.8probabilities and densities 39 (we map this event to the value 0). If Xis a r.v. drawn from the Bernoulli (p)distribution, then we write: X∼Bernoulli (p)and deﬁne Xas follows: X=/braceleftbigg 1w/ prob p 0otherwise The p.m.f. of r.v. Xis deﬁned as follows: pX(1) = p pX(0) = 1−p The p.m.f. is depicted in Figure 3.4. 00.20.40.60.81 1–pp 1 0 Figure 3.4. Probability mass function of Bernoulli (p)distribution, with p=0.76. Binomial( n, p )builds on Bernoulli (p). Given a coin with probability pof coming up heads (success), we ﬂip the coin ntimes (these are independent ﬂips). If X∼ Binomial (n,p), then Xrepresents the number of heads (successes) when ﬂipping a Bernoulli (p)coinntimes. Observe that Xcan take on discrete values: 0,1,2,...,n . The p.m.f. of r.v. Xis deﬁned as follows: pX(i)=P{X=i} =/parenleftbiggn i/parenrightbigg pi(1−p)n−i,where i=0,1,2,...,n The p.m.f. is shown in Figure 3.5. 00.20.40.60.81 4 3 2 1 0 Figure 3.5. Probability mass function of the Binomial (n,p)distribution, with n=4andp=0.3. Geometric( p)also builds on Bernoulli (p). Again we have a coin with probability pof coming up heads (success). We now ﬂip it until we get a success; these are independent trials, each Bernoulli (p).I fX∼Geometric (p), thenXrepresents the number of ﬂips until we get a success. 40 probability review The p.m.f. of r.v. Xis deﬁned as follows: pX(i)=P{X=i}=( 1−p)i−1p,where i=1,2,3,... The p.m.f. is shown in Figure 3.6. 1 0.8 0.6 0.4 0.2 0 56 4 3 2 1 Figure 3.6. Probability mass function of the Geometric (p)distribution, with p=0.5. Question: Let’s review. Suppose you have a room of ndisks. Each disk independently dies with probability peach year. How are the following quantities distributed? 1.The number of disks that die in the ﬁrst year 2.The number of years until a particular disk dies 3.The state of a particular disk after one year Answer: The distributions are: 1. Binomial (n,p), 2. Geometric (p), 3. Bernoulli (p). Poisson( λ)is another discrete distribution that is very common in computer systems analysis. We deﬁne Poisson (λ)via its p.m.f. Although the p.m.f. does not appear to have any meaning at present, we will show many interesting properties of this distribution in Chapter 11.",3101
Chapter 3 Probability Review. 3.8 Probabilities and Densities,"The Poisson distribution occurs naturally when looking at a mixture of a very large number of independent sources, each with a very small individual probability. It can therefore be a reasonable approximation for the numberof arrivals to a website or a router per unit time. If X∼Poisson (λ), then pX(i)=e−λλi i.,where i=0,1,2,... The p.m.f. for the Poisson (λ)distribution is shown in Figure 3.7. 00.20.40.60.81 5 4 3 2 1 0 Figure 3.7. Probability mass function of the Poisson (λ)distribution with λ=2. 3.8probabilities and densities 41 You may have noticed that the Poisson distribution does not look all that different from the Binomial distribution. It turns out, as shown in Exercise 3.12, that if nis large and pis small, then Binomial (n,p)is actually very close to Poisson (np). 3.8.2 Continuous: Probability Density Function Continuous r.v.’s take on an uncountable number of values. The range of a continuous r.v. can be thought of as an interval or collection of intervals on the real line. Theprobability that a continuous r.v., X, is equal to any particular value is zero. We deﬁne probability for a continuous r.v. in terms of a density function. Deﬁnition 3.15 The probability density function (p.d.f.) of a continuous r.v. Xis a non-negative function fX(·)where P{a≤X≤b}=/integraldisplayb afX(x)dx and where/integraldisplay∞ −∞fX(x)dx=1. Deﬁnition 3.15 is illustrated in Figure 3.8. fX(x) This area represents  the probability that 5 < X < 6 6 5 Figure 3.8. Area under the curve represents the probability that r.v. Xis between 5and6, namely/integraltext6 5fX(x)dx. Question: DoesfX(x)have to be <1for all x? Answer: No,fX(x)/negationslash=P{X=x}. To interpret the density function, f(·), think of fX(x)dx.=P{x≤X≤x+dx}. Question: Which of these are valid p.d.f.’s? fX(x)=/braceleftbigg .5x−.5if0<x< 1 0 otherwise fX(x)=/braceleftbigg 2x−2if0<x< 1 0 otherwise fX(x)=/braceleftbigg x−2if1<x<∞ 0 otherwise Answer: Only the ﬁrst and third p.d.f.’s integrate to 1, so only they are valid. 42 probability review Deﬁnition 3.16 The cumulative distribution function (c.d.f.) of a continuous r.v. Xis the function F(·)deﬁned by FX(a)=P{−∞ <X≤a}=/integraldisplaya −∞fX(x)dx. We also write: F(a)=1−FX(a)=P{X>a}. Question: We know how to get FX(x)fromfX(x). How do we get fX(x)from FX(x)? Answer: By the Fundamental Theorem of Calculus, fX(x)=d dx/integraldisplayx −∞f(t)dt=d dxFX(x). There are many common continuous distributions. Below we brieﬂy deﬁne just a few: the Uniform, Exponential, and the Pareto distributions. Uniform( a,b), often written U(a, b), models the fact that any interval of length δ between aandbis equally likely. Speciﬁcally, if X∼U(a, b), then fX(x)=⎧ ⎨ ⎩1 b−aifa≤x≤b 0 otherwise. Question: ForX∼U(a, b), what is FX(x)? Answer: FX(x)=/integraldisplayx a1 b−adx=x−a b−a Figure 3.9depicts fX(x)andFX(x)graphically. bx x a 01 FX(x) fX(x)1 b − a b a Figure 3.9. The p.d.f., f(x), and c.d.f., F(x), functions for Uniform (a,b). The shaded region in the left graph has an area equal to the height of the darkened segment in the right graph. Exp(λ)denotes the Exponential distribution, whose probability density function drops off exponentially. We say that a random variable Xis distributed Exponentially with 3.8probabilities and densities 43 rateλ, written X∼Exp(λ),i f fX(x)=/braceleftbiggλe−λxx≥0 0 x<0. The graph of the p.d.f. is shown in Figure 3.10. The c.d.f., FX(x)=P{X≤x},i s given by FX(x)=/integraldisplayx −∞f(y)dy=/braceleftbigg1−e−λxx≥0 0 x<0. FX(x)=1−FX(x)=e−λx,x≥0 λ λe−λ λe−2λ λe−3λ x 4fX(x) 0 12 3 Figure 3.10. Exponential probability density function. Observe that both fX(x)andF(x)drop off by a constant factor, e−λ, with each unit increase of x. This fact will be important in proving the “memoryless” property of the Exponential distribution, described in Chapter 11. Pareto( α)is a distribution with a power-law tail, meaning that its density decays as a polynomial in 1/xrather than exponentially, as in Exp( λ). The parameter αis often referred to as the “tail parameter.” It is generally assumed that 0<α< 2.A s we see later, this range of αgives the Pareto inﬁnite variance (variance is deﬁned in Section 3.9). IfX∼Pareto(α), then fX(x)=/braceleftBigg αx−α−1x≥1 0 otherwise. FX(x)=1−x−α. FX(x)=x−α. Although the Pareto distribution has a ski-slope shape, like that of the Exponential, its tail decreases much more slowly (compare F(x)for the two distributions). The Pareto",4425
3.9 Expectation and Variance,"44 probability review distribution is said to have a “heavy tail” or a “fat tail,” where a lower αcorresponds to a fatter tail. This is all covered in Chapter 20. An important continuous distribution that we have not mentioned is the Normal , a.k.a. Gaussian, distribution. The discussion of the Normal distribution requires ﬁrst understanding expectation and variance, so we defer it until Section 3.14. 3.9 Expectation and Variance Themean of a distribution, also known as its expectation , follows immediately from the probability mass function (or density function, in the case of continuous distributions) for the distribution. For r.v. X, we write E[X]to denote its mean. This is deﬁned in the following table. Discrete case Continuous case E[X]=/summationtext xx·pX(x) E[X]=/integraltext∞ −∞x·fX(x)dx For the case of a discrete r.v., X, its expectation can be viewed as a sum of the possible outcomes, each weighted by its probability. E[X]=/summationdisplay xxP{X=x} To see this, consider the following example. Example: Average Cost of Lunch What is the average cost of my lunch? Monday Tuesday Wednesday Thursday Friday Saturday Sunday $7 $7 $5 $5 $5 $0 $2 Avg=7+7+5+5+5+0+2 7 ||| E[Cost]=2 7(7) +3 7(5) +1 7(2) +1 7(0) Each possible value – 7,5,2, and0– is weighted by its probability. Question: IfX∼Bernoulli (p), what is E[X]? Answer: E[X]=0·(1−p)+1·(p)=p. Question: Suppose a coin has probability1 3of coming up heads. In expectation, how many times do I need to toss the coin to get a head? 3.9expectation and variance 45 Answer: This is simply E[X], where X∼Geometric (p), with p=1 3. Assuming X∼Geometric (p),w eh a v e E[X]=∞/summationdisplay n=1n(1−p)n−1p =p·∞/summationdisplay n=1n·qn−1where q=( 1−p) =p·∞/summationdisplay n=1d dq(qn) =p·d dq∞/summationdisplay n=1qn =p·d dq/parenleftbiggq 1−q/parenrightbigg =p (1−q)2 =1 p. So when p=1 3, the expected number of ﬂips is 3. Question: IfX∼Poisson (λ), what is E[X]? Answer: E[X]=∞/summationdisplay i=0ie−λλi i. =∞/summationdisplay i=1ie−λλi i. =λe−λ∞/summationdisplay i=1λi−1 (i−1). =λe−λ∞/summationdisplay k=0λk k. =λe−λeλ =λ. Question: IfX∼Exp(λ), what is E[X]? Answer: E[X]=/integraldisplay∞ −∞xfX(x)dx=/integraldisplay∞ 0xλe−λxdx=1 λ(integration by parts) . 46 probability review Observe that whereas the λparameter for the Poisson distribution is also its mean, for the Exponential distribution, the λparameter is the reciprocal of the mean. We will refer to λas the “rate” of the Exponential. For example, if the time until the next arrival is Exponentially distributed with rate 3arrivals per second, then the expected time until the next arrival is1 3seconds. We can also think about higher moments of a random variable X. Theith moment of r.v.X, denoted by E[Xi], is deﬁned as follows: Discrete case Continuous case E[Xi]=/summationtext xxi·pX(x) E[Xi]=/integraltext∞ −∞xi·fX(x)dx More generally, we can talk about the expectation of a function g(·)of a random variable X. This is deﬁned as follows for a discrete r.v. X: E[g(X)] =/summationdisplay xg(x)·pX(x) and as follows for a continuous r.v. X: E[g(X)] =/integraldisplay∞ −∞g(x)fX(x)dx Question: Suppose Xis deﬁned as follows: X=⎧ ⎪⎨ ⎪⎩0w/ prob. 0.2 1w/ prob. 0.5 2w/ prob. 0.3 What is E[X]and what is E[2X2+3 ]? Answer: E[X]=( 0 ) ( .2) + (1)( .5) + (2)( .3). E/bracketleftbig 2X2+3/bracketrightbig =/parenleftbig 2·02+3/parenrightbig (.2) +/parenleftbig 2·12+3/parenrightbig (.5) +/parenleftbig 2·22+3/parenrightbig (.3). You may have noticed that E[2X2+3 ]=2 E[X2]+3 . This is no coincidence and is due to Linearity of Expectation to be discussed in Section 3.13. Deﬁnition 3.17 The variance o far . v . X, written as Var(X), is the expected squared difference of Xfrom its mean (i.e., the square of how much we expect X to differ from its mean, E[X]). This is deﬁned as follows: Var(X)=E/bracketleftBig (X−E[X])2/bracketrightBig and can be equivalently expressed as follows: Var(X)=E[X2]−(E[X])2 (The derivation of why these expressions are equivalent will be obvious after we cover Linearity of Expectation in Section 3.13.)",4063
3.10 Joint Probabilities and Independence,"3.10 joint probabilities and independence 47 Question: IfX∼Bernoulli (p), what is Var(X)? Answer: E[X]=p Var(X)=E/bracketleftbig (X−p)2/bracketrightbig =p(1−p)2+( 1−p)(0−p)2=p(1−p) Question: What is the variance of X∼Uniform (a, b)? Answer: E[X]=/integraldisplayb ax1 b−adx=1 b−a·(b2−a2) 2=a+b 2 Var(X)=E/bracketleftBigg/parenleftbigg X−a+b 2/parenrightbigg2/bracketrightBigg =/integraldisplayb a/parenleftbigg X−a+b 2/parenrightbigg2 ·1 b−adx=(b−a)2 12 Table 3.2shows the p.m.f. (or p.d.f.) and the mean and variance for many common distributions. Table 3.2. Discrete and continuous distributions Distribution p.m.f. pX(x) Mean Variance Bernoulli (p) pX(0) = 1 −p;pX(1) = pp p (1−p) Binomial (n,p) pX(x)=/parenleftbign x/parenrightbig px(1−p)n−x, np np (1−p) x=0,1,...,n Geometric (p) pX(x)=( 1 −p)x−1p,x=1,2,...1 p1−p p2 Poisson( λ) pX(x)=e−λ·λx x.,x=0,1,2,... λ λ Distribution p.d.f. fX(x) Mean Variance Exp(λ) fX(x)=λe−λx 1 λ1 λ2 Uniform (a,b) fX(x)=1 b−a,i fa≤x≤bb+a 2(b−a)2 12 Pareto( α),0<α< 2fX(x)=αx−α−1,i fx>1/braceleftbigg∞ ifα≤1 α α−1ifα>1∞ Normal( μ,σ2) fX(x)=1√ 2πσe−1 2(x−μ σ)2 , μσ2 −∞<x< ∞ 3.10 Joint Probabilities and Independence We are often interested in probability statements concerning two or more r.v.’s simulta- neously. For example, we might want to know the probability that two disks will bothcrash within some time interval. The behavior of the two disks might be correlated or not. As another example, computer systems performance is often measured in terms of the energy-delay product [ 68], namely the product of the energy used by the system and the delay experienced by users. Energy and delay typically are correlated with each other, and one can imagine a joint distribution between these two random variables. Inthis section and the next, we present the deﬁnitions needed to formally express theseideas. 48 probability review Deﬁnition 3.18 The joint probability mass function between discrete r.v.’s Xand Yis deﬁned by pX,Y(x, y)=P{X=x&Y=y}. This is typically written as P{X=x, Y=y}. Similarly, fX,Y(x, y)represents thejoint probability density function between continuous r.v.’s XandY, where /integraldisplayd c/integraldisplayb afX,Y(x, y)dxdy=P{a<X<b &c<Y <d} Question: What is the relationship between fX(x)andfX,Y(x, y)? Answer: Applying the Law of Total Probability, we have fX(x)=/integraldisplay∞ −∞fX,Y(x, y)dyand fY(y)=/integraldisplay∞ −∞fX,Y(x, y)dx. Likewise, pX(x)=/summationdisplay ypX,Y(x, y)a n d pY(y)=/summationdisplay xpX,Y(x, y). Similarly to the way we deﬁned two events EandFas being independent, we can likewise deﬁne two r.v.’s as being independent. Deﬁnition 3.19 We say that discrete r.v.’s XandYareindependent , written X⊥Y,i f pX,Y(x, y)=pX(x)·pY(y). Likewise, we say that continuous r.v.’s XandYare independent if fX,Y(x, y)=fX(x)·fY(y),∀x, y. Theorem 3.20 IfX⊥Y, thenE[XY]=E[X]·E[Y]. Proof E[XY]=/summationdisplay x/summationdisplay yxy·P{X=x, Y=y} =/summationdisplay x/summationdisplay yxy·P{X=x}P{Y=y}(by deﬁnition of ⊥) =/summationdisplay xxP{X=x}·/summationdisplay yyP{Y=y} =E[X]E[Y] The same argument works for continuous r.v.’s.",3104
3.11 Conditional Probabilities and Expectations,"3.11 conditional probabilities and expectations 49 The same proof shows that if X⊥Y, then E[g(X)f(Y)] =E[g(X)]·E[f(Y)] for arbitrary functions gandf. Question: IfE[XY]=E[X]E[Y], does that imply that X⊥Y? Answer: No, see Exercise 3.10. 3.11 Conditional Probabilities and Expectations Just as we studied conditional probabilities of events – that is, the probability that one event occurs, given that another has occurred – we can also extend this to conditionalprobabilities in random variables. We start with the discrete case and then move on to the continuous case. The following example will help motivate the idea. Example: Hair Color Suppose we divide the people in the class into Blondes (color value 1), Red-heads (color value 2), Brunettes (color value 3), and Black-haired people (color value 4).Let’s say that 5students are Blondes, 2are Red-heads, 17are Brunettes, and 14 are Black-haired. Let Xbe a random variable whose value is hair color. Then the probability mass function for Xlooks like this: pX(1) =P{Blonde}=5/38 pX(2) =P{Red}=2/38 pX(3) =P{Brown}=1 7/38 pX(4) =P{Black}=1 4/38 Now let’s say that a person has light-colored hair if the hair color is either Blonde or Red. Let’s say that a person has dark-colored hair if the hair color is either Brown or Black. Let Adenote the event that a person’s hair color is light. P{A}=7/38 andP/braceleftbig AC/bracerightbig =3 1/38 Deﬁnition 3.21 LetXbe a discrete r.v. with p.m.f. pX(·)deﬁned over a countable space. Let Abe an event. Then pX|A(·)is the conditional p.m.f. ofXgiven event A. We deﬁne pX|A(x)=P{X=x|A}=P{(X=x)∩A} P{A}. More formally, if Ωdenotes the sample space and ωrepresents a sample point in the sample space, and {ω:X(ω)=x}is the set of sample points that result in X having value x, then pX|A(x)=P{X=x|A}=P{{ω:X(ω)=x}∩A} P{A}. 50 probability review A conditional probability thus involves narrowing down the probability space. For example, pX|A(Blonde )=P{(X=Blonde )∩A} P{A}=5 38 7 38=5 7. Likewise pX|A(Red)=2/7. As another example, pX|A(Brown )=P{(X=Brown )∩A} P{A}=0 7 38=0. Likewise pX|A(Black)=0 . Question: If we sum pX|A(x)over all x, what do we get? Answer: /summationdisplay xpX|A(x)=/summationdisplay xP{(X=x)∩A} P{A}=P{A} P{A}=1. ThuspX|A(x)is a valid p.m.f. Deﬁnition 3.22 For a discrete r.v. X, the conditional expectation of Xgiven event Ais as follows: E[X|A]=/summationdisplay xxpX|A(x)=/summationdisplay xx·P{(X=x)∩A} P{A} Question: For our example, viewing Blonde as having value 1and Red-haired as having value 2, what is E[X|A]? Answer: E[X|A]=1·5 7+2·2 7=9 7. We can also consider the case where the event, A, is an instance of a random variable. For example, Amight be the event Y=y. It is then common to write the conditional p.m.f. of Xgiven the event Y=yas pX|Y(x|y)=P{X=x|Y=y}=P{X=x&Y=y} P{Y=y}=pX,Y(x, y) pY(y), and E[X|Y=y]=/summationdisplay xx·pX|Y(x|y). Example of Conditioning on Random Variables Two discrete random variables XandYtaking the values {0,1,2}have a joint probability mass function given by Table 3.3. 3.11 conditional probabilities and expectations 51 Table 3.3. Joint probability mass function, pX,Y(x, y) Y=2 01 61 8 Y=11 81 61 8 Y=01 61 80 X=0 X=1 X=2 Question: Compute the conditional expectation E[X|Y=2 ] . Answer: E[X|Y=2 ]=/summationdisplay xx·pX|Y(x|2) =/summationdisplay xx·P{X=x|Y=2} =0·P{X=0& Y=2} P{Y=2}+1·P{X=1& Y=2} P{Y=2} +2·P{X=2& Y=2} P{Y=2} =1·1 6 7 24+2·1 8 7 24=10 7. For a continuous, real-valued, r.v. X, the conditional p.d.f. of Xgiven event Ais analogous to that for the discrete case, except that Ais now a subset of the real line, where we deﬁne P{X∈A}to be the probability that Xhas value within the subset A. Deﬁnition 3.23 LetXbe a continuous r.v. with p.d.f. fX(·)deﬁned over the reals. LetAbe a subset of the real line with P{X∈A}>0. Then fX|A(·)is the conditional p.d.f. ofXgiven event A. We deﬁne fX|A(x)=/braceleftBiggfX(x) P{X∈A}ifx∈A 0 otherwise. As with the discrete case, the conditional p.d.f. is zero outside the conditioning set A. Within A, the conditional p.d.f. has exactly the same shape as the unconditional one, except that it is scaled by the constant factor1 P{X∈A}, so that fX|A(x)integrates to 1. Deﬁnition 3.24 LetXbe a continuous r.v. with p.d.f. fX(·)deﬁned over the reals. LetAbe a subset of the real line with P{X∈A}>0. The conditional expectation ofXgivenA, written E[X|A], is deﬁned by E[X|A]=/integraldisplay∞ −∞xfX|A(x)dx=/integraldisplay AxfX|A(x)dx=1 P{X∈A}/integraldisplay AxfX(x)dx. 52 probability review Example: Pittsburgh Supercomputing Center The Pittsburgh Supercomputing Center (PSC) runs large parallel jobs for scientists from all over the country. To charge users appropriately, jobs are grouped into differentbins based on the number of CPU hours they require, each with a different price.Suppose that job durations are Exponentially distributed with mean 1,000 processor- hours. Further suppose that all jobs requiring less than 500 processor-hours are sent to bin 1, and all remaining jobs are sent to bin 2. Question: Consider the following questions: (a)What is P{Job is sent to bin 1 }? (b)What is P{Job duration <200|job is sent to bin 1 }? (c)What is the conditional density of the duration X,fX|Y(t), where Yis the event that the job is sent to bin 1? (d)What is E[Job duration |job is in bin 1 ]? Answer: Start by recalling that for X∼Exp/parenleftbig1 1000/parenrightbig we have fX(t)=/braceleftBigg 1 1000e−t 1000 ift>0 0 otherwise. FX(t)=P{X≤t}=1−e−1 1000t. Then: (a)FX(500) = 1−e−500 1000=1−e−1 2≈0.39 (b)FX(200) FX(500)=1−e−1 5 1−e−1 2≈0.46 (c) fX|Y(t)=⎧ ⎨ ⎩fX(t) F(500)=1 1000e−t 1000 1−e−1 2ift<500 0 otherwise (d) E[Job duration |job in bin 1 ]=/integraldisplay∞ −∞tfX|Y(t)dt =/integraldisplay500 0t1 1000e−t 1000 1−e−1 2dt≈229 Question: Why is the expected size of jobs in bin 1 less than 250? Answer: Consider the shape of the Exponential p.d.f. Now truncate it at 500, and scale everything by a constant needed to make it integrate to 1. There is still more weight onthe smaller values, so the expected value is less than the midpoint. Question: How would the answer to question (d) change if the job durations were distributed Uniform (0,2000) , still with mean 1,000? Answer: Logically, given that the job is in bin 1 and the distribution is uniform, we should ﬁnd that the expected job duration is 250 hours. Here is an algebraic argument: E[Job duration |job in bin 1 ]=/integraldisplay∞ −∞tfX|Y(t)dt=/integraldisplay500 0t1 2000 500 2000dt= 250",6477
3.13 Linearity of Expectation,"3.12 probabilities and expectations via conditioning 53 3.12 Probabilities and Expectations via Conditioning Recall from the Law of Total Probability that, if F1,...,F npartition the sample space Ω, then P{E}=n/summationdisplay i=1P{E|Fi}P{Fi}. This extends to random variables, because “ X=k” is an event. TheLaw of Total Probability for Discrete Random Variables says P{X=k}=/summationdisplay yP{X=k|Y=y}P{Y=y} (A similar statement can be made for continuous random variables.) This is a huge tool. It allows us to break a problem into a number of simpler problems. The trick, as usual, is knowing what to condition on. Example: Which Exponential Happens First? DeriveP{X1<X 2}where X1⊥X2andX1∼Exp(λ1)andX2∼Exp(λ2). Question: What do you condition on? Answer: We choose to condition on the value of X2, where we use f2(·)to denote the p.d.f. for X2: P{X1<X 2}=/integraldisplay∞ −∞P{X1<X 2|X2=k}·f2(k)dk =/integraldisplay∞ 0P{X1<k}·λ2e−λ2kdk =/integraldisplay∞ 0/parenleftbig 1−e−λ1k/parenrightbig/parenleftbig λ2e−λ2k/parenrightbig dk =λ1 λ1+λ2 Theorem 3.25 For discrete random variables, E[X]=/summationdisplay yE[X|Y=y]P{Y=y}. Similarly for continuous random variables, E[X]=/integraldisplay E[X|Y=y]fY(y)dy. 54 probability review Proof We present the proof for the discrete case: E[X]=/summationdisplay xxP{X=x} =/summationdisplay xx/summationdisplay yP{X=x|Y=y}P{Y=y} =/summationdisplay x/summationdisplay yxP{X=x|Y=y}P{Y=y} =/summationdisplay y/summationdisplay xxP{X=x|Y=y}P{Y=y} =/summationdisplay yP{Y=y}/summationdisplay xxP{X=x|Y=y} =/summationdisplay yP{Y=y}E[X|Y=y] This proof generalizes to E[g(X)] =/summationdisplay yE[g(X)|Y=y]P{Y=y}, which is very important when we need to compute the variance of Xor higher moments. Example: Geometric Suppose we want to use conditioning to easily compute the mean of the Geometric distribution with parameter p. That is, we seek E[N], where Nis the number of ﬂips required to get the ﬁrst head. Question: What do we condition on? Answer: We condition on the value of the ﬁrst ﬂip, Y, as follows: E[N]=E[N|Y=1 ]P{Y=1}+E[N|Y=0 ]P{Y=0} =1p+( 1+ E[N])(1−p) pE[N]=p+( 1−p) E[N]=1 p Note how much simpler this derivation is than our original derivation of the mean of a Geometric. 3.13 Linearity of Expectation The following is one of the most powerful theorems of probability. 3.13 linearity of expectation 55 Theorem 3.26 (Linearity of Expectation) For random variables XandY, E[X+Y]=E[X]+E[Y]. Question: Does Theorem 3.26 require X⊥Y? Answer: No. Recall that we doneed independence for simplifying E[XY], but not forE[X+Y]. Proof Here is a proof in the case where XandYare continuous. The discrete case is similar: Just replace fX,Y(x, y)withpX,Y(x, y). E[X+Y] =/integraldisplay∞ y=−∞/integraldisplay∞ x=−∞(x+y)fX,Y(x, y)dxdy =/integraldisplay∞ y=−∞/integraldisplay∞ x=−∞xfX,Y(x, y)dxdy+/integraldisplay∞ y=−∞/integraldisplay∞ x=−∞yfX,Y(x, y)dxdy =/integraldisplay∞ x=−∞/integraldisplay∞ y=−∞xfX,Y(x, y)dydx+/integraldisplay∞ y=−∞/integraldisplay∞ x=−∞yfX,Y(x, y)dxdy =/integraldisplay∞ x=−∞x/integraldisplay∞ y=−∞fX,Y(x, y)dydx+/integraldisplay∞ y=−∞y/integraldisplay∞ x=−∞fX,Y(x, y)dxdy =/integraldisplay∞ x=−∞xfX(x)dx+/integraldisplay∞ y=−∞yfY(y)dy =E[X]+E[Y] This identity can simplify many proofs. Consider the following example: Example: Binomial X∼Binomial (n,p). What is E[X]? Question: If we simply use the deﬁnition of the Binomial, what expression do we have forE[X]? Answer: E[X]=/summationtextn i=0i/parenleftbign i/parenrightbig pi(1−p)n−i. This expression appears daunting. Question: Can we think of Binomial (n,p)as a sum of random variables? Answer: Let X=number of successes in ntrials=X1+X2+···+Xn 56 probability review where Xi=/braceleftbigg 1if trial iis successful 0otherwise E[Xi]=p. Then E[X]=E[X1]+E[X2]+···+E[Xn]=nE[Xi]=np. This result should make sense, because ncoin ﬂips, each with probability pof coming up heads, should result in an average of npheads. TheXi’s above are called indicator random variables because they take on values 0or1. In the previous example, the Xi’s were i.i.d. (independent and identically distributed). However, even if the trials were not independent, we would have E[X]=E[X1]+···+E[Xn]. The following example makes this clear. Example: Hats At a party, npeople throw their hats into the middle of a circle. Each closes his or her eyes and picks a random hat. Let Xdenote the number of people who get back their own hat. Our goal is to determine E[X]. Question: How can we express Xas a sum of indicator random variables? Answer: X=I1+I2+···+In, where Ii=/braceleftbigg 1if theith person gets their own hat 0otherwise. Observe that although the Ii’s have the same distribution (by symmetry), they are not independent of each other. Nevertheless, we can still use Linearity of Expectation tosay E[X]=E[I1]+E[I2]+···+E[In] =nE[Ii] =n/parenleftbigg1 n·1+n−1 n·0/parenrightbigg =1. Observe that Linearity of Expectation can also be used to show that E/bracketleftbig X2+Y2/bracketrightbig =E/bracketleftbig X2/bracketrightbig +E/bracketleftbig Y2/bracketrightbig . Nonetheless this does not imply that Linearity of Expectation holds for variance. For that, we require an independence assumption, as in the following theorem. Theorem 3.27 LetXandYbe random variables where X⊥Y. Then Var(X+Y)=Var(X)+Var(Y).",5311
3.14 Normal Distribution,"3.14 normal distribution 57 Proof Var(X+Y)=E/bracketleftBig (X+Y)2/bracketrightBig −(E[(X+Y)])2 =E/bracketleftbig X2/bracketrightbig +E/bracketleftbig Y2/bracketrightbig +2E[XY] −(E[X])2−(E[Y])2−2E[X]E[Y] =Var(X)+Var(Y) +2E[XY]−2E[X]E[Y]/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright equals 0 if X ⊥Y 3.14 Normal Distribution A very important and ubiquitous continuous distribution is the Normal distribution. Deﬁnition 3.28 A continuous r.v. Xis said to be Normal (μ,σ2)o r Gaussian (μ, σ2) if it has p.d.f. fX(x)of the form fX(x)=1√ 2πσe−1 2(x−μ σ)2 ,−∞<x<∞ where σ>0. The parameter μis called the mean , and the parameter σis called the standard deviation . Deﬁnition 3.29 AN o r m a l (0,1)r.v.Yis said to be a standard Normal . Its c.d.f. is denoted by Φ(y)=FY(y)=P{Y≤y}=1√ 2π/integraldisplayy −∞e−t2/2dt. The Normal (μ, σ2)p.d.f. has a “bell” shape and is clearly symmetric around μ,a s shown in Figure 3.11. The fact that fX(x)in Deﬁnition 3.28 is actually a density function can be seen by integrating it via a change into polar coordinates (trust me, you do not want to see the gory details [ 176]). 2π1 -1 1 2 3fX(x) x Figure 3.11. Normal (1,1)p.d.f. 58 probability review Theorem 3.30 LetX∼Normal (μ, σ2), thenE[X]=μandVar(X)=σ2. Proof Because fX(x)is symmetric around μ, it is obvious that E[X]=μ. Var(X)=/integraldisplay∞ −∞(x−μ)2fX(x)dx =1√ 2πσ/integraldisplay∞ −∞(x−μ)2e−1 2((x−μ)/σ)2dx =σ2 √ 2π/integraldisplay∞ −∞y2e−y2/2dy by change of variables y=(x−μ)/σand dx=σdy =σ2 √ 2π/integraldisplay∞ −∞y·/parenleftBig ye−y2/2/parenrightBig dy =σ2 √ 2π/parenleftBig −ye−y2/2/parenrightBig/bracketrightBig∞ −∞+σ2 √ 2π/integraldisplay∞ −∞e−y2/2dy by integration by parts =σ2 √ 2π/integraldisplay∞ −∞e−y2/2dy =σ2 The last line was obtained by using the fact that 1√ 2π/integraldisplay∞ −∞e−y2/2dy=1 because the integrand is the density function of the standard Normal. 3.14.1 Linear Transformation Property The Normal distribution has a very particular property known as the “Linear Transfor- mation Property,” which says that if Xis a Normal r.v., and you take a linear function ofX, then that new r.v. will also be distributed as a Normal. Note that this property is nottrue for other distributions that we have seen, such as the Exponential. Theorem 3.31 (Linear Transformation Property) LetX∼Normal (μ, σ2).L e t Y=aX+b, where a>0andbare scalars. Then Y∼Normal (aμ+b, a2σ2). Proof It is easy to show that E[Y]=aE[X]+b=aμ+band Var(Y)= a2Var(X)=a2σ2. All that remains is to show that fY(y)is Normally distributed. We relate the c.d.f. of Yto the c.d.f. of Xas follows: FY(y)=P{Y≤y}=P{aX+b≤y}=P/braceleftbigg X≤y−b a/bracerightbigg =FX/parenleftbiggy−b a/parenrightbigg 3.14 normal distribution 59 We now differentiate both sides with respect to y: d dyFY(y)=d dy/integraldisplayy −∞fY(t)dt=fY(y) d dyFX/parenleftbiggy−b a/parenrightbigg =d dy/integraldisplayy−b a −∞fX(t)dt=fX/parenleftbiggy−b a/parenrightbigg ·d dy/parenleftbiggy−b a/parenrightbigg =fX/parenleftbiggy−b a/parenrightbigg ·1 a Thus we have shown that fY(y)=1 afX/parenleftbiggy−b a/parenrightbigg . Evaluating this, we have fY(y)=1 afX/parenleftbiggy−b a/parenrightbigg =1 a√ 2πσe−(y−b a−μ)2/2σ2 =1√ 2π(aσ)e−(y−b−aμ)2/2a2σ2 =1√ 2π(aσ)e−(y−(b+aμ))2/2a2σ2. SofY(y)is a Normal p.d.f. with mean aμ+band variance a2σ2. Unfortunately, we do not know how to integrate the density of the Normal from 0toy symbolically. To compute the c.d.f. of a Normal distribution, we must therefore use a table of numerically integrated results for Φ(y), such as that given in [ 200].1A subset of the table is given next for reference: y 0.5 1.0 1.5 2.0 2.5 3.0 Φ(y)0.6915 0.8413 0.9332 0.9772 0.9938 0.9987 Question: Looking at the table you see, for example, that Φ(1) = 0 .8413 . What does this tell us about the probability that the standard Normal is within one standard deviation of its mean? 1In practice no one ever goes to the table anymore, because there are approximations that allow you to compute the values in the table to within seven decimal places; see for example [ 131]. 60 probability review Answer: We are given that P{Y<1}=0.84. We want to know P{−1<Y < 1}. P{−1<Y < 1}=P{Y<1}−P{Y<−1} =P{Y<1}−P{Y>1}(by symmetry) =P{Y<1}−(1−P{Y<1}) =2P{Y<1}−1 = 2Φ(1)−1 .=2·0.84−1 =0.68 So with probability 68 percent, we are within one standard deviation of the mean. Likewise, we can use the same argument to show that with probability 95 percent, we are within two standard deviations of the mean, and with probability 99.7 percent, we are withinthree standard deviations of the mean, etc. Question: The previous results were expressed for a standard Normal. What if we do not have a standard Normal? Answer: We can convert a non-standard Normal into a standard Normal using the Linear Transformation Property. Here is how it works: X∼Normal (μ, σ2)⇐⇒Y=X−μ σ∼Normal (0,1) So P{X<k}=P/braceleftbiggX−μ σ<k−μ σ/bracerightbigg =P/braceleftbigg Y<k−μ σ/bracerightbigg =Φ/parenleftbiggk−μ σ/parenrightbigg . Theorem 3.32 IfX∼Normal (μ, σ2), then the probability that Xdeviates from its mean by less than kstandard deviations is the same as the probability that the standard Normal deviates from its mean by less than k. Proof LetY∼Normal (0,1). Then, P{−kσ < X−μ<k σ}=P/braceleftbigg −k<X−μ σ<k/bracerightbigg =P{−k<Y <k} Theorem 3.32 illustrates why it is often easier to think in terms of standard deviations than in absolute values. Question: Proponents of IQ testing will tell you that human intelligence (IQ) has been shown to be Normally distributed with mean 100 and standard deviation 15. Whatfraction of people have an IQ greater than 130 (“the gifted cutoff”)? Answer: We are looking for the fraction of people whose IQ is more than two standard deviations above the mean. This is the same as the probability that the standard Normal 3.14 normal distribution 61 exceeds its mean by more than two standard deviations, which is 1−Φ(2) = 0 .023. Thus only about 2 percent of people have an IQ above 130. 3.14.2 Central Limit Theorem Consider sampling the heights of all the individuals in the state and taking that average. The Central Limit Theorem (CLT), which we deﬁne soon, says that this average willtend to be Normally distributed. This would be true even if we took the average of a large number of i.i.d. random variables, where the random variables come from a distribution that is decidedly non-Normal, say a Uniform distribution. It is this propertythat makes the Normal distribution so important. We now state this more formally. Let X1,X2,X3,...,X nbe independent and identi- cally distributed r.v.’s with some mean μand variance σ2. Note: We are notassuming that these are Normally distributed r.v.’s. In fact we are not even assuming that they are necessarily continuous r.v.’s – they may be discrete r.v.’s. Let Sn=X1+X2+···+Xn. (3.2) Question: What are the mean and standard deviation of Sn? Answer: E[Sn]=nμandVar(Sn)=nσ2. Thus the standard deviation is σ√n. Let Zn=Sn−nμ σ√n. Question: What are the mean and standard deviation of Zn? Answer: Znhas mean 0and standard deviation 1. Theorem 3.33 (Central Limit Theorem (CLT)) LetX1,X2,...,X nbe a se- quence of i.i.d. r.v. ’s with common mean μand variance σ2, and deﬁne Zn=X1+···+Xn−nμ σ√n. Then the c.d.f. of Znconverges to the standard normal c.d.f.; that is, lim n→∞P{Zn≤z}=Φ (z)=1√ 2π/integraldisplayz −∞e−x2/2dx for every z. Proof Our proof makes use of transforms, so we defer the proof of CLT to Chap- ter25, Exercise 25.15 .",7486
3.15 Sum of a Random Number of Random Variables,"62 probability review Question: What is the distribution of Snin (3.2)? Answer: By the Linear Transformation Property, Sn∼Normal (nμ, nσ2). The Central Limit Theorem is extremely general and explains many natural phenomena that result in Normal distributions. The fact that CLT applies to any sum of i.i.d. r.v.’s allows us to prove that the Binomial (n,p)distribution, which is a sum of i.i.d. Bernoulli (p)r.v.’s, converges to a Normal distribution when nis high. When we study the Poisson distribution in more depth in Chapter 11, we will see that the Poisson (λ) distribution can also be viewed as a sum of i.i.d. r.v.’s; hence the Poisson (λ)distribution is also well approximated by a Normal distribution with mean λand variance λ. We now illustrate the use of the Normal distribution in approximating the distribution of a complicated sum. Example: Normal Approximation of a Sum Imagine that we are trying to transmit a signal. During the transmission, there are a hundred sources independently making low noise. Each source produces an amount ofnoise that is Uniformly distributed between a=−1andb=1. If the total amount of noise is greater than 10or less than −10, then it corrupts the signal. However, if the absolute value of the total amount of noise is under 10, then it is not a problem. Question: What is the approximate probability that the absolute value of the total amount of noise from the 100 signals is less than 10? Answer: LetXibe the noise from source i. Observe that μXi=0. Observe that σ2 Xi=(b−a)2 12=1 3andσXi=1√ 3. LetS100=X1+X2+···+X100. P{−10<S 100<10}=P/braceleftBigg −10/radicalbig 100/3<S100−0/radicalbig 100/3<10/radicalbig 100/3/bracerightBigg ≈2Φ/parenleftbigg10√ 33.33/parenrightbigg −1 =2 ( 0.9572)−1 =0.9144 Hence the approximate probability of the signal getting corrupted is less than 10 percent. In practice, this approximation is excellent. 3.15 Sum of a Random Number of Random Variables In many applications one often needs to add up a number of i.i.d. random variables,where the number of these variables is itself a random variable. Speciﬁcally, we are talking about the quantity Sin the following expression. Let X1,X2,X3,... be i.i.d. random variables. Let S=N/summationdisplay i=1Xi,N⊥Xi where Nis a non-negative, integer-valued random variable. 3.15 sum of a random number of random variables 63 We now review how to derive quantities like E[S]andE[S2], which we will need throughout the book. Question: Why can’t we directly apply Linearity of Expectation? Answer: Linearity equations only apply when Nis a constant. Question: Does this give you any ideas? Answer: Let’s condition on the value of N, and then apply Linearity of Expectation. E[S]=E/bracketleftBiggN/summationdisplay i=1Xi/bracketrightBigg =/summationdisplay nE/bracketleftBiggN/summationdisplay i=1Xi/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleN=n/bracketrightBigg ·P{N=n} =/summationdisplay nE/bracketleftBiggn/summationdisplay i=1Xi/bracketrightBigg ·P{N=n} =/summationdisplay nnE[X]·P{N=n} =E[X]·E[N] (3.3) Question: Can we use the same trick to get E[S2]? Answer: The difﬁculty with conditioning on Nis that we end up with a big sum that we need to square, and it is not obvious how to do that. Consider the following: E/bracketleftbig S2/bracketrightbig =/summationdisplay nE/bracketleftbig S2|N=n/bracketrightbig ·P{N=n} =/summationdisplay nE⎡ ⎣/parenleftBiggn/summationdisplay i=1Xi/parenrightBigg2⎤⎦·P{N=n} A better idea is to ﬁrst derive Var(S|N=n)and then use that to get E[S2|N=n]. Observe that, by Theorem 3.27, Var(S|N=n)=nVar(X). Observe also that nVar(X)=Var(S|N=n)=E/bracketleftbig S2|N=n/bracketrightbig −(E[S|N=n])2 =E/bracketleftbig S2|N=n/bracketrightbig −(nE[X])2. From the previous expression, we have that E/bracketleftbig S2|N=n/bracketrightbig =nVar(X)+n2(E[X])2.",3834
3.16 Exercises,"64 probability review It follows that E/bracketleftbig S2/bracketrightbig =/summationdisplay nE/bracketleftbig S2|N=n/bracketrightbig ·P{N=n} =/summationdisplay n/parenleftBig nVar(X)+n2(E[X])2/parenrightBig P{N=n} =E[N]Var(X)+E/bracketleftbig N2/bracketrightbig (E[X])2. Furthermore, Var(S)=E/bracketleftbig S2/bracketrightbig −(E[S])2 =E[N]Var(X)+E/bracketleftbig N2/bracketrightbig (E[X])2−(E[N]E[X])2 =E[N]Var(X)+Var(N)(E[X])2. We have proven Theorem 3.34: Theorem 3.34 LetX1,X2,X3,... be i.i.d. random variables. Let S=N/summationdisplay i=1Xi,N⊥Xi. Then E[S]=E[N]E[X], E/bracketleftbig S2/bracketrightbig =E[N]Var(X)+E/bracketleftbig N2/bracketrightbig (E[X])2, Var(S)=E[N]Var(X)+Var(N)(E[X])2. The variance trick was pretty cool. You may be wondering how we would get the third moment, E[S3], if we ever needed it, given that the variance trick will not work there. The answer is to use transform analysis (generating functions), which will easilyprovide any moment of S. This topic is covered in Chapter 25. 3.16 Exercises 3.1 Expectation Brainteaser A friend told me that during his ﬁrst year in school he was never in a classwith less than 90 students. He said that almost all of his friends had the same experience. The dean, however, insists that the mean freshman class size is 30 students. How can this be? Explain with a simple numerical example what isgoing on. 3.2 Nerdy Ned Nerdy Ned asks out a new girl every day. With probability 1 100the girl says “yes,” and with probability99 100the girl says “no.” What is the probability that it takes Ned more than 100 days to get a girlfriend? 3.3 Variance Use Linearity of Expectation to prove that Var(X)=E[X2]−E[X]2. 3.16 exercises 65 3.4 Chain Rule for Conditioning LetE1,E2,...,E nbenevents, each with positive probability. Prove that P/braceleftBiggn/intersectiondisplay i=1Ei/bracerightBigg =P{E1}·P{E2|E1}·P{E3|E1∩E2}···P/braceleftBigg En|n−1/intersectiondisplay i=1Ei/bracerightBigg . 3.5 Assessing Risk Queueville Airlines knows that on average 5 percent of the people making ﬂight reservations do not show up. (They model this information by assuming that each person independently does not show up with probability of 5 percent.) Consequently, their policy is to sell 52 tickets for a ﬂight that can only hold 50 passengers.What is the probability that there will be a seat available for every passengerwho shows up? 3.6 Practice with Conditional Expectation For the joint p.m.f. in Table 3.3, compute E[X|Y/negationslash=1 ] . 3.7 How Does Variance Scale? Consider the following two random variables: X=⎧ ⎪⎨ ⎪⎩3w/prob1 3 2w/prob1 3 1w/prob1 3Y=⎧ ⎪⎨ ⎪⎩30 w/prob1 3 20 w/prob1 3 10 w/prob1 3 (a)Yis a scaled version of X.D oXandYhave the same variance? (b) Intuitively, if we think of Xas representing measurements in seconds, and Yas representing measurements in tenths of seconds, then we would like to feel that XandYhave the same variance. A common metric in computer systems is the squared coefﬁcient of variation, where the squared coefﬁcient of variation of Xis written as C2 Xand is deﬁned as C2 X=Var(X) E[X]2. This can be viewed as a normalized variance.",3135
3.16 Exercises,"How do C2 XandC2 Ycompare? 3.8 Understanding Variance and Risk Letcbe an integer where c>1. We are given cindependent instances of the r.v.X: call these X1,X2,...,X c. (a) Which has lower variance: Var(X1+X2+···+Xc)orVar(cX)?C o m - pute each of these. (b) The selling point of mutual funds is that they are less risky than buying a single stock. Explain this statement. 3.9 Identities LetAandBbe independent random variables. Prove or disprove the following statement: E[A/B]=E[A]/E[B] 3.10 Expectation of Product Prove or disprove the following claim: If E[XY]=E[X]·E[Y], thenXandYare independent r.v.’s. 66 probability review 3.11 Variance of the Binomial LetX∼Binomial (n,p). Use Theorem 3.27 to easily derive Var(X). 3.12 Poisson Approximation to Binomial Prove that the Binomial (n,p)distribution is well approximated by the Poisson (np)distribution when nis large and pis small. [Hint: Start with the probability mass function for the Binomial (n,p)distribution. Set p=λ/n. Expand out all the terms. Take limits and show you get a Poisson (λ)distribution, where λ=np.] 3.13 Probability Bounds You are told that the average ﬁle size in a database is 6K. (a) Explain why it follows (from the deﬁnition of expectation) that fewer than half of the ﬁles can have size >12K. (b) You are now given the additional information that the minimum ﬁle size is 3K. Derive a tighter upper bound on the percentage of ﬁles that have size >12K. 3.14 Quality of Service A company pays a ﬁne if the time to process a request exceeds 7 seconds. Processing a request consists of two tasks: (a) retrieving the ﬁle – which takessome time Xthat is Exponentially distributed with mean 5, and (b) parsing the ﬁle – which takes some time Ythat is independent of Xand is distributed Uniform (1,3), with mean 2. Given that the mean time to process a request is clearly 7seconds, the company views the ﬁne as unfair, because it will have to pay the ﬁne on half its requests. Is this right? What is the actual fraction of time that the ﬁne will have to be paid, and how much does this differ from 1/2? 3.15 Positive Correlation We say that events AandBarepositively correlated if P{A|B}>P{A}. (3.4) Prove or disprove that ( 3.4) implies P{B|A}>P{B}. (3.5) 3.16 Covariance Thecovariance of any two random variables XandY, denoted by cov (X,Y), is deﬁned by cov(X,Y)=E[(X−E[X])(Y−E[Y])]. (a) Prove that cov (X,Y)=E[XY]−E[X]E[Y]. (b) IfX⊥Y, what can we say about cov (X,Y)? (c) Let XandYbe indicator random variables, where X=/braceleftbigg 1if event Aoccurs 0o.w. 3.16 exercises 67 and Y=/braceleftbigg 1if event Boccurs 0o.w.. Prove that if events AandBare positively correlated (see Exercise 3.15), then cov (X,Y)>0, whereas if AandBare negatively correlated, then cov(X,Y)<0.Note: This notion can be extended to general random variables XandY, not just indicator random variables. 3.17 Normal Approximation Bill Gater invites 1,000 friends to a dinner. Each is asked to make a contribution. The contributions are i.i.d. Poisson-distributed random variables with mean $1,000 each.",3055
3.16 Exercises,"Bill hopes to raise $1,000,000. Your job is to compute the probability that Bill raises <$999,000. (a) Compute this using the Normal approximation from this chapter. (b) Now write an exact expression for this probability, and then use your calcu- lator or a small program to evaluate the expression. 3.18 Joint Distributions Your TAs, Eric and Timmy, have agreed to meet between 2 and 3 pm to design the next homework. They are rather busy and are not quite sure when they canarrive, so assume that each of their arrival times is independent and uniformly distributed over the hour. Each agrees to wait 15 minutes for the other TA, afterwhich he will leave. What is the probability that Eric and Timmy will be ableto meet? 3.19 Bayesian Reasoning for Weather Prediction In the hope of having a dry outdoor wedding, John and Mary decide to getmarried in the desert, where the average number of rainy days per year is 10. Unfortunately, the weather forecaster is predicting rain for tomorrow, the day of John and Mary’s wedding. Suppose that the weather forecaster is not perfectly accurate: If it rains the next day, 90 percent of the time the forecaster predicts rain. If it is dry the next day, 10 percent of the time the forecaster still (incorrectly) predicts rain. Given this information, what is the probability that it will rain during John and Mary’s wedding? 3.20 Bayesian Reasoning for Health Care Testing A pharmaceutical company has developed a potential vaccine against the H1N1 ﬂu virus. Before any testing of the vaccine, the developers assume that with probability 0.5their vaccine will be effective and with probability 0.5it will be ineffective. The developers do an initial laboratory test on the vaccine. This initial lab test is only partially indicative of the effectiveness of the vaccine, with an accuracy of 0.6. Speciﬁcally, if the vaccine is effective, then this labo- ratory test will return “success” with probability 0.6, whereas if the vaccine is ineffective, then this laboratory test will return “failure” with probability 0.6. (a) What is the probability that the laboratory test returns “success”? (b) What is the probability that the vaccine is effective, given that the laboratory test returned “success”? 68 probability review (c) The developers decide to add a second experiment (this one on human beings) that is more indicative than the original lab test and has an accuracy of0.8. Speciﬁcally, if the vaccine is effective, then the human being test will return “success” with probability 0.8. If the vaccine is ineffective, then the human being test will return “failure” with probability 0.8. What is the probability that the vaccine is effective, given that both the lab test andthe human being test came up “success”? How useful was it to add this additional test? Assume that the two tests (human test and lab test) are conditionally independent on the vaccine being effective or ineffective. 3.21 Dating Costs: Deriving Expectation and Variance via Conditioning A man, in search of a wife, tries two approaches: generous and cheapskate. When the man tries the generous approach, he ends up spending $1,000 on his date, who will, eventually, with probability 0.95break up with him, but with probability 0.05marry him. When the man tries the cheapskate approach, he spends $50 on his date, who will eventually break up with him.",3372
3.16 Exercises,"So far in his life, the man has only experienced failure, so he cannot tell which approach works better. He therefore decides to choose an approach (generous or cheapskate) at random.(a) Assuming the man starts searching today, what is his expected cost to ﬁnd a wife? (b) Compute the variance on the amount of money the man ends up spending to ﬁnd a wife. 3.22 Variance of the Geometric Let X∼Geometric (p). Prove that Var(X)=1−p p2. [Hint: Use conditioning.] 3.23 Good Chips versus Lemons A chip supplier produces 95 percent good chips and 5 percent lemons. The good chips failwith probability 0.0001 each day. The lemons fail with probability 0.01each day. You buy a random chip. Let Tbe the time until your chip fails. Compute E[T]andVar(T). 3.24 Alternative Deﬁnition of Expectation2 (a) Let X: non-negative, discrete, integer-valued random variable. Prove E[X]=∞/summationdisplay x=0P{X>x} (b) Let X: non-negative, continuous random variable. Prove E[X]=/integraldisplay∞ x=0P{X>x}dx (c) Let X: non-negative, continuous random variable. Does this quantity have a nicer name?/integraldisplay∞ x=0xP{X>x}dx 2Warning: The result of this exercise will be invoked throughout the book. 3.16 exercises 69 3.25 Expectation via Conditioning Stacy’s fault-tolerant system only crashes if there are k=1 0 consecutive fail- ures. If every minute a failure occurs independently with probability p=1 10, what is the expected number of minutes until Stacy’s system crashes. (Expressgenerally in terms of kandp.) [Hint: Write a recurrence relation.] 3.26 Napster – Brought to You by the RIAA As a present for my brother, I decided to create a collection of all the songsfrom his favorite band. I needed to download the band’s 50 songs. Unfortunately, whenever I typed in the band name, I was sent a random song from the band. Let Ddenote the number of downloads required to get all 50 songs. (a) What is E[D]? Give a closed-form approximation. (b) What is Var(D)? (No need for closed-form here.) 3.27 Fractional Moments Given the ugliness of the Normal distribution, I am happy to say that it nevercomes up in my research . . . until a few days ago. Here’s the story: I had a random variable X∼Exp(1)and I needed to compute E/bracketleftbig X1 2/bracketrightbig . Figure out why I needed a Normal distribution to do this and what answer I ﬁnally got.Here are some hints: Start by applying integration by parts. Then make theright change of variables. If you do it right, the standard Normal should popout. Remember that the Exponential ranges from 0 to ∞, whereas the Normal ranges from −∞ to∞.",2584
Chapter 4 Generating Random Variables for Simulation. 4.1 Inverse-Transform Method,"CHAPTER 4 Generating Random Variables for Simulation In Chapter 3we reviewed the most common discrete and continuous random variables. This chapter shows how we can use the density function or cumulative distribution function for a distribution to generate instances of that distribution. For example, wemight have a system in which the interarrival times of jobs are well modeled by anExponential distribution and the job sizes (service requirements) are well modeled by a Normal distribution. To simulate the system, we need to be able to generateinstances of Exponential and Normal random variables. This chapter reviews the twobasic methods used in generating random variables. Both these methods assume thatwe already have a generator of Uniform(0,1) random variables, as is provided by mostoperating systems. 1,2 4.1 Inverse-Transform Method This method assumes that (i) we know the c.d.f. (cumulative distribution function), FX(x)=P{X≤x}, of the random variable Xthat we are trying to generate, and (ii) that this distribution is easily invertible, namely that we can get xfromFX(x). 4.1.1 The Continuous Case Idea: We would like to map each instance of a uniform r.v. generated by our operating system – that is, u∈U(0,1)–t os o m e x, which is an instance of the random variable X, where Xhas c.d.f. FX. We assume WLOG that Xranges from 0to∞. Let’s suppose there is some mapping that takes each uand assigns it a unique x. Such a mapping is illustrated by g−1(·)in Figure 4.1. Question: Can you ﬁgure out what the mapping g−1(·)in Figure 4.1should be? Hint: Think about what property we want for our output. What should be the probability of outputting a value between 0andx? Answer: A value in (0,x)should be output with probability FX(x). Question: What is the actual probability that g−1(·)outputs a value in (0,x)? 1Actually, most operating systems provide a random integer between 1 and N=232−1. This is easy to convert into a Uniform(0,1) by just dividing by N. 2One cannot always trust the random number generator provided by one’s operating system. It is worth reading the literature to understand how to best “seed” the random number generator and what guarantees it provides.See for example, [ 31]. 70 4.1inverse-transform method 71 XgU(0,1) 01 u x Figure 4.1. Illustration of mapping g(·). Answer: Because g−1(·)only maps values in (0,u)to values in (0,x), the probability of outputting a value in (0,x)is the probability that the uniform instance is in (0,u). Question: And what is the probability that the uniform instance is in (0,u)? Answer: u. So we want that u=P{0<U<u}=P{0<X<x}=FX(x). That is, we want u=FX(x)or equivalently x=F−1 X(u). (4.1) Question: So what was the g(·)function in Figure 4.1? Answer: g(·)=F(·), the cumulative distribution function. Inverse-Transform Method to generate r.v. X : 1.Generate u∈U(0,1). 2.Return X=F−1 X(u). Example: Generate X∼Exp(λ) For the Exp (λ)distribution, F(x)=1−e−λx. So by ( 4.1) we want x=F−1(u) =⇒F(x)=u =⇒1−e−λx=u =⇒−λx= ln(1−u) =⇒x=−1 λln(1−u). Given u∈U(0,1), setting x=−1 λln(1−u)produces an instance of X∼Exp(λ).",3090
4.2 Accept-Reject Method,"72 generating random variables for simulation 4.1.2 The Discrete Case The discrete case follows the same basic idea as the continuous case (see Figure 4.2). This time, we want to generate a discrete r.v. Xsuch that X=⎧ ⎪⎪⎨ ⎪⎪⎩x0with prob p0 x1with prob p1 ... xkwith prob pk. U(0,1) 0X1 x0x1 x2 x3p0p1p2p3 Figure 4.2. Generating a discrete random variable with 4 values. Solution: 1.Arrange x0,...,x ks.t.x0<x 1<...<x k. 2.Generate u∈U(0,1). 3.If0<u≤p0, then output x0. Ifp0<u≤p0+p1, then output x1. Ifp0+p1<u≤p0+p1+p2, then output x2. If/summationtext/lscript−1 i=0pi<u≤/summationtext/lscript i=0pi, then output x/lscript, where 0≤/lscript≤k. Notice that again our g(·)function is FX(·), the cumulative distribution function. This sounds easy enough, but it is not always practical. If Xcan take on many values, then we have to compute many partial sums:/summationtext/lscript i=0pifor all 0≤/lscript≤k. For this method to be practical, we therefore need closed-form expressions for/summationtext/lscripti=0pifor all /lscript. Equivalently, we need a closed form for FX(x)=P{X≤x}for any x. Then we could do the same thing as in the continuous case, as in ( 4.1): generate u∈U(0,1), and return x=F−1 X(u). Thus, as in the continuous case, we need to both have a closed-form expression for the cumulative distribution function and also know how to invert this function. 4.2 Accept-Reject Method The Inverse-Transform method required knowing the cumulative distribution function, FX(·). However, there are many cases where we do not know the c.d.f., FX(·), but only know the p.d.f., fX(·). For example, suppose we want to generate a random variable from the Normal distribution, whose c.d.f. is not known. We thus need a new method. 4.2accept-reject method 73 The Accept-Reject method involves generating instances of the desired random vari- able, but throwing away (rejecting) some of the generated instances until the desiredp.d.f (or p.m.f.) is met. It is easiest to explain the method for the case of a discrete r.v.ﬁrst. 4.2.1 Discrete Case The Accept-Reject method requires the following structure: Given : Efﬁcient method for generating random variable Qwith probability mass function{qj,j:discrete}, where qj=P{Q=j}. Output : Random variable Pwith probability mass function {pj,j:discrete}, where pj=P{P=j}. Requirement : For all j, we must have qj>0⇐⇒pj>0. That is, PandQtake on the same set of values. Example: Suppose we want to generate P=⎧ ⎨ ⎩1with prob p1=0.36 2with prob p2=0.24 3with prob p3=0.40. We know how to generate Q=⎧ ⎨ ⎩1with prob q1=0.33 2with prob q2=0.33 3with prob q3=0.33. Any ideas? We are looking for a method where we generate an instance of Q, and then we either choose to accept the value or reject it. If we accept it, that becomes the valueof P. Idea #1: Suppose we generate an instance jofQand accept it with probability pj? Question: What are the disadvantages to this approach? Answer: The obvious disadvantage is the time needed to output a value of P. Suppose the number of possible values is n, andnis high. Then qj=1 n, and most pj’s will be very low – certainly it could be the case that all pj’s are approximately1 nbut not exactly. In this case, the time needed to output a value is on the order of n. Another disadvantage of Idea #1 is that in general Qmay not have a uniform distribu- tion, so we need to normalize the acceptance probabilities. Idea #2: Suppose we generate an instance jof Q and accept it with probabilitypj qj? That is, with probabilitypj qj, we return P=j, and with probability 1−pj qj,w eﬂ i p again. 74 generating random variables for simulation Question: What is the intuition behind Idea #2? Answer: Suppose Qis not uniform, and Qhas an especially low probability of generating j. Then we will make up for that by having a higher than pjprobability of accepting jwhen it is generated. Question: What is wrong with Idea #2? Answer: It requires that pj≤qj,∀j, which cannot be true if P/negationslash=Q. But we can work with Idea #2. We just need a normalizing constant. Let cbe a constant such that pj qj≤c,∀js.t.pj>0. Observe c>1. Accept-Reject Algorithm to generate discrete r.v. P : 1.Find r.v. Qs.t.qj>0⇔pj>0. 2.Generate an instance of Q, and call it j. 3.Generate r.v. U∈(0,1). 4.IfU<pj cqj, return P=jand stop; else return to step 2. We will now prove that the Accept-Reject algorithm does in fact result in a Pwith the appropriate distribution. We want to prove that P{Pends up being set to j(as opposed to some other value) }=pj. Now observe that P{Pends up being set to j}=Fraction of time jis generated and accepted Fraction of time any value is accepted. Fraction of time jis generated and accepted =P{jis generated }·P{jis accepted given jis generated } =qj·pj cqj=pj c. Fraction of time any value is accepted =/summationdisplay jFraction of time jis generated and is accepted =/summationdisplay jpj c=1 c. 4.2accept-reject method 75 So, P{Pends up being set to j}=pj c 1 c=pj as desired. Question: On average, how many values of Qare generated before one is accepted? Answer: c. (The fraction of time any value is accepted is1 c.) In our example, c=m a x/parenleftbigg0.36 0.33,0.24 0.33,0.40 0.33/parenrightbigg =1.2. Thus we only need 1.2iterations on average. 4.2.2 Continuous Case The Accept-Reject method works the same way for continuous random variables, except that we now use probability density functions, rather than probability mass functions. Given: We know how to generate Ywith probability density function fY(t). Goal: To generate Xwith p.d.f. fX(t). Requirement: For all t, fY(t)>0⇐⇒fX(t)>0. Accept-Reject Algorithm to generate continuous r.v. X: 1.Find continuous r.v. Ys.t.fY(t)>0⇔fX(t)>0. Letcbe a constant such that fX(t) fY(t)≤c,∀ts.t.fX(t)>0. 2.Generate an instance tofY. 3.With probabilityfX(t) c·fY(t), return X=t(i.e. “accept t” and stop). Else reject tand return to step 2. Simple Example Suppose we want to generate a r.v. Xwith p.d.f.: fX(t)=2 0 t(1−t)3,0<t< 1 If you plot this function, it looks like Figure 4.3. Observe that Xhas positive p.d.f. only in the interval (0,1). Thus we want to choose a Ythat is easy to generate and also has positive p.d.f. only in (0,1). 76 generating random variables for simulation t 00.511.522.5 0.2 0.4 0.6 0.8 1 Figure 4.3. Plot of fX(t). Question: Any ideas for what fY(t)should be? Answer: Consider simply fY(t)=1 , where 0<t< 1. Question: Suppose we now apply the Accept-Reject method. What will cbe? Answer: cshould not be too bad – just over 2 based on the plot. To determine c precisely, we want to determine max t/braceleftbiggfX(t) fY(t)/bracerightbigg =m a x t/braceleftbig 20t(1−t)3/bracerightbig . Taking the derivative with respect to t, and setting it equal to zero, we have d dt(20t(1−t)3)=0⇔t=1 4. So the maximum value is obtained when t=1 4: fX/parenleftbig1 4/parenrightbig fY/parenleftbig1 4/parenrightbig=2 0/parenleftbigg1 4/parenrightbigg/parenleftbigg3 4/parenrightbigg3 =135 64=c. (4.2) Observe how easy it was to make a good guess for fY(t)just by looking at the plot of fX(t). Example: Generating Normal Random Variable For the previous example we could have used the Inverse-Transform method. Now let’s try an example where we cannot apply the Inverse-Transform method. Goal: Generate N∼Normal (0,1). Idea: It will be enough to generate X=|N|and then multiply Nby−1with proba- bility0.5. So how do we generate such an X? A plot of Xis shown in Figure 4.4. LetfX(t)be the p.d.f of X: fX(t)=2√ 2πe−t2 2,0<t<∞ 4.2accept-reject method 77 00.20.40.60.81 2468 1 0fX(t) fY(t) t Figure 4.4. Solid line shows fX(t). Dashed line shows proposed fY(t). Question: The idea is now to think of a random variable Ythat we know how to generate, such that fY(t)(the p.d.f. of Y)ﬁ t sfX(t)reasonably well. Can you think of such a Y? Answer: LetY∼Exp(1). fY(t)=e−t,0<t<∞ Observe that fX(t)is not too much higher than fY(t), according to Figure 4.4. Question: How many iterations are needed on average? Answer: We need to determine c. fX(t) fY(t)=2√ 2πe−t2 2+t=/radicalbigg 2 πet−t2 2 So, the maximum value occurs when t−t2 2is maximized. 0=d dt/parenleftbigg t−t2 2/parenrightbigg =1−t⇒t=1 So, c=fX(1) fY(1)=/radicalbigg 2e π≈1.3. Thus we only need 1.3iterations on average. 4.2.3 Some Harder Problems Consider a Poisson r.v. with mean λ. pi=P{X=i}=e−λλi i. Observe that there are an inﬁnite number of pi’s. There is no closed form for F(i)= P{X≤i}so the Inverse-Transform method will not work. It looks like we should be able to apply the Accept-Reject method, but it is hard to ﬁnd the right distribution to match up to (for more discussion see [ 116], p. 503).",8618
4.3 Readings. Chapter 5 Sample Paths Convergence and Averages,"78 generating random variables for simulation In Chapter 11, we see that the Poisson distribution can be viewed as counting the number of instances of an Exponentially distributed random variable that occur by a ﬁxed time. This gives us another way of generating Poisson random variables – by generating many instances of an Exponential random variable. 4.3 Readings A lot more is known about simulating random variables than we have described in this chapter. Some particularly well-written texts are [ 148] (see Chs. 4 and 5) and [ 116] (see Ch. 8). 4.4 Exercises 4.1 Generating Random Variables for Simulation (from [ 148]). Give an algorithm for generating a r.v. having the following density function f(x) = 30( x2−2x3+x4),where 0≤x≤1. 4.2 Inverse-Transform Method Explain how to generate values from a continuous distribution with densityfunction f(t)=5 4t−2, where 1<t< 5,givenu∈U(0,1). 4.3 Simulation of M/M/1 This problem asks you to simulate a single M/M/1 queue. Do not worry; you do not need to know what this notation means – everything you need to know is explained in this problem. Use any programming language you like. The job sizes are distributed according to Exp (μ), where μ=1. The interarrival times between jobs are i.i.d. according to Exp (λ). Consider three cases: λ=0.5,λ=0.7, andλ=0.9. Your goal is to measure the mean response time E[T]for each load level (each value of λ). Do this by averaging independent samples. Let one “run” of the simulator consist of running the system from the empty state for 2,000 arrivals, and then record the response time experienced by ar- rival number 2,001. Perform n= 200 (independent) runs, each of which will generate one “sample,” and then determine the mean of the n= 200 samples.",1747
5.1 Convergence,"CHAPTER 5 Sample Paths, Convergence, and Averages If you are a theoretician, you probably are already starting to get uncomfortable with the way we use the word “average” without carefully deﬁning it and, in particular,with the way we deﬁne the load ρby seemingly dividing two averages ( ρ=1/μ 1/λ=λ μ). Everything we have said is correct, but we would like to prove this, rather than just assuming it. This chapter sets up the groundwork to allow us to make such claims about averages. Before we can talk about averages, we ﬁrst need to discuss convergence of random variables. In this chapter, we deﬁne the convergence of random variables and statesome limit theorems. We then deﬁne two types of averages: ensemble averages and time averages. These are needed for the next chapter on Little’s Law, which will allow us to formally relate mean response time to the mean number of jobs in the system and to properly deﬁne the load, ρ. This chapter is more theoretically oriented and abstract than the rest of this book. It is not necessary for the reader to follow everything in this chapter to understand laterchapters. A reader might wish to skim the chapter to pick up the basic terminology and then come back later for a more in-depth reading. Although this chapter is somewhat formal, we are still just grazing the surface of this material. If you really want to understand the concepts in depth, we recommend readinga measure-theory book such as Halmos’s book [ 80]. 5.1 Convergence Recall from high school the standard deﬁnition of convergence of a sequence of numbers: Deﬁnition 5.1 A sequence {an:n=1,2,...}converges to basn→∞ , written an−→b,asn→∞ or equivalently, lim n→∞an=b if∀/epsilon1>0,∃n0(/epsilon1), such that∀n>n 0(/epsilon1),w eh a v e|an−b|</epsilon1. 79 80 sample paths, convergence, and averages This is very easy to think about because the ai’s are constants. It says that a sequence converges to bif, for any given “degree of convergence,” /epsilon1, one can ﬁnd some index point in the sequence (call that point n0(/epsilon1)) such that, beyond that point, all elements of the sequence are within /epsilon1ofb. We now need a similar deﬁnition for random variables. The point to remember is that a random variable becomes a constant for each possible outcome of an experiment . We refer to the outcome of the experiment as a sample path . For example, consider a random variable, Z, equal to the larger of two rolls of a die. Given a particular sample path,ω=( 4,6), we know that the value of Zis exactly 6. As another example, consider a sequence of random variables: {Yn:n=1,2,...}, where Yndenotes the average of the ﬁrst ncoin ﬂips. Here again, these are all variables. Now consider a sample path ,ω, consisting of an inﬁnite sequence of coin ﬂips (e.g. ω= 01101001011 ...). If we evaluate the sequence of random variables on ω,w e have a sequence of constants: {Yn(ω):n=1,2,...}={0,1 2,2 3,1 2,3 5,...}. Deﬁnition 5.2 The sequence of random variables {Yn:n=1,2,...}converges almost surely toμ, written Yna.s.−→μ,asn→∞ or equivalently, the sequence converges with probability 1 , written Yn−→μ,asn→∞ w.p.1 if ∀k>0,P/braceleftBig lim n→∞|Yn−μ|>k/bracerightBig =0. TheP{...}in the previous expression is over the set of sample paths. More precisely we might write ∀k>0,P/braceleftBig ω: lim n→∞|Yn(ω)−μ|>k/bracerightBig =0 (although no one actually writes this). To understand Deﬁnition 5.2, consider the sequence of random variables, {Yn:n= 1,2,...}, evaluated on a particular sample path, ω0, yielding the sequence of constants, {Yn(ω0):n=1,2,...}. Now look at the limit of this sequence of constants and ask whether it deviates from μby more than k. We say that the sample path ω0behaves well if the sequence of constants, {Yn(ω0):n=1,2,...}, converges to μ(meaning it is within kofμfor all k>0asn→∞ ) and that it behaves badly otherwise. Likewise, the sample path ω1behaves well if the sequence of constants, {Yn(ω1):n=1,2,...}, converges to μ. Question: What does P{ω: lim n→∞|Yn(ω)−μ|>k}represent? 5.1convergence 81 Answer: This represents the mass (probability) of sample paths that behave badly in that, for each such bad sample path, ω, the limit of the sequence {Yn(ω):n=1,2,...} is notμor does not exist. Almost sure convergence occurs when, on almost all sample paths, the sequence of random variables will, after some point, start behaving well and continue behavingwell from that point on. That is, almost all sample paths ωhave the property that the sequence{Yn(ω):n=1,2,...}converges to μ. The mass comprising sample paths that do not have this property has probability zero – meaning, there may be some sample paths that do not have this property, but these paths have a total “mass” of zero. Figure 5.1shows an illustration of almost sure convergence. Y(ω2)Y(ω1) Y(ω3) Y(ω4)nµ Figure 5.1. Illustration of the concept of almost sure convergence. The dotted line indicates μ. Y(ω1)is shorthand for the sequence of constants: {Yn(ω1):n=1,2,...}. All four sample paths shown, after some point, behave well – meaning that the sequence of constants, created by evaluating {Yn:n=1,2,...}on that sample path, converges to μ. Question: In the case where Ynrepresents the average of the ﬁrst ncoin ﬂips, what do we expect the sequence {Yn(ω):n=1,2,...}to converge to? Answer: Assuming a fair coin,1 2. Question: Why can’t we say that this convergence holds for all sample paths? Answer: There are always some sample paths, such as the coin ﬂips 1111..., that do not average to1 2no matter how far out we look. Luckily the total measure made up by such sample paths is zero. Question: How many badly behaving sample paths are there? A ﬁnite number? Count- ably many? Uncountably many? Answer: Actually there are uncountably many such bad paths, each occurring with probability zero and summing to a measure of zero. Question: How can we determine that there are uncountably many bad paths? Answer: Let’s refer to the sequence 110 as a “red car” and to the sequence 101 as a “blue car.” Now any sequence made up of red and blue cars is clearly bad (because it has twice as many 1’s as 0’s). However, there are an uncountable number of possiblesequences of red and blue cars, because there are an uncountable number of binarysequences (by Cantor’s diagonalization argument). 82 sample paths, convergence, and averages We now present another deﬁnition of convergence of random variables that is sometimes used. Deﬁnition 5.3 The sequence of random variables {Yn:n=1,2,...}converges in probability toμ, written YnP−→μ,asn→∞ if ∀k>0,lim n→∞P{|Yn−μ|>k}=0. TheP{...}in Deﬁnition 5.3is over the set of possible sample paths, ω. More precisely we might write ∀k>0,lim n→∞P{ω:|Yn(ω)−μ|>k}=0 (5.1) (although no one actually writes this). To understand Deﬁnition 5.3, again consider the sequence of random variables, {Yn: n=1,2,...}, evaluated on a particular sample path, ω0. This time, however, look only at thenth constant in the resulting sequence of constants, Yn(ω0). If that nth constant, Yn(ω0), deviates from μby more than k, we say that the sample path ω0behaves badly for Yn. Let’s repeat the experiment for a different sample path, ω1. Consider the sequence{Yn(ω1):n=1,2,...}. Again look only at the nth constant, Yn(ω1), and ask whether Yn(ω1)deviates from μby more than k. If so, then the sample path ω1 behaves badly for Yn. Question: What does P{ω:|Yn(ω)−μ|>k}represent? Answer: The probability comprising sample paths that behave badly for the nth r.v., Yn. This is a number between 0and1. Question: What does P{ω:|Yn+1(ω)−μ|>k}represent? Answer: The probability comprising sample paths that behave badly for the n+1th r.v.,Yn+1. Note that YnandYn+1may behave badly on different sample paths. We are only interested in the mass (probability) of sample paths that are bad for Yn, the mass that are bad for Yn+1, the mass of those that are bad for Yn+2, etc. Question: What is limn→∞P{ω:|Yn(ω)−μ|>k}? Answer: This is the limit of a sequence of probabilities: the probability comprising sample paths that are bad for Yn, the probability comprising sample paths that are bad forYn+1, the probability comprising sample paths that are bad for Yn+2, etc. If this limit,limn→∞P{ω:|Yn(ω)−μ|>k}, exists and is zero for all k>0, then we say that the sequence of random variables {Yn:n=1,2,...}converges in probability toμ.",8349
5.3 Time Average versus Ensemble Average,"5.2strong and weak laws of large numbers 83 Question: Given the deﬁnition of a limit of a sequence of constants, how could we expand the deﬁnition of convergence in probability to replace the limit in there? Answer: ∀k>0,∀/epsilon1>0,∃n0(/epsilon1)s.t.∀n>n 0(/epsilon1),|P{ω:|Yn(ω)−μ|>k}|</epsilon1 . Question: Which is stronger: almost sure convergence or convergence in probability? Answer: Almost sure convergence implies convergence in probability. Here is the intuition: Given almost sure convergence, we know that (almost) all sample paths eventually do the right thing, each from some n0(ω)point onward. Thus, looking out at higher and higher n, we see that the number of sample paths behaving badly past that point gets smaller and smaller. From this it seems intuitive that the mass of sample paths behaving badly gets smaller and smaller as we look at further out values of n. Note that this is only intuition, because the total number of sample paths also grows withn. Thus it is hard to immediately claim that the probability comprising paths behaving badly decreases for all nvalues. Question: Explain how a sequence {Yn}might converge in probability but notalmost surely. Answer: Even if{Yn}converges in probability, it could still be the case that nosample path has the property that from some point onward it behaves well. For example, each sample path may have occasional spikes; however, these spikes get further and furtherapart for large n. Thus for no sample path ωdoes{Yn(ω):n=1,2,...}converge. However, for any ﬁxed nthe fraction of sample paths ωunder which Yn(ω)is far from μis small – and gets smaller as we increase n. This is illustrated in Figure 5.2. Y(ω2)Y(ω1) Y(ω3)nµ Figure 5.2. Illustration of the convergence in probability without almost sure convergence. Again, the dotted line indicates μ. 5.2 Strong and Weak Laws of Large Numbers Theorem 5.4 (Weak Law of Large Numbers) LetX1,X2,X3,... be i.i.d. ran- dom variables with mean E[X].L e t Sn=n/summationdisplay i=1Xiand Yn=Sn n. 84 sample paths, convergence, and averages Then YnP−→E[X],asn→∞. This is read as “ Ynconverges in probability to E[X], ” which is shorthand for the following: ∀k>0,lim n→∞P{|Yn−E[X]|>k}=0. Theorem 5.5 (Strong Law of Large Numbers) LetX1,X2,X3,... be i.i.d. random variables with mean E[X].L e t Sn=n/summationdisplay i=1Xiand Yn=Sn n. Then Yna.s.−→E[X],asn→∞. This is read as “ Ynconverges almost surely to E[X]”o r“Ynconverges to E[X] with probability 1, ” which is shorthand for the following: ∀k>0,P/braceleftBig lim n→∞|Yn−E[X]|≥k/bracerightBig =0. Question: Going back to the example where the Xi’s are all 0/1random variables with mean1 2, what is the Strong Law of Large Numbers saying? Answer: Each sample path is an inﬁnite sequence of coin ﬂips. The Strong Law says that for “almost every” sample path, if we average the coin ﬂips far out enough along the path, we will get convergence to1 2from that point onward. As we have discussed, even if there are uncountably many bad paths that do not behave this way, the mass comprising those paths is zero, when compared to all the well-behaved sample paths.",3129
5.3 Time Average versus Ensemble Average,"The proof of the Weak Law of Large Numbers is derived in Exercise 5.1. The proof of the Strong Law is much more involved (as are many proofs regarding almost all sample paths). There are several different proofs; one of the simpler versions is givenin Ross [ 149], pp. 56–58. 5.3 Time Average versus Ensemble Average You may think that the concept of an “average” is quite clear. However, in stochastic processes there are multiple types of averages. Two of these types are the time average and the ensemble average . To keep this discussion from becoming too abstract, we will repeatedly return to the following simple example: a single FCFS queue in which at every second a new job isadded to the queue with probability pand at every second the job in service (if there 5.3time average versus ensemble average 85 is one) is completed with probability q, where q>p . LetN(v)=number of jobs in the system at time v. 5.3.1 Motivation Once upon a time there were two students in my class, Tim and Enzo (see Figure 5.3). Tim was very tall and long, and he looked very much like a time-line. Enzo was more 2-dimensional looking (if they both look a little like robots, remember that this is a computer science department). Both Tim and Enzo were trying to simulate their FCFS queue to determine the average number of jobs in the system. Tim Enzo Figure 5.3. Tim and Enzo. Tim, who saw the world as a time-line, generated onevery long sequence of coin ﬂips (a single process), which he used to simulate the queue over a very, very long period of time, as shown in Figure 5.4. During the running of this queue, Tim logged the number of jobs in the system each second, obtaining a million samples. Then he took the average over all the million samples in his log to get the “average number of jobs.” Enzo took a more 2-dimensional approach. Instead of averaging over one long simula- tion of length 1,000,000, he generated 1,000 shorter simulations, each of length 1,000. For each simulation, he would wait until his simulation had run for t=1,000seconds, and then he would sample the queue at exactly time t, obtaining onevalue for N(t), the number of jobs at time t. Enzo then restarted the experiment from scratch (with a oznE miT Figure 5.4. Tim and Enzo’s different simulation approaches. 86 sample paths, convergence, and averages new random seed) and again simulated the queue until time t, when he sampled the number of jobs, obtaining one more value. Enzo continued to restart his experiment a thousand times. Each time, he would run his simulation until time tand obtain one more sample for the number of jobs. After obtaining a thousand samples, he averaged these to get the “average number of jobs.” Question: Who is “right”? Tim or Enzo? Answer: We will soon see . . . 5.3.2 Deﬁnition Deﬁnition 5.6 NTime Avg= lim t→∞/integraltextt 0N(v)dv t. Deﬁnition 5.7 NEnsemble= lim t→∞E[N(t)] =∞/summationdisplay i=0ipi where pi= lim t→∞P{N(t)=i} =mass of sample paths with value iat time t. 5.3.3 Interpretation When we talk about a time average we implicitly have in mind a particular sample path ωover which we are taking the time average. Thus a more precise deﬁnition might be as follows: Deﬁnition 5.8 NTime Avg(ω) = lim t→∞/integraltextt 0N(v,ω)dv t, where N(v,ω)represents the number of jobs in the system at time vunder sample pathω. Thus the time average, NTime Avg, is deﬁned by observing a single sample path over a long period of time, t, as shown in Figure 5.5.",3471
5.3 Time Average versus Ensemble Average,"During this long period of time, we monitor the number of jobs in the system, and then we take the average over time. The important point here is that we are looking at a single process – one sequence of 5.3time average versus ensemble average 87 coin ﬂips ,ω. Consider the example of the single server. The queue might start empty (N(0,ω)=0 ). Then at time 1, there might be an arrival but no departure ( N(1,ω)= 1). At time 2, there might again be an arrival but no departure ( N(2,ω)=2 ). At time 3, there might again be an arrival but no departure ( N(3,ω)=3 ). Now at time 4, there might be no arrival and a departure ( N(4,ω)=2 ), etc. The average number of jobs in the system by time 4 for this process is ( 0+1+2+3+2 ) /5=8/5. We could continue looking at this process up to time tfor some huge time tin the future and ask what is the average number of jobs in the system for this process by time t.I ftis really large, we hope that the average number of jobs in the system for this sample path, ω, converges. We then call this limit the time average number of jobs in the system along sample path ω. time νN(ν,ω) Figure 5.5. Time average for sample path ω. Yet the time average number may seem suspicious because we are only looking at a single sequence of coin ﬂips. Perhaps this was a particularly unusual sequence? The ensemble average, NEnsemble, is what we more typically mean when we talk about the average number of jobs in the system, E[N]. This represents the expected number of jobs in the system when the system is in steady state. ( Note: the term “steady state” will only be formally deﬁned when we get to Markov chains. For now consider steady state to be some point in time where the effects of the initial starting state are longgone.) The ensemble average takes into account all possible sequences of coin ﬂips – all sample paths, as shown in Figure 5.6. Consider again the example of the single server. Again the system might start empty ( N(0) = 0 ). Considering all possible events during the ﬁrst time step, we see that at time 1 there is some probability that the system is still empty and there is some probability that the system contains one job. Thus we can compute E[N(1)], the expected number of jobs at time 1. Now at time 2, again considering all possible sequences of coin ﬂips and their likelihoods, we can again see that there is some probability that the system is empty, some probability that the system contains 1 job, and some probability that the system contains 2 jobs. We can thus compute E[N(2)], the expected number of jobs in the system at time 2. Likewise, for any time twe can compute E[N(t)]. If we choose tlarge enough ( t→∞ ), under typical conditions there will be some limiting probability that the system contains 0 jobs,p0, and some limiting probability that the system contains 1 job, p1, and some limiting probability that the system contains 2 jobs, p2, and some limiting probability that the system contains ijobs, for any i,pi. The expectation of these,/summationtext∞ i=0ipi,i s exactly what we mean by NEnsemble.",3080
5.3 Time Average versus Ensemble Average,"88 sample paths, convergence, and averages time tY(ω2)Y(ω1) Y(ω3) Y(ω4) Figure 5.6. Ensemble average. Question: Which type of average is Tim? Which type is Enzo? Answer: Tim is measuring a time average, whereas Enzo is measuring the ensemble average. Remark: As a practical matter, both Tim and Enzo need to be concerned about initial conditions, but in different ways. Enzo needs to be sure his initial conditions have attenuated sufﬁciently before his measurement point, whereas Tim needs to make sure the portion of his simulation that is affected by initial conditions is sufﬁciently small. 5.3.4 Equivalence How does NTime Avgcompare with NEnsemble? Theorem 5.9 For an “ergodic” system (see Deﬁnition 5.10), the ensemble average exists and, with probability 1, NTime Avg=NEnsemble. That is, for (almost) all sample paths, the time average along that sample path converges to the ensemble average. This theorem is discussed in greater detail and proven in Chapter 9. The intuition, however, is very simple. To explain the intuition, we ﬁrst need to explain the term “ergodic.” Question: First, do you have any intuition about what conditions might be required to make the time average equal to the ensemble average? Deﬁnition 5.10 Anergodic system is one that is positive recurrent, aperiodic, and irreducible. 5.3time average versus ensemble average 89 These terms are all deﬁned precisely in Chapter 9, but we explain the ideas now. We start with irreducibility . Irreducibility says that a process should be able to get from any state to any other state (think of the state as the number of jobs in the system). This is important for ensuring that the choice of initial state does not matter. Thepositive recurrent property is the most important condition with respect to under- standing the equivalence between the time average and the ensemble average: Given an irreducible system, in which we can get to any state, the system is positive recurrent if for any state i, the state is revisited inﬁnitely often, and the mean time between visits to state i(renewals) is ﬁnite. Furthermore, every time that we visit state ithe system will probabilistically restart itself. Question: Give an example of what it means for the process to probabilistically restart itself.Answer: Every time that the system empties ( 0jobs), the process starts anew in state 0. We call this a “restart.” In a positive recurrent system, the system empties inﬁnitely often. This includes all systems that we will study.Consider our example of a queue, where a new job is created at each time step with probability pand a job is removed with probability q>p . We start out with zero jobs in the system. We now start ﬂipping coins, and the number of jobs in the system goes up and down. At some point, the number of jobs in the system returns to zero. At this point, we can imagine the same statistical process starting over again. And the nexttime the number of jobs in the system returns to zero, it will start over again. Thus a single long run of the system (Tim’s view) actually appears to be an inﬁnite number ofstatistically independent runs (Enzo’s view).",3142
5.3 Time Average versus Ensemble Average,"The aperiodicity condition is important in making sure that the ensemble average exists. Aperiodicity refers to the fact that the system state (number of jobs in the system) should not be tied in some particular way to the time step; for example, itshould not be the case that the system is always in state 0for even time steps and state 1 for odd time steps; otherwise, the particular tthat Enzo picked for stopping the system might sway his result. Question: Explain intuitively why an ergodic system should have the property that the time average equals the ensemble average. Answer: Consider the time average over a single long run of the system as shown in Figure 5.7. This run can be thought of as a chain of many independent but statistically identical runs, each called a “renewal.” Let X1represent the time average over just Restart Restart Restart Restart Restart Figure 5.7. Single process restarting itself. 90 sample paths, convergence, and averages the ﬁrst renewal, let X2represent the time average over just the second renewal, etc. Then the overall time average is the average of X1,X2,.... But these are i.i.d. So, by the Strong Law of Large Numbers (SLLN), the average of these converges withprobability 1 to the expected time average over a single renewal, where the expectation is an ensemble average (taken over all sample paths). 5.3.5 Simulation What does all this say about how we do simulation? Tim’s method of sampling a single process over a very long period of time and averaging those samples results in NTime Avg. Enzo’s method of generating many independent processes and taking their average at some far-out time tyields NEnsemble. If these yield the same result, should we go for the easier method? Question: The ensemble average seems more costly to compute, because we need new random seeds. Why bother with the ensemble average if it comes out to the same thing as the time average? Answer: The main reason is that the ensemble average can be obtained in parallel, by running simulations on different cores or different machines. Another reason forusing the ensemble average is that the independent data points allow us to generateconﬁdence intervals, which allow us to bound the deviation in our result. Question: Why in both the deﬁnitions of ensemble average and time average is it so important that the system be run for a “long” time? Answer: We want to get to the point where the initial state has no effect: We want to reach “steady state.” This will all become more clear when we get to Markov chain theory. 5.3.6 Average Time in System So far, we have talked about the average number of jobs in the system. We can also deﬁne two versions of the average time in system as follows: TTime Avg= lim t→∞/summationtextA(t) i=1Ti A(t), where Tiis the time in system of the ith arrival and A(t)is the number of arrivals by timet. Again the time average is assumed to be associated with a single sample path. TEnsemble= lim i→∞E[Ti], whereE[Ti]is the average time in system of the ith job, where the average is taken over all sample paths.",3076
5.4 Related Readings. 5.5 Exercise,"5.5exercise 91 5.4 Related Readings The following books provide more detail on the information covered in this chapter: Karlin and Taylor (pp. 474–89) [ 105], and Gross and Harris (pp. 38–45) [ 75]. 5.5 Exercise 5.1 Weak Law of Large Numbers LetX1,X2,X3, ..., b e i . i . d . r andom variables with ﬁnite mean E[X]and ﬁnite variance σ2. Your goal is to prove the Weak Law of Large Numbers: ∀/epsilon1,lim n→∞P/braceleftbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingleS n n−E[X]/vextendsingle/vextendsingle/vextendsingle/vextendsingle>/epsilon1/bracerightbigg =0 where Sn=/summationtextn i=1Xi. (a) Start out by proving Markov’s Inequality, which says: If Xis non-negative then P{X>t}≤E[X] t,∀t>0. (b) Now use Markov’s Inequality to prove Chebyshev’s Inequality, which says: LetYbe a random variable with ﬁnite mean E[Y]and ﬁnite variance σ2 Y. Then P{|Y−E[Y]|≥t}≤σ2 Y t2. (c) Finally use Chebyshev’s Inequality to prove the Weak Law of Large Numbers.",962
Part III The Predictive Power of Simple Operational Laws What-If Questions and Answers,"PART III The Predictive Power of Simple Operational Laws: “What-If” Questions and Answers Part IIIis about operational laws. Operational laws are very powerful because they apply to any system or part of a system. They are both simple and exact. A very important feature of operational laws is that they are “distribution independent.” This means, for example, that the laws do not depend on the distribution of the job service requirements (job sizes), just on their mean. Likewise the results do not depend on thedistribution of the job interarrival times, just on the mean arrival rate. The fact that theresults do not require the Markovian assumptions that we will see in Part IV, coupled with the fact that using operational laws is so easy, makes these laws very popular with system builders. The most important operational law that we will study is Little’s Law, which relates the mean number of jobs in any system to the mean response time experienced byarrivals to that system. We will study Little’s Law and several other operational lawsin Chapter 6. In Chapter 7we will see how to put together several operational laws to prove asymp- totic bounds on system behavior (speciﬁcally, mean response time and throughput)for closed systems. Asymptotic bounds will be proven both in the limit as the multi-programming level approaches inﬁnity and in the limit as the multiprogramming levelapproaches 1. These asymptotic bounds will be very useful in allowing us to answer“what-if” questions of the form, “Is it preferable to increase the speed of the CPU bya factor of 2, or to increase the speed of the I/O device by a factor of 3, or does neitherreally make a difference?” 93",1682
Chapter 6 Littles Law and Other Operational Laws. 6.2 Intuitions,"CHAPTER 6 Little’s Law and Other Operational Laws Little’s Law is probably the single most famous queueing theory result. It states that the average number of jobs in the system is equal to the product of the average arrivalrate into the system and the average time a job spends in the system. It also holds whenthe system consists of just the “queues” in the system. Little’s Law applies to both openand closed systems, and we explain it in both cases. 6.1 Little’s Law for Open Systems Let’s ﬁrst consider open systems, as shown in Figure 6.1. Theorem 6.1 (Little’s Law for Open Systems) For any ergodic1open system we have that E[N]=λE[T] whereE[N]is the expected number of jobs in the system, λis the average arrival rate into the system, and E[T]is the mean time jobs spend in the system. Arrivals (rate λ) Depart ures Any system Time in system, T Figure 6.1. Setup for Little’s Law. It is important to note that Little’s Law makes no assumptions about the arrival process, the service time distributions at the servers, the network topology, the service order, oranything. At this point it may be hard to appreciate Little’s Law. Its usefulness stems from the fact that when we study Markov chains, we see many techniques for computing E[N]. Applying Little’s Law will then immediately yield E[T]. 1The term ergodic was deﬁned brieﬂy in Section 5.3. In Section 6.4we elaborate on its purpose in Theorems 6.1 and6.2. 95",1424
6.4 Proof of Littles Law for Open Systems,"96 little’s law and other operational laws 6.2 Intuitions This section contains some intuitions to help you remember Little’s Law. They are not proofs. We will prove Little’s Law in Section 6.4. It should seem intuitive that E[T]andE[N]are proportional. Consider the example of a fast-food restaurant [ 18]. It gets people out fast (low E[T]) and also does not require much waiting room (low E[N]). By contrast, a slow-service restaurant gets people out slowly (high E[T]) and therefore needs a lot more seating room ( E[N]). ThusE[T]should be directly proportional to E[N]. Here is the way I always remember Little’s Law (intuition only): Think about a single FCFS queue, as shown in Figure 6.2. A customer arrives and sees E[N]jobs in the system. The expected time for each customer to complete is 1/λ(not1/μ), because the average rate of completions is λ(see Section 2.5). Hence the expected time until the customer leaves is E[T]≈1 λ·E[N]. FCFS Rate λ Figure 6.2. Little’s Law applied to a single server. 6.3 Little’s Law for Closed Systems In a closed system, E[N]is ﬁxed at N, the multiprogramming level. Thus, for a closed system, the statement of Little’s Law is as follows: Theorem 6.2 (Little’s Law for Closed Systems) Given any ergodic closed system, N=X·E[T], where Nis a constant equal to the multiprogramming level, Xis the throughput (i.e., the rate of completions for the system), and E[T]is the mean time jobs spend in the system. Figure 6.3shows a batch system and an interactive (terminal-driven) system. Note that for the interactive system (right), the time in system, T, is the time to go from “out” to “out,” whereas response time, R, is the time from “in” to “out.” Speciﬁcally, for a closed interactive system , we deﬁne E[T]=E[R]+E[Z], where E[Z]is the average think time, E[T]is the average time in system, and E[R]is the average response time. The notation is a little overloaded, in that for open systems and closedbatch systems, we refer to E[T]as mean response time, whereas for closed interactive systems E[T]represents the mean time in system and E[R]is the mean response time, since response time does not include thinking. 6.4proof of little’s law for open systems 97 SubsystemN jobs N jobs Subsystemin o ut in o ut Figure 6.3. Closed systems: A batch system (left) and an interactive system (right). Recall from Chapter 2that, for an open system , throughput and mean response time are uncorrelated. By contrast, Little’s Law tells us that, for a closed system, XandE[T] are inversely related, as are XandE[R].Thus in a closed system, improving response time results in improved throughput and vice versa. 6.4 Proof of Little’s Law for Open Systems We are now ready to prove Little’s Law. This section focuses on open systems (see Figure 6.4). The next section concentrates on closed systems. Arrivin g jobs Departin g jobs Any system Figure 6.4. Open system. 6.4.1 Statement via Time Averages Theorem 6.3is a statement of Little’s Law as you will see it in the literature. As you see, Little’s Law is actually stated as a relationship between time averages (see Section 5.3). Let λ= lim t→∞A(t) tandX= lim t→∞C(t) t, where A(t)is the number of arrivals by time tandC(t)is the number of system completions (departures) by time t. Observe that it is typically the case that λ=X (one could have λ>X if some arrivals get dropped, or if some jobs get stuck and never complete for some reason). 98 little’s law and other operational laws Theorem 6.3 (Little’s Law for Open Systems Restated) Given any system where NTime Avg,TTime Avg,λ, andXexist and where λ=X, then NTime Avg=λ·TTime Avg. Observe that Little’s Law is stated as an equality between time averages , not ensemble averages . Little’s Law says that the time-average number in system for sample path ωis equal to λtimes the time-average time in system for that sample path. However, we know that if we assume that the system is also ergodic , then the time average converges to the ensemble average with probability 1; namely, on almost every sample path, the time average on that sample path will be equal to the ensemble average over all paths (see Section 5.3). Thus, assuming ergodicity, we can apply Little’s Law in an ensemble-average sense, which we will do. Consider the requirements in Theorem 6.3. They are all subsumed by the assumption that the system is ergodic , for if the system is ergodic then the above limits all exist and furthermore the average arrival rate and completion rate are equal, because the system empties inﬁnitely often. Furthermore, if we assume that the system is ergodic,then the time average is equal to the ensemble (or “true”) average. Thus it is sufﬁcientto require that the system is ergodic for Little’s Law, as stated in Theorem 6.1,t o hold. 6.4.2 Proof Proof (Theorem 6.3)LetTidenote the time that the ith arrival to the system spends in the system, as shown in Figure 6.5. Now, for any time t, consider the area, A, contained within all the rectangles in Figure 6.5, up to time t(this includes most of the rectangle labeled T5). We ﬁrst view this area, A, by summing horizontally and then, equivalently, view it again by summing vertically. T6 T4 T3 T2 ttime Arrival 1st jobDepart ure 1st jobT1T5 Figure 6.5. Graph of arrivals in an open system. 6.4proof of little’s law for open systems 99 The horizontal view consists of summing up the Ti’s as follows: We observe that /summationdisplay i∈C(t)Ti≤A≤/summationdisplay i∈A(t)Ti where/summationtext i∈C(t)Tidenotes the sum of the time in system of those jobs that have completed by time t, and/summationtext i∈A(t)Tidenotes the sum of the time in system of those jobs that have arrived by time t. The vertical view of Aadds up the number of jobs in system at any moment in time, N(s), where sranges from 0tot. Thus, A=/integraldisplayt 0N(s)ds. Combining these two views, we have /summationdisplay i∈C(t)Ti≤/integraldisplayt 0N(s)ds≤/summationdisplay i∈A(t)Ti. Dividing by tthroughout, we get /summationtext i∈C(t)Ti t≤/integraltextt 0N(s)ds t≤/summationtext i∈A(t)Ti t or, equivalently, /summationtext i∈C(t)Ti C(t)·C(t) t≤/integraltextt 0N(s)ds t≤/summationtext i∈A(t)Ti A(t)·A(t) t. Taking limits as t→∞ , limt→∞/summationtext i∈C(t)Ti C(t)·lim t→∞C(t) t≤NTime Avg≤lim t→∞/summationtext i∈A(t)Ti A(t)·lim t→∞A(t) t ⇒TTime Avg·X≤NTime Avg≤TTime Avg·λ. Yet we are given that Xandλare equal. Therefore, NTime Avg=λ·TTime Avg. Question: Are we assuming FCFS service order in this argument? Answer: No, this argument does not depend on service order. Observe that the second arrival departs after the third arrival departs. Question: Are we assuming anywhere that this is a single-server system? Answer: No, this argument holds for any system. 100 little’s law and other operational laws 6.4.3 Corollaries Corollary 6.4 (Little’s Law for Time in Queue) Given any system where NTime Avg Q ,TTime AvgQ,λ, andXexist and where λ=X, then NTime Avg Q =λ·TTime AvgQ, where NQrepresents the number of jobs in queue in the system and TQrepresents the time jobs spend in queues. Question: How would you prove Corollary 6.4? Answer: Same proof as for Theorem 6.3, except that now instead of drawing Ti,w e drawTQ(i), namely the time the ith arrival to the system spends in queues (wasted time). Note that TQ(i)may not be a solid rectangle. It may be made up of several rectangles because the ith job might be in queue for a while, then in service, then waiting in some other queue, then in service, again, etc. Corollary 6.5 (Utilization Law) Consider a single device iwith average arrival rateλijobs/sec and average service rate μijobs/sec, where λi<μ i.L e tρidenote the long-run fraction of time that the device is busy. Then ρi=λi μi. We refer to ρias the “device utilization” or “device load.” Observe that, given ergodicity, ρirepresents both the long-run fraction of time that device iis busy and also the limiting probability (ensemble average) that device iis busy. Question: Do you see how to use Little’s Law to prove this corollary? What should we deﬁne the “system” to be? Proof Let the “system” consist of just the service facility without the associated queue, as shown in the shaded box of Figure 6.6. Now the number of jobs in the “system” is always just 0 or 1. Depart uresDevice i The “system ”Arrival rate λi i Figure 6.6. Using Little’s Law to prove the Utilization Law. Question: What is the expected number of jobs in the system as we have deﬁned it? Answer: The number of jobs in the system is 1when the device is busy (this happens with probability ρi) and is 0when the device is idle (this happens with probability",8614
6.7 Examples Applying Littles Law,"6.5proof of little’s law for closed systems 101 1−ρi). Hence the expected number of jobs in the system is ρi. So, applying Little’s Law, we have ρi=Expected number jobs in service facility for device i =(Arrival rate into service facility) ·(Mean time in service facility) =λi·E[Service time at device i] =λi·1 μi. We often express the Utilization Law as ρi=λiE[Si]=XiE[Si] where ρi,λi,Xi, andE[Si]are the load, average arrival rate, average throughput, and average service requirement at device i, respectively. Question: Suppose we are only interested in “red” jobs, where “red” denotes some type of jobs. Can we apply Little’s Law to just “red” jobs? Prove it. Answer: Yes. E[Number of red jobs in system ]=λred·E[Time spent in system by red jobs ] The proof is exactly the same as before, but only the Ti’s corresponding to the red jobs are included in Figure 6.5. 6.5 Proof of Little’s Law for Closed Systems 6.5.1 Statement via Time Averages As in the previous section, we begin with a restatement of Little’s Law for closed systems. As before we deﬁne X= lim t→∞C(t) t where C(t)is the number of system completions by time t. This time, however, there are no exogenous arrivals. We thus deﬁne λ= lim t→∞A(t) t where A(t)is the number of jobs that are generated by time t. Theorem 6.6 (Little’s Law for Closed Systems Restated) Given any closed system (either interactive or batch) with multiprogramming level Nand given that TTime AvgandXexist and that λ=X, then N=X·TTime Avg. 102 little’s law and other operational laws 6.5.2 Proof It is important to note that Tin Theorem 6.6corresponds to the total time in system, namely the time to go from “out” to “out” in Figure 6.3, which includes both response time (R) and think time ( Z). Thus, as soon as one Ticompletes, another immediately starts, as shown in Figure 6.7. T1T4T5T7T2T3 T8 T11 T10 T12 T9T6 ttimeN = 3 Figure 6.7. Graph of job system times in closed system with N=3. Proof Figure 6.7shows the time in system for arrivals. Observe that a new job cannot arrive until one departs. Thus there are always Njobs in the system. At any time t, the area made up by all rectangles up to time tisNt, which can be bounded above and below as follows: /summationdisplay i∈C(t)Ti≤N·t≤/summationdisplay i∈A(t)Ti ⇒/summationtext i∈C(t)Ti t≤N≤/summationtext i∈A(t)Ti t ⇒/summationtext i∈C(t)Ti C(t)·C(t) t≤N≤/summationtext i∈A(t)Ti A(t)·A(t) t Taking limits as t→∞ , lim t→∞/summationtext i∈C(t)Ti C(t)·lim t→∞C(t) t≤N≤lim t→∞/summationtext i∈A(t)Ti A(t)·lim t→∞A(t) t ⇒TTime Avg·X≤N≤λ·TTime Avg. ButXandλare equal. Therefore N=X·TTime Avg. 6.6 Generalized Little’s Law Note that the relationships presented so far have all been between the mean time in system, E[T], and the mean number of jobs in system, E[N]. You might be wondering if Little’s Law can be generalized to relate higher moments as well, such as a relationship between E[T2]andE[N2]. Some research papers have been successful at proving relationships between higher moments under certain very restrictive conditions, 6.7examples applying little’s law 103 generally requiring that jobs leave in the order that they arrive, as in a single FCFS queue, see [ 33,19]. Although we later derive a relationship between the higher moments ofTandNfor a single-server M/G/1 queue (see Chapter 26), it is typically very difﬁcult to get higher moments of Tfor more general multi-queue systems. 6.7 Examples Applying Little’s Law The versatility of Little’s Law lies in two properties: First, Little’s Law is distribution independent. This means that it depends only on mean quantities (e.g., the mean interarrival time or the mean service time), not on whether the service times are Exponentially distributed or Uniformly distributed, nor on whether the arrival process is Poisson or something else. Second, Little’s Law applies to any system or piece of a system , as we demonstrate in the following examples. Example 1: Refer to Figure 6.8 We have an interactive system with N=1 0 users, as shown in Figure 6.8. We are told that the expected think time is E[Z]=5 seconds and that the expected response time isE[R]=1 5 seconds. Note that the response time is the time it takes a job to get from “in” to “out” in Figure 6.8. SubsystemN = 10 users tuo ni Figure 6.8. An interactive system. Question: What is the throughput, X, of the system? Answer: Using Little’s Law for closed systems, we have N=X·E[T]=X(E[Z]+E[R]) ⇒X=N E[R]+E[Z]=10 5+1 5=0.5jobs/sec . The application of Little’s Law to closed systems is often referred to as the Response Time Law for Closed Systems : E[R]=N X−E[Z] 104 little’s law and other operational laws Example 2: Refer to Figure 6.9 N = 10 CPUDisk 1 Disk 2 Disk 3 Figure 6.9. A more complex interactive system. We are given the system in Figure 6.9and the following information: rThe throughput of disk 3 is 40 requests/sec ( Xdisk3=4 0 ). rThe service time of an average request at disk 3 is 0.0225 sec ( E[Sdisk3]=.0225 ). rThe average number of jobs in the system consisting of disk 3 and its queue is 4 (E[Ndisk3]=4 ). Question: What is the utilization of disk 3? Answer: ρdisk3=Xdisk3·E[Sdisk3]=4 0·(0.0225) = 90 percent . Question: What is the mean time spent queueing at disk 3? Answer: LetTdisk3denote the time spent queueing plus serving at disk 3. Let Tdisk3 Q denote the time spent queueing at disk 3. Then, E[Tdisk3]=E[Ndisk3] Xdisk3=4 40=.1sec. E/bracketleftbig Tdisk3 Q/bracketrightbig =E[Tdisk3]−E[Sdisk3]=0.1sec−0.0225 sec=0.0775 sec. Question: FindE[Number of requests queued at disk 3 ]. Answer: E/bracketleftbig Ndisk3 Q/bracketrightbig =E[Ndisk3]−E[Number requests serving at disk 3 ] =E[Ndisk3]−ρdisk3 =4−0.9 =3.1requests . 6.7examples applying little’s law 105 Alternatively, we could have obtained this same answer from E/bracketleftbig Ndisk3 Q/bracketrightbig =E/bracketleftbig Tdisk3 Q/bracketrightbig ·Xdisk3=0.775·40 = 3 .1requests . Next we are told that rE[Number of ready users (not thinking) ]=7.5. rNumber of terminals Nis 10. rE[Think time ]=E[Z]=5 sec. Question: What is the system throughput? Answer: Looking at the whole system, we have X=N E[R]+E[Z]=10 E[R]+5 but we do not know E[R]. Looking only at the non-thinking part of the system, we have E[R]=E[Nnot-thinking ] X=7.5 X but we do not know X. Solving these two equations simultaneously yields X=.5 requests per second and E[R]is 15 seconds. Question: Is there a way to get system throughput using only one equation? Answer: Yes, we could instead apply Little’s Law to the thinking region only. The throughput of the thinking region is still X, and the mean time spent in the thinking region is E[Z]. Hence, E[Nthinking]=X·E[Z] 2.5=X·5 X=0.5. Example 3: Refer to Figure 6.10 µ = 4 λ= 3 Figure 6.10. A ﬁnite buffer. Figure 6.10 shows a single FCFS queue with a capacity limitation of 7 jobs (there is room for 1 job to serve and buffer space for 6 more waiting jobs). Arrivals that ﬁnd a full buffer are dropped. Question: What does Little’s Law look like for this system? Answer: The problem is that λ/negationslash=Xas required by Little’s Law. However, theeffective arrival rate , meaning the rate of those jobs that get through, is",7162
6.9 Combining Operational Laws,"106 little’s law and other operational laws λ(1−P{7 jobs in system }), which is equal to the completion rate, as required. So E[N]=λ·(1−P{7 jobs in system })·E[T]. 6.8 More Operational Laws: The Forced Flow Law TheForced Flow Law relates system throughput to the throughput of an individual device as follows: Xi=E[Vi]·X where Xdenotes the system throughput, Xidenotes the throughput at device i, and Videnotes the number of visits to device iper job. Viis often referred to as the visit ratio for device i(see Figure 6.11). out Jobs ini Vi visits per jobDevice i System Figure 6.11. A single device within a larger system. (In a closed system the “in” and “out” arrows would be connected.) The Forced Flow Law should seem intuitive: For every system completion, there are on average E[Vi]completions at device i. Hence the rate of completions at device iis E[Vi]times the rate of system completions.2 2A more formal argument would go like this: Consider Figure 6.11. Suppose we observe the system for some large observation period t.L e tC(t)denote the number of system completions during time tand let Ci(t) denote the number of completions at device iduring time t.L e tV(j) ibe the number of visits that the jth job entering the system makes to device i. Then, Ci(t)≈/summationdisplay j∈C(t)V(j) i Ci(t) t≈/summationtext j∈C(t)V(j) i t Ci(t) t≈/summationtext j∈C(t)V(j) i C(t)·C(t) t lim t→∞Ci(t) t≈lim t→∞/summationtext j∈C(t)V(j) i C(t)·lim t→∞C(t) t Xi=E[Vi]·X. Note that approximation signs are used here because C(t)actually provides a lower bound on the sum, whereas A(t)would provide an upper bound. To be precise, we should use both the upper and lower bounds, but this becomes irrelevant once we take the limit as t→∞ . 6.9combining operational laws 107 Example of Forced Flow Law Question: Suppose we are given the network shown in Figure 6.12. What are the visit ratios? That is, what are E[Va],E[Vb], andE[Vcpu]? Disk a Disk bCPUN = 10 Figure 6.12. Calculating the visit ratios. Answer: Although it may seem obvious for this example, let’s work it out formally because later exercises may be more complicated. Looking at the ﬁgure, we see Ca=Ccpu·80/181 Cb=Ccpu·100/181 C=Ccpu·1/181 Ccpu=Ca+Cb+C. Dividing through by C(the number of system completions) yields the visit ratios. So we get E[Va]=E[Vcpu]·80/181 E[Vb]=E[Vcpu]·100/181 1=E[Vcpu]·1/181 E[Vcpu]=E[Va]+E[Vb]+1. Solving this system of simultaneous equations yields E[Vcpu] = 181 E[Va]=8 0 E[Vb] = 100 . 6.9 Combining Operational Laws Simple Example Suppose we have an interactive system with the following characteristics: r25 terminals ( N=2 5 ) r18 seconds average think time ( E[Z]=1 8 ) r20 visits to a speciﬁc disk per interaction on average ( E[Vdisk]=2 0 ) 108 little’s law and other operational laws r30 percent utilization of that disk ( ρdisk=.3) r0.025 sec average service time per visit to that disk ( E[Sdisk]=.025) That is all the information we have. We are not told anything else about the rest of the system. Question: What is the mean response time, E[R]? Answer: 1.E[R]=N X−E[Z], but we still need X. 2.X=Xdisk E[Vdisk], but we still need Xdisk. 3.Xdisk=ρdisk E[Sdisk], both of which we know. Working backward, we calculate Xdisk=ρdisk E[Sdisk]=1 2 requests/sec ⇒X=Xdisk E[Vdisk]=.6interactions/sec ⇒E[R]=N X−E[Z]=2 3 .7sec. Harder Example This is a case study taken from Lazowska et al., p. 49 [ 117]. We are told the following information only: rIt is an interactive system. rThe central subsystem consists of a CPU and three disks. rSwapping may occur between interactions, causing a user to lose her memory partition. Thus a request sometimes has to queue up in the memory queue to get back its memory partition before entering the central subsystem, but sometimes can skip this queue. Figure 6.13 is a sketch of what the system looks like based on this information. Observe that some jobs have to wait in the “get memory queue,” whereas others already have the prerequisite memory allocated and can skip over this part and go directly to the central subsystem. We are not given information as to the fraction of jobs that go each way. Here are the measurements that were collected about this system: rnumber of time-sharing users ( N=2 3 ) raverage think time per user ( E[Z]=2 1 seconds) rsystem throughput ( X=0.45interactions per second) raverage number of requests trying to get memory ( E[Ngetting memory ]=1 1 .65) raverage number of visits to the CPU per interaction ( E[Vcpu]=3 ) raverage service demand per visit to the CPU ( E[Scpu]=.21seconds) 6.9combining operational laws 109 Disk a Disk b Disk cCPU Get memory q ueue Central s ubsystem Figure 6.13. A system with a memory queue. Question: What is the average amount of time that elapses between getting a memory partition and completing the interaction? Answer: This question asks us for the expected time that jobs spend in the central subsystem. There are several ways to answer it. Here is one: E[Time in central subsystem ]=E[Response Time ]−E[Time to get memory ] It is true that not every job has to go get memory, but you can think of E[Time to get memory ]as the expected time to go from the point right before the split in the ﬁgure to right after the join in the ﬁgure. Now by the Response Time Law, E[Response Time ]=N X−E[Z]=23 0.45−21 = 30 .11sec. Furthermore, E[Time to get memory ]=E[Number getting memory ] X=11.65 0.45=2 5.88sec. Thus, E[Time in central subsystem ]=E[Response Time ]−E[Time to get memory ] =3 0.11−25.88 =4.23sec. Question: What is the CPU utilization? Answer: ρcpu=Xcpu·E[Scpu]=X·E[Vcpu]·E[Scpu]=0.45·3·0.21 = 0 .28.",5613
6.11 Readings and Further Topics Related to Littles Law,"110 little’s law and other operational laws 6.10 Device Demands We end with one ﬁnal law, called the Bottleneck Law. This law is very important in answering “what-if” type questions about systems, which come up in the next chapter. Deﬁne Dito be the total service demand on device ifor all visits of a single job (i.e., a single interaction). That is, Di=Vi/summationdisplay j=1S(j) i, where S(j) iis the service time required by the jth visit of the job to server i. We immediately see by ( 3.3) that E[Di]=E[Vi]·E[Si], provided that Viand the S(j) i’s are independent. That is, we are assuming that the number of visits a job makes to device iis not affected by its service demand at the device. We will soon discuss the importance of these Di’s. First, let’s observe how easy Di typically is to measure. Suppose we had to measure the Vi’s. This would be hard, because we would have to keep track of a particular job and count its visits to device i. If device iis time-shared among jobs, it would be even harder. Luckily, we do not have to do this.Question: How would you determine E[Di]in practice? Answer: Consider a long observation period. Observe that E[Di]=Bi C, where Biis the busy time at device ifor the duration of our observation period and Cis the number of system completions during this observation period. These are very easy measurements to get. The importance of E[Di]lies in the following law, which we call the Bottleneck Law : ρi=X·E[Di] Question: Can you explain the Bottleneck Law intuitively? Answer: Xis the jobs/sec arriving into the whole system. Each of those outside arrivals into the system contributes E[Di]seconds of work for device i. So device iis busy for X·E[Di]seconds out of every second (e.g., device imight be busy for half a second out of every second). Thus X·E[Di]represents the utilization of device i. Here is a proof of the Bottleneck Law: ρi=Xi·E[Si]=X·E[Vi]·E[Si]=X·E[Di].",1922
6.12 Exercises,"6.12 exercises 111 Example As a simple example, consider a system with an outside arrival rate of 3 jobs/second. Suppose that each job, on average, visits the disk 10 times. Suppose that each visitto the disk takes 0.01second on average. Then, the per-job demand on the disk is .1seconds, and the utilization of the disk is .3. 6.11 Readings and Further Topics Related to Little’s Law Little’s Law was invented by J.D.C. Little in 1961, [ 121]. The following books are useful in providing examples of the application of Little’s Law and other operational laws, as explained in this chapter and Chapter 7: Jain (pp. 547–67) [ 104], Lazowska et al. (pp. 40–95) [ 117], Bertsekas & Gallager (pp. 152–57) [ 18], and Menasc ´ee ta l . (pp. 84–89) [ 125]. The proof of Little’s Law can be generalized to allow for more general notions of the time in system, T, and the number in system, N. One of the generalizations is known in the literature as H=λG, where Htakes the place of NandGtakes the place of T. TheH=λGlaw and its further generalizations are described in great detail in a gem of a book by El-Taha and Stidham [ 51], Ch. 6. Another generalization is the Rate Conservation Law (RCL); see [ 126,103,167,183]. Finally, as mentioned earlier, there have been many attempts to prove relationships between higher moments of TandN. The Distributional Little’s Law holds only under certain very restrictive conditions, generally requiring that jobs leave in the order that they arrive, as in a single FCFS queue. Some relevant references are [ 33,19]. Exercises 26.4 and26.5 derive the Distributional Little’s Law for an M/G/1 FCFS queue and illustrate its application to more complex systems. 6.12 Exercises 6.1 Professors and Students A professor practices the following strategy with respect to taking on newPh.D. students. On even-numbered years, she takes on 2 new students. On odd- numbered years, she takes on 1 new student. Assuming the average time to graduate is 6 years, how many students on average will the professor have?Prove your answer using an operational law. 6.2 Simpliﬁed Power Usage in Server Farms Given that power is expensive, it is common practice to leave servers on only when they are being used and to turn them off whenever they are not in use.Assume that the following power-aware algorithm is used: When a job arrives,it instantly turns on a fresh server (assume zero setup cost). When the jobcompletes service, it instantly turns off that server. Assume that there is alwaysa server available for every job (i.e., there is no queueing). Your goal is to derive the time-average rate at which power is used in our system. Assume that when a server is on, it consumes power at a rate of P= 240 watts. Assume λ=1 0 112 little’s law and other operational laws jobs arrive per second and that the service requirement of jobs is Uniformly distributed ranging from 1second to 9seconds. (Note: This is a highly simpliﬁed model. We will study much more complex models in Chapter 27.) 6.3 Measurements Gone Wrong After spending months carefully building his closed batch data storage system,David comes to see his advisor with the following description and measure- ments: The MPL for the system is ﬁxed at 19jobs. David explains that 90 percent of jobs ﬁnd the data they need in the cache, and hence their expected response time is only 1second. However, 10 percent end up having to go to the database, where their expected response time is 10seconds. David’s advisor asks one question: “How many jobs do you see on average at the database?” When David answers “5,” his advisor says he needs to go back to the drawing board. What went wrong? 6.4 More Practice Manipulating Operational Laws For the interactive system in Figure 6.14, suppose that we are given the following information: mean user think time =5 seconds expected service time at device i=.01 seconds utilization of device i=.3 utilization of CPU =.5 expected number of visits to device iper visit to CPU =10 expected number of jobs in the central subsystem (the cloud shape) =20 expected total time in system (including think time) per job =50 seconds. How many jobs are there in the queue portion of the CPU on average, E/bracketleftbig Ncpu Q/bracketrightbig ? CPU½½ Device i Figure 6.14. Figure for Exercise 6.4. 6.5 Little’s Law for Closed Systems Recall that the Response Time Law for a closed interactive system says that E[R]=N X−E[Z]. Thus it seems possible that E[R]might be negative. Prove that this can never happen. (If you are clever, your proof can be only two lines.) 6.12 exercises 113 6.6 Little’s Law for Mean Slowdown Recall that Little’s Law relates the mean response time to the mean number of jobs in any ergodic system. It is interesting to ask whether a similar law can be proven that relates mean slowdown to the mean number of jobs in the system. We do not have an answer. However, you should be able to derive the followingbound in the case of a single FCFS queue : E[Slowdown ]≤E[N] λ·E/bracketleftbigg1 S/bracketrightbigg where Srepresents job size, Nrepresents the number of jobs in the system, and λis the average arrival rate into the queue. 6.7 More on SRPT The SRPT scheduling policy is important because it minimizes mean response time. In Exercise 2.3, we saw that SRPT does notminimize mean slowdown. Runting suggests that the problem with SRPT is that it picks jobs with the shortest remaining time, whereas to minimize mean slowdown we want tochoose jobs that have both short remaining time and also small original size. Runting proposes that we use the RS algorithm , which computes the product of a job’s current remaining size ( R) and its (original) size ( S), and then runs that job whose product ( RS) is smallest. Is Runting right? (a) Explain the intuition behind the RS algorithm for minimizing mean slow- down. (b) Prove or disprove that the RS algorithm minimizes mean slowdown on every arrival sequence. If it minimizes mean slowdown, provide a proof. If it does not minimize mean slowdown, provide a counterexample. RS is also known as SPTP and is analyzed in [ 100].",6102
Chapter 7 Modification Analysis What-If for Closed Systems. 7.2 Asymptotic Bounds for Closed Systems,"CHAPTER 7 Modiﬁcation Analysis: “What-If” for Closed Systems In the last chapter we learned about several operational laws. Operational laws are laws that hold independently of any assumptions about the distribution of arrivals or thedistribution of service times (job sizes). They are extremely useful and simple to apply.Operational laws may be applied to open and closed systems, although they often aremost powerful when applied to closed systems. In this chapter we do the following: 1.We use our operational laws to prove some very cool asymptotic bounds for closed systems. Note: These asymptotic bounds apply only toclosed systems. 2.We use our newly developed asymptotic bounds to do modiﬁcation analysis on closed systems. In modiﬁcation analysis we ask “what-if” questions about whichdesign changes will result in performance improvements for the closed system. 3.Finally, we return to the question of how closed systems differ from open systems. After this chapter, you can don a suit and call yourself a systems consultant :-) 7.1 Review So far we have seen several operational laws. They all follow immediately from the derivation of Little’s Law. Little’s Law for an Open System This holds for anyergodic open system and states that E[N]=λ·E[T], where λis the average outside arrival rate into the system, also equal to the (average) throughput rate of the system, X.H e r eE[N]is the expected number of jobs in the system, and E[T]is the expected time a job spends in the system. We saw several variations on this law, including E[NQ]=λ·E[TQ], which relates the number of jobs that are waiting (in queues) to the mean time jobs spend waiting, and E[Nred]=λred·E[Tred], which applies Little’s Law to just the “red-colored” jobs. 114 7.2asymptotic bounds for closed systems 115 Little’s Law for a Closed Batch System (Zero Think Time) This holds for any ergodic closed batch system and states that N=X·E[T], where Nis the multiprogramming level of the system. Response Time Law for Closed Interactive Systems This law holds for any ergodic closed interactive (terminal-driven) system and states that E[R]=N X−E[Z], where Nis the multiprogramming level (number of users), Xis the throughput, E[Z]denotes the mean time spent thinking, and E[R]is the expected response time. Utilization Law This applies to a single server iand states that ρi=λi μi=λiE[Si], where ρiis the utilization of the server, λiis the average arrival rate into the server (this is also the server’s throughput rate, Xi), and μi=1 E[Si]is the mean service rate at the server. Forced Flow Law This law relates system throughput to the throughput of an in- dividual device i: Xi=E[Vi]·X, where Xdenotes the system throughput, Xidenotes the throughput at device i, and E[Vi]denotes the expected number of visits to device iper job. Bottleneck Law This law involves Di, the total service demand on device ifor all visits of a single job. Over a long observation period T,Di=Bi/C, where Biis the total time during Tthat device iis busy and Cis the total number of system completions during time T. The Bottleneck Law states that ρi=X·E[Di]. 7.2 Asymptotic Bounds for Closed Systems We will now see that, by knowing the Di’s alone, we are able to both: 1.Estimate XandE[R]as a function of the multiprogramming level, N(this section). 2.Determine which changes to the system will be worthwhile and which will not (next section). Letmbe the number of devices in our system. Let D=m/summationdisplay i=1E[Di] 116 modiﬁcation analysis: “what-if” for closed systems and let Dmax=m a x i{E[Di]}. We will assume an interactive system ( E[Z]/negationslash=0). One can always set E[Z]=0 to get a batch system. Theorem 7.1 For any closed interactive system with Nterminals, X≤min/parenleftbiggN D+E[Z],1 Dmax/parenrightbigg . E[R]≥max(D,N·Dmax−E[Z]). Importantly, the ﬁrst term in each clause (N D+E[Z]orD)is an asymptote for small N, and the second term (1 DmaxorN·Dmax−E[Z])is an asymptote for large N. Proof First, we derive the large Nasymptotes: 1. ∀i, X·E[Di]=ρi≤1 ⇒∀i,X≤1/E[Di] ⇒X≤1/D max. (7.1) ForlargeN, theDmaxserver is always busy ( ρmax≈1), soX=1/D max. Thus 1/D maxis an asymptote for large N. 2. E[R]=N/X−E[Z]≥N·Dmax−E[Z], where the inequality comes from (7.1) and thus forms a tight bound for large N. Next, we derive the small Nasymptotes: 1.LetE[R(N)]denote the mean response time when the multiprogramming level isN. Then, E[R(N)]≥E[R(1)] = D1, (7.2) where the above expression is a tight asymptote for low N(when there is no congestion). Question: Why is E[R(1)] = D? Are we saying all devices must be visited by every job? Answer: No, We are not saying that all devices must be visited by every job, but that an average job has an expected amount of time at each device because some fraction of all jobs go to each device. 1For all the systems that we will look at, E[R(1)] = D. However, one can imagine some systems where E[R(1)]/negationslash=D. For example, suppose that a job can utilize two devices at the same exact time. Then E[R(1)] might be less than D=/summationtext Di. In this case, we want to make sure that we use E[R(1)], in Theorem 7.1, notD. 7.2asymptotic bounds for closed systems 117 2. X=N E[R]+E[Z] ≤N D+E[Z], where the inequality comes from ( 7.2) and thus forms a tight bound for small N. The power of this theorem lies in the fact that the bounds are asymptotes . That is, for largeNor small N, the curve comes very close to touching these lines. It is possible to get even tighter estimates (upper and lower bound on XandE[R] by using the Balanced Bounds technique, described in Lazowska et al.’s book [ 117] (Section 5.4). A Simple Example of Bounds Let’s examine a system like the one in Figure 7.1. Suppose rE[Z]=1 8 rE[DCPU]=5 sec rE[Ddisk a]=4 sec rE[Ddisk b]=3 sec Central s ubsystemtuo niCPUDisk a Disk b Figure 7.1. Closed system example. Our goal is to determine XandE[R]as a function of the multiprogramming level N. From this information, we see that rD=5+4+3=1 2 seconds rDmax=5 (the CPU is the bottleneck device) ThusX≤min{N/30,1/5}, andE[R]≥max{12,5N−18}. This is illustrated in Figures 7.2(a) and 7.2(b), which give us a good estimate of the performance of the system as a function of N. Observe that the point at which the asymptotes cross is denoted by N∗.",6287
7.4 More Modification Analysis Examples,"118 modiﬁcation analysis: “what-if” for closed systems N.05.1.15.2Xslope = 1/( D+Z) 1/Dmax actual curve 0 5 10 15 20 25 N* = 6 (a) X versus N (b) E [R] versus NN75100 50 25 0 5 10 15 20 25 N* = 6slope = DmaxE[R] Figure 7.2. Performance as a function of multiprogramming level, N. 7.3 Modiﬁcation Analysis for Closed Systems We start with some motivation for where we are going. A Simple, but Counterintuitive Example Consider the very simple closed network shown in Figure 7.3(a). Let’s suppose that N is high for this system. In this network both servers have service rate μ=1/3.N o w consider the “improvement” to the system shown in Figure 7.3(b), where one of the servers has been replaced with a faster server of service rate μ=1/2. N: high ½ ½µ=⅓  µ=⅓  (a) OriginalN: high ½½µ=½ µ=⅓  (b) “Improved” Figure 7.3. A simple system and the “improved” system. Question: How much does the throughput improve in going from Figure 7.3(a) to Figure 7.3(b)? How much does the mean response time improve? Answer: Neither throughput nor mean response time changes. This is because we are only looking at the high Nregime, which is dominated by Dmax, andDmaxhas not changed. Yes, this is counterintuitive. We examine this result more carefully in Exercise 7.2. For now, let’s continue with our discussion . . . Important Observations Looking at the asymptotic bounds, we make the following observations: 7.4more modiﬁcation analysis examples 119 rThe knee of the XandE[R]curves occurs at some point N, which we denote byN∗, where N∗=D+E[Z] Dmax. Question: What does N∗represent? Answer: N∗represents the point beyond which there must be some queueing in the system ( E[R]>D ). rFor ﬁxed N>N∗, to get more throughput, one must decrease Dmax. To get lower response time, one must similarly decrease Dmax. Other changes will be largely ineffective. rTo expand on the previous item, let us suppose we decrease some other Di, likeDnext tomax. What happens? The heavy load asymptote in both XandE[R] does not change, so performance for N/greatermuchN∗does not change. Performance for N/lessmuchN∗will improve a little because Dwill drop. For the graph of Xversus N, when Ddecreases, the light-load asymptote will get a little steeper (better). For the graph of E[R]versus N, when Ddecreases, the light-load asymptote will get a little lower (better). Question: What happens if E[Z]goes to zero (the batch case)? Answer: N∗decreases, meaning that the domination of Dmaxoccurs with fewer jobs in the system. Summary: To summarize, the device corresponding to Dmaxis the bottleneck device . The bottleneck device is the key limiting factor to improving system per- formance. Improving other devices will have little effect. The ﬁrst step in improving system performance is to identify the bottleneck device. 7.4 More Modiﬁcation Analysis Examples Simple Example Refer to the system in Figure 7.4, with N=2 0 , andE[Z]=5 . Now consider the following two systems: N = 10 CPU Disk Figure 7.4. Simple closed system. 1. System A looks like Figure 7.4withDcpu=4.6andDdisk=4.0. 2. System B looks like Figure 7.4withDcpu=4.9andDdisk=1.9(a slightly slower CPU and a much faster disk). 120 modiﬁcation analysis: “what-if” for closed systems Question: Which system has higher throughput? Answer: N∗ A=D+E[Z] Dmax=13.6 4.6<3andN∗ B=11.8 4.9<3.S oN/greatermuchN∗for both sys- tems. Thus System Awins, because it has a lower Dmax. Harder Example The following measurements were obtained for an interactive system2: rT= 650 seconds (the length of the observation interval) rBcpu= 400 seconds rBslowdisk = 100 seconds rBfastdisk= 600 seconds rC=Ccpu= 200 jobs rCslowdisk =2,000jobs rCfastdisk=2 0,000jobs rE[Z]=1 5 seconds rN=2 0 users The above are typically easy-to-measure quantities. In this example, we examine four possible improvements (modiﬁcations) – hence the name “modiﬁcation analysis.” 1. Faster CPU: Replace the CPU with one that is twice as fast. 2. Balancing slow and fast disks: Shift some ﬁles from the fast disk to the slow disk, balancing their demand. 3. Second fast disk: Buy a second fast disk to handle half the load of the busier existing fast disk. 4. Balancing among three disks plus faster CPU: Make all three improvements together: Buy a second fast disk, balance the load across all three disks, and also replace the CPU with a faster one. To evaluate these modiﬁcations, we need to derive the following quantities. Note that we sometimes drop the expectation symbols around a random variable when it isobvious that they are implied. rDcpu=Bcpu/C= 400 sec/200jobs=2.0sec/job rDslowdisk =Bslowdisk/C= 100 sec/200jobs=0.5sec/job rDfastdisk=Bfastdisk/C= 600 sec/200jobs=3.0sec/job rE[Vcpu]=Ccpu/C= 200 visits/200jobs=1visit/job rE[Vslowdisk]=Cslowdisk/C=2,000visits/200job=1 0 visits/job rE[Vfastdisk]=Cfastdisk/C=2 0 ,000visits/200job= 100 visits/job rE[Scpu]=Bcpu/C cpu= 400 sec/200visits=2.0sec/visit rE[Sslowdisk]=Bslowdisk/C slowdisk = 100 sec/2,000visits=.05sec/visit rE[Sfastdisk]=Bfastdisk/C fastdisk= 600 sec/20,000visits=.03sec/visit 2Just as most fairy tales start with “once upon a time,” most performance analysis problems begin with “the following measurements were obtained.” 7.4more modiﬁcation analysis examples 121 Now let’s examine the four possible modiﬁcations: 1. Faster CPU: Originally, Dmax=3sec/job, D=5.5,N∗=20.5 3≈7/lessmuchN. Dcpu→1sec/job does not change Dmax=3sec/job. Notice that N∗hardly changes at all. The fast disk is the bottleneck. We can never get more than 1job done every 3seconds on average. 2. Balancing slow and fast disks: Shift some ﬁles from the fast disk to the slow disk, balancing their demand. To do this we need that Vslow+Vfast= 110 as originally butSslow·Vslow=Sfast·Vfastbecause we are balancing the demand. Solving this system of linear equations yields the new demands Dslow=Dfast= 2.06.N o w , Dmax=2.06sec/job, although Dincreases slightly because some ﬁles have been moved from the fast disk to the slow disk. 3. Second fast disk: We keep Dslow=0.5, the same as before. However, we buy a second fast disk to handle half the load of the original fast disk. So now Dfast1=Dfast2=1.5sec/job . Thus our new Dmaxis 2.0 sec/job (the CPU becomes the bottleneck). 4. Balancing among three disks plus faster CPU: We now make the CPU faster and balance load across all three disks, so Vslow+Vfast1+Vfast2= 110 . Sslow·Vslow=Sfast1·Vfast1=Sfast2·Vfast2. Solving these simultaneous equations yields: Ddisk1=Ddisk2=Ddisk3=1.27.S o Dmax=1.27, since we cut Dcputo 1 already. A graph of the results is shown in Figure 7.5. Assuming Nis not too small, we conclude the following: rChange 1 is insigniﬁcant. rChanges 2 and 3 are about the same, which is interesting because change 2 was achieved without any hardware expense. rChange 4 yields the most dramatic improvement. 234 1X N1 23 4E[R] N Figure 7.5. Throughput and response time versus N, showing the effects of four possible improvements from the harder example, where the improvements are labeled 1, 2, 3, and 4.",7005
7.5 Comparison of Closed and Open Networks. 7.6 Readings. 7.7 Exercises,"122 modiﬁcation analysis: “what-if” for closed systems Concluding Remarks The salient features of modiﬁcation analysis are that (i) it is easy and computation- ally feasible; (ii) it does not rely on any assumptions about the distribution of theservice time, the interarrival time, or the scheduling order used for serving jobs; and (iii) although it only yields bounds, if Nis sufﬁciently far from N∗these bounds are all we need to analyze proposed changes. 7.5 Comparison of Closed and Open Networks The asymptotic bounds in this chapter were for closed networks. Question: Why don’t they make sense for open networks? Answer: Because they are not asymptotic bounds in the open case. For open networks, it is still true that X≤1/D max. For example, if jobs require 3seconds of service on average, there is no way that we can complete more than 1 job every 3 seconds on average. However, we already know that X=λ,s o1/D maxis an upper bound on X, but not necessarily a tight upper bound. Thus, our corresponding bound on E[R]for largeNis also not tight. However, the lessons of this chapter will still be true in the open network case if the outside arrival rate is high enough that Xis close to 1/D max: Alleviate the bottleneck device. As an interesting example of the difference between closed and open networks, consider Figure 7.3. In the closed network shown, it did not help to speed up only one of the two devices (under probabilistic routing). However, consider the same network now in the form of an open network. The mean response time, E[T], will certainly improve by speeding up just one of the two devices. 7.6 Readings A few years ago, one of the smart, industrious students studying this material in my class, Eno Thereska, decided that operational laws might actually be important forreal computer systems design (unimaginable.). So he got together with another smart student who had also taken the class, Dushyanth Narayanan, and they wrote a paper [175] on self-predicting storage systems. This led to a series of papers, all dealing with predictions possible via operational laws, and eventually to Eno’s Ph.D. thesis on how operational laws can be applied to storage performance prediction [ 174]. Eno and Dushyanth continue to leverage operational laws today. That’s it. Time to throw on that suit and go make some money. 7.7 Exercises 7.1 Outside Arrival Rates – Open Networks Consider an open network consisting of two devices. Packets arrive to device 1 from outside with rate r1jobs/sec. Packets arrive to device 2 from outside with 7.7exercises 123 rater2=1 0 jobs/sec. Assume 30 percent of the packets completing service at device 1 will next queue up at device 2 (the rest leave the system). Assume 50 percent of the packets completing service at device 2 will next queue up at device 1 (the rest leave the system). The mean service time at device 1 is E[S1]=.1sec. The mean service time at device 2 is E[S2]=.05sec. (a) In this network, how high can we make r1? (b) When r1is maximized, what is the utilization of device 2? 7.2 Open versus Closed Consider the system in Figure 7.6. Suppose that server 2 is replaced by one exactly twice as fast. Server 1 Server 2N = 6 ½ ½µ=⅓  µ= Figure 7.6. The system prior to improvement. (a) Does this replacement result in signiﬁcant improvement in the mean re- sponse time of the network? Explain via operational laws. (b) Explain your answer to (a) by showing a time-line of where the jobs are at each step, both before and after the replacement. To do this you will need to make the problem deterministic, so you should assume that the servicetime at each server is a constant and that jobs alternately go to server 1 and2. This is not meant to be a proof, just an explanation of what is going on. Make sure that you extend your time-line long enough that the average response time becomes clear. (c) Given that the replacement has been made, is there any further modiﬁcation you would propose to improve the mean response time in the closed system that does not involve spending more money? By how much would yourmodiﬁcation improve performance? (d) If the above system were an open system, would the replacement improve the mean response time? Prove your answer. ( Note: we do not expect you to know how to determine mean response time in an open system yet, but you can still come up with a proof.) 7.3 Modiﬁcation Analysis Marty is running his database as a closed interactive system with N=5 0 users. Each user submits a screenful of data to the database (her “job”) to process, waits until she gets back an answer from the system, spends E[Z]=1 0 seconds entering a new screenful of data (think time), and then submits that new job tothe database. This process repeats ad inﬁnitum. 124 modiﬁcation analysis: “what-if” for closed systems Marty realizes that his system’s CPU utilization and his disk utilization are both high. He considers two modiﬁcations to his database to increase throughput.The ﬁrst is to buy a second CPU (new CPUs on the market run at twice the speed of old ones) and divide the CPU load among the old CPU and the new one according to some optimal split. The second is to buy a second disk (newdisks on the market run at three times the speed of old ones) and divide the disk load among the old disk and the new one according to some optimal split. You obtain the following measurements of Marty’s original system: rC= 100 (number of jobs that completed during the observation period) rCCPU= 300 (number of completions at the CPU during observation) rCdisk= 400 (number of completions at the disk during observation) rBCPU= 600 sec (time that the CPU was busy during observation) rBdisk=1,200sec (time that the disk was busy during observation) Your job is to answer two questions: 1. Assuming that the new disk and new CPU are equally priced, which should Marty buy to increase throughput? 2. Assuming that he chooses to buy the new disk (CPU), how should he opti- mally split requests between the old disk (CPU) and the new one? Work this out for whichever device you chose. 7.4 More Practice with Modiﬁcation Analysis – from [ 117] Consider an interactive system with a CPU and two disks. The following mea- surement data was obtained by observing the system: robservation interval =17 minutes rmean think time =12 seconds rnumber of complete transactions during observation interval =1,600 rnumber of completions at CPU =1,600 rnumber of fast disk accesses =32,000 rnumber of slow disk accesses =12,000 rCPU busy time =1,080 seconds rfast disk busy time =400 seconds rslow disk busy time =600 seconds (a) Give asymptotic bounds on throughput and response time as a function of the number of terminals. (b) Now consider the following modiﬁcations to the system: 1. Move all ﬁles to the fast disk. 2. Replace the slow disk by a second fast disk.3. Increase the CPU speed by 50 percent (with the original disks).4. Increase the CPU speed by 50 percent and balance the disk load across the two fast disks. For each of these four modiﬁcations, compute and graph the effects on the original system. Explain in words the effect when the multiprogramming level, N, is small and when Nis large. 7.7exercises 125 7.5 Proportional Power – based on [ 69] In the world of power distribution, one reasonable approximation is that the power that is allocated to a machine is proportional to the speed at which that machine can run. In this problem we assume that, if a machine is allocated power w, then that machine processes jobs at speed wjobs/sec. Consider a closed batch system with two servers and Nusers, where Nis assumed to be high. Assume that each job, with probability p, is routed to server 1 for processing and, with probability 1−p, is routed to server 2. It may help to look at Figure 7.6here. You are given a total power budget W, which you need to distribute between the two machines. You can choose any way of dividing the power budget W between the two machines, and you can also choose any value you want for p, the routing probability. (a) What choice for dividing Wand for picking pwill maximize the throughput of your system? (b) Suppose that Nwas small. Would your answer still be the same? If so, explain why. If not, derive the optimal strategy. 7.6 Minimizing Mean Slowdown In Exercise 6.7, we saw that the RS algorithm does not minimize mean slowdown on every arrival sequence. We have also seen that the SRPT algorithm does not minimize mean slowdown. In this problem either ﬁnd an algorithm thatminimizes mean slowdown or prove that no online algorithm can minimize mean slowdown on every arrival sequence (an online algorithm is one that does not know future arrivals).",8691
Part IV From Markov Chainsto Simple Queues,"PART IV From Markov Chains to Simple Queues Part IVintroduces both discrete-time Markov chains (referred to as DTMCs) and continuous-time Markov chains (referred to as CTMCs). These allow us to model systems in much greater detail and to answer distributional questions, such as “What is the probability that there are kjobs queued at server i?” Markov chains are extremely powerful. However, only certain problems can be modeled via Markov chains. These are problems that exhibit the Markovian property, which allows the future behavior to be independent of all past behavior. Chapter 8introduces DTMCs and the Markovian property. We purposely defer the more theoretical issues surrounding ergodicity, including the existence of a limiting distribution and the equivalence between time averages and ensemble averages, toChapter 9. Less theoretically inclined readers may wish to skim Chapter 9during a ﬁrst reading. Chapter 10considers some real-world examples of DTMCs in computing today, including Google’s PageRank algorithm and the Aloha (Ethernet) protocol. Thischapter also considers more complex DTMCs that occur naturally and how generatingfunctions can be used to solve them. Next we transition to CTMCs. Chapter 11discusses the Markovian property of the Exponential distribution and the Poisson process, which make these very applicable to CTMCs. Chapter 12shows an easy way to translate all that we learned for DTMCs to CTMCs. Chapter 13applies CTMC theory to analyzing the M/M/1 single-server queue and also covers the PASTA property. CTMCs will be used extensively in Part Vto analyze multi-server systems. 127",1624
8.1 Discrete-Time versus Continuous-Time Markov Chains,"CHAPTER 8 Discrete-Time Markov Chains Let’s review what we already know how to do at this point. Closed Systems For closed systems, we can approximate and bound the values of throughput, X, and the expected response time, E[R]. The approximations we have developed are independent of the distribution of service times of the jobs, but require that the system isclosed . When the multiprogramming level, N, is much higher than N∗,w eh a v ea tight bound on XandE[R]. Also, when N=1, we have a tight bound. However, for intermediate values of N, we can only approximate XandE[R]. Open Systems For open systems, we cannot do very much at all yet. Consider even a single queue. If we knew E[N], then we could calculate E[T], but we do not yet know how to compute E[N]. Markov chain analysis is a tool for deriving the above performance metrics and in fact deriving a lot more. It will enable us to determine not only the mean number of jobs, E[Ni], at server iof a queueing network, but also the full distribution of the number of jobs at the server. All the chapters in Parts IVandVwill exploit the power of Markov chain analysis. It is important, however, to keep in mind that not all systems can readily be modeled using Markov chains. We will see that, in queueing networks where the service timesat a server are Exponentially distributed and the interarrival times of jobs are also Exponentially distributed, the system can often be exactly modeled by a Markov chain.This is true because the Exponential distribution has the Markovian property (a.k.a.memoryless property), meaning that the remaining time until a service completes ora new job arrives is independent of how long we have waited so far. Properties of theExponential distribution are covered in Chapter 11. The same holds for Geometrically distributed interarrival times and service times, where jobs arrive or complete with some ﬁxed probability at each time step, independent of the past. All of this will become more clear after we deﬁne discrete-time Markov chains in this chapter. By contrast, other workload distributions do not have the Markovian property, and thus are harder to model via a Markov chain. In many cases, however, even these non-Markovian workloads can be approximated by mixtures of Exponential distributions, and hence still lend themselves to Markov chain analysis, as explained in Chapter 21. 129",2387
8.3 Examples of Finite-State DTMCs,"130 discrete-time markov chains Markov chains are extremely powerful and are used to model problems in computer science, statistics, physics, biology, operations research, and business – you nameit. They are used extensively in machine learning, computer science theory, and inall areas of computer system modeling (analysis of networking protocols, memorymanagement protocols, server performance, capacity provisioning, disk protocols, etc.).Markov chains are also very common in operations research, including supply-chainmanagement and inventory management. As we study Markov chains, be on the lookout for Markov chains in your own work and the world around you. They are everywhere. 8.1 Discrete-Time versus Continuous-Time Markov Chains We now cover Markov chains in depth, starting with Discrete-Time Markov Chains(DTMCs). In a DTMC, the world is broken up into synchronized time steps. An event(arrival or departure) can only occur at the end of a time step. This property makesDTMCs a little odd for modeling computer systems. However, there are many other problems that are well modeled by DTMCs. In Continuous-Time Markov Chains (CTMCs) events can happen at any moment in time. This makes CTMCs convenient for modeling systems. Note: Solving Markov chains typically requires solving large systems of simultaneous equations. We therefore recommend that readers take the time to familiarize themselveswith the three M’s: Matlab, Mathematica, and Maple. The latter two are particularlyuseful in that they allow symbolic computation. 8.2 Deﬁnition of a DTMC Astochastic process is simply a sequence of random variables. Deﬁnition 8.1 ADTMC (discrete-time Markov chain) is a stochastic process {Xn,n=0,1,2,...}, where Xndenotes the state at (discrete) time step nand such that,∀n≥0,∀i, j, and∀i0,...,i n−1, P{Xn+1=j|Xn=i, Xn−1=in−1,...,X 0=i0}=P{Xn+1=j|Xn=i} =Pij(by stationarity) , where Pijis independent of the time step and of past history. The ﬁrst equality in the deﬁnition of a DTMC indicates the application of the Markovian property. Deﬁnition 8.2 The Markovian Property states that the conditional distribution of any future state Xn+1, given past states X0,X1,...,Xn−1, and given the present stateXn, is independent of past states and depends only on the present state Xn. 8.3examples of finite-state dtmcs 131 The second equality in the deﬁnition of a DTMC follows from the “stationary” property, which indicates that the transition probability is independent of time. Deﬁnition 8.3 The transition probability matrix associated with any DTMC is a matrix, P, whose (i, j)th entry, Pij, represents the probability of moving to state j on the next transition, given that the current state is i. Observe that the transition probability matrix, P, might have inﬁnite order, if there are inﬁnitely many states. Also observe that by deﬁnition,/summationtext jPij=1,∀i, because, given that the DTMC is in state i, it must next transition to some state j. We begin this chapter by focusing on DTMCs with a ﬁnite number of states ,M. Later in the chapter, we generalize to DTMCs with an inﬁnite number of states. In this chapter, we do notdiscuss issues of ergodicity. Speciﬁcally, we do not dwell on questions of the existence of limiting probabilities. We simply assume that there exists some limiting probability of being in each state of the chain (to be deﬁned soon), andwe defer all discussion of the existence of these limits to Chapter 9. 8.3 Examples of Finite-State DTMCs We start with a few examples of some simple Markov chains to illustrate the key concepts. More involved and interesting examples are saved for the exercises. 8.3.1 Repair Facility Problem A machine is either working or in the repair center. If it is working today, then there isa 95 percent chance that it will be working tomorrow. If it is in the repair center today, thenthere is a 40 percent chance that it will be working tomorrow. We are interested in questionslike “what fraction of time does my machine spend in the repair shop?” Question: Describe the DTMC for the repair facility problem. Answer: There are two states, “Working” and “Broken,” where “Broken” denotes that the machine is in repair. The transition probability matrix is P=/bracketleftbiggWB W0.95 0.05 B0.40 0.60/bracketrightbigg . The Markov chain diagram is shown in Figure 8.1. 0.6 0.950.05 0.4W orkin g Broken Figure 8.1. Markov chain for repair facility problem. 132 discrete-time markov chains Question: Now suppose that after the machine remains broken for 4 days, the machine is replaced with a new machine. How does the DTMC diagram change? Answer: The revised DTMC is shown in Figure 8.2. 0.05 0.40.4 0.410.6 0 0.95Broken Day 1W orkin g 00.6 0.6 Broken Day 2Broken Day 4Broken Day 3 Figure 8.2. Markov chain for repair facility problem with 4-day limit. 8.3.2 Umbrella Problem An absent-minded professor has two umbrellas that she uses when commuting from home to ofﬁce and back. If it rains and an umbrella is available in her location, shetakes it. If it is not raining, she always forgets to take an umbrella. Suppose that it rains with probability peach time she commutes, independently of prior commutes. Our eventual goal is to determine the fraction of commutes during which the professor gets wet.1 Question: What is the state space? Hint: You can model this with three states. Answer: The states track the number of umbrellas available at the current location, regardless of what this current location is. The DTMC is shown in Figure 8.3. The transition probability matrix is P=⎡ ⎣00 1 01−pp 1−pp 0⎤ ⎦. p 1–p1.0 1–pp Figure 8.3. DTMC for umbrella problem. 8.3.3 Program Analysis Problem A program has three types of instructions: CPU instructions (C), Memory instructions (M), and User interaction instructions (U). In analyzing the program, we note that 1The umbrella example is borrowed from Bertsekas & Gallager [ 18].",5903
8.4 Powers of P n-Step Transition Probabilities,"8.4powers of P:n-step transition probabilities 133 a C instruction with probability 0.7is followed by another C instruction, but with probability 0.2is followed by an M instruction and with probability 0.1is followed by a U instruction. We also note that an M instruction with probability 0.1is followed by another M instruction, but with probability 0.8is followed by a C instruction, and with probability 0.1is followed by a U instruction. Finally, a U instruction, with probability 0.9is followed by a C instruction, and with probability 0.1is followed by an M instruction. In the exercises for this chapter and the next, we answer questions like, “What is the fraction of C instructions?” and “What is the mean length of the instruction sequencebetween consecutive M instructions?” For now, we simply note that the program canbe represented as a Markov chain with the transition probability matrix, P: P=⎡ ⎣CMU C0.70.20.1 M0.80.10.1 U0.90.10⎤ ⎦ 8.4 Powers of P:n-Step Transition Probabilities LetPn=P·P···P, multiplied ntimes. We will use the notation Pn ijto denote (Pn)ij. Question: What does Pn ijrepresent? Answer: To answer this, we ﬁrst consider two examples. Umbrella Problem Consider the umbrella problem from before where the chance of rain on any given day isp=0.4. We then have P=⎡ ⎣001 00.60.4 0.60.40⎤ ⎦,P5=⎡ ⎣.06.30.64 .18.38.44 .38.44.18⎤ ⎦,P30=⎡ ⎣.230.385.385 .230.385.385 .230.385.385⎤ ⎦. Observe that all the rows become the same . Note also that, for all the above powers, each row sums to 1. Repair Facility Problem Now, consider again the simple repair facility problem, with general transition proba- bility matrix P: P=/bracketleftbigg 1−aa b1−b/bracketrightbigg ,0<a< 1,0<b< 1 134 discrete-time markov chains You should be able to prove by induction that Pn=/bracketleftBiggb+a(1−a−b)n a+ba−a(1−a−b)n a+b b−b(1−a−b)n a+ba+b(1−a−b)n a+b/bracketrightBigg . lim n→∞Pn=/bracketleftBiggb a+ba a+b b a+ba a+b/bracketrightBigg . Question: Again, all rows are the same. Why? What is the meaning of the row? Hint: Consider a DTMC in state i. Suppose we want to know the probability that it will be in state jtwo steps from now. To go from state ito state jin two steps, the DTMC must have passed through some state kafter the ﬁrst step. Below we condition on this intermediate state k: For an M-state DTMC, as shown in Figure 8.4, P2 ij=M−1/summationdisplay k=0Pik·Pkj =Probability that after 2 steps we will be in state j, given that we are in state inow. ij Pij =2 Figure 8.4. P2 ij. Likewise, the n-wise product can be viewed as Pn ij=M−1/summationdisplay k=0Pn−1 ikPkj =Probability of being in state jinnsteps, given we are in state inow. Limiting Probabilities We now move on to looking at the limit. Consider the (i, j)th entry of the power matrix Pnfor large n: lim n→∞Pn ij=/parenleftBig lim n→∞Pn/parenrightBig ij This quantity represents the limiting probability of being in state jinﬁnitely far into the future, given that we started in state i. Question: So what is the limiting probability of having 0umbrellas? Answer: According to P30, it is 0.23.",3081
8.6 The Stationary Distribution Equals the Limiting Distribution,"8.5stationary equations 135 Question: The fact that the rows of limn→∞Pnare all the same is interesting because it says what? Answer: It says that the starting state ( i) does not matter. Deﬁnition 8.4 Let πj= lim n→∞Pn ij. πjrepresents the limiting probability that the chain is in state j(independent of the starting state i). For an M-state DTMC, with states 0,1,...,M−1, /vectorπ=(π0,π1,...,π M−1),whereM−1/summationdisplay i=0πi=1 represents the limiting distribution of being in each state. Important Note: As deﬁned, πjis a limit. Yet it is not at all obvious that the limit πj exists. It is also not obvious that /vectorπrepresents a distribution (i.e.,/summationtext iπi=1), although this latter part turns out to be easy to see (Exercise 8.2). For the rest of this chapter, we assume that the limiting probabilities exist. In Chapter 9we look at the existence question in detail. Question: So what is the limiting probability that the professor gets wet? Answer: The professor gets wet if both (i) the state is 0, that is there are zero umbrellas in the current location; and (ii) it is raining. So the limiting probability that the professor gets wet on any given day is π0·p=( 0.23)(0.4) =.092. Question: Can you see why the limiting probability of having 1 umbrella is equal to the limiting probability of having 2 umbrellas? Answer: This is a little tricky. Notice that if we are only looking at the DTMC from the perspective of 1 versus 2 umbrellas, then the chain becomes symmetric. The collapsed chain is shown in Figure 8.5. 1–p 1–pp p Figure 8.5. Compressed umbrella problem. 8.5 Stationary Equations Question: Based only on what we have learned so far, how do we determine πj= limn→∞Pn ij? Answer: We take the transition probability matrix Pand raise it to the nth power for some large nand look at the jth column, any row. 136 discrete-time markov chains Question: Multiplying Pby itself many times sounds quite onerous. Also, it seems one might need to perform a very large number of multiplications if the Markov chain is large. Is there a more efﬁcient way? Answer: Yes, by solving stationary equations, given in Deﬁnition 8.5. Deﬁnition 8.5 A probability distribution /vectorπ=(π0,π1,...,π M−1)is said to be stationary for the Markov chain if /vectorπ·P=/vectorπandM−1/summationdisplay i=0πi=1. These equations are referred to as the stationary equations . Deﬁnition 8.5says that /vectorπ is stationary if M−1/summationdisplay i=0πiPij=πj,∀jandM−1/summationdisplay i=0πi=1. (8.1) Question: What does the left-hand-side (LHS) of the ﬁrst equation in ( 8.1) represent? Answer: The LHS represents the probability of being in state jone transition from now, given that the current probability distribution on the states is /vectorπ. So equation ( 8.1) says that if we start out distributed according to /vectorπ, then one step later our probability of being in each state will still follow distribution /vectorπ. Thus from then on we will always have the same probability distribution on the states. Hence we call the distribution “stationary.” 8.6 The Stationary Distribution Equals the Limiting Distribution The following theorem relates the limiting distribution to the stationary distribution for a ﬁnite-state DTMC. Speciﬁcally, the theorem says that for a ﬁnite-state DTMC, thestationary distribution obtained by solving ( 8.1) is unique and represents the limiting probabilities of being in each state, assuming these limiting probabilities exist. Theorem 8.6 (Stationary distribution =Limiting distribution) Given a ﬁnite- state DTMC with Mstates, let πj= lim n→∞Pn ij>0 be the limiting probability of being in state jand let /vectorπ=(π0,π1,...,π M−1),whereM−1/summationdisplay i=0πi=1 be the limiting distribution. Assuming that the limiting distribution exists, then /vectorπis also a stationary distribution and no other stationary distribution exists. 8.6the stationary distribution equals the limiting distribution 137 Proof We will prove two things about the limiting distribution /vectorπ. 1.We will prove that {πj,j=0,1,2,...,M−1}is a stationary distribution. Hence at least one stationary distribution exists. 2.We will prove that any stationary distribution must be equal to the limiting distribution. Throughout, {πj,j=0,1,2,...,M−1}is used to refer to the limiting distribution. Part 1: Proof that {πj,j=0,1,2,...,M−1}is a stationary distribution: πj= lim n→∞Pn+1 ij= lim n→∞M−1/summationdisplay k=0Pn ik·Pkj=M−1/summationdisplay k=0lim n→∞Pn ikPkj=M−1/summationdisplay k=0πkPkj Hence /vectorπsatisﬁes the stationary equations. Part 2: Proof that any stationary distribution must equal the limiting distribution: Let/vectorπ/primebe any stationary probability distribution. As usual, /vectorπrepresents the limiting probability distribution. We will prove that /vectorπ/prime=/vectorπ, and speciﬁcally that π/prime j=πj. Let’s assume that we start at time 0with distribution /vectorπ/prime. Then π/prime j=P{X0=j}=P{Xn=j}because /vectorπ/primeis stationary. So π/prime j=P{Xn=j},∀n =M−1/summationdisplay i=0P{Xn=j|X0=i}·P{X0=i},∀n =M−1/summationdisplay i=0Pn ijπ/prime i,∀n. So π/prime j= lim n→∞π/prime j= lim n→∞M−1/summationdisplay i=0Pn ijπ/prime i=M−1/summationdisplay i=0lim n→∞Pn ijπ/prime i=M−1/summationdisplay i=0πjπ/prime i=πjM−1/summationdisplay i=0π/prime i=πj. Note that we were allowed to pull the limit into the summation sign in both parts because we had ﬁnite sums ( Mis ﬁnite). One more thing: In the literature you often see the phrase “Consider a stationary Markov chain,” or “Consider the following Markov chain in steady state ...” Deﬁnition 8.7 A Markov chain for which the limiting probabilities exist is said to bestationary or in steady state if the initial state is chosen according to the stationary probabilities.",5785
8.9 Infinite-State Stationarity Result,"138 discrete-time markov chains Summary: Finding the Limiting Probabilities in a Finite-State DTMC : By Theorem 8.6, given the limiting distribution {πj,j=0,1,2,...,M−1} exists, we can obtain it by solving the stationary equations /vectorπ·P=/vectorπ andM−1/summationdisplay i=0πi=1 where /vectorπ=(π0,π1,...,π M−1). 8.7 Examples of Solving Stationary Equations 8.7.1 Repair Facility Problem with Cost Consider again the repair facility problem represented by the ﬁnite-state DTMC shown here: 0.6 0.950.05 0.4W orkin g Broken We are interested in the following type of question. Question: The help desk is trying to ﬁgure out how much to charge me for maintaining my machine. They ﬁgure that it costs them $300 every day that my machine is in repair. What will my annual repair bill be? To answer this question, we ﬁrst derive the limiting distribution /vectorπ=(πW,πB)for this chain. We solve the stationary equations to get /vectorπas follows: /vectorπ=/vectorπ·P,whereP=/parenleftbigg .95.05 .4.6/parenrightbigg πW+πB=1 This translates to the following equations: πW=πW·.95 +πB·.4 πB=πW·.05 +πB·.6 πW+πB=1 Question: What do you notice about the ﬁrst two equations above? Answer: They are identical. In general, if /vectorπ=/vectorπ·Presults in Mequations, only M−1of these will be linearly independent. Fortunately, the last equation above (the 8.8inﬁnite-state dtmcs 139 normalization condition) is there to help us out. Solving, we get πW=8 9andπB=1 9. By Theorem 8.6, the stationary distribution also represents the limiting probability distribution. Thus my machine is broken 1 out of every 9 days on average. The expected daily cost is1 9·300 = $33.33 (with an annual cost of more than $12,000). 8.7.2 Umbrella Problem Consider again the umbrella problem with probability pof rain each day. Before, we raised the transition probability matrix Pto the nth power to get the limiting probabilities, in the case where p=0.4. Now let’s use the stationary equations to obtain the limiting probabilities for general p. p 1–p1.0 1–pp We solve the following stationary equations to get the limiting probabilities: π0=π2·(1−p) π1=π1·(1−p)+π2·p π2=π0·1+π1·p π0+π1+π2=1 Their solution is π0=1−p 3−p.π 1=1 3−p.π 2=1 3−p. Question: Suppose the probability of rain is p=0.6. What fraction of days does the professor get soaked? Answer: The professor gets wet if she has zero umbrellas and it is raining: π0·p= 0.4 2.4·0.6=0.1. Not too bad. 8.8 Inﬁnite-State DTMCs So far we have only talked about ﬁnite -state DTMCs with Mstates. Now we move on to inﬁnite-state DTMCs. For a Markov chain with an inﬁnite number of states, one can still imagine a transition probability matrix, P, although the matrix has inﬁnite order. We denote the limiting probability distribution on the states by /vectorπ=(π0,π1,π2,...)where πj= lim n→∞Pn ij and∞/summationdisplay j=0πj=1. 140 discrete-time markov chains Inﬁnite-state Markov chains are common in modeling systems where the number of customers or jobs is unbounded, and thus the state space is unbounded. 8.9 Inﬁnite-State Stationarity Result We have seen that for a ﬁnite-state DTMC, if the limiting distribution exists, then thelimiting distribution and stationary distribution are equivalent (Theorem 8.6). The same result holds for inﬁnite-state DTMCs. Theorem 8.8 (Stationary distribution =Limiting distribution) Given an inﬁnite-state DTMC, let πj= lim n→∞Pn ij>0 be the limiting probability of being in state jand let /vectorπ=(π0,π1,π2,...)where∞/summationdisplay i=0πi=1 be the limiting distribution. Assuming that the limiting distribution exists, then /vectorπis also a stationary distribution and no other stationary distribution exists. Proof We will prove two things about this limiting distribution, assuming it exists. 1.We will prove that {πj,j=0,1,2,...}is a stationary distribution. Hence at least one stationary distribution exists. 2.We will prove that any stationary distribution must be equal to the limiting distribution. Part 1: Proof that {πj,j=0,1,2,...}is a stationary distribution: πj= lim n→∞Pn+1 ij= lim n→∞∞/summationdisplay k=0Pn ik·Pkj (8.2) Question: If we could interchange the limit and sum at this point, what would we know aboutπj? Answer: We would know that πjis a stationary distribution – we would be done with Part 1. Unfortunately, we cannot in general interchange the limit and sum when the sum is inﬁnite. So what we need to do in these types of proofs is convert the inﬁnite sum to aﬁnite sum, make the switch, and then convert back to an inﬁnite sum ...carefully. πj= lim n→∞Pn+1 ij = lim n→∞∞/summationdisplay k=0Pn ikPkj 8.9inﬁnite-state stationarity result 141 ≥lim n→∞M/summationdisplay k=0Pn ikPkj,∀M =M/summationdisplay k=0lim n→∞Pn ikPkj,∀M =M/summationdisplay k=0πkPkj,∀M So ∀M, π j≥M/summationdisplay k=0πkPkj ⇒πj≥lim M→∞M/summationdisplay k=0πkPkj ⇒πj≥∞/summationdisplay k=0πkPkj. We are almost there. We would like to prove that the above inequality is actually an equality. Suppose, by contradiction, ∃lsuch that πl>∞/summationdisplay k=0πkPkl. Let’s consider/summationtext∞ j=0πj: ∞/summationdisplay j=0πj>∞/summationdisplay j=0/parenleftBigg∞/summationdisplay k=0πkPkj/parenrightBigg =∞/summationdisplay k=0∞/summationdisplay j=0πkPkj=∞/summationdisplay k=0πk·1=1 Yet this says that the sum of the limiting probabilities is strictly greater than 1, which is impossible and hence a contradiction. So we have shown that πj=∞/summationdisplay k=0πkPkj. (8.3) Part 2: Proof that any stationary distribution must equal the limiting distribution: Let/vectorπ/primebe any stationary probability distribution. As usual, /vectorπrepresents the limiting probability distribution. Our goal is to prove that π/prime j=πj,∀j. Let’s assume that we start at time 0with distribution /vectorπ/prime. Then π/prime j=P{X0=j}=P{Xn=j}because π/prime jis stationary.",5837
8.10 Solving Stationary Equations in Infinite-State DTMCs,"142 discrete-time markov chains So π/prime j=P{Xn=j} =∞/summationdisplay i=0P{Xn=j|X0=i}·P{X0=i} =∞/summationdisplay i=0Pn ijπ/prime i =M/summationdisplay i=0Pn ijπ/prime i+∞/summationdisplay i=M+1Pn ijπ/prime i(for any integer M). Observing that 0≤Pn ij≤1, we now apply the sandwich theorem to the above equa- tion, which will allow us to prove that π/prime jis bounded above and below by πj. M/summationdisplay i=0Pn ijπ/prime i≤π/prime j≤M/summationdisplay i=0Pn ijπ/prime i+∞/summationdisplay i=M+1π/prime i lim n→∞M/summationdisplay i=0Pn ijπ/prime i≤lim n→∞π/prime j≤lim n→∞M/summationdisplay i=0Pn ijπ/prime i+ lim n→∞∞/summationdisplay i=M+1π/prime i M/summationdisplay i=0πjπ/prime i≤π/prime j≤M/summationdisplay i=0πjπ/prime i+∞/summationdisplay i=M+1π/prime i πjM/summationdisplay i=0π/prime i≤π/prime j≤πjM/summationdisplay i=0π/prime i+∞/summationdisplay i=M+1π/prime i lim M→∞πjM/summationdisplay i=0π/prime i≤lim M→∞π/prime j≤lim M→∞πjM/summationdisplay i=0π/prime i+ lim M→∞∞/summationdisplay i=M+1π/prime i πj≤π/prime j≤πj Thus we have shown that π/prime j=πjas desired. 8.10 Solving Stationary Equations in Inﬁnite-State DTMCs We have seen that to obtain the limiting probability distribution /vectorπ, assuming that it exists, we only need to solve the stationary equations. Yet there are an inﬁnite number of stationary equations. Let’s see how we solve them. Consider the example of an unbounded queue (see Figure 8.6). Imagine jobs (or customers) arriving at a server. These jobs queue up at the server. The server works on 8.10 solving stationary equations in inﬁnite-state dtmcs 143 the job at the head of the queue, and when it ﬁnishes that job, it moves on to the next job. This server never drops jobs, but just allows them to queue. Figure 8.6. Illustration of a server with unbounded buffer. Suppose at every time step, with probability p=1 40one job arrives, and independently, with probability q=1 30one job departs. Note that during a time step, we might have both an arrival and a transmission, or neither. We will be interested in answering questions like, what is the average number of jobs in the system? To answer this question, we model the problem as a DTMC with an inﬁnite number of states: 0,1,2,..., representing the number of jobs at the router. Let r=p(1−q)= 29 1200ands=q(1−p)=39 1200, where r<s . Figure 8.7shows the Markov chain for our problem. 0r sr sr s1−r−s 1−r−s 1−r−s 00 1 2 1−r 3 Figure 8.7. DTMC for a server with unbounded queue. Here the transition probability matrix is inﬁnite. P=⎛ ⎜⎜⎜⎜⎜⎝1−rr 00 ... s1−r−sr 0 ... 0 s 1−r−s r ... 00 s 1−r−s ... ...............⎞ ⎟⎟⎟⎟⎟⎠ The stationary equations look like this: π0=π0(1−r)+π1s π1=π0r+π1(1−r−s)+π2s π2=π1r+π2(1−r−s)+π3s π3=π2r+π3(1−r−s)+π4s ... π0+π1+π2+π3+···=1 144 discrete-time markov chains Question: How are we going to solve this inﬁnite number of equations? Hint: Observe that the ﬁrst equation can be rewritten as π1=r sπ0. Can you use this to express π2in terms of π0? Answer: If we substitute the above expression for π1into the second stationary equa- tion, we can express π2in terms of π0as well: π2=/parenleftBigr s/parenrightBig2 π0 We can now substitute the expression for π2into the third stationary equation, to express π3in terms of π0as well: π3=/parenleftBigr s/parenrightBig3 π0 We can now make a general “guess”: πi=/parenleftBigr s/parenrightBigi π0 Question: How do we verify that this guess is correct? Answer: To verify your guess, you need to show that it satisﬁes the stationary equations: πi=πi−1r+πi(1−r−s)+πi+1s /parenleftBigr s/parenrightBigi π0=/parenleftBigr s/parenrightBigi−1 π0r+/parenleftBigr s/parenrightBigi π0(1−r−s)+/parenleftBigr s/parenrightBigi+1 π0s√ Question: OK, but we still do not know π0. How can we determine π0? Answer: To determine π0, we make use of the fact that/summationtext iπi=1. This says that π0·/parenleftbigg 1+r s+/parenleftBigr s/parenrightBig2 +/parenleftBigr s/parenrightBig3 +···/parenrightbigg =1 π0·/parenleftbigg1 1−r s/parenrightbigg =1 π0=1−r s. So πi=/parenleftBigr s/parenrightBigi ·/parenleftBig 1−r s/parenrightBig .",4100
8.11 Exercises,"8.11 exercises 145 Question: What is the average number of jobs at the server? Answer: LetNdenote the number of jobs at the server. Then E[N]=π0·0+π1·1+π2·2+π3·3+... Question: Can we get a closed-form expression for E[N]? Answer: Yes. It will help to deﬁne ρ=r s for shorthand. Then πi=ρi(1−ρ). E[N]=1ρ(1−ρ)+2ρ2(1−ρ)+3ρ3(1−ρ)+... =( 1−ρ)ρ/parenleftbig 1+2ρ+3ρ2+4ρ3+.../parenrightbig =( 1−ρ)ρd dρ/parenleftbig 1+ρ+ρ2+ρ3+ρ4+.../parenrightbig =( 1−ρ)ρd dρ/parenleftbigg1 1−ρ/parenrightbigg =( 1−ρ)ρ·1 (1−ρ)2 =ρ 1−ρ(8.4) Wow. That is a really simple formula. We will see this again . . . For our example ρ=29 39andE[N]=2.9. So on average there are about 3jobs in the system. 8.11 Exercises 8.1 Solving for Limiting Distribution Consider the program analysis problem from Section 8.3.3 . Determine the limiting distribution, (πC,πM,πU), by solving the stationary equations. 8.2 Powers of Transition Matrix Given any ﬁnite-state transition matrix, P, prove that for any integer n,Pn maintains the property that each row sums to 1. 8.3 Doubly Stochastic Matrix A doubly stochastic matrix is one in which the entries in each row sum up to 1 and the entries in each column sum up to 1. Suppose you have a ﬁnite-stateMarkov chain whose limiting probabilities exist and whose transition matrix is doubly stochastic. What can you prove about the stationary distribution of thisMarkov chain? 146 discrete-time markov chains 8.4 Gambling Game Dafna starts out with zero dollars. Every day she gains a dollar with prob- ability p, stays put with probability s, or loses all her money (goes broke) with probability b, where p+s+b=1. Dafna plays the game forever. Use a DTMC to determine the stationary probability that Dafna has idollars. What happens to your solution when s=0? What is Dafna’s long-run expected money? 8.5 Randomized Chess In chess, a rook can move either horizonally within its row (left or right) or vertically within its column (up or down) any number of squares. In an 8×8 chess board, imagine a rook that starts at the lower left corner of a chess board. At each move, a bored child decides to move the rook to a random legal location(assume that the “move” cannot involve staying still). Let Tdenote the time until the rook ﬁrst lands in the upper right corner of the board. Compute E[T] andVar(T). 8.6 Threshold Queue We deﬁne a threshold queue with parameter Tas follows: When the number of jobs is <T, then the number of jobs decreases by 1 with probability 0.4 and increases by 1 with probability 0.6at each time step. However, when the number of jobs increases to >T, then the reverse is true, and the number of jobs increases by 1 with probability 0.4and decreases by 1 with probability 0.6 at each time step, as shown in Figure 8.8. 0.4 0.60.4 0.4 0.6 0.6q0.6 0.40.60.2 0.40 0.4 4 2 3 1 q0.6 0.40 0.4 05 Figure 8.8. Markov chain for threshold queue with T=3. (a) Assume that the limiting probabilities exist. Use the stationary equations to derive the limiting probability distribution as a function of T, for arbitrary threshold T. (b) Compute the mean number of jobs, E[N], in a threshold queue as a function ofT. (c) What happens to E[N]whenT=0? Does this answer make sense? 8.7 Naval Battle Analysis In the game Axis & Allies, the outcome of a two-sided naval battle is decided by repeated rolling of dice. Until all ships on at least one side are destroyed, each side rolls one (six-sided) die for each of its existing ships. The die rollsdetermine casualties inﬂicted on the opponent; these casualties are removedfrom play and cannot ﬁre (roll) in subsequent rounds. There are two types ofships: battleships and destroyers. For a battleship, a die roll of four or lower is scored as a “hit.” For a destroyer, a die roll of three or lower is scored as a “hit.” 8.11 exercises 147 It takes two hits (not necessarily in the same round) to destroy a battleship and only one hit to destroy a destroyer (side note: battleships are twice as expensiveas destroyers). The defender gets to decide to which ship to allocate the hit; weassume the defender chooses intelligently. If two destroyers engage a battleshipin a naval battle, what is the probability that the destroyers win? How about thebattleship? [Hint: You will need to raise a matrix to a large power.]",4275
Chapter 9 Ergodicity Theory. 9.2 Finite-State DTMCs,"CHAPTER 9 Ergodicity Theory 9.1 Ergodicity Questions At this point, in our discussion of DTMCs, we have deﬁned the notion of a limiting probability of being in state j: πj= lim n→∞(Pn)ij, typically written πj= lim n→∞Pn ij, where the limiting distribution is /vectorπ=(π0,π1,π2,π3,...)with∞/summationdisplay i=0πi=1. We have also deﬁned the notion of a stationary distribution ,/vectorπ, as a distribution that satisﬁes /vectorπ·P=/vectorπ and∞/summationdisplay i=0πi=1 or, equivalently, πj=∞/summationdisplay i=0πiPij and∞/summationdisplay i=0πi=1. We also proved two theorems (Theorem 8.6for ﬁnite-state chains and Theorem 8.8 for inﬁnite-state chains) that said that, assuming the limiting distribution exists, then the limiting distribution is a stationary distribution and no other stationary distribution exists. These theorems are key because they allow us to simply solve the stationaryequations to get the limiting distribution. Question: Is πj= lim n→∞Pn ija time average or an ensemble average? Answer: Ensemble. When we raise matrix Pto thenth power, we are averaging over all sample paths of length n(i.e., all possible choices for the ﬁrst hop, 2nd hop, 3rd hop, etc.). πjis deﬁned to be the limiting probability of being in state j. By contrast, we can deﬁne pjto be the time-average fraction of time spent in state j, averaged over one inﬁnitely long sample path. In the previous chapter we looked at how to ﬁnd πj, assuming it exists. However, we did not spend much time on questions like the following: 1.Under what conditions does the limiting distribution exist? 2.How does the limiting probability of being in state j,πj, compare with the long-run time-average fraction of time spent in state j,pj? 148 9.2finite-state dtmcs 149 3.What can we say about the mean time between visits to state j, and how is this related to πj? This entire chapter is devoted to these and other theoretical questions, all related to the notion of ergodicity (you can look ahead to Deﬁnition 9.24, where ergodicity is deﬁned). We end with a brief discussion of time-reversibility, which gives a faster method for computing limiting probabilities in the case of certain Markov chains. Unsurprisingly, most of the questions just presented are simpler to think about in the context of a ﬁnite-state Markov chain. Hence, we start in Section 9.2by discussing these issues for a ﬁnite-state chain. After that, we move on to inﬁnite-state chains. This is a highly theoretical chapter. The reader may wish to forgo the proofs during a ﬁrst reading and return later for a more in-depth reading. 9.2 Finite-State DTMCs 9.2.1 Existence of the Limiting Distribution We dive right into the question of existence of the limiting distribution, with a few examples. Question: What is an example of a valid two-state transition matrix for which πjdoes not exist?Answer: P=/bracketleftbigg 01 10/bracketrightbigg The problem is that this chain is periodic ; speciﬁcally, a given state is only visited every other time step. Observe that πj= lim n→∞Pn jjdoes not exist, although limn→∞P(2n) jj does exist.",3086
Chapter 9 Ergodicity Theory. 9.2 Finite-State DTMCs,"Question: What is the time average, pj, for the above chain? Answer: The above chain is a valid DTMC, so there has to be some fraction of time spent in each state. In this case, the time averages are obvious: p0=1 2=p1. Question: Does this chain have a stationary distribution? Answer: Yes, the stationary distribution does exist. To see this, let’s set up the stationary equations /vectorπ·P=/vectorπ: π0=π1 π1=π0 π0+π1=1 Solving these, we get /vectorπ=(1 2,1 2)=(p1,p2). Examples like this one illustrate why we need to pay attention to the conditions under which all these kinds of averages agree. Let’s consider another example. 150 ergodicity theory Question: Does the following transition matrix have limiting probabilities? P=⎡ ⎢⎢⎣001 /21/2 10 0 0 01 0 001 0 0⎤ ⎥⎥⎦ Answer: No, this too is periodic – it is just a little harder to see. Deﬁnition 9.1 The period of state jis the greatest common divisor (GCD) of the set of integers n, such that Pn jj>0. A state is aperiodic if it has period 1. A chain is said to be aperiodic if all of its states are aperiodic. So aperiodicity is clearly necessary for the limiting probabilities to exist. However in an aperiodic Markov chain, it could still turn out that the limiting probabilities depend on the start state, whereas we want πj= lim n→∞Pn ijto be the same for all i. If we also want the limiting probabilities to be independent of the start state, we need one more condition, known as irreducibility , which says that from any state one can get to any other state. Deﬁnition 9.2 Statejisaccessible from state iifPn ij>0for some n>0. States iandjcommunicate ifiis accessible from jand vice versa. Deﬁnition 9.3 A Markov chain is irreducible if all its states communicate with each other. Question: Why is irreducibility needed for the limiting probabilities to be independent of the start state? Answer: Without irreducibility, one might, for example, have the situation where the Markov chain consists of two disconnected components – thus the limiting probabilities would depend on which component contains the start state. Question: What is a simple transition matrix that is notirreducible? Answer: The identity matrix. Question: Do you think that aperiodicity and irreducibility are enough to guarantee the existence of the limiting distribution? Answer: As we see in Theorem 9.4, for a ﬁnite-state DTMC, aperiodicity and ir- reducibility are all that is needed to ensure that the limiting probabilities exist, are positive, sum to 1, and are independent of the starting state. This is very convenient,because it is often easy to argue that a DTMC is aperiodic and irreducible. Theorem 9.4 Given an aperiodic, irreducible, ﬁnite-state DTMC with transition matrixP,a sn→∞ ,Pn→L, where Lis a limiting matrix all of whose rows are the same vector, /vectorπ. The vector /vectorπhas all positive components, summing to 1. 9.2finite-state dtmcs 151 Proof We are trying to show that Pnconverges to a matrix where all rows are the same. Speciﬁcally, we are trying to show that, for any j, thejth column of Pn converges to a vector of all constants. Let/vectorerepresent the column vector of the same dimension as P, whose jth component is1and whose remaining components are all 0.",3235
Chapter 9 Ergodicity Theory. 9.2 Finite-State DTMCs,"That is /vectore=⎛ ⎜⎜⎜⎜⎜⎜⎜⎜⎜⎜⎝0 ... 0 10 ... 0⎞ ⎟⎟⎟⎟⎟⎟⎟⎟⎟⎟⎠. We are trying to show that Pn·/vectore converges to a vector all of whose components are the same. The idea is to view Pn/vectore=P(...(P(P(P/vectore)))). Consider the innermost product P/vectore. Because Pis a matrix of probabilities, where each row sums to 1, the effect of multiplying /vectorebyPis to replace each component of /vectoreby a value that is a weighted average of all the components. In particular, the effect is to bring all the components of /vectorecloser together. That is, the difference between the maximum component and the minimum component should decrease. Here is an example of the effect of successive multiplications by P: P/vectore=⎛ ⎜⎝1 21 31 6 1 31 31 3 1 43 40⎞ ⎟⎠·⎛ ⎝0 10⎞ ⎠=⎛ ⎜⎝1 3 1 33 4⎞ ⎟⎠ P(P/vectore)=⎛ ⎜⎝1 21 31 6 1 31 31 3 1 43 40⎞ ⎟⎠·⎛ ⎜⎝1 3 1 33 4⎞ ⎟⎠=⎛ ⎝.40 .47 .33⎞ ⎠ LetMndenote the maximum component of Pn/vectoreand let mndenote the minimum component of Pn/vectore. We now claim that Mn−mn≤(1−2s)(Mn−1−mn−1) (9.1) where sis the smallest element in P. To see why ( 9.1) is true, consider the vector /vectory=Pn−1/vectore. By our deﬁnition, the maxi- mum component of /vectoryisMn−1and the minimum is mn−1. Now, if we multiply /vectorybyP 152 ergodicity theory (obtaining P/vectory=Pn/vectore), we are replacing each component of /vectoryby a weighted average of all the components of /vectory. Question: What is an upper bound on the largest possible component in P·/vectory? Answer: The largest possible weighted average is obtained if all but one of the elements of/vectoryareMn−1, with the remaining one being mn−1, where mn−1is weighted by the smallest value, s. An upper bound on the largest possible component of P·/vectoryis s·mn−1+( 1−s)·Mn−1. Question: What is a lower bound on the smallest possible component in P·/vectory? Answer: In the smallest weighted average, all but one of the elements of /vectoryaremn−1, with the remaining one being Mn−1, where Mn−1is weighted by the smallest value, s. Thus a lower bound on the smallest possible component of P·/vectoryis (1−s)·mn−1+s·Mn−1. Thus an upper bound on the greatest difference between the components in P/vectoryis s·mn−1+( 1−s)·Mn−1−(1−s)·mn−1−s·Mn−1 =( 1−2s)(Mn−1−mn−1). This proves our claim in ( 9.1). Finally, because s≤1 2(when M≥2), we see that the difference between the maximum and minimum elements of Pn/vectorecontinues to decrease as we continue to multiply by P, until eventually all elements are the same. The proof would now be complete except for a small hole . . . Question: Can you see the hole? Answer: Ifs=0, then the above argument does not result in convergence, because (1−2s)=1 . Question: How can this be ﬁxed? Hint: Even if Pcontains some zero elements, what do we know about Pnfor high enough n, given that Pis aperiodic and irreducible? Answer: Because Pis aperiodic and irreducible, there exists some n0such that, ∀n≥n0,Pnhas all positive elements. This follows from the Euclidean number property. [Here is a sketch: For any (j,j)entry, by aperiodicity, there are some powers xandysuch that PxandPyhave a positive (j,j)entry, where GCD(x, y)=1 . Hence, by the Euclidean number property, ∃n0(j,j)s.t.,∀n≥n0(j,j),ncan be expressed as a linear combination of xandywith non-negative coefﬁcients; hence, ∀n≥n0(j,j), there is a path of length nfromjtoj, and thus the (j,j)th entry of Pn is positive.",3396
Chapter 9 Ergodicity Theory. 9.2 Finite-State DTMCs,"Now repeat this argument for all (j,j)pairs (there are only a ﬁnite number). Finally, consider two arbitrary states iandj, where i/negationslash=j. By irreducibility there is somexs.t. there is a path from itojof length x. However, since we also know that 9.2finite-state dtmcs 153 ∀n≥n0(i, i)there is a path of length nfromitoi, it follows that ∀n≥n0(i, i)+x there is a path of length nfromitoj. Deﬁne n0(i, j)=n0(i,i)+x. Finally, deﬁne n0to be the maximum of all n0(i, j)values, over all iandj. Now, for all n≥n0,Pn has all positive elements.] To complete the proof, we now deﬁne P/prime=Pn0. Then Pn/vectore=(Pn0)n/n 0=(P/prime)n/n 0. Now repeat the argument in ( 9.1), except that the decrease by a factor of (1−2s)<1 occurs only every n0multiplications of P. However, because n/n 0→∞ asn→∞ , we still have an inﬁnite number of these decreases, meaning that (P/prime)n/n 0→L,asn→∞. To ﬁnish off the proof of the theorem, we note that by Exercise 8.2, all powers of P have the property that the components of each row sum to 1. Furthermore, because Pn0has all positive elements, and because multiplying by Ponly creates weighted averages, then P·Pn0still has all positive elements and so forth as we continue to multiply by P. Hence the limiting matrix Lwill still have all positive elements and will have the property that the components of each row sum to 1. Summary : We have proven that for any aperiodic, irreducible, ﬁnite-state Markov chain, the limiting probabilities exist. 9.2.2 Mean Time between Visits to a State Consider the mean time between visits to state j. It seems that this quantity should be related to the limiting probability of being in state j. Let’s see how. Consider an irreducible ﬁnite-state Markov chain with Mstates and transition matrixP. Deﬁnition 9.5 Letmijdenote the expected number of time steps needed to ﬁrst get to state j, given we are currently at state i. Likewise, let mjjdenote the expected number of steps between visits to state j. In Exercise 9.16, we will prove from ﬁrst principles that mjjis ﬁnite. Theorem 9.6 relates mjjtoπj. Theorem 9.6 For an irreducible, aperiodic ﬁnite-state Markov chain with transi- tion matrix P, mjj=1 πj where mjjis the mean time between visits to state jandπj= lim n→∞(Pn)ij. 154 ergodicity theory Proof By conditioning on the ﬁrst step, we have mij=Pij·1+/summationdisplay k/negationslash=jPik(1 +mkj) =1+/summationdisplay k/negationslash=jPikmkj (9.2) Likewise mjj=Pjj·1+/summationdisplay k/negationslash=jPjk(1 +mkj) =1+/summationdisplay k/negationslash=jPjkmkj (9.3) Let’s express ( 9.2) and ( 9.3) using matrix notation. All the matrices in this proof are of the same order as P, namely M×M. Imagine a matrix Mwhose (i,j)th entry ismij. For purposes of the proof, it will be convenient to express Mas a sum of two matrices M=D+N,whereDis a matrix whose entries are all zero, except for its diagonal entries: djj=mjj, andNis a matrix whose diagonal entries are all zero, but where Nij=mij,∀i/negationslash=j. Finally, let Ebe a matrix with allentries 1. Then by (9.2) and ( 9.3), we can write1 M=E+PN. (9.4) Rewriting ( 9.4), we have N+D=E+PN. (I−P)·N=E−D. Let/vectorπdenote the limiting probability distribution. We know that /vectorπexists because we have aperiodicity and irreducibility. Multiplying both sides by /vectorπ,w eh a v e /vectorπ·(I−P)·N=/vectorπ(E−D). (9.5) Question: What do we know about the left-hand side of ( 9.5)? Hint: Remember that /vectorπis also a stationary distribution. Answer: /vectorπP=/vectorπ ⇒/vectorπ(I−P)=/vector0 ⇒/vectorπ(I−P)N=/vector0 1To see this, observe that by ( 9.4), ∀i/negationslash=j, m ij=1+/summationdisplay kPikNkj=1+/summationdisplay k/negationslash=jPikNkj=1+/summationdisplay k/negationslash=jPikmkj which matches ( 9.2). mjj=1+/summationdisplay kPjkNkj=1+/summationdisplay k/negationslash=jPjkNkj=1+/summationdisplay k/negationslash=jPjkmkj which matches ( 9.3).",3904
9.3 Infinite-State Markov Chains,"9.3inﬁnite-state markov chains 155 Thus, we have from ( 9.5) /vector0=/vectorπ(E−D) ⇒/vectorπE=/vectorπD ⇒(1,1,...,1) = ( π0m00,π1m11,...,π M−1mM−1,M−1) ⇒πimii=1,∀i. 9.2.3 Time Averages So far, we have seen that, for a ﬁnite-state Markov chain, the limiting distribution, /vectorπ=(π0,π1,...,π M−1), when it exists, is equal to the unique stationary distribution. We have also seen that πj=1 mjj, where mjjis the mean time (number of steps) between visits to state j. We now consider pj, the fraction of time that the Markov chain spends in state j, along a given sample path. Question: What would you guess is the relationship between πjandpj, assuming that the limiting distribution exists? Answer: It seems pretty natural to believe that πj=pj. We prove this formally later in Theorem 9.28, where we show that pj=1 mjjwith probability 1(i.e., for almost every sample path). Because we also know that πj=1 mjj, it follows that, with probability 1, pj=πj. The formal argument requires renewal theory, which is described in Section 9.5.H o w - ever, intuitively, it should make sense that if the average time between visits to state j ismjj, then, during a long period of time t, we visit state japproximately x=t mjj times. Hence the proportion of time spent in state jduring time tisx t=t mjj·1 t =1 mjj. 9.3 Inﬁnite-State Markov Chains We now turn to inﬁnite-state Markov chains. These are far more difﬁcult to reason about than ﬁnite-state Markov chains, and it will take some time to even develop theterminology we need to discuss them. Consider the three inﬁnite-state DTMCs shown in Figure 9.1. Question: Which of these chains are aperiodic and irreducible? Answer: All of them. Question: Forﬁnite-state DTMCs that are aperiodic and irreducible, does a limiting distribution always exist? Answer: Yes, by Theorem 9.4. Question: Does a limiting distribution exist for all the chains in Figure 9.1? Answer: We will see that a limiting distribution exists only for the ﬁrst chain. For the ﬁrst chain, there is a well-deﬁned limiting probability of being in each state, and 156 ergodicity theory 3 1 2 0.6 0.5 0.5 0.5 0.1 0.1 0.10.50.4 0.4 0.4 0.4 4 3 1 2 0.5 0.4 0.4 0.4 0.1 0.1 0.10.40.5 0.5 0.5 0.5 4 3 1 2 0.50.5 0.5 0.5 0.5 0.5 0.5 0.5 0.54 Figure 9.1. Examples of positive recurrent, transient, and null-recurrent chains (looking from top to bottom). these probabilities sum to 1. For the other two chains, we will show that the limiting probability of being in each state is 0, and the limiting probabilities do not sum to 1; hence there does not exist a limiting distribution. The ﬁrst chain has a property called “positive recurrent.” The second chain is what we call “transient,” and the third chain is “null recurrent.” We explain all these terms in this chapter and how they relate to the existence of limiting distributions. Question: Intuitively, what is the problem with the second and third chains in Fig- ure9.1? Answer: The second chain can be viewed as an ocean, where the shore is at state 1. There is a drift away from shore. Given this drift, it is not obvious that we keep returning back to shore. There could be some point after which we never return to the shore. This same argument holds for any state kthat we call the “shore.” In the case of the third chain, it seems that we should return to each state, but it is not obvious howlong it will take to return.",3389
9.3 Infinite-State Markov Chains,"If the time between visits to a state is inﬁnite, then it seems that the limiting probability of being in the state should be zero. 9.3.1 Recurrent versus Transient Deﬁnition 9.7 fj=probability that a chain starting in state jever returns to state j. Deﬁnition 9.8 A state jis either recurrent or transient: rIffj=1, thenjis arecurrent state. rIffj<1, thenjis atransient state. 9.3inﬁnite-state markov chains 157 Question: What is the distribution of the number of visits to a transient state j? Answer: Every time we visit state jwe have probability 1−fjof never visit- ing it again. Hence the number of visits is distributed Geometrically with mean 1/(1−fj). Theorem 9.9 With probability 1, the number of visits to a recurrent state is inﬁnite. With probability 1, the number of visits to a transient state is ﬁnite. Proof If a state jis recurrent, then starting in state j, with probability 1we will visit jagain. Thus, repeating this argument, we see that with probability 1statejwill be visited an inﬁnite number of times. In contrast, if state jis transient, then every time we visit state j, there is some probability ( 1−fj) that we will never again visit j. Thus, with probability 1statejwill be visited a ﬁnite number of times. Theorem 9.10 E[# visits to state iinssteps|start in state i]=s/summationdisplay n=0Pn ii (9.6) E[Total # visits to state i|start in state i]=∞/summationdisplay n=0Pn ii (9.7) Proof E[Number visits to state iinssteps|X0=i] =E/bracketleftBiggs/summationdisplay n=0In|X0=i/bracketrightBigg ,where In=/braceleftbigg 1ifXn=i 0o.w. =s/summationdisplay n=0E[In|X0=i] =s/summationdisplay n=0P{Xn=i|X0=i} =s/summationdisplay n=0Pn ii The above proves ( 9.6). To get ( 9.7), we take the limit as s→∞ . So, combining Theorems 9.9and9.10, we have the following theorem.2 Theorem 9.11 If state iis recurrent, then/summationtext∞ n=0Pn ii=∞. If state iis transient, then/summationtext∞n=0Pn ii<∞. 2Theorem 9.11 is an application of the Borel-Cantelli lemma [ 57]. 158 ergodicity theory Theorem 9.12 If state iis recurrent and icommunicates with j,(i←→j), then jis recurrent. We start with the intuition for Theorem 9.12. Consider Figure 9.2. We know that we come back to iinﬁnitely many times. By the deﬁnition of “communicates,” every time we are in i, we have some probability of taking the road to j, and once we are in j, we have some probability of taking the road to i. So, for every visit to i, there’s some non-zero probability that we’ll also visit j. Therefore the number of visits to jis proportional to the number of visits to i. Because the number of visits to iis inﬁnite, so is the number of visits to j. Always come backRoad to j Road to ij i Figure 9.2. Proof of Theorem 9.12. Now for the formal proof. Proof We know that icommunicates with j. Thus, there exists an msuch that Pm ji>0and there exists nsuch that Pn ij>0. Now Pm+s+n jj≥Pm jiPs iiPn ij. (9.8) The right-hand side of ( 9.8) represents only some of the ways to go from jtojin m+n+ssteps, whereas the left-hand side represents all the ways.",3043
9.3 Infinite-State Markov Chains,"Summing both sides of ( 9.8) overs,w eh a v e /summationdisplay sPm+s+n jj≥/summationdisplay sPm jiPs iiPn ij=Pm jiPn ij/summationdisplay sPs ii=∞, where the last step is due to the fact that state iis recurrent. So ∞/summationdisplay t=0Pt jj≥∞/summationdisplay t=m+nPt jj=∞/summationdisplay s=0Pm+n+s jj =∞. Therefore state jis recurrent. Theorem 9.13 If state iis transient and icommunicates with j,(i←→j), then j is transient. 9.3inﬁnite-state markov chains 159 Proof This follows directly from the previous Theorem 9.12. Suppose by contradic- tion that state jis recurrent. Then because jandicommunicate, iis recurrent as well, which is a contradiction to the assumption. We have thus seen that in an irreducible Markov chain, either all states are transient, or all are recurrent. Theorem 9.14 For a transient Markov chain, lim n→∞Pn ij=0,∀j. Proof As we have seen, in a transient Markov chain there is some point after which we never visit state jagain. So the probability of being in state jafternsteps is zero asn→∞ . This holds for every state j. Theorem 9.15 If for a Markov chain πj= lim n→∞Pn ij=0,∀j, then ∞/summationdisplay j=0πj=0 so the limiting distribution does not exist. Proof This follows because we are adding a countable number of 0’s, which equals 0. Corollary 9.16 For a transient Markov chain the limiting distribution does not exist. Proof This follows immediately from Theorems 9.14 and9.15. In situations where the limiting probabilities are all 0, it seems hard to imagine that a stationary distribution exists. Theorem 9.17 states that, in agreement with our intuition, no stationary distribution exists. Theorem 9.17 Given an aperiodic, irreducible chain. Suppose that the limiting probabilities are all zero. That is, πj= lim n→∞Pn ij=0,∀j. Then the stationary distribution does not exist. Proof This proof follows very closely the structure of the proof of Theorem 8.8. Let/vectorπ/primebe any stationary probability distribution. As usual, /vectorπrepresents the limiting probability distribution. We are given that πj= lim n→∞Pn ij=0,∀j. Our goal is to prove that π/prime j=0,∀j. Observe that π/prime j=P{X0=j}=P{Xn=j}because π/prime jis stationary. 160 ergodicity theory So π/prime j=P{Xn=j} =∞/summationdisplay i=0P{Xn=j|X0=i}·P{X0=i} =∞/summationdisplay i=0Pn ijπ/prime i =M/summationdisplay i=0Pn ijπ/prime i+∞/summationdisplay i=M+1Pn ijπ/prime i(for any integer M). We now prove that π/prime jis bounded above by 0. By the previous equation, π/prime j≤M/summationdisplay i=0Pn ijπ/prime i+∞/summationdisplay i=M+1π/prime i lim n→∞π/prime j≤lim n→∞M/summationdisplay i=0Pn ijπ/prime i+ lim n→∞∞/summationdisplay i=M+1π/prime i π/prime j≤M/summationdisplay i=0πjπ/prime i+∞/summationdisplay i=M+1π/prime i π/prime j≤0+∞/summationdisplay i=M+1π/prime i Now taking the limit as M→∞ , the ﬁnal summation becomes zero, so π/prime j≤0as desired. 9.3.2 Inﬁnite Random Walk Example Consider the random walk shown in Figure 9.3, where at each step a gambler either gains a dollar (with probability p) or loses a dollar (with probability q=1−p).",3077
9.3 Infinite-State Markov Chains,"pppppp qqqqqq0 0–1 0 1 –2 2 Figure 9.3. Random walk. Because all states communicate, it follows from Theorems 9.12 and9.13 that either all states are transient or all are recurrent. Hence to determine whether the chain is recurrent or transient, it sufﬁces to look at state 0. To determine whether state 0is transient or recurrent, we invoke Theorem 9.11. Let V=∞/summationdisplay n=1Pn 00 9.3inﬁnite-state markov chains 161 denote the expected number of visits to state 0.I fVis ﬁnite, then state 0is transient. Otherwise it is recurrent. Since one cannot get from 0to0in an odd number of steps, it follows that V=∞/summationdisplay n=1P2n 00=∞/summationdisplay n=1/parenleftbigg 2n n/parenrightbigg pnqn(9.9) We now simplify this equation using Lavrov’s lemma. Lemma 9.18 (due to Misha Lavrov) Forn≥1, 4n 2n+1</parenleftbigg 2n n/parenrightbigg <4n(9.10) Proof By simple binomial expansion, 2n/summationdisplay k=0/parenleftbigg 2n k/parenrightbigg =( 1+1 )2n=22n=4n Since/parenleftBig2n n/parenrightBig is the largest term in the sum, it follows that it is bigger than the average term,4n/(2n+1 ) . However it is also smaller than the total sum, 4n. Substituting ( 9.10) into ( 9.9), we get that ∞/summationdisplay n=14n 2n+1pnqn<V <∞/summationdisplay n=14npnqn(9.11) If we substitute p=q=1 2into the left-hand side of ( 9.11), we get that V>∞/summationdisplay n=14n 2n+1·1 4n=∞/summationdisplay n=11 2n+1=∞ (9.12) If instead we assume p/negationslash=qand consider the right-hand side of ( 9.11), we get that V<∞/summationdisplay n=1(4pq)n<∞ (since 4pq <1) (9.13) Thus by ( 9.12) and ( 9.13) we see that V=/summationtext∞ n=1Pn 00is inﬁnite if and only if p=1 2. So the chain is recurrent if and only if p=1 2. We have thus proven Theorem 9.19. Theorem 9.19 The random walk shown in Figure 9.3is recurrent only when p=1 2 and is transient otherwise. 162 ergodicity theory Question: Recall that we deﬁned f0as the probability that the chain ever returns to state0. What do we know about f0for the random walk example? Answer: We know that when p=1 2, we should have f0=1. However, when p/negationslash=1 2, it should be the case that f0<1. Lemma 9.20 For the random walk shown in Figure 9.3, in the case where the chain is transient with rightward drift ( p>q ), we have that f0=2q<1. Proof This follows by conditioning. Let fijdenote the probability that we ever get to state jgiven that we start in state i. Thus, f00=f0. Then f0=qf−1,0+pf1,0. We will argue two things: 1.f−1,0=1 2.f1,0=q p Together these result in f0=qf−1,0+pf1,0=q+p·q p=2q. Thatf−1,0=1 should be clear from the fact that the chain has a rightward drift, so eventually we must get to state 0. It can also be seen by conditioning on the ﬁrst step as follows: f−1,0=qf−2,0+p=q(f−1,0)2+p and observing that f−1,0=1is a solution to the above equation, because q+p=1. The fact that f1,0=q/pcan be seen by conditioning on the ﬁrst step as follows: f1,0=q·1+p·f2,0=q+p·(f1,0)2 and observing that f1,0=q/pis a solution to the above equation, because q+p=1. 9.3.3 Positive Recurrent versus Null Recurrent Question: Is knowing that a chain is aperiodic, irreducible, and recurrent enough to guarantee the existence of the limiting distribution?",3208
9.3 Infinite-State Markov Chains,"Answer: No. What is required is “positive recurrence.” Deﬁnition 9.21 Recurrent Markov chains fall into two types: positive recurrent andnull recurrent . In a positive-recurrent MC, the mean time between recurrences (returning to same state) is ﬁnite. In a null-recurrent MC, the mean time between recurrences is inﬁnite. The following theorem is proven in Exercise 9.16. Theorem 9.22 If state iis positive recurrent and i←→j, then jis positive recurrent. If state iis null recurrent and i←→j, thenjis null recurrent. 9.3inﬁnite-state markov chains 163 Null-recurrent chains seem like an oxymoron: For a null-recurrent state j, the mean time between visits to state jis∞, and yet state jis visited an inﬁnite number of times. An example of a null-recurrent chain is the random walk shown in Figure 9.3with p=1 2. In the previous example we proved that this chain is recurrent. We now show that the mean time between visits to state 0is inﬁnite. Hence state 0is null recurrent, and, since all states communicate, by Theorem 9.22 all states are null recurrent. Theorem 9.23 For the symmetric random walk shown in Figure 9.3withp=1 2, the mean number of time steps between visits to state 0is inﬁnite. Proof The theorem can be proven in several ways. We present a very short argument here, but illustrate two more proofs in Exercises 9.11 and9.13.3We use the notation mi,jto denote the mean number of time steps until we visit state j, given that we are currently at state i. Our goal is to prove that m00is inﬁnite. We present a proof by contradiction. Assume that m00is ﬁnite. Then it follows that m1,0must be ﬁnite as well. This follows from the fact that m00=1 2m1,0+1 2m−1,0+1. Hence we cannot have m1,0being inﬁnity. Now that we know that m1,0is ﬁnite, we compute it by conditioning on the next state m1,0=1+1 2·0+1 2m2,0. (9.14) Now observe that m2,0=2m1,0 (9.15) because the mean time to go from 2 to 0 is the mean time to go from 2 to 1 plus the mean time to go from 1 to 0; and m2,1=m1,0because the chain is location-invariant. Hence ( 9.14) reduces to m1,0=1+1 2·0+1 2m2,0 =1+1 2·2m1,0(by9.15) m1,0=1+ m1,0. However, this contradicts the fact that m1,0is ﬁnite. 3The proof here is due to a student in my class, Ameya Velingker.",2235
9.4 Ergodic Theorem of Markov Chains,"164 ergodicity theory 9.4 Ergodic Theorem of Markov Chains Deﬁnition 9.24 Anergodic DTMC is one that has all three desirable properties: aperiodicity, irreducibility, and positive recurrence.4 Remark: For a ﬁnite-state DTMC, positive recurrence is a consequence of irreducibil- ity. This fact is proven in Exercise 9.16. Hence, for ﬁnite-state chains, aperiodicity and irreducibility sufﬁce for ergodicity. The Ergodic Theorem of Markov Chains (Theorem 9.25) tells us that for any ergodic DTMC, the limiting probabilities exist and are positive. Furthermore, for any state i, the limiting probability of being in state iis equal to the reciprocal of the mean time between visits to state i. The Ergodic Theorem of Markov Chains is saying the same thing that we saw in Theorems 9.4and 9.6. However, those theorems were restricted to ﬁnite -state chains. The fact that we now allow for inﬁnite-state chains makes the proof much more technical, and thus we defer the proof to Section 9.10. Theorem 9.25 (Ergodic Theorem of Markov Chains) Given a recurrent, aperi- odic, irreducible DTMC, πj= lim n→∞Pn ijexists and πj=1 mjj,∀j. For a positive recurrent, aperiodic, irreducible DTMC, πj>0,∀j. Proof Deferred to Section 9.10. Question: The second sentence in Theorem 9.25 follows immediately from the ﬁrst one. Why is this? Answer: For a positive-recurrent chain, mjjis ﬁnite, so1 mjj>0. Remark: It may not seem obvious that the πj’s as deﬁned by Theorem 9.25 actually sum up to 1, when mjjis ﬁnite. This fact will be proven shortly in Corollary 9.30. Let us now consider what Theorem 9.25 says about a null-recurrent Markov chain. 4Note that in some books, ergodicity is deﬁned as the equivalence of the ensemble- and and time-average proba- bilities, where the three properties of aperiodicity, irreducibility, and positive recurrence are then consequences of this equivalence. 9.4ergodic theorem of markov chains 165 Theorem 9.26 For an aperiodic, null-recurrent Markov chain, the limiting prob- abilities are all zero and the limiting distribution and stationary distribution do not exist. Proof For a null-recurrent chain, the mean time between visits to each state is inﬁnite (mii=∞). Hence, by Theorem 9.25, all the limiting probabilities are zero. Thus, by Theorem 9.15, a limiting distribution does not exist, and by Theorem 9.17, neither does the stationary distribution. We now state a single theorem that summarizes all that we have seen so far regardinglimiting distributions and stationary distributions. Theorem 9.27 (Summary Theorem) An irreducible, aperiodic DTMC belongs to oneof the following two classes: Either (i)All the states are transient, or all are null recurrent. In this case πj= limn→∞Pn ij=0,∀j, and there does NOT exist a stationary distribution. or (ii)All states are positive recurrent. Then the limiting distribution /vectorπ= (π0,π1,π2,...)exists, and there is a positive probability of being in each state. Here πj= lim n→∞Pn ij>0,∀i is the limiting probability of being in state j. In this case /vectorπis a stationary distribution, and no other stationary distribution exists. Also, πjis equal to 1 mjj, where mjjis the mean number of steps between visits to state j. Proof We know by Theorems 9.22 and9.13 that transience, null recurrence, and positive recurrence are class properties, meaning that in an irreducible Markov chain all the states are of the same one type. If all states are transient, then by Theorem 9.14 all the limiting probabilities are zero, and by Theorem 9.15, these limiting probabilities add up to 0, so no limiting distribution exists. If all states are null recurrent, then by Theorem 9.26 all the limiting probabilities are zero, and again by Theorem 9.15, no limiting distribution exists. Whenever the limiting probabilities are all zero, it follows by Theorem 9.17 that the stationary probabilities are all zero as well, so no stationary distribution exists. If all states are positive recurrent, then by Theorem 9.25, the limiting probabilities are all positive and equal to1 mjj, and by Corollary 9.30 (coming up soon) they sum to 1, so the limiting distribution exists. Furthermore, by Theorems 8.6and8.8, the limiting distribution is also equal to the unique stationary distribution.",4251
9.5 Time Averages,"166 ergodicity theory Important Remark :What is nice about this summary theorem is that it tells us that we never have to actually determine whether our DTMC is positive recurrent. It sufﬁces to simply check for irreducibility and aperiodicity and then solve thestationary equations. If these stationary equations yield a distribution, then thatdistribution is also the limiting probability distribution. So life is good when our DTMC is irreducible and aperiodic. One question that youmight be wondering about is what happens when our DTMC is either not irreducibleor is periodic. Can we still solve the stationary equations? If the solution still exists,what does it represent? Section 9.8answers these questions. We see, for example, that for periodic chains, when the solution to the stationary equations exists, it does not represent the limiting distribution, but rather it represents the long-run time-averagefraction of time spent in each state. Time averages are the topic of our nextsection. 9.5 Time Averages Question: Recall that πj= lim n→∞Pn ijis an ensemble average. How might we deﬁne pj, the time-average fraction of time spent in state j(i.e., the “long-run” proportion of time spent in state j)? Answer: LetNj(t)be the number of times that the Markov chain enters state jby timet(ttransitions). The time-average fraction of time that the Markov chain spends in state jis then pj= lim t→∞Nj(t) t=Time-average fraction of time in state j. Observe that pjis actually deﬁned as an average over a single sample path, ω.W h a t we would like to say is (i) that this average converges with probability 1 (meaning it converges along “almost” all the sample paths), (ii) that it always converges to thesame quantity, and (iii) that this quantity is positive. Theorem 9.28 tells us that when the chain is positive recurrent and irreducible, all these good things happen. Theorem 9.28 For a positive recurrent, irreducible Markov chain, with probabil- ity1, pj= lim t→∞Nj(t) t=1 mjj>0, where mjjis the (ensemble) mean number of time steps between visits to state j. Importantly, the existence of pjdoes notrequire aperiodicity. Before we prove Theorem 9.28, let’s discuss some of its consequences. 9.5time averages 167 Question: Where have we seen the term1 mjjbefore? Answer: This is the same expression that was equal to the limiting probability πj; see Theorem 9.27(ii). This observation leads to Corollary 9.29. Corollary 9.29 For an ergodic DTMC, with probability 1, pj=πj=1 mjj where pj= lim t→∞Nj(t) tandπj= lim n→∞Pn ijandmjjis the (ensemble) mean number of time steps between visits to state j. Corollary 9.30 For an ergodic DTMC, the limiting probabilities sum to 1(i.e.,/summationtext∞ j=0πj=1). Proof This is an immediate consequence of the fact that pj=πjfrom Corollary 9.29: Because the pj’s sum up to 1(as the Markov chain must be in some state at every moment of time), it follows that the πj’s must likewise sum up to 1. The remainder of this section is devoted to proving Theorem 9.28. We start with some preliminary theorems that we will need to invoke. Theorem 9.31 reviews the Strong Law of Large Numbers (SLLN) from Theorem 5.5. Theorem 9.31 (SLLN) LetX1,X2,... be a sequence of independent, identically distributed random variables each with mean E[X].L e tSn=/summationtextn i=1Xi. Then with probability 1, lim n→∞Sn n=E[X]. With SLLN in hand, we are ready to deﬁne a renewal process. Deﬁnition 9.32 Arenewal process is any process for which the times between events are i.i.d. random variables with a distribution F. An example of a renewal process is shown in Figure 9.4. LetN(t)denote the number of events by time t. Then, we have the following theorem. Events time X2 X3 X1 Figure 9.4. A renewal process. Xi∼F,f o ra l l i.",3759
9.6 Limiting Probabilities Interpreted as Rates,"168 ergodicity theory Theorem 9.33 (Renewal Theorem) For a renewal process, if E[X]is the mean time between renewals, we have lim t→∞N(t) t=1 E[X]with probability 1. (9.16) Proof The basic idea in this proof is to apply SLLN, which gives us the convergence on all sample paths (w.p.1). Let Snbe the time of the nth event. Then we have, ∀t, SN(t)≤t< S N(t)+1 SN(t) N(t)≤t N(t)<SN(t)+1 N(t). But, SN(t) N(t)=/summationtextN(t) i=1Xi N(t)−→E[X]ast→∞ w.p.1. (SLLN) Likewise, SN(t)+1 N(t)=SN(t)+1 N(t)+1·N(t)+1 N(t)−→E[X]ast→∞ w.p.1. (SLLN) So, by the sandwich theorem, we have that t N(t)−→E[X]w.p.1. ⇒N(t) t−→1 E[X]ast→∞ w.p.1. Proof (Theorem 9.28)To prove Theorem 9.28, we simply apply the Renewal theo- rem, where we consider each time that the Markov chain enters state jto be a renewal. Because the Markov chain is irreducible, we know that it will eventually reach state j. Because the chain is positive recurrent, we know that mjj<∞, where mjjis the mean number of steps between visits to state j. From the Renewal theorem we know pj= lim t→∞Nj(t) t=1 mjjw.p.1, and since mjj<∞, we have that pj>0. 9.6 Limiting Probabilities Interpreted as Rates So far we have seen that, for an ergodic Markov chain, πi=limiting probability Markov chain is in state i =long-run proportion of time process is in state i. Now we observe that πiPij=“rate” of transitions from state ito state j. 9.6limiting probabilities interpreted as rates 169 To see this, observe that the DTMC is in state iforπifraction of all time steps. Furthermore, Pijfraction of those time steps will result in the chain next moving to j. Hence, for πiPijfraction of all time steps, the DTMC is in state i, and its next step is to go to state j. Thus, if we look over ttime steps (let tbe large), then πiPijttransitions will have their start point in iand their end point in j. Dividing by t, we see that the rate of transitions (number of transitions per time step) that have their start point in i and their end point in jisπiPij. Question: What does/summationtext jπiPijrepresent? Answer: This is the total rate of transitions out of state i, including possibly returning right back to state i(if there are self-loops in the chain). Question: What does/summationtext jπjPjirepresent? Answer: This is the total rate of transitions into state i, from any state, including possibly from state i(if there are self-loops in the chain). Recall the stationary equation for state i: πi=/summationdisplay jπjPji We also know that πi=πi/summationtext jPij=/summationtext jπiPij. Thus we have πi=/summationdisplay jπiPij=/summationdisplay jπjPji. (9.17) Yet this says that the stationary equations are simply relating the total rate of transitions out of state iwith the total rate of transitions into state i: Total rate leaving state i=Total rate entering state i Question: Why does it make sense that the total rate of transitions leaving state i should equal the total rate of transitions entering state i? Answer: Every time a transition leaves state i, we cannot have another transition leave stateiuntil some transition enters state i. Hence the number of transitions leaving state iis within 1 of the number of transitions entering state i. Now the rate of transitions leaving state iis the total number of transitions over a long period of time, t, divided by that time t. Since tis large, the difference of 1in the number of transitions leaving stateiand the number entering state ivanishes when divided by t, and hence the rates are equal. We can also rewrite the stationary equations, equivalently, as follows by ignoring self-loops: /summationdisplay j/negationslash=iπiPij=/summationdisplay j/negationslash=iπjPji (9.18) Equation ( 9.18) follows by subtracting πiPiifrom both sides of the stationary equa- tion ( 9.17). The set of equations ( 9.18) over all states iare often referred to as",3856
9.8 When Chains Are Periodic or Not Irreducible,"170 ergodicity theory balance equations because they equate the rate that we leave state ito go to a state other than i, with the rate that we enter state ifrom a state other than i.A s you can see, balance equations are mathematically equivalent to stationary equations – hence we can always simply ignore the self-loops and write balance equations. Balanceequations can also be applied to a set of states as well as to a single state. For example,if a Markov chain is divided into two sets of states – call these SandSc(hereSc denotes the complement of S) – then we can equate the rate of transitions (the “ﬂux”) fromStoScwith the rate of transitions from SctoS. Question: Why does it make sense that the total ﬂux from StoScshould equal that fromSctoS? Answer: The argument is identical to what we observed for a single state. Every time a transition takes us from StoSc, we have left the states in S. We therefore cannot have another transition from StoScuntil we reenter the states in S, but this requires a transition from SctoS. 9.7 Time-Reversibility Theorem You might be wondering at this point whether we can simplify the stationary/balance equations even further. In some cases we can. The following theorem is useful becauseit simpliﬁes the balance equations. We will revisit time-reversibility later in the book. Theorem 9.34 (Time-reversible DTMC) Given an aperiodic, irreducible Markov chain, if there exist x1,x2,x3,...s.t.,∀i, j, /summationdisplay ixi=1 andxiPij=xjPji, then 1.πi=xi(thexi’s are the limiting probabilities). 2.We say that the Markov chain is time-reversible. Proof xiPij=xjPji ⇒/summationdisplay ixiPij=/summationdisplay ixjPji ⇒/summationdisplay ixiPij=xj/summationdisplay iPji ⇒/summationdisplay ixiPij=xj Now, because we also know that/summationtext ixi=1, we know that the xj’s satisfy the stationary equations. Hence, because by Theorem 9.27 the solution to the stationary equations is unique, we know that xj=πj, the limiting probability of being in state j. 9.8when chains are periodic or not irreducible 171 This leads to the following simpler algorithm for determining the πj’s: 1.First try time-reversibility equations (between pairs of states): xiPij=xjPji,∀i,jand/summationtext ixi=1. 2.If you ﬁnd xi’s that work, that is great. Then we are done: πi=xi. 3.If not, we need to return to the regular stationary (or balance) equations. The exercises at the end of this chapter help elucidate which chains are time-reversible and which are not. Example: Three Types of Equations Consider the Markov chain depicted in Figure 9.5. 1–p 0p qp qpp qqr r r 00 1 2 3 Figure 9.5. A very familiar Markov chain. Regular Stationary Equations: πi=πi−1p+πir+πi+1qand/summationdisplay iπi=1 These are messy to solve. Balance Equations: πi(1−r)=πi−1p+πi+1qand/summationdisplay iπi=1 These are a little nicer, because we are ignoring self-loops, but still messy to solve. Time-Reversibility Equations: πip=πi+1qand/summationdisplay iπi=1 These are much simpler to solve. 9.8 When Chains Are Periodic or Not Irreducible From the Summary Theorem (Theorem 9.27) we know that if a DTMC is both irre- ducible and aperiodic, and if we can ﬁnd a solution to the stationary equations, then that solution is the unique limiting distribution for the Markov chain. However, what can be said when we have a chain that is not irreducible or is not aperiodic?",3369
9.8 When Chains Are Periodic or Not Irreducible,"What does the solution to the stationary equations (or the time-reversibility equations) representin this case? This section answers these questions. 9.8.1 Periodic Chains We show that analyzing periodic chains is not a problem. Speciﬁcally, we show in Theorem 9.36 that for any periodic, irreducible positive-recurrent chain the stationary 172 ergodicity theory distribution, /vectorπ, still exists. However /vectorπdoes not represent the limiting distribution, but rather the long-run time-average proportion of time spent in each state. We also prove a Summary Theorem for irreducible, periodic chains, Theorem 9.37, which is reminiscent of the Summary Theorem for irreducible, aperiodic chains (Theorem 9.27). Theorem 9.37 states that for an irreducible, periodic chain, if a stationary distribution, /vectorπ, exists, then the chain must be positive recurrent; hence, by Theorem 9.36, it follows that/vectorπis also the time-average distribution. We start with a lemma.5 Lemma 9.35 In an irreducible DTMC, all states have the same period. Proof Suppose states iandjcommunicate, where the period of iispand the period ofjisq. Since iandjcommunicate, there is a path of length, say, d1, from itojand some path of length, say, d2, from jtoi. Joining these gives a loop from iback to iof length d1+d2. The period, p, is the GCD of all loops, so in particular p|(d1+d2) (i.e.,pdivides (d1+d2)). Now consider any loop from jback to j(note that the loop may or may not contain i). Let’s say that the length of this loop is x. Now take the path fromitojof length d1, then follow the loop of length x, then take the path from jto iof length d2. This entire journey from itoihas length d1+d2+x; hence p|(d1+d2+x). Subtracting the previous two lines, we have that p|x However this is true for all loops from jtoj. Therefore, palso divides the GCD of the lengths of all these loops. Thus p|q. By a symmetric argument q|p, so it must be the case that p=q. Theorem 9.36 In an irreducible, positive-recurrent DTMC with period d<∞, the solution /vectorπto the stationary equations /vectorπ·P=/vectorπand/summationdisplay iπi=1 exists, is unique, and represents the time-average proportion of time spent in each state. The majority of this section will be devoted to proving Theorem 9.36. We will follow this outline: 1.We start by ﬁnding a convenient way to label the states of a periodic chain in terms of “residue classes.” 2.We prove that the distribution of time averages is a stationary distribution. 3.We show that any stationary distribution equals the time-average distribution. 5The algebraic argument in this section was proposed by PhD students, Sherwin Doroudi and Misha Lavrov. 9.8when chains are periodic or not irreducible 173 Labeling the States of Periodic Chains Imagine a chain where every state has period d. Question: Pick a state, i. Does state iget visited once every dsteps? If not, can we at least say that there is some positive probability that state iwill be visited every dsteps? Answer: No. Consider a state iwhose period is 2.",3046
9.8 When Chains Are Periodic or Not Irreducible,"There may be a path from itoi that takes 4steps and another path that takes 6steps. There is zero probability of going fromitoiin2steps, yet the period is 2, as shown in the coloring of Figure 9.6. i Figure 9.6. Chain has period 2, as illustrated in the alternating coloring of the states. What isclear is that the time between visits to any state ican never be less than dtime steps. Now every state has period d, and we must be somewhere at each time step, and the chain is irreducible (so we eventually get to each state). It follows that we can partition the states into d“residue classes,” with names: 0,1,2,...,d−1, where from a state in class 0, we can only next transition to a state in class 1, from a state in class 1we can only next transition to a state in class 2,..., and from a state in class d−1 we can only next transition to a state in class 0. Every state is in exactly one class and thus will be visited at most once every dsteps. For a more mathematically rigorous deﬁnition of residue classes see Exercise 9.15. Question: Given a chess board and a knight, if the “state” of the knight is the square that it is currently on, how many residue classes do we have? Answer: The knight alternates between black squares and white ones, and every state can return to itself in 2 steps. Hence we have 2 residue classes: 0and1. The ﬁrst step of the proof is to relabel all states based on their residue classes, so that their names are as follows: 01,02,03,...,11,12,13,...,21,22,23,...,(d−1)1,(d−1)2,(d−1)3,... More succinctly, we will refer to the states as (/vector0,/vector1,/vector2,...,−−−→d−1). Question: Once states are relabeled in this way, what is the form of the transition matrixP? Where are its non-zero elements? Answer: P=⎡ ⎢⎢⎢⎢⎢⎣/vector0 /vector1 /vector2 ...−−−→d−1 /vector0 0A 0,1000 /vector1 00 A 1,200 /vector2 00 0 A 2,30 ... 00 0 0... −−−→d−1Ad−1,00000⎤ ⎥⎥⎥⎥⎥⎦(9.19) 174 ergodicity theory Question: What can we say about the matrices Ai,i+1? Answer: These matrices each have rows that sum to 1(they are stochastic ). This follows from the fact that Pis stochastic. Question: Are all the elements in Ai,i+1positive? Answer: Not necessarily – there may not be a direct connection between every element of/vectoriand−−→i+1. Now consider the dth power of P. Question: What does Pdlook like? How can we express it in terms of the Ai,i+1 matrices? Answer: Pd=⎡ ⎢⎢⎢⎢⎢⎣/vector0 /vector1 /vector2 ...−−−→d−1 /vector0D0,000 0 0 /vector1 0D 1,100 0 /vector2 00 D 2,200 ... 000... 0−−−→d−1000 0 D d−1,d−1⎤ ⎥⎥⎥⎥⎥⎦(9.20) where D0,0=A0,1·A1,2·A2,3···Ad−1,0 D1,1=A1,2·A2,3···Ad−1,0·A0,1 D2,2=A2,3···Ad−1,0·A0,1·A1,2 Di,i=Ai,i+1·Ai+1,i+2···Ai−2,i−1·Ai−1,i (9.21) Question: IsDi,istochastic? What does Di,irepresent? Is it irreducible? aperiodic? positive recurrent? Answer: Di,iis stochastic because it is the product of stochastic matrices, see Exer- cise 8.2. The matrix represents the probability of moving between each state in /vectorito each of the other states in /vectoriindsteps.Di,iis irreducible since Pis irreducible, and all paths from states in /vectorito states in /vectorihave length that is a multiple of d.",3142
9.8 When Chains Are Periodic or Not Irreducible,"To see that Di,iis aperiodic, assume not. Then the period of Di,iis at least 2. But this contradicts the fact that all states in /vectorihave period d. Finally, since the original chain is positive recurrent, we know that Di,iis as well. Showing that the Time-Average Distribution is a Stationary Distribution Using the above labeling, consider the time-average distribution, /vectorp: /vectorp=(p01,p02,p03,...,p 11,p12,p13,...,p (d−1)1,p(d−1)2,p(d−1)3,...) where d−1/summationdisplay i=0/summationdisplay jpij=1 Herepijrepresents the long-run proportion of time spent in state ij. In shorthand, we will write /vectorp=(p/vector0,p/vector1,...,p −−→d−1). 9.8when chains are periodic or not irreducible 175 Question: What do we know about/summationtext jpij? Answer: Since/vectoriis only visited once every dsteps,/summationtext jpij=1 d. Let q/vectori=d·p/vectori (9.22) Observe that/summationtext jqij=1. Question: What does q/vectorirepresent? What does it mean in relation to Di,i? Answer: Imagine observing the chain only everydsteps when it hits states in /vectori. Then q/vectorirepresents the time-average proportion of time spent in each state of /vectoriduring those observations and Di,irepresents the probability transition matrix, where its (x, y)th entry is the probability that from state ixwe will next transition to iy(at the next observation time). SinceDi,iis ergodic, it follows that it has a unique stationary distribution, that is equal both to the limiting distribution and the time-average distribution. Thus ∀i,q/vectoriis the unique solution to the stationary equations: q/vectori·Di,i=q/vectoriand/summationdisplay jqij=1 (9.23) From ( 9.23) it is tempting to start thinking about (p/vector0,p/vector1,...,p −−→d−1)being a stationary distribution for D=Pd. However that’s notwhere we want to go. What we want to prove is that (p/vector0,p/vector1,...,p −−→d−1)is a stationary distribution for P. To do this, we need to get back to the Ai,i+1matrices, rather than the Di,imatrices. From ( 9.23) and ( 9.21), we have that: q/vectori·Ai,i+1=(q/vectoriDi,i)Ai,i+1 =q/vectori·(Ai,i+1Ai+1,i+2···Ai−1,i)·Ai,i+1 =(q/vectoriAi,i+1)·(Ai+1,i+2···Ai,i+1) =(q/vectoriAi,i+1)·Di+1,i+1 (9.24) Let /vectorr=q/vectori·Ai,i+1 Question: What do we know about the sum of the elements in /vectorr? Answer: Since the elements of q/vectorisum to 1, and since Ai,i+1is stochastic and thus preserves sums of vectors, we have that the sum of elements of /vectorris 1. From ( 9.24) we thus have that: /vectorr=/vectorr·Di+1,i+1and/summationdisplay jrj=1 Thus/vectorris a stationary distribution for Di+1,i+1.B u tq−−→i+1is the unique stationary distribution for Di+1,i+1. Hence it follows that: /vectorr=q−−→i+1 ⇒q/vectori·Ai,i+1=q−−→i+1 176 ergodicity theory ⇒(q/vector0,q/vector1,...,q −−→d−1)·P=(q/vector0,q/vector1,...,q −−→d−1)where/summationdisplay i/summationdisplay jqij=d ⇒(p/vector0,p/vector1,...,p −−→d−1)·P=(p/vector0,p/vector1,...,p −−→d−1)where/summationdisplay i/summationdisplay jpij=1 Hence we see that /vectorpsatisﬁes the stationary equations for the original chain with transition matrix P. Showing That the Solution to the Stationary Distribution Is Unique Consider a stationary distribution /vectors=(s/vector0,s/vector1,...,s −−→d−1). We will show that /vectors=/vectorp. /vectors·P=/vectorsand/summationdisplay jsj=1 ⇒/vectors·Pd=/vectors ⇒/vectors·D=/vectors ⇒s/vectori·Di,i=s/vectori Furthermore, /summationdisplay jsij=1 d since we only visit states in /vectorionce every dsteps. But by ( 9.23) and ( 9.22),p/vectoriis the unique solution to: p/vectori·Di,i=p/vectoriand/summationdisplay jpij=1 d Hence p/vectori=s/vectori,∀i. Theorem 9.37 (Summary Theorem for Periodic Chains) Given an irreducible DTMC with period d<∞, if a stationary distribution /vectorπexists for the chain, then the chain must be positive recurrent. Proof The proof uses much of the proof of Theorem 9.36. We partition all states intodresidue classes. We denote by /vectorithe states with residue iand denote by π/vectorithose components of /vectorπthat correspond to states with residue i. We deﬁne Di,ias in this section. Via the same arguments as used in this section, we can argue that Di,iis irreducible and aperiodic. (However we don’t know that Di,iis positive recurrent.) Since/vectorπis stationary, we have that /vectorπ·P=/vectorπ. It therefore follows that /vectorπ·Pd=/vectorπ.",4389
9.10 Proof of Ergodic Theorem of Markov Chains,"9.9conclusion 177 Looking at ( 9.20), we see that, ∀i, π/vectori·Di,i=π/vectori. We can now conclude that we have a stationary solution to Di,i, once we multiply π/vectori by some appropriate normalizing constant to make sure its probabilities sum to 1. At this point, we have shown that Di,iis aperiodic and irreducible and has a stationary solution. Thus, from Theorem 9.27, it follows that Di,imust be positive recurrent, for everyi. But now, since all the Di,i’s are positive recurrent, it must be the case that the original Markov chain was positive recurrent as well. 9.8.2 Chains that Are Not Irreducible Given an aperiodic, positive-recurrent chain that is notirreducible, there is still a notion of “limiting probabilities.” However two things are no longer true: First, it is no longer the case that the limiting probability of being in state jis necessarily independent of the starting state i. Thus, we can’t deﬁne πj= lim n→∞Pn ij, independent of i, as in Theorem 9.27. Second, it is no longer the case that the limiting probability of every state jis positive, as we had in Theorem 9.27, since some states may not be reachable, or there may be an “absorbing” state (or states), from which one neverleaves. While the entire chain is not irreducible, the chain can still be subdivided into irreducible components (sometimes individual states), where an irreducible component may function as its own ergodic chain. In Section 10.1.2 , we consider some examples of chains that are not irreducible and illustrate the above points. 9.9 Conclusion What you should take away from this chapter is that, given ergodicity, there are many equivalent representations of limiting probabilities. We can think of the limitingprobability of being in state jas either the average fraction of time spent in state j, the stationary probability of being in state j, the reciprocal of the mean time between visits to state j, or even the rate of transitions out of state j. Depending on the occasion, you may ﬁnd it preferable to use one representation over another. Figure 9.7illustrates some of these equivalences. Reciprocal of time  between visits            πj = 1 mjjStationary probability  for state j               πj iPij Limitin g probability of  bein g in state j  πj = lim Pijn→∞n  Time−avera ge fraction of  time spent in state j          πj = lim          = pj    Nj(t) t t→∞i Figure 9.7. Equivalent representations of limiting probabilities. 178 ergodicity theory You should also take away the fact that there are many techniques for determining the limiting probabilities, including raising the probability transition matrix Pto high powers, solving stationary equations (or equivalently balance equations), or trying to solve time-reversibility equations. Although some techniques are simple (e.g., solvingtime-reversibility equations), they will not always work. 9.10 Proof of Ergodic Theorem of Markov Chains∗ This section is devoted to proving Theorem 9.25, adapting material in Karlin and Taylor [105], (Ch.",3020
9.10 Proof of Ergodic Theorem of Markov Chains,"4). Our goal is to show that the sequence {Pn ii,n=1,2,3,...}converges to1 mii.O u r plan is to deﬁne an upper and lower bound on the sequence of Pn iiand then show that our upper and lower bounds are actually the same, both equaling1 mii. We begin with the following deﬁnition: Deﬁnition 9.38 Deﬁne fk iito be the probability of ﬁrst returning to state iafter the kth transition, where we deﬁne f0 iito be zero. Deﬁne Pkiito represent the probability of being in state iafter the kth transition, given that we started in state i, where we deﬁne P0 ii=1. Finally, we deﬁne mii=E[Number time steps to return to state i]=∞/summationdisplay k=0kfk ii which follows by conditioning on the time of the ﬁrst return to state i. We now review deﬁnitions of limsup andliminf and present several preliminary lemmas on the limiting behavior of Pn ii. We then express Theorem 9.25 more precisely as Theorem 9.43. Finally, we prove Theorem 9.43. Deﬁnition 9.39 Consider a sequence {an}. 1.We say lim n→∞an=bif∀/epsilon1>0,∃n0(/epsilon1)s.t.|an−b|</epsilon1,∀n≥n0(/epsilon1). 2.We say limsup n→∞an=bif∀/epsilon1>0,∃n0(/epsilon1)s.t.,∀n≥n0(/epsilon1), (a)an<b+/epsilon1, and (b)bis the smallest value for which the above is true. 3.We say liminf n→∞an=bif∀/epsilon1>0,∃n0(/epsilon1)s.t.,∀n≥n0(/epsilon1), (a)an>b−/epsilon1, and (b)bis the largest value for which the above is true. The following are three immediate consequences of the deﬁnition of limsup . Similar consequences exist for liminf . ∗This section can be skipped without disturbing the ﬂow of the book. 9.10 proof of ergodic theorem of markov chains 179 Lemma 9.40 Fromlimsup n→∞an=bit follows that 1.∀/epsilon1>0, the sequence {an}exceeds the value b−/epsilon1inﬁnitely many times. 2.There exists an inﬁnite subsequence of {an}, denoted by {anj}where n1<n 2<n 3<... ,s . t .limj→∞anj=b. 3.If there is an inﬁnite subsequence of {am}, denoted by {amj}where m1<m 2<m 3<... , and if limj→∞amj/negationslash=b(or does not exist), then there exists b/prime<bsuch that there are an inﬁnite number of elements of {amj} that are below b/prime. Proof 1.This follows from the fact that there cannot be a “last time” that {an}exceeds b−/epsilon1; otherwise b−/epsilon1would be the limsup , rather than b. 2.We need to show that for any /epsilon1, there is some point on the subsequence after which all elements are in the range of b±/epsilon1. We deﬁne our subsequence to meet these requirements as follows: First, by the deﬁnition of limsup , we know that there is some n0s.t.∀n>n 0,w eh a v e an<b+/epsilon1. Furthermore by (1.), we know that there are inﬁnitely many elements of {an}withn>n 0, where an>b−/epsilon1. We now consider all those elements as our subsequence, S. If we now pick a smaller /epsilon1/prime, we can just look further out in Sto a point where again all elements are less than b+/epsilon1/prime, while still being assured that by (1.) there will be an inﬁnite subsequence of {an}exceeding b−/epsilon1/primeand also contained within S. 3.Suppose that the subsequence {amj}has a limit, but that limit is not b.",3071
9.10 Proof of Ergodic Theorem of Markov Chains,"Let that limit be b/prime/prime. We know that b/prime/prime<b. Then deﬁne b/primeto lie between b/prime/primeandb.B y the fact that limj→∞{amj}=b/prime/prime, we know that it has an inﬁnite number of elements less than b/prime. Now suppose that the subsequence {amj}does not have a limit. In this case, there exists some /epsilon1such that there is no point after which all the elements of {amj}are above b−/epsilon1. Thus, if we deﬁne b/prime=b−/epsilon1, then we know that at any point there is always “yet another” element of {amj}that lies below b/prime, and hence there are an inﬁnite number of elements of {amj}below b/prime. Lemma 9.41 Given a recurrent Markov chain, let/braceleftbig fk ii/bracerightbig and/braceleftbig Pk ii/bracerightbig be the se- quences speciﬁed in Deﬁnition 9.38.L e tλ≡limsup k→∞Pk ii. By Lemma 9.40.2 there exists a subsequence {Pnj ii},n1<n 2<... , for which lim j→∞Pnj ii=λ. Given a c>0such that fc ii>0, then lim j→∞Pnj−c·d ii =λfor all integers d≥0. 180 ergodicity theory Lemma 9.42 Given a recurrent Markov chain, let μ≡liminf k→∞Pk ii. By the ana- logue of Lemma 9.40.2 there exists a subsequence {Pmj ii},m1<m 2<... , for which lim j→∞Pmj ii=μ. Given a c>0such that fc ii>0, then lim j→∞Pmj−c·d ii =μfor all integers d≥0. We now present a proof of Lemma 9.41. The proof of Lemma 9.42 follows via a very similar argument. Proof (Lemma 9.41)We ﬁrst prove that lim j→∞Pnj−c ii=λ, by using the given condition fc ii>0. Only at the very end of the proof do we consider d. Suppose, to the contrary, that lim j→∞Pnj−c ii/negationslash=λ. Then it follows by Lemma 9.40.3 that there exists λ/prime<λ such that Pnj−c ii<λ/primefor an inﬁnite number of j. Let/epsilon1=[fc ii(λ−λ/prime)]/3. We determine Nsuch that ∞/summationdisplay k=Nfk ii</epsilon1 . (9.25) (We know that/summationtext∞ k=0fk ii=1, so we are simply looking at the tail of this distribution.) Letjbe chosen so large that nj≥Nand Pnj ii>λ−/epsilon1/parenleftbigg possible because lim j→∞Pnj ii=λ/parenrightbigg , (9.26) Pnj−c ii<λ/prime<λ (determination of λ/prime), (9.27) Pn ii<λ+/epsilon1∀n≥nj−N (Deﬁnition 9.39.2a). (9.28) By conditioning on the time of ﬁrst return, we get the following equation: Pn ii=n/summationdisplay k=0fk iiPn−k ii∀n>0 (9.29) Then, Pnj ii=nj/summationdisplay k=0fk iiPnj−k ii (by9.29) ≤N/summationdisplay k=0fk iiPnj−k ii+nj/summationdisplay k=N+1fk ii/parenleftbig because Pk ii≤1/parenrightbig <N/summationdisplay k=0fk iiPnj−k ii+/epsilon1(by9.25) 9.10 proof of ergodic theorem of markov chains 181 =N/summationdisplay k=0,k/negationslash=cfk iiPnj−k ii+fc iiPnj−c ii+/epsilon1 <N/summationdisplay k=0,k/negationslash=cfk ii(λ+/epsilon1)+fc iiλ/prime+/epsilon1 (Pnj−k ii<λ+/epsilon1by9.28; andPnj−c ii<λ/primeby9.27 ) =/parenleftBiggN/summationdisplay k=0fk ii−fc ii/parenrightBigg (λ+/epsilon1)+fc ii·λ/prime+/epsilon1 ≤(1−fc ii)(λ+/epsilon1)+fc iiλ/prime+/epsilon1 =λ+2/epsilon1−fc ii(λ+/epsilon1−λ/prime) <λ+2/epsilon1−fc ii(λ−λ/prime) =λ−/epsilon1(by deﬁnition of /epsilon1and the fact that fc ii>0) Thus,Pnj ii<λ−/epsilon1. Yet this contradicts ( 9.26), and so lim j→∞Pnj−c ii=λ. By induction, we ﬁnd that, for any integer d≥0, lim j→∞Pnj−c·d ii =λ.",3184
9.10 Proof of Ergodic Theorem of Markov Chains,"(9.30) Theorem 9.43 Given a recurrent, aperiodic Markov chain, let/braceleftbig fk ii/bracerightbig and/braceleftbig Pk ii/bracerightbig be the sequences speciﬁed in Deﬁnition 9.38. Then lim n→∞Pn iiexists, and lim n→∞Pn ii=1/summationtext∞ k=0kfk ii≡1 mii. Proof Let rn=fn+1 ii+fn+2 ii+···=P{Time to return to iexceeds n}. Observe mii=E[Time to return to i]=/summationtext∞ k=0kfk ii=/summationtext∞n=0rn. Consider the quantity n/summationdisplay k=0rkPn−k ii=n/summationdisplay k=0rn−kPk ii Question: What is the value of this sum? Answer: This sum equals 1, for all n. To see this, suppose that we start in state iat time0. We now ask, “What is the last time we visit state ibefore time n?” Observe that this could be any time step between 0andn, inclusive. There certainly must exist some last time, because we are already in state iat time 0. The quantity Pk iirn−krepresents the probability that the last time that we visited state iup to and including time nwas 182 ergodicity theory at time k. We now sum Pk iirn−kfromk=0tok=n, representing the full domain of the probability distribution; hence, n/summationdisplay k=0rkPn−k ii=n/summationdisplay k=0rn−kPk ii=1. (9.31) We would like to take the limit on relation ( 9.31) in such a way that Pn−k iican be moved out of the sum as a constant. We will look for subsequences of Pn iifor relatively large nwhere we can do this by looking at partial sums of Equation ( 9.31), and exploiting Lemmas 9.41 and9.42. Let λ= limsup n→∞Pn ii. μ= liminf n→∞Pn ii. Clearly μ≤λ. We will show that μ≥λ. This will establish that πi= lim n→∞Pn ii= λ=μ. Letn1<n 2<... denote the indices of a subsequence of {Pn ii}for which lim j→∞Pnj ii= λ. This subsequence must exist by Lemma 9.40.2. Likewise, let m1<m 2<... de- note the indices of a subsequence of {Pm ii}for which lim j→∞Pmj ii=μ. This subsequence must exist by the analogue to Lemma 9.40.2. Using Equation ( 9.31), and because rn≥0and0≤Pn ii≤1for all n, we obtain, for any ﬁnite Mand ﬁxed jsuch that nj,mj>N+M>0, nj−M/summationdisplay k=0rkPnj−M−k ii=1=mj−M/summationdisplay k=0rkPmj−M−k ii N/summationdisplay k=0rkPnj−M−k ii+nj−M/summationdisplay k=N+1rk·0≤1≤N/summationdisplay k=0rkPmj−M−k ii+mj−M/summationdisplay k=N+1rk·1.(9.32) To take the limits with the desired effect, we apply Lemmas 9.41 and9.42 and ﬁnd that, iff1 ii>0, then lim j→∞Pnj−M−k ii =λandlim j→∞Pmj−M−k ii =μ, where M=0. We will shortly argue that even if f1 ii=0, so long as the chain is aperiodic we can ﬁx ﬁnite M>0and still apply Lemmas 9.41 and9.42. Evaluating the inequality chain in Equation ( 9.32)ﬁ r s ta s j→∞ and then as N→∞ gives λN/summationdisplay k=0rk≤ 1≤μN/summationdisplay k=0rk+∞/summationdisplay k=N+1rk(asj→∞ ) λ∞/summationdisplay k=0rk≤ 1≤ μ∞/summationdisplay k=0rk (asN→∞ ) λ≤1/summationtext∞ k=0rk≤ μ.",2794
9.11 Exercises,"9.11 exercises 183 Yet, by deﬁnition of limsup andliminf ,μ≤λ. Thus μ=λ, which means that lim n→∞Pn iiexists and its value is πi= lim n→∞Pn ii=1/summationtext∞ k=0rk=1/summationtext∞k=0kfk ii(9.33) We now consider the remaining case: f1 ii=0. However, because the chain is aperiodic, the greatest common divisor of those cfor which fc ii>0is 1. Consider the set of {ci}such that fci ii>0, where we know, by aperiodicity, that the greatest common divisor of the {ci}is 1. Now consider any linear combination of the ci’s:p=/summationtext icidi, where di>0. Then we can show by induction on Lemmas 9.41 and9.42 that lim j→∞Pnj−p ii=λand lim j→∞Pmj−p ii=μ. Applying the Euclidean number property, we know that there exists an Mwhere any n>M can be expressed as a positive linear combination of a set of {ci}whose greatest common divisor is 1. Therefore, there exists a sufﬁciently large Msuch that lim j→∞Pnj−M−d ii =λand lim j→∞Pmj−M−d ii =μ,∀integers d≥0. At this point we have proved our theorem when πj= lim n→∞Pn jj.W en o wi n v o k e the irreducibility assumption, which allows us to reach state jfrom any initial state i, hence completing the proof of the theorem. 9.11 Exercises 9.1 Irreducibility, Aperiodicity, and Positive Recurrence For each of the following transition matrices, state whether the chain is (i) irreducible, (ii) aperiodic, or (iii) positive recurrent. [Note: If the period is not deﬁned, then the chain is notaperiodic.] (a)⎛ ⎝1 41 41 2 001 100⎞ ⎠ (b)⎛⎝010 010100⎞ ⎠ (c)⎛⎝1 302 31 43 40 001⎞⎠ 9.2 Practice with Balance Equations and Time-Reversibility Equations Consider the following Markov chains: P(1)=⎛ ⎜⎜⎝02/301 /3 1/302 /30 01/302 /3 2/301 /30⎞ ⎟⎟⎠ P(2)=⎛ ⎜⎜⎝1/32/30 0 1/302 /30 01/302 /3 00 1 /32/3⎞ ⎟⎟⎠ (a) Draw the corresponding Markov chains for P(1)andP(2). 184 ergodicity theory (b) Solve for the time-average fraction of time spent in each state for both P(1) andP(2). First try to use the time-reversibility equations, and if they do not work, then use the balance equations. (c) Was P(1)time-reversible? Was P(2)time-reversible? (d) For those chain(s) that were time-reversible, explain why it makes sense that for all states i,jin the chain, the rate of transitions from itojshould equal the rate of transitions from jtoi. 9.3 Data Centers, Backhoes, and Bugs Data centers alternate between “working” and “down.” There are many reasonswhy data centers can be down, but for the purpose of this problem we mentiononly two reasons: (i) a backhoe accidentally dug up some cable, or (ii) a software bug crashed the machines. Suppose that a data center that is working today will be down tomorrow due to backhoe reasons with probability 1 6, but will be down tomorrow due to a software bug with probability1 4. A data center that is down to- day due to backhoe reasons will be up tomorrow with probability 1. A data center that is down today due to a software bug will be up tomorrow with probability3 4. (a) Draw a DTMC for this problem. (b) Is your DTMC ergodic? Why or why not? (c) Is your DTMC time-reversible?",3050
9.11 Exercises,"Why or why not? (d) What fraction of time is the data center working? (e) What is the expected number of days between backhoe failures? 9.4 Ergodicity Summary Y o ua r eg i v e na n aperiodic ,irreducible DTMC, with n>1states. Put a check mark in ALL boxes that are valid (possible). Note that some rows may be empty, whereas others may have multiple check marks. (We startedyou off by ﬁlling in some boxes.) Chain is Chain is Chain is Positive Recurrent Transient Null Recurrent fj=1√ fj=0 0<fj<1 mjj=∞ mjj<∞√ /summationtext∞ n=0Pn jj=∞ /summationtext∞ n=0Pn jj<∞ 0<π j<1 πj=0 πj=1 πj<0 Glossary: mjj=mean number of steps to return to jgiven we’re in state j Pn ii=probability that the chain is in state iinnsteps given the chain is currently in state i fj=probability that a chain starting in state jever returns to state j πj=limiting probability of being in state j 9.11 exercises 185 Warning: Read the directions carefully. Every word is meaningful. 9.5 Time between Visits Given an ergodic DTMC, let mijdenote the mean number of steps to get from stateito state j. Sherwin makes the following conjecture: mjj≤mji+mij (9.34) Either prove or disprove Sherwin’s conjecture. 9.6 Pricing Model You are the market maker for GOGO. You have no clue whether GOGO stock will rise or fall, but you are obligated to buy or sell single shares from customersat all times. However, you do get to set the share price. To control the size of your position (number of shares of GOGO you own), when you are long (i.e., own) GOGO, you set the price so that with probability p<1 2, your next trade is a buy, and with probability q=1−pyour next trade is a sell. In contrast, if you are short (i.e., owe) GOGO, you set the price so that with probability p, your next trade is a sell, and with probability qyour next trade is a buy. Your position is represented by the bidirectional chain in Figure 9.8, with a negative state indicating how many shares you owe and a positive state indicating how many shares you own. qqq 0.5 pp pp 0.5 qqq0 0–1 0 1 –2 2 Figure 9.8. Bidirectional chain for pricing. (a) Given this pricing, what does your position tend to revert to? (b) Derive the time-average fraction of time spent in each state. (c) Why weren’t you asked to ﬁnd the limiting probabilities? (d) What is the expected (absolute value) size of your position? 9.7 Expected Time until k Failures This is a repeat of Exercise 3.25, where we want to derive the expected number of minutes until there are kconsecutive failures in a row, assuming that a failure occurs independently every minute with probability p. However this time, the problem should be solved by ﬁnding the limiting probability of some Markov chain. Please include a picture of your Markov chain. [Hint: You will have to think a bit to see how to convert from the limiting probabilities of the DTMC to what you really want.] 9.8 Walks on Undirected Weighted Graphs This problem comes up in many areas. Consider any undirected graph withweights, where wij=wjiis the weight on edge (i, j).",3033
9.11 Exercises,"Consider a particle that moves from node to node in the graph in the following manner: A particle residing at node iwill next move to node jwith probability Pijwhere Pij=wij Σjwij. 186 ergodicity theory (Draw a picture to help yourself visualize this.) What is the long-run proportion of time that the particle is in state i? [Hint: To answer this question, it will help to write out the time-reversibility equations, rather than the stationary equations. You will need to guess a solution to these equations.] 9.9 Randomized Chess This problem concerns the behavior of various chess pieces as they move randomly around the board. If you are not familiar with chess, all you need toknow for this problem is the following. The game is played on a board divided into 64 squares ( 8×8) that alternate from white to black. There are many different types of pieces that each move in a different way. The three pieces in this exercise are the king, bishop, and knight. The king can move one square in any direction (including the diagonal). The bishop can move any number of squares, but only in the diagonal directions. Finally, the knight moves in anL-shape. That is, the knight moves two squares to either side (left or right) andone square up or down. Or, the knight can move two squares up or down andone square to the side (left or right). (a) You are given an empty 8×8chessboard with a lone king placed in one corner. At each time step, the king will make a uniformly random legal move. Is the corresponding Markov chain for this process (i) irreducible? (ii) aperiodic? (b) What if a bishop is used instead? (c) What if a knight is used instead? (d) Now take advantage of Exercise 9.8on undirected weighted graphs and time-reversibility to calculate the expected time for the king to return to the corner. Think about how hard this would be without time-reversibility.[Hint: the calculation should be very simple.] (e) Do the same for the bishop. (f) Do the same for the knight. 9.10 Threshold Queue Revisited In Exercise 8.6, we deﬁned a threshold queue, depicted by the chain in Figure 9.9. (a) Argue that the Markov chain is aperiodic and irreducible. (b) Argue that the Markov chain is positive recurrent. 0.4 0.60.4 0.4 0.6 0.6q0.6 0.40.60.2 0.40 0.4 4 2 3 5 1 Figure 9.9. Threshold chain where threshold point is T=3. 9.11 Symmetric Random Walk [Proposed by PhD student, Srivatsan Narayanan] This problem presents a com- binatorial proof of Theorem 9.23 that uses Catalan numbers. Given the sym- metric random walk shown in Figure 9.10, we know that, if we start at state 0, then, with probability 1, we will return to state 0. Prove that m00=∞, where m00denotes the mean time between visits to state 0. 9.11 exercises 187 ½½½½½ ½½½½½½½ 0 0–1 0 1 –2 2 Figure 9.10. Symmetric random walk. (a) Let T00be a random variable denoting the time of the ﬁrstreturn to state 0. If we knew the probability mass function for T00, how would we use that to getm00? (b) Assume WLOG that the ﬁrst step is to the right (from 0 to 1). Then the last step before returning to state 0 must be to the left (from 1 to 0).",3107
9.11 Exercises,"If T00=n, how can we characterize the middle n−2steps? (c) The Catalan number C(k)represents the number of strings of length 2k such that there are k0’s and k1’s, such that no preﬁx of the strings contains more 0’s than 1’s. Express P{T00=n}in terms of an expression involving a Catalan number. It may help to start by observing that P{T00=n}= P{T00=n|First step is right }. (d) It is well known that C(k)=1 k+1/parenleftbigg 2k k/parenrightbigg . Use this fact and Lemma 9.18 to derive a lower bound on P{T00=n}. Then use that lower bound in (a) to show that m00=∞. 9.12 Stopping Times and Wald’s Equation A positive integer-valued random variable Nis said to be a stopping time for a sequence: X1,X2,X3,...if the event {N=n}is independent of Xn+1, Xn+2,...That is, the stopping time, N, can depend on everything seen so far, but not on the future. (a) Consider a sequence of coin ﬂips. Let Ndenote the time until we see 5 heads total. Is Na stopping time? How about the time until we see 5 consecutive heads? (b) Consider a gambler who starts with zero dollars and in each game is equally likely to win a dollar or lose a dollar. Let Xidenote the result of the ith game. The gambler stops whenever he is 2 dollars ahead. Let Nbe the stopping time in terms of number of games. Write a mathematical expression for N, involving a sum. (c) Let Xibe i.i.d. random variables, and let Ydenote a positive integer-valued random variable that is independent of the Xi’s. What do we know about E/bracketleftBig/summationtextY i=1Xi/bracketrightBig ? (d) Let Xibe i.i.d. random variables with ﬁnite mean. Let Nbe a stopping time for the sequence X1,X2,X3,...Assume E[N]<∞. Then Wald’s equation says that E/bracketleftBiggN/summationdisplay i=1Xi/bracketrightBigg =E[N]E[X]. (9.35) 188 ergodicity theory Importantly, Nisnotindependent of the Xi’s. Prove Wald’s equation. [Hint: (i) It may help to deﬁne an indicator random variable In=1 if and only ifN≥nand then consider the product XnIn. (ii) The fact that the Xi’s have ﬁnite mean will allow you to move an expectation into an inﬁnite summation.] 9.13 Another Derivation of the Symmetric Random Walk Wu suggests a different proof of Theorem 9.23 based on Wald’s equation ( 9.35). Given the symmetric random walk shown in Figure 9.11, we know that, because the chain is recurrent, if we start at any state, then with probability 1we will return to that state. Our goal is to prove that m11=∞, where m11denotes the mean time between visits to state 1. ½½½½½ ½½½½½½½ 0 0–1 0 1 –2 2 Figure 9.11. Symmetric random walk. (a) Prove that m11>0.5m01. It thus sufﬁces to show that m01=∞. (b) Let T01denote the time until we ﬁrst hit state 1, given that we start at state 0. Note that T01is well deﬁned because the symmetric random walk is recurrent. Explain why T01is a stopping time. (c) IfXnis the state at time step n, what is XT01? (d) Express XT01as a sum of i.i.d. r.v.’s. Assuming that E[T01]is ﬁnite, show that Wald’s equation leads to a contradiction. Hence m01=E[T01]=∞. 9.14 Recurrent versus Transient This problem involves the DTMC shown in Figure 9.12.",3097
9.11 Exercises,"Assume throughout this problem that q=1−p. p qpp qqqp qp q0 q 3 1 2 4 0 Figure 9.12. Markov chain for Exercise 9.14. (a) For what values of pis this chain recurrent? For what values of pis it transient? Give an argument for each case based on the expected number of visits to each state. You might choose to compute/summationtext nPn 00or to leverage any of the other ideas and arguments from this chapter. (b) In the case where the chain is transient, compute f0=P{Ever return to state 0given start there } as a function of p. (c) Assume that p<q . LetT00denote the time to go from state 0to state 0. DeriveE[T00]. What does this tell us about π0= lim n→∞Pn 00? 9.11 exercises 189 (d) Assume p<q . Use the stationary equations to derive all the limiting prob- abilities. (e) Again assume p<q . Is the chain time reversible? Why or why not? 9.15 Residue Classes in Periodic Chains In Section 9.8, we partitioned the states of an irreducible DTMC with period dinto “residue classes.” This problem deﬁnes residue classes more rigorously. Letibe an arbitrary state. Deﬁne ito have residue class 0. For every other state j, deﬁne its residue class as the length of any path from itoj, taken modulo d (by irreducibility, there exists at least one such path). (a) Show that the notion of residue classes is well-deﬁned, by proving that the lengths of any two paths from itojare equivalent modulo d. (b) Prove that from a state in residue class kwe can only go to a state in residue classk+1. 9.16 Finite-State DTMCs (a) Prove the following theorem: Theorem: For a ﬁnite state, irreducible DTMC, all states are positive recurrent. In your proof, you may make use of the following two class properties, which are proved in (b): rTheorem: Null recurrence is a class property (i.e., if i: null recurrent and icommunicates with jthenj: null recurrent). rTheorem: Positive recurrence is a class property (i.e., if i: positive recur- rent and icommunicates with jthenj: positive recurrent). (b) Prove the preceding two class property theorems. Your proof should work for inﬁnite-state Markov chains as well.",2094
Chapter 10 Real-World Examples Google Aloha and Harder Chains. 10.1 Googles PageRank Algorithm,"CHAPTER 10 Real-World Examples: Google, Aloha, and Harder Chains∗ This chapter discusses applications of DTMCs in the real world. Section 10.1 describes Google’s PageRank algorithm, and Section 10.2 analyzes the Aloha Ethernet protocol. Both problems are presented from the perspective of open-ended research problems, so that they serve as a lesson in modeling. Both are also good examples of ergodicity issuesthat come up in real-world problems. Finally, in Section 10.3, we consider DTMCs that arise frequently in practice but for which it is difﬁcult to “guess a solution” for thelimiting probabilities. We illustrate how generating functions can be used to ﬁnd thesolution for such chains. 10.1 Google’s PageRank Algorithm 10.1.1 Google’s DTMC Algorithm Most of you probably cannot remember a search engine before google.com. When Google came on the scene, it quickly wiped out all prior search engines. The featurethat makes Google so good is not the web pages that it ﬁnds, but the order in which it ranks them. Consider a search on some term; for example, “koala bears.” Thousands of web pages include the phrase “koala bears,” ranging from the San Diego zoo koala bear homepage, to anecdotes on the mating preferences of Australian lesbian koala bears, to a koala bear chair. The value of a good search engine is to rank these pages so that thepage we need will most likely fall within the “top 10,” thus enabling us to quicklyﬁnd our information. Of course, how can a search engine know exactly which of thethousand pages will be most relevant to us? A common solution is to rank the pages in order of the number of links to that page (often called backlinks of the page), starting with the page that has the highest number of pointers into it. We refer to this strategy as citation counting . Citation counting is a very commonly used measure of importance. For example, many tenure decisions are determined not by your number of publications, but by the numberof citations to your publications. Question: Suppose that we could determine the number of backlinks of each page (number of links pointing to the page). Why would that notnecessarily be a good measure of the importance of the page? ∗This chapter can be skipped without disturbing the ﬂow of the book. 190 10.1 google’s pagerank algorithm 191 Answer: 1.Not all links are equal. If a page has a link to it from the Yahoo web page, that link should be counted much more than if a page has a link to it from Joe Schmo’sweb page. 2.The citation counting scheme is easily tricked. Suppose I want my web page to have a high rank. I simply create a thousand pages that each point to my webpage. Now my web page has a thousand pointers into it, so it should be rankedhighly. (Hmmm ...not a bad way to handle the tenure citation issue too ...). OK, so citation counting is not the best of schemes. While it is insufﬁcient to just count the number of pages pointing into a page, we might do better by weighting each pointerby the number of pages pointing into it. Question: Why is this system also easy to fool? Answer: Now, to make my web page rank highly, I again create a thousand dummy web pages and have them all point to each other as well as to my page. That is, I createa clique of size 1,000. Now my web page has a high number of backlinks, all of whichalso have a high number of backlinks. Google’s Solution: Google’s solution is to deﬁne page rank recursively: “A page has high rank if the sum of the ranks of its backlinks is high.” Observe that this covers boththe case when a page has many backlinks and when a page has a few highly rankedbacklinks. Question: It is easy to say that “a page has high rank if the sum of the ranks of its backlinks is high,” but how does that help us ﬁgure out the rank of a page? Answer: The “aha” that the Google founders made was to realize that the recursive deﬁnition is actually saying πj=n/summationdisplay i=1πiPij. That is, the only way for page jto have high limiting probability is if the i’s pointing intojhave high limiting probability. Remind you of anything? The rank of a page is thus just its limiting probability in a Markov chain. Google’s PageRank Algorithm : 1.Create a DTMC transition diagram where there is one state for each web page and there is an arrow from state ito state jif page ihas a link to pagej. 2.If page ihask>0outgoing links, then set the probability on each outgoing arrow from state ito be1/k. 3.Solve the DTMC to determine limiting probabilities. Pages are then ranked based on their limiting probabilities (higher probability ﬁrst). This simple algorithm was the original basis behind the entire Google company. 192 real-world examples: google, aloha, and harder chains N M A Figure 10.1. Links between web pages. Example Suppose the entire web consists of the three pages shown in Figure 10.1. Then the corresponding DTMC transition diagram is shown in Figure 10.2. 1½ ½½N M A½ Figure 10.2. Corresponding DTMC transition diagram. We now solve the balance equations: πA=1 2πN+πM 1 2πN=1 2πA πM=1 2πA 1=πA+πM+πN This results in: πA=πN=2 5;πM=1 5. Intuition behind the Google Algorithm: Imagine that each page initially has one unit of importance. At each round, each page shares whatever importance it has among its successors. Pages with a lot of incoming links will receive lots of importance (will be visited frequently in the DTMC). 10.1.2 Problems with Real Web Graphs Unfortunately, PageRank does not work well on all web graphs. Consider the following two examples. 10.1 google’s pagerank algorithm 193 Example: Dead End or Spider Trap Consider Figure 10.1, where this time there is either no outgoing link from page M (in this case M is called a “dead end”) or there is a self-loop at state M (in this case M is called a “spider trap”). In either case Figure 10.3 shows the corresponding DTMC transition diagram. ½ 1½ ½½N M A Figure 10.3. DTMC for a web graph with a dead end or spider trap at M. The balance equations are 1 2πN=1 2πA 0·πM=1 2πA πA=1 2πN πA+πN+πM=1. The solution to these equations is πM=1,πN=0= πA. These are also the limiting probabilities (note that the start state does not matter). Somehow this solution is very unsatisfying. Just because person M chooses to be anti-social and not link to anyone else, it should not follow that person M is the only important person on the web. Our solution does not match our intuitive view of surﬁnga web graph. Example: Two Spider Traps Now imagine that both M and N are anti-social and link only to themselves. The resulting DTMC transition diagram is shown in Figure 10.4. The corresponding balance equations are: 0·πN=1 2·πA 0·πM=1 2·πA πA=0 πA+πN+πM=1. 194 real-world examples: google, aloha, and harder chains 1 1½N M A½ Figure 10.4. DTMC for a web graph with two spider traps. Observe that there are an inﬁnite number of possible solutions. This is because the limiting probabilities depend on the start state. Again the solution is very unsatisfying. 10.1.3 Google’s Solution to Dead Ends and Spider Traps Google’s solution to dead ends and spider traps is to “tax” each page some fraction of its “importance” and then distribute that taxed importance equally among all pagesin the web graph. This “tax” keeps the DTMC from getting trapped in a dead end or spider trap. Figure 10.5 shows the effect of applying a 30 percent tax on the DTMC of Figure 10.3. First, every existing transition is multiplied by 70 percent . Then, for each state sin ann-state chain, we add a transition of weight30 percent nfrom state sto every other state, including itself. Thus in the three-state chain in Figure 10.3, we add a transition of weight 10 percent from each state to every other state. .8.1 .1 .1.7·½+.1 .7·½+.1 .7· ½+.1 .7·½+.1 .1N M A Figure 10.5. DTMC transition diagram for Figure 10.3 after 30 percent tax. Observe that the spider trap is now no longer a problem, and we can easily solve for the limiting probabilities: πA=.19;πM=.55;πN=.26",7961
10.2 Aloha Protocol Analysis,"10.2 aloha protocol analysis 195 The problem now is that these limiting probabilities are highly dependent on the amount of tax. The readings at the end of the chapter describe experiments with other taxation ideas; for example, where the tax is distributed among just one or two pages. 10.1.4 Evaluation of the PageRank Algorithm PageRank is intended to give an indication of the popularity of a page – the fraction of times that page is referenced as compared with other pages. This works well whenthe graph is irreducible, but is problematic when there are spider traps or dead ends.The taxation solution for solving the spider trap problem seems ad hoc. If the tax is toosmall, then we still end up with too high a limiting probability at the spider trap state (as in πM=0.55in Section 10.1.3 ). Thus we need to use a high tax. Yet a high tax seems totally unrealistic, because it leads to every state being of equal weight. In practice it seems that when you come to a page with links only back to itself, you usually back up (hit the “BACK” key). Perhaps we can combine the idea of taxation with the idea of backing up. That is, we apply a high tax to each page, but the tax isdistributed only among the predecessors of the page, not among all pages of the web. This idea is explored in [ 53]. 10.1.5 Practical Implementation Considerations You might be wondering how in practice Google goes about solving the DTMC for the limiting probabilities, given that it is a huge (ﬁnite) DTMC. Solving such a largenumber of simultaneous equations seems difﬁcult. Question: Is there another approach to obtain the limiting probabilities? Answer: Yes, we can take powers of P, the transition probability matrix. This turns out to be faster when the transition probability matrix is large and sparse and only an approximate solution is needed. This is the approach employed by Google. 10.2 Aloha Protocol Analysis The slotted Aloha protocol is the progenitor of the Ethernet protocol. Ethernet is adatalink-level protocol allowing multiple users to transmit a data frame along a single wire in a switchless LAN as shown in Figure 10.6. Only one user (host) can use the wire at a time. However, because the multiple users are working independently, it 123 mEthernet Figure 10.6. Ethernet with mhosts. 196 real-world examples: google, aloha, and harder chains could turn out that more than one user tries to send a packet at once. In that case, a “collision” occurs, and all messages are corrupted and must be resent. Of course, ifwe had centralized control, we could ensure that the users take turns sending packets. However, we want to make this work without centralized control. Ethernet uses CSMA/CD (Carrier Sense Multiple Access/Collision Detection). What is important in CSMA/CD is that, although the users basically submit independently ofeach other, 1when their messages do collide, they are able to detect the collision (they do this by seeing that their data frames are garbled), and then they know that they need to resend. The key idea in CSMA/CD is that the retransmissions of the data need to occur at random times, so as to minimize the chance of repeated collisions. In this section we use DTMCs to begin to analyze various protocols for how to handle the retransmissions. We start by looking at the Slotted Aloha protocol and studying theproblems with this earlier protocol.",3384
10.2 Aloha Protocol Analysis,"We will only go part of the way toward solving this problem during this chapter, but this discussion will give you a feel for how to model such problems with Markov chainsand will also help make concepts of ergodicity more concrete. 10.2.1 The Slotted Aloha Protocol The Slotted Aloha protocol is deﬁned as follows: Time is divided into discrete time steps or “slots.” There are mtransmitting hosts. At each time step, each of the mhosts independently transmits a new message (frame) with probability p(assume p<1 m). If exactly 1 message (frame) is transmitted in a slot, the transmission is deemed “successful” and the message leaves the system. However, if more than 1 messageis transmitted during a slot, the transmission is deemed “unsuccessful.” In this casenone of those messages leave the system. Every message involved in an “unsuccessful transmission” is then retransmitted at every step with probability q, until it successfully leaves the system. To keep things stable, we may need to make qvery small; for the time being, assume that qis a very small constant. Note that, regardless of the backlog of messages, each of the mhosts continues to transmit newmessages with probability pat each step. 10.2.2 The Aloha Markov Chain Question: Given values of m,p, andq/lessmuchp, what does the Markov chain for the Slotted Aloha protocol look like? Hint: It may not be obvious what we need to track. Each of the mhosts independently transmits a message at each time step with probability p, so there is no need to track that. What we need to track is the number of messages that need retransmission (i.e., the messages that have been through at least one collision). 1This is not entirely true, because users do “listen” to the wire before sending, although listening is not sufﬁcient to avoid all collisions. 10.2 aloha protocol analysis 197 Answer: Before we begin, observe that the number of new messages transmitted during a time slot is distributed Binomially with parameters mandp. Therefore, the probability of generating knew messages is pk=/parenleftbigg m k/parenrightbigg pk(1−p)m−k,∀k=0,1,...,m . Likewise, when there are nmessages in the previously collided pile, the probability of kretransmissions occurring is qn kwhere, qn k=/parenleftbigg n k/parenrightbigg qk(1−q)n−k,∀k=0,1,...,n. We deﬁne the state at time step tto be the number of messages remaining in the system at the end of time step t. We now describe the transition probabilities for the states. First, consider state 0(no messages remaining in the system). The probability of remaining at state 0is the probability that there are no new transmissions or there is exactly 1 new transmission (which gets out of the system). For a state transition tooccur from 0toj>1, we need jnew transmissions. There cannot be more than m new transmissions. Thus the probability of moving from state 0to state j>m is zero. Also, it is logically impossible to go from state 0to state 1. Hence we have P0,0=( 1−p)m+mp(1−p)m−1. P0,1=0. P0,j=/parenleftbigg m j/parenrightbigg pj(1−p)m−j,∀j=2,...,m . P0,j=0,∀j>m .",3078
10.2 Aloha Protocol Analysis,"Now consider state k,k > 0(i.e., there are kunsuccessful messages left in the system at the end of the time step, waiting to be retransmitted). Because at most 1 messagegets through at every time step, transitions from kto state j≤k−2cannot occur. Further, a maximum of only mnew messages can be generated. Therefore, the state cannot increase by more than m. The possible transitions are thus as follows: rk→k−1: No new transmissions and 1 retransmission. The retransmitted mes- sage gets out of the system. Probability: (1−p)mkq(1−q)k−1. rk→k: There are several ways this can happen: 1. One new transmission and no retransmissions: Probability: mp(1−p)m−1(1−q)k. 2. No new transmission and no retransmissions: Probability: (1−p)m(1−q)k. 3. No new transmission and at least 2 retransmissions: Probability: (1−p)m/parenleftbig 1−(1−q)k−kq(1−q)k−1/parenrightbig . rk→k+1: One new transmission and at least 1 retransmission. As a result, collision occurs, and the number of messages increases by 1. Probability: mp(1−p)m−1/parenleftbig 1−(1−q)k/parenrightbig . 198 real-world examples: google, aloha, and harder chains rk→k+j, j=2,...,m : There are jnew transmissions. The number of re- transmissions does not matter, because collision occurs anyway. Probability:/parenleftbigg m j/parenrightbigg pj(1−p)m−j. To summarize, Pk,j=0,∀j≤k−2. Pk,k−1=( 1−p)mkq(1−q)k−1. Pk,k=m(1−q)kp(1−p)m−1+/parenleftbig 1−kq(1−q)k−1/parenrightbig (1−p)m. Pk,k+1=mp(1−p)m−1/parenleftbig 1−(1−q)k/parenrightbig . Pk,k+j=/parenleftbigg m j/parenrightbigg pj(1−p)m−j,∀j=2,...,m . Pk,j=0,∀j>k +m. These probabilities describe the system completely. 10.2.3 Properties of the Aloha Markov Chain Question: Is this chain aperiodic and irreducible? Answer: Yes. Question: Does the Aloha protocol work? Hint: Is the Markov chain ergodic (positive recurrent and aperiodic and irreducible), or is it transient, or is it null recurrent? Answer: LetP(k) backrepresent the probability of transitioning to a lower numbered state, given we are in state k. LetP(k) forw=1−P(k) back. Then, P(k) back=k−1/summationdisplay j=0Pk,j=Pk,k−1=kq(1−q)k−1(1−p)m. It can be seen that for a given constant qandp, lim k→∞P(k) back= lim k→∞k(1−p)mq(1−q)k−1=∞·0 =q(1−p)mlim k→∞k (1−q)1−k=∞ ∞ =q(1−p)mlim k→∞d dk[k] d dk[(1−q)1−k] =q(1−p)mlim k→∞1 (1−q)1−k·ln(1−q)·(−1) =0. 10.2 aloha protocol analysis 199 lim k→∞P(k) forw=1−lim k→∞P(k) back=1. lim k→∞Pk,k= lim k→∞/parenleftbig m(1−q)kp(1−p)m−1+/parenleftbig 1−kq(1−q)k−1/parenrightbig (1−p)m/parenrightbig = lim k→∞/parenleftbig m(1−q)kp(1−p)m−1+( 1−p)m/parenrightbig −lim k→∞/parenleftbig kq(1−q)k−1(1−p)m/parenrightbig =( 1−p)m+ lim k→∞P(k) back =( 1−p)m<1. Thus as kincreases, the probability of going to lower states tends to zero, and the probability of staying at the same state tends to a small constant, (1−p)m; with high probability, tending to 1−(1−p)m, we move to higher states. Consider a state k, forklarge. Once the state is visited, the probability of returning back to the state goes to zero, because, almost surely, the chain proceeds ahead and never returnsback. Question: If you make qreally, really small, does the Aloha protocol work then? Answer: No, for any constant qthe chain is transient. Here’s some more intuition: Consider the expected number of transmissions during a slot, given that the DTMC is in state k. The expected number of new transmissions is mp. The expected number of retransmissions is kq. Now, if the expected total number of transmissions ( E[N]=mp+kq) exceeds 1, then the state either stays the same or gets worse. Assume a ﬁxed q. When kgets higher than1 q, thenE[N]>1. Thus we expect that the number of simultaneous transmissions for each state from that point onexceeds 1. Unsurprisingly to us queueing theorists, the original Aloha protocol implementation was subject to occasional unexplained freezes, in which all messages were dropped.However, the protocol was improved and became the basis behind today’s Ethernetprotocol. 10.2.4 Improving the Aloha Protocol Question: Can you see a different way to set qso as to make the chain ergodic? Answer: We want to ensure that the expected number of transmissions during a slot is less than 1. That is, we want to ensure that, for all states k, mp+kq <1. This could perhaps be achieved by making qdecreasing in k(e.g.,q<1−mp k), or going even further and making qgeometrically decreasing in k, such as q∝α/knwhere α<(1−mp)andn>1, or even where q∝β−k, for some β>1. Question: Is there any drawback to making qsmall?",4506
10.3 Generating Functions for Harder Markov Chains,"200 real-world examples: google, aloha, and harder chains Answer: Ifqis small, the probability of retransmission is very low, and unsuccessful messages are likely to remain in the system for a long time. As q→0, the mean delay for retransmission goes to inﬁnity; hence the mean time to send a message goes to inﬁnity too. The goal is therefore to look for an optimal value for qthat is just low enough to ensure that the Markov chain is ergodic, without being so low as to causethe mean time for a transmission to skyrocket. The actual Ethernet protocol is based on the idea of exponential backoff , where each host waits some random time after each collision before resubmitting and where the mean of that “waiting time” increases exponentially as a function of the number ofcollisions experienced so far [ 114]. 10.3 Generating Functions for Harder Markov Chains Solving DTMCs is not always easy. In the case of a ﬁnite-state DTMC, we at least know that the number of simultaneous balance equations is ﬁnite. Hence, given enoughcomputing power, we should in theory be able to solve for limiting probabilities. (Of course, in practice, there are some singularity problems that may arise when the chains are too big or the probabilities are too small.) However, for an inﬁnite-state DTMC, it is not at all obvious that one can even solve the chain. It is often the case that the balance equations take the form of recurrence relations, as in the recurrence from Section 8.10: πi+1(r+s)=πi·r+πi+2·s (10.1) or equivalently πi+2=πi+1/parenleftBigr s+1/parenrightBig −πi·r s. So far, we have been able to “guess” the solution for all the recurrences that we have looked at, and the solution was often simple. For example, the solution to ( 10.1)i s πi=ρiπ0 where ρ=r s. However, in general the recurrence relation is not always so easy to solve. Considerfor example, a very simple looking recurrence relation: fi=fi−1+fi−2 (10.2) Question: Do you recognize the relation? Answer: It is the Fibonacci sequence. Although ( 10.2) seems even simpler than ( 10.1), it turns out to be impossible to solve by just unraveling the recurrence or “guessing” the solution – please try it. In this section, we see how to derive a closed-form expression for fn, thenth Fibonacci number, using a four-step method involving generating functions (that we will introduce shortly). This method may seem overly complex. However, for many Markov chains 10.3 generating functions for harder markov chains 201 that come up in practice (see for example Exercise 10.7), there is no clear way to “guess” a solution, and using generating functions is the easiest way to solve these chains for their limiting distribution. 10.3.1 The z-Transform The generating function that we choose to use is a called a z-transform . This is one type of generating function. We discuss transforms in much more depth in Chapter 25, but for this chapter you will not need more than the deﬁnition. Deﬁnition 10.1 Given a sequence {f0,f1,f2,...}, deﬁne F(z)=∞/summationdisplay i=0fizi. F(z)is the z-transform of the sequence . In the Markov chains that we look at, fitakes the place of πi=P{State is i}, and our goal is to derive a closed-form expression for fi. 10.3.2 Solving the Chain We illustrate the method on a recurrence relation of this form: fi+2=bfi+1+afi (10.3) where we assume f0andf1are given and aandbare constants. However, the method can obviously be applied more generally. Step 1: Represent F(z)as a ratio of polynomials. The goal in Step 1 is to represent F(z)as a ratio of two polynomials in z.F r o m( 10.3), we have fi+2=bfi+1+afi. fi+2zi+2=bfi+1zi+2+afizi+2. ∞/summationdisplay i=0fi+2zi+2=b∞/summationdisplay i=0fi+1zi+2+a∞/summationdisplay i=0fizi+2. F(z)−f1z−f0=bz∞/summationdisplay i=0fi+1zi+1+az2∞/summationdisplay i=0fizi. F(z)−f1z−f0=bz(F(z)−f0)+az2F(z). /parenleftbig 1−bz−az2/parenrightbig F(z)=f1z+f0−bzf0. F(z)=f0+z(f1−bf0) 1−bz−az2. (10.4) 202 real-world examples: google, aloha, and harder chains Step 2: Rewrite F(z)via partial fractions. The goal in Step 2 is to apply partial fractions to F(z).I fF(z)=N(z) D(z), then we want to write F(z)=A h(z)+B g(z), where D(z)=h(z)g(z)andh, gare (hopefully) linear. Lemma 10.2 IfD(z)=az2+bz+1, then D(z)=/parenleftbigg 1−z r0/parenrightbigg/parenleftbigg 1−z r1/parenrightbigg where r0andr1are the (real) roots of D(z). Proof To see that the two ways of writing D(z)are equivalent, we note that the two quadratic expressions have the same two roots, r0andr1, and furthermore have the same constant term, 1. In our case, see ( 10.4),D(z)=−az2−bz+1,s o (r0,r1)=/parenleftbigg−b−√ b2+4a 2a,−b+√ b2+4a 2a/parenrightbigg . (10.5) D(z)=h(z)·g(z) h(z)=1−z r0 g(z)=1−z r1 We now use N(z)=f0+z(f1−f0b)from ( 10.4) to solve for AandB: F(z)=A 1−z r0+B 1−z r1(10.6) =A/parenleftBig 1−z r1/parenrightBig +B/parenleftBig 1−z r0/parenrightBig /parenleftBig 1−z r0/parenrightBig/parenleftBig 1−z r1/parenrightBig =(A+B)+z/parenleftBig −A r1−B r0/parenrightBig /parenleftBig 1−z r0/parenrightBig/parenleftBig 1−z r1/parenrightBig=N(z) D(z)=f0+z(f1−f0b) D(z)(10.7) Matching the z-coefﬁcients in the numerators of ( 10.7), we have A+B=f0 −A r1−B r0=f1−f0b",5164
10.5 Exercises,"10.4 readings and summary 203 which solves to B=r0f0+(f1−f0b)r0r1 r0−r1. (10.8) A=f0−B. (10.9) Step 3: Rewrite F(z)via series expansion. Returning to ( 10.6), and using the fact that1 1−αz=/summationtext∞ i=0(αz)i,w eh a v e A 1−z r0=A∞/summationdisplay i=0/parenleftbiggz r0/parenrightbiggi andB 1−z r1=B∞/summationdisplay i=0/parenleftbiggz r1/parenrightbiggi . Thus, the geometric series expansion of F(z)can be rewritten as follows: F(z)=∞/summationdisplay i=0fizi=A∞/summationdisplay i=0/parenleftbiggz r0/parenrightbiggi +B∞/summationdisplay i=0/parenleftbiggz r1/parenrightbiggi (10.10) Step 4: Match terms to obtain fn. Finally, we match the z-coefﬁcients in ( 10.10 ) to obtain the fn’s: fn=A rn 0+B rn 1 Summary We have proven that the solution to a recurrence relation of the form fn+2=b·fn+1+a·fn givenf0andf1is given by fn=A rn 0+B rn 1 where AandBare obtained from ( 10.9) and ( 10.8) andr0andr1are obtained from (10.5). In Exercise 10.5, you will apply these steps to derive a closed-form expression for the nth Fibonacci number. 10.4 Readings and Summary This chapter has explored a couple of open-ended modeling problems illustrating the ergodicity properties that we covered in Chapter 9in the context of real-world problems. There is much more information about both problems available on the web. The exercises at the end of the chapter provide more examples of modeling and ergodicity. For Google’s PageRank algorithm, we recommend several early researchpapers: [ 139,109,53]. 204 real-world examples: google, aloha, and harder chains 10.5 Exercises 10.1 Caching If you think about it, web browsing is basically a Markov chain – the page you will go to next depends on the page you are currently at. Suppose our web server has three pages, and we have the following transition probabilities: P1,1=0 P1,2=xP 1,3=1−x P2,1=yP 2,2=0 P2,3=1−y P3,1=0 P3,2=1 P3,3=0 where Pi,jrepresents the probability that I will next ask for page j, given that I am currently at page i. Assume that 0<x<y<1 2. Web browsers cache pages so that they can be quickly retrieved later. We will assume that the cache has enough memory to store two pages. Whenever arequest comes in for a page that is not cached, the browser will store that page in the cache, replacing the page least likely to be referenced next based on the current request. For example, if my cache contained pages {2,3}and I requested page 1, the cache would now store {1,3}(because x<1−x). (a) Find the proportion of time that the cache contains the following pages: (i){1,2}(ii){2,3}(iii){1,3}. (b) Find the proportion of requests that are for cached pages. 10.2 DTMC for Stock Evaluation A stock has an equilibrium price P, where Pis an integer. The stock price ﬂuctuates each day according to the DTMC shown in Figure 10.7. Note that, for ease of analysis, we assume that the stock price can go negative. ½½½¼¼¼ ¼¼¼½½¼¼½¼¼ ½0 0P–1 P P+1 P–2 P+2 Figure 10.7. DTMC for the stock price. (a) What is the fraction of time that the stock is priced at P? (b) Let Idenote the difference between the stock price and P. What is the expectation of the absolute value of I? 10.3 Time to Empty Consider a router where, at each time step, the number of packets increases by 1 with probability 0.4and decreases by 1with probability 0.6. We are interested in the time required for the router to empty. The Markov chain depicting the number of packets is shown in Figure 10.8. LetT1,0denote the time to get 0.4 0.60.4 0.4 0.6 0.6q0.4 0.60.4 0.60 0.6 3 1 2 4 0 Figure 10.8. Number of packets at router. 10.5 exercises 205 from state 1to state 0. (a) Compute E[T1,0]. (b) Compute Var(T1,0). [Hint: The variance computation is a little tricky. Be careful not to lump together distinct random variables.] 10.4 Time to Empty – Extra Strength Consider the same setup as in Exercise 10.3. This time, we use Tn,0to denote the time to get from state nto state 0. (a) Compute E[Tn,0]. (b) Compute Var(Tn,0). 10.5 Fibonacci Sequence The Fibonacci sequence is deﬁned by f0=0,f1=1,fn+2=fn+1+fn. Use the generating function technique from this chapter to derive fn, thenth term of the Fibonacci sequence. 10.6 Simple Random Walk: Solution via Generating Functions Figure 10.9 shows a simple random walk, where r<s . Follow the generating function approach in this chapter to solve for the limiting probabilities of thisrandom walk using the z-transform, Π(z)=/summationtext∞ i=0πizi.[Note: To get the initial probability, π0, observe that Π(z)|z=1=1. You will also need to use the balance equation for state 0to getπ1.] 0r sr sr s1−r−s 1−r−s 1−r−s 00 1 2 1−r 3 Figure 10.9. DTMC for random walk. 10.7 Processor with Failures Consider the DTMC shown in Figure 10.10 . This kind of chain is often used to model a processor with failures. The chain tracks the number of jobs in the system. At any time step, either the number of jobs increases by 1 (withprobability p), or decreases by 1 (with probability q), or a processor failure occurs (with probability r), where p+q+r=1. In the case of a processor failure, all jobs in the system are lost. Derive the limiting probability, πi,o f there being ijobs in the system. [Hint: Use the generating function approach from this chapter.] rq+r  rrp qpp qqqpp q0 1−p 3 1 2 4 0 Figure 10.10. DTMC for processor with failures.",5301
Chapter 11 Exponential Distribution and the Poisson Process. 11.2 Memoryless Property of the Exponential,"CHAPTER 11 Exponential Distribution and the Poisson Process We ﬁnished discussing Discrete-Time Markov Chains (DTMCs) in Chapter 10 and are now heading toward Continuous-Time Markov Chains (CTMCs). DTMCs are totallysynchronized, in that the state only changes at discrete time steps, whereas in CTMCsthe state can change at any time. This makes CTMCs more realistic for modelingcomputer systems, where events can occur at any time. In preparation for CTMCs, we need to discuss the Exponential distribution and the Poisson arrival process. 11.1 Deﬁnition of the Exponential Distribution We say that a random variable Xis distributed Exponentially with rate λ, X∼Exp(λ) ifXhas the probability density function: f(x)=/braceleftbigg λe−λxx≥0. 0 x<0. The graph of the probability density function is shown in Figure 11.1. λ λe−λ λe−2λ λe−3λ x 4f(x) 0 12 3 Figure 11.1. Exponential p.d.f., f(x). The cumulative distribution function, F(x)=P{X≤x}, is given by F(x)=/integraldisplayx −∞f(y)dy=/braceleftbigg 1−e−λxx≥0. 0 x<0. F(x)=e−λx,x≥0. 206 11.2 memoryless property of the exponential 207 Observe that both f(x)andF(x)drop off by a constant factor, e−λ, with each unit increase of x. The Exponential distribution has mean: E[X]=/integraldisplay∞ −∞xf(x)dx=1 λ. The second moment of X∼Exp(λ)is E/bracketleftbig X2/bracketrightbig =/integraldisplay∞ −∞x2f(x)dx=2 λ2. The variance is Var(X)=E/bracketleftbig X2/bracketrightbig −(E[X])2=1 λ2. Question: Why is λreferred to as the “rate” of the distribution? Answer: Because the mean of the distribution is 1/λand “rate” is typically viewed as the reciprocal of the “mean.” Question: What is the squared coefﬁcient of variation of Exp (λ)? Answer: The squared coefﬁcient of variation of random variable Xis deﬁned as C2 X=Var(X) E[X]2. This can be thought of as the “scaled” or “normalized” variance. When X∼Exp(λ), C2 X=1. 11.2 Memoryless Property of the Exponential A random variable Xis said to be memoryless if P{X>s +t|X>s}=P{X>t},∀s, t≥0. Question: Prove that X∼Exp(λ)is memoryless. Answer: P{X>s +t|X>s}=P{X>s +t} P{X>s}=e−λ(s+t) e−λs=e−λt=P{X>t}. To understand this, think of Xas being the lifetime of, say, a lightbulb. The expression says that the probability that the lightbulb survives for at least another tseconds before burning out, given that the lightbulb has survived for sseconds already, is the same as the probability that the lightbulb survives at least tseconds, independent of s . Question: Does this seem realistic for a lightbulb? Answer: Who knows? 208 exponential distribution and the poisson process Question: What are some real-life examples whose lifetimes can be modeled by an X such that P{X>s +t|X>s}goes down as sgoes up? Answer: A car’s lifetime. The older a car is, the less likely that it will survive another, say,t=6years. Distributions for which P{X>s +t|X>s}goes down as sgoes up are said to have increasing failure rate . The device is more and more likely to fail as time goes on. Question: What are some real-life examples whose lifetimes can be modeled by an X such that P{X>s +t|X>s}goes up as sgoes up? Answer: One example is UNIX job CPU lifetimes; see [ 85]. The more CPU a job has used up so far, the more CPU it is likely to use up. Another example is computer chips. If they are going to fail, they will do so early. That is why chip manufacturers test chips for a while before selling them. Distributions for which P{X>s +t|X>s}goes up as sgoes up are said to have decreasing failure rate . The device is less likely to fail as time goes on. More precisely, the failure rate function r(t) (a.k.a. hazard rate function) is deﬁned as follows: Let Xbe a continuous random variable with probability density function f(t)and cumulative distribution function F(t)=P{X<t}. Then r(t)≡f(t) F(t). To interpret this expression, consider the probability that a t-year-old item will fail during the next dtseconds: P{X∈(t, t+dt)|X>t}=P{X∈(t, t+dt)} P{X>t} ≈f(t)·dt F(t) =r(t)·dt Thusr(t)represents the instantaneous failure rate of a t-year-old item. Deﬁnition 11.1 When r(t)is strictly decreasing in t, we say that the distribution f(t)hasdecreasing failure rate ;i fr(t)is strictly increasing in t, we say that the distribution has increasing failure rate . Observe that in general r(t)is not necessarily going to always decrease with tor increase with t– it might behave differently for different t. Question: Suppose r(t)is constant. What do you know about f(t)? Answer: In Exercise 11.4, we prove that f(t)must be the Exponential p.d.f.",4523
11.3 Relating Exponential to Geometric via -Steps,"11.3 relating exponential to geometric via δ-steps 209 Bank Example Question: If the time a customer spends in a bank is Exponentially distributed with mean 10 minutes, what is P{Customer spends >5 min in bank }? Answer: e−5·1/10=e−1/2. Question: What is P{Customer spends >15 min in bank total |he is there after 10 min}? Answer: Same as previous answer. The reason why the Exponential distribution is so convenient to work with is that history does not matter. Question: Suppose X∼Exp(λ). What is E[X|X>20]? Answer: The Exponential distribution “starts over” at 20, or at any other point. Hence, E[X|X>20] = 20 + E[X] = 20 +1 λ. Post Ofﬁce Example Suppose that a post ofﬁce has two clerks. Customer Bis being served by one clerk, and customer Cis being served by the other clerk, when customer Awalks in. All service times are Exponentially distributed with mean1 λ. Question: What is P{Ais the last to leave }? Answer:1 2. Note that either BorCwill leave ﬁrst. WLOG, let us say Bleaves ﬁrst. ThenCandAwill have the same distribution on their remaining service time. It does not matter that Chas been served for a while. It can be proven that the Exponential distribution is the only continuous-time memo- ryless distribution. Question: What is the only discrete-time memoryless distribution? Answer: The Geometric distribution. 11.3 Relating Exponential to Geometric via δ-Steps We ﬁnd it very helpful when reasoning about Exponential random variables to instead think about Geometric random variables, for which we have more intuition. We like tothink of the Exponential distribution as the “continuous counterpart” of the Geometric distribution by making the following analogy: Recall that the Geometric distribution can be viewed as the number of ﬂips needed to get a “success.” The distribution of the remaining number of ﬂips is independent of how many times we have ﬂipped so far.The same holds for the Exponential distribution, which is the time until “success.” To unify the Geometric and Exponential distributions, we introduce the notion of a “ δ-step proof.” Throughout the next few chapters, we will use this way of thinking to 210 exponential distribution and the poisson process come up with quick intuitions and arguments.1The idea is to imagine each unit of time as divided into npieces, each of size δ=1 n, and suppose that a trial (ﬂip) occurs every δtime period, rather than at unit times. Let X∼Exp(λ). We now deﬁne a random variable Y, where Yis Geometrically distributed with probability p=λδof getting a head, for some small δ→0. However, rather than ﬂipping every unit time step, we ﬂip every δ-step. That is, Y∼Geometric (p=λδ|ﬂip every δ-step). Observe that Ydenotes the number of ﬂips until success. Now deﬁne /tildewideYto be the time until success under Y: /tildewideY=Time associated with Y Observe that as δ→0(orn→∞ ),/tildewideYbecomes a positive, real-valued random variable, because success can occur at any time. Question: What is E/bracketleftBig /tildewideY/bracketrightBig ?H o wi s/tildewideYdistributed? Answer: The mean of/tildewideYis1 λ. E/bracketleftBig /tildewideY/bracketrightBig =(avg. number trials until success) ·(time per trial) =1 δλ·δ=1 λ To understand the distribution of /tildewideY, we observe that /tildewideY> t if all the trials up to at least timethave been failures (i.e., we have had at least t/δfailures). P/braceleftBig /tildewideY> t/bracerightBig =P/braceleftbigg at leastt δfailures/bracerightbigg =( 1−δλ)t δ =[ ( 1−δλ)1 δ]t =/bracketleftBigg/parenleftbigg 1−1 1 δλ/parenrightbigg1 δλ·λ/bracketrightBiggt −→[(e−1)λ]t,a sδ→0 =e−λt This says that /tildewideY∼Exp(λ). 1I concocted this notion of a δ-step proof as a PhD student, struggling with messy integrals. The δ-step proofs helped me reason about properties of the Exponential distribution and Poisson process. They also helped me leverage my understanding of DTMCs to quickly reason about CTMCs (see Chapter 12).",3937
11.4 More Properties of the Exponential,"11.4 more properties of the exponential 211 We have thus seen that an Exponential random variable with rate λrepresents the time to a successful event, given that an event occurs every δ-step and is successful with probability λδ, where δ→0.This is depicted in Figure 11.2. λδ λδ δ 2δ 3 0 δ (n–1)δ nδ Exp( λ)UnitedStatesofQueueingλδUnitedStatesofQueueingλδUnitedStatesofQueueingλδUnitedStatesofQueueing Figure 11.2. Geometric depiction of the Exp (λ)distribution. Time is divided into steps of duration δ, and a coin (with probability λδof “heads”) is ﬂipped only at each δ-step. 11.4 More Properties of the Exponential Before we continue, here is a useful deﬁnition: Deﬁnition 11.2 f=o(δ)iflim δ→0f δ=0. For example, f=δ2iso(δ)becauseδ2 δ→0asδ→0. Basically, a function is o(δ) if it goes to zero faster than δ,a sδ→0.2 We now illustrate how to combine the o(δ)notation with the discretized view of an Exponential to prove a few properties of the Exponential distribution. Theorem 11.3 Given X1∼Exp(λ1),X2∼Exp(λ2),X1⊥X2, P{X1<X 2}=λ1 λ1+λ2. Proof (Traditional Algebraic Proof) P{X1<X 2}=/integraldisplay∞ 0P{X1<X 2|X2=x}·f2(x)dx =/integraldisplay∞ 0P{X1<x}·λ2e−λ2xdx 2This deﬁnition may seem a little odd, if one is used to theoretical computer science where “big-O” and “little-o” notation are deﬁned in terms of some n→∞ , not as δ→0. 212 exponential distribution and the poisson process =/integraldisplay∞ 0(1−e−λ1x)(λ2e−λ2x)dx =/integraldisplay∞ 0λ2e−λ2xdx−λ2/integraldisplay∞ 0e−(λ1+λ2)xdx =1−λ2 λ1+λ2 =λ1 λ1+λ2 Here is the more intuitive proof, by analogy with the Geometric distribution: Proof (Intuitive Geometric Proof) Success of type 1 occurs with probability λ1δon eachδ-step. Independently, success of type 2 occurs with probability λ2δon each δ-step. The problem is really asking the following: Given that a success of type 1 or type 2 has occurred, what is the probability that it is a success of type 1? P{type 1|type 1 or type 2 }=P{type 1} P{type 1 or type 2 } =λ1δ λ1δ+λ2δ−(λ1δ)(λ2δ) =λ1δ λ1δ+λ2δ−o(δ) =λ1 λ1+λ2−o(δ) δ =λ1 λ1+λ2asδ→0 Example There are two potential failure points for our server: the power supply and the disk. The lifetime of the power supply is Exponentially distributed with mean 500 days, and thelifetime of the disk is independently Exponentially distributed with mean 1,000 days. Question: What is the probability that the system failure, when it occurs, is caused by the power supply? Answer:1 500 1 500+1 1000. Theorem 11.4 Given X1∼Exp(λ1),X2∼Exp(λ2),X1⊥X2. Let X=m i n ( X1,X2). Then X∼Exp(λ1+λ2).",2543
11.5 The Celebrated Poisson Process,"11.5 the celebrated poisson process 213 Proof (Traditional Algebraic Proof) P{X>t}=P{min(X1,X2)>t} =P{X1>tandX2>t} =P{X1>t}·P{X2>t} =e−λ1t·e−λ2t =e−(λ1+λ2)t Here is an alternative argument by analogy with the Geometric distribution: Proof (Intuitive Geometric Proof) 1.A trial occurs every δ-step. 2.The trial is “successful of type 1” with probability λ1δ. 3.The trial is “successful of type 2” independently with probability λ2δ. 4.We are looking for the time until there is a success of either type. A trial is “successful” (either type) with probability λ1δ+λ2δ−(λ1δ)·(λ2δ)=δ/parenleftbigg λ1+λ2−o(δ) δ/parenrightbigg . 5.Thus the time until we get a “success” is Exponentially distributed with rate λ1+λ2+o(δ) δ, and as δ→0this gives the desired result. Question: In the server from the previous example, what is the time until there is a failure of either the power supply or the disk? Answer: Exponential with rate/parenleftBig 1 500+1 1,000/parenrightBig . 11.5 The Celebrated Poisson Process The Poisson process is the most widely used model for arrivals into a system for two reasons: 1.The Markovian properties of the Poisson process make it analytically tractable. 2.In many cases, it is an excellent model. For example, (a) In communications networks, such as the telephone system, it is a good model for the sequence of times at which telephone calls are originated. Althoughthe calls of a single user do not look like a Poisson process, the aggregateover many users does. (b) Many physical phenomena behave in a Poisson fashion, such as the sequence of gamma ray emissions from a radioactive substance. 214 exponential distribution and the poisson process The Poisson process appears often in nature when we are observing the aggregate effect of a large number of individuals or particles operating independently. The reason for this is explained by the Limiting Theorem (due to Palm ’43, Khinchin ’60, and described in [ 105] pp. 221–228). This theorem states that if you merge n(assume that nis very large) identical and independently distributed arrival processes, each with an arrival rateλ n, where each of the arrival processes is a renewal process with an arbitrary ﬁxed interarrival distribution F, then the aggregate arrival process approaches a Poisson process with rate λ. When considering questions on resource allocation, task assignment, scheduling, and the like, we ﬁnd that, whereas the job size distribution has a large effect on meanresponse times, the arrival process of jobs typically has much less of an effect. Specif-ically, assuming a Poisson arrival process for arrivals allows us to analytically predictresponse times, and these predictions are often not too far from results based on trace- driven simulation. Before we deﬁne a Poisson process, we need a little terminology. Consider a sequence of events: t 0Events time Deﬁne N(t),t≥0as the number of events that occurred by time t. Deﬁnition 11.5 An event sequence has independent increments if the numbers of events that occur in disjoint time intervals are independent. Speciﬁcally, for all t0<t1<t2<...<t n, the random variables N(t1)−N(t0),N(t2)−N(t1),...,N (tn)−N(tn−1) are independent. Example Let us look at three event processes: 1.births of children 2.people entering a building 3.goals scored by a particular soccer player Question: Do these event processes have independent increments? 11.5 the celebrated poisson process 215 Answer: 1.No. Birth rate depends on population, which increases with births. 2.Yes. 3.Maybe. Depends on whether we believe in slumps. Deﬁnition 11.6 The event sequence has stationary increments if the number of events during a time period depends only on the length of the time period and noton its starting point. That is, N(t+s)−N(s)has the same distribution for all s. Deﬁnition 1 of the Poisson Process : APoisson process having rate λis a sequence of events such that 1.N(0) = 0 . 2.The process has independent increments. 3.The number of events in any interval of length tis Poisson distributed with meanλt. That is,∀s, t≥0, P{N(t+s)−N(s)=n}=e−λt(λt)n n.n=0,1,... Question: Why is λcalled the “rate” of the process? Answer: Observe that E[N(t)] =λt,s oE[N(t)] t=λ. Question: Why only “independent increments” ? Answer: The third item in the deﬁnition implies stationary increments, because the number of events within an interval of length tdepends only on t. Observe that the assumption of stationary and independent increments is equivalent to asserting that, at any point in time, the process probabilistically restarts itself ; that is, the process from any point onward is independent of all that occurred previously (byindependent increments) and also has the same distribution as the original process (bystationary increments). Simply put, a Poisson process has no memory. This leads us tothe second deﬁnition of the Poisson process. Deﬁnition 2 of the Poisson Process : APoisson process with rate λis a sequence of events such that the interarrival times are i.i.d. Exponential random variables with rate λandN(0) = 0 . Question: Which deﬁnition of a Poisson process would you use when trying to simulate a Poisson process: Deﬁnition 1 or Deﬁnition 2? Answer: Deﬁnition 2. 216 exponential distribution and the poisson process Deﬁnition 1 ⇒Deﬁnition 2 LetT1,T2,...,T n,... be the interarrival times of a sequence of events. We need to show that Ti∼Exp(λ),∀i. By Deﬁnition 1, P{T1>t}=P{N(t)=0}=e−λt(λt)0 0.=e−λt. Next, P/braceleftBigg Tn+1>t/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglen/summationdisplay i=1Ti=s/bracerightBigg =P/braceleftBigg 0 events in (s, s+t)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglen/summationdisplay i=1Ti=s/bracerightBigg =P{0 events in (s, s+t)}, by independent increments =e−λt, by stationary increments . Deﬁnition 2 ⇒Deﬁnition 1 Feller [ 58], p. 11, has a rigorous algebraic proof that Deﬁnition 2 ⇒Deﬁnition 1. The idea is to show that the sum of ni.i.d. Exp (λ)random variables has a Gamma, Γ(n,λ), distribution. Feller then uses the Γ(n,λ)distribution to show that the number of arrivals by time thas a Poisson distribution. Rather than going through this tedious algebraic proof, we instead provide an argument by analogy with the Geometric distribution: N(t)refers to the number of arrivals by timet. Our goal is to prove that N(t)∼Poisson (λt). Think of an “arrival” as being a “success.” Exp (λ)interarrival times correspond to ﬂipping a coin every δ-step, where a ﬂip is a success (i.e., arrival) with probability λδ. N(t)=Number of successes (arrivals) by time t ∼Binomial (# ﬂips,probability of success of each ﬂip ) ∼Binomial/parenleftbiggt δ,λ δ/parenrightbigg Observe above that as δ→0,t δbecomes very large and λδbecomes very small. Question: Now what do you know about Binomial( n,p) for large nand tiny p? Answer: Recall from Exercise 3.12 that Binomial (n,p)→Poisson (np),asn→∞ andp→0. So asδ→0, N(t)∼Poisson/parenleftbiggt δ·λδ/parenrightbigg =Poisson (λt). 11.5 the celebrated poisson process 217 Deﬁnition 3 of the Poisson Process : APoisson process having rate λis a sequence of events such that 1.N(0) = 0 . 2.The process has stationary and independent increments. 3.P{N(δ)=1}=λδ+o(δ). 4.P{N(δ)≥2}=o(δ). We have shown that Deﬁnition 1 ⇔Deﬁnition 2. To show that all three deﬁnitions are equivalent, we now show that Deﬁnition 1 ⇔Deﬁnition 3. Deﬁnition 1 ⇒Deﬁnition 3 This is taken from [ 127], p. 245: P{N(δ)=1}=e−λδ(λδ)1 1. =λδ/bracketleftbigg 1−λδ+(λδ)2 2.−···/bracketrightbigg =λδ−λ2(δ)2+λ3(δ)3 2−··· =λδ+o(δ) P{N(δ)=i}=e−λδ(λδ)i i. =(λδ)i i./parenleftbigg 1−λδ+(λδ)2 2.−···/parenrightbigg =λiδi i.+o(δi) So P{N(δ)≥2}=∞/summationdisplay i=2P{N(δ)=i}=∞/summationdisplay i=2/parenleftbiggλiδi i.+o(δi)/parenrightbigg =o(δ). Deﬁnition 3 ⇒Deﬁnition 1 A slightly approximate argument is provided in [ 149], Ch. 2, which is very intuitive and which we repeat here. To show that N(t)∼Poisson (λt), rSubdivide [0,t]into increments of length δ→0. rP{Any interval has ≥2events} ≤(# of intervals )·P{Single interval has ≥2events} =t δ·o(δ) =t·o(δ) δ→0,asδ→0.",8099
11.6 Merging Independent Poisson Processes. 11.7 Poisson Splitting,"218 exponential distribution and the poisson process rSo now we can think of each δ-size interval as having 1 event with probability λδ+o(δ)and otherwise having 0 events (note this is just an approximation). rBut now we see that N(t), the number of events by time tis simply N(t)∼Binomial/parenleftbiggt δ,λ δ+o(δ)/parenrightbigg →Poisson/parenleftbiggt δ(λδ+o(δ))/parenrightbigg asδ→0 =Poisson/parenleftbigg λt+to(δ) δ/parenrightbigg →Poisson (λt). 11.6 Merging Independent Poisson Processes Theorem 11.7 Given two independent Poisson processes, where process 1 has rateλ1and process 2 has rate λ2, the merge of process 1 and process 2 is a single Poisson process with rate (λ1+λ2). Proof Process 1 has Exp (λ1)interarrival times. Process 2 has Exp (λ2)interarrival times. The time until the ﬁrst event from either process 1 or process 2 is the time untilthe minimum of Exp (λ1)and Exp (λ2), which is distributed Exp (λ1+λ2). Likewise, the time until the second event is also distributed Exp (λ1+λ2), etc. Thus by Deﬁnition 2 of the Poisson process we have a Poisson process with rate λ1+λ2. Alternative Proof LetNi(t)denote the number of events in process iby time t. N1(t)∼Poisson (λ1t) N2(t)∼Poisson (λ2t) Yet the sum of two independent Poisson random variables is still Poisson with the sum of the means, so N1(t)+N2(t)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright merged process∼Poisson (λ1t+λ2t). /squaresolid 11.7 Poisson Splitting Theorem 11.8 Given a Poisson process with rate λ, suppose that each event is classiﬁed “type A” with probability pand “type B” with probability 1−p. Then type A events form a Poisson process with rate pλ, type B events form a Poisson process with rate (1−p)λ, and these two processes are independent. Speciﬁcally, 11.7 poisson splitting 219 ifNA(t)denotes the number of type A events by time t, andNB(t)denotes the number of type B events by time t, then P{NA(t)=n,N B(t)=m}=P{NA(t)=n}·P{NB(t)=m} =e−λtp(λtp)n n.·e−λt(1−p)(λt(1−p))m m.. This is one of those theorems that is very difﬁcult to prove if you just stick to the idea of Exponential interarrival times. It is really not clear why the times between the typeA events end up being Exponentially distributed with rate λpas opposed to something else. Consider the original Poisson process and a sequence of coin ﬂips with bias p. When the coin ﬂip comes up “heads” (this happens with probability p), then the event is classiﬁed “type A.” If we now consider a sequence of just the type A events, we might imagine that the time between type A events would be Exp( λ), for a time period during which the coin ﬂips had a streak of “heads,” and then there might be a largeinterarrival time consisting of some sum of Exp( λ)’s during the time period when the coin ﬂips had a streak of “tails,” after which we return to an interarrival time ofExp (λ). It is not at all clear why the interarrival times between type A events are actually Exp(λp). However, this theorem is very easy to understand by analogy with the Geometric distribution. We ﬁrst provide intuition for the theorem, by making use of the Geometric δ-step arguments. We then provide a rigorous proof of the theorem. Intuition – by Analogy with the Geometric Distribution The original process has Exp( λ) interarrival times, which is equivalent to tossing a coin everyδ→0steps, where the coin comes up “success” with probability λδ. We refer to this λδcoin as the “ﬁrst” coin. Each success (head) of the ﬁrst coin is labeled as a type A success with probability p. Thus we can imagine a second coin being ﬂipped, where the second coin has probability pof success. Only if both the ﬁrst and second coins are successes do we have a type A success. But this is equivalent to ﬂipping just a single coin with probability λδp of success. The time between type A successes is then distributed Exp(λp). This proof is illustrated in Figure 11.3 and can be repeated for type B events. Proof This proof is taken from [ 150], p. 258. What makes this proof precise is that (1) it uses no approximations and (2) it explicitly proves independence. Let N(t)=Number of events by time tin the original process NA(t)=Number of type A events by time t NB(t)=Number of type B events by time t The idea is to compute the joint probability that there are nevents of type A and mevents of type B by time t,P{NA(t)=n,N B(t)=m}, and then to use this to compute 220 exponential distribution and the poisson process δ 2δ 0λδ λδ λδ λδ λδ λδ λδp p p p p p p First coin δ 2δ 0λδp λδp λδp λδp λδp λδp λδp λδp Single coinSecon d coin Type A success time = Exp( λp) Figure 11.3. A “type A success” only occurs if both the λδ-coin and the p-coin are heads. P{NA(t)=n}andP{NB(t)=m}, so that we can verify the independence of the two processes. P{NA(t)=n, N B(t)=m} =∞/summationdisplay k=0P{NA(t)=n, N B(t)=m|N(t)=k}·P{N(t)=k} =P{NA(t)=n, N B(t)=m|N(t)=n+m}·P{N(t)=n+m} (because this is the only non-zero term in the above sum) =P{NA(t)=n, N B(t)=m|N(t)=n+m}·e−λt(λt)n+m (n+m). =/parenleftbigg n+m n/parenrightbigg pn(1−p)me−λt(λt)n+m (n+m). =(m+n). n.m.pn(1−p)me−λt(λt)n+m (n+m). =e−λtp(λtp)n n.·e−λt(1−p)(λt(1−p))m m.(11.1)",5164
11.9 Exercises,"11.8 uniformity 221 Now to compute P{NA(t)=n}, we simply sum the joint probability, ( 11.1), over all values of m, as follows: P{NA(t)=n}=∞/summationdisplay m=0P{NA(t)=n,N B(t)=m} =e−λtp(λtp)n n.∞/summationdisplay m=0e−λt(1−p)(λt(1−p))m m. =e−λtp(λtp)n n. In a similar fashion we can show that P{NB(t)=m}=e−λt(1−p)(λt(1−p))m m.. Hence by ( 11.1), we have that P{NA(t)=n,N B(t)=m}=P{NA(t)=n}·P{NB(t)=m},(11.2) showing that the processes are independent. Now because the other conditions in Deﬁnition 1 such as independent increments are also obviously satisﬁed, we have that {NA(t),t≥0}forms a Poisson process with rate λpand{NB(t),t≥0}forms an independent Poisson process with rate λ(1−p). 11.8 Uniformity Theorem 11.9 Given that one event of a Poisson process has occurred by time t, that event is equally likely to have occurred anywhere in [0,t]. Proof LetT1denote the time of the one event. P{T1<s|N(t)=1}=P{T1<sandN(t)=1} P{N(t)=1} =P{1 event in [0,s]and 0 events in [s, t]} e−λt(λt)1 1. =P{1 event in [0,s]}·P{0 events in [s, t]} e−λt·λt =e−λs·λs·e−λ(t−s)·(λ(t−s))0 e−λt·λt =s t 222 exponential distribution and the poisson process Generalization: Ifkevents of a Poisson process occur by time t, then the kevents are distributed independently and uniformly in [0,t]. This is proven in [ 149], pp. 36–38. 11.9 Exercises 11.1 Memorylessness LetX∼Exp(λ). What is E[X|X>10]? Solve this in two ways: (a) by integrating the conditional p.d.f. (b) by a two-line argument via the memoryless property of Exponential dis- tribution. 11.2 Memorylessness Continued Given X∼Exp(1), what is E[X2|X>10]? 11.3 Doubling Exponentials Suppose that job sizes are Exponentially distributed with rate μ. If job sizes all double, what can we say about the distribution of job sizes now? Prove it. 11.4 Failure Rate LetXbe a continuous random variable with probability density function f(t)and cumulative distribution function F(t)=P{X<t}. We deﬁne the failure rate of Xto ber(t), where r(t)≡f(t) F(t). Thusr(t)dtrepresents the probability that a t-year-old item will fail in the nextdtseconds. (a) Prove that for the Exponential distribution, the failure rate is a constant. (b) Prove that the Exponential distribution is the only distribution with constant failure rate. 11.5 Practice with Deﬁnition of Poisson Process (a) Consider a stream of packets arriving according to a Poisson process with rateλ=5 0 packets/sec. Suppose each packet is of type “green” with probability 5 percent and of type “yellow” with probability 95 percent. Given that 100 green packets arrived during the previous second, (i) what is the expected number of yellow packets that arrived during the previous second? (ii) what is the probability that 200 yellow packets arrived during the previoussecond? (b) Red packets arrive according to a Poisson process with rate λ1=3 0 packets/sec. Black packets arrive according to a Poisson process with rate λ2=1 0 packets/sec. Assume the streams are statistically multiplexed into one stream. Suppose we are told that 60 packets arrived during the second. What is the probability that exactly 40 of those were red? (c) Suppose packets arrive according to a Poisson process with rate λ, and you are told that by time 30 seconds 100 packets have arrived. What is the probability that 20 packets arrived during the ﬁrst 10 seconds? 11.9 exercises 223 11.6 Number of Arrivals of a Poisson Process during a Service In this chapter, we considered, N(t), the number of Poisson( λ) arrivals during a time t. In queueing, one often needs to know AS, the number of Poisson( λ) arrivals during S, where Sis a continuous random variable denoting, say, the service time of a job. Derive E[AS]andVar(AS). 11.7 Malware and Honeypots A new malware is out in the Internet. Our goal is to estimate its spread/damage by time t, assuming it starts at time 0. Assume that the Internet hosts get infected by this malware according to a Poisson process with parameter λ, where λis not known . Thrasyvoulos installs a Honeypot security system to detect whether hosts are infected. Unfortunately there is a lag time between when a computer is infected by the malware and the Honeypot detects the damage. Assume that this lag time is distributed Exp (μ). Suppose that Thrasyvoulos’s Honeypot system has detected N1(t)infected hosts by time t. Thrasyvoulos worries that, because of the lag, the number of infected hosts is actually much higher than N1(t). The goal of the problem is to understand how many additional hosts, N2(t), are expected to also be infected at time t. (a) Suppose that an infection happens at time s, where 0<s<t . What is the probability that the infection is detected by time t? (b) Consider an arbitrary infection that happens before time t. What is the (un- conditional) probability, p, that the infection is detected by the Honeypot by time t? (c) How can we use our knowledge of N1(t)to estimate λ? (d) Use your estimate of λto determine the expected value of N2(t). [Note: None of the above solutions requires more than a couple lines.] 11.8 Sum of Geometric Number of Exponentials3 LetN∼Geometric (p). LetXi∼Exp(μ). LetSN=/summationtextN i=1Xi. Your goal is to prove that SNis Exponentially distributed and derive the rate of SN. Prove this fact using δ-step arguments. [ Note: In Chapter 25you will see how to prove this same result using transforms.] 11.9 Reliability Theory: Max of Two Exponentials Redundancy is often built into systems so that if a device (say a disk) fails there is no catastrophe. In these settings, we are often concerned with the expectedtime until both disks fail, which is the time until a catastrophe occurs. This can be viewed as the “max” of two random variables.(a) Let X1∼Exp(λ). Let X2∼Exp(λ). Suppose X1⊥X2. What is E[max( X1,X2)]? (b) Let X1∼Exp(λ1). LetX2∼Exp(λ2). Suppose X1⊥X2. What is E[max( X1,X2)]? 11.10 Exponential Downloads You need to download two ﬁles: ﬁle 1 and ﬁle 2. File 1 is available via source A or source B. File 2 is available only via source C. The time to download 3Warning: The result of Exercise 11.8 will be used many times throughout the book. 224 exponential distribution and the poisson process ﬁle 1 from source A is Exponentially distributed with rate 1. The time to download ﬁle 1 from source B is Exponentially distributed with rate 2. The time to download ﬁle 2 from source C is Exponentially distributed with rate 3. You decide to download from all three sources simultaneously, in the hope that you get both ﬁle 1 and ﬁle 2 as soon as possible. Let Tdenote the time until you get both ﬁles. (a) What is E[T]? (b) What is P{T<t}? 11.11 Reliability Theory: Max of Many Exponentials LetX1,X2,X3,...,X nbe i.i.d. Exponentially distributed random variables all with rate λ. Let Z= max( X1,X2,...,X n). (a)What is E[Z]? (b)Roughly, what does E[Z]look like as a function of nandλwhennis high? (c)Derive the distribution of Z. 11.12 Conditional Distribution LetX∼Exp(λX)andY∼Exp(λY), where X⊥Y. LetZ=m i n ( X,Y). Prove that (X|X<Y )∼Z. That is, show that P{X>t|X<Y}=P{Z>t}.",7044
Chapter 12 Transition to Continuous-Time Markov Chains. 12.1 Defining CTMCs,"CHAPTER 12 Transition to Continuous-Time Markov Chains 12.1 Deﬁning CTMCs Recall the deﬁnition of a DTMC (repeated from Deﬁnition 8.1): Deﬁnition 12.1 ADTMC (Discrete-Time Markov Chain) is a stochastic process {Xn,n=0,1,2,...}, where Xndenotes the state at (discrete) time step nand such that,∀n≥0,∀i, j, and∀i0,...,i n−1, P{Xn+1=j|Xn=i, Xn−1=in−1,...,X 0=i0}=P{Xn+1=j|Xn=i} =Pij(by stationarity) , where Pijis independent of the time step and of past history. Notice the three properties of Deﬁnition 12.1: 1.Transitions are always made at discrete time steps, n=0,1,2,... 2.The past does not matter. Only the present state matters. In particular, it does not matter how long the Markov chain was sitting in state ialready. This is the Markovian Property (M.P.). 3.Transition probabilities are “stationary,” meaning that they are independent of time step n. Continuous-Time Markov Chains (CTMCs) are the continuous-time analogue of DTMCs. Thus we keep properties 2 and 3 of DTMCs. However, we replace prop-erty 1 with: “transitions between states can happen at any time.” Deﬁnition 12.2 AContinuous-Time Markov Chain (CTMC) is a continuous-time stochastic process {X(t),t≥0}s.t.,∀s, t≥0and∀i,j,x(u), P{X(t+s)=j|X(s)=i,X(u)=x(u),0≤u≤s} =P{X(t+s)=j|X(s)=i}(by M.P.) =P{X(t)=j|X(0) = i}=Pij(t)(stationarity) . We assume throughout that the state space is countable. Now consider the quantity τi, deﬁned next. Deﬁnition 12.3 Deﬁne τito be the time until the CTMC leaves state i, given that the CTMC is currently in state i. 225 226 transition to continuous-time markov chains By the Markovian and stationary properties of the CTMC, the probability that the CTMC leaves state iin the next tseconds is independent of how long the CTMC has already been in state i. That is, P{τi>t+s|τi>s}=P{τi>t}. Question: What does this say about τi? Answer: This says that τiis memoryless. But this means τiis Exponentially dis- tributed. This means that we can deﬁne a CTMC as follows: Deﬁnition 12.4 CTMC – VIEW 1: A CTMC is a stochastic process with the property that every time it enters state i, the following hold: 1.The amount of time the process spends in state ibefore making a transition is Exponentially distributed with some rate (call it νi). 2.When the process leaves state i, it will next enter state jwith some probability (call it pij) independent of the time spent at state i. VIEW 1 of a CTMC is depicted in Figure 12.1. In this view, we stay in state ifor timeτi∼Exp(νi). When we leave i, we transition to jwith probability pij, where/summationtext jpij=1. Sit here for time Exp( νi); then flip coin to determine  where to go next.pij pik pilj lk i Figure 12.1. VIEW 1 of a CTMC. Observe that pij, the probability that when we leave iwe next go to state j, is a constant. It is independent of time, t, by stationarity. It is independent of the time spent in state i,τi, by the Markovian property. Consider the moment just before we leave state i. At this moment, the time we have spent in state iis irrelevant: That is all history (Markovian assumption). All that is relevant is that we are at state iat this moment s. The particular time sis irrelevant as well (stationarity assumption).There is an alternative way to view CTMCs (we call it VIEW 2) that is more practical. 12.1 deﬁning ctmcs 227 Deﬁnition 12.5 CTMC – VIEW 2: LetXj∼Exp(νipij)represent the time to transition from itoj,∀j/negationslash=i. Letτi=m i n j{Xj}be the time until the Markov chain leaves state i. Let the next state be mwhere m=a r g m i n j{Xj}, i.e.,Xmwas themin j{Xj}. This deﬁnition may seem confusing. Here is what VIEW 2 is really saying (see Fig- ure12.2): Think of yourself as sitting in state i(home) on a Saturday night and waiting to receive a phone call that will tell you where to move next. There are three possible transitions that you can take: to j,t ok,o rt o l(these are the names of the three dates who might call). You have three phones. The ﬁrst is a direct line to state jsojcan call you and invite you over. The second is a direct line to state k. The third is a direct line to state l. You will go to whomever calls you ﬁrst – you are desperate. The time until you receive a phone call from state jis a random variable Xj∼Exp(νipij). Independently, the time until you receive a phone call from state kis a random variable Xk∼Exp(νipik). The time until you receive a phone call from state lis a random variable Xl∼Exp(νipil). All of Xj,Xk,Xlare taking place simultaneously. As soon as you get any phone call, you leave state iand go to the party who called you, and the process starts all over again at that state. j lk i Sit here until get  first phone call.Exp( νi · pij) time until call Exp( νi · pik) time until call Exp( νi · pil) time until call Figure 12.2. VIEW 2 of a CTMC. It is not at all obvious that VIEW 1 is equivalent to VIEW 2. Proof That VIEW 2 ⇒VIEW 1 Using VIEW 2, consider the time spent in state i, namely τi. τi=m i n j{Xj}∼ Exp/parenleftBigg/summationdisplay jνipij/parenrightBigg =Exp(νi). Furthermore, the probability that from state iwe transition to state mis: P/braceleftbigg Xm=m i n j{Xj}/bracerightbigg =νipim/summationdisplay jνipij=pim. /squaresolid 228 transition to continuous-time markov chains Heuristic Proof That VIEW 1 ⇒VIEW 2 Using VIEW 1, we describe the Markov chain as sitting in state ifor Exp (νi)time. After that a “direction coin” is ﬂipped. With probability pijthe direction coin points toj. With probability pikthe direction coin points to k. With probability pilthe direction coin points to l. To make this more concrete, let’s assume pij=1 2,pik=1 3, pil=1 6. Now let’s translate the above into its Geometric analogue: The Markov chain (MC) sits in state iﬂipping a coin every δsteps. The coin has probability νiδof success. The MC waits for a success. As soon as it gets a success, it ﬂips the direction coin to determine the type of its success. This description is equivalent to the following: The MC sits in state iﬂipping a coin everyδsteps. With probability νi·1 2δ, the coin is a “success type j.” With probability νi·1 3δ, the coin is a “success type k.” With probability νi·1 6δ, the coin is a “success typel.” With probability 1−νiδ, the coin is not a success. The Markov chain waits for a success (of any type) and heads to the appropriate next destination (based on the type of the success). Considering those coin ﬂips solely from the perspective of whether they lead to a success of type j, we see that the time until a success of type jis Exp(νipij). Like- wise, independently and in parallel, we see that the time until a success of type k is Exp(νipik). And again, independently and in parallel, we see that the time until a success of type lis Exp(νipil). But this is exactly VIEW 2. /squaresolid Remark: The heuristic proof can be made a little more rigorous by including the o(δ)probabilities that two success types happen on a given δtime step. We have not included this detail because it washes out in the end as you will see in later examples. Example Let us model the single-server network shown in Figure 12.3 as a CTMC. Here the state is the number of jobs in the system. Poisson ( λ) e.g., λ = 3 jobs/sec Service demand ~Exp( μ) e.g., μ = 5 jobs/secμ Figure 12.3. A single-server network. Using VIEW 2, we arrive at the equivalent picture shown in Figure 12.4 about which we make the following remarks:",7384
12.2 Solving CTMCs,"12.2 solving ctmcs 229 1 0λ λλ 2 Figure 12.4. VIEW 2 of the same single-server network. rλandμarenotprobabilities (we can have λ=3,μ=5). rAn event is something that changes our state. rSuppose we are in state i, where i≥1. Then the next event is either an arrival or a departure. rLetXAdenote the time to the next arrival. Then XA∼Exp(λ)regardless of how long we have been in the current state. Let XDdenote the time to the next departure. Then XD∼Exp(μ)regardless of how long we have been in the current state. XAandXDare independent of each other. rThe previous two events are happening in parallel. One of these, the arrival or the departure, will occur ﬁrst. So τi, the time until we leave state i, has the following distribution: τi∼Exp(λ+μ). Thus, νi=λ+μ. rThe probability that when we leave state iwe will next go to state i+1 is P{XA<X D}=λ λ+μ. 12.2 Solving CTMCs Letπj= lim t→∞Pij(t)=limiting probability of being in state j. How do we deter- mine the πj’s? Different books have different ways of leading the reader to the right method. Ross[149] (see Section 4.8 and then Section 5.5) goes through semi-Markov chains. Trivedi [179] goes through Kolmogorov equations. Gallager [ 66] goes through semi-Markov chain theory and embedded Markov chains. We go through a more intuitive argument for obtaining the limiting probabilities. For ease of readability, we continue to refer to the previous very simple chain example, buteverything generalizes to more complex CTMCs, as we discuss later. 1.Suppose you had a DTMC . Then you would know how to obtain the πi’s: Simply check for aperiodicity and irreducibility, and then try to solve the stationary equations, as explained in Theorem 9.27. If a solution to the stationary equations exists, that solution is the limiting probability. If no solution to the stationary equations exists, then all the limiting probabilities are zero. 2.But we do not have a DTMC ; we have a CTMC. 3.However, we can model the CTMC via a DTMC . In the CTMC, if we are in statei, rTime to next arrival ∼Exp(λ) 230 transition to continuous-time markov chains rTime to next departure ∼Exp(μ) rTime until ﬁrst of these occurs (i.e., leave state i)∼Exp(λ+μ). We can model this situation by ﬂipping two coins simultaneously every δ-step, where δ→0, as shown in Figure 12.5. δ 2δ 3δ 4δ 5δ 6δ +1 +1 +0 +0 +0 –1μδλδ λδ μδλδ λδ λδ λδ μδ μδ μδ μδ Depart ure Number of jobs:Arrival Figure 12.5. Flipping two coins simultaneously each δ-step, one with probability λδof heads and the other with probability μδof heads. The ﬁrst coin represents arrivals. When the ﬁrst coin is ﬂipped at each δ-step, it has probability λδof returning “arrival” and probability 1−λδof returning nothing. The second coin represents departures. When the second coin is ﬂipped at each δ-step, it has probability μδof returning “departure” and probability 1−μδof returning nothing. A “ﬂip” refers to the result of the two coins. Expanding out the four cases yields rWith probability λδ(1−μδ), the ﬂip returns “arrival and no departure.” rWith probability (1−λδ)μδ, the ﬂip returns “departure and no arrival.” rWith probability λδμδ , the ﬂip returns “arrival and departure.” rWith probability (1−all of the above ), the ﬂip returns “no arrival and no departure.” But this looks just like a DTMC that makes a transition every δsteps with the probabilities shown in Figure 12.6. λδ(1–μδ) μδ(1–λδ)i i–1 1–λδ(1–μδ)–μδ(1–λδ)i+1 Figure 12.6. The equivalent DTMC. 4.Thus the solution to the original CTMC in Figure 12.4 equals the solution to the DTMC in Figure 12.6 where transitions occur at every δ-step. Let’s see if we can clean up this DTMC. 12.2 solving ctmcs 231 We can rewrite λδ(1−μδ)−→λδ+o(δ) μδ(1−λδ)−→μδ+o(δ) λδμδ−→o(δ) (1−all of the above )−→1−λδ−μδ+o(δ), which allows us to represent the DTMC as in Figure 12.7. Observe that the edges are just probabilities, and transitions occur on every δ-step. Observe also that if the DTMC is in state i, with high probability it will still be in state iat the next δ-step. µδ+o(δ)λδ+o(δ) λδ+o(δ) µδ+o(δ)i i–1 1–λδ–µδ+o(δ)i+1 Figure 12.7. The equivalent DTMC with small factors hidden. 5.Let’s solve this DTMC, while taking the limit as δ→0. It simpliﬁes the math to observe that we can ignore self-loops in a DTMC and write balance equations (recall Section 9.6). We then divide by δ, take the limit as δ→0, and solve. Rate leave state 0 =Rate enter state 0 π0(λδ+o(δ)) =π1(μδ+o(δ)) π0/parenleftbigg λ+o(δ) δ/parenrightbigg =π1/parenleftbigg μ+o(δ) δ/parenrightbigg lim δ→0π0/parenleftbigg λ+o(δ) δ/parenrightbigg = lim δ→0π1/parenleftbigg μ+o(δ) δ/parenrightbigg π0·λ=π1·μ ⇒π1=λ μπ0 Rate leave state 1 =Rate enter state 1 π1(λδ+o(δ)+μδ+o(δ)) =π0(λδ+o(δ)) +π2(μδ+o(δ)) lim δ→0π1/parenleftbiggλδ δ+o(δ) δ+μδ δ/parenrightbigg = lim δ→0π0/parenleftbiggλδ δ+o(δ) δ/parenrightbigg +π2/parenleftbiggμδ δ+o(δ) δ/parenrightbigg π1(λ+μ)=π0(λ)+π2(μ) λ μπ0(λ+μ)=λπ0+μπ2 ⇒π2=/parenleftbiggλ μ/parenrightbigg2 π0",4945
12.3 Generalization and Interpretation,"232 transition to continuous-time markov chains Rate leave state 2 =Rate enter state 2 π2(λδ+o(δ)+μδ+o(δ)) =π1(λδ+o(δ)) +π3(μδ+o(δ)) ... π2(λ+μ)=π1(λ)+π3(μ) ⇒π3=/parenleftbiggλ μ/parenrightbigg3 π0 etc. 6.Look at the format of the equations we are left with for the DTMC . These look just like what we would imagine “balance equations” should look like for the original CTMC: π0(λ)=π1(μ) (12.1) π1(λ+μ)=π0(λ)+π2(μ) (12.2) π2(λ+μ)=π1(λ)+π3(μ) (12.3) Consider these in light of our original CTMC, redrawn in Figure 12.8. In the balance equations shown in ( 12.1), (12.2), (12.3),λandμarenotprobabilities, but they behave as if they are with respect to creating the equations. 1 0λ λλ 2 Figure 12.8. Our original CTMC. 7.So it seems that to solve a CTMC, all one has to do is write out the balance equations for the CTMC and solve them . That will result in the same answer as solving the δ-step DTMC, which is equivalent to the CTMC. Note that we have only shown that this statement is true for this particular example. In the nextsection we discuss more general chains. 8.To ﬁnd limiting probabilities via balance (or stationary) equations, we still need to ensure that the DTMC is irreducible and aperiodic so that we can apply thetheory of DTMCs (Theorem 9.27). To do so, it sufﬁces to check that the Markov chain is irreducible (aperiodicity is not an issue in the continuous case). 12.3 Generalization and Interpretation The argument we just presented for translating from a CTMC to a DTMC was applied to one speciﬁc example. Figure 12.9 provides some intuition for why this argument works for a general CTMC. 12.3 generalization and interpretation 233 Assume we start with a general CTMC. Consider a single state ias shown in Figure 12.9. The arcs pointing out of state irepresent Exponential rates. We can model the CTMC as a DTMC where transitions happen every δ-step. The transition probabilities are shown in Figure 12.9. There is a self-loop at state ithat contains the remaining probability of leaving state i. Observe that in the DTMC interpretation, there is some probability that when we are in state i, more than one of our coins will come up a success during a particular ﬂip (single δ-step). However, the probability of such an event is just o(δ). It does not matter how we choose to interpret such an event because the o(δ)washes out. We will react to the event of more than one success in a single δ-step by simply staying at state i. Now we solve the DTMC by writing out the balance equations for the DTMC. The limiting probabilities we obtain for the DTMC are also the limiting probabilities of the original CTMC. Observe that in the DTMC shown in Figure 12.9, if we are in state i, on most δ-step transitions, we simply return to state i. This exactly models the CTMC where we sit in state ifor a while. DTMC with δ-size time step Model it as  an eq uivalent DTMC with δ-stepsStart with an arbitrary irred ucible CTMC (here s a piece of one) Rewrite using  o() notation Theπi’s are  the limitin g probabilities  for the CTMC as well .Now solve  the DTMC  by solvin g the  balance eqns. λk λl λjlk jλlδ(1–λjδ)(1–λkδ) λjδ(1–λlδ)(1–λkδ)λkδ(1–λjδ)(1–λlδ) i lk j λlδ+o(δ) λjδ+o(δ)λkδ+o(δ) i lk ji Figure 12.9. The solution of an arbitrary CTMC using our method.",3277
12.4 Exercises,"234 transition to continuous-time markov chains The point to take away from this is that in practice we do not need to go through the translation to a DTMC with δ-steps. Just think that part and write down the balance equations for the CTMC directly, from which we can solve for the πi’s. 12.3.1 Interpreting the Balance Equations for the CTMC We have been referring to the equations we obtain at the end of the translation as“balance equations.” This name is in fact appropriate because they balance the rate atwhich jobs leave state jin the CTMC with the rate at which jobs enter state jin the CTMC, for each state j. Here is the standard notation for CTMCs: πjνj=/summationdisplay iπiqij (12.4) The left-hand side (LHS) of ( 12.4) is the product of the limiting probability of being in state j,πj, and the rate the MC leaves state jgiven that it is in state j,νj. Thus the LHS represents the total rate of transitions leaving state j. Theith term in the summand of the RHS represents the product of the limiting proba- bility of being in state i, πi, and the rate the MC leaves state ito go to state jgiven that it is in state i, qij. Thus the ith term in the summand of the RHS represents the rate of transitions leaving state ito go to state j. The RHS therefore represents the total rate of transitions entering state jfrom any state. Observe that qij=νi·pij. Hence we can equivalently write: πj/summationdisplay iqji=/summationdisplay iπiqij 12.3.2 Summary Theorem for CTMCs Because CTMCs can basically be viewed as DTMCs in which the time step goes tozero, all the ergodicity theory that we developed for DTMCs carries over to CTMCs.In particular, we have the following summary theorem, analogous to Theorem 9.27. Theorem 12.6 (Summary Theorem for CTMCs) Given an irreducible CTMC, suppose∃πi’s s.t.∀j, πjνj=/summationdisplay iπiqijand/summationdisplay iπi=1. Then the πi’s are the limiting probabilities for the CTMC, and the CTMC is ergodic. 12.4 Exercises 12.1 Converting a CTMC to a DTMC In this chapter we saw how to model any CTMC as a DTMC where the timestep in the DTMC is of length δ. Draw the corresponding DTMC for the CTMC 12.4 exercises 235 in Figure 12.10 . Then write out the DTMC balance equations, take the limit as δ→0, and show the resulting CTMC balance equations. You need not solve them. λ31λ12 λ21 λ32λ23 3 1 2 Figure 12.10. A simple CTMC. 12.2 Potential Pitfall: Balance /negationslash=Stationary for CTMC Recall that for DTMCs, balance equations are equivalent to stationary equa- tions (see Sections 9.6and9.7). For a CTMC, the balance equations yield the limiting probabilities, while the stationary equations are meaningless, un- less we ﬁrst translate to a DTMC. We illustrate this point for the CTMC inFigure 12.10 . (a) Write all the balance equations for the CTMC: πjνj=/summationdisplay iπiqij where/summationdisplay iπi=1 (b) Write all the (meaningless) stationary equations for the CTMC: πj=/summationdisplay iπiqij where/summationdisplay iπi=1 Observe that these do not match the balance equations. (c) Convert the CTMC to a DTMC, as in Exercise 12.1. Now write the balance equations and the stationary equations for the DTMC. Explain why these are equivalent.",3204
Chapter 13 MM1 and PASTA. 13.1 The MM1 Queue,"CHAPTER 13 M/M/1 and PASTA 13.1 The M/M/1 Queue The simplest queueing model consists of a single server in which the service times are i.i.d. Exponential random variables with mean 1/μ, and the customers (jobs) arrive into the system according to a Poisson process with rate λ. Such a system is referred to as an M/M/1 queueing system and is shown in Figure 13.1. Poisson ( λ) μ Figure 13.1. The M/M/1 queueing system. M/M/1 is Kendall notation and describes the queueing system architecture. The ﬁrst slot characterizes the distribution of the interarrival times for the arrival process. The“M” in this ﬁrst slot stands for “memoryless” and says that the interarrival times are Exponentially distributed. The second slot characterizes the distribution of the service times. The “M” in this slot says that the service times of jobs are “memoryless,” namelyExponentially distributed. The third slot indicates the number of servers in the system.For now this is 1, but we will see more complicated examples later. A fourth slot istypically used to indicate an upper bound on the capacity of the system in terms of the total space available to hold jobs. Sometimes, however, the fourth slot is used toindicate the scheduling discipline used for the system. The absence of a fourth ﬁeldindicates that the queue is unbounded and that the scheduling policy is FCFS. Kendallnotation is by no means sufﬁcient to fully describe the characteristics of all queueingsystems. For example, systems where jobs move from one queue to another are not represented by Kendall notation, but it is a reasonable start for describing single-queue systems. The number of customers in an M/M/1 system forms a continuous-time Markov chain (CTMC) where the state of the system corresponds to the number of customers in thesystem. Figure 13.2 shows the transition rate diagram for the M/M/1 system. λ λ λ μμλλ μμμλ μ0 2 j j+1 1 0 Figure 13.2. CTMC for the M/M/1 queueing system. 236 13.1 the m/m/ 1queue 237 The structure of this chain is referred to as a birth-death process , with the λ’s denoting the “births” and the μ’s denoting the “deaths.” In general, in a birth-death process, transitions are only deﬁned between consecutive states, but the rates of the births (ordeaths) do not have to be homogeneous. The limiting probabilities for the states of the M/M/1 CTMC may be obtained by solving the balance equations. Recall that the balance equations equate the rate at which the system leaves state jwith the rate at which the system enters statej. Question: What is the rate of transitions leaving state 1to go to state 2? Answer: π1λ. Observe that λrepresents the rate of transitions (number of transitions per second) that move from any state ito the next higher state, i+1. If we multiply byπ1, we are limiting ourselves to only those upward transitions that occur when the chain is in state 1. Here are the full balance equations: State Balance equation Simpliﬁed equation 0: π0λ=π1μ ⇒π1=λ μπ0 1: π1(λ+μ)=π0λ+π2μ⇒π2=/parenleftbiggλ μ/parenrightbigg2 π0 2: π2(λ+μ)=π1λ+π3μ⇒π3=/parenleftbiggλ μ/parenrightbigg3 π0 i:πi(λ+μ)=πi−1λ+πi+1μ⇒??? We guess that πi=/parenleftbiggλ μ/parenrightbiggi π0. We check that this is correct by substituting back into the balance equation for state i, as follows: /parenleftbiggλ μ/parenrightbiggi π0(λ+μ)=/parenleftbiggλ μ/parenrightbiggi−1 π0λ+/parenleftbiggλ μ/parenrightbiggi+1 π0μ λi+1 μi+λi μi−1√ =λi μi−1+λi+1 μi 238 m/m/ 1and pasta Next we determine π0such that the equation/summationtext∞ i=0πi=1is satisﬁed: ∞/summationdisplay i=0πi=1 ⇒∞/summationdisplay i=0/parenleftbiggλ μ/parenrightbiggi π0=1 ⇒π0/parenleftBigg 1 1−λ μ/parenrightBigg =1 ⇒π0=1−λ μ Therefore, substituting back into the equation for πiwe obtain πi=/parenleftbiggλ μ/parenrightbiggi/parenleftbigg 1−λ μ/parenrightbigg =ρi(1−ρ) π0=1−λ μ=1−ρ where ρ=λ/μ is the server utilization. It should make sense that π0, the probability that the system is idle, equals 1−ρ. Observe that the condition ρ<1must be met if the system is to be stable in the sense that the number of customers in the system does not grow without bound. For this condition to be true, we must have λ<μ . The mean number of customers in the system can be derived by conditioning on the state: E[N]=∞/summationdisplay i=0iπi =∞/summationdisplay i=1iπi =∞/summationdisplay i=1iρi(1−ρ) =ρ(1−ρ)∞/summationdisplay i=1iρi−1 =ρ(1−ρ)d dρ/bracketleftBigg∞/summationdisplay i=0ρi/bracketrightBigg",4442
13.2 Examples Using an MM1 Queue,"13.2 examples using an m/m/ 1queue 239 =ρ(1−ρ)d dρ/bracketleftbigg1 1−ρ/bracketrightbigg =ρ(1−ρ)1 (1−ρ)2 =ρ 1−ρ. Figure 13.3 plots the equation E[N]=ρ/(1−ρ). Observe that for ρ<0.5or even ρ<0.6, the mean number of customers in the system hardly goes up. However after that point, it goes up a lot. Also, the impact of increasing ρfrom0.8to0.9is much greater than the impact of increasing ρfrom0.7to0.8. 246810 0.2 0.4 0.6 0.8 1.00E[N] ρ Figure 13.3. Plot of the expected number of customers in the M/M/1 system vs. ρ. In Exercise 13.12 , we will prove that the variance of the number of customers in the system is given by Var(N)=ρ (1−ρ)2. This grows even more sharply than the mean number of jobs. The mean time in the system and mean time in queue are found using Little’s Law: E[T]=E[N] λ=1 μ−λ E[TQ]=E[T]−1 μ=ρ μ−λ 13.2 Examples Using an M/M/1 Queue Example: Practice with the Formulas Question: Given an M/M/1 server, what is the maximum allowable arrival rate of jobs if the mean job size (service demand) is 3 minutes and the mean waiting time ( E[TQ]) must be kept under 6 minutes? 240 m/m/ 1and pasta Answer: We are given that μ=1/3jobs/minute. We are also given that the expected time in the system must be less than 9 minutes ( E[T]=E[TQ]+E[S]). Therefore, 1 μ−λ≤9 ⇒λ≤μ−1 9=2 9jobs/min . Example: Increasing Arrival and Service Rates Proportionally Given an M/M/1 system (with λ<μ ), suppose that we increase the arrival rate λand the service rate μby a factor of keach. Question: How are the following affected? rutilization, ρ? rthroughput, X? rmean number in the system, E[N]? rmean time in system, E[T]? Answer: We are given that λnew=kλ. μnew=kμ. This yields ρnew=kλ kμ=λ μ=ρold. Xnew=λnew=kλold. E[Nnew]=ρnew 1−ρnew=ρold 1−ρold=E[Nold]. E[Tnew]=1 μnew−λnew=1 k(μ−λ)=1 kE[Told]. Thus the system utilization is unchanged. The throughput is increased by a factor of k. The mean number of jobs in the system is unchanged. The mean response time drops by a factor of k. These results should help explain the following quote from Bertsekas and Gallager [18]: A transmission line ktimes as fast will accommodate ktimes as many packets at k times smaller average delay per packet. This is a very general result that also holds for any distribution on the service timesand even applies to networks of queues. 13.2 examples using an m/m/ 1queue 241 Question: Why? Answer: By speeding up both arrivals and service times by a factor of k,w ea r e basically just speeding up our “clock speed” by a factor of k. That is, we can imagine a system where we make no changes, except for making the time scale a factor of k smaller. Now the number of packets an arriving packet sees ahead of it is the same under both time scales, but response time becomes a factor of ksmaller when time is scaled. This is the reasoning we used in the example on the Federation versus the Klingons from Chapter 1. Example: Statistical Multiplexing vs. Frequency-Division Multiplexing Suppose mindependent Poisson packet streams, each with an arrival rate of λ/m packets per second, are transmitted over a communication line. The transmission time for each packet is Exponentially distributed with mean1 μ. We wish to analyze the performance of two different approaches to multiplexing the use of the communication line. Statistical Multiplexing (SM): This approach merges the mstreams into a single stream. Because the merge of mPoisson streams is still a Poisson stream, the resulting system may be modeled as a simple M/M/1 queueing system as shown in Figure 13.4. λ μ Figure 13.4. The statistical multiplexing model. Frequency-Division Multiplexing (FDM): This approach leaves the mstreams sep- arated and divides the transmission capacity into mequal portions as shown in Figure 13.5. λ/m μ/mλ/m μ/mλ/m μ/m Figure 13.5. The frequency-division multiplexing model. Question: How do the two methods compare with respect to mean response time? Answer: The expected time in the system for SM is simply E/bracketleftbig TSM/bracketrightbig =1 μ−λ.",4026
13.3 PASTA,"242 m/m/ 1and pasta The expected time in the system for FDM is E/bracketleftbig TFDM/bracketrightbig =1 μ/m−λ/m=m μ−λ. Thus the response time is mtimes greater under FDM. Question: Why would one ever use FDM? Answer: Frequency-division multiplexing guarantees a speciﬁc service rate to each stream. Statistical multiplexing is unable to provide any such guarantee. More impor- tantly, suppose the original mstreams were very regular (i.e., the interarrival times were less variable than Exponential, say closer to Deterministic than Exponential). By merging the streams, we introduce lots of variability into the arrival stream. This leadsto problems if an application requires a low variability in delay (e.g., voice or video). Warning: This is one of those results we may overturn later when we discuss higher variability job sizes. 13.3 PASTA In later examples we will often be interested in the state of the system as seen from the perspective of an arrival. To motivate this discussion, consider that you are running a simulation of some system. You want to determine the fraction of time that the system has njobs. To do this, you consider each arrival into the system and ask whether it sees njobs or not. You then track the fraction of arrivals that witnessed njobs when arriving into the system. The question is whether this method gives you the right answer. We’ll assume an ergodic continuous-time system. Let πn=pnbe the limiting proba- bility that there are njobs in the system (or equivalently the long-run fraction of time that there are njobs in the system). Let anbe the limiting probability that an arrival seesnjobs in the system (or equivalently the long-run fraction of arrivals that see n jobs). Let dnbe the limiting probability that a departure leaves behind njobs in the system when it departs (or equivalently the long-run fraction of departures that leave behind njobs). Question: Isan=pn? Answer: No, according to Claim 13.1. Claim 13.1 anis not necessarily equal to pn.1 1Note: Although the average number of jobs in the system is not necessarily the same as the average number seen by an arrival, the average time in system (response time) is by deﬁnition the same as the average response time experienced by an arrival. Similarly, the probability that the response time exceeds xis by deﬁnition the probability that an arrival spends more than xseconds in the system. 13.3 pasta 243 Proof By example. Consider a single queue whose customers have an interarrival time distributed Uniformly between 1 and 2 (i.e., ∼U(1,2)). Assume that all service times are constant with a value of 1. Then, a0=1 andd0=1 because a customer will complete service before the next customer arrives. However, p0/negationslash=1 because the system is not always empty. Question: Isan=dn? Answer: Yes, according to Claim 13.2. Claim 13.2 Assuming that customers arrive one at a time and are served one at a time, then an=dn. Proof An arrival sees ncustomers already in the system whenever the number of customers in the system goes from nton+1. A departure leaves ncustomers in the system whenever the number of customers in the system goes from n+1ton. Because customers arrive one at a time and depart one at a time, these events happen an equal number of times (within 1). Because all states are recurrent, each of these events happens an inﬁnite number of times. Thus the proportion of arrivals that ﬁnd n customers in the system is equal to the proportion of departures that leave ncustomers in the system, given that the overall arrival rate equals the overall departure rate. We are now ready for PASTA – “Poisson Arrivals See Time Averages” (see Figure 13.6). PASTA states that an=pn, and by Claim 13.2,dn=pn, when the arrivals follow a Poisson process. We state this as Claim 13.3. Figure 13.6. PASTA makes us happy. Claim 13.3 If the arrival process to the system is a Poisson process, then an=pn.2 Proof Viewing pnandanas limiting probabilities, we have pn= lim t→∞P{N(t)=n}. an= lim t→∞P{N(t)=n|an arrival occurred just after time t}. 2Sometimes the following requirement is appended: “Assume that interarrival times and service times are independent.” This is necessary only for the perverse scenario described in the question at the very end of this section. 244 m/m/ 1and pasta We show that an=pn. LetA(t, t+δ)be the event that an arrival occurred just after timet. Then, an= lim t→∞lim δ→0P{N(t)=n|A(t, t+δ)} = lim t→∞lim δ→0P{N(t)=n,A(t, t+δ)} P{A(t, t+δ)} = lim t→∞lim δ→0P{A(t, t+δ)|N(t)=n}P{N(t)=n} P{A(t, t+δ)}(∗) = lim t→∞lim δ→0P{A(t, t+δ)}P{N(t)=n} P{A(t, t+δ)}(∗∗) = lim t→∞P{N(t)=n} =pn. The key step where the Poisson process assumption is used is in going between lines (*) and (**). Remark: All you need to make this proof go through is the fact that A(t, t+δ)is independent of N(t). Question: Why would this proof notgo through for the example of the Uniform arrival process with Deterministic job service times? Answer: Consider the case where interarrival times are distributed U(1,2)and job service times are Deterministic, equal to 1. In this case, we cannot move from (*) to (**) in the PASTA proof because knowing N(t)affects whether there will be an arrival in the next δseconds. In particular if N(t)=1 , then there will notbe an arrival in the nextδseconds. By contrast, for the Poisson arrival process, an arrival occurs during (t, t+δ)with probability λδ+o(δ)independent of N(t). The fact that an arrival occurs tells us nothing about N(t)and vice versa. Question: Why might we need to make the further assumption (stated in the footnote to Claim 13.3) that the interarrival times and service times are independent? Isn’t Poisson arrivals already saying this? Answer: Imagine the perverse situation where you have Poisson arrivals, but the service times are correlated to the interarrival times of the arrivals. Speciﬁcally, suppose that the service time of the nth arrival is always set to equal half the interarrival time between packets nandn+1. In this case, an arrival would ﬁnd the system empty; however, the time-average number of packets in the system would be1 2. Note that this situation is purely hypothetical because it is not possible to know the interarrival times between packets until the next arrival occurs. Application to Simulation PASTA is useful in system simulations. If we are simulating a Poisson arrival process to some system and would like to know the mean number of jobs in the system, or the",6469
13.4 Further Reading. 13.5 Exercises,"13.5 exercises 245 fraction of time the system has njobs, or something of that type, then it sufﬁces to average over what arrivals see at the moment they enter the system. By contrast, if the arrival process is not Poisson, it is very dangerous to average over what arrivals see, because that may not be the true time average for the system. 13.4 Further Reading PASTA can be stated much more generally, applying to more than just the numberof jobs in the system. For further reading on PASTA, we recommend Wolff [ 195], pp. 293–96. 13.5 Exercises 13.1 Bathroom queue It is well known that women spend twice as long in the restroom on averageas men. 3That said, the waiting time, TQ, in the women’s line seems much longer than twice that in the men’s line. Is this an illusion or reality? Model the women’s line as an M/M/1 queue with arrival rate λand service rate μ. Model the men’s line as an M/M/1 queue with arrival rate λand service rate 2μ. Derive the ratio E[TQ]women E[TQ]men as a function of the load ρ=λ μin the women’s queue. What is the lowest value of this ratio? What is the highest? 13.2 Server Farm In the server farm shown in Figure 13.7, jobs arrive according to a Poisson process with rate λand are probabilistically split between two servers, with p fraction of the jobs going to server 1, which has service rate μ1, andq=1−p fraction going to server 2, which has service rate μ2. Assume that job sizes are Exponentially distributed. Derive an expression for the mean response time, E[T], experienced by arrivals to the server farm. p 1–pFCFS FCFSμ1 μ2Poisson ( λ) Figure 13.7. Server farm from Exercise 13.2. 3Women spend 89±7seconds, compared to men’s 39±6seconds [ 62]. 246 m/m/ 1and pasta 13.3 M/M/1 Simulation This problem is a slight twist on Exercise 4.3. Your job is to simulate an M/M/1 queue. You can write your simulator in any programming language. See Chapter 4for techniques for generating the needed random variables. The mean job size is 10. The mean arrival rate is λ. Adjust λas needed to create the following three loads – ρ=0.5,ρ=0.7, andρ=0.9– and run your simulator under each load to measure mean response time. Compare your results with the steady-state mean response time derived in this chapter. 13.4 M/M/1 Number in Queue For an M/M/1 queue with load ρ, prove that E[NQ]=ρ2 1−ρ. (13.1) 13.5 M/M/1/FCFS with Finite Capacity Your system consists of a single CPU with ﬁnite buffer capacity. Jobs arrive according to a Poisson process with rate λjobs/sec. The job sizes are Expo- nentially distributed with mean 1/μseconds. Jobs are serviced in FCFS order. LetN−1denote the maximum number of jobs that your system can hold in the queue. Thus, including the job serving, there are a maximum of Njobs in the system at any one time (this is called an M/M/1/N queue). If a job arrives when there are already Njobs in the system, then the arriving job is rejected. Your DARPA proposal requires that you reduce the loss probability in your system. To do this you could either ask for money to double the buffer size, or, alternatively, you could ask for money to double the speed of the CPU sothat jobs get processed faster, thereby lowering the probability that there are Njobs in the system.",3231
13.4 Further Reading. 13.5 Exercises,"Assuming both proposals have the same cost, which do you choose? (Asking for both makes you seem greedy.) These are the speciﬁc questions you should answer: (a) Draw the CTMC. (b) Derive the limiting probabilities. (c) What is the utilization of the system? (d) What is the fraction of jobs turned away (loss probability)? Use the word PASTA in your explanation. (e) What is the rate at which jobs are turned away? (f) Derive a closed-form expression for E[Number in system ]. (g) Determine a closed-form expression for E[T]for only those jobs that enter the system. (h) Suppose that N=5, andρ=λ μ=.4. Which would have the greater effect on lowering loss probability: doubling the buffer size or doubling the CPU speed? (i) Answer the same question as (h) except now N=5, andρ=λ μ=.8. (j) Explain intuitively why (h) and (i) resulted in different answers. 13.6 Admission Control Consider the M/M/1 with ﬁnite capacity from Exercise 13.5. Now consider those jobs that are turned away (because there are already Njobs in the 13.5 exercises 247 system). Is the stream of arrivals that are turned away a Poisson process? Why or why not? 13.7 Open versus Closed Networks Consider the closed batch network shown in Figure 13.8(a) and the single- server open network shown in Figure 13.8(b). In (a), Nis often called the “multiprogramming level” or “load.” In (b), the load is ρ=λ μ. Under what criterion does (a) have higher E[T]than (b)? Express your crite- rion in terms of Nandρonly. Also try to explain your ﬁnding. (a) Close d N FCFS μ (b) OpenPoisson ( λ) μ Figure 13.8. Open and closed systems. 13.8 More Open versus Closed Systems Figure 13.9 shows a closed queueing network and an open one. Job sizes are Exponentially distributed, where the service rate is shown for each server, and pdenotes a probability. (a) Close d systemN = 1,000 p 1–pμ = 4  μ = 1  (b) Open systemPoisson ( λ = 1)p 1–pμ = 4 μ = 1  Figure 13.9. Figure for Exercise 13.8. (i) For the closed system, what value of pminimizes mean response time, E[T]? (ii) Derive an expression for E[T]for the open system. (iii) Does the value of pthat you found in (i) minimize E[T]in the open system? If yes, give a proof. If no, give a counterexample. (iv) Under the optimal pfor the closed system, what is the (approximate) throughput Xfor the closed system? (v) Under the optimal pfor the open system, what is Xfor the open system? 13.9 M/M/1/2 Consider an M/M/1/2 (see Exercise 13.5) with arrival rate λ, service rate μ, and ﬁnite capacity of 2.D e r i v e E[T1,0], the mean time to go from having one job in the system until the system is empty. 248 m/m/ 1and pasta 13.10 Busy Period in M/M/14 A busy period, B, is the time from when the system has 1 job until the system is ﬁrst empty. (Obviously, the number of jobs may go up and down a lot in going from state 1 to state 0.) Your goal is to derive E[B]for an M/M/1. (a) Draw the CTMC for the M/M/1 with arrival rate λand service rate μ. (b) Write a recurrence relation for E[B]by conditioning on the next state that the CTMC moves to after leaving state 1. (c) Solve the recurrence relation for E[B]. What does the expression for E[B] remind you of?",3166
13.4 Further Reading. 13.5 Exercises,"13.11 Response time distribution for M/M/14 In this problem, you are asked to derive the distribution of response time for an M/M/1 queue with arrival rate λand service rate μ. To do this, think about the response time experienced by an arrival, “job x.” Think about the number of jobs that job xsees in the system, and the work associated with each of these jobs. Then express job x’s response time in terms of these quantities. (a) At the time when job xarrives, what is the service requirement (job size) for each job in the queue? What is the remaining service requirement for the job in service, if there is one? (b) Let Ndenote the total number of jobs in the system that job xsees when it arrives. What is P{N=n}? Use PASTA. (c) Consider a new distribution N/primewhere N/primeis the number of jobs in the system seen by job x, plus itself. What is P{N/prime=n}? (d) The distribution N/primehas a name. What is the name of the distribution of N/primeand what is the appropriate parameter? (e) IfSidenotes the service requirement of the ith job in the M/M/1, we can express the response time of job xas a sum involving some of the random variables above. Write this sum. (f) Fully specify the distribution of response time of job xalong with its parameter(s). [Hint: you will need to utilize a result from the exercises inChapter 11.] 13.12 Variance of the Number of Jobs in an M/M/1 Let Ndenote the number of jobs in an M/M/1 with load ρ. Prove that Var(N)=ρ (1−ρ)2. [Hint: It may help to make use of Exercise 3.22.] 13.13 Back to the Server Farm Consider again the server farm from Exercise 13.2. Use what you learned in Exercise 13.11 to derive expressions for (a) the tail behavior of response time, P{T>t} (b) variance of response time, Var(T). 4Warning: This result will be used many times throughout the book. 13.5 exercises 249 13.14 Threshold Queue We deﬁne a threshold queue with parameter Tas follows: When the number of jobs is <T, then jobs arrive according to a Poisson process with rate λand their service time is Exponentially distributed with rate μ, where λ>μ (i.e., the queue is running in overload). However, when the number of jobs is >T, then jobs arrive with Exponential rate μand are served with Exponential rate λ. Figure 13.10 shows the CTMC for the case of T=2. Compute E[N], the mean number of jobs in the system, as a function of T. As a check, evaluate your answer when T=0. Note that when T=0,w eh a v e ρ=μ/λ. λ λλqλ λ 0 3 1 2 4 0 Figure 13.10. Threshold queue with T=2.",2508
Part V Server Farms and Networks Multi-server Multi-queue Systems,"PART V Server Farms and Networks: Multi-server, Multi-queue Systems PartVinvolves the analysis of multi-server and multi-queue systems. We start in Chapter 14with the M/M/k server farm model, where kservers all work “cooperatively” to handle incoming requests from a single queue. We derive simple closed-form formulas for the distribution of the number of jobs in the M/M/k. We then exploit these formulas in Chapter 15to do capacity provisioning for the M/M/k. Speciﬁcally, we answer questions such as, “What is the minimum number of servers needed to guarantee that only a small fraction of jobs are delayed?” We derive simpleanswers to these questions in the form of square-root stafﬁng rules. In these twochapters and the exercises therein, we also consider questions pertaining to resource allocation, such as whether a single fast server is superior to many slow servers, andwhether a single central queue is superior to having a queue at each server. We then move on to analyzing networks of queues, consisting of multiple servers, each with its own queue, with probabilistic routing of packets (or jobs) between the queues. In Chapter 16we build up the fundamental theory needed to analyze networks of queues. This includes time-reversibility and Burke’s theorem. In Chapter 17, we apply our theory to Jackson networks of queues. We prove that these have product form, and we derive the limiting distribution of the number of packets at each queue. Ourproofs introduce the concept of Local Balance, which we use repeatedly in derivationsthroughout the book. In Chapter 18, we generalize our analysis to allow for classed networks, where the route of a packet can depend on its class (type). Chapter 19extends the analysis to closed networks of queues. In the exercises in Chapters 17,18, and 19,w e derive further extensions, including networks of servers with load-dependent servicerate, where the speed of the server can depend on the number of jobs in the queue, andnetworks of M/M/k queues, where each service station is a server farm. Throughout Part V, to facilitate analysis, we assume Markovian distributions, including Exponentially distributed service times and Poisson arrival processes. Later in Part VI, we explore more general analysis that does not require Markovian assumptions. 251",2307
Chapter 14 Server Farms MMk and MMkk. 14.1 Time-Reversibility for CTMCs,"CHAPTER 14 Server Farms: M/M/k and M/M/k/k In today’s high-volume world, almost no websites, compute centers, or call centers consist of just a single server. Instead a “server farm” is used. The server farm is acollection of servers that work together to handle incoming requests. Each requestmight be routed to a different server, so that servers “share” the incoming load. Froma practical perspective, server farms are often preferable to a single “super-fast” server because of their low cost (many slow servers are cheaper than a single fast one) andtheir ﬂexibility (it is easy to increase/decrease capacity as needed by adding/removingservers). These practical features have made server farms ubiquitous. In this chapter, we study server farms where there is a single queue of requests and where each server, when free, takes the next request off the queue to work on. Speciﬁcally, there are no queues at the individual servers. We defer discussion of models with queues at the individual servers to the exercises and later chapters. The two systems we consider in this chapter are the M/M/k system and the M/M/k/k system. In both, the ﬁrst “M” indicates that we have memoryless interarrival times,and the second “M” indicates memoryless service times. The third ﬁeld denotes that kservers share a common pool of arriving jobs. For the M/M/k system, there is no capacity constraint, and this common pool takes the form of an unbounded FCFS queue, as shown later in Figure 14.3, where each server, when free, grabs the job at the head of the queue to work on. For the M/M/k/k system shown in Figure 14.1, there is a capacity constraint of kjobs. This means that there is no room for a queue. If a job arrives to ﬁnd all kservers busy, then the job is dropped. Because the analysis of the M/M/k/k is easier, we begin with that, in Section 14.2, and then go on to the M/M/k, in Section 14.3. Before we discuss these systems, it will be helpful to revisit the concept of time-reversibility, this time for CTMCs rather than DTMCs. We do this in Section 14.1. 14.1 Time-Reversibility for CTMCs We start by reviewing terminology used in CTMCs. Question: Can you properly deﬁne the following terms: qij,πiqij,νi,νiPij? Answer: Recall that qijis the rate of transitions from state ito state j, given that the CTMC is in state i. That is, qijis the label on the arrow from itojin the Markov transition diagram for the CTMC. If πiis the limiting probability that the CTMC is in 253 254 server farms: m/m/ kand m/m/ k/k statei, thenπiqijis the rate of transitions from state ito state j. Likewise πjqjiis the rate of transitions from state jto state i. Recall also that νiis the total rate of transitions leaving i, given that we are in state i, andνiPijdenotes the rate of transitions leaving state iand going to state j,g i v e n that we are in state i, i.e.,νiPij=qij. Thus πiνidenotes the rate of transitions leaving statei, andπiνiPijdenotes the rate of transitions leaving iand going to j. Recall the useful time-reversibility theorem for DTMCs, Theorem 9.34, which said that, for an aperiodic and irreducible DTMC, if we can ﬁnd xi’s such that /summationdisplay ixi=1 and xiPij=xjPji,∀i, j then these xi’s are the limiting probabilities. We now prove a counterpart to this theorem for CTMCs. Deﬁnition 14.1 AC T M Ci s time-reversible if, for all states iandj, the rate of transitions from state ito state jequals the rate of transitions from state jto state i (i.e.,πiqij=πjqji, where/summationtext iπi=1). Lemma 14.2 Given an irreducible CTMC, suppose we can ﬁnd xi’s such that /summationdisplay ixi=1 and xiqij=xjqji,∀i, j where qijis the rate of transitions from state ito state jgiven that the MC is in state i. Then, 1.Thexi’s are the limiting probabilities of the CTMC. 2.The CTMC is time-reversible. Proof What we need to prove here is that the xi’s are the πi’s (the limiting probabil- ities). We are given that, ∀i, j, xiqij=xjqji. Thus, /summationdisplay ixiqij=xj/summationdisplay iqji /summationdisplay ixiqij=xj/summationdisplay iνjPji /summationdisplay ixiqij=xjνj/summationdisplay iPji /summationdisplay ixiqij=xjνj.",4134
14.2 MMkk Loss System,"14.2 m/m/ k/kloss system 255 Since these are the balance equations for the CTMC, by Theorem 12.6 it then follows that the xi’s must be the πi’s. Thus it further follows that πiqij=πjqji,∀i,j hence the CTMC is time-reversible. Question: What is an example of a CTMC that is nottime-reversible? Answer: Consider a chain that has an arc from state ito state jlabeled qij, but no arc from state jto state i. Then the rate of going from state ito state jisπiqij, but the rate of going from state jto state iis zero. Question: Recall that the M/M/1 chain is a birth-death process. Are all birth-death processes time-reversible? Answer: Yes. Here’s a proof: First observe that during any period of time, t, the number of transitions from state ito state i+1is within 1 of the number of transitions from statei+1to state i. The reason for this is that you cannot repeat going from itoi+1 without ﬁrst going back to iagain – and the only way to go back to state iis to make a transition from i+1toi. Thus the long-run rate of transitions (number of transitions divided by time) from state ito state i+1is equal to the rate of transitions from i+1 toi(as time gets big, that “difference of 1” can be ignored). As in the case of DTMCs, it is often helpful to write the time-reversibility equations and see if a solution to these can be found. If so, that solution also represents the limitingdistribution. If not, then one needs to go back to the balance equations. Fortunately, wewill see that the CTMCs for the M/M/k/k and the M/M/k are both birth-death processes,and hence the time-reversibility equations will be solvable. 14.2 M/M/k/k Loss System The M/M/k/k queueing system is also called the k-server loss system. Jobs arrive according to a Poisson process, with some average arrival rate, λ. Job sizes are Expo- nentially distributed with rate μ. There are kservers that can each hold one job. The system only has capacity for kjobs total; if an arrival shows up and sees all kservers already busy with a job, the arrival is dropped. The M/M/k/k loss system originally arose from the early phone switching systems that could handle at most kcalls simultaneously, as shown in Figure 14.1. An incoming call request could be picked up and serviced by any one of the kcircuits. However, if none of the kcircuits was free, the phone call request was dropped. The duration of a phone call was assumed to be Exponentially distributed. Another application for the k-server loss system is a system that maintains virtual connections between nodes A and B in a network. Only kvirtual connections are allowed. Each incoming request for a virtual connection is given one; however, if all k virtual connections are in use, the request is rejected. 256 server farms: m/m/ kand m/m/ k/k Phone calls  come inPhone call may be serviced  by any one of the k circ uits. However, if none is free,  the phone call is lost. Duration of phone call ~ Exp( μ)μ μ μServer 1 Server 2 Server k Figure 14.1. The k-server loss system: M/M/k/k. Thekey question in these types of systems is, “What is the fraction of jobs that are lost?” This fraction is known as the blocking probability ,Pblock. We determine the blocking probability by modeling the M/M/k/k queueing system as a CTMC. Question: What should the state space be? Answer: The state represents the number of busy servers in the system. The CTMC is shown in Figure 14.2. kλ 2λλ 3λ 2 0 1 Figure 14.2. An M/M/k/k queueing system modeled using a CTMC. The state represents the number of busy servers. We solve the time-reversibility equations to determine the limiting probabilities for the states as shown in Table 14.1. Table 14.1. Time-reversibility equations for the M/M/k/k State Time-reversibility equation Simpliﬁed equation 0 π0λ=π1μπ 1=λ μπ0 1 π1λ=π22μπ 2=/parenleftBig λ μ/parenrightBig21 2.π0 2 π2λ=π33μπ 3=/parenleftBig λ μ/parenrightBig31 3.π0 k−1πk−1λ=πkkμ π k=/parenleftBig λ μ/parenrightBigk1 k.π0 We guess that πi=/parenleftbiggλ μ/parenrightbiggi1 i.π0. (14.1) 14.2 m/m/ k/kloss system 257 We can verify that this is correct by substituting back into the time-reversibility equation forπi. Finally, we determine π0such that the equation/summationtextk i=0πi=1is satisﬁed: k/summationdisplay i=0πi=1 k/summationdisplay i=0/parenleftbiggλ μ/parenrightbiggi1 i.π0=1 ⇒π0=1 /summationtextki=0/parenleftBig λ μ/parenrightBigi 1 i. Therefore, substituting back into equation ( 14.1), we obtain πi=/parenleftBig λ μ/parenrightBigi /i. /summationtextkj=0/parenleftBig λ μ/parenrightBigj 1 j.. The blocking probability, Pblock, is the probability that an arrival ﬁnds all kservers busy. By PASTA, this is the limiting probability that the chain is in state k. Thus, Pblock=πk=/parenleftBig λ μ/parenrightBigk /k. /summationtextk j=0/parenleftBig λ μ/parenrightBigj 1 j.. (14.2) Equation ( 14.2) is called the Erlang-B formula. Question: There is an easy way to remember the formula for Pblockby relating it to the Poisson distribution. Can you see what it is? Hint: Multiply both the numerator and denominator by e−λ μ. Lemma 14.3 LetX∼Poisson/parenleftBig λ μ/parenrightBig .Then Pblock=e−λ μ·(λ μ)k/k. /summationtextk j=0e−λ μ·/parenleftBig λ μ/parenrightBigj 1 j.=P{X=k} P{X≤k}(14.3) The applicability of the Erlang-B formula stems from the fact that it is independent of the service time distribution. That is, this same formula arises when the service demand has a mean of1 μwith any probability distribution. This is known as an insensitivity result , because the result depends only on the mean of the distribution. Insensitivity results are always quite striking when they occur, because it is much more typical that queueing behavior is highly inﬂuenced by the distribution of the service time. Insensitivity results often occur in situations where there is no queue . We will see several other insensitivity results during the course of this book.",5890
14.3 MMk,"258 server farms: m/m/ kand m/m/ k/k 14.3 M/M/k Figure 14.3 illustrates the M/M/k queueing system. As in the ﬁxed-capacity system, thekservers draw from the same pool of incoming jobs, except that this time the pool has inﬁnite space. Whenever a server becomes free, it takes the next job from the pool. The “pool” is just an FCFS queue with unbounded capacity. Server 1 Server 2 Server k Figure 14.3. An M/M/k queueing system. We can model the number of jobs in the M/M/k queueing system as a CTMC as shown in Figure 14.4. kλ 2λλ 3λ 2 0 1λ λ λ k+2 k+1 Figure 14.4. An M/M/k queueing system modeled using a CTMC. We write the time-reversibility equations as shown in Table 14.2. Table 14.2. Time-reversibility equations for the M/M/k State Time-reversibility equation Simpliﬁed equation 0 π0λ=π1μπ 1=λ μπ0 1 π1λ=π22μπ 2=/parenleftBig λ μ/parenrightBig21 2.π0 2 π2λ=π33μπ 3=/parenleftBig λ μ/parenrightBig31 3.π0 k−1πk−1λ=πkkμ π k=/parenleftBig λ μ/parenrightBigk1 k.π0 kπ kλ=πk+1kμ π k+1=/parenleftBig λ μ/parenrightBigk+11 k.1 kπ0 k+1 πk+1λ=πk+2kμ π k+2=/parenleftBig λ μ/parenrightBigk+21 k.1 k2π0 14.3 m/m/ k 259 Therefore, πi=⎧ ⎪⎪⎨ ⎪⎪⎩/parenleftBig λ μ/parenrightBigi 1 i.π0 ifi≤k /parenleftBig λ μ/parenrightBigi 1 k./parenleftbig1 k/parenrightbigi−kπ0ifi>k. Let’s express these equations in terms of the system utilization. Question: But what is the system utilization? Answer: For an M/M/k, the system utilization is deﬁned as ρ=λ kμ where λis the arrival rate into the system in jobs/sec, and kμrepresents the total service capacity of the system in jobs/sec. Note: In a typical system, the term “system utilization” is not well deﬁned because different devices may be running at different utilizations. The term “utilization” is thustypically reserved for a single device. An M/M/k queue is an exception in that systemutilization is well deﬁned because, by symmetry, the utilization (load) is the same atall servers. Speciﬁcally, consider the fraction of time that a particular server is busy.That server, by symmetry, sees an arrival rate of λ kand experiences a service rate of μ. Hence the utilization at that server isλ kμ. But this is also the utilization at every server. LetRdenote the expected number of busy processors. Question: What is R? Answer: R=λ/μ. To see this, consider that each server is busy with probabilityλ kμ and there are kservers. Thus the expected number of jobs in service is R=E[number in service ]=k·λ kμ=λ μ. (14.4) Observe that Rcan also be viewed as the minimal resource requirement (i.e., the minimum number of servers required to handle the arrival rate). For example, if theaverage arrival rate is λ=3 0 jobs/sec, and the service rate of each server is μ=5 jobs/sec, then we have a minimal resource requirement of R=λ/μ=3 0/5=6 servers needed just to maintain stability. These deﬁnitions are used throughout the book, so we state them again for reference: Deﬁnition 14.4 For an M/M/k with average arrival rate λand service rate μ, the system utilization orload is denoted by ρ, where ρ=λ kμ. 260 server farms: m/m/ kand m/m/ k/k The resource requirement is denoted by R, where R=λ μ. Rcan also be viewed as the minimum number of servers needed to keep the system stable, or as the expected number of servers that are busy, or as the expected number of jobs in service. Using ρ, we rewrite the equations for πias follows: πi=/braceleftBigg(kρ)i i.π0ifi≤k ρi k.kkπ0ifi>k Finally, we need to determine π0: π0+k−1/summationdisplay i=1πi+∞/summationdisplay i=kπi=1 π0/bracketleftBigg 1+k−1/summationdisplay i=1(kρ)i i.+∞/summationdisplay i=kρi k.kk/bracketrightBigg =1 π0/bracketleftBiggk−1/summationdisplay i=0(kρ)i i.+kk k.ρk 1−ρ/bracketrightBigg =1 ⇒π0=/bracketleftBiggk−1/summationdisplay i=0(kρ)i i.+(kρ)k k.(1−ρ)/bracketrightBigg−1 Probability That an Arriving Job Has to Queue Having found the stationary probabilities, we now ﬁnd the probability that an arriving job has to queue, PQ. Observe that PQis the probability that an arrival ﬁnds all k servers busy. PQ=P{An arrival ﬁnds all servers busy } =P{An arrival sees ≥kjobs in system } =Limiting probability that there are ≥kjobs in system (by PASTA) =∞/summationdisplay i=kπi =kk k.π0∞/summationdisplay i=kρi =(kρ)kπ0 k.(1−ρ)where π0=/bracketleftBiggk−1/summationdisplay i=0(kρ)i i.+(kρ)k k.(1−ρ)/bracketrightBigg−1 (14.5) Equation ( 14.5) is the famous Erlang-C formula. 14.3 m/m/ k 261 It is interesting to compare the probability that an arrival ﬁnds all servers busy in an M/M/k, PQ, with the probability that an arrival ﬁnds all servers busy in an M/M/k/k, Pblock. Question: Intuitively, which system will have a higher probability that all kservers are busy? Answer: The M/M/k system will. Question: Why? Answer: In the M/M/k system, jobs can arrive during the time that the kservers are busy. These jobs do not disappear but rather queue up, thus creating more work for later and thus affecting the future probability that the system is busy. Theorem 14.5 relates the blocking probability for the M/M/k/k to the queueing proba- bility for the M/M/k. Theorem 14.5 LetPblockdenote the blocking probability for the M/M/k/k and PQ the queueing probability for the M/M/k. Let ρdenote the load (system utilization) for the M/M/k. Then Pblock=(1−ρ)PQ 1−ρPQ. (14.6) Proof Observing that the M/M/k/k chain is contained within the M/M/k chain, we have PM/M/k/k block =P{N=k|N≤k}M/M/k =P{N=k}M/M/k P{N≤k}M/M/k =P{N≥k}M/M/k−P{N>k}M/M/k 1−P{N>k}M/M/k =PQ−ρPQ 1−ρPQ where the last line follows from the fact that, beyond state k, the M/M/k looks like an M/M/1 with load ρ, hence P{N>k}M/M/k=ρ·P{N≥k}M/M/k. Expected Number in the Queue We can now calculate the expected number in the queue portion of the M/M/k: E[NQ]M/M/k=∞/summationdisplay i=kπi(i−k) =π0∞/summationdisplay i=kρikk k.·(i−k) 262 server farms: m/m/ kand m/m/ k/k =π0ρkkk k.∞/summationdisplay i=kρi−k·(i−k) =π0ρkkk k.∞/summationdisplay i=0ρi·i =π0ρkkk k.·ρ·1 (1−ρ)2 =PQρ 1−ρ Question: Explain why E[NQ]=PQρ 1−ρ. Answer: E[NQ]=E[NQ|queueing ]·P{queueing} +E[NQ|no queueing ]·P{no queueing }. But E[NQ|no queueing ]=0. So E[NQ]=E[NQ|queueing ]·PQ. Now consider the CTMC for the M/M/k, given that there is queueing. That CTMC looks identical to the CTMC for an M/M/1, where the M/M/1 has arrival rate λand service ratekμ. Speciﬁcally, E[NQ|queueing ]for the M/M/k is just the expected number of jobs in system for an M/M/1 queue, where the M/M/1 queue has load ρ=λ kμand mean number of jobsρ 1−ρ.S o , E[NQ]=ρ 1−ρ·PQ. (14.7) Finishing up, we can derive the remaining performance metrics for the M/M/k easily as follows: E[TQ]=1 λ·E[NQ]=1 λ·PQ·ρ 1−ρ(14.8) E[T]=E[TQ]+1 μ=1 λ·PQ·ρ 1−ρ+1 μ(14.9) E[N]=λ·E[T]=PQ·ρ 1−ρ+kρ (14.10) As a check, observe that E[Number being served ]=E[N]−E[NQ]=kρ=λ μ=R. This is the expected result from ( 14.4).",6791
14.5 Readings,"14.4 comparison of three server organizations 263 14.4 Comparison of Three Server Organizations Consider the following three different server organizations, all having arrival rate λ, total service rate kμ, and load ρ=λ kμ, shown in Figure 14.5. Under frequency-division multiplexing (FDM), trafﬁc is split into kseparate channels. Under the M/M/k, the trafﬁc is lumped together, but the service capacity is split. Under the M/M/1, nothing is split. We want to determine which of these conﬁgurations is best for minimizing mean response time. M/M /1 M/M/k λ kμFrequency-division multiplexing λ/k μλ/k μλ/k μ μλ μμ Figure 14.5. Frequency-division multiplexing, M/M/1, and M/M/k, all with load ρ=λ kμ. Question: Which is better in terms of mean response time: FDM or the M/M/1? Answer: Obviously the M/M/1. Each job experiences a ktimes higher arrival rate under the M/M/1, but also a ktimes higher service rate. Thus we expect the mean response time to be ktimes lower for the M/M/1. Computing these response times, we have: E[T]FDM=1 μ−λ k=k kμ−λ. (14.11) E[T]M/M/1=1 kμ−λ. (14.12) By comparing equations ( 14.11 ) and ( 14.12 ), it is obvious that M/M/1 is ktimes better than FDM. Question: How does the M/M/1 system compare with the M/M/k system? Answer: Recall that for the M/M/k, from (14.9) E[T]M/M/k=1 λ·PQ·ρ 1−ρ+1 μ where ρ=λ kμ, andPQis the probability an arrival is forced to queue.",1391
14.6 Exercises,"264 server farms: m/m/ kand m/m/ k/k To compare the M/M/k with the M/M/1, consider E[T]M/M/k E[T]M/M/1=1 λ·PQ·ρ 1−ρ+1 μ 1 λ·ρ 1−ρ =PM/M/k Q+λ μ·1−ρ ρ =PM/M/k Q+k(1−ρ). (14.13) Now consider two cases. Case 1: ρ≈0 As the load drops, the probability of queueing drops, so PM/M/k Q≈0, and expression (14.13 ) is approximately 0+k=k. Thus, the M/M/1 is ktimes faster than M/M/k. Question: Explain intuitively why this makes sense. Answer: In the M/M/k, under light load, most servers are idle. The few servers that are busy serve the jobs they get at rate μ. By contrast, in the M/M/1, with the same light load, every job gets served with rate kμ. Thus jobs complete more quickly in the M/M/1. Case 2: ρ≈1 With the load high, PM/M/k Q≈1, and so expression ( 14.13 ) is approximately 1. Thus, the M/M/k and M/M/1 have the same response time.Question: Explain why this makes sense. Answer: Because the load is high, there are always jobs in the queue. Thus, the state of the CTMC for the M/M/k is always greater than k. This portion of the CTMC looks like Figure 14.6. Thus the M/M/k under high load behaves just like an M/M/1 with arrival rate λand service rate kμ. λ kμλ kμk Figure 14.6. M/M/k queue under high load. 14.5 Readings We stated that the k-server loss system exhibits an interesting insensitivity property, whereby the distribution of the number of jobs in the loss system depends only on the mean job size, not on its distribution. For a unique and interesting proof of the insensitiv- ity property for this system and several others, we refer the reader to [ 178], pp. 202–09. 14.6 Exercises 14.1 Comparison of Three Server Organizations Repeat the comparison of three server organizations from Section 14.4. This time, however, assume k=2and derive exact closed-form formulas for E[T] for each of the three architectures shown in Figure 14.5. 14.6 exercises 265 14.2 Scherr’s Thesis 1965 Once upon a time, back in 1965, an MIT student named Allan Scherr needed to analyze the Compatible Time-Sharing System (CTSS). CTSS was an early time-sharing system in which user programs were swapped in and out of main memory with only one complete program in memory at a time. Because therewas no overlap of program execution and swapping, Scherr modeled the sumof the program execution time and swapping time as the CPU service time, S. He modeled the CTSS as a simple interactive system with Nterminals and one CPU as shown in Figure 14.7. For Scherr’s system, Nwas60, the mean CPU service time was E[S]=0.8seconds, and the mean user think time wasE[Z]=3 5 seconds. To determine the mean response time of the system, E[R], Scherr made the false assumption that ZandSwere Exponentially distributed random variables. This assumption allowed him to set up a CTMC and solve for the mean response time of the system. Everyone was surprised when the mean response time that Scherr got via his analysis was in fact very close to the measured mean response time of the system, given all hissimpliﬁcations, so Scherr got a PhD and won a bunch of awards.",3046
14.6 Exercises,"His thesis isonline. Don’t you wish it was still 1965? N = 60 E{Z} = 35 seconds E{S} = .8 secondsCPU Figure 14.7. Scherr’s CTSS model. (a) Solve Scherr’s problem as he did, by making the Exponential assumptions and setting up a CTMC. Determine the limiting probabilities (can you apply the time-reversibility equations?). Write out an expression for E[R].N o w plug in Scherr’s numbers and determine E[R](you will need to write a small program to do the sum). (b) Now use operational analysis (see Chapters 6and7), which is distribution- independent , to obtain asymptotic bounds for E[R]in Scherr’s problem (remember to determine N∗). If you have done it all right, you may be wondering at this point why Scherrhimself did not use operational analysis. Turns out operational analysis did not exist until the early 1970s. 14.3 M/M/2/3 Figure 14.8 shows a 2-server system with a waiting room that can hold only 1 job. Any arrival that sees 3jobs already in the system is dropped. Jobs arrive from outside according to a Poisson process with rate λ=1. Whenever a server ﬁnishes serving a job, it grabs the job from the waiting area, if there is one. Job sizes are Exponentially distributed with rate μ=1. 266 server farms: m/m/ kand m/m/ k/k Poisson ( λ)μ μ Figure 14.8. The M/M/2/3 system. (a) Draw a CTMC where the state represents the total number of jobs in the system. (b) Suppose that there are exactly 2 jobs in the system. What is the probability that a job arrives before a job completes? (c) Use your CTMC to determine the probability that the system is idle (both servers are idle). (d) What is the throughput of the system? (e) What is E[N], the expected number of jobs in the system? (f) What is E[T], the expected response time (for those jobs not dropped)? (g) Consider the process of arrivals to the system that are not dropped. Is this a Poisson process? Why or why not? 14.4 The Inﬁnite Help Desk (M/M/ ∞) Imagine that you could call up a company for customer service and neverget the message, “We’re sorry; all of our service representatives are busywith other customers ...” This can be modeled by a queueing system with an inﬁnite number of servers. Concretely, consider the M/M/ ∞queueing system, where interarrival times are Exponential with rate λand the service times are Exponential with rate μ, but where there are an inﬁnite number of servers ( k=∞). (a) Draw a state diagram for the continuous-time Markov chain of this system. (b) Derive the limiting probabilities. You need to get a closed-form expression here that is simple and easy to recognize. (c) From the limiting probabilities, derive a closed-form expression for the expected number of jobs in the system, E[N]. (d) Applying Little’s Law gives you E[T]. DoesE[T]make sense? Explain. 14.5 M/M/2 with Heterogeneous Servers Consider a variant of the M/M/2 queue where the service rates of the twoprocessors are not identical. Denote the service rate of the ﬁrst processor by μ1 and the service rate of the second processor by μ2, where μ1>μ 2. In the case of heterogeneous servers, the rule is that when both servers are idle, the fasterserver is scheduled for service before the slower one.",3176
14.6 Exercises,"Deﬁne the utilization, ρ, for this system to be ρ=λ μ1+μ2. Set up a CTMC and determine the mean number of jobs in the system and the mean response time. You should get E[N]=1 A(1−ρ)2(14.14) 14.6 exercises 267 where A=μ1μ2(1 + 2 ρ) λ(λ+μ2)+1 1−ρ. (14.15) 14.6 Is Load Balancing Good? +More on Closed vs. Open Systems Consider the server farm shown in Figure 14.9. The arrival stream is a Poisson process with rate λ, and job sizes are Exponentially distributed. Each job with probability pis sent to Host 1, which has service rate μ1, and with probability 1−pis sent to Host 2, which has service rate μ2. There is a queue at each host. (a) Assume μ1=μ2. Either prove or disprove that E[TQ]andE[T]are always minimized when pis chosen to balance the load. (b) Now assume μ1/negationslash=μ2. Either prove or disprove that E[TQ]andE[T]are always minimized when pis chosen to balance the load. (c) Continue to assume μ1/negationslash=μ2, but now suppose that we have a closed sys- tem with zero think time and large MPL, N, where Figure 14.9 represents the central subsystem in the closed system. Either prove or disprove that E[TQ]andE[T]are always minimized when pis chosen to balance the load. p 1–pFCFS FCFSμ1 μ2Poisson ( λ) Figure 14.9. Distributed server system. 14.7 Throwing Away Servers Suppose your computer center currently consists of a single server of speed μ. Jobs arrive according to a Poisson process with rate λ, and their service times are Exponentially distributed. Suppose the current response time is considered intolerable by the users. A second, faster server, running at speed αμ(forα>1), is purchased and added to the system in a heterogeneous M/M/2 structure with a single queue as in Exercise 14.5. Denote the load (utilization) of the M/M/2 system by ρ. Denote the mean response time of the M/M/2 system by E[T]. (a) Use the result in ( 14.14 ) from Exercise 14.5 to derive a formula for E[T], the mean response time of the M/M/2 system with heterogeneous servers. (b) A hotshot consultant walks in and makes the radical proposal of discon- necting the original server entirely (i.e., simply letting the faster server run by itself). Clearly this makes sense with respect to power, but the consul-tant claims this is also a win for E[T]. For $400/hr, what is the consultant thinking? Come up with an instance, in terms of λ,μ2, andμ1for which the consultant is right. Also, explain intuitively what is happening. [If you 268 server farms: m/m/ kand m/m/ k/k ﬁnd this problem interesting, you can think about a general criterion under which the consultant would be right . . . Throwing away servers is fun.] 14.8 Comparison of Multi-server Architectures with Heterogeneous Servers This problem asks you to apply ( 14.14 ), but does not require you to have solved Exercise 14.5. Consider four different server conﬁgurations. In all of these the outside arrival process is Poisson with rate λ. Also the service time at Host 1 (respectively, Host 2) is Exponentially distributed with rate μ1(respectively, μ2), where μ1=αμ2,α≥1. (1) An M/M/2 heterogeneous server system.(2) A server farm consisting of two hosts, each with its own queue. Every incoming job is immediately dispatched to Host 1 (with probability p) or to Host 2 (with probability 1−p). The probabilities pand1−pare chosen so as to balance load at the two hosts. (3) A server farm consisting of two hosts, each with its own queue. Every incoming job is immediately dispatched to Host 1 (with probability p) or to Host 2 (with probability 1−p). The probabilities pand1−pare chosen so as to minimize mean response time . (4) A server farm consisting of two hosts, each with its own queue. Every incoming job is immediately dispatched to Host 1 (with probability p)o r to Host 2 (with probability 1−p), where we set p=1. Observe that ρ=λ μ1+μ2=λ αμ2+μ2. Now consider the following table: ρ=low=0.25ρ=high=0.75 Two identical hosts: Fill in... Fill in... μ1=μ2=1 (useλ=0.5) (useλ=1.5) Host 1 is faster: Fill in... Fill in... μ1=4,μ2=1 (useλ=1.25) (useλ=3.75) Your job is to ﬁll in each entry of this table with a ranking of the four server con- ﬁgurations in order from greatest mean response time to least mean response time; for example, Tconﬁg1>T conﬁg2=Tconﬁg3>T conﬁg4. You may use “ >”o r“=” signs, but may notuse ambiguous signs like ≥. Note : For conﬁguration (4) observe that the correspondence between ρandλ does not make sense. Thus when evaluating conﬁguration (4) please just use theλvalue. It will help if you ﬁrst try to think about the problem using intuition. Feel free to use Mathematica to compare your expressions.",4613
Chapter 15 Capacity Provisioning for Server Farms. 15.1 What Does Load Really Mean in an MMk,"CHAPTER 15 Capacity Provisioning for Server Farms If servers were free, then every server farm would have an inﬁnite number of servers, and no job would ever have to wait in a queue. Unfortunately, servers are not free tobuy, and they are also not free to operate. Running servers consumes lots of power, andeven leaving a server on, but idle, still consumes nearly 60 percent of the power consumedby a busy server [ 15]. Given these costs, it pays to spend some time thinking about how many servers one really needs. This subject is called capacity provisioning . Observe that we can actually already, in theory, answer the question of how many servers we need to achieve a given Quality of Service (QoS) goal, based on theformulas we derived in Chapter 14. In that chapter, we considered the M/M/k server farm model and derived expressions for the distribution of the number of jobs in the system, the probability of queueing, PQ, and the expected response time, E[T].G i v e n a QoS constraint on E[T]orPQ, we can iterate over these formulas and deduce the exact number of servers, k, needed to achieve the desired constraint. However, iterating over a formula is time consuming and also does not provide any intuitions for the result. The purpose of this chapter is to formulate intuitions and rules of thumb for understanding how many servers we need to achieve a certain QoS goal, and what the impact is of increasing the number of servers. As usual, we build up to the question with discussions aimed at honing our intuition. We start in Section 15.1 by trying to get a better understanding of what load means in a multi-server system. We ﬁnd that, in an M/M/k, having high load does not necessarilyimply high delay. In Section 15.2, we introduce the concept of a server farm with an inﬁnite number of servers, the M/M/ ∞. Although this does not exist in the real world, this hypothetical system will simplify many future proofs and will give us a ﬁrst cut at a capacity provisioning rule. The chapter culminates in the famous “square-rootstafﬁng rule,” described and proved in Section 15.3, which will provide a very good approximation for the number of servers needed in an M/M/k as a function of QoS goals. In the exercises we explore additional QoS goals, such as the 95th percentile ofresponse time. 15.1 What Does Load Really Mean in an M/M/k? A common rule of thumb for a single-server M/M/1 system is that the utilization, ρ, should be kept below 0.8.I fρgets higher (e.g., ρ=0.95), delays explode. For example, withρ=0.8,E[N]for an M/M/1 is 4, whereas for ρ=0.95,E[N]=1 9 . In this 269 270 capacity provisioning for server farms section we ask whether this rule of thumb of ρ<0.8makes sense for a multi-server M/M/k system as well. Consider the formula from ( 14.8) for an M/M/k system: E[TQ]M/M/k=1 λPQρ 1−ρ(15.1) Hereρ=λ kμrepresents the load or system utilization (see Deﬁnition 14.4). It is hard to get a feel for how E[TQ]behaves, because there is a PQfactor, which we also do not have a handle on yet. For convenience, let’s therefore consider a slightly different metric that washes out the PQfactor:E[TQ]/PQ. Question: What does E[TQ]/PQrepresent? Answer: Observe that E[TQ]=E[TQ|delayed ]·PQ+E[TQ|not delayed ]·(1−PQ) =E[TQ|delayed ]·PQ. Thus, E[TQ] PQ=E[TQ|delayed ]. Namely, E[TQ]/PQrepresents the expected waiting time of those customers who are delayed. Now observe from ( 15.1) that E[TQ] PQ=E[TQ|delayed ]=1 λ·ρ 1−ρ=1 kμ(1−ρ). (15.2) Suppose that we now ﬁx ρto be some constant. Then we ﬁnd that the expected waiting time of those customers who are delayed drops in direct proportion to the number of servers, k. Thetake-home message is that high values of system utilization, ρ, do not imply that customers will suffer, provided that there are sufﬁciently many servers. For example, we might have an average server utilization of ρ=0.95with 5 servers. In this case, the average wait for customers who are delayed is1 5μ(.05)=4 μ, namely 4 times a job size. By contrast, we could have the same average server utilization of ρ=0.95with 100 servers. In this case, the average wait experienced by customers who are delayed is only1 100μ(.05)=1 5μ, namely a ﬁfth of a job size. Question: Why does having more servers help, given that ρ, the average server utiliza- tion, stays the same? Answer: Even if all servers still have utilization ρ, with more servers it is less likely that they are allbusy at the same time. Hence it is more likely that an arrival ﬁnds a free server. Question: Haven’t we seen an analogous result for a single-server system?",4577
15.2 The MM,"15.2 the m/m/∞ 271 Answer: Yes, even in an M/M/1, if we hold ρconstant, but increase both λandμby the same factor, then delay will drop indeﬁnitely. 15.2 The M/M/ ∞ We start, in Section 15.2.1 , by imagining a server farm with an inﬁnite number of servers. Although this is somewhat unrealistic, it will lead us to a good ﬁrst cut at an approximation for capacity provisioning, which we describe in Section 15.2.2 . 15.2.1 Analysis of the M/M/ ∞ Imagine that you could call up the phone company for customer service, and never getthe message, “We’re sorry, but all of our service representatives are busy serving othercustomers ...” This dream situation can be modeled by a queueing system with an inﬁnite number of servers, so that there is always a server to take your call. Such a system is called the M/M/ ∞queueing system. The interarrival times are Exponential with rate λ, the service times are Exponential with rate μ, and there are an inﬁnite number of servers. We are interested in deriving the probability distribution of the number of jobs in such a system. Question: What does the state diagram look like for the M/M/ ∞? Answer: The Markov chain for the system is shown in Figure 15.1. λ 2μλλ 3μ 4μλ μ2 0 13 Figure 15.1. CTMC for the M/M/ ∞system. Question: You should be able to solve this for the limiting probabilities. Can you express the limiting probabilities via a closed-form expression that is simple and clearly recognizable as something you have seen before? Answer: To derive the limiting probabilities, we set up the time-reversibility equations: π1=λ μπ0 π2=λ 2μπ1=λ 2μ·λ μ·π0 π3=λ 3μπ2=λ 3μ·λ 2μ·λ μ·π0 272 capacity provisioning for server farms Based on this, a good guess for the limiting probabilities is πi=/parenleftbiggλ μ/parenrightbiggi ·1 i.·π0. You should recognize this distribution as being the Poisson distribution with meanλ μ, where π0=e−λ μ. Question: From the limiting probabilities, derive a closed-form expression for the expected number of jobs in the system, E[N]. Answer: Number of jobs in the M/M/ ∞∼ Poisson/parenleftbiggλ μ/parenrightbigg . (15.3) The mean of this distribution is E[N]=λ μ. Question: Applying Little’s Law gives us E[T]. DoesE[T]make sense? Answer: By Little’s Law, E[T]=E[N] λ=1 μ. Thus the mean response time is just the mean service time. This makes sense, because jobs do not ever have to queue up. Question: We have actually seen the M/M/ ∞before when we discussed closed sys- tems. Where was this? Hint: What happens in a closed interactive system? Answer: The think station in a closed interactive system is an M/M/ ∞, where the mean “service time” is the mean time spent thinking.You may be worrying that the think time is not necessarily Exponentially distributed. However, this does not matter because the M/M/ ∞is insensitive to the distribution of service time (see Exercise 15.7). 15.2.2 A First Cut at a Capacity Provisioning Rule for the M/M/k Our goal is to understand how many servers, k, we need in an M/M/k so as to keep the probability of queueing, PQ, below some level, say 20 percent. Question: If the average arrival rate is λ, and the average service rate at each server isμ, what is the minimum number of servers, k, needed just to keep the system stable? 15.2 the m/m/∞ 273 Answer: We need ρ<1 ⇒λ kμ<1 ⇒k>λ μ. Observe thatλ μcan be a fraction, in which case we would actually have to round up to the next integer. We have seen this expression before in Deﬁnition 14.4, which we repeat here for reference. Deﬁnition 15.1 (Repeated from Deﬁnition 14.4)For an M/M/k with average arrival rate λand service rate μ, the resource requirement is denoted by R, where R=λ μ. Rcan be viewed as the minimum number of servers needed to keep the system stable, or as the expected number of servers that are busy, or as the expected number of jobs in service. We now argue that, if Ris a large number, then by using relatively few servers more thanR, namely k=R+√ R servers, we can get PQdown below the 20 percent range. Our argument is based on the M/M/∞queue. Question: What is the probability of having more than R+√ Rjobs in the M/M/ ∞? Answer: As we saw in ( 15.3), the number of jobs in the M/M/ ∞is Poisson distributed with mean R. Given that Ris large, the Poisson (R)distribution is well approximated by a Normal (R,R)distribution (see Feller [ 57], p. 245). Hence, we are asking what is the probability that the Normal (R,R)distribution is more than one standard deviation above its mean. This is simply the probability that the standard Normal exceeds its mean by more than one standard deviation, namely 1−Φ(1) , or about 16 percent.1 Thus, for an M/M/ ∞the probability that we use more than R+√ Rservers is only 16 percent. But the question we really wanted to answer was how many servers we need in an M/M/k, not an M/M/ ∞. Question: Is the M/M/∞result an upper bound or a lower bound on the M/M/k? Answer: When a lot of work arrives, the M/M/ ∞has more resources available for clearing this work than the M/M/k has (the work may have to queue in the M/M/k). 1Normal distributions are covered in Section 3.14.",5104
15.3 Square-Root Staffing,"274 capacity provisioning for server farms Hence the fraction of time that the M/M/ ∞has more than xservers busy is going to be lower than the fraction of time that the M/M/k has more than xservers busy. Hence 16 percent is a lower bound. In fact, as we see in the next section, when using k=R+√ R servers in the M/M/k, PQis about 20 percent. 15.3 Square-Root Stafﬁng In this section, we reﬁne the R+√ Rapproximation developed in the previous section. As before, we assume an M/M/k with average arrival rate λand average server speed μ. The QoS goal that we set is that PQ, the probability of queueing in the M/M/k, should be below some given value α(e.g.,α= 20 percent ). Our goal is to determine the minimal number of servers, k∗ α, needed to meet this QoS goal. Note that bounding PQis really equivalent to bounding mean response time or mean queueing time, or similar metrics, because they are all simple functions of PQ(e.g., from ( 14.9), we have E[TQ]=1 λ·PQ·ρ 1−ρ). Theorem 15.2 (Square-Root Stafﬁng Rule) Given an M/M/k with arrival rate λ and server speed μandR=λ/μ, where Ris large, let k∗ αdenote the least number of servers needed to ensure that PM/M/k Q<α. Then k∗ α≈R+c√ R, where cis the solution to the equation, cΦ(c) φ(c)=1−α α(15.4) where Φ(·)denotes the c.d.f. of the standard Normal and φ(·)denotes its p.d.f. Remark: It is interesting to observe that the constant cin Theorem 15.2 does not depend on Ror the arrival rate λ. Also, in practice, cis quite small. A good rule of thumb to remember is that when α=0.2,c≈1. Thus, to ensure that only 20 percent of jobs queue up, it sufﬁces to use just k=R+√ Rservers, where Ris the number of servers needed to just maintain stability. Here are a few more values: α=0.8α=0.5α=0.2α=0.1 c=0.173 c=.506 c=1.06c=1.42 Remark: In Exercise 15.3, you will be asked to derive k∗ αboth (i) via the approximation in Theorem 15.2 and (ii) exactly by evaluating the PM/M/k Q at different values of k. What you will ﬁnd is that the approximation in Theorem 15.2 is exact or off by at most 1, even for very low R, like 1. This is surprising, because the proof of Theorem 15.2 assumes large R. Thus Theorem 15.2 even works well for stafﬁng small server farms. 15.3 square-root stafﬁng 275 Proof (Square-Root Stafﬁng) Our approach is to express PQin terms of Pblockand determine a simple approximation for Pblock. This may seem logically confusing, since PQrefers to the M/M/k, while Pblockis the blocking probability for the M/M/k/k (see Chapter 14). However, our approach is just an algebraic maneuver, since Pblockis easy to derive and will thus quickly yield an approximation for PQ. Recall from ( 14.6) that Pblock=(1−ρ)PQ 1−ρPQ. This allows us to express PQin terms of Pblockas follows: PQ=Pblock 1−ρ+ρPblock=kPblock k−R+RP block. (15.5) We now turn to deriving Pblock. If we let XRdenote a random variable with Poisson distribution and mean R, then we can use ( 14.3) to express Pblockas Pblock=P{XR=k} P{XR≤k}. These latter expressions involving XRcan be simply expressed if we use the fact that the Poisson distribution of mean Rcan be well approximated by the Normal distribution of the same mean and variance R, provided that Ris large. Speciﬁcally, setting k=R+c√ R, we see that P{XR≤k}=P/braceleftBig XR≤R+c√ R/bracerightBig ≈P/braceleftBig Normal (R,R)≤R+c√ R/bracerightBig =P{Normal (0,1)≤c} =Φ (c). P{XR=k}=P{XR≤k}−P{XR≤k−1} ≈Φ(c)−P/braceleftBig XR≤R+c√ R−1/bracerightBig =Φ (c)−P/braceleftbigg XR≤R+√ R/parenleftbigg c−1√ R/parenrightbigg/bracerightbigg ≈Φ(c)−Φ/parenleftbigg c−1√ R/parenrightbigg ≈1√ Rφ(c)(again, we are assuming R: large) .",3606
15.4 Readings. 15.5 Exercises,"276 capacity provisioning for server farms Thus we have Pblock=P{XR=k} P{XR≤k}≈φ(c)√ RΦ(c). (15.6) Returning to the expression for PQin (15.5), and substituting in ( 15.6), as well as the fact that k=R+c√ R,w en o wh a v e PQ=kPblock k−R+RP block ≈(R+c√ R)φ(c)√ RΦ(c) R+c√ R−R+Rφ(c)√ RΦ(c) =(√ R+c)φ(c) Φ(c) c√ R+√ Rφ(c) Φ(c) =1+c√ R 1+Φ(c) φ(c)·c. If we now assume that Ris large so that c< <√ R, then PQ≈/parenleftbigg 1+Φ(c) φ(c)c/parenrightbigg−1 . (15.7) Now recall that our goal is to make PQ<α. PQ<α ⇐⇒/parenleftbigg 1+Φ(c) φ(c)c/parenrightbigg−1 <α ⇐⇒Φ(c) φ(c)c>1 α−1 The minimum value of cthat satisﬁes the above is the solution to Φ(c) φ(c)c=1 α−1, which is exactly equation ( 15.4). 15.4 Readings The square-root stafﬁng derivation is based on a beautifully written book by Tijms [178]. 15.5 Exercises 15.1 Effect of Increased Number of Servers Consider an M/M/k system, where the service rate at each server is μ=1. Fix system utilization at ρ=0.95. Now increase the number of servers, k,a s 15.5 exercises 277 follows – 1, 2, 4, 8, 16, 32 – adjusting the arrival rate, λ, accordingly. For each number of servers, derive (i) the fraction of customers that are delayed and (ii) the expected waiting time for those customers who are delayed. We arejust looking for numerical answers here. Feel free to write a math program toevaluate the needed summations. Explain the trend that you see. 15.2 Capacity Provisioning to Avoid Loss In a call center with koperators, all calls that are not immediately answered by an operator are dropped . Calls arrive according to a Poisson process with rateλand have Exponentially distributed service times with rate μ=1.F o rλ in the set{1,2,4,8}, what should kbe as a function of λto ensure that fewer than1 percentof calls are dropped? We are just looking for numerical solutions. Feel free to write a math program to evaluate the needed summations. When λdoubles, does the needed number of operators double? 15.3 Accuracy of Square-Root Stafﬁng Rule The point of this problem is to test the accuracy of the square-root stafﬁngapproximation given in Theorem 15.2. We want to determine the minimum number of servers, k∗, needed to staff our M/M/k call center, such that fewer than 20 percent of customers are delayed. Assume that job sizes are Exponentially distributed with mean1 μ=1. Consider the following cases for the resource re- quirement: R=λ μ=1,5,10,50,100,250,500,1,000. For each case, derive k∗according to the square-root stafﬁng approximation given in Theorem 15.2, and then derive it from scratch using PQfor the M/M/k. How close are the results? 15.4 95th Percentile of Response Time – M/M/1 While mean response time is a common performance metric, many system administrators prefer instead to measure the 95th percentile of response time,denoted by T95. Formally, T95is deﬁned to be that xsuch that P{T>x}=0.05. Namely, only 5 percent of jobs have higher response time than T95. Consider an M/M/1 with service rate μ=1and load ρ=λ. (a) How is response time, T, distributed in an M/M/1, in terms of ρ? (b) How does E[T]scale with ρ? (c) How does T95grow with ρ?",3122
15.4 Readings. 15.5 Exercises,"How does this compare with how E[T]grows withρ? 15.5 95th Percentile of Time in Queue – M/M/k In Exercise 15.4 we derived the 95th percentile of response time for the M/M/1. We now wish to follow a similar approach to derive the 95th percentile of the queueing time in the M/M/k, for those jobs that queue. Assume arrival rate λ, service rate μat each of the kservers, and ρ=λ kμ<1. (a) Consider the queueing time of those jobs which queue, namely [TQ|delayed ]. How is this quantity distributed? (b) What is the 95th percentile of the queueing time of those jobs that queue, as a function of k,μ, andλ? 278 capacity provisioning for server farms 15.6 How to Split Capacity For the server farm in Figure 15.2, jobs arrive according to a Poisson process with rate λand are probabilistically split between two servers, with p>1 2 fraction going to server 1, and q=1−p<1 2fraction going to server 2. If we have a total service capacity of μfor the two servers, how should we optimally splitμbetween the two servers, into μ1andμ2, where μ=μ1+μ2,s oa st o minimize E[T]? Assume job sizes are Exponentially distributed. p 1–pFCFS FCFSμ1 μ2Poisson ( λ) Figure 15.2. How should we split capacity μbetween two servers? (a) Let’s start with some easy cases. What should the answer be if p=1? How about if p=1 2? (b) Returning to the general case of p>1 2, what is a lower bound on μ1? How about on μ2? After we allocate this minimum capacity to server 1 and server 2, what is the extra capacity left over? (c) Of the “extra capacity” that remains, what fraction do you intuitively believe should be allocated to server 1? (d) Prove that the optimal fraction of extra capacity going to server 1 is √p √p+√1−p. (15.8) That is, the optimal value for μ1isμ∗ 1=λp+√p√p+√1−p(μ−λ). (e) Provide intuition for at least the direction of the result. 15.7 Insensitivity of M/G/ ∞ The M/G/∞system consists of a single FCFS queue, served by an inﬁnite number of servers, where jobs arrive according to a Poisson process with rate λand have generally distributed i.i.d. job service requirements with mean1 μ.I t turns out that the probability that there are kjobs in the M/G/ ∞is insensitive to the distribution of G, depending on only the mean of G. Speciﬁcally, P{There are kjobs in the M/G/∞}=e−λ μ/parenleftBig λ μ/parenrightBigk k.. (15.9) This problem leads us through a heuristic derivation of this result, borrowed from [ 178], which provides a lot of intuition for the insensitivity result. (This argument can be made completely rigorous by using differential equations, see [178], pages 10–11.) (a) Consider ﬁrst the case where all jobs have the same Deterministic size D=1 μ. Consider a time t>D . Derive the probability that there are k 15.5 exercises 279 customers at time tand show this agrees with ( 15.9). [Hint: What can you say about the arrival times of customers who are around at time t,g i v e n that all customers have ﬁxed size D?] (b) Now consider the case where there are /lscriptclasses of jobs. With probability pi, an arrival is of class i. Jobs of class ihave Deterministic size Di. The average job size is still1 μ, that is,/summationtext/lscript i=1piDi=1 μ.",3165
15.4 Readings. 15.5 Exercises,"Consider a time t>max iDi. Derive the probability that there are kcustomers present at timetand show that this agrees with ( 15.9). 15.8 Pricing and Queueing A software ﬁrm is designing a new cloud computing service and has hired you as a consultant to help price its service. Users submit computing jobs to an M/M/1 (FCFS) server with arrival rate λ and service rate μ=1. The actual job size is unknown to both the user and the server until the job begins receiving service. All users receiving service gain a monetary value worth V−c·Tfor each completed job, where V>1is a given constant value for all jobs, Tis the response time of the job, and cis the cost of waiting per unit time. Without loss of generality, we will normalize our units to let c=1, so a customer receives V−Tvalue from service. At the time of arrival, a user must decide whether to allow his or her job to join the queue based on the following information: (i) The ﬁrm reveals the numberof jobs already in the system, n, and (ii) the ﬁrm charges a ﬁxed price of entry P>0. The user will allow the job to join if and only if the price of entry is no more than the value he or she expects to receive from the service. We can express this condition as V−E[T|N=n]≥P. The ﬁrm wishes to set Pto maximize its own earning rate: R=λP·P{an arrival joins the queue } Because not all arrivals will join the queue, the queue will be stable, even for λ>1. You may assume throughout this problem that VandPare integers. (a) What is the greatest nfor which arrivals are willing to join the queue (in terms of VandP)? (b) What is the earning rate R(in terms of λ,V, andP)? (c) Compute the optimal integer price P∗and the corresponding earning rate Rfor the following cases: (i) V=6andλ=0.1; (ii)V=6andλ=0.9; and (iii) V=6andλ=1.8. (Create a table of Ras a function of different Pvalues.) (d) Sherwin proposes that we can do better by charging a state-dependent price,P(n), when the state is n, where P(n)=m a x{1,Highest price users will pay in state n}. 280 capacity provisioning for server farms We charge 1 when users are unwilling to pay a positive integer price, effectively turning these users away and thereby ensuring that we alwaysearn money for each job we serve. Deﬁne n0to be the lowest numbered statenfor which users are unwilling to pay a positive price. Determine P(n)(in terms of nandVandn0). (e) Under state-dependent pricing, the earning rate becomes R=λn0−1/summationdisplay n=0P(n)·P{an arrival joins the queue and pays P(n)}. Compute the earning rate Runder state-dependent pricing for the cases given in part (c). How do your results compare to those in part (c)? Explainyour ﬁndings intuitively. Remark: It turns out that Sherwin’s suggestion can sometimes be improved on by using a threshold policy whereby users are barred from entry once the queue length reaches a certain threshold [ 39]. 15.9 Congestion Management Consider this common congestion management scheme: Jobs are served in an M/M/1 queue, provided that the number of jobs is no more than Thigh. Once the number of jobs hits Thigh, a second server is immediately added, creating an M/M/2. The second server continues to be utilized until the number of jobs drops to Tlow, at which point the second server is removed, and we are back to an M/M/1, and the process repeats. Assume that jobs arrive according to aPoisson process with rate λand that job sizes are Exponentially distributed with rateμ. Assume that Tlow=1 andThigh=t, as shown in Figure 15.3.D e r i v e an expression for the mean response time, E[T], as a function of t. Your expression does not need to be in closed form. Evaluate E[T]forλ=1.5, μ=1, andt=4,8,16,32,64.[Note: This problem is algebraically messy; using a math software package will help.] t–1λ µλλ µλ µ2 λ 2µ2΄0 1 µ t–1΄λ λ 2µλ 2µλ 2µt+1 t 2µ Figure 15.3. CTMC for Exercise 15.9. 15.10 M/M/1 with Setup Times Consider an M/M/1 queue, where the server immediately shuts off when it isidle (e.g., to save power). When a job arrives and ﬁnds the server off there is a setup time , I, required to get the server back on. In this problem we assume I∼Exp(α). Setup times are very important in capacity provisioning 15.5 exercises 281 for systems, because they delay not only the job that ﬁnds the server off, but also subsequent jobs that arrive before the server is operational again.Interestingly, for an M/M/1 with an Exponentially distributed setup cost, one can prove the following result, relating the mean response time for an M/M/1 with setup to an M/M/1 without setup: E[T]M/M/1/setup=E[T]M/M/1+E[I] (15.10) Derive ( 15.10 ) by modeling the system via a Markov chain and solving for the limiting probabilities. Warning: While the chain looks simple, the fact that there are two rows makes it a lot harder to solve. This is a difﬁcult problem.[Note: This problem will be revisited in Chapter 27on power management in greater generality.]",4911
Chapter 16 Time-Reversibility and Burkes Theorem. 16.1 More Examples of Finite-State CTMCs,"CHAPTER 16 Time-Reversibility and Burke’s Theorem Many practical problems can be represented by a small ﬁnite-state CTMC. When this happens, one is always happy. A ﬁnite-state CTMC, whose transition rates are numbers(not variables), can always be solved, given enough computational power, because it simply translates to a ﬁnite set of linear simultaneous equations. When transition rates are arbitrary parameters ( λ’s and μ’s and such), the chain might still be solvable via symbolic manipulation, provided that the number of equations is not too great. Sec- tion16.1 provides additional practice with setting up and solving ﬁnite-state CTMCs. Unfortunately, many systems problems involve unbounded queues that translate into inﬁnite-state CTMCs. We have already seen the M/M/1 and the M/M/k, which involvejust a single queue and are solvable, even though the number of states is inﬁnite. However, as we move to queueing networks (systems with multiple queues), we seethat we need to track the number of jobs in each queue, resulting in a chain that is inﬁnitein more than one dimension. At ﬁrst such chains seem entirely intractable. Fortunately,it turns out that a very large class of such chains is easily solvable in closed form. Thischapter, starting with Section 16.2 on time-reversibility and leading into Section 16.3 on Burke’s theorem, provides us with the foundations needed to develop the theory ofqueueing networks, which will be the topic of the next few chapters. 16.1 More Examples of Finite-State CTMCs 16.1.1 Networks with Finite Buffer Space Imagine a small hair salon with only 2 chairs (see Figure 16.1). A customer ﬁrst goes to chair 1, by the sink, where her hair is washed, and then to chair 2, by the mirror, where her hair is cut. There is no standing room in the salon (no queueing). Thus, a customer only enters the salon if chair 1 is empty, and if a customer is ﬁnished with chair 1 but chair 2 is still occupied, the customer waits in chair 1. Poisson ( λ) Exp( μ1) service timeExp( μ2) service time Figure 16.1. The hair salon. 282 16.1 more examples of finite-state ctmc s 283 This example may seem artiﬁcial, but in fact it is quite practical. It represents the situation where there are two routers in tandem, each with a ﬁnite capacity (in this casethe ﬁnite buffer is of size 1only, but it could be higher in general), and packets continue to occupy a buffer simply because the next buffer in the chain of routers is full. We wish to answer these two questions: 1.What proportion of potential customers enter the salon? 2.What is the mean response time, E[T]? To answer these questions, we need to determine the state space. Question: What is wrong with making the state be the number of customers in the system? Answer: Doing so will not allow us to answer Question 1. Question: How many customers can we have in each chair? Answer: There can be 0 or 1 customers in each chair. Question: How about this state space: (0,0), (0,1), (1,0), (1,1)? Answer: Not good enough: (1,1) is ambiguous. Suppose we are in state (1,1). With rate μ2, where do we go? If (1,1) represents the fact that there is one customer receiving service in chair 1 and one customer receiving service in chair 2, then with rate μ2we should go to state (1,0). However, if (1,1) represents the fact that there is one customer who has ﬁnished service in chair 1 and one customer still receiving service in chair 2, then with rate μ2we should go to state (0,1). Figure 16.2 shows the appropriate CTMC. State (b,1)in the CTMC represents the state where there is a customer in both chairs, but the customer at chair 1 is ﬁnished and is blocked, waiting for chair 2. μ2λ μ1 μ1 μ2λ1,1 1,0 0,10,0 b,1μ2 Figure 16.2. The hair salon state space. We now write the balance equations for each state: (0,0) : π0,0·λ=π0,1·μ2 (1,0) : π1,0·μ1=π0,0·λ+π1,1·μ2 284 time-reversibility and burke’s theorem (0,1) : π0,1·(μ2+λ)=π1,0·μ1+πb,1·μ2 (1,1) : π1,1·(μ2+μ1)=π0,1·λ (b,1) : πb,1·μ2=π1,1·μ1/summationdisplay πi,j:π0,0+π1,0+π0,1+π1,1+πb,1=1 We can now answer our questions, in terms of the limiting probabilities. Question: What proportion of potential customers enter the salon? Answer: An arrival enters the salon if she sees 0customers in the ﬁrst chair. By PASTA, the probability that an arrival sees 0in the ﬁrst chair is equal to the proportion of time there are 0in the ﬁrst chair, namely: π0,0+π0,1 Question: What is E[N]? Answer: E[N]=π1,0+π0,1+2·(π1,1+πb,1). Question: What is E[T]for an entering customer? Answer: E[T]=E[N] λarrival=E[N] λ(π0,0+π0,1). Importantly, in applying Little’s Law, we use λarrival, which includes only those arrivals that actually make it through the network. 16.1.2 Batch System with M/M/2 I/O Consider a system consisting of one CPU queue and one I/O queue, where the I/O queue is served by two disks, operating as an M/M/2 system, as shown in Figure 16.3. Our goal is to determine the exact throughput for this system (not approximations based on high Nasymptotics). N = 3 μ=1.5 Disk A μ=4  CPU Disk B μ=1.5  Figure 16.3. A batch system with M/M/2 I/O. Question: Show the CTMC for this system. Answer: Figure 16.4 shows the state space of the system. 444 1.5 3 31,2 3,0 0,3 2,1 Figure 16.4. State space of a batch system with M/M/2 I/O.",5264
16.2 The Reverse Chain,"16.2 the reverse chain 285 State(i, j)represents the fact that there are ijobs in the CPU subsystem (including the CPU queue and server) and jjobs in the disk subsystem (including the disk queue and two disks). There are a total of N=3jobs in the whole system. The balance equations are as follows: π3,0·4=π2,1·1.5 π2,1·5.5=π3,0·4+π1,2·3 π1,2·7=π2,1·4+π0,3·3 π0,3·3=π1,2·4 π3,0+π2,1+π1,2+π0,3=1 Solving these, the steady-state probabilities are: π3,0=0.08,π2,1=0.22,π1,2=0.3, andπ0,3=0.4. Question: What is the throughput, X? Answer: Every job passes through the CPU, so it sufﬁces to look at Xcpu: ρcpu=π3,0+π2,1+π1,2=0.6 X=Xcpu=ρcpu·μcpu=0.6·4jobs/sec =2.4jobs/sec Question: How does this compare with what we get from asymptotic calculations using only operational laws and assuming high N, as in Chapter 7? Answer: For high N, we will have X=3 jobs/sec, because at most 3jobs can pass through the disk module each second. Question: What is E[Tcpu]? Answer: E[Tcpu]=E[Ncpu] Xcpu=3·π3,0+2·π2,1+1·π1,2 2.4=0.41sec. Question: What is ρdisk a? Answer:1 2·π2,1+π1,2+π0,3=0.8. 16.2 The Reverse Chain In the previous examples, the state space was ﬁnite, making the CTMC easy to solve. In open queueing systems, the state space is typically inﬁnite, and it is often inﬁnite inmore than one dimension, because we need to track the “unbounded” number of jobs ateach of several queues. To analyze such systems, we need to develop a new technique.This section and the next present this new technique. Consider an ergodic CTMC in steady state. Now imagine we are watching the CTMC as it transitions between states: ···− → 3−→5−→1−→2−→1−→3−→4−→1− →··· 286 time-reversibility and burke’s theorem Now consider the reverse process for the CTMC. That is, we watch the CTMC, but we look backward in time (think of watching a movie being played in reverse): ···← − 3←−5←−1←−2←−1←−3←−4←−1← −··· That is, the reverse process transitions from state 1 to 4 to 3 to 1 to 2 to 1, etc. Claim 16.1 The reverse process is also a CTMC. Proof To see this, think of the CTMC via VIEW 1, as described in Chapter 12. The forwards process sits in state 3for Exp (ν3)time and then ﬂips a coin with probability P3,5of next going to 5. The process then sits in state 5for Exp (ν5)time and again ﬂips a coin to determine where to go next with probability P5,1of next going to state 1. The process then sits in state 1for Exp (ν1)time. If we look at just the coin ﬂips (ignoring the time spent in each state), then the sequence of coin ﬂips forms what is called an embedded DTMC . Now consider the reverse process , transitioning over these same states. The reverse process also sits in state 1for Exp (ν1)time. It then moves to state 5where it sits for Exp(ν5)time and then moves to state 3where it sits for Exp (ν3)time. So we already see that each time the reverse process visits state i, it also sits in state ifor Exp (νi) time. To show that the reverse process is a CTMC, all that remains is to show that thereareprobabilities deﬁning the reverse process’s transitions between states. The probability that the reverse process moves from state 1to state 5is exactly the probability that the forwards process got to state 1from state 5, rather than from some other state, given that the forwards process wound up in state 1. LetP∗ ijdenote the probability that the reverse embedded DTMC moves from state ito state j, given that it is in state i. To ﬁnish this proof we do not need to explicitly compute P∗ ij; we just need to know that it is a valid probability, meaning that /summationdisplay jP{Reverse process moves from state ito state j}=1, which is obviously true given that the forward chain must have gotten to state ifrom some state.1 To keep from getting confused, we will tag all quantities associated with the reverse chain with an asterisk (*). So for example, we have seen that νj=ν∗ j. Question: How does πjrelate to π∗ j? 1We will not need to know this, but if you are curious about what P∗ ijlooks like, you will ﬁnd out in equation ( 16.2). 16.2 the reverse chain 287 Answer: πjrepresents the fraction of time that the forward CTMC chain is in state j. But this is equal to the fraction of time that the reverse chain is in state j. Thus, πj=π∗ j. Letπiqijdenote the rate of transitions from itojin the forwards process, where πi denotes the limiting probability of being in state iandqijdenotes the rate of transitions fromitoj, given we are in state i. Note here that qij=νi·Pij, (16.1) where νiis the total rate of transitions leaving state i, given that we are in state i. Question: Is the rate of transitions from state ito state jin the reverse CTMC process the same as the rate of transitions from state ito state jin the forwards CTMC process? Answer: No,π∗ iq∗ ijis not necessarily equal to πiqijbecause q∗ ijis not necessarily equal to qij. For example, there may be zero rate of transitions from itojin the forwards chain, and yet a positive rate of transitions from itojin the reverse chain. Claim 16.2 The rate of transitions from itojin the reverse CTMC process equals the rate of transitions from jtoiin the forwards CTMC process. That is, π∗ iq∗ ij=πjqji. This claim is always true and has nothing to do with time-reversibility. Proof Consider any observation period T. During Tthe number of transitions that the reverse process makes from itojis exactly equal to the number of transitions that the forwards process makes from jtoi. Thus the rates (number of transitions during T, divided by T) are also the same. An immediate corollary of Claim 16.2 combined with ( 16.1) is that2 P∗ ij=πjνjPji πiνi. (16.2) 2Here is an independent derivation of P∗ ij. Consider the embedded DTMC within our CTMC. Let πDTMC ibe the limiting probability of being in state ifor the embedded DTMC (note this is not the same as the limiting probability for the CTMC, πCTMC i). Observe that the rate of transitions from jtoiin the forward embedded DTMC equals the rate of transitions from itojin the reverse embedded DTMC. (This is true for every chain and has nothing to do with time-reversibility.) So πDTMC jPji=π∗DTMC iP∗ ij. But because π∗DTMC i=πDTMC i,w eh a v e πDTMC jPji=πDTMC iP∗ ij, which results in P∗ ij=πDTMC jPji πDTMC i,",6217
16.3 Burkes Theorem,"288 time-reversibility and burke’s theorem It turns out that we can say a lot more about the reverse chain ifwe know that the forwards chain is time-reversible . Deﬁnition 16.3 AC T M Ci s time-reversible if, for all i,j: πiqij=πjqjiand/summationdisplay iπi=1. (16.3) In other words, a CTMC is time-reversible if for every pair of states i,j, the rate of transitions from itojin the forwards process equals the rate of transitions from j toiin the forwards process. For example, the CTMC corresponding to a birth-death process is time-reversible, because the number of transitions from state ito state i+1 is always within 1 of the number of transitions from state i+1 toi, and hence the long-run rateof transitions from itoi+1equals the rateof transitions from i+1to i. Note that time-reversibility is deﬁned as a property of the forwards process. Claim 16.4 If a CTMC is time-reversible, then its reverse chain is statistically identical to the forwards chain, meaning that the reverse chain can be described by the same CTMC as the forwards chain. Proof If the CTMC is time-reversible, then πiqij=πjqji(by deﬁnition of time-reversibility) =π∗ iq∗ ij(by Claim 16.2) =πiq∗ ij. Therefore, qij=q∗ ij for all i,j. Because these rates deﬁne the CTMC (think VIEW 2 of a CTMC from Chapter 12), the forwards and reverse chains are statistically identical. Note that this also implies Pij=P∗ ij, because qij=νiPijandνi=ν∗ i. Thus the embedded DTMCs for the forwards and reverse processes are also identical. 16.3 Burke’s Theorem Theorem 16.5 (Burke) Consider an M/M/1 system with arrival rate λ. Suppose the system starts in a steady state. Then the following are true: Now observe that there is a clear relation between πDTMC i(which spends time 1during each visit to a state) and πCTMC i(which spends time Exp (νi)during each visit to state i); namely, πCTMC i=πDTMC i·1 νi·C, where Cis just a normalizing constant needed to get the limiting probabilities to sum to 1. Hence, P∗ ij=πDTMC jPji πDTMC i=πCTMC jνjPji πCTMC iνi. 16.3 burke’s theorem 289 1.The departure process is Poisson (λ). 2.At each time t, the number of jobs in the system at time tis independent of the sequence of departure times prior to time t. Part (1) of Theorem 16.5 says that the interdeparture times are Exponentially distributed with rate λ. It is not at all obvious that this should be the case. Clearly, while the server is busy, the interdeparture times are distributed Exp (μ). But then the server is idle for Exp(λ)time, so the time until the following departure is Exp (λ)+Exp(μ).I ti sn o t obvious then why this should result in a departure process with Exp (λ)interdeparture times. Part (2) of the theorem says that the number of jobs in the system at any time does not depend on the previous departure times or patterns. For example, knowing that therewas recently a stream of closely spaced departures does not indicate that the numberof jobs in the system currently is below average. Proof 1.Observe that the departures in the forwards process occur at points of arrivals in the reverse process (see Figure 16.5). Now consider the points of arrivals in the reverse process. Because the M/M/1 is time-reversible, the reverse process isstatistically identical to the forwards process by Claim 16.4. Thus the points of arrivals in the reverse process constitute a Poisson process with rate λ.S o( b y our previous observation) the points of departures in the forwards process also constitute a Poisson process with rate λ. timeNumber of jobs Figure 16.5. Departures in forwards process are arrivals in reverse process. 2.The sequence of departure times prior to time tin the forwards process is exactly the sequence of arrival times after timetin the reverse process. However, the future arrival pattern for the reverse process does not depend on the number of jobs at time t, because this process is a Poisson process. Therefore, looking at the forwards process, the number of jobs at time tis independent of the sequence of departures prior to time t. The claims in Burke’s theorem also hold for an M/M/k system. The proofs are exactlythe same. Question: Give an example of a queueing network for which part (2) of Burke’s theorem does nothold.",4228
16.5 Application Tandem Servers,"290 time-reversibility and burke’s theorem Answer: Consider a single-server network, where arrivals occur exactly at times 0,2, 4,6,...S uppose the service time is U(0,2)(i.e., Uniformly distributed between 0and 2). LetN(t)be the number of jobs in the system at time t. Then N(1)is either 0or1 and speciﬁcally depends on whether there was a departure during (0,1). 16.4 An Alternative (Partial) Proof of Burke’s Theorem Having taught this material for many years, I have found that there are always some students who remain unconvinced about the ﬁrst part of Burke’s theorem, namely that the interdeparture times are distributed Exp (λ). These students argue that the interdeparture times are either Exp (μ)(when the server is busy) or are of the form of Exp(λ)+Exp(μ)(when the server is idle); the term Exp (λ)+Exp(μ)comes from having to wait for an arrival and then to wait for that arrival to depart. It is not at all clear why having interdeparture times switch between these modes should form aPoisson (λ)departure process. This paradox is shown in Figure 16.6. Events time Exp( μ) Exp( μ) Exp( μ) Exp( μ)+Exp( λ) Exp( μ) Figure 16.6. Interdeparture times in M/M/1. For these frustrated students, I offer the following alternative explanation. First observe that, for an M/M/1, the probability that a departure leaves behind a busy system is ρ, and the probability that a departure leaves behind an idle system is 1−ρ. Question: Why is this? Answer: As explained in Section 13.3, by PASTA, an=pn,∀n, implying that the probability that an arrival ﬁnds the system busy is the time-average fraction of time that the system is busy, namely ρ. However, for any ergodic system, an=dn,s odn=pn, ∀n; hence the probability that a departure leaves behind a busy system is ρ. Now, let’s suppose that a departure just happened. We are interested in the quantity T, which is the time until the next departure. We would like to prove that T∼Exp(λ). Now, when the departure leaves, with probability ρ, it leaves behind a busy system, soT∼Exp(μ), and with probability 1−ρ, it leaves behind an idle system, so T∼ Exp(λ)+Exp(μ). Thus, T∼/braceleftbigg Exp(μ) w.p.ρ Exp(μ)+Exp(λ)w.p.1−ρ. 16.5 application: tandem servers 291 Question: Does the distribution of Tlook Exponential? Answer: It does not seem so, but here is the argument. By conditioning on the value, t, of Exp (λ), P{T>x}=ρe−μx+( 1−ρ)/parenleftbigg/integraldisplayx t=0e−μ(x−t)λe−λtdt+/integraldisplay∞ t=x1·λe−λtdt/parenrightbigg =ρe−μx+( 1−ρ)e−μxλ/integraldisplayx t=0e(μ−λ)tdt+( 1−ρ)e−λx =e−μx/parenleftBigg ρ+(1−ρ)λ/parenleftbig e(μ−λ)x−1/parenrightbig μ−λ+( 1−ρ)e(μ−λ)x/parenrightBigg =e−μx/parenleftbig ρ+ρe(μ−λ)x−ρ+( 1−ρ)e(μ−λ)x/parenrightbig =e−μx/parenleftbig e(μ−λ)x/parenrightbig =e−λx. Hence the time between departures is in fact Exponentially distributed with rate λ. Note that this proof is only a partial proof, compared with the proof in Section 16.3, because it does not argue independence of the interarrival times. Nonetheless it does shed some insight onto how the Exp (λ)interdeparture times come about. 16.5 Application: Tandem Servers We will now see how to apply Burke’s theorem to obtain formulas that allow us to instantly analyze a large class of queueing networks. We start with a simple tandemsystem. We want to ﬁnd the limiting probabilities of the tandem system, shown in Figure 16.7. 2 1 Poisson ( λ) ρ1 = 1 ρ2 = 2 Figure 16.7. Tandem queues. We can try to model the system by drawing the CTMC and solving the associated balance equations. We end up with an inﬁnite-state CTMC, where each state is a pair (n1,n2)denoting the number of jobs at server 1 and the number at server 2. A piece of the CTMC is shown in Figure 16.8. 292 time-reversibility and burke’s theorem n1–1,n2 n1+1,n2–1 n1, n2+1n1, n2 n1–1,n2+1 n1, n2–1λ μ1 μ2λ μ1 μ2n1+1,n2 Figure 16.8. Portion of CTMC, assuming n1,n2≥1. The corresponding balance equations when n1≥1andn2≥1take the following form: πn1,n2(λ+μ1+μ2)=πn1−1,n2·λ+πn1+1,n2−1·μ1+πn1,n2+1·μ2 These balance equations look hard to solve. On the other hand, we can apply Burke’s theorem to ﬁnd the solution to Figure 16.7 very easily. By part (1) of Burke’s theorem, we know that the arrival stream into server 2 is Poisson (λ). If we view the two servers in isolation, they are both M/M/1 systems with arrival rates λ. Therefore, P{n1jobs at server 1 }=ρn1 1(1−ρ1). P{n2jobs at server 2 }=ρn2 2(1−ρ2). Next, we show that the numbers of jobs at the two servers are independent. Let N1(t) denote the number of jobs at server 1at time t. LetN2(t)denote the number of jobs at server 2at time t. By part (2) of Burke’s theorem, the sequence of departures from server 1 prior to time tis independent of N1(t). Because departures from server 1 are arrivals into server 2, we see that the sequence of arrivals into server 2 prior to time tis independent of N1(t).B u tN2(t)is completely determined by the sequence of arrivals into server 2 prior to time t. Therefore N2(t)is independent of N1(t)for all t. Using these results, we can determine the limiting probabilities: πn1,n2= lim t→∞P{N1(t)=n1andN2(t)=n2} = lim t→∞P{N1(t)=n1}·P{N2(t)=n2} = lim t→∞P{N1(t)=n1}·limt→∞P{N2(t)=n2} =P{n1at server 1}·P{n2at server 2} =ρn1 1(1−ρ1)ρn2 2(1−ρ2) To check our answer, we can substitute our expression for πn1,n2back into the balance equations: πn1,n2(λ+μ1+μ2)=πn1−1,n2λ+πn1+1,n2−1μ1+πn1,n2+1μ2 Try plugging it in . . . you will see it works. This therefore provides a second proof for why the number of jobs at server 1 and the number of jobs at server 2 are independent.",5565
16.7 Readings,"16.6 general acyclic networks with probabilistic routing 293 Poisson ( λ) μ=3 μ=6 versus Poisson ( λ) μ=6 μ=3 Figure 16.9. Which of these is better? Question: Which of the systems in Figure 16.9 has better performance? Answer: Both have the same performance. For both systems, E[N]=E[N1]+E[N2]=ρ1 1−ρ1+ρ2 1−ρ2, where ρ1=λ 3andρ2=λ 6. 16.6 General Acyclic Networks with Probabilistic Routing Now consider any acyclic network of servers with probabilistic routing, as shown in Figure 16.10 . 12 4 5 3Poisson ( λ)½⅔ ⅓ 1 ½ Figure 16.10. An acyclic network of servers. Burke’s theorem (Theorem 16.5) can be applied to ﬁnd the limiting probabilities here in the same way as we applied Burke’s theorem to the tandem system. By part (1) of Burke’s theorem, we see that, for each server, the arrival process into the server is a (merged and/or split) Poisson process. So each server, in isolation, can be viewed as an M/M/1 queue. Using part (2) of Burke’s theorem and the same argumentas for tandem queues, we can show that the numbers of jobs at the different servers areindependent. Thus, assuming kservers we have πn1,n2,...,n k=P{n1jobs at server 1 }·P{n2jobs at server 2 }···P{nkjobs at server k} =ρn1 1(1−ρ1)·ρn2 2(1−ρ2)···ρnk k(1−ρk). Question: What is P{N1=n1}in such an acyclic network with kservers?",1301
16.8 Exercises,"294 time-reversibility and burke’s theorem Answer: P{N1=n1}=/summationdisplay n2,n3,...,n kπn1,n2,...,n k =/summationdisplay n2,n3,...,n kρn1 1(1−ρ1)ρn2 2(1−ρ2)···ρnk k(1−ρk) =ρn1 1(1−ρ1). 16.7 Readings With respect to the sections on the reverse chain and on time-reversibility, we highly recommend the following readings: [ 149] (Ch. 5, Section 6), and [ 18] (pp. 214–21). Burke’s theorem was originally presented in [ 34]. 16.8 Exercises 16.1 Practice with Finite-State Chains: Closed System Performance For the closed interactive network in Figure 16.11 , there are N=3 users, think time is Z∼Exp(λ=1 ) , service time is S∼Exp(μ=2 ) , and routing probabilities are as shown. For this network compute N = 3 ½ ½ Figure 16.11. Closed queueing network from Exercise 16.1. (a) the exact throughput, X. (b) the exact mean response time, E[R], not including think time. (c) the asymptotic throughput for high Nusing operational analysis from Chapter 7. 16.2 More Closed System Performance For the closed interactive network in Figure 16.12 , there are N=4 users, think time is Z∼Exp(λ=2 ) , service time is S∼Exp(μ=4 ) , and routing probabilities are as shown.(a) Use operational laws to approximate throughput, X. (b) Derive the exact throughput, X. (c) Derive the exact mean response time, E[R], not including think time. (d) What is the mean number of users that are thinking? 16.8 exercises 295 N = 4 ¼ ¾ Figure 16.12. Closed queueing network from Exercise 16.2. 16.3 Chip Manufacturing Plant At a chip manufacturing plant, wafers arrive according to a Poisson process with rate λ=1. The wafers pass through three stations: a photoresist coating station, a circuit imprinting station, and an alkaline rinse station. Each station consists of two identical workers serving a single queue, as shown in Fig-ure16.13 . For the purpose of this problem, assume that all service times are Exponentially distributed and that the service rate at station iisμi=i,f o ri= 1,2,3. Derive the mean time from when a wafer arrives until a chip is created. Poisson ( λ)μ1 μ1Coatin g station μ2 μ2Circ uit imprintin g station μ3 μ3Rinse station Figure 16.13. Sequence of M/M/2 stations in chip manufacturing. 16.4 Application of Square-Root Stafﬁng to Chip Manufacturing Figure 16.14 shows the 3 stations that wafers pass through in a chip man- ufacturing plant: a photoresist coating station, a circuit imprinting station, and an alkaline rinse station. Assume that all service times are Exponentially μ1Poisson ( λ) μ1μ1 μ2μ2μ2 μ3μ3μ3Coating station Circuit Imprinting station Rinse station Figure 16.14. Sequence of stations in chip manufacturing. 296 time-reversibility and burke’s theorem distributed with rates shown, where μi=i. Assume that wafers arrive ac- cording to a Poisson process with rate λ=10,000 wafers per second. Use the square-root stafﬁng rule from Chapter 15 to determine the minimum numberof servers, k∗, needed at each station such that at every station fewer than 20 percent of wafers experience any delay. 16.5 Alternative Views of Time-Reversibility Time-reversible chains have many beautiful properties. In this problem youwill prove two of these. (a) Prove that for any time-reversible CTMC, for any ﬁnite subset of states, S, the product of the transition rates along any cycle involving states in S equals the product of the transition rates along the same cycle in reverse order. Speciﬁcally, for any states j1,j2,...,j n∈S: qj1,j2·qj2,j3·qj3,j4···qjn−1,jn·qjn,j1 =qj1,jn·qjn,jn−1·qjn−1,jn−2···qj2,j1. (b) Prove that for a time-reversible CTMC, the rate of traversing any path equals the rate of traversing the same path in the reverse direction. Specif-ically, for any state jand any states j1,j2,...,j n∈S: πj·qj,jn·qjn,jn−1·qjn−1,jn−2···qj2,j1 =πj1·qj1,j2·qj2,j3···qjn−1,jn·qjn,j. [Hint: Part (a) may be useful in proving this.] 16.6 Burke’s Theorem for Finite Queues? Consider the M/M/1/k single-server queue with ﬁnite capacity of k. (a) Is this Markov chain time-reversible? (b) Can we apply the proof of Burke’s theorem to say that the departure process is a Poisson process? Explain.",4106
Chapter 17 Networks of Queues and Jackson Product Form. 17.2 The Arrival Process into Each Server,"CHAPTER 17 Networks of Queues and Jackson Product Form We are now ready to consider a very general architecture called the “network of queues.” This architecture allows for any number of servers, each with its own (unbounded)queue, and probabilistic routing between the servers. The architecture allows for cyclesin the network and is very useful in modeling packet-routing computer networks ornetworks of manufacturing stations. In this chapter, we consider the simplest such network of queues, called the Jackson network. In later chapters, we consider fancier versions. For example, in Chapter 18, the routing probabilities are allowed to depend on the “class” of the packets, which makes it even more applicable to packet-routing in the Internet. The point of this chapter is toprove the Jackson Product Form theorem, which provides us with an immediate simple closed-form solution for the limiting probabilities of any Jackson network. 17.1 Jackson Network Deﬁnition A Jackson network is a very general form of queueing network. In a Jackson network, there are kservers, each with its own (unbounded) queue. Jobs at a server are served in FCFS order. The ith server has service rate Exp (μi). Each server may receive arrivals from inside andoutside the network. The arrivals into the ith server from outside the network constitute a Poisson process with rate ri. The routing of jobs is proba- bilistic. Speciﬁcally, every job that completes at server iwill be transferred to server jwith probability Pij, or will exit the system with probability Pi,out=1−/summationtext jPij. Figure 17.1 shows the general setup of a Jackson network. Poisson ( ri)Server i Server kServer j Poisson ( rj) Poisson ( rk)PijPj,out Pi,outPjk PkiPik Figure 17.1. A simple Jackson network. 297 298 networks of queues and jackson product form The response time of a job is deﬁned as the time from when the job arrives to the network until it leaves the network, including possibly visiting the same server or different servers multiple times. For each server i, we denote the total arrival rate into server ibyλi. Question: What is the total rate at which jobs leave server j? Answer: λjis both the total rate at which jobs enter server jand at which they leave server j. Question: What is the total rate at which jobs leave server j, going to server i? Answer: λjPji. The total arrival rate into server iis the sum of the outside arrival rate (rate of jobs arriving to server ifrom outside the network) and the inside arrival rate (rate of jobs arriving to server ifrom inside the network): λi/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright total arrival= ri/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright outside arrival+/summationdisplay jλjPji /bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright internal transition. (17.1) We can solve these simultaneous equations to obtain all the λi’s. Equivalently, we can write λi(1−Pii)/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright total arrival= ri/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright outside arrival+/summationdisplay j/negationslash=iλjPji /bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright internal transition(17.2) where ( 17.2) is identical to ( 17.1), except that on both sides we are not including transitions from server iback to server i. Note: Be careful not to confuse servers with states. Right now we are only talking about servers. 17.2 The Arrival Process into Each Server At this point we see how to compute λi, the total arrival rate into server i. If we knew that the arrival process into each server was a Poisson process, then we could view each server as an M/M/1 queue and determine the distribution of the number of jobs at that server. This is the approach that we followed in the last chapter for acyclic networks. Question: For acyclic networks, we saw that the arrival process into each server is a Poisson process. Can we still say that the arrival process into each server is a Poisson process if the network is not acyclic? 17.2 the arrival process into each server 299 More speciﬁcally, consider the network in Figure 17.2. Here the output of a server feeds back into the same server. Is the arrival process into the server in Figure 17.2 a Poisson process? p 1–p Poisson ( λ) Figure 17.2. Network with feedback. Answer: At ﬁrst one might think the answer is yes. Here is the WRONG argument: We start with an M/M/1 with Poisson arrivals of rate λ. The departures of an M/M/1 are also a Poisson process of rate λby Burke’s theorem. Some fraction, 1−pof those departures leaves, and the remaining fraction, p, gets fed back. This portion that gets fed back is also a Poisson process (by Poisson splitting) of rate λp. This gets merged with the outside arrival process, which is a Poisson process, and we know that the merge of two Poisson processes is still a Poisson process. Hence the total arrival process into the queue is a Poisson process. Unfortunately, the above answer is wrong. To see this, consider the network in Figure 17.3. 0.99 Poisson ( λ: very low) 0.01μ fast Figure 17.3. Illustrating why we do not see Poisson arrivals. Suppose that the arrival rate, λ, is very low, so that the time between arrivals is typically very high. Now suppose there is an arrival at the server at time t. Then with high probability there will be another arrival to the server shortly. That is, it is much more likely that there is an arrival during (t, t+/epsilon1)than during some other /epsilon1-interval. Thus the arrival process into server idoes not have independent increments. So it is not a Poisson process. Question: What was wrong with the argument that said we were merging two Poisson processes and therefore should get a Poisson process? Answer: The two Poisson processes that we were merging were not independent Poisson processes; therefore their merge was not a Poisson process. Because the arrival process into this server is not a Poisson process, we cannot use the simpliﬁcations we used for solving tandem queues, where each server becomes anindependent M/M/1.",6174
17.4 The Local Balance Approach,"300 networks of queues and jackson product form 17.3 Solving the Jackson Network So let’s go back to modeling the network with a CTMC and trying to solve the balance equations. The states of the network can be deﬁned as a set of k-tuples (n1,n2,...,n k), in which the jth element in the tuple represents the number of jobs at server j(including both the queue and the server). We need to write the balance equation for each state. Remember the balance equation for each state is Rate of jobs leaving the state =Rate entering the state. Suppose the system is in state (n1,n2,...,n k). To simplify the writing of balance equations, we will assume throughout the chapter that ni>0,∀i. The case where some states have 0jobs is left as an exercise. The CTMC leaves state (n1,n2,...,n k)when there is either (i) an outside arrival, or (ii) a service completion at any of the servers. Observe that both of these events happenwith Exponential rates. The rate of transitions leaving the state (n1,n2,...,n k)(and not returning to the state) is πn1,n2,...,n k·/bracketleftBiggk/summationdisplay i=1ri+k/summationdisplay i=1μi(1−Pii.)/bracketrightBigg . Now consider the rate at which the CTMC enters the state (n1,n2,...,n k)(from some other state). State (n1,n2,...,n k)is entered at moments where (i) there is an outside arrival, or (ii) there is a departure to outside, or (iii) there is an internal transition. Againthese are Exponential rates. The rate of transitions entering the state is k/summationdisplay i=1πn1,...,n i−1,...,n k·ri /bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright outside arrival+k/summationdisplay i=1πn1,...,n i+1,...,n k·μiPi,out /bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright departure to outside +k/summationdisplay i=1/summationdisplay j/negationslash=iπn1,...,n i−1,...,n j+1,...,n k·μjPji /bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright internal transition from server jto server i,j/negationslash=i. Therefore the balance equation for state (n1,...,n k)is πn1,n2,...,n k·/bracketleftBiggk/summationdisplay i=1ri+k/summationdisplay i=1μi(1−Pii)/bracketrightBigg =k/summationdisplay i=1πn1,...,n i−1,...,n k·ri+k/summationdisplay i=1πn1,...,n i+1,...,n k·μiPi,out +k/summationdisplay i=1/summationdisplay j/negationslash=iπn1,...,n i−1,...,n j+1,...,n k·μjPji.. (17.3) 17.4 the local balance approach 301 Of course ( 17.3) is the balance equation for just one particular state, (n1,...,n k).W e need to write out the balance equation for each state. Question: Why are there no λi’s in the balance equation? Answer: Theevents that change the state are only arrivals or service completions, all of which are Exponentially distributed. The λi’s are not events; they denote average rates at which packets arrive and are thus used when discussing the network of servers , not the Markov chain with states. Making a guess as to the limiting probabilities based on these complicated balance equations is impossible. Furthermore, it is going to get a lot messier in the next chapterwhen we move on to classed networks, where routing probabilities depend on class.",3151
17.4 The Local Balance Approach,"17.4 The Local Balance Approach We need an approach to simplify the huge number of balance equations. Many popular books (e.g., [ 18,149,150]) at this point go into the “reverse chain argument.” They try to guess what the reverse chain looks like and then use the limiting probabilities for the reverse chain. We do not want to take this approach because it is long and unintuitive, and how in the world can you start picturing what the reverse chain looks like whenthe forwards process is so complicated already? Instead we are going to take a different approach based on the idea of local balance . This idea is not precisely deﬁned and is just part of the “bag of tricks” that queueing theorists use. Although local balance is brieﬂy mentioned in several texts (e.g., [ 151]), there is typically no algorithm provided for how to set up the local balance equations. That part is the “art,” which is learned through trial and error. In the next few chapters,we will repeatedly show one particular way of using local balance that has worked very well for us when analyzing complex networks of queues. The idea is to break down the left-hand side and right-hand side of the balance equation (17.3) into k+1 matching components. If we can ﬁnd a solution that maintains the equality for each matching component (local balance), then we know that it is a solution to the equation as a whole (global balance). Observe that satisfying local balance is a stronger condition than satisfying global balance. Because the local balance equations are so much simpler looking, it will be much easier to make a guess based on theseequations and also to “check” that a guess satisﬁes these equations. Figure 17.4 shows the way to break down a balance equation into k+1distinct components. It is very important that you do it in exactly this way . There are many other ways of subdividing a balance equation that do not satisfy the local balance. We want to ﬁnd a solution that makes A=A/primeandBi=B/prime itrue for all 1≤i≤k.H e r e Adenotes the rate of leaving state (n1,n2,...,n k)due to an outside arrival coming into the network. Here Bidenotes the rate of leaving state (n1,n2,...,n k)due to a departure from server i. This departure may either go to some other server j/negationslash=ior may leave the network. Likewise A/primedenotes the rate of entering state (n1,n2,...,n k) 302 networks of queues and jackson product form A B BkRate leavin g (n1, n2, ..., n k)Due to outside arrival Due to  a depart ure  from...B1 server 1 B2 server 2 server kA B BkRate′ enterin g (n1, n2, ..., n k)Due to outside depart ure Due to  an arrival at...B1 server 1 B2 server 2 server k= = = =′ ′′ ′ Figure 17.4. Local balance decomposition approach. due to a job departing to outside the network. B/prime idenotes the rate of entering state (n1,n2,...,n k)due to an arrival at server i, where this arrival may either be coming from outside the network, or from another server j/negationslash=i. At this point we are not even sure whether a solution satisfying local balance exists. If we are lucky enough to ﬁnd a solution that satisﬁes all the local balanceequations, then we have global balance as well.",3182
17.4 The Local Balance Approach,"First we try to solve A=A/prime. To show A=A/prime, we need to show that k/summationdisplay i=1πn1,...,n i,...,n kri=k/summationdisplay i=1πn1,...,n i+1,...,n kμiPi,out. We need to make a guess for πn1,...,n kand show that it satisﬁes this A=A/primeequation. Here is how we come to our guess: Observe that the πn1,...,n i,...,n kterm in Aand the πn1,...,n i+1,...,n kterm in A/primeonly differ in the nispot. Let’s suppose that πn1,...,n i,...,n k·ci=πn1,...,n i+1,...,n k, where ciis some constant depending on i. Then rewriting the A=A/primeequation, we have k/summationdisplay i=1πn1,...,n i,...,n kri=k/summationdisplay i=1πn1,...,n i+1,...,n kμiPi,out. k/summationdisplay i=1πn1,...,n i,...,n kri=k/summationdisplay i=1πn1,...,n k·ci·μiPi,out. k/summationdisplay i=1ri=k/summationdisplay i=1(ci·μi)Pi,out. (17.4) 17.4 the local balance approach 303 Question: Can you ﬁgure out what we would like cito be? Answer: Observe that if (ci·μi)=λi, then ( 17.4) is true because it would then say that k/summationdisplay i=1ri=k/summationdisplay i=1λiPi,out, which simply says that the total rate of jobs entering the system from outside is the same as the total rate of jobs leaving the system (to go outside). This is obviously truein steady state. Thus in our earlier guess, we want ci=λi μi=ρi. Let’s return to the process of making a guess for πn1,...,n k. We know that to satisfy A=A/primewe would like to have πn1,...,n i,...,n k·ρi=πn1,...,n i+1,...,n k,∀i. Thus it seems a reasonable guess is that πn1,...,n i,...,n k=Cρn1 1...ρnk k, where Cis the usual normalizing constant. Now we try to solve for Bi=B/prime i.H e r e Biis the rate of transitions leaving state (n1,...,n k)due to a departure from server i(not back to i), namely, Bi=πn1,...,n k·μi(1−Pii). B/prime iis the rate of transitions entering (n1,...,n k)due to an arrival at server i. This includes outside arrivals into server ior internal arrivals from other servers. Therefore the expression for B/prime iis B/prime i=/summationdisplay js.t.j/negationslash=iπn1,...,n i−1,...,n j+1,...,n k·μjPji /bracehtipupleft /bracehtipdownright/bracehtipdownleft /bracehtipupright internal transition from server jto server i(j/negationslash=i)+πn1,...,n i−1,...,n k·ri/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright outside arrival. Let’s use our previous guess for πn1,...,n kand check if it satisﬁes Bi=B/prime i. Let πn1,...,n i,...,n k=Cρn1 1ρn2 2...ρnk k. 304 networks of queues and jackson product form Now check that Bi=B/prime i Cρn1 1ρn2 2···ρnk kμi(1−Pii)=/summationdisplay j/negationslash=iCρn1 1ρn2 2···ρnk k/parenleftbiggρj ρi/parenrightbigg μjPji +Cρn1 1ρn2 2...ρnk k/parenleftbigg1 ρi/parenrightbigg ri μi(1−Pii)=/summationdisplay j/negationslash=iρjμj ρiPji+ri ρi ρiμi(1−Pii)=/summationdisplay j/negationslash=iρjμjPji+ri λi(1−Pii)=/summationdisplay j/negationslash=iλjPji+ri. (17.5) Question: Is Equation ( 17.5) true? Answer: Yes, of course, this is exactly equation ( 17.2), the equation deﬁning the outside arrival rates.",3023
17.4 The Local Balance Approach,"So our guess for πn1,...,n kalso satisﬁes Bi=B/prime i. Lastly, we need to ﬁnd the normalizing constant C: /summationdisplay n1,...,n kπn1,...,n k=1 C/summationdisplay n1,...,n kρn1 1···ρnk k=1 C/summationdisplay n1ρn1 1/summationdisplay n2ρn2 2···/summationdisplay nkρnk k=1 C/parenleftbigg1 1−ρ1/parenrightbigg/parenleftbigg1 1−ρ2/parenrightbigg ···/parenleftbigg1 1−ρk/parenrightbigg =1 Hence, C=( 1−ρ1)( 1−ρ2)···(1−ρk). As a result, πn1,...,n k=ρn1 1(1−ρ1)ρn2 2(1−ρ2)···ρnk k(1−ρk). (17.6) This is an example of a product form solution for the limiting probabilities. Question: What does the previous expression tell us about the distribution of the number of jobs at server 1? 17.4 the local balance approach 305 Answer: P{n1jobs at server 1}=/summationdisplay n2,...,n kπn1,...,n k =/summationdisplay n2,...,n kρn1 1(1−ρ1)ρn2 2(1−ρ2)...ρnk k(1−ρk)=ρn1 1(1−ρ1). Likewise, P{nijobs at server i}=ρni i(1−ρi). That means all servers still behave like M/M/1 queues in terms of their stationary queue length distributions. This is really surprising because the arrival process into eachserver is notusually a Poisson process. Furthermore, by ( 17.6), the number of jobs at the different queues is independent . Speciﬁcally, we have now proven Theorem 17.1. Theorem 17.1 A Jackson network with kservers has product form, namely, P/braceleftbigg State of network is(n1,n2,...,n k)/bracerightbigg =k/productdisplay i=1P{nijobs at server i}=k/productdisplay i=1ρni i(1−ρi). Warning: So far, we have only proven product form for networks of queues that ﬁt the Jackson model; that is, there is a probabilistic routing between servers, the outsidearrivals are Poisson, the service times are Exponentially distributed, and jobs are served in FCFS order at each server. Example: Web Server Consider a web server that receives requests for ﬁles according to a Poisson arrival process, as shown in Figure 17.5. Each request requires alternating between the CPU and I/O some Geometrically distributed number of times as the ﬁle is segmented intopackets and sent to the network. CPU I/OPoisson ( λ) p 1–pμ1 μ2 Figure 17.5. Example of a web server. Question: What is πn1,n2for Figure 17.5? Answer: The system is a Jackson network. We ﬁrst solve for λ1andλ2: λ1=λ+λ2 λ2=( 1−p)λ1",2263
17.5 Readings. 17.6 Exercises,"306 networks of queues and jackson product form Hence λ1=λ pandλ2=λ p(1−p). Thus, ρ1=λ1 μ1=λ pμ1. ρ2=λ2 μ2=λ(1−p) pμ2. We can now substitute these values into πn1,n2=ρn1 1ρn2 2(1−ρ1)(1−ρ2). Question: What is the average number of jobs in the system, E[N]? Answer: P{n1jobs at server 1}=ρn1 1(1−ρ1). P{n2jobs at server 2}=ρn2 2(1−ρ2). E[N1]=ρ1 1−ρ1,E[N2]=ρ2 1−ρ2,E[N]=E[N1]+E[N2]. 17.5 Readings Jackson networks and their product form solution were introduced in [ 102]. This paper was printed in Management Science’s “Ten Most Inﬂuential Titles of Management Science’s First Fifty Years.” 17.6 Exercises 17.1 Practice Analyzing Jackson Networks Figure 17.6 shows a queueing network with three FCFS servers. All servers have Exponentially distributed service times with rates as shown. Outside arrivals occur according to a Poisson process with rate λ=1packets/sec. The edges of the network indicate routing probabilities (assume 1 if none shown). What is the mean response time, E[T]? Poisson ( λ=1) μ1=3 μ2=5μ3=6 0.250.75Server 2Server 3 Server 1 Figure 17.6. Queueing network from Exercise 17.1. 17.2 More Practice Analyzing Jackson Networks A packet-switched Jackson network routes packets among two routers accord-ing to the routing probabilities shown in Figure 17.7. Notice that there are two 17.6 exercises 307 points at which packets enter the network and two points at which they can depart. Poisson ( r1) Poisson ( r2=1)μ1=3 μ2=5 Figure 17.7. Jackson network from Exercise 17.2. (a) What is the maximum allowable rate r1that the network can tolerate? Call thisrmax 1. (b) Set r1=0.9rmax 1. What is the mean response time for a packet entering at the router 1 queue? 17.3 Queue with Feedback Figure 17.8 shows a simple queueing network. Jobs arrive according to a Poisson process with rate λ. When a job completes service, the job goes back into the queue with probability pand leaves the system with probability 1−p. Thus a single job may serve multiple times before leaving the system. Eachtime the job serves, its service time is a new Exponentially distributed random variable with rate μ. p 1–p Poisson ( λ) Figure 17.8. Network with feedback from Exercise 17.3. Your goal is to derive the mean response time for a job in up to four different ways. A job’s response time is the time from when the job ﬁrst arrives until itﬁnally leaves, including possibly multiple visits to the queue. (1) To start, use the theory of Jackson networks from this chapter to derive an expression for the mean response time in terms of λ,μ, andp. (2) Now again derive the mean response time, but this time do it by solving a CTMC that tracks the number of jobs in the system (draw only transitions thatchange the state). (3) Tinglong makes the following suggestion: Why not view the whole network as a single M/M/1 where the arrival rate is ˆλ=λ 1−pand the service rate isμ. Does Tinglong’s solution result in the correct mean response time? Why or why not? (4) Runting makes a different suggestion: Let E[Tvisit]be the mean response time experienced by jobs during one visit to the server (including queue- ing plus service time). Then E[T]=E[Tvisit]·E[Number visits ]. Does Runting’s suggestion work? Why or why not? 308 networks of queues and jackson product form 17.4 Network with Feedback For the Jackson network in Figure 17.9, assume that 0<p<q< 1and assume that ris chosen so as to not overload the network. Answer the following questions: p  1–pq  1–q Poisson ( r) µµ Figure 17.9. Network for Exercise 17.4. (a) Determine the mean response time, E[T], as a function of r,μ,p, andq. (b) If we interchange the order of the queues (i.e., the pandqare ﬂipped), doesE[T]increase, decrease, or stay the same? 17.5 Supercomputing Center (This result was originally proved in [ 7].) In a supercomputing center, arriving jobs are parallel, typically running on several servers at once, as shown in Figure 17.10 . Consider a supercomputing center with kservers and no waiting room, where outside arrivals occur according to a Poisson process with rate λ (think M/M/k/k). Assume that with probability pian arriving job is of “type i,” which means that the job requires iservers simultaneously. If there are fewer thaniservers free, the type ijob is dropped. Otherwise the type ijob grabs the iservers that it needs and holds these for Exp (μi)time, after which it releases alliservers at once. Poisson ( λ) Service time ~ Exp ( μ3)Service time ~ Exp ( μ2) Service time ~ Exp ( μ2) Figure 17.10. Supercomputing center with two jobs of type 2 and one job of type 3. Let(n1,n2,...,n k)be the state of the system, where niis the number of jobs of type i. Prove that πn1,n2,...,n k=k/productdisplay i=1ρni i ni.·C, where ρi=λi μiandλi=λpiandCis a normalizing constant. 17.6 exercises 309 17.6 Cloud Service Center (This result was originally proved in [ 187].) A cloud service center consists of two server farms. The ﬁrst server farm has CPU-powerful servers, and the second has I/O-powerful servers. Each incoming request (job) to the cloudservice center asks for some number of CPU servers, i, and some number of I/O servers, j. Requests occur according to a Poisson process with rate λ, where a request is of type (i, j)with probability pij. If there are fewer than i free CPU servers or fewer than jfree I/O servers, then a request of type (i,j) will be dropped. Otherwise, the request will grab all its requested servers and will hold these for time Exp (μij), after which it will release all the servers at once. This is illustrated in Figure 17.11 . Poisson ( λ)CPU farmJob 1 Service time ~ Exp ( μ23) Job 2 Service time ~ Exp ( μ32) Job 3 Service time ~ Exp ( μ21) I/O farm Figure 17.11. Cloud service center where three requests are being satisﬁed. Let(n11,n12,...,n 1k,n21,n22,...,n 2k,...,n k1,nk2,...,n kk)denote the state of the system, where nijis the number of jobs of type (i, j)in the system. 310 networks of queues and jackson product form Prove that πn11,n12,n13,...,n kk=k/productdisplay i=1k/productdisplay j=1ρnij ij nij.·C, where ρij=λij μijandλij=λpijandCis a normalizing constant.",6093
Chapter 18 Classed Network of Queues. 18.1 Overview. 18.2 Motivation for Classed Networks,"CHAPTER 18 Classed Network of Queues 18.1 Overview Throughout this chapter, when talking about a queueing network, we will use the vector, (n1,n2,...,n k), to denote that there are n1jobs at server 1 and n2jobs at server 2 and so on. In the previous chapter, we saw that Jackson networks exhibit the “product form”property: P/braceleftbigg Distribution of jobs is (n1,n2,...,n k)/bracerightbigg =k/productdisplay i=1P{nijobs at server i}=k/productdisplay i=1ρni i(1−ρi) The ﬁrst equality represents the fact that the queues behave in an independent fashion. The second equality says that we can consider all the queues to behave as independentM/M/1 queues from a performance standpoint (although the arrival stream into each server is not actually Poisson). In the next several chapters, as well as in the exercises at the end of this chapter, we will generalize the Jackson result to a much broader class of networks that exhibit product form. For example, we ﬁnd in Chapter 19that product form holds for closed Jackson networks as well as open Jackson networks (for closed networks, the product form requires a normalizing constant). We also ﬁnd in that chapter’s exercises that productform holds for Jackson-type networks where the service rate is allowed to depend onthe number of jobs at the server; see Exercise 19.3. These are called load-dependent servers. In particular, each server could be an M/M/k station. We furthermore ﬁnd thatwe can allow the routing probabilities, Pij, (here i,jare servers, not states) to depend not just on i, jbut also on the “class” of the packet or job. Such networks are called classed networks and are the topic of the current chapter. Finally, in Chapter 22,w e prove product form results for networks of queues where the scheduling policy at the queues is no longer FCFS. Throughout, we use the method of local balance. 18.2 Motivation for Classed Networks We provide three examples motivating the need for classed networks. 311 312 classed network of queues Motivating Example 1: Connection-Oriented Networks Consider a network where each packet follows a particular route based on its type. A packet’s type might, for example, be the concatenation of its source IP address andits destination IP address. For example, in the network shown in Figure 18.1 and the routes shown in Figure 18.2, type 1 packets always follow “route 1,” meaning that they go to server 1, then server 2, then server 3. Type 2 packets always follow “route 2,” meaning that they ﬁrst go to server 3, then to server 2, then to server 4, then to server 5. 23 1 5Poisson ( r1)Poisson ( r3) 4 Figure 18.1. The network. Assume we know the average outside arrival rate of packets along each route. A typical goal in such an example might be to determine E[T]for packets on route 2. Route 1: Route 2:2 1 3 2 3 5 4 Figure 18.2. The routes. Question: Why can’t we model this network as a Jackson network? Answer: The probability of going from server 2 to server 3 depends on the route. If the packet is of type 1, then the packet leaving server 2 always goes to server 3. However, if the packet is of type 2, then the packet leaving server 2 never goes to server 3. So we would like the routing probability to be able to depend on the type of the packet. Motivating Example 2: CPU-Bound and I/O-Bound Jobs Consider a computer system with two different workloads. Suppose that I/O-bound jobs have a high probability of visiting the I/O device and a low probability of visiting 18.2 motivation for classed networks 313 the CPU. In contrast, CPU-bound jobs have a high probability of visiting the CPU and a low probability of visiting the I/O device. Poisson ( r1) Poisson ( r2)CPU I/O We need different routing probabilities for the CPU-bound and I/O-bound jobs. Motivating Example 3: Service Facility with Repair Center Jobs repeatedly visit some service facility. After each visit, with low probability the job needs to go to the repair center. If a job ever visits the repair center, it gets repaired andreturns to the service facility; however, from then onward, there is a high probabilitythat this job will have to go to the repair center again. Poisson ( r)Service Facility Repair Center So again we want the routing probability to depend on the “type” of job. We would like to differentiate between two types of jobs: “good” and “bad.” Good jobs have nevervisited the repair center, whereas bad jobs have visited the repair center. Question: What else do we need? Answer: We need to be able to change a job’s type from “good” to “bad” once it visits the repair center. Summary In general, we would like our model to accommodate the following: 1.The outside arrival rate at server i,ri(c), should depend on the job class c. 2.The routing probabilities for moving from server ito server jshould be allowed to depend on the job class c. 3.Jobs should be allowed to change classes after service.",4906
18.4 A Single-Server Classed Network,"314 classed network of queues To accommodate items (2.) and (3.), we use P(c1)(c2) ij to denote the probability that a job of class c1at server inext moves to server jand changes class to c2. 18.3 Notation and Modeling for Classed Jackson Networks In this section we deﬁne classed Jackson networks . We assume an open queueing network with kservers and /lscriptclasses of packets. We deﬁne the following quantities: ri=arrival rate to server ifrom outside the network ri(c)=arrival rate of class cjobs to server ifrom outside the network λi=total arrival rate to server i,from both inside and outside =total departure rate from server i λi(c)=total arrival rate of class cjobs to server i =total departure rate of class cjobs from server i P(c)(c/prime) ij =probability that job at server iof class cnext moves to server jand becomes a class c/primejob μi=service rate at server i ρi=λi μi=utilization at server i c(j) i=the class of the jth job in the queue at server i Observe that ri=/lscript/summationdisplay c=1ri(c). λi=/lscript/summationdisplay c=1λi(c). Remark: It is important to note that, although the class of a packet determines the routing probability, it does not determine the service rate at a server. The service rate at server iis assumed to be μifor all packets. Although this is a drawback of the classed Jackson model, it is not as limiting as it may seem in that the routing probability canbe used to force a certain class of packets to visit a server multiple times on average,thereby in effect creating a greater “service demand” at the server for that class. Typically, we are given the outside arrival rates, ri(c), the per-class routing probabili- ties,P(c)(c/prime) ij , and the service rates, μi, for all i,j,c,c/prime, and we are asked to determine some metric like E[Ni], the mean number of jobs at server i. Question: Can we solve for λj, the total arrival rate into server j, directly? Answer: No. Here is an attempt: λj=rj+k/summationdisplay i=1λiPij, butPijis not deﬁned. 18.4 a single-server classed network 315 However, we can compute λj(c), the arrival rate of class cjobs into server j.I ti s determined by solving the following system of simultaneous equations: λj(c)=rj(c)+k/summationdisplay i=1/lscript/summationdisplay c/prime=1λi(c/prime)P(c/prime)(c) ij (18.1) Then we get λjby summing the per-class rates as follows: λj=/lscript/summationdisplay c=1λj(c) Question: We need to be able to derive limiting probabilities. What should the “states” of the CTMC look like? Hint: What’s wrong with using (n1,n2,...,n k)where nidenotes the number of jobs at server i? Answer: This is not detailed enough information for our CTMC because, to know the probability of moving between states, we need to at least know the class of the job at the head of the queue at each server. We deﬁne the state of the network to be z=(z1,z2,...,z k), where ziis the state of server i. Speciﬁcally, zi=/parenleftBig c(1) i,c(2)i,...,c(ni) i/parenrightBig , where nidenotes the number of packets at server i, andc(1) idenotes the class of the 1st job at server i(the one serving), c(2) idenotes the class of the 2nd job at server i, andc(ni) idenotes the class of the last job queued at server i. Thus, z=(z1,z2,...,z k) =/parenleftBig/parenleftBig c(1) 1,c(2)1,...,c(n1) 1/parenrightBig ,/parenleftBig c(1)2,c(2)2,...,c(n2) 2/parenrightBig ,...,/parenleftBig c(1) k,c(2)k,...,c(nk) k/parenrightBig/parenrightBig . 18.4 A Single-Server Classed Network To get a feel for classed networks, let’s start by considering the case where the whole network consists of just a single server, say server 1. Server 1 represents a classedM/M/1 queue with /lscriptclasses of jobs (see Figure 18.3). Class cpackets arrive with rateλ1(c), and we use λ1to denote the total arrival rate from all classes into server 1; that is, λ1=/summationtext cλ1(c). All packets are served with rate μ1. The class has no effect in this simple example, because all packets leave after serving (i.e., there is no routing). 316 classed network of queues Poisson ( λ1(2)) Poisson ( λ1())Poisson ( λ1(1)) μ1 Figure 18.3. Single-server classed network. We are interested in the limiting probability that the state of the system is (c(1) 1,c(2)1,...,c(n1) 1); that is, the probability that there are n1jobs in the system and that their classes (in order from head to tail) are c(1)1,c(2)1,...,c(n1) 1, respectively. Here c(i) 1denotes the class of the ith job queued at server 1. Question: Can you guess what the limiting probability π(c(1) 1,c(2)1,...,c(n1) 1)looks like? Answer: We know that the limiting probability must be related to the limiting prob- ability that there are n1jobs in the system, which is ρn1 1(1−ρ1), where ρ1=λ1 μ1. However, we also know that we need to include the particular classes of the jobs. Thus it seems plausible that π(c(1) 1,c(2)1,...,c(n1) 1)=λ1/parenleftBig c(1) 1/parenrightBig λ1/parenleftBig c(2)1/parenrightBig ···λ1/parenleftBig c(n1) 1/parenrightBig μn1 1·(1−ρ1).(18.2) Observe that, under the conjecture in ( 18.2), P{n1jobs at server } =/lscript/summationdisplay c(1) 1=1/lscript/summationdisplay c(2)1=1···/lscript/summationdisplay c(n1) 1=1π(c(1) 1,c(2)1,...,c(n1) 1) =/lscript/summationdisplay c(1)1=1/lscript/summationdisplay c(2)1=1···/lscript/summationdisplay c(n1) 1=1λ1/parenleftBig c(1) 1/parenrightBig λ1/parenleftBig c(2)1/parenrightBig ···λ1/parenleftBig c(n1) 1/parenrightBig μn1 1·(1−ρ1) =( 1−ρ1)/lscript/summationdisplay c(1) 1=1λ1/parenleftBig c(1) 1/parenrightBig μ1·/lscript/summationdisplay c(2) 1=1λ1/parenleftBig c(2) 1/parenrightBig μ1···/lscript/summationdisplay c(n1) 1=1λ1/parenleftBig c(n1) 1/parenrightBig μ1 =λn1 1 μn1 1(1−ρ1) =ρn1 1(1−ρ1) as desired. We now prove that the guess in ( 18.2) satisﬁes the balance equations. We equate the rate that we leave the state/parenleftBig c(1) 1,c(2)1,...,c(n1) 1/parenrightBig with the rate that we enter the state/parenleftBig c(1)1,c(2)1,...,c(n1) 1/parenrightBig . Leaving the state happens when we are in the state/parenleftBig c(1)1,c(2)1,...,c(n1) 1/parenrightBig and have either an arrival or a departure. Entering the state",6126
18.5 Product Form Theorems,"18.5 product form theorems 317 occurs in one of two ways: Either we are in state/parenleftBig c(1) 1,c(2)1,...,c(n1−1) 1/parenrightBig and we have an arrival of class c(n1) 1, which joins the end of the queue, orwe are in state/parenleftBig c,c(1)1,c(2)1,...,c(n1) 1/parenrightBig , where the job at the head of the queue is of class c, and we have a departure, so the job of class cleaves: Rate Leave =Rate Enter π(c(1) 1,c(2)1,...,c(n1) 1)(μ1+λ1)=π(c(1)1,c(2)1,...,c(n1−1) 1)λ1/parenleftBig c(n1) 1/parenrightBig +/summationdisplay cπ(c,c(1) 1,c(2)1,...,c(n1) 1)μ1 Substituting in our “guess” from ( 18.2), we note that, for example, π(c,c(1)1,c(2)1,...,c(n1) 1)=λ1(c) μ1π(c(1)1,c(2)1,...,c(n1) 1), allowing us to reduce the rates of entering and leaving as follows: Rate Leave =Rate Enter π(c(1)1,c(2)1,...,c(n1) 1)(μ1+λ1)=π(c(1)1,c(2)1,...,c(n1−1) 1)λ1/parenleftBig c(n) 1/parenrightBig +/summationdisplay cπ(c,c(1)1,c(2)1,...,c(n1) 1)μ1 π(c(1)1,c(2)1,...,c(n1) 1)(μ1+λ1)=μ1 λ1/parenleftBig c(n1) 1/parenrightBig·π(c(1)1,c(2)1,...,c(n1) 1)λ1/parenleftBig c(n1) 1/parenrightBig +/summationdisplay cλ1(c) μ1π(c(1)1,c(2)1,...,c(n1) 1)μ1 μ1+λ1=μ1 λ1/parenleftBig c(n1) 1/parenrightBig·λ1/parenleftBig c(n1) 1/parenrightBig +/summationdisplay cλ1(c) μ1·μ1 μ1+λ1=μ1+/summationdisplay cλ1(c)√ We have thus veriﬁed that the limiting probabilities for the M/M/1 classed queue are given by equation ( 18.2). We use this in the next section. 18.5 Product Form Theorems Theorem 18.1 The classed network of queues with kservers has product form, namely, π(z1,z2,...,z k)=k/productdisplay i=1P{state at server iiszi}, 318 classed network of queues where zi=/parenleftBig c(1) i,c(2)i,...,c(ni) i/parenrightBig , and server ibehaves like an M/M/1 classed queue . Speciﬁcally, P{state at server iiszi}=λi/parenleftBig c(1) i/parenrightBig λi/parenleftBig c(2)i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μini·(1−ρi) Proof We use the concept of local balance, as explained in Chapter 17. Statez ≡(z1,z2,...,z k) =/parenleftBig/parenleftBig c(1) 1,c(2)1,...,c(n1) 1/parenrightBig ,/parenleftBig c(1)2,c(2)2,...,c(n2) 2/parenrightBig ,...,/parenleftBig c(1) k,c(2)k,...,c(nk) k/parenrightBig/parenrightBig We deﬁne (see Figure 18.4): A=rate at which leave state zdue to arrival from outside Bi=rate at which leave state zdue to departure from server i(1≤i≤k) A/prime=rate at which enter state zdue to departure to outside B/prime i=rate at which enter state zdue to arrival at server i(1≤i≤k) Note that Rate at which leave state z=k/summationdisplay i=1Bi+A A B BkRate leave state zDue to outside arrival Due to a depart ure from...B1 server 1 B2 server 2 server kA B BkRate enter state zDue to outside depart ure B1 server 1 B2 server 2 server k= = = = =Bi Bi server i server iDue to  an arrival at...′ ′ ′ ′ ′ ′ Figure 18.4. Balancing the rate of leaving and entering state z. 18.5 product form theorems 319 and Rate at which enter state z=k/summationdisplay i=1B/prime i+A/prime. We will make the following guess, inspired by our analysis of the single-server classed network, see ( 18.2): πz=π(z1,z2,...,z k)=k/productdisplay i=1(1−ρi)λi/parenleftBig c(1) i/parenrightBig λi/parenleftBig c(2)i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μni i(18.3) where ρi=λi μiandλi=/summationtext/lscript c=1λi(c). It sufﬁces to show that our guess satisﬁes Bi=B/prime ifor all 1≤i≤kandA=A/prime.W e will now prove each of these statements. To simplify notation, when denoting the state of the system, we will assume that the state at each server iis the usual zi=/parenleftBig c(1) i,c(2)i,...,c(ni) i/parenrightBig , unless otherwise stated. Thus we will typically show only the state at those servers at which a job arrives or departs. To keep the number of cases down, we will for now ignore border cases wherethere are zero jobs at one or more queues. These cases can be handled very similarly to what is done here. One last remark: In the derivation of the unclassed Jacksonnetworks (Theorem 17.1), we viewed the rate of leaving a state (or entering a state) as including only transitions that change the state, not transitions that return to the same state. However, in the following derivation, it is easier to broaden the deﬁnitionof leaving the state (or entering) to include transitions back into the same state. Noneof this affects the validity of the balance equations. To show Bi=B/prime ifor all 1≤i≤k: Bi=Rate at which leave state zdue to departure from server i =π(z1,z2,...,z k)·μi Note that the service rate does not depend on the class of the job. B/prime i=Rate at which enter state zdue to arrival at server i =π(...,(c(1) i,c(2)i,...,c(ni−1) i),...)·ri/parenleftBig c(ni) i/parenrightBig +k/summationdisplay j=1/lscript/summationdisplay cj=1π/parenleftBig ...,(c(1) i,c(2)i,...,c(ni−1) i),...,/parenleftBig cj,c(1)j,...,c(nj) j/parenrightBig ,.../parenrightBig·μjP(cj)(c(ni) i) ji =π(z1,z2,...,z k)·μi λi/parenleftBig c(ni) i/parenrightBig·ri/parenleftBig c(ni) i/parenrightBig +k/summationdisplay j=1/lscript/summationdisplay cj=1π(z1,z2,...,z k)·μi λi/parenleftBig c(ni) i/parenrightBig·λj(cj) μj·μjP(cj)(c(ni) i) ji 320 classed network of queues =πz·μi λi/parenleftBig c(ni) i/parenrightBig·⎡ ⎣ri/parenleftBig c(ni) i/parenrightBig +k/summationdisplay j=1/lscript/summationdisplay cj=1λj(cj)P(cj)(c(ni) i) ji⎤⎦ =π z·μi λi/parenleftBig c(ni) i/parenrightBig·λi/parenleftBig c(ni) i/parenrightBig (by Equation ( 18.1)) =πz·μi =Bi To show A=A/prime: A=Rate at which leave state zdue to outside arrival =π(z1,z2,...,z k)·k/summationdisplay i=1/lscript/summationdisplay c=1ri(c) A/prime=Rate at which enter state zdue to departure to outside =k/summationdisplay i=1/lscript/summationdisplay ci=1π(...,(ci,c(1) i,...,c(ni) i),...)·μiP(ci)(∗) i,out (the(∗)denotes any class) =π(z1,z2,...,z k)·k/summationdisplay i=1/lscript/summationdisplay ci=1λi(ci) μi·μiP(ci)(∗) i,out =π(z1,z2,...,z k)·k/summationdisplay i=1/lscript/summationdisplay ci=1λi(ci)P(ci)(∗) i,out Now observe that A=πz·(total rate of entering the network from outside ) A/prime=πz·(total rate of leaving the network ) Because the network is in equilibrium, the total average rate of entering the network must equal the total average rate of leaving the network; hence we have A=A/prime.√ Verify that the product form holds : We would like to show that π(z1,z2,...,z k)=k/productdisplay i=1P{state at server iiszi}, given our guess from ( 18.3) that π(z1,z2,...,z k)=k/productdisplay i=1(1−ρi)λi/parenleftBig c(1) i/parenrightBig λi/parenleftBig c(2)i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μni i. To compute P{state at server iiszi}, we simply sum ( 18.3) over all zj, where j/negationslash=i. Observe that summing over zjinvolves both summing over all possible classes in the 18.5 product form theorems 321 vector/parenleftBig c(1) j,c(2)j,...,c(nj) j/parenrightBig and also summing over all possible values of nj. This is illustrated in the following expressions: P{state at server iiszi} =/summationdisplay zj,j/negationslash=iπ(z1,z2,...,z k) =( 1−ρi)λi/parenleftBig c(1)i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μni i ×k/productdisplay j=1,j/negationslash=i∞/summationdisplay nj=0/summationdisplay c(1) j,...,c(nj) j(1−ρj)λj/parenleftBig c(1) j/parenrightBig ···λj/parenleftBig c(nj) j/parenrightBig μnj j =( 1−ρi)λi/parenleftBig c(1) i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μni ik/productdisplay j=1,j/negationslash=i∞/summationdisplay nj=0(1−ρj)λnj j μnj j =( 1−ρi)λi/parenleftBig c(1) i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μni ik/productdisplay j=1,j/negationslash=i1 =( 1−ρi)λi/parenleftBig c(1)i/parenrightBig ···λi/parenleftBig c(ni) i/parenrightBig μni i Hence we can rewrite ( 18.3)a s π(z1,z2,...,z k)=k/productdisplay i=1P{state at server iiszi}, which is the deﬁnition of product form. Corollary 18.2 In a classed network of queues, the number of jobs in each queue obeys the following distribution: P/braceleftbigg Distribution of jobs is (n1,n2,...,n k)/bracerightbigg =k/productdisplay i=1P{nijobs at server i}=k/productdisplay i=1ρni i(1−ρi) Observe that Corollary 18.2 is identical to what we proved for the unclassed Jackson network. Proof We again use the shorthand: zi=/parenleftBig c(1) i,c(2)i,...,c(ni) i/parenrightBig",8297
18.6 Examples Using Classed Networks,"322 classed network of queues P{Distribution of jobs is (n1,n2,...,n k)} =/summationdisplay c(1) 1...c(n1) 1,...,c(1) k...c(nk) kP⎧ ⎪⎪⎨ ⎪⎪⎩state at server 1isz1, state at server 2isz2, ... state at server kiszk⎫ ⎪⎪⎬ ⎪⎪⎭ (Thm 18.1)=/summationdisplay c(1) 1...c(n1) 1,...,c(1) k...c(nk) kk/productdisplay i=1P{state at server iiszi} =k/productdisplay i=1/summationdisplay c(1) i...c(ni) iP/braceleftBig state at server iis/parenleftBig c(1) i,...,c(ni) i/parenrightBig/bracerightBig =k/productdisplay i=1/summationdisplay c(1) i...c(ni) iλi/parenleftBig c(1) i/parenrightBig λi/parenleftBig c(2)i/parenrightBig ...λ i/parenleftBig c(ni) i/parenrightBig μini·(1−ρi) =k/productdisplay i=1ρni i·(1−ρi) Thus, we have shown that P{Distribution of jobs is (n1,n2,...,n k)}=k/productdisplay i=1ρni i·(1−ρi).(18.4) Summing both sides of ( 18.4) over all i/negationslash=j, we have further shown that P{njjobs at server j}=ρnj j(1−ρj). Hence we have shown that P{Distribution of jobs is (n1,n2,...,n k)}=k/productdisplay i=1P{nijobs at server i}. 18.6 Examples Using Classed Networks In this section, we elaborate on some of the motivating examples mentioned in Sec- tion18.2. Our ﬁrst example only requires Corollary 18.2, whereas the other examples need the full power of Theorem 18.1. 18.6.1 Connection-Oriented ATM Network Example Consider a connection-oriented network (not shown) with particular routes along whichpackets ﬂow. The routes are shown in Figure 18.5. 18.6 examples using classed networks 323 Route 1: Poisson (3 pkts/sec) o ut out out outRoute 2: Poisson (4 pkts/sec) Route 3: Poisson (5 pkts/sec) Route 4: Poisson (6 pkts/sec)1 2 3 1 3 4 22 33 4 µ2 = 10 µ1 = 10 µ3 = 20 µ4 = 10 Figure 18.5. Routes for connection-oriented network. Goal: We want to determine E[T]for packets on route 2. Question: How can we express this problem as a classed network? Answer: We want to associate the packets on each route with a particular class. ri(c)=outside arrival rate into server iof class cpackets P(c) ij=probability that when a packet of class cﬁnishes at server i, it next moves to server j λi(c)=total arrival rate into server iof class cpackets So, we have the following: For class 1: r1(1) = 3; P(1) 12=1 ; P(1) 23=1 ; P(1) 3,out=1 For class 2: r1(2) = 4; P(2) 13=1 ; P(2) 34=1 ; P(2) 4,out=1 For class 3: r2(3) = 5; P(3) 23=1 ; P(3) 34=1 ; P(3) 4,out=1 For class 4: r3(4) = 6; P(4) 3,out=1 All other ri(c)’s and P(c) ij’s are zero. Now, we can solve for the λi(c)’s by solving these simultaneous equations: λj(c)=rj(c)+/summationdisplay iλi(c)P(c) ij 324 classed network of queues However, in this case, the problem is so easy that we can determine the λj(c)’s by sight (it helps to read these from right to left): λ3(1) = λ2(1) = λ1(1) = r1(1) = 3 jobs/sec λ4(2) = λ3(2) = λ1(2) = r1(2) = 4 jobs/sec λ4(3) = λ3(3) = λ2(3) = r2(3) = 5 jobs/sec λ3(4) = r3(4) = 6 jobs/sec Question: How do we determine the λi’s? Answer: λj=Total arrival rate into server j=/lscript/summationdisplay c=1λj(c). λ1=λ1(1) + λ1(2) = 3 + 4 = 7 jobs/sec λ2=λ2(1) + λ2(3) = 3 + 5 = 8 jobs/sec λ3=λ3(1) + λ3(2) + λ3(3) + λ3( 4 )=3+4+5+6=1 8 jobs/sec λ4=λ4(2) + λ4(3) = 4 + 5 = 9 jobs/sec Question: How do we determine the ρi’s? Answer: ρi=load at server i=λi μi. ρ1=7 10;ρ2=8 10;ρ3=18 20;ρ4=9 10.",3275
18.6 Examples Using Classed Networks,"Question: What is E[Tfor route 2 packets ]? Answer: We ﬁrst determine the expected time that is spent at each server by determining the expected number of packets at each server and applying Little’s Law. E[Ni]=Expected number of packets at server i=ρi 1−ρi. E[N1]=0.7 0.3=7 3;E[N2]=4 ; E[N3]=9 ; E[N4]=9 E[Ti]=Expected time at server iper visit =E[Ni] λi E[T1]=E[N1] λ1=7/3 7=1 3sec E[T2]=E[N2] λ2=4 8=1 2sec E[T3]=E[N3] λ3=9 18=1 2sec E[T4]=E[N4] λ4=9 9=1sec 18.6 examples using classed networks 325 The total time a packet spends on route 2 is the sum of the times spent at each server that it visits. E[Tfor packets on route 2 ]=E[T1]+E[T3]+E[T4]=11 6sec 18.6.2 Distribution of Job Classes Example In the previous example, we only needed Corollary 18.2. Sometimes we need the more powerful Theorem 18.1. Suppose, for example, that there are only two job types called class1and class 2, and we want to know the probability that there are exactly sjobs of class 1 and tjobs of class 2 at server i. Theorem 18.1 implies P{Server ihassjobs of class 1andtjobs of class 2} =/parenleftbigg s+t s/parenrightbiggλi(1)sλi(2)t μs+t i·(1−ρi), where ρi=λi μiandλi=λi(1) + λi(2). Let’s see if we can write this expression in a more intuitive way: P{Server ihassjobs of class 1andtjobs of class 2} =/parenleftbigg s+t s/parenrightbiggλi(1)sλi(2)t μs+t i·(1−ρi) =/parenleftbigg s+t s/parenrightbiggλi(1)sλi(2)t μs+t iρs+t i·ρs+t i(1−ρi) =/parenleftbigg s+t s/parenrightbiggλi(1)sλi(2)t λs+t i·ρs+t i(1−ρi) =/parenleftbigg s+t s/parenrightbigg/parenleftbiggλi(1) λi/parenrightbiggs ·/parenleftbiggλi(2) λi/parenrightbiggt ·ρs+t i(1−ρi) =/bracketleftBigg/parenleftbigg s+t s/parenrightbigg/parenleftbiggλi(1) λi(1) + λi(2)/parenrightbiggs ·/parenleftbiggλi(2) λi(1) + λi(2)/parenrightbiggt/bracketrightBigg ·/bracketleftbig ρs+t i(1−ρi)/bracketrightbig (18.5) We have written the result as a product of two factors (in brackets). Question: What is the right factor in ( 18.5)? Answer: The right factor is just the probability that there are s+tjobs at server i. Question: What is the left factor in ( 18.5)? Answer: By deﬁnition the left factor of ( 18.5) must represent the probability that there aresjobs of type 1 and tjobs of type 2 at server i, given that there are s+tjobs total at server i. In fact, setting p=λi(1) λi(1) + λi(2)=λi(1) λi=Fraction of type 1 arrivals at server i, 326 classed network of queues we can rewrite the left factor of ( 18.5)a s /parenleftbiggs+t s/parenrightbigg ps(1−p)t(18.6) If we now think of each job at server ias independently being of type 1 with probability pand type 2otherwise, we see that ( 18.6) represents exactly what we want, namely the probability that there are sjobs of type 1 and tof type 2 at server i, given that there ares+tjobs total at server i. 18.6.3 CPU-Bound and I/O-Bound Jobs Example Here is a more complex example. Your system consists of two devices: a CPU device with Exponential service rate 2 jobs/sec and an I/O device with Exponential servicerate 1 job/sec. There are two different types of jobs: CPU-bound jobs andI/O-bound jobs. CPU-bound jobs arrive at the CPU from outside according to a Poisson process of rate 0.2 jobs/sec. After serving at the CPU, three things can happen to a CPU-bound job: 1.With probability 0.3, the job leaves the system. 2.With probability 0.65, the job returns to the CPU queue to repeat the process. 3.With probability 0.05, the job goes to the I/O device queue, serves there once, and immediately returns to the CPU queue to repeat the process. The I/O-bound jobs arrive at the I/O from outside the network according to a Poissonprocess with rate 0.25 jobs/sec. After serving at the I/O, there are three things that can happen to an I/O-bound job: 1.With probability 0.4, the job leaves the system. 2.With probability 0.5, the job returns to the I/O queue to repeat the process. 3.With probability 0.1, the job goes to the CPU device queue. Each time the job serves at the CPU device, it has a 0.05 probability of return- ing to the CPU device and a 0.95 probability of returning to the I/O queue. Our goal is to answer the following questions: (a)What is the expected time in system of CPU-bound jobs? (b)What is the average number of CPU-bound jobs at the CPU?",4253
18.6 Examples Using Classed Networks,"Solution: We model the routing of jobs between servers as shown in Figure 18.6. Let the CPU be device 1 and the I/O be device 2. Also, let Cbe the class of a CPU-bound job and Ibe the class of an I/O-bound job. For the CPU-bound jobs, λC 1=rC 1+λC1·PC 1,1+λC2·PC 2,1 =0.2+0.65λC1+λC2. λC2=rC 2+λC2·PC 2,2+λC1·PC 1,2=0.05λC1. 18.6 examples using classed networks 327 Device 2: I/ODevice 1: C PU P1,out= 0.3C P2,out= 0.4  I p2,2= 0.5  IP1,1= 0.65 CP1,1= 0.05  I P1,2= 0.05  CP2,1= 0.1  IP1,2= 0.95  I P2,1= 1  C  Cr1= 0.2 r2= 0.25  I Figure 18.6. Class-based routing probabilities. Solving these simultaneous equations, we get λC 1=2 3,λC 2=1 30. Similarly for the I/O-bound jobs, λI 1=rI 1+λI 1·PI 1,1+λI 2·PI 2,1 =0.05λI 1+0.1λI 2. λI 2=rI 2+λI 2·PI 2,2+λI 1·PI 1,2 =0.25 + 0 .95λI 1+0.5λI 2. Again we solve these simultaneous equations and get λI1=5 76,λI 2=5 8. We now ﬁnd the other parameters that we are interested in: λ1=λC 1+λI 1=0.7325 λ2=λC 2+λI 2=0.6583 ρ1=λ1 μ1=0.3663 ρ2=λ2 μ2=0.6583 E[N1]=ρ1 1−ρ1=0.578 E[N2]=ρ2 1−ρ2=1.9265 E[T1]=E[N1] λ1=0.7895 E[T2]=E[N2] λ2=2.9265 328 classed network of queues (a) What is the expected time in system of CPU-bound jobs? Let the expected time in system of CPU-bound jobs be E[TC]. Method 1 E/bracketleftbig TC/bracketrightbig =0.3E[T|leaves after visiting 1 ] +0.65E[T|loops back to 1 ] +0.05E[T|loops back to 1 via 2 ] =0.3E[T1]+0.65(E[T1]+E/bracketleftbig TC/bracketrightbig )+0.05(E[T1]+E[T2]+E/bracketleftbig TC/bracketrightbig ) E/bracketleftbig TC/bracketrightbig =3.117 Method 2 E/bracketleftbig TC/bracketrightbig =E/bracketleftbig VC 1/bracketrightbig ·E[T1]+E/bracketleftbig VC 2/bracketrightbig ·E[T2] We obtain E[VC 1]andE[VC 2]by solving these simultaneous equations: E/bracketleftbig VC 1/bracketrightbig =1+0 .65E/bracketleftbig VC 1/bracketrightbig +1.0E/bracketleftbig VC 2/bracketrightbig E/bracketleftbig VC 2/bracketrightbig =0.05E/bracketleftbig VC 1/bracketrightbig (b) What is the average number of CPU-bound jobs at the CPU? Question: We need to ﬁnd E[NC 1]. How can we do this? Hint: Use ( 18.5). Answer: From ( 18.5) it follows that the expected number of CPU-bound jobs at server 1 is the expected number of jobs at server 1multiplied by p, the fraction of those jobs that are CPU-bound jobs. That is, E/bracketleftbig NC 1/bracketrightbig =E[Number jobs at CPU ]·p=ρ1 1−ρ1·λC 1 λC 1+λI1. In case the above is not obvious, here is a full derivation: E/bracketleftbig NC 1/bracketrightbig =∞/summationdisplay s=0P{sjobs of type Cat server 1}·s =∞/summationdisplay s=0∞/summationdisplay n1=sP{sjobs of type Cat server 1 and n1jobs total}·s",2612
18.7 Readings. 18.8 Exercises,"18.8 exercises 329 =∞/summationdisplay s=0∞/summationdisplay n1=s/parenleftBign1 s/parenrightBig ps(1−p)n1−s·ρn1 1(1−ρ1)·sby (18 .5) =∞/summationdisplay n1=0ρn1 1(1−ρ1)/parenleftBiggn/summationdisplay s=0/parenleftBign1 s/parenrightBig ps(1−p)n1−s·s/parenrightBigg =∞/summationdisplay n1=0ρn1 1(1−ρ1)(n1·p)(mean of Binomial (n1,p)) =E[N1]·p. 18.7 Readings A nice example of using a classed Jackson network to solve a problem is provided in the SIGCOMM ’99 best student paper [ 145]. 18.8 Exercises 18.1 Classed Queueing Network The server in Figure 18.7 processes jobs at an Exponential rate of μ=1 0 jobs/sec. There are two types of jobs being served at the FCFS server. Jobs of type 1 arrive according to a Poisson process with rate r(1)=0.5jobs/sec. After each visit to the server, they require an additional visit with probability 0.75. Jobs of type 2 arrive according to a Poisson process with rate r(2)=3 jobs/sec. After each visit to the server, they require an additional visit with probability 0.5. What is the mean response time for jobs of type 1? Type 2? r(1) = 0.5 r(2) = 3.0P(1) = 0.75 P(2) = 0.5 μ=10 Figure 18.7. Classed queueing network. 18.2 Quick versus Slow Customers Consider a single queue with a single service station with service time dis- tributed Exponentially with mean 1. There are two types of customers: 1. “Quick customers” arrive according to a Poisson process with rate1 3, visit the server once, and leave. 2. “Slow customers” arrive according to a Poisson process with rate1 6and visit the server a Geometric number of times with mean 3. On average, how many quick customers and how many slow customers are in the system? 330 classed network of queues 18.3 Jobs Needing Repair A system consists of a service facility and a repair facility. The service time at both facilities is Exp/parenleftbig1 10/parenrightbig . Jobs arrive at the service facility according to a Poisson process with rate λ. After each visit to the service facility, the job either: rleaves the system (probability 0.1) rrequires repair (probability 0.01) rrevisits the service facility (probability 0.89). After completing repair, a job returns to the service facility, except that now,after each visit to the service facility, the job either: rleaves the system (probability 0.1) rrequires repair (probability 0.5) rrevisits the service facility (probability 0.4). Please answer the following questions about the system:(a) What is the expected number of times that a job visits the service facility? (b) What is the highest possible throughput, λ? (c) Set λ=1 200. What is the expected time in system, E[T]? 18.4 Class-Based Service Rates? Consider a Jackson network with /lscriptclasses. Until now we have always assumed that the service rate is the same for each of the classes. Suppose you want tohave the service rate depend on the class of the job (e.g., jobs of class care served at rate μ(c)). Can you solve balance equations for the case of a single server with class-dependent service rates? Why or why not? If you can, do itand determine the limiting probabilities: π(c(1),...,c(n)), where c(i)denotes the class of the ith job in queue at the server. 18.5 Distribution of Job Classes In Section 18.6.2 , we considered a network with two classes of jobs and derived the probability that server ihassjobs of class 1 and tjobs of class 2, namely: P{Server ihassjobs of class 1andtjobs of class 2} =/bracketleftBigg/parenleftbigg s+t s/parenrightbigg/parenleftbiggλi(1) λi(1) + λi(2)/parenrightbiggs ·/parenleftbiggλi(2) λi(1) + λi(2)/parenrightbiggt/bracketrightBigg ·/bracketleftbig ρs+t i(1−ρi)/bracketrightbig . (a) Generalize this expression to /lscriptclasses; namely, derive P{Server ihasm1jobs of class 1,m2of class 2,...,m /lscriptof class /lscript}. (b) Provide an expression for the expected number of class 1 jobs at server i. 18.6 Not All Networks Have Product Form Give an example of a 2-server network that does nothave a product form limiting distribution. Analyze the limiting distribution of your network and prove that there exist n1,n2, such that P{n1jobs at server 1 & n2jobs at server 2 } /negationslash=P{n1jobs at server 1 }·P{n2jobs at server 2 }.",4188
Chapter 19 Closed Networks of Queues. 19.1 Motivation,"CHAPTER 19 Closed Networks of Queues Thus far, all of our analysis of networks of queues involved open queueing networks. We have witnessed the product form property for Jackson-type networks (those with probabilistic routing), which has allowed us to instantly derive the probability distribu-tion of the number of jobs at each of the servers. It turns out that the same basic productform idea applies to closed queueing networks. The only difference is that additional work is involved in computing the normalizing constant for the case of closed networks, whereas it has a simple closed form for the case of open networks. In this chapter, we brieﬂy illustrate the product form analysis of closed queueing networks with probabilistic routing, also known as closed Jackson networks. To keepthings simple, we stick to single-class networks, although everything that we say applies to multi-class networks as well. Also, we throughout assume a batch closed network, meaning zero think time (see Section 2.6.2 ). The extension to interactive closed networks is studied in the Exercise 19.3(4). 19.1 Motivation Consider a closed system with multiple queues and probabilistic routing between the queues, as shown in the batch network in Figure 19.1. Our goal might be to determine the probability that there are 2jobs at the third server. N = 2 μ2 μ3μ1p 1–p Figure 19.1. Example of a closed batch network. For this example, the possible states are (0,0,2),(0,2,0),(2,0,0),(1,0,1),(1,1,0), and(0,1,1). The corresponding 6-state Markov chain results in a ﬁnite number of 331 332 closed networks of queues simultaneous equations, which can be solved to obtain the limiting probability of being in each state. In particular, we can obtain π0,0,2, which is what we wanted. The Markov chain is shown in Figure 19.2. 3 2 2 1p 1p 1p1(1–p) 1(1–p)3 1(1–p)3 21,1,0 0,2,02,0,0 0,0, 2 1,0,1 0,1,1 Figure 19.2. The corresponding CTMC. In fact, any closed batch network is solvable, at least in theory, because we are dealing with a ﬁnite number of simultaneous equations. Provided that the total number of jobs, N, and the total number of servers/queues, k, are not too large, speciﬁc instances of the closed network (meaning chains with speciﬁc values of the μi’s) should be tractable. Let’s make this more concrete. Question: Suppose there are kservers and Njobs total. What is the number of simultaneous balance equations that need to be solved for the CTMC? Answer: Number of simultaneous equations =Number of states =/parenleftbigg N+k−1 k−1./parenrightbigg . Note: This expression represents all the ways of dividing the Njobs among kservers or, alternatively, of distributing k−1“dividers” into N+k−1slots, as shown in Figure 19.3. Figure 19.3. Distributing a dozen balls into 5 bins (the 4th is empty). The point of this chapter is to ﬁnd a faster way to get to the limiting probabilities. We want to be able to express these limiting probabilities in closed form, as a function ofthe μi’s and routing probabilities.",3007
19.2 Product Form Solution,"19.2 product form solution 333 19.2 Product Form Solution We consider a general closed batch Jackson-type network. This is characterized by the following properties. There are kservers, each with a FCFS queue. There is probabilistic routing between the servers: With probability Pij, when a job leaves server i,i tn e x t goes to server j, as for example in Figure 19.4. There are no outside arrivals and no departures to the outside. There is a ﬁxed multiprogramming level, N. That is, there are exactly Njobs in the network at any time. The state is (n1,n2,...,n k), where ni denotes the number of jobs at server i. p12 p32 p23 p31μ1 μ2 μ3 Figure 19.4. Closed batch Jackson network. Question: It seems that a closed Jackson network is deﬁned exactly like an open Jackson network, except for what? Answer: For the closed network, ri=0andPi,out=0for all i. Thus, the balance equations for closed networks are identical to the balance equations for the open networks, except that some of the terms ( ri’s and Pi,out’s) are now set to zero. Thus it would seem that πn1,...,n k=Cρn1 1ρn2 2...ρnk k (19.1) might still work as a solution for the limiting probabilities. However, the set of balance equations in a closed network is a subset of the set of balance equations in the open network; some states are not allowed in the closed network because the number of jobs in the system do not sum up to N. Hence it is not obvious that the guess in ( 19.1) will work. 19.2.1 Local Balance Equations for Closed Networks The local balance equations for a closed network equate Bi, the rate of leaving a state due to a departure from server i, withB/prime i, the rate of entering the state due to an arrival at server i. In both BiandB/prime i, we will allow for transitions which take us back to the same state. Question: Why don’t we need to worry about A=A/prime? Answer: There are no outside departures or arrivals. 334 closed networks of queues We now need to check that the guess in ( 19.1) satisﬁes Bi=B/prime i. Bi Rate leave state (n1,n2,...,n k) due to departure from server i=B/prime i Rate enter state (n1,n2,...,n k) due to arrival at server i πn1,...,n k·μi=k/summationdisplay j=1πn1,...,n i−1,...,n j+1,...,n k·μj·Pji μi=k/summationdisplay j=1ρj ρiμj·Pji λi=k/summationdisplay j=1λj·Pji The ﬁnal line simply states that the total arrival rate into server iis the sum of the de- parture rates into server ifrom the other servers. This is obviously true, so we are done. Question: Great, so we have veriﬁed that πn1,...,n k=Cρn1 1ρn2 2...ρnk k. But what is ρi? Answer: ρi=λi μi Question: But how do we determine λi? Answer: For open networks, we determined λiby solving ksimultaneous equations: λi=ri+k/summationdisplay j=1λjPji Question: Suppose we try solving these simultaneous equations for the case of a closed network. What goes wrong? Answer: For closed networks, ri=0so theksimultaneous equations only have k−1 linearly independent variables. So we cannot get a unique solution. For example, consider the closed network of servers shown in Figure 19.5. μ1 μ20.5 0.70.3 0.5 Figure 19.5. Simple example. The simultaneous equations are λ1=λ2(0.7) +λ1(0.5). λ2=λ1(0.5) +λ2(0.3). 19.2 product form solution 335 Both equations are the same. So λ2=5 7λ1, but we do not know λ1. Another way to think about this is that we only know the λi’s to within a constant factor. That is, we know (cλ1,c λ2,...,cλ k) but we do not know what cis. This turns out to be OK, however, because the c’s get hidden into the normalizing constant in the limiting probabilities: πn1,...,n k=C/parenleftbigg cλ1 μ1/parenrightbiggn1/parenleftbigg cλ2 μ2/parenrightbiggn2 .../parenleftbigg cλk μk/parenrightbiggnk =CcNρn1 1...ρnk k =C/primeρn1 1...ρnk k What is important in this expression is that the ﬁnal constant, C/prime, is the same for any state of the CTMC. We summarize the procedure below. Solving Closed Batch Jackson Networks : 1.Determine λi’s. To do this, solve the simultaneous rate equations. You will have an inﬁnite number of solutions that work. Pick any one solution (e.g., setλ1=1). 2.Compute ρi=λi μi, for all i. 3.Setπn1,...,n k=C/primeρn1 1ρn2 2...ρnk k 4.Finally compute C/prime. To do this, use the fact that /summationdisplay n1,...,n k s.t./summationtext ini=NC/prime·ρn1 1ρn2 2···ρnk k=1 19.2.2 Example of Deriving Limiting Probabilities Consider again the closed system shown in Figure 19.1, where μ1=1,μ2=2,μ3=3, andp=1 3. We want to determine E[Number jobs at server 1]. The ﬁrst thing to do is determine the ρi’s. To do this we want to determine the λi’s. This is done by solving the simultaneous rate equations: λ1=λ2+λ3 λ2=1 3·λ1 λ2=2 3·λ1 336 closed networks of queues These equations are not linearly independent, so we arbitrarily set λ1=1. This leaves us with λ2=1 3 λ3=2 3. We now compute ρi=λi μias follows, for i=1,2,3: ρ1=1,ρ 2=1 6,ρ 3=2 9 Question: Are the above utilizations? Answer: No.These are not “real loads. ” They do not mean anything in terms of load because they are based on a made-up value for λ1. To determine any performance metric, we ﬁrst need to determine the limiting probabilities of the CTMC. We use the product form representation of the limitingprobabilities: πn1,n2,n3=C·ρn1 1·ρn2 2·ρn3 3 To use this formula we need to determine C. We consider all the possible states: (0,0,2), (0,2,0), (2,0,0), (1,0,1), (1,1,0), (0,1,1): 1=/summationdisplay all statesπstate =C/parenleftbig ρ0 1ρ02ρ23+ρ0 1ρ22ρ03+ρ2 1ρ02ρ03+ρ1 1ρ02ρ13+ρ1 1ρ12ρ03+ρ0 1ρ12ρ13/parenrightbig =C/parenleftBigg/parenleftbigg2 9/parenrightbigg2 +/parenleftbigg1 6/parenrightbigg2 +( 1 )2+/parenleftbigg2 9/parenrightbigg +/parenleftbigg1 6/parenrightbigg +/parenleftbigg1 6·2 9/parenrightbigg/parenrightBigg =C·1.5031 So we are left with C=1 1.5031=.6653. Now we can use Cand the ρi’s to get the limiting probabilities: π0,0,2=C·ρ0 1ρ02ρ23=0.033 π0,2,0=C·ρ0 1ρ22ρ03=0.018 π2,0,0=C·ρ2 1ρ02ρ03=0.665 π1,0,1=C·ρ1 1ρ02ρ13=0.148 π1,1,0=C·ρ1 1ρ12ρ03=0.111 π0,1,1=C·ρ0 1ρ12ρ13=0.025",5982
19.3 Mean Value Analysis MVA,"19.3 mean value analysis (mva) 337 Given the limiting probabilities, it is easy to determine any performance metric. For example, E[Number at server 1] =π1,0,1+π1,1,0+2π2,0,0=1.589. Utilization of server 1 =1−π0,0,2−π0,2,0−π0,1,1=0.924. 19.3 Mean Value Analysis (MV A) The only difﬁculty in the previous approach for closed systems is that it requirescomputing C/prime, the normalizing constant for the limiting probabilities. This involves summing r=/parenleftbigg N+k−1 k−1/parenrightbigg terms. Thus the number of terms we have to add up grows exponentially in Nand k. (Note this is already a lot better than solving the original CTMC from scratch, where rather than just having to add rterms, we have to solve that many simultaneous equations.) In practice, for a single-class closed network, summing these rterms to determine the normalizing constant is not usually a big deal. Typically the number of servers, k, is low. Now, if Nisalso low, then we can easily compute the normalizing constant. Otherwise, if Nis high, operational bounds analysis will work very well. Nonetheless, many people still ﬁnd it cumbersome to have to determine this normalizing constant and there has been research into faster approaches for com- puting it [ 35]. We now present an alternative method for analyzing closed product form networks, which is very efﬁcient and intuitive. This method is called Mean Value Analysis (MV A). The downside of MV A is that it does not provide more than mean metrics. That is, rather than providing the distribution of the number of jobs at each server, MV A provides only the mean number of jobs at each server. MV A recursively relates the mean number of jobs at server jin a closed system where the total number of jobs is M, namely E/bracketleftBig N(M) j/bracketrightBig , to the mean number of jobs at server jin the same system where the total number of jobs is M−1, namely E/bracketleftBig N(M−1) j/bracketrightBig (note that we have switched to writing Mfor the total number of jobs, rather than N, to avoid notation overload). This recursive relationship allows us to then start with a 1-job system ( M=1), which is easy to reason about; then use that to get the mean response time for the 2-job system; then use that to get the mean response time for the 3-job system; and so on, building up to the M-job system. The recursive relationship between the M-job system and the ( M−1)-job system is captured in the Arrival Theorem. 338 closed networks of queues 19.3.1 The Arrival Theorem Theorem 19.1 (The Arrival Theorem) In a closed Jackson network with M>1 total jobs, an arrival to server jwitnesses a distribution of the number of jobs at each server equal to the steady-state distribution of the number of jobs at each server in the same network with M−1total jobs. In particular, the mean number of jobs that the arrival sees at server jisE/bracketleftBig N(M−1) j/bracketrightBig . The Arrival Theorem may make some intuitive sense because the arrival is seeing a system that does not contain itself; hence it has M−1total jobs.",3064
19.3 Mean Value Analysis MVA,"However, it is not true for all networks. Question: Provide an example of a closed network for which the Arrival Theorem is false. Answer: Imagine a closed system consisting of two servers in tandem with M=2 jobs, where the service time at each server is deterministically 1. Suppose that we start out with one job at each server. Then forever after, there will be exactly one job ateach server (because jobs move in lock-step). Thus, an arrival, job j, into server 1will always witness 0jobs at server 1and yet E/bracketleftBig N(1) 1/bracketrightBig =1 2. The previous question/answer illustrates why the Arrival Theorem can be thought of as the “counterpart to PASTA” for closed systems: it requires job sizes to be Exponentially distributed. In the rest of the section, we prove the Arrival Theorem and then show how to use it to derive E/bracketleftbig T(M)/bracketrightbig , the mean response time in a closed system with Mjobs. Before we do this, however, we need to digress and recall the limiting probability for a closed Jackson network with Mjobs. We use the superscript Mto denote the fact that this is anM-job system. Recall that π(M) n1,n2,...,n k=C(M)/parenleftBigg λ(M) 1 μ1/parenrightBiggn1 ·/parenleftBigg λ(M) 2 μ2/parenrightBiggn2 ···/parenleftBigg λ(M) k μk/parenrightBiggnk (19.2) whenever/summationtextk i=1ni=M, and0otherwise. Here λ(M) jdenotes the total arrival rate into server j, given a closed system with Mjobs, and C(M)is the appropriate normalizing constant for the M-job system. The problem is that the λ(M) jterm in ( 19.2) depends onM. For reasons that will become clear soon, it will be very helpful to replace this with a term that does not depend on M. Let’s deﬁne a term that we call pj, where pj=λ(M) j λ(M). (19.3) 19.3 mean value analysis (mva) 339 Hereλ(M)=/summationtextk j=1λ(M) jdenotes the total arrival rate into all servers in the M-job system. Observe that pjis just the fraction of total arrivals that are arrivals to server j (as opposed to some other server). Because pjis a proportion rather than an absolute quantity, pjis independent of M.1 We can now rewrite the limiting probabilities from ( 19.2) in terms of pjas follows: π(M) n1,n2,...,n k=C/prime(M)/parenleftbiggp1 μ1/parenrightbiggn1 ·/parenleftbiggp2 μ2/parenrightbiggn2 ···/parenleftbiggpk μk/parenrightbiggnk , (19.5) whenever/summationtextki=1ni=M, and0otherwise. What is nice about the limiting probabilities given by ( 19.5) is that all the terms involving “ M” have been subsumed into the constant. We now prove the Arrival Theorem, after which we illustrate the derivation of E/bracketleftbig T(M)/bracketrightbig . Proof (Arrival Theorem) We consider a job, job x,i na n M-job system, that has just left server iand is headed to server j. We wish to determine the distribution of jobs at each server, as seen by job x. We will show that the probability that job xobserves n1 jobs at server 1, n2at server 2, n3at server 3, etc., where/summationtextkj=1nj=M−1(we are not including the job itself), is exactly π(M−1) n1,n2,...,n k.",3052
19.3 Mean Value Analysis MVA,"Our argument follows that of [ 150]. We start by observing that the probability that jobxobserves state (n1,n2,...,n k), where/summationtextkj=1nj=M−1is the same as the ratio of two rates: the rate of transitions from server ito server jwhich observe state (n1,n2,...,n k)and the total rate of transitions from server ito server j. P/braceleftBig jobxobserves (n1,n2,...,n k), where/summationtextkj=1nj=M−1/bracerightBig =π(M) n1,...,n i+1,...,n kμiPij/summationdisplay h1,...,hk s.t./summationtext /lscripth/lscript=M−1π(M) h1,...,h i+1,...h kμiPij =π(M) n1,...,n i+1,...,n k/summationdisplay h1,...,hk s.t./summationtext /lscripth/lscript=M−1π(M) h1,...,h i+1,...h k 1To illustrate why pjis independent of M, letVjdenote the number of visits to server jper job completion (independent of M), and let X(M)denote the total rate of job completions per second in a system with M jobs. Then pj=λ(M) j λ(M)=X(M)Vj/summationtextk j=1X(M)Vj=Vj/summationtextkj=1Vj, (19.4) which is clearly independent of M. 340 closed networks of queues =pi μi·k/productdisplay /lscript=1/parenleftbiggp/lscript μ/lscript/parenrightbiggn/lscript /summationdisplay h1,...,hk s.t./summationtext /lscripth/lscript=M−1π(M) h1,...,h i+1,...h kby(19.5) =Ck/productdisplay /lscript=1/parenleftbiggp/lscript μ/lscript/parenrightbiggn/lscript ,where C:constant, independent of n1,n2,...,nk =π(M−1) n1,n2,...,n k. The last line follows from the fact that the probability over what job xsees is a “density” in the sense that, when we sum it over all possible n1,n2,...,n k, where/summationtextk /lscript=1n/lscript=M−1, we get 1. Hence the constant Cabove is the unique constant needed to make this density sum to 1. But that means that C=C(M−1), the unique constant needed to make the density in ( 19.5) sum to 1. The above chain of equalities is true for all i,j, completing the proof. 19.3.2 Iterative Derivation of Mean Response Time We are now ﬁnally ready to express E/bracketleftBig T(M) j/bracketrightBig in terms of E/bracketleftBig T(M−1) j/bracketrightBig . Once we have done this, we can then start with E/bracketleftBig T(1) j/bracketrightBig and use that to get E/bracketleftBig T(2) j/bracketrightBig , which we will then use to get E/bracketleftBig T(3) j/bracketrightBig , and so forth, until we have E/bracketleftBig T(M) j/bracketrightBig . Question: Pop quiz: What is E/bracketleftBig T(1) j/bracketrightBig ? Answer: We are asking what is the mean response time at server jwhen the number of jobs in the system is 1. This is just the mean service time:1 μj. Invoking the Arrival Theorem, we have E/bracketleftBig T(M) j/bracketrightBig =1 μj+E[Number at server jas seen by an arrival to j] μj =1 μj+E/bracketleftBig N(M−1) j/bracketrightBig μj(by the Arrival Theorem) =1 μj+λ(M−1) jE/bracketleftBig T(M−1) j/bracketrightBig μj(by Little’s Law) =1 μj+pj·λ(M−1)E/bracketleftBig T(M−1) j/bracketrightBig μj(by defn of pjin19.3) 19.3 mean value analysis (mva) 341 At this point, we have expressed E/bracketleftBig T(M) j/bracketrightBig in terms of E/bracketleftBig T(M−1) j/bracketrightBig : E/bracketleftBig T(M) j/bracketrightBig =1 μj+pj·λ(M−1)E/bracketleftBig T(M−1) j/bracketrightBig μj(19.6) However, we still have a λ(M−1)term in there. Question: H o wd ow eg e t λ(M−1)?",3262
19.3 Mean Value Analysis MVA,"Hint: Use the fact that/summationtextk j=1E/bracketleftBig N(M−1) j/bracketrightBig =M−1and apply Little’s Law. Answer: M−1=k/summationdisplay j=1E/bracketleftBig N(M−1) j/bracketrightBig =k/summationdisplay j=1λ(M−1) jE/bracketleftBig T(M−1) j/bracketrightBig =k/summationdisplay j=1pjλ(M−1)E/bracketleftBig T(M−1) j/bracketrightBig ,by (19.3) =λ(M−1)k/summationdisplay j=1pjE/bracketleftBig T(M−1) j/bracketrightBig . From this expression we have that λ(M−1)=M−1 /summationtextkj=1pjE/bracketleftBig T(M−1) j/bracketrightBig. (19.7) Combining equations ( 19.6) and ( 19.7), we have the recurrence for E/bracketleftBig T(M) j/bracketrightBig . 19.3.3 An MVA Example Consider a closed system composed of 2 servers in tandem, where the second server is twice as fast as the ﬁrst server, as shown in Figure 19.6. Given that the system has M=3 jobs, how many of these are at server 1 and how many are at server 2 on average? To simplify calculations, we assume that the service rate at the ﬁrst server is μ=1. N = 3 2 Figure 19.6. An MV A example. What is the expected number of jobs at each server? 342 closed networks of queues Question: What do you expect the number of jobs at each server to be? Answer: One might naively think that because the ﬁrst server is half the speed of the second server, there should be twice as many jobs at the ﬁrst server. This is not true. As we will see, the expected number of jobs at the ﬁrst server is actually more than three times that at the second server. Our goal is to determine E/bracketleftBig N(3) 1/bracketrightBig . We will get this by deriving E/bracketleftBig T(3) 1/bracketrightBig via MV A and then applying Little’s Law. Question: What are p1andp2? Answer: Normally we would have to solve the simultaneous equations in ( 19.4) to get these, but in this case they are simple. Because the number of arrivals to server 1 is equal to the number of arrivals to server 2, we have that p1=p2=1 2. We start by deriving E/bracketleftBig T(1) 1/bracketrightBig ,E/bracketleftBig T(1) 2/bracketrightBig , andλ(1). E/bracketleftBig T(1) 1/bracketrightBig =1 μ1=1 E/bracketleftBig T(1) 2/bracketrightBig =1 μ2=1 2 λ(1)=1 1 2·/parenleftbig 1+1 2/parenrightbig=4 3by (19.7) From here we immediately move to E/bracketleftBig T(2) 1/bracketrightBig ,E/bracketleftBig T(2) 2/bracketrightBig , andλ(2). E/bracketleftBig T(2) 1/bracketrightBig =1+1 2·4 3·1 1=5 3by (19.6) E/bracketleftBig T(2) 2/bracketrightBig =1 2+1 2·4 3·1 2 2=2 3by (19.6) λ(2)=2 1 2·/parenleftbig5 3+2 3/parenrightbig=12 7by (19.7) Next, we move to E/bracketleftBig T(3) 1/bracketrightBig ,E/bracketleftBig T(3) 2/bracketrightBig , andλ(3). E/bracketleftBig T(3) 1/bracketrightBig =1+1 2·12 7·5 3 1=17 7by (19.6) E/bracketleftBig T(3) 2/bracketrightBig =1 2+1 2·12 7·2 3 2=11 14by (19.6) λ(3)=3 1 2·/parenleftbig17 7+11 14/parenrightbig=28 15by (19.7)",2854
19.4 Readings. 19.5 Exercises,"19.5 exercises 343 Finally, we derive E/bracketleftBig N(3) 1/bracketrightBig : E/bracketleftBig N(3) 1/bracketrightBig =E/bracketleftBig T(3) 1/bracketrightBig ·λ(3) 1 =E/bracketleftBig T(3) 1/bracketrightBig ·p1·λ(3) =17 7·1 2·28 15 =34 15 As a check, we also derive E/bracketleftBig N(3) 2/bracketrightBig : E/bracketleftBig N(3) 2/bracketrightBig =E/bracketleftBig T(3) 2/bracketrightBig ·λ(3)2 =E/bracketleftBig T(3) 2/bracketrightBig ·p2·λ(3) =11 14·1 2·28 15 =11 15 Observe that E/bracketleftBig N(3) 1/bracketrightBig +E/bracketleftBig N(3) 2/bracketrightBig =3as expected.√ 19.4 Readings There has been a lot of work on obtaining the normalizing constants for closed queueing networks. Some good references are [ 94], [72], [40]. MV A was developed by Reiser and Lavenberg [ 147]. In this book we have chosen to only give a brief explanation of MV A and why it works. While our exposition was limited to single-class closed networks with no think time, the MV A method appliesmuch more generally. A comprehensive discussion of the use of MV A for solving both single-class and multi-class product form networks is provided in [ 23]. The MV A method needs to be modiﬁed slightly to allow for think times as well as multiple classes.Some good references that explain these modiﬁcations are [ 125] and [ 5]. 19.5 Exercises 19.1 Closed Jackson Network Consider the very simple closed Jackson network given in Figure 19.7.D e - rive the expected number of jobs at server 1 in the case where the total number of jobs is (i) M=1, (ii)M=2, and (iii) M=3. Do not use MV A. 344 closed networks of queues ½ ½1 2=11=1 Figure 19.7. Jackson network for Exercise 19.1. 19.2 MV A Repeat Exercise 19.1 using MV A to get your answers. 19.3 Networks with Load-Dependent Service Rates This is a four-part question, with dependent parts, so please do these in order. Throughout, assume all packets come from a single class. (1) The system consists of just a single (FCFS) server. Jobs arrive according to a Poisson process with rate λ. The service rate at the server is “load- dependent,” meaning that when there are njobs in the system, the job in service is served with rate μ(n). Systems with load-dependent service rate are used to model parallel processing applications. Determine the distribution of the number of jobs in the system. (2) Now your system is a (single-class) open Jackson network of load- dependent servers. The state of the network is (n1,n2,...,n k), where nidenotes the number of jobs at server i. Letμi(ni)denote the service rate at server iwhen there are nijobs at server i. i. Solve for the limiting probabilities, π(n1,n2,...,n k), using the local balance approach. These will not be in closed form. ii. Prove that the limiting probabilities have a product form solution; namely that π(n1,n2,...,n k)=k/productdisplay i=1P{Number of jobs at server iisni}. iii. Check your solution by making the service rate constant at each server (i.e.,μi(ni)=μi,∀ni), and showing that you get the solution for ordinary open Jackson networks. (3) Now your system is a Jackson network where each server is an M/M/m. Determine the limiting probabilities, π(n1,n2,...,n k). (4) This chapter described the analysis of closed batch Jackson networks, but did not say anything about closed interactive Jackson networks. Assume that you can extend the analysis you have done in this problem to closed 19.5 exercises 345 batch Jackson networks, with load-dependent service rates. Explain in words how this would help you analyze a closed interactive Jackson net- work with Exponentially distributed think time with mean E[Z]. Specif- ically, explain how you would derive mean response time and throughputfor a closed interactive network.",3729
Part VI Real-World Workloads High Variability and Heavy Tails,"PART VI Real-World Workloads: High Variability and Heavy Tails Part VIdiscusses queueing analysis where the arrival process and/or service process are generally distributed. We start with Chapter 20, where we study empirical job size distributions from com- puting workloads. These are often characterized by heavy tails, very high variance, and decreasing failure rate. Importantly, these are very different from the Markovian(Exponential) distributions that have enabled the Markov-chain-based analysis that wehave done so far. New distributions require new analysis techniques. The ﬁrst of these, the method of phase-type distributions, is introduced in Chapter 21. Phase-type distributions allow us to represent general distributions as mixtures of Exponential distributions. This in turn enables the modeling of systems involving general distributions using Markov chains.However, the resulting Markov chains are very different from what we have seen before and often have no simple solution. We introduce matrix-analytic techniques for solving these chains numerically. Matrix-analytic techniques are very powerful. They are efﬁcient and highly accurate. Unfortunately, they are still numerical techniques,meaning that they can only solve “instances” of the problem, rather than solving theproblem symbolically in terms of the input variables. In Chapter 22we consider a new setting: networks of Processor-Sharing (PS) servers with generally distributed job sizes. These represent networks of computers, where each computer time-shares among several jobs. We again exploit the idea of phase-type distributions to analyze these networks, proving the BCMP product form theoremfor networks with PS servers. The BCMP theorem provides a simple closed-formsolution for a very broad class of networks of PS servers. Another analysis technique, called the “tagged-job” technique, is introduced in Chap- ter23. This technique provides us with a clean simple formula for the mean delay in an M/G/1 FCFS queue, known as the Pollaczek-Khinchin (P-K) formula. We alsostudy extensions of the M/G/1 in the exercises, such as mean delay for the M/G/1 withfailures and repairs, as well as the notion of a semi-Markov process that transitionsbetween states, but allows for sitting in a state for a generally distributed time beforetransitioning. The P-K mean delay formula is so simple that it facilitates the analysis of 347 348 real-world workloads: high variability and heavy tails whole server farms consisting of FCFS queues. Chapter 24is an applications chapter, where we combine everything we have learned about FCFS queues and PS queues to design and analyze routing policies for general server farms. Although the P-K formula is elegant and insightful, it does not provide us information about the variability of response time. To get higher moments of response time, weneed transform analysis. Laplace transforms and z-transforms, as applied to queueinganalysis, are introduced in Chapter 25. These are then applied to analyzing the M/G/1 queue in Chapter 26. Chapter 27is another applications chapter, this time looking at power management in servers, where there are tradeoffs between keeping the server on to reduce response time and turning it off to save on power. The problem is complicated by the fact thatthere is a “setup cost” for turning on a server. Transform analysis is extremely useful in analyzing systems with setup costs under generally distributed workloads – in fact, we do not know of any other solution technique for this problem.",3550
Chapter 20 Tales of Tails A Case Study of Real-World Workloads. 20.2 UNIX Process Lifetime Measurements,"CHAPTER 20 Tales of Tails: A Case Study of Real-World Workloads We have alluded several times during this book to the fact that computing workloads have highly variable job sizes (service requirements), that are not well described byan Exponential distribution. This chapter is a story of my own experience in studyingUNIX jobs in the mid-1990s, as a PhD student at U.C. Berkeley. Results of this researchare detailed in [ 84,85]. The story serves as both an introduction to empirical measure- ments of computer workloads and as a case study of how a deeper understanding of computer workloads can lead to improved computer system designs. The remaining chapters in the book address modeling and performance evaluation of systems withhigh-variability workloads. 20.1 Grad School Tales ...Process Migration In the mid-1990s, an important research area was CPU load balancing in a Network of Workstations (at U.C. Berkeley it was coined the “N.O.W. project”). The idea inCPU load balancing is that CPU-bound jobs might beneﬁt from being migrated from a heavily loaded workstation to a more lightly loaded workstation in the network. CPU load balancing is still important in today’s networks of servers. It is not free, however:Migration can be expensive if the job has a lot of “state” that has to be migrated withthe job (e.g., lots of open ﬁles associated with the job), as is common for jobs thathave been running for a while. When the state associated with the job is great, then the time to migrate the job to another machine is high, and hence it might not be worthmigrating that job. There are two types of migration used in load balancing techniques: 1.migration of newborn jobs only – also called initial placement orremote execution 2.migration of jobs that are already active (running) – also referred to as active process migration In the mid-1990s it was generally accepted that migrating active processes was a bad idea, because of their high migration cost. Except for one or two experimental operatingsystems, like MOSIX [ 13], people only migrated newborn jobs. Important terminology: When we talk about a job’s size we mean its total CPU requirement. When we talk about a job’s agewe mean its total CPU usage thus far. A job’s lifetime refers to its total CPU requirement (same thing as size). A job’s remaining lifetime refers to its remaining CPU requirement. 349 350 tales of tails: a case study of real-world workloads Observe that what we really want to know is a job’s remaining lifetime. If the job has a high remaining CPU requirement, then it may pay to migrate the job, even if the jobhas accumulated a lot of state, because the job will get to spend its long remaining lifetime on a lightly loaded machine. Sadly, we do not know a job’s remaining lifetime, just its current CPU age. The common wisdom in the 1990s, backed up by many research papers, was that UNIX job CPU lifetimes were Exponentially distributed . Question: What is the implication of UNIX job lifetimes being Exponentially dis- tributed? Answer: Exponential distributions exhibit a constant failure rate. That is, all jobs have the same remaining lifetime (and the same probability of requiring another second of CPU), regardless of their current age. Since newborn jobs and older (active) jobs havethesame expected remaining lifetime, yet newborn jobs are much cheaper to migrate, it makes sense to migrate only the newborn jobs. 20.2 UNIX Process Lifetime Measurements Refusing to believe that there were no beneﬁts to active process migration, I decided to measure the distribution of job lifetimes. I collected the CPU lifetimes of millions of jobs on a wide range of different machines, including instructional, research, and administrative machines, over the course of many months. Figure 20.1 shows the fraction of jobs whose size exceeds x, for all jobs whose size is greater than 1 second. 32 16 8 421x secondsP{Job size > x} 1 ½ ¼ ⅛ Figure 20.1. Plot of measured distribution, F(x)=P{Job size >x}. At a ﬁrst glance this plot looks like an Exponential distribution, F(x)=e−λx. But on closer examination you can see that it is not Exponential. Question: How can you tell that it is not Exponential? 20.2 unix process lifetime measurements 351 Answer: For an Exponential distribution, the fraction of jobs remaining should drop by a constant factor with each unit increase in x(constant failure rate). In Figure 20.1, we see that the fraction of jobs remaining decreases by a slower and slower rate as we increase x(decreasing failure rate). In fact, looking at the graph, we see that if we start with jobs of CPU age 1second, half of them make it to 2seconds. Of those that make it to2seconds, half of those make it to 4seconds. Of those that make it to 4seconds, half of those make it to 8seconds. Of those that make it to 8seconds, half of those make it to 16seconds, and so on. To see the distribution more easily it helps to view it on a log-log plot as shown in Figure 20.2. The bumpy line shows the data, and the straight line is the best-ﬁt curve. Figure 20.2. Log-log plot of measured distribution, F(x)=P{Job size >x}. To see that the measured distribution is notan Exponential distribution, consider Figure 20.3, which shows the best-ﬁt Exponential distribution in juxtaposition with the measured distribution from Figure 20.2. Figure 20.3. Plot of measured distribution on log-log axes along with best-ﬁt Exponential distribution.",5444
20.5 Heavy Tails,"352 tales of tails: a case study of real-world workloads From Figure 20.2 it is apparent that the tail of the distribution of jobs with lifetimes longer than 1second decays like1 x. That is, P{Job size >x|Job size >1}=1 x. At the time (mid-90s), I did not recognize this distribution and was suspicious of its simplicity, so I tried measuring different types of UNIX workloads. I also triedremoving shells and daemon processes, as well as removing very short jobs. No matter what I tried, in all cases, I saw a straight line on a log-log plot, indicating the following distribution: F(x)=1 xα,x≥1, where αranged from about 0.8to about 1.2, in my measurements, across machines. Most commonly αwas very close to 1, and the regression showed goodness of ﬁt ( R2) values of more than 0.96. 20.3 Properties of the Pareto Distribution It turns out that the distribution that I had measured has a name in economic theory. It is called the Pareto distribution, or “power-law distribution.” Deﬁnition 20.1 A distribution, FX(x), such that FX(x)=P{X>x}=x−α,forx≥1, where 0<α< 2is called a Pareto(α)distribution . Question: What is the failure rate of the Pareto distribution? Answer: F(x)=P{X>x}=x−α,x≥1 ⇒F(x)=P{X<x}=1−x−α,x≥1 ⇒f(x)=dF(x) dx=αx−α−1,x≥1 ⇒r(x)=f(x) F(x)=αx−α−1 x−α=α x,x≥1. Notice that/integraltext∞ 1f(x)dx=/integraltext∞ 1αx−α−1dx=1,s of(x)is a valid probability distri- bution. Because r(x)=α xdecreases with x, the Pareto distribution has decreasing failure rate (DFR). Thus the older a job is (the more CPU it has used up so far), the greater its probability of using another second of CPU. 20.4 the bounded pareto distribution 353 Question: For a Pareto with α≤1, what are the mean and variance of the distribution? Answer: The calculations are straightforward, by integration over the density function. If0<α≤1, E[Lifetime ]=∞ E[ith moment of Lifetime ]=∞,i=2,3,... E[Remaining Lifetime |age=a>1] =∞. Question: How do these answers change when αis above 1? Answer: Both the expected lifetime and the expected remaining lifetime are now ﬁnite. Higher moments of lifetime are still inﬁnite. Question: Under the Pareto distribution with α=1, what is the probability that a job of CPU age alives to CPU age b, where b>a ? Answer: P{Life>b|Life≥a>1}=1/b 1/a=a b. Using this expression, for the Pareto (α=1 ) distribution, we can interpret the distri- bution in the following way: rOf all the jobs currently of age 1sec, half of those will live to age ≥2sec. rThe probability that a job of age 1sec uses >T sec of CPU is1 T. rThe probability that a job of age Tsec lives to be age ≥2Tsec is1 2. 20.4 The Bounded Pareto Distribution When we look for a curve ﬁt to the measured data , we observe that the measured data have a minimum job lifetime and a maximum job lifetime. Thus the measured data have all ﬁnite moments. To model the measured data, we therefore want a distribution with a Pareto shape, but truncated on both ends. We refer to such a distribution as aBounded Pareto distribution. Deﬁnition 20.2 TheBounded Pareto (k, p, α )distribution has density function f(x)=αx−α−1·kα 1−/parenleftBig k p/parenrightBigα, fork≤x≤pand0<α< 2. We often write BP(k,p,α )for short. The factorkα 1−(k/p)αin Deﬁnition 20.2 is a normalization factor needed to make the integral of the density function between kandpcome out to 1. For the Bounded Pareto distribution, obviously all of the moments are ﬁnite.",3405
20.7 Pareto Distributions Are Everywhere,"354 tales of tails: a case study of real-world workloads For the UNIX job sizes that I measured, the squared coefﬁcient of variation, C2,w a s ﬁnite, ranging between C2=2 5 andC2=4 9 . This may seem like a very high level of variability, but computer workloads today exhibit even higher squared coefﬁcients of variation. 20.5 Heavy Tails The following are three properties of the Pareto distribution: 1. Decreasing failure rate (DFR) — The more CPU you have used so far, the more you will continue to use. 2. Inﬁnite or near-inﬁnite variance 3. Heavy-tail property — A minuscule fraction of the very largest jobs comprise half of the total system load. For example, when α=1.1, the largest 1 percentof the jobs comprise about1 2of the load. (Note that this is much more biased than the often quoted 80–20 rule.) The last property, which we call the “heavy-tail property,” comes up in many othersettings. For example, in economics, when studying people’s wealth, it turns out thatthe richest 1 percentof all people have more money between them than all the remaining 99 percent of us combined. The heavy-tail property is often referred to as “a few big elephants (big jobs) and many, many mice (little jobs),” as illustrated in Figure 20.4. For comparison, in an Exponential distribution with the same mean, the largest 1 percentof the jobs comprise only about 5 percentof the total demand. Figure 20.4. Heavy-tail property: “Elephants and mice.” The parameter αcan be interpreted as a measure of the variability of the distribution and the heavy-tailedness: α→0yields the most variable and most heavy-tailed dis- tribution, whereas α→2yields the least variable and least heavy-tailed distribution. These properties are explored in more depth in the exercises. These properties largely hold for the Bounded Pareto distribution as well as the Pareto, although clearly the Bounded Pareto cannot have pure DFR, because there is an upperbound on job size. 20.6 The Beneﬁts of Active Process Migration Now, let’s return to the original question of CPU load balancing. Question: What does the DFR property of the Pareto distribution tell us about whether it pays to migrate older jobs? 20.7 pareto distributions are everywhere 355 Answer: DFR says that older jobs have higher expected remaining lifetimes. This leads us to think that it may pay to migrate oldjobs. Although an old job may have a high migration cost because it has accumulated a lot of state (memory), if the job is really old then it has a high probability of using a lot more CPU in the future. This meansthat the cost of migration can then be amortized over a very long lifetime, as the job gets to spend its long remaining lifetime running on a lightly loaded machine. Question: What does the heavy-tail property of the Pareto distribution tell us? Answer: By the heavy-tail property, it may only be necessary to migrate the 1 percentbiggest jobs, because they contain most of the work. However, it is not clear which jobs are “old enough” as a function of their migration cost. The confusion comes from the fact that for a Pareto distribution with α≤1,all jobs (regardless of age) have the same expected remaining lifetime, namely ∞. Does this mean all jobs are “old enough” to make them worth migrating? The difﬁculty in working with distributions with inﬁnite moments is coming up with a modeling approach that gets around all the inﬁnities. We need some criterion to determine if a job is “old enough.” This criterion should take into account the job’s age and its migration cost, as well as the difference in load at the source and target host. Allen Downey (a fellow grad student) and I developed such a criterion, based on the Pareto job size distribution. The trick for getting around the “inﬁnities” was to lookat the expected slowdown of a job, rather than its expected response time (recall that the slowdown of a job is its response time normalized by its size). In experimentsinvolving networks of workstations, we showed that active process migration, basedon our criterion, ends up migrating fewer than 4 percentof jobs, while vastly reducing mean slowdown when compared with remote execution. We will not spend time discussing the criterion here, but if you are intrigued at this point, we encourage you to read the paper [ 85]. 20.7 Pareto Distributions Are Everywhere It is not just UNIX jobs that ﬁt a heavy-tailed Pareto distribution. Pareto job size distributions are everywhere. Here are some more practical and interesting stories. Around 1996–98, Mark Crovella, Azer Bestavros, and Paul Barford at Boston Univer- sity were measuring the sizes of ﬁles at websites. They found that these sizes had a Pareto distribution with α≈1.1. They also found similar results for the sizes of ﬁles requested from websites. Their SURGE web workload generator is based on these ﬁndings [ 14,47,48]. Around this same time, the three Faloutsos brothers were observing a similar distri- bution when looking at the Internet topology. They observed, for example, that most nodes have low out-degree, but a very few nodes have very high out-degree, and the dis-tribution of the degrees follows a Pareto distribution. This and other observations werepublished in their beautiful 1999 paper that won the Sigcomm Test of Time award [ 54]. 356 tales of tails: a case study of real-world workloads In 1999, Jennifer Rexford, Anees Shaikh, and Kang Shin at AT&T were working on routing IP ﬂows to create better load balancing. They did not want to have toreroute all ﬂows because the overhead would be too high. Ideally, they wanted to have to reroute only 1 percentof the IP ﬂows. Would that be enough? Fortunately, their measurements showed that the number of packets in IP ﬂows follows a heavy-tailed Pareto distribution. Consequently, the 1 percentlargest IP ﬂows (those with the most packets) contain about 50 percent of the bytes in all ﬂows. Thus by rerouting only 1 percent of the ﬂows, they were able to redistribute half the load. Their paper appeared in Sigcomm 99 [ 166] and generated a large group of follow-up papers dealing with sampling methods for how to detect which ﬂows are large, based on using the DFR property and the knowledge of how many packets the ﬂow has sent so far. Around this same time, my students and I, in collaboration with Mark Crovella at Boston University, started a project called SYNC (Scheduling Your Network Connections).The goal was to improve the performance of web servers by changing the order inwhich they scheduled their jobs to favor requests for small ﬁles over requests for largeﬁles. Clearly favoring requests for small ﬁles over large ones would decrease meanresponse time. However people had not tried this in the past because they were afraidthat the requests for large ﬁles would “starve” or at least be treated unfairly compared torequests for small ﬁles. Using the heavy-tail property of web ﬁle sizes, we were able toprove analytically and in implementation that this fear is unfounded for the distributionof web ﬁles. The crux of the argument is that, although short requests do go aheadof long requests, all those short requests together make up very little load (more thanhalf the load is in the top 1 percent of long requests) and hence do not interfere noticeablywith the long requests [ 12,46,92]. In 2004, Ernst Biersack, Idris Rai, and Guillaume Urvoy-Keller extended the SYNC results to TCP ﬂow scheduling by exploiting theDFR property of the Pareto distribution to discern which ﬂows have short remainingduration [ 144,142]. There are many, many more examples of the Pareto distribution in measured distri-butions involving jobs created by humans. Wireless session times have been shown to follow a Pareto distribution [ 22]. Phone call durations have been shown to follow a distribution similar to a Pareto. Human wealth follows a Pareto distribution. Natu- ral phenomena too follow Pareto distributions. For example, John Doyle at Caltechhas shown that the damage caused by forest ﬁres follows a Pareto distribution, withmost forest ﬁres causing little damage, but the largest few forest ﬁres causing themajority of the damage. The same property holds for earthquakes and other naturaldisasters. Given the prevalence of the Pareto distribution, there has been a great deal of research interest in why the Pareto distribution comes up everywhere. Ideally, we would like to prove something similar in nature to the Central Limit Theorem, which explains the ubiquity of the Normal distribution, but this time for the Pareto distribution. We donot have room to delve into the many theories proposed for the origin of the Paretodistribution (e.g., the HOT theory [ 37]). To date, this is still an open research problem of great practical importance.",8775
20.8 Exercises,"20.8 exercises 357 20.8 Exercises 20.1 Simulation of M/BP/1 In this problem you will simulate a single FCFS server, where jobs arrive according to a Poisson process with rate λ, and job sizes are distributed according to a Bounded Pareto distribution, BP(k,p,α ), with mean 3,000. We will experiment with two values of α:α=1.5(high variability and heavier tail) and α=2.9(low variability and light tail).1Fixp=1 010, and set k appropriately so as to keep the mean steady at 3,000 (for example, when α=1.5you want k≈1,000, and when α=2.9you want k≈1,970). Now setλappropriately to create a server utilization of ρ=0.8. Your goal is to measure the mean time in the queue, E[TQ]. You will do this by averaging independent samples. Let one “run” of the simulator consist of running the system from empty state for ﬁfty thousand arrivals and then recording the time in queue experienced by arrival number 50,001. You will perform n(independent) runs, each of which will generate one sample and then you will determine the mean of the nsamples. For each of the two values of α: (a) Perform n=5,000runs of the simulator. Let X1,X2,...,X ndenote the nsamples you obtain for TQ. Determine the sample mean, SM: SM=X1+X2+···+Xn n Determine the sample variance, SV, via the following well-known formula: SV=1 n−1n/summationdisplay i=1(Xi−SM)2 (b) Compute the “true” E[TQ]andVar(TQ)using the following formulas (these will be proven in Chapter 23) for the M/G/1 queue, where Sdenotes the job size, which is in this case two instances of a Bounded Pareto: E[TQ]=ρ 1−ρ·E[S2] 2E[S](20.1) Var(TQ)=(E[TQ])2+λE[S3] 3(1−ρ)(20.2) Compare your results with the sample mean and sample variance. (c) For the lower αcase, it will likely turn out that your analytically derived values for E[TQ]and Var(TQ)are much higher than your measured (simulated) values. Why is this? (d) Why did we ask you to make each run consist of so many arrivals before taking a sample point? For example, why couldn’t you just have used 1,000 arrivals in each run? 1When the αparameter is this high, the distribution is often no longer considered to be Pareto because the tail is so light. 358 tales of tails: a case study of real-world workloads 20.2 The Heavy-Taile Property We explore three distributions for job size: (1) Exponential distribution with mean 3,000 (2) Bounded Pareto distribution BP(k=.0009,p=1 010,α=0.5)with mean 3,000 (3) Bounded Pareto distribution BP(k= 332 .067,p=1 010,α=1.1)with mean 3,000 In each case, compute the fraction of load made up by just the top 1 percentof all jobs. Also report the size cutoff xdeﬁning the top 1 percentof jobs. It is easiest to use a symbolic math package to do this calculation. 20.3 Why It Is So Hard to Simulate the Bounded Pareto This problem will illustrate why it is so hard to correctly generate instances of the Bounded Pareto. To generate instances of BP(k,p,α ), we follow the usual Inverse-Transform procedure, obtaining x=k/parenleftbigg 1+u/parenleftbigg/parenleftbiggk p/parenrightbiggα −1/parenrightbigg/parenrightbigg 1 α where xis an instance of BP(k,p,α ), anduis an instance of Uniform(0,1). This formula is correct except that uis not really an instance of Uniform (0,1), because the UNIX random number generator function rand() actually re- turns integers between 0and231−1. Thus uis actually an instance of Uniform (0,1−2−31). Close enough, right? We will see ... Table 20.1 shows different Bounded Pareto distribution parameters. Fill in the blank entries for this table. In particular, for the column pActual, ﬁll in the actual maximum value possible, given that uis never higher than 1−2−31.U s e pActual to compute C2 Actual for the Bounded Pareto that is actually generated, as compared with C2 Theory , the value we should have obtained if we had used pTheory . AspTheory gets higher, what do you notice about C2 Actual as compared with C2 Theory ? Table 20.1. Theory versus what is actually generated kp Theory αE[XTheory]C2 Theory pActualE[XActual]C2 Actual 0.297 1031.4 1 0.290 1041.4 1 0.287 1051.4 1 0.286 1061.4 1 0.286 1071.4 1",4073
Chapter 21 Phase-Type Distributions and Matrix-Analytic Methods. 21.1 Representing General Distributions by Exponentials,"CHAPTER 21 Phase-Type Distributions and Matrix-Analytic Methods We have seen many examples of systems questions that can be answered by modeling the system as a Markov chain. For a system to be well modeled by a Markov chain,it is important that its workloads have the Markovian property. For example, if jobsizes and interarrival times are independent and Exponentially distributed, and routingis probabilistic between the queues, then the system can typically be modeled easily using a CTMC. However, if job sizes or interarrival times are distributed according toa distribution that is not memoryless, for example Uniform (0,100) , then it is not at all clear how a Markov chain can be used to model the system. In this chapter, we introduce a technique called “the method of stages” or “the method of phases.” The idea is that almost all distributions can be represented quite accurately by a mixture of Exponential distributions, known as a phase-type distribution (PH). We will see how to represent distributions by PH distributions in Section 21.1. Because PH distributions are made up of Exponential distributions, once all arrival and service processes have been represented by PH distributions, we will be able to model oursystems problem as a CTMC, as shown in Section 21.2. The Markov chains that result via the method of phases are often much more complexthan Markov chains we have seen until now. They typically cannot be solved in closedform. Thus, in Section 21.3, we introduce the matrix-analytic method, a very powerful numerical method that allows us to solve many such chains that come up in practice. 21.1 Representing General Distributions by Exponentials Variance plays a big role in representing general distributions. Deﬁnition 21.1 Thesquared coefﬁcient of variation (SCV) ,C2 X,o fr . v . X,i sg i v e n by C2 X=Var(X) E[X]2=E[X2] E[X]2−1. One can view C2as a normalized variance, because the variance is being scaled down by the square of the mean. Recall that if X∼Exp(μ), thenE[X]=1 μ,Var(X)=1 μ2, andC2 X=1. We will now consider distributions with lower C2and higher C2. 359 360 phase-type distributions and matrix-analytic methods Suppose that we would like to model a service time distribution with C2<1by using Exponential distributions. For example, we might be trying to describe the transmission time of a packet through a wire, which we denote by r.v. T. Although Tmay exhibit some small variability, the distribution of Tis much closer to a Deterministic (constant- valued) distribution, with C2=0, than to an Exponential. Question: How can we mix Exponential distributions to create a Deterministic or near-Deterministic distribution? Hint: Think about putting Exponential distributions in series. Answer: We could model Tas the time to pass through kstages, each requiring Exp(kμ)time, as shown in Figure 21.1. That is, let Ti∼Exp(kμ), where T=T1+T2+T3+···+Tk. Exp(kμ) Exp(kμ) Exp(kμ) Figure 21.1. The time, T, to pass through all kstages has an Erlang-k distribution. Deﬁnition 21.2 IfTis the sum of ki.i.d.",3049
Chapter 21 Phase-Type Distributions and Matrix-Analytic Methods. 21.1 Representing General Distributions by Exponentials,"Exponential random variables, then T is said to have an Erlang-k distribution. A generalized Erlang distribution (also called a Hypoexponential distribution) is a sum of Exponential random variables with different rates. Question: What are E[T],Var(T), andC2 Tfor Figure 21.1? Answer: E[T]=k·1 kμ=1 μ. Var(T)=k·Var(Single Stage )=k·/parenleftbigg1 kμ/parenrightbigg2 =1 k·1 μ2. C2 T=Var(T) E[T]2=1 k. Question: What happens to Task→∞ ? Answer: Ask→∞ ,C2 T→0, andTconverges to the Deterministic distribution of value1 μ. Thus with an inﬁnite number of Exponential phases (or stages), we can approach aDeterministic distribution. The important point is that, given any mean E[T]=1 μand 21.1 representing general distributions by exponentials 361 C2 Tof the form of C2 T=1 k, for some integer k>1, one can construct an Erlang-k distribution matching that given E[T]and that C2 T. In the same way that an Erlang-k distribution is useful for approximating distributions withC2<1, we can also deﬁne a mixture of Exponentials that is useful for approxi- mating distributions with C2>1. For example, it is well known that the time to serve web requests has high variability [ 47]. IfTrepresents the time to serve a web request, we might have E[T]=1 seconds and C2 T=2 5 . Question: How do we create a distribution with C2>1using Exponential stages? Answer: Rather than putting the Exponential stages in series, we instead view these “in parallel,” as shown in Figure 21.2. 1–p p 2Exp(1) Exp(2) Figure 21.2. Hyperexponential distribution. Deﬁnition 21.3 IfTis distributed as Exp (μ1)with probability pand is distributed as Exp (μ2)with probability 1−p, then we say that Tfollows a Hyperexponential distribution, denoted by H2. T∼/braceleftbiggExp(μ1) with probability p Exp(μ2) with probability 1−p This is also sometimes referred to as a 2-phase Hyperexponential. If there are k>2 phases, where Tis distributed as Exp (μi)with probability pi,f o r1≤i≤k, then we say that Tfollows a k-phase Hyperexponential distribution, denoted by Hk. Observe that the Hyperexponential distribution has three parameters: μ1,μ2, andp. Thus it seems reasonable that, given a mean and a C2value, we should be able to ﬁnd some setting of the parameters of the Hyperexponential to match them. It turns out that the (2-phase) Hyperexponential distribution sufﬁces to match any mean and C2, provided C2>1; see [ 152]. It can even be used to match 3 moments of a distribution, provided that the third moment is sufﬁciently high; see [ 185]. (One can express each of 3 moments of Tas an equation involving the 3 parameters. This system of 3 equations and 3 parameters often has a solution.) However, the Hyperexponential is not usefulfor the case of C2<1. To gain some intuition for why the Hyperexponential is good at representing high- variability distributions, let us analyze the simple case of a Degenerate Hyperexpo- nential distribution, where one of the phases is identically zero: T∼/braceleftbiggExp(pμ) with probability p 0 with probability 1−p 362 phase-type distributions and matrix-analytic methods Question: What is E[T]?",3103
Chapter 21 Phase-Type Distributions and Matrix-Analytic Methods. 21.1 Representing General Distributions by Exponentials,"Answer: E[T]=p·1 pμ=1 μ. Question: What is C2 T? Answer: E/bracketleftbig T2/bracketrightbig =p·2/parenleftbigg1 pμ/parenrightbigg2 . Var(T)=E/bracketleftbig T2/bracketrightbig −(E[T])2=p·2/parenleftbigg1 pμ/parenrightbigg2 −/parenleftbigg1 μ/parenrightbigg2 =2−p p·/parenleftbigg1 μ/parenrightbigg2 . C2 T=2−p p=2 p−1. Observe that by deﬁnition C2 T>1. As the value of pdecreases, the value of C2 T increases. The important point is that, given anymeanE[T]=1 μand any C2 T≥1, we can ﬁnd a Degenerate Hyperexponential to match that mean and C2 T(by setting p= 2/(C2 T+1 ) ). Question: Does the (non-degenerate) Hyperexponential distribution have increasing failure rate or decreasing failure rate or neither? Hint: There is an easy way to argue this intuitively without doing any derivations. Answer: In Exercise 21.5, we will prove that the failure rate is decreasing, by going back to the original deﬁnition of failure rate. Here is a more intuitive argument: Imagine thatTis distributed Hyperexponentially with 2 branches, where μ1>μ 2. The longer Thas lasted so far, the greater the probability that we are in the μ2branch, and thus the greater the probability that Twill last even longer. Thus far we have seen how to model distributions with C2<1, with an Erlang distribution, and distributions with C2>1, with a Hyperexponential distribution. By combining these ideas of phases in series and phases in parallel, we can represent (almost) any distribution. A phase-type distribution (PH) denotes the most general mixture of Exponential dis- tributions in series and parallel. Deﬁnition 21.4 Ak-phase PH distribution with parameters (/vectora,T)is the distribu- tion of time until absorption in the following (k+1 ) -state CTMC: rStates 1through kare transient, and state 0is absorbing. r/vectora=(a0,a1,...,a k)where aidenotes the probability that the starting state isi, and/summationtextk i=0ai=1. rTis ak×(k+1 ) rate transition matrix from states {1,2,...,k}to {0,1,...,k}, where Tij=μijis the rate of moving from state ito state j, where i/negationslash=j. There is no transition out of state 0, and none from a state back to itself. 21.1 representing general distributions by exponentials 363 µ12 µ23 µ30 µ32 µ31µ13 µ21µ20µ10a0 a3 a2 a11 2 3 0 Figure 21.3. A 3-phase PH distribution is the time until absorption in this CTMC, where the initial state is chosen according to probability vector /vectora=(a0,a1,a2,a3). An illustration of a 3-phase PH distribution is given in Figure 21.3. The power of PH distributions lies in the fact that they are dense in the class of all non- negative distribution functions. Practically speaking, this means that a PH distributionwith a sufﬁcient number of phases can approximate any non-negative distributionarbitrarily closely (see [ 8], Theorem 4.2). A k-phase PH distribution has more than k2parameters. It is not obvious that one needs so many parameters to be able to well approximate arbitrary distributions. The class of Coxian distributions is still dense in the class of non-negative distribution functions [153,154], yet Coxian distributions have many fewer parameters (they are a subset of the PH distributions). A k-stage Coxian distribution, depicted in Figure 21.4, looks similar to an Erlang-k, except that there are probabilities of stopping after each stage. Exp(μ1) Exp(μ2) Exp(μk)a0 b0 b1 b2 bk–1a1 a2 ak–1 Figure 21.4. Ak-stage Coxian distribution. The ai’s and bi’s are probabilities, where ai+bi=1,∀i. In general, modeling an arbitrary distribution as a Coxian distribution is non-trivial, but doable. It is very common for researchers to match the ﬁrst 3 moments of a given distribution using a 2-phase Coxian distribution, see Section 21.6. This allows us to represent problems involving general distributions via Markov chains, which we can often solve. We will see this in the next section. Remark: The fact one can match the several moments of a distribution by a Coxian or PH distribution does not always mean that one has truly “captured” the character of the distribution, particularly its tail behavior, P{X>t}. The question of how to best characterize a distribution using Exponential phases is still part of ongoing debate.",4204
21.2 Markov Chain Modeling of PH Workloads,"364 phase-type distributions and matrix-analytic methods 21.2 Markov Chain Modeling of PH Workloads In this section we consider four simple examples of using Markov chains to model PH workloads. We defer discussion of how to solve these Markov chains to Section 21.3. Markov Chain for M/E 2/1 Consider a single FCFS queue, with Poisson arrivals of rate λ, where the service times follow an Erlang-2 distribution. Speciﬁcally, the mean job size is1 μ, and a job’s service requires ﬁrst passing through an Exp (μ1)hurdle and then passing through an Exp (μ2) hurdle, where μ1=μ2=2μ. Question: What do we need to track in the state space? Answer: Observe that, because the service order is still FCFS, only the earliest arrival can be serving. Assuming there is at least one job in the system, the job at the head of the queue is in either phase 1or phase 2. The other jobs are waiting in the queue. Thus a reasonable choice of state space is (i,j)where iindicates the number of jobs that are queueing (not serving) and jtakes on value 1or2, depending on whether the job in service is in phase 1or phase 2. Figure 21.5 shows the resulting Markov chain. μ2 μ1 μ2 μ1 μ2 μ1 μ1λλλ μ21,1 3,1 λ2,1 0,0 λλλ0,1 0,2 1,2 2,2 3,2 Figure 21.5. Markov chain for M/E 2/1, with average arrival rate λand average service rate μ. State(i, j)indicates that there are ijobs waiting in the queue and the job in service (if there is one) is in phase j. Throughout μ1=μ2=2μ. Markov Chain for M/H 2/1 Next consider a single-server FCFS queue, with Poisson arrivals of rate λ, where the service times follow a Hyperexponential distribution. Speciﬁcally, with probability p, a job will require Exp (μ1)service, and with probability 1−pthe job will require Exp(μ2)service. Question: What should the Markov chain look like? Hint: It is tempting to assign the job size at the time that the job arrives. What is the problem with doing this? Answer: If we assign the job size at the time that it arrives, then for every job in the queue we need to track whether it has size Exp (μ1)or Exp (μ2). Thus, it is wiser to hold off determining the job’s size until it is about to serve. Only when a job ﬁnishes serving is the size of the next job determined. 21.2 markov chain modeling of ph workloads 365 Question: What then is the state space? Answer: One reasonable choice is to again use (i, j), where idenotes the number of jobs in the queue (not serving) and jdenotes that the job in service (assuming there is one) has size Exp (μj). The resulting chain is shown in Figure 21.6. λλλ λλλ μ2(1–p μ ) 2(1–p μ ) 2(1–p)μ2p μ2p μ2pμ1(1–p μ ) 1(1–p μ ) 1(1–p) μ2μ1 λ(1–p)μ1p μ1p μ1p1,1 3,1λp2,1 0,0 1,2 0,2 2,2 3,20,1 Figure 21.6. Markov chain for M/H 2/1, with average arrival rate λ. State (i, j)indicates that there are ijobs waiting in the queue and the job in service (if there is one) has size Exp (μj). Markov Chain for E 2/M/1 Sometimes it is the arrival process, not the service process, that is non-Markovian. The E 2/M/1 queue is a single-server FCFS queue where job sizes are distributed as Exp(μ), but the interarrival times between jobs follow an Erlang-2 distribution. The mean interarrival time is1 λ; hence the rate of each phase of the Erlang-2 is 2λ. Question: What should the Markov chain look like? Answer: The key is to realize that the time until the next arrival involves two phases (two hurdles), and a second arrival cannot begin until both those hurdles have completed. That is, two arrivals cannot be “in progress” at the same time. The resulting state space is therefore (i,j), where now idenotes the number of jobs in the system (including the job in service) and j∈{1,2}denotes the phase of the arrival in progress. The resulting chain is shown in Figure 21.7. μμμμλ1 μμμ1,2 0,2 2,2 3,2 1,10,1 2,1 3,1 4,1λ1 λ2 λ1 λ2 λ1 λ2 λ2 Figure 21.7. Markov chain for E 2/M/1 with average arrival rate λand service rate μ. State (i, j)indicates that there are ijobs in the system, including the job in service, and jdenotes the phase of the arrival in progress. The top row indicates that there is an arrival in progress that has just completed phase 1and is trying to complete phase 2. The bottom row indicates that there is an arrival in progress that is still trying to complete phase 1. Throughout λ1=λ2=2λ.",4289
21.4 Analysis of Time-Varying Load,"366 phase-type distributions and matrix-analytic methods Markov Chain for M t/M/1 Another example of a queue with a non-Markovian arrival process is the case of a time-varying arrival rate, where the arrival rate ﬂuctuates between λH(some high rate) and λL(some low rate), spending Exp (αH)time in the high arrival rate regime and Exp (αL)time in the low arrival rate regime, as depicted in Figure 21.8. Time- varying load is denoted by M t. The notation M t/M/1 indicates that the arrival rate changes over time. The notation M/M t/1 indicates that the service rate changes over time. λHλH λLλLExp( αH) Exp( αH) Exp( αL) Exp( αL) Figure 21.8. The arrival process is called a Markov-modulated Poisson process. Question: What should the Markov chain look like for the M t/M/1? Answer: We need to track whether the system as a whole is operating in the high-load phase or the low-load phase. We use the upper (respectively, lower) row of the chain to denote that the system is in the high load (respectively, low load) phase. The resultingMarkov chain is shown in Figure 21.9. λLλLαLαHαLαHαLαLαHαHλHλHλH λLμμ μ μμ μ0H1H2H3H 3L2L1L0L Figure 21.9. Markov chain for M t/M/1, where the arrival rate oscillates between λHfor Exp(αH)duration and λLfor Exp (αL)duration. The state indicates the number of jobs in the system, and the superscript indicates the current regime. 21.3 The Matrix-Analytic Method Consider the inﬁnite-state Markov chains from Section 21.2. These look like the random walk of the M/M/1; however, rather than having just one row, they have two rows – and possibly more than two rows if more than two phases are used in the PH distribution. If we attempt to write out the balance equations for these chains, we 21.4 analysis of time-varying load 367 quickly see that they are quite complex, and there is no obvious “guess” for the limiting distribution. Developed by Marcel Neuts [ 129,130], matrix-analytic methods are approximate numerical methods for solving Markov chains where the chains (i) repeat (after some point) and (ii) grow unboundedly in no more than one dimension. In particular, matrix-analytic methods can be used to solve all the chains we have seen in Section 21.2.A l l these chains grow unboundedly in one dimension (increasing number of jobs), yet they have only a ﬁnite number of states (two, in all the examples we have seen) in the otherdimension, and they all repeat. By saying that matrix-analytic methods are “numericalmethods,” we mean that they do not provide a closed-form symbolic solution, in termsof λ’s and μ’s, but rather we can only solve an instance of the chain (where the rates are all numbers). The solution is obtained by iteration, and there is an error associated with the solution. In practice, the number of iterations is not too large, allowing the solution of chains such as those in Section 21.2 to be obtained within seconds. Also in practice the error is quite small, except for very unusual PH distributions with highly unbalanced rates, created for example by modeling workloads with extremely high C2 values in the thousands.",3094
21.4 Analysis of Time-Varying Load,"The remainder of this chapter serves as a very brief introduction to matrix-analytic methods. For a more comprehensive treatment, we refer the reader to [ 115]. 21.4 Analysis of Time-Varying Load Our ﬁrst illustration of matrix-analytic methods is the M t/M/1 queue, shown earlier in Figure 21.8. This is a particularly nice example, because the repetition starts right from the beginning. 21.4.1 High-Level Ideas We think of the M t/M/1 chain as being divided into levels. Level 0consists of the states 0Hand0L. Likewise, level iconsists of the states iHandiL. In the same way that for the M/M/1 we sought πi, we now seek /vectorπi, where /vectorπi=(πiH,πiL). The high-level idea behind matrix-analytic methods is that we recursively express /vectorπi in terms of /vectorπi−1. However, rather than being related by a constant, ρ, as in the M/M/1, they are instead related by a matrix R, such that /vectorπi=/vectorπi−1·R, which, when expanded, yields /vectorπi=/vectorπ0·Ri. 368 phase-type distributions and matrix-analytic methods Finding this matrix Rrequires solving a matrix equation by iteration. Note that through- out, we still denote the limiting distribution by /vectorπ, where /vectorπis the vector of all limiting probabilities. In the case of the M t/M/1, /vectorπ=(π0H,π0L,π1H,π1L,π2H,π2L,...). 21.4.2 The Generator Matrix, Q To illustrate the method, it is useful to start by rewriting the balance equations in terms of a “generator matrix,” Q. This is a matrix such that /vectorπ·Q=/vector0 where /vectorπ·/vector1=1. (21.1) Here/vectorπis the limiting distribution, and /vector1is always an appropriately sized vector of 1s. Question: Try to write down Qfor the case of an M/M/1, just to get the feel of it. Answer: Q=⎡ ⎢⎢⎢⎢⎣0 123 ··· 0−λλ 1μ−(λ+μ) λ 2 μ−(λ+μ) λ 3 μ−(λ+μ) ··· ... μ...⎤ ⎥⎥⎥⎥⎦. Equation ( 21.1) directly translates to the balance equations: 0=π0·(−λ)+π1·μ 0=π0·λ+π1·(−(λ+μ)) +π2·μ 0=π1·λ+π2·(−(λ+μ)) +π3·μ ... Observe that the diagonal entries of Qare all negative and represent the negation of the total rate of leaving the corresponding state. Question: LetQ(∗,i)denote the ith column of Q. What is the value of the dot product /vectorπ·Q(∗,i)? Answer: Each column of Q, when multiplied by /vectorπ, corresponds to a single balance equation. Thus, by deﬁnition, the dot product is 0. Question: Now try to write Qfor the M t/M/1. 21.4 analysis of time-varying load 369 Answer: It helps to recall that /vectorπ=(π0H,π0L,π1H,π1L,π2H,π2L,...). Now, viewing each column as the coefﬁcients of a balance equation, we have Q= ⎡ ⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣0H0L1H1L2H2L··· 0H−/parenleftbig λH+αH/parenrightbig αH/vextendsingle/vextendsingle/vextendsingleλH0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle 0LαL−/parenleftbig λL+αL/parenrightbig/vextendsingle/vextendsingle/vextendsingle0 λL/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle 1Hμ 0/vextendsingle/vextendsingle/vextendsingle−/parenleftbig λH+αH+μ/parenrightbig αH/vextendsingle/vextendsingle/vextendsingleλH0/vextendsingle/vextendsingle/vextendsingle 1L0 μ/vextendsingle/vextendsingle/vextendsingleαL−/parenleftbig λL+αL+μ/parenrightbig/vextendsingle/vextendsingle/vextendsingle0 λL/vextendsingle/vextendsingle/vextendsingle 2H/vextendsingle/vextendsingle/vextendsingleμ 0/vextendsingle/vextendsingle/vextendsingle−/parenleftbig λH+αH+μ/parenrightbig αH/vextendsingle/vextendsingle/vextendsingle 2L/vextendsingle/vextendsingle/vextendsingle0 μ/vextendsingle/vextendsingle/vextendsingleαL−/parenleftbig λL+αL+μ/parenrightbig/vextendsingle/vextendsingle/vextendsingle ···/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle...⎤ ⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦. We can see that this Qmatrix is composed of three 2×2matrices that repeat, plus one2×2matrix that does not repeat: B=/bracketleftbigg(i−1)H(i−1)L iHμ 0 iL0 μ/bracketrightbigg (“Backwards”) i>0 L=/bracketleftbiggiHiL iH−(λH+αH+μ) αH iL αL−(λL+αL+μ)/bracketrightbigg (“Local”) i>0 F=/bracketleftbigg(i+1 )H(i+1 )L iHλH0 iL0 λL/bracketrightbigg (“Forwards”) i≥0 L0=/bracketleftbiggiHiL iH−(λH+αH) αH iL αL−(λL+αL)/bracketrightbigg (“Initial Local”) i=0 We can now write Qmore economically as Q=⎡ ⎢⎢⎣2 222 2|L0F 2|BLF 2| BLF 2| B...⎤ ⎥⎥⎦.",4304
21.4 Analysis of Time-Varying Load,"370 phase-type distributions and matrix-analytic methods Using the notation /vectorπi=(πiH,πiL), we now rewrite the balance equations /vectorπ·Q=/vector0 asmatrix equations : /vector0=/vectorπ0·L0+/vectorπ1·B /vector0=/vectorπ0·F+/vectorπ1·L+/vectorπ2·B /vector0=/vectorπ1·F+/vectorπ2·L+/vectorπ3·B /vector0=/vectorπ2·F+/vectorπ3·L+/vectorπ4·B ... 21.4.3 Solving for R We make the educated guess that /vectorπi=/vectorπ0·Ri,∀i>0 for some matrix R, to be determined, where /vectorπ0=(π0H,π0L)and/vectorπi=(πiH,πiL). Substituting this guess into the matrix equations yields the following: /vector0=/vectorπ0·L0+/vectorπ0·RB ⇒ /vectorπ0(L0+RB)=/vector0 /vector0=/vectorπ0·F+/vectorπ0·RL+/vectorπ0·R2B⇒/vectorπ0(F+RL+R2B)=/vector0 /vector0=/vectorπ1·F+/vectorπ1·RL+/vectorπ1·R2B⇒/vectorπ1(F+RL+R2B)=/vector0 /vector0=/vectorπ2·F+/vectorπ2·RL+/vectorπ2·R2B⇒/vectorπ2(F+RL+R2B)=/vector0 ... Observe the common portion is: F+RL+R2B=0. We use this common portion to determine Ras follows: F+RL+R2B=0 ⇒RL=−/parenleftbig R2B+F/parenrightbig ⇒R=−/parenleftbig R2B+F/parenrightbig L−1 We now solve for Rby iterating (here Rndenotes the nth iteration of R): 1.LetR0=0(or a better guess, if available). 2.While||Rn+1−Rn||>/epsilon1, SetRn+1=−(R2 nB+F)L−1. This process keeps iterating until it determines that Rhas “converged.” Sadly there is no known closed-form solution for the above matrix quadratic in general; thus iteration is the approach that is used.1OnceRconverges, we set /vectorπi=/vectorπ0Ri. These limiting probabilities satisfy the balance equations. There are several points related to solving for Rthat we have not deﬁned. First, there are several possible deﬁnitions of the metric: ||Rn+1−Rn||. The typical deﬁnition is the maximum of all the elements in the matrix Rn+1−Rn. Thus, while the biggest 1For some special chains Rcan be expressed in closed form; see [ 115]. 21.4 analysis of time-varying load 371 difference exceeds /epsilon1, we continue iterating. Only when all the element-wise differences are smaller than /epsilon1do we stop iterating. Also, the deﬁnition of /epsilon1is unspeciﬁed. We typically start with /epsilon1=1 0−7; however, if convergence is slow, we might try increasing /epsilon1by a factor of 10. This is tricky because small differences in Rcan have a profound effect on the ﬁnal limiting probabilities. 21.4.4 Finding /vectorπ0 The only value remaining is /vectorπ0=(π0H,π0L). We have two equations involving /vectorπ0: First, we have the ﬁrst matrix balance equation listed in Section 21.4.3 : /vectorπ0(L0+RB)=/vector0 (21.2) Second we have the normalizing equation: /vectorπ·/vector1=1 (21.3) Just as we did in the scalar case, we are going to replace one of the balance equations with the normalization equation. We start by rewriting the normalizing equation ( 21.3) in terms of /vectorπ0: ∞/summationdisplay i=0/vectorπi·/vector1=1,where /vector1=( 1 ,1) ∞/summationdisplay i=0/vectorπ0Ri·/vector1=1 /vectorπ0/parenleftBigg∞/summationdisplay i=0Ri/parenrightBigg /vector1=1 /vectorπ0(I−R)−1/vector1=1 (21.4) For notational simplicity, let Φ=L0+RB andΨ=(I−R)−1/vector1. Thus, ( 21.2) becomes /vectorπ0Φ=/vector0and ( 21.4) becomes /vectorπ0Ψ=1. Expanding out /vectorπ0Φ=/vector0to show its components, we have /bracketleftbigπ0Hπ0L/bracketrightbig/bracketleftbigg Φ00Φ01 Φ10Φ11/bracketrightbigg =/bracketleftbig00/bracketrightbig . After replacing one balance equation (one column) with the normalizing equation, we get: /bracketleftbigπ0Hπ0L/bracketrightbig/bracketleftbigg Ψ0Φ01 Ψ1Φ11/bracketrightbigg =/bracketleftbig10/bracketrightbig . This system of equations has a unique solution, and we solve this system for /vectorπ0= (π0H,π0L). Using /vectorπi=/vectorπ0Ri, we now have all the /vectorπi.",3740
21.5 More Complex Chains,"372 phase-type distributions and matrix-analytic methods 21.4.5 Performance Metrics From the limiting probabilities, we now develop a closed-form expression for E[N] in terms of only /vectorπ0andR: E[N]=∞/summationdisplay i=0i·/vectorπi·/vector1 =∞/summationdisplay i=0i·/vectorπ0·Ri·/vector1 =/vectorπ0·∞/summationdisplay i=1i·Ri−1·R·/vector1 =/vectorπ0·d dR/parenleftBigg∞/summationdisplay i=0Ri/parenrightBigg ·R·/vector1(matrix calculus) =/vectorπ0·d dR(I−R)−1·R·/vector1 =/vectorπ0·(I−R)−2·R·/vector1 Similarly, we can deﬁne higher moments of N. To determine E[T], we ﬁrst deﬁne the average arrival rate λavg,b y λavg=1 αHλH+1 αLλL 1 αH+1 αL. Then, via Little’s Law, E[T]=1 λavgE[N]=1 λavg·/vectorπ0·(I−R)−2·R·/vector1. The analysis of the M t/M/1 is discussed further in Exercise 21.2. Question: Suppose that we applied the matrix-analytic method to derive the limiting probabilities for the M/M/1. What would Rlook like? Answer: In this case, Ris just a 1×1matrix, namely a scalar, and does not require iteration to obtain. You will solve for it in Exercise 21.1. 21.5 More Complex Chains Sometimes the repeating portion of a chain only starts after level M. In this case, we can still use matrix-analytic methods to solve the chain. However, the initial ma- trix,L0, must be larger, so as to encompass the entire non-repeating portion of the chain. To illustrate how this works, consider the following example, which we refer to as the M∗/E∗ 2/1. Here the arrival process is Poisson, but the average arrival rate is λwhenever the system is non-empty and is λ/primewhen the system is empty (imagine that the queue is sent additional work from another source when it is empty, as part of a load balancing effort). The job service distribution is a two-phase generalized Erlang, where the ﬁrst 21.5 more complex chains 373 λλλ μ21,1 3,1 λ′2,1 0,0 λλλ0,1 0,2 1,2 2,2 3,2μ2 μ1 μ2 μ1 μ2 μ1 μ1 Figure 21.10. Markov chain for M∗/E∗ 2/1. phase is distributed as Exp (μ1)and the second is distributed as Exp (μ2). We deﬁne the state as (i,s), where iis the number of jobs in queue (not counting any job in service) andsis the phase of the job in service, or 0if there is no job in service. Figure 21.10 shows the CTMC for this system. Question: Deﬁning a1=−(λ+μ1)anda2=−(λ+μ2), express Qusinga1and a2. Answer: Q=⎡ ⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣(0,0) (0 ,1) (0 ,2) (1 ,1) (1 ,2) (2 ,1) (2 ,2) (3 ,1) (3 ,2) ··· (0,0)−λ/primeλ/prime0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle00/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (0,1)0a1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleλ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (0,2)μ20a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0λ/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (1,1)000/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglea1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleλ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (1,2)0μ20/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0λ/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (2,1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle00/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglea1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleλ0/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (2,2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleμ20/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0λ/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (3,1)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle00/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglea1μ1/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle (3,2)/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingleμ20/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle0a2/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle .../vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle...⎤ ⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦ . 374 phase-type distributions and matrix-analytic methods More succinctly, this can be written as Q=⎡ ⎢⎢⎢⎢⎣3 2 222 3|L0F0 2|B0LF 2| BLF 2| BLF 2| B...⎤ ⎥⎥⎥⎥⎦. In this case L0is a3×3matrix, representing the non-repeating portion of the chain. Also observe that we needed to introduce F0andB0which are very similar to F andB, respectively, but have asymmetric dimensions, which are needed to “link” the non-repeating portion of the chain to the repeating portion of the chain. We deﬁne /vectorπ0=/parenleftbig π(0,0),π(0,1),π(0,2)/parenrightbig and/vectorπi=/parenleftbig π(i,1),π(i,2)/parenrightbig ,∀i>0.N o ww e rewrite the balance equations /vectorπ·Q=/vector0as matrix equations: /vector0=/vectorπ0·L0+/vectorπ1·B0 /vector0=/vectorπ0·F0+/vectorπ1·L+/vectorπ2·B /vector0=/vectorπ1·F+/vectorπ2·L+/vectorπ3·B /vector0=/vectorπ2·F+/vectorπ3·L+/vectorπ4·B /vector0=/vectorπ3·F+/vectorπ4·L+/vectorπ5·B ... We now guess that /vectorπM+i=/vectorπM·Ri. (21.5) Question: What is Mhere? Answer: In the time-varying load example from Section 21.4,Mwas0, but for this chain, M=1. Substituting the above guess into the balance equations yields the following matrix equations: /vector0=/vectorπ0·L0+/vectorπ1·B0 /vector0=/vectorπ0·F0+/vectorπ1·L+/vectorπ1·RB /vector0=/vectorπ1·F+/vectorπ1·RL+/vectorπ1·R2B⇒/vectorπ1/parenleftbig F+RL+R2B/parenrightbig =0 /vector0=/vectorπ2·F+/vectorπ2·RL+/vectorπ2·R2B⇒/vectorπ2/parenleftbig F+RL+R2B/parenrightbig =0 /vector0=/vectorπ3·F+/vectorπ3·RL+/vectorπ3·R2B⇒/vectorπ3/parenleftbig F+RL+R2B/parenrightbig =0 ... 21.5 more complex chains 375 The common portion is again F+RL+R2B=0. Thus RL=−(R2B+F) =⇒R=−/parenleftbig R2B+F/parenrightbig L−1. We now solve for Rby iterating: 1.LetR0=0(or a better guess, if available). 2.While||Rn+1−Rn||>/epsilon1, SetRn+1=−(R2 nB+F)L−1. As before, we iterate until Rhas “converged.” All that is left is to determine the initial limiting probabilities. In this case, this means determining both /vectorπ0=/parenleftbig π(0,0),π(0,1),π(0,2)/parenrightbig and/vectorπ1=/parenleftbig π(1,1),π(1,2)/parenrightbig . The “local” portion of the balance equations can be written as /bracketleftbig/vectorπ0/vectorπ1/bracketrightbig/bracketleftbigg L0F0 B0L+RB/bracketrightbigg =/vector0, or equivalently/bracketleftbig/vectorπ0/vectorπ1/bracketrightbig Φ=→ 0where Φ=/bracketleftbigg L0F0 B0L+RB/bracketrightbigg . (21.6) Here/vector0refers to [0,0,0,0,0]. We also have the normalizing equation /vectorπ·/vector1=1 . We again replace one of the balance equations with the normalization equation. Rewriting the normalization equation interms of /vectorπ0and/vectorπ1, /vectorπ0·/vector1+∞/summationdisplay i=1/vectorπi·/vector1=1. /vectorπ0·/vector1+∞/summationdisplay i=0/vectorπ1Ri·/vector1=1. /vectorπ0·/vector1+/vectorπ1/parenleftBigg∞/summationdisplay i=0Ri/parenrightBigg /vector1=1. /vectorπ0·/vector1+/vectorπ1(I−R)−1/vector1=1. Note that the ﬁrst /vector1in each equation above has dimension 3, while the second /vector1has dimension 2. We deﬁne Ψ=/bracketleftbigg/vector1 (I−R)−1·/vector1/bracketrightbigg to be a column vector of size 5.",8515
21.6 Readings and Further Remarks. 21.7 Exercises,"376 phase-type distributions and matrix-analytic methods Then we can write the normalization equation as /bracketleftbig/vectorπ0/vectorπ1/bracketrightbig Ψ=1. To combine the balance equations with the normalization equation, we return to equa- tion ( 21.6), repeated here for easy reference: /bracketleftbig/vectorπ0/vectorπ1/bracketrightbig Φ=[ 0,0,0,0,0],where Φ=/bracketleftbigg L0F0 B0L+RB/bracketrightbigg We replace the ﬁrst column of ΦwithΨ, and the ﬁrst element of the zero vector with 1. We then solve the resulting system of 5 linear equations for (/vectorπ0,/vectorπ1).F r o m( 21.5), we now obtain all the remaining limiting probabilities. 21.6 Readings and Further Remarks Some additional information on phase-type distributions is provided in [ 5], pp. 148– 59. Representing general distributions by phase-type distributions is a very powerful technique. It is often the only technique known for Markov modeling of problems involving general distributions. To make the Markov chain tractable, it is important that the PH representation of these general distributions does not require too many phases ortoo many parameters. There is a great deal of research into ﬁnding PH representationsof general distributions that use few phases and yet accurately represent the givendistribution. We recommend [ 135] and [ 137] as examples of moment matching and [56] as an example of tail ﬁtting. Unfortunately there are not many books that explain matrix-analytic methods. Latouche and Ramaswami [ 115] have an excellent textbook devoted to matrix-analytic methods. The book goes much further than this chapter, explaining the meaning behind the R matrix. The book also discusses convergence properties of the iteration. Matrix-analytic methods are also covered in Nelson’s book [ 127]. One ﬁnal remark: There are situations where matrix-analytic methods break down because higher powers of Rbecome singular. This can happen for a number of reasons, but one condition that induces such behavior is highly variable distributions. Suppose for example that one is studying delay in the M/H 2/2 system. If one chooses H2with C2<100, matrix-analytic methods are excellent for deriving mean delay. However, withC2>1000 , matrix-analytic methods can sometimes break down. 21.7 Exercises 21.1 Applying Matrix-Analytic Methods to the M/M/1 Consider the M/M/1 with arrival rate λand service rate μ. Solve for the limiting probabilities using the matrix-analytic method in this chapter. Speciﬁcally, deriveQ,B,L,F, andR, and then use these to write out the limiting probabilities. 21.7 exercises 377 21.2 Time-Varying Load Consider the M t/M/1 with a mean job size of 1and mean load 0.7, where the arrival rate ﬂuctuates between high-load, 1.2, and low-load, 0.2, with Exp (α) time in each state. Apply the matrix-analytic procedure described in this chapter to determine the mean response time, E[T], for a range of switching rates, α, ranging from very quick alternation to very slow alternation (use a log scale). (a) Create a plot of E[T]versus α. (b) When alternation is very fast (high α), what does your E[T]converge to? Why? (c) When alternation is very slow (very low α), what happens to E[T]?W h y ? (d) Suppose that the arrival rate instead ﬂuctuates between 0.9and0.5with Exp(α)time in each state. Again the mean is 0.7. What should the mean response time look like now in the case when alternation is very slow (verylow α)? Why? Remark: Unfortunately, exact closed-form solutions for the M t/M/1 require solving a cubic, and thus are not straightforward, nor has much been developed in terms of approximations. See [ 78] for additional insights. 21.3 Applying Matrix-Analytic Methods to the M/Cox/1 Use the matrix-analytic method to analyze the M/Cox/1 queue. The arrival process is Poisson( λ). The service time distribution is phase-type with 2 stages, the ﬁrst of duration Exp (μ1)and the second of duration Exp (μ2), where the second stage is only invoked with probability p(with probability 1−p, service completes immediately after the ﬁrst stage). Derive E[N]andE[T]when λ=1,μ1=2,μ2=3, andp=0.4. Here are some steps: (a) Deﬁne a state space. (b) Draw out the Markov chain. (c) Write out the generator matrix Q(it is inﬁnite, so a portion will do). (d) Write out the matrices: F0,L0,B0,F,L,B. [Check: Lshould be a 2×2 matrix.] (e) Write out the balance equations, and make the appropriate guess for the repeating part of the limiting probabilities. (f) Solve for the matrix R. [Check: Rshould be a 2×2matrix.] (g) Use the initial (non-repeating) balance equations together with the normal- ization constraint to solve for the initial limiting probabilities. Remember that these may be vectors. [Check: Compute the probability of there being zero jobs in the system. This should equal 1−ρ≈0.367.] (h) At this point you should have all the limiting probabilities. Use these to compute E[N]andE[T]. 21.4 Effect of Variability in Service Time Create a Hyperexponential distribution, H2, with balanced branches/parenleftBig p μ1=1−p μ2/parenrightBig , ﬁxed mean E[S]=1 , andC2=1 0 . Now use matrix-analytic methods to determine mean response time, E[T], for the M/H 2/1 when the average load is ρ=0.8. Hold ρandE[S]ﬁxed but increase C2.T r yC2=2 0 , 378 phase-type distributions and matrix-analytic methods C2=3 0 ,C2=4 0 , andC2=5 0 . What happens to E[T]? Why do you think this occurs? 21.5 Hyperexponential Distribution: DFR Prove that the H2Hyperexponential distribution has decreasing failure rate (DFR). Derive the failure rate function, r(x)=f(x) F(x), and then take its deriva- tive to show that r(x)is decreasing in x. Also explain intuitively why the Hyperexponential has DFR. 21.6 Variance of Number of Jobs In the same way that we derived a closed-form expression for the mean number of jobs, E[N], in terms of R, we can also write a closed-form expression forVar(N)in terms of R, using a little more matrix calculus. Derive this expression. 21.7 Effect of Variability in Service Time in Multi-Server Systems In this problem we repeat the analysis from Exercise 21.4, except that we deal with a 2-server system. Again create an H2with balanced branches/parenleftbigp μ1=1−p μ2/parenrightbig and ﬁxed mean E[S]=1 andC2=1 0 . This time, use matrix- analytic methods to determine E[T]for the M/H 2/2 when the system load is ρ=0.8. Hold ρandE[S]ﬁxed but increase C2.T r yC2=2 0 ,C2=3 0 , C2=4 0 , andC2=5 0 . What happens to E[T]? Is the effect of increased variability more or less pronounced than for the case of a single server? Give as much intuition as you can for what is going on. There is no known closed-form solution for the mean response time in an M/H 2/2. The best known approximation is due to Lee and Longton [ 118]w h o state that E/bracketleftbig TM/G/k Q/bracketrightbig ≈/parenleftbiggC2+1 2/parenrightbigg E/bracketleftbig TM/M/k Q/bracketrightbig , where Ghere denotes any general distribution, including the H2. How do your results compare to the Lee and Longton approximation? 21.8 Understanding Setup Times The effect of setup times is not well understood in multi-server systems, see[68]. This exercise uses matrix-analytic methods to analyze these systems numerically. Setup times for the M/M/1 were introduced in Exercise 15.10 . We deﬁne a setup time for a multi-server system as follows: When a server goes idle, it immediately shuts off. When a job arrives, it needs to set up a server before itcan use the server. The setup time is denoted by I. If a server, s1, is in setup mode, and another server s2becomes free, then the job waiting for s1is routed tos2. At this point server s1is shut off, unless there is a job in the queue, in which case the queued job takes over waiting for s1. (a) Draw a CTMC for an M/M/1 with setup time, I, where I∼Exp(α). (b) Draw a CTMC for an M/M/1 with setup time, I, where I∼Erlang-2 with mean1 α. (c) Draw a CTMC for an M/M/2 with setup time, I, where I∼Exp(α). 21.7 exercises 379 (d) Draw a CTMC for an M/M/2 with setup time, I, where I∼Erlang-2 with mean1 α. (e) For parts (a) and (c), use matrix-analytic methods to analyze response time, assuming μ=1,α=0.1, andρ=0.5,0.7,0.9. How does setup affect the M/M/2 as compared with the M/M/1?",8219
Chapter 22 Networks with Time-Sharing PS Servers BCMP. 22.1 Review of Product Form Networks. 22.2 BCMP Result,"CHAPTER 22 Networks with Time-Sharing (PS) Servers (BCMP) In Chapter 21, we saw one application for phase-type (PH) distributions: If we need to analyze a system whose workload involves distributions that are non-Exponential (e.g., high-variability workloads), then we can use a PH distribution to at least match2 or 3 moments of that workload distribution. This allows us to represent the systemvia a Markov chain, which we can often solve via matrix-analytic methods. In this chapter we see another application of PH distributions. Here, we are interested in analyzing networks of Processor-Sharing (time-sharing) servers (a.k.a. PS servers).It will turn out that networks of PS servers exhibit product form solutions, evenunder general service times. This is in contrast to networks of FCFS servers, whichrequire Exponential service times. Our proof of this PS result will rely on phase-type distributions. This result is part of the famous BCMP theorem [ 16]. 22.1 Review of Product Form Networks So far we have seen that all of the following networks have product form: rOpen Jackson networks: These assume probabilistic routing, FCFS servers with Exponential service rates, Poisson arrivals, and unbounded queues. rOpen classed Jackson networks: These are Jackson networks, where the outsidearrival rates and routing probabilities can depend on the “class” of the job. rClosed Jackson networks rClosed classed Jackson networks We have also seen (see Exercise 19.3) that Jackson networks with load-dependent service rates have product form. Here the service rate can depend on the number of jobs at the server. This is useful for modeling the effects of parallel processing. Note that all of our results thus far have assumed FCFS scheduling at each server. 22.2 BCMP Result In 1975 Baskett, Chandy, Muntz, and Palacios-Gomez wrote a very famous paper providing a broad classiﬁcation of networks with product form. We describe here asubset of the results in this paper and refer the reader to the original paper [ 16] for full results. 380 22.2 bcmp result 381 The results can be subdivided based on the type of service discipline (scheduling policy) at the servers. The ﬁrst set of results assumes FCFS servers (we are alreadyfamiliar with these). The second set of results assumes either Processor-Sharing (PS)service discipline or one of a few other service disciplines at the servers. 22.2.1 Networks with FCFS Servers For networks with FCFS servers with unbounded queues, BCMP states that prod- uct form solutions exist for open, closed, single-class, and multi-class networks withprobabilistic routing with the following restrictions: Conditions rThe outside arrivals must be Poisson. rThe service times at the servers must be Exponentially distributed. rThe service rate at a server may be load dependent but cannot be class dependent. The BCMP results for the case of networks of FCFS servers are very powerful. They say that, for the purpose of performance evaluation, we can think of the servers asindependent M/M/1 queues.",3038
Chapter 22 Networks with Time-Sharing PS Servers BCMP. 22.1 Review of Product Form Networks. 22.2 BCMP Result,"However, the BCMP requirements (for the case of FCFS servers) are also unrealistic in two ways. First, the fact that the service times must be Exponentially distributed issomewhat restrictive. The second drawback is referred to as “Kleinrock’s independence assumption.” This says that every time a job visits a server, its service time at the server is a newindependent random variable. In particular, a job may visit the same server twice andexperience different service times during the two visits. The issue is that the service time is associated with the server , not with the job.W e need this in order to get product form. If we could at least allow the service rate tobe associated with the class of the job, then we could model the idea of different job sizes (e.g., “small jobs” that have very fast service rates at every server and “big jobs” that have slow service rates at every server). That is, we could maintain the “size” of a job as it moves between servers, so that subsequent visits of a job to the same serverdo not result in different service requirements. But alas, in the case of networks ofFCFS servers, we cannot analyze the model where the service rate depends on the jobclass. Usefulness for Communication Networks Nevertheless, despite the Exponential service rates and the highly unrealistic Klein- rock’s independence assumption, the BCMP results are highly useful for predictingdelays in communication networks. In communication networks, the “jobs” are just 382 networks with time-sharing (ps) servers (bcmp) ﬁxed-size packets (all packets have the same size). Time is only spent when a packet is transmitted on a link. Servers are thus used to model the links leaving a router – one server per outgoing link. The service time of a job at a server corresponds to the packet’s transmission time (the time to put the packet onto the wire). There isan FCFS queue associated with each server, made up of packets waiting to go onto that corresponding link. Note that a job’s “service time” (transmission time for thepacket) is really some constant (depending on the link bandwidth). An Exponentialservice time distribution does a decent enough job of modeling that situation, because the Exponential has somewhat low variability. A Jackson network with Exponential service times actually provides an upper bound (with respect to mean response time)on the same network with constant service times, see [ 81] for a proof. Furthermore, it is especially convenient that we can make the routing of packets be class dependent to represent the fact that certain packets follow one route while other packets followother routes. 22.2.2 Networks with PS Servers The main BCMP results deal with networks where the servers use Processor-Sharing service order. In this case the results are much more powerful. Deﬁnition 22.1 A server with service rate μoperates under Processor-Sharing (PS) service order if, whenever there are njobs at the server, each of the jobs is processed at rateμ n. Under PS scheduling, every job in the queue receives service at all times.",3079
Chapter 22 Networks with Time-Sharing PS Servers BCMP. 22.1 Review of Product Form Networks. 22.2 BCMP Result,"However, the share received by a job depends on how many other jobs are currently present. Question: Give an example of Processor-Sharing in computer systems. Answer: A time-sharing CPU rotates in round-robin order between the njobs in the system, giving the ﬁrst job one quantum, then the second job one quantum, ..., then thenth job one quantum, and then returning back to the ﬁrst job to repeat. If we think of the quantum size as approaching 0, we get PS. Note that under PS there is no cost for switching between jobs, whereas in time-sharing CPUs there is a small overhead for context-switching. Question: Suppose njobs arrive at time 0to a PS server with service rate 1. They each have service requirement 1. At what time do they complete? What is their slowdown? Answer: All jobs complete at time nand have slowdown n. Question: The previous question/answer may make it seem that PS is a poor scheduling policy. When is PS scheduling useful?Answer: PS scheduling is useful when job sizes have high variability. PS prevents short jobs from having to wait behind long jobs, without requiring knowledge of the size of the job a priori. We will learn more about this in Chapter 30. 22.2 bcmp result 383 PS Figure 22.1. PS server To indicate the fact that in a PS server all jobs are being worked on at once, we will often draw the queue as in Figure 22.1. BCMP states that for networks where servers use PS service order, product form solutions exist for open, closed, single-class, or multi-class networks with probabilisticrouting, with the following conditions: Conditions rThe outside arrivals must be Poisson. rThe service times at servers can follow any Coxian distribution . rThe service rate at a server may be load dependent, and the service time distri- bution is also allowed to depend on the class of the job. The last two “conditions” are not actually restrictions. Recall from Chapter 21 that Coxian distributions are dense in the class of non-negative distributions. Hence, givenenough phases, the service time at the servers can approximate any general non-negativedistribution arbitrarily closely. The Processor-Sharing (PS) result is often ignored by most books. This is probably because most books are concerned with communication networks and thus FCFSservers. However, in analyzing networks of workstations, it is much more common thatthe workstations are time-sharing machines, scheduling their jobs in PS order. Thismakes the PS result very important to computer system designers. Why the PS Result is Important The standard weakness in queueing networks is that service time is afﬁliated with the server, not with the job. However, observe that for networks of PS servers, we cancircumvent this drawback: We make the service time afﬁliated with the job by makingthe service time afﬁliated with the class of the job. The job’s class then determines the job’s service time at all servers. Observe that service time can even be a (near) constant dependent on the class. Thus some jobs always have size 1, and some have size2, and some have size 3, etc. We can even go so far as to create a realistic workload distribution by using enough different classes. To take this idea even further, we could use the fact that jobs can change classes to model the notion of a job’s remaining service time increasing based on its service time so far. The possible ideas for networks of PS servers are limitless. Much more research needs to be done on exploiting this fantastic result.",3497
22.4 MCox1PS,"384 networks with time-sharing (ps) servers (bcmp) Outline of the Rest of the Chapter We have discussed why the PS result is so powerful. The rest of this chapter is devoted to proving a small piece of the PS result. To keep from losing the intuition, we derivethe limiting probabilities for only the cases of 1 PS queue and 2 PS queues in tandem, with only a single class of jobs. The proof for the case of kPS queues is very similar to that for the case of 2 PS queues, and we expect the reader to be able to see how to expand the 2-server proof to kservers. Rather than state the general result upfront, we keep the suspense alive by deriving the results one at a time, because the derivations areas beautiful as the results themselves. We refer the reader to the BCMP paper [ 16]f o r a description of the full product form formulas in the case of multi-classed networks and the case of class-dependent service rates. Remark: The BCMP paper [ 16] describes many results that we will not be proving. For example, the results for the PS service discipline are extended to the Preemptive- Last-Come-First-Served (PLCFS) service discipline. Under PLCFS a running job isalways preempted by the last job to arrive. Surprisingly, PLCFS exhibits product formas well, and the proofs are similar in style to the proofs we present for PS service order.We will not study the PLCFS service order until Chapter 30. The BCMP results also allow for service stations with an inﬁnite number of servers (no delay). The BCMPpaper also allows for mixing different types of servers – for example, both PS and FCFS servers – within the same network. 22.3 M/M/1/PS Before we discuss Coxian service times, it is instructive to start by considering Ex- ponentially distributed service times and see what we can say about the M/M/1/PSqueue. Consider a single M/M/1/PS queue with arrival rate λand service rate μ. The server services jobs in PS order; namely, when there are njobs at the server, each is being serviced with rate μ/n. Question: What is the limiting probability of there being njobs in the M/M/1/PS queue? How does your answer compare with that of an M/M/1/FCFS server? Hint: This may seem like a really hard problem. The trick is to model the M/M/1/PS queue via a CTMC. Answer: Figure 22.2 describes the CTMC for M/M/1/PS. States represent the number of jobs at the server. The arrival rate at each state is λ, so the forward transitions are Figure 22.2. CTMC for M/M/1/PS. 22.4 m/cox/ 1/ps 385 clear. To understand the backward transitions, suppose that the chain is in state i. The rate at which an individual job gets serviced in state iisμ/i, because the server is shared among the ijobs. However, because all ijobs are running, the rate at which some job completes is i·(μ/i)=μ(recall that the minimum of iExponentially distributed random variables is still Exponentially distributed with rate equal to the sum of their rates). So, given that the CTMC is in state i, the rate of moving to state i−1isμ. Thus this CTMC looks exactly like the regular M/M/1/FCFS.",3057
22.4 MCox1PS,"We already know how to solve this chain: πn=P{njobs at server }=ρn(1−ρ). 22.4 M/Cox/1/PS Now consider a single M/Cox/1/PS server. A general k-phase Coxian distribution is shown in Figure 22.3, where the pi’s are probabilities. We simplify the computation by just doing the analysis for an abridged 2-phase Coxian service distribution, asshown in Figure 22.4, because the idea is the same as you increase the number of phases. 1–p1 1–p2 1–p3p1 p0 p3 p2 pk–1μ1 μ2 μk μ3 λ 1–p0 Figure 22.3. Service time is Coxian with kphases. In the abridged Coxian distribution with 2 phases, each job independently must ﬁrstcomplete phase 1 and then, with probability p, must complete phase 2. However, this is a PS server, not a FCFS server. Thus there is no queue, and all jobs are actuallyserving at once (they are all in the gray region). Speciﬁcally, there may be several jobs λ 1–pp μ1 μ2 Figure 22.4. Service time is abridged Coxian distribution with 2 phases. 386 networks with time-sharing (ps) servers (bcmp) working on completing phase 1, and there may be several others working on completing phase2. We deﬁne the state of our system to be (n1,n2), where n1represents the number of jobs currently in phase 1andn2represents the number of jobs currently in phase 2. We deﬁne πn1,n2to be the probability of the server being in state (n1,n2). The way to picture this is to imagine a professor with ngraduate students. Each of her students is in one of two phases of graduate school – the “quals” phase, where thestudent is preparing for qualiﬁer exams, which takes time Exp (μ1), and the “thesis” phase, where the student is writing a thesis, which takes time Exp (μ2). At any moment of time the professor has n1students simultaneously trying to get through the “quals” phase and n2students simultaneously trying to get through the “thesis” phase. The egalitarian professor splits her time evenly between all nstudents. Question: What is the service rate experienced by a student in phase 1(the “quals” phase)? Answer: If there were no other students, a student in phase 1would be served at rate μ1. However, because the student has to share the professor with all other students of the professor, the student is actually served at rate μ1 total number of students=μ1 n1+n2. To determine πn1,n2, we need to write balance equations for the M/Cox/1/PS. These can get quite complex. We therefore solve for the limiting probabilities via the methodof local balance, except that this time we apply local balance to each phase . That is, we will equate Bi=Rate leave state (n1,n2) due to a departure from phase i=Rate enter state (n1,n2) due to an arrival into phase i=B/prime i. Note about notation: We use B0to represent the rate that we leave state (n1,n2)due to a departure from phase 0, where phase 0represents the outside. Thus a departure from phase 0represents an arrival from outside. Hence B0represents the rate that we leave state (n1,n2)due to an arrival from outside. Likewise B/prime 0represents the rate that we enter state (n1,n2)due to an arrival into phase 0, where phase 0represents the outside. Hence B/prime 0represents the rate that we enter state (n1,n2)due to a departure to the outside. Question: Warmup: How do we deﬁne B1, the rate of leaving state (n1,n2)due to a departure from phase 1? Answer: There are n1jobs at phase 1. Each leaves phase 1 with Exponential rate πn1,n2·μ1 n1+n2. 22.4 m/cox/ 1/ps 387 Note: We divided by n1+n2because the job is slowed down by all the other jobs in the PS server – not just in its phase. Thus the total rate of leaving state (n1,n2)due to a departure from phase 1is n1·πn1,n2·μ1 n1+n2. Bi: Rate leaving state (n1,n2)due to a departure from phase i: B0=πn1,n2λ B1=πn1,n2μ1n1 n1+n2 B2=πn1,n2μ2n2 n1+n2 (Recall that B0means “leaving the outside” or, equivalently, arriving from outside into the system.) B/prime i: Rate entering state (n1,n2)due to an arrival into phase i: B/prime 0=πn1+1,n2μ1(n1+1)(1 −p) n1+n2+1+πn1,n2+1μ2(n2+1) n1+n2+1 B/prime 1=πn1−1,n2λ B/prime 2=πn1+1,n2−1μ1(n1+1)p n1+n2 (Recall that B/prime 0means “entering outside” or leaving the system.) We now need to make a guess for the limiting probability πn1,n2.",4178
22.4 MCox1PS,"Question: Look at equating B1andB/prime 1. What guess makes B1=B/prime 1? Hint: Observe that B1=B/prime 1=⇒πn1,n2=ρ1n1+n2 n1πn1−1,n2,where ρ1=λ μ1. Answer: The fact that the limiting probabilities differ by factors involving n1+n2 andn1suggests a combinatorial choose. A guess for the limiting probabilities is: πn1,n2=/parenleftbigg n1+n2 n1/parenrightbigg ρ1n1ρ2n2π0,0, (22.1) where ρ1=λ μ1andρ2=λp μ2. Note that ρ1andρ2do not mean anything here. This is just a notational convenience. Let’s verify this guess by checking Bi=B/prime ifor all i. 388 networks with time-sharing (ps) servers (bcmp) Check for i=1 : B/prime 1=πn1−1,n2λ =/parenleftbign1+n2−1 n1−1/parenrightbig ρ1n1−1ρ2n2π0,0λ =/parenleftbign1+n2 n1/parenrightbign1 n1+n2ρ1n1ρ2n2π0,0λ ρ1 =πn1,n2n1 n1+n2λ ρ1 =πn1,n2μ1n1 n1+n2 =B1 Check for i=2 : B/prime 2=πn1+1,n2−1μ1(n1+1)p n1+n2 =/parenleftbign1+n2 n1+1/parenrightbig ρ1n1+1ρ2n2−1π0,0μ1(n1+1)p n1+n2 =/parenleftbign1+n2 n1/parenrightbign2 n1+1ρ1n1ρ2n2π0,0μ1(n1+1)p n1+n2ρ1 ρ2 =πn1,n2n2 n1+1μ1(n1+1)p n1+n2ρ1 ρ2 =πn1,n2μ2n2 n1+n2 =B2 Check for i=0 : B/prime 0=πn1+1,n2μ1(n1+1)(1 −p) n1+n2+1+πn1,n2+1μ2(n2+1) n1+n2+1 =/parenleftbign1+n2+1 n1+1/parenrightbig ρ1n1+1ρ2n2π0,0μ1(n1+1)(1 −p) n1+n2+1+/parenleftbign1+n2+1 n1/parenrightbig ρ1n1ρ2n2+1π0,0μ2(n2+1) n1+n2+1 =πn1,n2n1+n2+1 n1+1ρ1μ1(n1+1)(1 −p) n1+n2+1+πn1,n2n1+n2+1 n2+1ρ2μ2(n2+1) n1+n2+1 =πn1,n2λ(1−p)+πn1,n2λp =πn1,n2λ =B0 So the guess in ( 22.1) works. Let’s use this guess to express P{njobs in system }. Let n=n1+n2. Then by ( 22.1)w eh a v e P{njobs in system }=n/summationdisplay n1=0πn1,n−n1=n/summationdisplay n1=0/parenleftbiggn n1/parenrightbigg ρ1n1ρ2n−n1π0,0. 22.4 m/cox/ 1/ps 389 Note that the last expression on the right is just a binomial expansion: n/summationdisplay n1=0/parenleftbiggn n1/parenrightbigg ρ1n1ρ2n−n1π0,0=(ρ1+ρ2)nπ0,0. So P{njobs in system }=(ρ1+ρ2)nπ0,0. (22.2) Question: What is ρ1+ρ2? Answer: ρ1+ρ2=λ μ1+λp μ2 =λ·/parenleftbigg1 μ1+p μ2/parenrightbigg . Question: Does this term/parenleftBig 1 μ1+p μ2/parenrightBig have a meaning? Answer: Yes. Observe that/parenleftbigg1 μ1+p μ2/parenrightbigg =Average service requirement of job entering the system =E[S]. So ρ1+ρ2=λ·E[S] =ρ=load for the single-server system. Thus we have from ( 22.2), P{njobs in system }=ρnπ0,0. Now, we just need the normalization constant π0,0, which allows ∞/summationdisplay n=0P{njobs in system }=1. Clearly, because π0,0is the fraction of time that the server is idle, π0,0=1−ρ. Hence, P{njobs in system }=ρn(1−ρ). But this is the same as for an M/M/1. UNBELIEV ABLE. The fact that the limiting probabilities of the M/G/1/PS are independent of the job size distribution (they depend only on its mean) is called an insensitivity property . 390 networks with time-sharing (ps) servers (bcmp) Insensitivity properties are rare and always very interesting. It is hard to ﬁnd intuitive explanations for why certain queueing networks exhibit insensitivity. Example 1 – Single Server Consider a time-sharing CPU, shown in Figure 22.5. The jobs arriving to this server have service requirements (sizes) that come from some unknown distribution. The arrival process is Poisson with rate λ=3jobs/sec. The mean job service requirement is1/5sec. Poisson ( λ) PS Job sizes come from  any weird distrib ution yo u like  Figure 22.5. M/G/1/PS. Question: What is the mean response time for this system? Answer: The solution is the same as if we had an M/M/1/FCFS: E[T]=1 μ−λ=1 5−3=1 2sec Example 2 – Server Farm Suppose you have a distributed server system consisting of two hosts. Each host is a time-sharing host. Host 1 is twice as fast as Host 2. Jobs arrive to the system according to a Poisson process with rate λ=1/9jobs/sec. The job service requirements come from some general distribution with mean 3seconds if run on Host 1, but take twice as long on Host 2. When a job enters the system, with probability p=3 4it is sent to Host 1, and with probability 1−p=1 4is sent to Host 2. Mean service time  is 3 seconds. Poisson (1/9) ¾ ¼PS PS Mean service time is 6 seconds. Figure 22.6. PS server farm.",4076
22.5 Tandem Network of MG1PS Servers,"22.5 tandem network of m/g/ 1/ps servers 391 Question: What is the mean response time for jobs? Answer: Figure 22.6 shows the server farm. The mean response time is simply E[T]=3 4·(Mean response time at server 1) +1 4·(Mean response time at server 2) =3 4·1 1 3−1 9·3 4+1 4·1 1 6−1 9·1 4=24 5sec. 22.5 Tandem Network of M/G/1/PS Servers Figure 22.7 displays two PS servers in tandem, each with two phases. Here, the state is the number of jobs at every phase of every server: ( n1,n2,m1,m2). To determine the limiting probabilities, once again we apply local balance to each phase . That is, we equate Bi=Rate leave state (n1,n2,m1,m2) due to a departure from phase i=Rate enter state (n1,n2,m1,m2) due to an arrival into phase i=B/prime i. Here we have 5 phases: phase 0 corresponds to “outside,” and phases 1, 2, 3, and 4 are as shown in Figure 22.7. We now deﬁne the rates of leaving/entering a state. Bi: Rate leaving state ( n1,n2,m1,m2) due to a departure from phase i: B0=πn1,n2,m1,m2λ B1=πn1,n2,m1,m2μ1n1 n1+n2 B2=πn1,n2,m1,m2μ2n2 n1+n2 B3=πn1,n2,m1,m2μ3m1 m1+m2 B4=πn1,n2,m1,m2μ4m2 m1+m2 λ 1–pp μ1 μ212 1–qq μ3 μ434Phases: 1,2  Phases: 3,4 Figure 22.7. Tandem network. 392 networks with time-sharing (ps) servers (bcmp) B/prime i: Rate entering state ( n1,n2,m1,m2) due to an arrival into phase i: B/prime 0=πn1,n2,m1+1,m2μ3(m1+1)(1 −q) m1+m2+1+πn1,n2,m1,m2+1μ4(m2+1) m1+m2+1 B/prime 1=πn1−1,n2,m1,m2λ B/prime 2=πn1+1,n2−1,m1,m2μ1(n1+1)p n1+n2 B/prime 3=πn1,n2+1,m1−1,m2μ2(n2+1) n1+n2+1+πn1+1,n2,m1−1,m2μ1(n1+1)(1 −p) n1+n2+1 B/prime 4=πn1,n2,m1+1,m2−1μ3(m1+1)q m1+m2. The following is a product form guess for the limiting probabilities: πn1,n2,m1,m2=/parenleftbiggn1+n2 n1/parenrightbigg ρ1n1ρ2n2/parenleftbiggm1+m2 m1/parenrightbigg ρ3m1ρ4m2π0, (22.3) where ρ1=λ/μ 1,ρ2=λp/μ 2,ρ3=λ/μ 3,ρ4=λq/μ 4, andπ0is a short form for π0,0,0,0. It is easy to see that this guess satisﬁes the local balance equations ( Bi=B/prime i)f o r i=0,1,2,3,4using very similar algebra to what was used in the case of a single server. The algebra is left to Exercise 22.2. We now need to ﬁnd π0to determine the limiting probabilities. Let n=n1+n2, and m=m1+m2. Note that the load on the ﬁrst server, ρa,i sρa=ρ1+ρ2, and the load on the second server, ρb,i sρb=ρ3+ρ4.S ow eh a v e P{njobs at server 1 ,mjobs at server 2 } =n/summationdisplay n1=0m/summationdisplay m1=0πn1,n−n1,m1,m−m1 =π0n/summationdisplay n1=0/parenleftbiggn n1/parenrightbigg ρ1n1ρ2n−n1m/summationdisplay m1=0/parenleftbiggm m1/parenrightbigg ρ3m1ρ4m−m1 =π0(ρ1+ρ2)n(ρ3+ρ4)m =π0ρanρbm. Now, using the fact that ∞/summationdisplay n=0∞/summationdisplay m=0P{njobs at server 1,mjobs at server 2}=1, we get π0=( 1−ρa)(1−ρb).",2678
22.7 Readings,"22.6 network of ps servers with probabilistic routing 393 Furthermore, P{njobs at server 1 }=∞/summationdisplay m=0π0ρanρbm=∞/summationdisplay m=0(1−ρa)(1−ρb)·ρanρbm =( 1−ρa)ρan and likewise P{mjobs at server 2 }=( 1−ρb)ρbm. Thus, P{njobs at server 1 ,mjobs at server 2 } =ρan(1−ρa)ρbm(1−ρb) =P{njobs at server 1 }·P{mjobs at server 2 }. So two M/G/1/PS servers in tandem have a product form solution, where the distribution of the number of jobs at each server again follows an M/M/1. 22.6 Network of PS Servers with Probabilistic Routing Given a network of PS servers, with Poisson outside arrivals, and general (Coxian)service times, we still have product form and the format of the product form looksexactly like it did for the case of Jackson networks with FCFS servers. Namely, P/braceleftbigg Number of jobs at each queue is (n1,n2,...,n k)/bracerightbigg =k/productdisplay i=1P{nijobs at server i} =k/productdisplay i=1ρni i·(1−ρi) where ρi=λiE[Si]. The proof follows along the same lines as that in Section 22.5. Again, we say that a network of PS servers exhibits the insensitivity property , because only the mean of the job size distribution is relevant. Question: Why don’t these nice product form results come up when we have a network of FCFS servers with Coxian service times? Why doesn’t the same analysis go through? Answer: The state space and job behavior look very different for a network of FCFS servers than for a network of PS servers. In the case of PS servers, all jobs are inside the gray bubble (representing the server) at all times, and all jobs move through thephases independently of each other (with the other jobs only affecting their rate). Inthe case of FCFS servers, only one job at a time can be processing within the gray bubble. The rest of the jobs are queued outside the bubble. The movement of jobs is thus very restricted. Generally, insensitivity arises in situations where there is no strictqueueing – jobs receive service right away, as in PS queues or an M/G/ ∞system.",2016
Chapter 23 The MG1 Queue and the Inspection Paradox,"394 networks with time-sharing (ps) servers (bcmp) 22.7 Readings The purpose of this chapter was to illustrate another application of the method of phases. We saw that we could prove that the M/Cox/1/PS queue behaves like an M/M/1/FCFSqueue, and furthermore that a network of PS queues with Coxian service times and probabilistic routing between queues has product form and can be decomposed into M/Cox/1/PS queues. These results and the further extension to classed networks areprovided in the original BCMP paper [ 16]. The BCMP result has also been rederived via other techniques, see for example Harrison’s work [ 95]. The product form results described in this chapter have been extended by Frank Kelly [106] to networks of quasi-reversible queues , which allow for more general queueing disciplines than PS or PLCFS. Some good references describing this broader class of product form networks are [ 127] and [ 38]. 22.8 Exercises 22.1 M/BP/1/PS Recall Exercise 20.1, which asked you to simulate the M/G/1/FCFS queue, where Gwas a Bounded Pareto( k,p,α) distribution with mean 3,000. There were two settings of parameters for the Bounded Pareto: (i) k=1,000,p= 1010,α=1.5, and (ii) k=1,970,p=1 010,α=2.9. The arrival rate, λ, was set to create a server load of ρ=0.8. Suppose now that you are asked to redo the experiment in Exercise 20.1 under PS scheduling. That is, you now need to simulate an M/BP/1/PS queue, ﬁrst under α=1.5and then under α=2.9, with the goal of measuring mean response time. What do you expect the mean response time to be in the two cases? Either ﬁgure it out analytically, or simulate it and ﬁnd out. 22.2 Verifying Product Form Solution for Tandem Network of PS Servers In Section 22.5, we considered a tandem network of PS servers. We made the following “guess” for the limiting probabilities of this network: πn1,n2,m1,m2=/parenleftbiggn1+n2 n1/parenrightbigg ρ1n1ρ2n2/parenleftbiggm1+m2 m1/parenrightbigg ρ3m1ρ4m2π0, where ρ1=λ/μ 1,ρ2=λp/μ 2,ρ3=λ/μ 3,ρ4=λq/μ 4, andπ0is a short form for π0,0,0,0. This expression represents the probability that there are n1 jobs in phase 1 at server 1, and n2jobs in phase 2 at server 1, and m1jobs in phase 3 (this is phase 1 at server 2) and m2jobs in phase 4 (this is phase 2 at server 2). Prove that this guess satisﬁes the local balance equations: Bi=B/prime ifori= 0,1,2,3,4, as deﬁned in Section 22.5.",2377
23.2 The MG1 Queue and Its Analysis,"CHAPTER 23 The M/G/1 Queue and the Inspection Paradox In Chapter 22we studied the M/G/1/PS queue and derived simple closed-form solutions forπn,E[N], andE[T](assuming Gis any Coxian distribution). In this chapter we move on to the M/G/1/FCFS queue. We have already had some exposure to thinking about the M/G/1/FCFS. Using the matrix-analytic techniques of Chapter 21, we saw that we could solve the M/PH/1/FCFS queue numerically, where PH represents an arbitrary phase-type distribution. However, we still do not have a simple closed-form solution for the M/G/1/FCFS that lets us understand the effect ofload and the job size variability on mean response time. This chapter introduces a simple technique, known as the “tagged job” technique, which allows us to obtain a simple expression for mean response time in the M/G/1/FCFSqueue. The technique will not allow us to derive the variance of response time, nor willit help us understand the higher moments of the number of jobs in the M/G/1/FCFS –for those, we will need to wait until we get to transform analysis in Chapter 25. Nonetheless, the resulting simple formula for mean response time will lead to many insights about the M/G/1 queue and optimal system design for an M/G/1 system. 23.1 The Inspection Paradox We motivate this chapter by asking several questions. We will come back to these questions repeatedly throughout the chapter. By the end of the chapter everything willbe clear. Question: Suppose buses arrive at a bus stop every 10 minutes on average, and the time between arrivals at the bus stop is Exponentially distributed. I arrive at the bus stop at a random time. How long can I expect to wait for a bus? t EXCESSExp(10)1Exp(10)1Exp(10)1 Figure 23.1. The Inspection Paradox. 395 396 the m/g/ 1queue and the inspection paradox Question: While you are thinking about the answer to the ﬁrst question, also ask yourself whether your answer changes if we change the distribution of the time between buses (the mean time between buses is still 10 minutes). What is the range of possible answers across all distributions? Deﬁnition 23.1 is associated with Figure 23.1. Deﬁnition 23.1 LetAdenote the time between bus arrivals. Let’s suppose a person arrives at a random time. Then the time that person has to wait until the next bus is denoted by the random variable Aeand is called the excess of A . 23.2 The M/G/1 Queue and Its Analysis An M/G/1 queue consists of a single server and queue with Poisson job arrivals, wherethe size (a.k.a. service time) of a job has a general distribution (see Figure 23.2). That is, the job service time, denoted by the random variable S, may follow any distribution, whereE[S]=1/μ. First-Come-First-Served (FCFS) service order is assumed unless otherwise stated. Poisson ( λ)FCFS General service timeμ Figure 23.2. An M/G/1 queue. In this chapter we study the tagged-job technique, in which we “tag” an arbitrary arrival and reason about the time that the tagged arrival spends in the queue. We will need the following notation: TQ: time in queue NQ: number in queue NA Q: number in queue as seen by the arrival S: service time of a job, where E[S]=1/μ Si: service time of the ithjob in the queue Se: excess of S – the remaining service time of the job in service, given that there is some job in service. The deﬁnition of Seis elucidated by Figure 23.3. We now have E[TQ]=E[Unﬁnished work that an arrival witnesses in the system ] =E[Unﬁnished work in queue ]+E[Unﬁnished work at the server ] (Expectations add even if r.v.s are not independent.) 23.2 the m/g/ 1queue and its analysis 397 =E⎡ ⎣NA Q/summationdisplay i=1Si⎤⎦+E[ Unﬁnished work at server ] (23.1) =E/bracketleftbig NA Q/bracketrightbig ·E[S]+P{Arrival sees job in service }·E[Se] (23.2) =E[NQ]E[S]+( Time-avg probability server busy )·E[Se] (23.3) =E[NQ]·E[S]+ρ·E[Se] (23.4) =E[TQ]·λ·E[S]+ρ·E[Se] =E[TQ]·ρ+ρ·E[Se] =ρ 1−ρ·E[Se]. t S S S Se Figure 23.3. Given that there is a job in service (system is busy), a Poisson arrival sees Se time remaining on the job in service. We have thus easily obtained a formula for the mean time in queue in an M/G/1 system (a.k.a. mean delay), provided we can compute E[Se]where Seis the excess of the service time S: E[TQ]=ρ 1−ρ·E[Se] (23.5) Question: Why were we allowed to break up the expectation in ( 23.1) into a product of expectations? Answer: TheSi,i=1,2,...,NA Q, are all independent of NA Q, because these jobs have not run yet, and hence their size has not inﬂuenced the queueing time seen by the tagged arrival. Question: Where in the previous derivation have we used the fact that the arrival process is a Poisson process? Answer: We invoked PASTA twice when moving from ( 23.2)t o(23.3). First, we used the PASTA assumption in stating that P{Arrival sees a job in service }=Time-average probability the server is busy. 398 the m/g/ 1queue and the inspection paradox Second, we used PASTA in stating that E/bracketleftbig NA Q/bracketrightbig =E[NQ]. We will soon derive a general formula for E[Se], but ﬁrst it is instructive to go through some examples: Examples rM/M/1 Queue: The service time, S, is Exponentially distributed with mean 1/μ. Because the service time distribution is memoryless, E[Se]=1/μ. Therefore, E[TQ]=ρ 1−ρ·1 μ. This agrees with our previous results for the M/M/1 queue. rM/D/1 Queue: The service time is Deterministic (constant) and equal to 1/μ. E[Se]=1 2μ, because the remaining service time of a job in service is Uniformly distributed between 0and1 μ. Therefore, E[TQ]=ρ 1−ρ·1 2μ. Note that the expected time in queue is halfthat of the M/M/1 queue. rM/E k/1 Queue: The service time has an Erlang-k distribution (see Deﬁni- tion 21.2). The Ekdistribution consists of kstages in series, each with Ex- ponential service time with mean 1/kμ. If there is a job in service at the time of an arrival, then it is equally likely that the job is at each of the kstages. On average, the job in service will be at the middle stage, leaving/ceilingleftbigk+1 2/ceilingrightbig stages left to be completed. We therefore should have E[Se]=/ceilingleftbiggk+1 2/ceilingrightbigg ·1 kμ. Mean time in queue is then given by E[TQ]=ρ 1−ρ·/ceilingleftbiggk+1 2/ceilingrightbigg ·1 kμ. Observe that for k=1 this is equal to the M/M/1 expression and for k→∞ this is equal to the M/D/1 expression. rM/H 2/1 Queue: The service time has a Hyperexponential distribution, H2,a si n Deﬁnition 21.3. Here it is not as obvious how to derive E[Se]. To compute E[Se]exactly, for any random variable S, we need to use the Renewal- Reward theorem , which we describe in the next section.",6599
23.4 Applying Renewal-Reward to Get Expected Excess,"23.3 renewal-reward theory 399 23.3 Renewal-Reward Theory Renewal-Reward theory is a powerful technique that allows us to obtain time averages of many quantities by considering only the average over a single renewal cycle. Wecan then compute the time-average excess, which, by PASTA, is also the excess seen by a random Poisson arrival. We start with a reminder of the deﬁnition of a renewal process and a reminder of the Renewal theorem. We then build up from there. Deﬁnition 23.2 (restated from Deﬁnition 9.32)Any process for which the times between events are i.i.d. r.v.s with a common distribution, F, is called a renewal process . Figure 23.4 illustrates a renewal process. Events time X2 X3 X1 Figure 23.4. A renewal process. The Xi’s all have common distribution F. Theorem 23.3 (restated from Theorem 9.33)For a renewal process, if E[X]>0 is the mean time between renewals (events), and N(t)is the number of renewals (events) by time t, then we have, with probability 1, N(t) t→1 E[X]ast→∞. (23.6) Now consider a renewal process having i.i.d. interarrival times Xn,n≥1with dis- tribution Fand mean E[X], and suppose that each time a renewal occurs we receive a reward. We denote by Rnthe reward earned over the course of the nthrenewal. We shall assume that the Rn,n≥1, are i.i.d. with mean E[R]≥0.H o w e v e r ,w ed o allow for the possibility that the Rnmay (and often will) depend on Xn, the length of thenthrenewal interval. If we let R(t)represent the total reward earned by time t, then N(t)/summationdisplay n=1Rn≤R(t)≤N(t)+1/summationdisplay n=1Rn. 400 the m/g/ 1queue and the inspection paradox Theorem 23.4 (Renewal-Reward) If0≤E[R]<∞and0<E[X]<∞, then with probability 1, R(t) t→E[R] E[X]ast→∞. Question: Interpret Theorem 23.4. Answer: The Renewal-Reward theorem says that the average rate at which we earn reward is equal to the expected reward earned during a cycle, divided by the ex- pected cycle length. This should make a lot of sense intuitively, because every cycle is probabilistically identical. The result is non-trivial, however, because normally it is meaningless to just divide two expectations. Therein lies the power of the theorem. Proof N(t)/summationdisplay n=1Rn≤R(t)≤N(t)/summationdisplay n=1Rn+RN(t)+1 /summationtextN(t) n=1Rn t≤R(t) t≤/summationtextN(t) n=1Rn t+RN(t)+1 t. (23.7) We know that /summationtextN(t) n=1Rn N(t)−→E[R]ast→∞,w.p.1.(by SLLN ) N(t) t−→1 E[X]ast→∞,w.p.1.(by Theorem 23.3) Combining these, we have that lim t→∞/summationtextN(t) n=1Rn t= lim t→∞/summationtextN(t) n=1Rn N(t)·lim t→∞N(t) t=E[R] E[X]. (23.8) Putting together ( 23.8) and ( 23.7), we have that E[R] E[X]≤lim t→∞R(t) t≤E[R] E[X]+ lim t→∞RN(t)+1 t. Observing thatRN(t)+1 t→0ast→∞ , because rewards are ﬁnite, we have the desired result. 23.4 Applying Renewal-Reward to Get Expected Excess We now apply Renewal-Reward theory to derive the expected excess. The deﬁnition of excess presumes that the server is busy. We thus consider a renewal process consistingof a sequence of service times, each an instance of the r.v. S, as shown in Figure 23.5: 23.4 applying renewal-reward to get expected excess 401 t S S S Figure 23.5. Renewal occurs at the end of each service time. Here the server is assumed to be always busy, with a renewal occurring at the end of each service. Figure 23.6 illustrates the function Se(t), the excess at time t. t S S SSe(t) Figure 23.6. The function Se(t)represents the excess service time at time t. Question: How do we express E[Se]in terms of Se(t)? Answer: E[Se]=Time-average Excess = lim s→∞/integraltexts 0Se(t)dt s. To compute E[Se], we need to express it as a long-run average award. Let R(s)denote the total “reward” earned by time s. Question: What is R(s)for our problem? Answer: R(s)=/integraldisplays 0Se(t)dt. Question: So what is the time-average reward? Answer: Time-average Reward = lim s→∞R(s) s= lim s→∞/integraltexts 0Se(t)dt s=E[Se] Now, by Renewal-Reward theory, the time-average reward is equal to the reward earned during one cycle divided by the expected length of one cycle. Question: What is a “cycle?” Answer: A cycle is one service time.",4121
23.6 Back to the MG1 Queue,"402 the m/g/ 1queue and the inspection paradox Now we can use Renewal-Reward theory to determine the time-average reward, which is the same as the time-average excess: Reward earned during a cycle =/integraldisplayS 0(S−t)dt=S2−S2 2=S2 2 E[Reward earned during a cycle ]=E[S2] 2 E[Length of one cycle ]=E[S] Time-avg Reward =E[Reward during cycle ] E[Cycle length ]=E[S2] 2E[S] Hence, E[Se]=E[S2] 2E[S]. This derivation was a calculus-based argument, which is needed when the rewardfunction is a complex curve. For this particular problem, the following simple geometricargument sufﬁces: Looking at Figure 23.6, the reward earned during one cycle is just the area under a triangle, where the height and base of the triangle have length S. Thus the area is S2/2. Hence the expected reward earned during a cycle is E[S2]/2.N o w because the expected length of a cycle is E[S], we have, by Renewal-Reward, the result that the time-average reward isE[S2] 2E[S]. 23.5 Back to the Inspection Paradox We now return to our buses question. Question: Suppose buses arrive at a bus stop every 10 minutes on average and the time between arrivals at the bus stop is Exponentially distributed. I arrive at the bus stop at a random time. How long can I expect to wait for a bus? Answer: Let r.v. Sdenote the time between arrivals of buses. Then the average time until the next bus is just the average excess, E[Se]; namely Time-average Excess =E[Se]=E[S2] 2E[S]. (23.9) IfShas an Exponential distribution, then the above quantity is equal to E[S], namely 10 minutes. If Shas a Deterministic (constant) distribution, then the above quantity is justE[S]/2, namely 5 minutes. If Shas very high variability, as in the Pareto distribution, then the expected excess will be much higher thanE[S]. Thus far we have been interested in the “time until the next bus arrives.” We could also have asked about the time since the last bus arrived. If Sdenotes the time between buses, then the time since the last bus arrived is called the age of S . 23.6 back to the m/g/ 1queue 403 Question: What would you guess is the mean age of S? Answer: The age of Shas the same mean and even the same distribution as Se, the excess of S. To understand why, see Exercises 23.5 and23.11 , which are argued using a Renewal-Reward argument. Adding the expected age and the expected excess, we see that a random arrival is likely to land in an interval where Expected time between buses as seen by arrival =E[S2] 2E[S]+E[S2] 2E[S]=E[S2] E[S]. IfSis highly variable, this quantity can be far higher than E[S]. Question: Is this just “Murphy’s Law,” or is there some reason why a random arrival is likely to experience a bigger-than-average time between buses? Answer: If you think about the renewal process represented by the interarrival times between buses, you will see that some renewals are short and some are long. It is more likely that a random arrival lands in a long interval than in a short interval. This iscalled the Inspection Paradox . We can also express E[Se]in terms of the squared coefﬁcient of variation of S,C2 S. Recalling that C2 S=Var(S) E[S]2=E[S2] E[S]2−1, it follows that E[Se]=E[S2] 2E[S]=E[S] 2·E[S2] E[S]2=E[S] 2·(C2 S+1 ). (23.10) This says that higher variability implies higher excess. In fact, observe that when C2 S=1, we have that E[Se]=E[S], and for C2 S/greatermuch1,E[Se]explodes. In practical terms, you arrive at the bus stop and ﬁnd that the time until the next bus is many times higher than the mean time between buses. Remark: We refer to Seas the excess ofS, but this is also commonly referred to as theequilibrium distribution ofS. 23.6 Back to the M/G/1 Queue Recall that when analyzing the M/G/1/FCFS queue we proved equation ( 23.5), repeated below for reference: E[TQ]=ρ 1−ρE[Se], (23.11) whereE[Se]was deﬁned as the expected remaining service time on the job in service at the time of an arrival, given that there is a job in service. 404 the m/g/ 1queue and the inspection paradox From ( 23.10 ), we know that E[Se]=E[S2] 2E[S]=E[S] 2·(C2 S+1 ). (23.12) Substituting ( 23.12 ) into ( 23.11 ), we get the Pollaczek-Khinchin (P-K) formula [ 141, 107], written here in several equivalent forms: E[TQ]=ρ 1−ρ·E[S2] 2E[S](23.13) E[TQ]=ρ 1−ρ·E[S] 2·(C2 S+1 ) (23.14) E[TQ]=λE[S2] 2(1−ρ)(23.15) Question: Looking at ( 23.14 ), why does C2 Splay such a key role in determining delay? Answer: What causes delays is “bunching up of jobs.” rFor the D/D/1 queue, with arrival rate λand service rate μ>λ , there are no delays, because arrivals see no one in service. rFor the M/D/1 queue, delays occur because arrivals sometimes “bunch up.” rFor the M/M/1 queue, “bunching up” is also created by occasional long service times. Thus the expected delay in M/M/1 is greater than that in M/D/1. rFor the M/G/1 queue, with highly variable job size, there is even more “bunchingup” of jobs. So what creates delays is the occasional extra-long service time (or extra-large number of arrivals) in some service period. That is, delay is proportional to the variance in the arrival andservice processes. Of course once one job is delayed, that affects all jobs in the queue behind it. The P-K formula assumes a Poisson arrival process, and the C2 S refers only to variability in the service times. Very Important Observation: Expected waiting time in an M/G/1 queue can be huge , even under very low utilization, ρ,i fC2 Sis huge. For example, if ρ=0.5,E[S]=1 , butC2 S=2 5 (which is not unusual, as pointed out in Chapter 20), thenE[TQ]=1 3 , which is 13 times the mean job size, even though system load is low. Final Remark: The result below follows from the transform of waiting time, which we will derive in Chapter 26: Var(TQ)=(E[TQ])2+λE[S3] 3(1−ρ) What is interesting here is that the second moment of delay depends on the third moment of service time, similarly to the way that the ﬁrst moment of delay dependson the second moment of service time. In general the ith moment of delay is related to the (i+1)th moment of service time.",6023
23.7 Exercises,"23.7 exercises 405 23.7 Exercises 23.1 M/H 2/1 For the M/H 2/1 queue with arrival rate λ, where the job sizes are speciﬁed in Deﬁnition 21.2, derive expressions for E[Excess] andE[TQ]. 23.2 M/G/1 – Doubling Service Rate and Arrival Rate Jobs arrive to a CPU according to a Poisson process with rate λ. The CPU requirement of each job is drawn from some general distribution G, with ﬁnite moments. The CPU currently has load ρ=λ·E[S]<1, where Sdenotes the CPU requirement of jobs. The current mean response time is denoted by E[Tcurrent]. Suppose that the arrival rate now increases by a factor of two. To compensate, we buy a CPU that is twice as fast, so each job’s service requirement on the new CPU is half what it was on the old CPU. Apply theP-K formula to determine the new mean response time and compare it withthe original mean response time. 23.3 M/G/1 with Different Job Types Consider an M/G/1 queue that serves two types of jobs: red and blue. Red jobs arrive according to a Poisson process with rate λR=1 4jobs/sec, and blue jobs arrive according to a Poisson process with rate λB=1 2jobs/sec. Red job sizes have mean 1 and variance 1, whereas blue job sizes have mean 0.5 and variance 1. All jobs arrive to the same FCFS queue, so that, at any time, the server might be serving a red job or a blue one, and there might be jobs of one or both types in the queue. What is the mean response time of red jobs, and what is the mean response time of blue jobs? 23.4 Understanding the Inspection Paradox Imagine that there are two types of renewals: short renewals of length exactly 1 and long renewals of length exactly 10. Suppose that short renewals occurwith probability 2 3and long renewals occur with probability1 3. (a) What is the average length of a renewal? (b) What is the probability that a randomly thrown dart lands in a long renewal? (c) What is the expected length of a renewal that I see if I arrive at a random time (use part (b))? (d) How does your answer to (c) compare with your answer to (a)? This difference is the Inspection Paradox. 23.5 Deriving the Expected Age LetAbe a random variable denoting the time between bus arrivals, with mean E[A]and second moment E[A2]. The time since the last bus arrival is called theage of A and is denoted by Aa. Use Renewal-Reward theory to derive E[Aa], the mean age of A. Follow the approach given in this chapter, showing the diagram of age across time. How does your answer compare with E[Ae], the mean excess of A? 23.6 Effect of Variability on Waiting Time in M/G/1 Consider a single M/G/1 queue. Let the service time, S, follow a 2-point distribution: S=/braceleftBigg 0 with probability q 1 1−qwith probability 1−q 406 the m/g/ 1queue and the inspection paradox Observe that as qgets close to 1, most jobs have service time 0. (a) Determine E[S], the expected service time. Is this affected by q? (b) Determine E[Se]. (c) Determine C2 S, the squared coefﬁcient of variation of the service time. What is the range of possible values of C2 Sas a function of q? (d) Now determine E[TQ], the mean waiting time for this system, as a function ofq, assuming load ρ<1. Simplify your expression as much as you can so that it is in terms of qandρ. What happens in the system as qapproaches 1? Give some intuition for what is going on. 23.7 Application of Renewal Reward – M/G/1 Busy Period Consider an M/G/1 queue with arrival rate λand mean service time E[S]. A busy period starts when the server becomes busy and ends when it goes idle. Determine the mean length of a busy period. Do notsolve this problem via transforms or via conditioning on the job size: Use only Renewal-Reward, thinking about busy and idle periods. [Hint: The answer is very short (3 lines)if you see the trick for how to apply Renewal-Reward.] 23.8 Application of Renewal-Reward – M/M/ ∞Busy Period Recall the M/M/ ∞system from Section 15.2: Jobs arrive according to a Poisson process with rate λ. Job sizes are Exponentially distributed with mean 1 μ. There are an inﬁnite number of servers, so that whenever a job arrives, it is given a new server. A busy period is deﬁned to be the time from when the M/M/∞ﬁrst becomes busy (a single job arrives) until the M/M/ ∞becomes idle. Derive the mean length of a busy period. [Hint: This is again a 3-line argument. It may help to recall that for the M/M/ ∞,πi=e−RRi i., where R=λ μ.] 23.9 Application of Renewal-Reward – Mean Time between Visits to a State in a CTMC Consider the expected time between visits to state iin a CTMC. Use a Renewal- Reward type argument to prove that E[Time between visits to state i]=1 πi·1 νi, where νiis the total rate of leaving state iin the CTMC, given that we are in statei. (Note the difference between this result and that for a DTMC.) 23.10 Semi-Markov Process Consider a stochastic process that moves between states according to sometransition probability matrix, P, where Pijrepresents the probability of next moving to state jgiven that we are currently in state i. However, when the process is in state i, it stays there for some holding time, Hi, where the Hi’s are generally distributed random variables, from possibly different distributions. Such a process is called a semi-Markov process. We will be interested in πSM i, the stationary probability of being in state ifor the semi-Markov process. To understand πSM i, it helps to consider πD i, the stationary probability for the embedded DTMC with the same transition matrix P, where one spends exactly 23.7 exercises 407 time1in each state. The goal of the problem is to prove that πSM i=πD i·E[Hi]/summationtext kπD k·E[Hk]. (23.16) (a) Explain why ( 23.16 ) makes intuitive sense. (b) Consider a long period of time, consisting of nstate transitions. Let Ni(n) denote the number of visits to state iduring these ntransitions. Pick n large enough, so that Ni(n)is large. Let H(j) idenote the time spent in stateiduring the jth visit to state i. Let f(n)=/summationtextNi(n) j=1H(j) i/summationtext k/summationtextNk(n) j=1H(j) k. What does f(n)represent? (c) Use tricks similar to those in the proof of Theorem 23.4 to reformulate f(n)so that it becomes the expression in ( 23.16 )a sn→∞ . 23.11 Distribution of Excess Consider a renewal process where Xrepresents the time between renewals. F(x)andf(x)are the c.d.f. and p.d.f. for X, respectively. We use Xeto denote the excess of X. Use Renewal-Reward to derive Fe(k)=P{Xe<k}. 23.12 Server with Failures and Repairs Consider an M/G/1 queue, where at any time when the server is busy it can fail. The time until the next failure is Exponentially distributed with rate α. Once the server fails, it goes into repair mode. The repair time is a generally distributedrandom variable denoted by R. After the server is repaired, it continues serving the job that it was serving from the point that it left off (i.e., no work is lost). Assume that the repair times are i.i.d. and are independent of the job sizes. Compute the mean response time of a job arriving to this M/G/1 queue. [Hint: This problem is challenging. Exercise 11.6 and Theorem 3.34 may help.]",7091
Chapter 24 Task Assignment Policies for Server Farms,"CHAPTER 24 Task Assignment Policies for Server Farms In this chapter we revisit server farms, however this time in the context of high- variability job sizes (indicative of the workloads described in Chapter 20), rather than Exponential job sizes. The server farm architecture is ubiquitous in computer systems. Rather than using a single, powerful server to handle all incoming requests (assuming such a beast caneven be purchased), it is more cost efﬁcient to buy many slow, inexpensive serversand pool them together to harness their combined computational power. The server farm architecture is also popular for its ﬂexibility: It is easy to add servers when loadincreases and easy to take away servers when the load drops. The term server farm is used to connote the fact that the servers tend to be co-located, in the same room or even on one rack. Thus far, we have primarily studied server farms with a central queue , as in the M/M/k system, which we initially examined in Chapter 14and then revisited from a capacity provisioning perspective in Chapter 15. In the M/M/k, jobs are held in a central queue, and only when a server is free does it take on the job at the head of the queue. By contrast, in computer systems, most server farms do immediate dispatching (also known as task assignment ), whereby incoming jobs are immediately assigned to servers (also known as hosts ). There is typically no central queue; instead the queues are at the individual hosts.Such server farms with immediate dispatching of jobs require an important policy decision, known as the task assignment policy . This is the rule that is used by the front-end router (also known as a dispatcher orload balancer ) to assign incoming jobs to servers. For example, incoming jobs may be assigned to servers in round-robinorder, or each incoming job might be assigned to the server with the shortest queue. The choice of task assignment policy hugely inﬂuences the response time of jobs atthe server farm, sometimes by orders of magnitude. Using the right task assignmentpolicy is particularly important when the job size distribution has high variability. Amajor question in computer systems design is ﬁnding a good task assignment policy tominimize mean response time (or some other performance variant). Figure 24.1 illustrates the server farm model that is the focus of this chapter. The high- speed front-end router deploys the task assignment policy , which assigns incoming jobs to hosts. Observe that the scheduling policy deployed at an individual host is not ﬁxed, but is typically application dependent. For example, in web server farms, the servers are typically time-sharing servers, and each server “simultaneously” serves all 408 task assignment policies for server farms 409 Sched uling Policy Sched uling Policy Sched uling PolicyHigh-speed RouterT ask Assi gnment Policy Incomin g  jobs Figure 24.1. Server farm model. jobs in its queue; that is, each server deploys the PS scheduling policy. By contrast, in manufacturing systems and in many supercomputing settings, jobs are often non-preemptible, and each server serves one job at a time in FCFS order. The goal of this chapter is to understand the performance of different task assignment policies. The literature is so vast in this area that we can only hope to highlight someimportant results. Our goal throughout is to provide intuition. The readings noted in Section 24.4 contain greater depth. In Section 24.1, we consider the case where jobs are non-preemptible and each server serves the jobs in its queue in FCFS order, as shown in Figure 24.2. In Section 24.2, we assume that jobs are preemptible and each server serves the jobs in its queue inPS order, as shown in Figure 24.6. For each of the settings in Sections 24.1 and24.2, we look for task assignment policies that minimize mean response time. To facilitateanalysis in these sections, we assume a Poisson arrival process. In Section 24.3,w e ask more broadly how one could design optimal server farms in the case where jobsare preemptible and all design decisions are open (i.e., we can use any task assignmentpolicy and any scheduling policy at the servers). Throughout we assume that job FCFS FCFSFCFS High-speed RouterT ask Assi gnment Policy Incomin g  jobs Figure 24.2. Server farm model with FCFS scheduling at hosts.",4344
24.1 Task Assignment for FCFS Server Farms,"410 task assignment policies for server farms sizes are drawn from a high-variability distribution, such as the Bounded Pareto from Chapter 20, because such distributions reﬂect empirically measured job sizes. 24.1 Task Assignment for FCFS Server Farms In this section, we assume the server farm model as shown in Figure 24.2, with k servers. In particular, we assume that jobs are not preemptible and that each server processes jobs in its queue in FCFS order. For simplicity, we assume that servers are homogeneous . We assume that job sizes are independently and identically distributed according to some high-variability distribution, G, with mean1 μ. We also assume that jobs arrive according to a Poisson process with average rate λ. As usual, we denote the system utilization, ρ,b y ρ=λ kμ,0≤ρ≤1 and the resource requirement, R,b y R=λ μ=kρ, 0≤R≤k in accordance with Deﬁnition 14.4. This model is common in manufacturing settings where it is often difﬁcult, if not impossible, to preempt a job in progress. It is also common in supercomputing settings,where jobs are typically parallel computations, which makes them very difﬁcult topreempt. There are many choices for task assignment policies under this model. Many policies are not analytically tractable. However, in some cases their performance can be ap- proximated. In others, even approximations are poor. Our discussion of these policiestherefore sometimes relies on empirical results. We can divide task assignment policies into those that make use of knowing the size (service requirement) of an arrival and those that do not assume any knowledge of thesize of an arrival. Question: What are some examples of task assignment policies for Figure 24.2 that do not assume any knowledge of the size of an arrival? Answer: We list some common policies: Under the RANDOM policy, each job is assigned to one of the khosts with equal probability. The aim of the RANDOM policy is to equalize the expected number of jobs at each host. Under the ROUND-ROBIN policy, jobs are assigned to hosts in a cyclical fashion with the ith job being assigned to host number (imodk)+1 . This policy also aims to equalize the expected number of jobs at each host. Under the JSQ (Join-the-Shortest-Queue) policy, each incoming job is assigned to the host that has the shortest queue (the queue with the fewest number of jobs) at the 24.1 task assignment for fcfs server farms 411 time when the job arrives. If several hosts have the same fewest number of jobs, then JSQ picks one of these hosts at random. This policy tries to equalize the instantaneousnumber of jobs at each host. All three policies immediately dispatch jobs to hosts, where there is a queue of jobs at each host. Alternatively, we could instead imagine a single central queue (like in the M/M/k), where a host, when free, picks the job at the head of the queue to run. Because we are assuming generally distributed i.i.d. job sizes, this architecture is referred to as the M/G/k . Note that, although the M/G/k is not strictly within our model because there are not queues at the hosts, it still obeys the general framework of our model,because jobs are non-preemptible and the (single) queue is serviced in FCFS order,and we do not need to know job sizes.",3266
24.1 Task Assignment for FCFS Server Farms,"Thus we include M/G/k as one of our policies. Question: Which of these policies – RANDOM, ROUND-ROBIN, JSQ, or M/G/k – would you guess has the lowest mean response time?Answer: We will discuss and compare the policies one at a time ...but hold on to your guess. Question: Which do you think is superior: ROUND-ROBIN or RANDOM? Why? Answer: It turns out that ROUND-ROBIN slightly outperforms RANDOM. To see why this is so, observe that the arrival process into each queue under RANDOM is a Poisson process, by Poisson splitting. By contrast, the interarrival time into each queue under ROUND-ROBIN is a sum of Exponentials – namely, an Erlang-k distribution – whichhas less variability than an Exponential. Hence, in RANDOM each queue behaves likean M/G/1, with average arrival rate λ/k, where Gis the job size distribution, whereas under ROUND-ROBIN each queue behaves like an Ek/G/1, with average arrival rate λ/k. The lower variability of the Ek, compared to the M(Exponential), results in ROUND-ROBIN having lower mean response time. Comparing ROUND-ROBIN with JSQ is more difﬁcult, because for JSQ it is not possible to boil down the behavior of each queue to some simple G/G/1 queue. Theissue is that the arrival process into a given queue under JSQ depends on the state ofthe other queues. To precisely analyze JSQ, one would need a k-dimensional Markov chain that tracks the number of jobs in each of the kqueues. Unfortunately, no one knows how to analyze such a k-dimensional chain that grows unboundedly in all k dimensions. Even the case of just k=2 dimensions and Exponential service times does not yield a closed form, and, for higher k(k>2), only approximations exist (see Section 24.4 for details). Based on the approximations that are known, it seems clear that JSQ is far superior to ROUND-ROBIN with respect to mean response time under higher job size variability. In fact, for high-variability job size distributions, JSQ canlower mean response time by an order of magnitude compared to ROUND-ROBIN. Question: Intuitively, why does it make sense that JSQ should outperform ROUND- ROBIN under higher job size variability? Answer: JSQ balances the instantaneous number of jobs at each queue, whereas ROUND-ROBIN balances the expected number of jobs. The difference is that JSQ can react quickly. Imagine that all queues have 5 jobs, but there is a lot of variability 412 task assignment policies for server farms among job sizes and one of the queues empties suddenly. JSQ can quickly remedy the situation by sending the next 5 arrivals to that queue, whereas ROUND-ROBINwould have to wait for k/2more arrivals on average before even one job could be sent to the empty queue. During that period of waiting for k/2arrivals, the server corresponding to the empty queue is not being utilized, increasing the load on all otherservers and increasing overall mean response time. When job size variability is high,queues can empty very suddenly. This is why the dynamic properties of JSQ are soimportant. Deﬁnition 24.1 Adynamic policy is one that adapts based on changes in the state of the system (e.g., the number of jobs at each queue), whereas a static policy is oblivious to the changes in state.",3212
24.1 Task Assignment for FCFS Server Farms,"Thus JSQ is dynamic , whereas ROUND-ROBIN is static . Question: How would you guess that JSQ compares with M/G/k under high job size variability? Why? Answer: Both M/G/k and JSQ are dynamic policies, and both are good at making sure that no host is left idle. However M/G/k has a big additional advantage: It holds off onassigning jobs to hosts as long as possible. Observe that in JSQ it could happen thatall queues have 5 jobs, and suddenly one queue empties, creating a situation whereone server is unutilized. This underutilization can never happen under M/G/k, becausewhenever there are ≥kjobs, every host is busy. Empirical results show that M/G/k can outperform JSQ by an order of magnitude with respect to mean response time when job size variability is high. Now suppose that we know the sizeof a job when it arrives. Clearly there are many more task assignment policies possible if we know the job size. One obvious exampleis the LWL policy. Under the LWL (Least-Work-Left) policy, each job goes to the queue where it will achieve the lowest possible response time. This is a greedy policy, because each job is acting in its own best interest. Speciﬁcally, each incoming job is assigned to the queuethat has the least total work at the time when the job arrives. Note that the work a jobsees ahead of it is exactly its waiting time. Unlike some of the policies we saw earlierthat aim to equalize the number of jobs at each host, the LWL policy aims to equalize the total work at each host. The LWL policy is exactly what we do when we go to the supermarket. We look at each line and count not the number of people (jobs) there, but rather we look at the number of items in each person’s basket (the job size) for every person in each line.We then join the line with the smallest total number of items (least work remaining). Recall that under JSQ we only look at the number of jobs in each queue in deciding where to route a job. When job size variability is high, the number of jobs in a queue 24.1 task assignment for fcfs server farms 413 can be a poor estimate of the total work in that queue. In this sense LWL is far superior to JSQ. Question: How do LWL and M/G/k compare? Answer: We will prove in Exercise 24.4 that LWL and M/G/k are actually equivalent, (i.e., LWL =M/G/k). Speciﬁcally, if both policies are fed the same arrival sequence of jobs, and ties are resolved in the same way in both systems, then it can be shown that the same job goes to the same host at the same time under both policies. Observe that when a job arrives to the M/G/k system, it may sit in the central queue for a while before being dispatched. However, the host that it will eventually go to is exactly thehost that had the least work in front of it under LWL. Unfortunately the analysis of M/G/k (and hence LWL) is a long-standing open problem in queueing theory. It is hard to imagine why the M/G/k is so hard to analyze, giventhat the M/M/k is so simple. Many young queueing theorists have devoted severalyears to beating their heads against the problem of analyzing the M/G/k system. Ofcourse, one can always replace the job size distribution Gwith some phase-type distribution, PH, and use matrix-analytic methods to solve the M/PH/k system (see Exercise 21.7). Although this yields numerical solutions, it does not provide insight into which properties of the job size distribution matter and how these properties affect the solution. Also, even from a numerical standpoint, matrix-analytic solutions are nota panacea, because they can become very unstable (the matrices become near singular)when the distributions are highly skewed (e.g., when the squared coefﬁcient of variationof the job size distribution, C2, is very high).",3732
24.1 Task Assignment for FCFS Server Farms,"The ﬁrst closed-form approximation for waiting time in an M/G/k was proposed by Lee and Longton [ 118] over a half-century ago; it says that the waiting time in an M/G/k is basically the same as that in an M/M/k, but scaled up by a simple factor related to C2: E/bracketleftbig TM/G/k Q/bracketrightbig ≈/parenleftbiggC2+1 2/parenrightbigg E/bracketleftbig TM/M/k Q/bracketrightbig (24.1) Many other authors have also proposed closed-form approximations for mean delay in the M/G/k, all involving only the ﬁrst 2 moments of the job size distribution (seeSection 24.4). Unfortunately, any approximation of mean delay based on using only the ﬁrst 2 moments is provably inaccurate for some job size distributions; in addition, the inaccuracy of the approximation can be off by a factor proportional to C2[76]. Table 24.1 (borrowed from [ 76]) illustrates why two moments of the job size distri- bution are insufﬁcient for predicting E[TQ]. The ﬁrst row of the table shows E[TQ] for an M/G/10 with mean job size of 1 and C2=1 9 (ﬁrst column) or C2=9 9 (sec- ond column) according to approximation ( 24.1). The remaining rows show various distributions, all of which have been parameterized to have the same mean job size, E[S]=1 , and appropriate C2. As shown, the difference in E[TQ]across distributions can be very high – E[TQ]differs by a factor of close to 2whenC2=1 9 and by a factor of more than 3whenC2=9 9 . 414 task assignment policies for server farms Table 24.1. Simulation results for the 95 percent conﬁdence intervals in an M/G/k, withk=1 0 ,ρ=0.9, andE[S]=1 E[TQ]forC2=1 9 E[TQ]forC2=9 9 2-Moment Approximation ( 24.1) 6.6873 33.4366 Weibull 6.0691±0.01 25 .9896±0.18 Bounded Pareto ( α=1.1) 5.5277±0.02 24 .6049±0.28 Lognormal 4.994±0.025 19 .543±0.42 Bounded Pareto ( α=1.3) 4.879±0.025 18 .774±0.36 Bounded Pareto ( α=1.5) 3.947±0.032 10 .649±0.54 T h eﬁ r s tl i n es h o w s E/bracketleftbig TQ/bracketrightbig for the 2-moment approximation given in ( 24.1). The remaining lines show various distributions with appropriate C2. Table 24.2 summarizes the task assignment policies that we have considered so far. There is one more commonly employed policy shown in the table that also makes use of knowing the size of jobs, namely the SITA policy. Table 24.2. Examples of common task assignment policies RANDOM Each job is assigned to one of the khosts with equal probability. ROUND-ROBIN The ith job is assigned to host (imodk)+1 . JSQ Each job is assigned to the host with the fewest number of jobs. LWL Each job is assigned to the host with the least total work. M/G/k When a server is free, it grabs the job at the head of the central queue. SITA Small jobs go to host 1, mediums to host 2, larges to host 3, etc. Under the SITA (Size-Interval-Task-Assignment) policy [ 83], each host is assigned to a size interval, where the size intervals are non-overlapping and span the full range of possible job sizes. For example, the ﬁrst host is assigned only “small” jobs (thoseof size between 0ands, for some s); the second host is assigned only “medium” jobs (those of size between sandm, for some m>s ); the third host is assigned only “large” jobs (those of size between mandl, for some l>m ), etc. Every incoming job is routed to the appropriate host based on its size.",3286
24.1 Task Assignment for FCFS Server Farms,"Question: What is the point of the SITA policy? Why does it make sense? Answer: The SITA policy is similar to the “express lane” in your local supermarket, where one or two queues are reserved for “short” jobs only. When job size variability is high, there can be some very large jobs and some very small ones. By dedicatingcertain queues to short jobs only, we provide isolation for short jobs, so that they donot get stuck waiting behind long jobs. Observe that we have not fully speciﬁed the SITA policy, because we have not speciﬁed the size cutoffs. Question: Under SITA, what size cutoffs make sense? Answer: One might think that choosing cutoffs that balance expected load among the queues makes sense. That is, we would choose s,mandlsuch that /integraldisplays 0tf(t)dt=/integraldisplaym stf(t)dt=/integraldisplayl mtf(t)dt. 24.1 task assignment for fcfs server farms 415 However, it turns out that choosing the cutoffs to balance expected load can be very far from optimal. This point is explored in Exercise 24.6. Finding the optimal cutoff is very counterintuitive and often involves severely unbal- ancing the load between the servers. For example, for a Bounded Pareto with α<1, one wants to choose cutoffs that unbalance the load, favoring small jobs by underload- ing the servers of small jobs, whereas for a Bounded Pareto with α>1, one wants to choose cutoffs that unbalance the load, favoring large jobs by underloading the serversof large jobs [ 93,82]. In the case of just k=2 servers, the optimal cutoff can be ob- tained by search; however, the search becomes less feasible with more than 2servers. As of the date of this book, the problem of ﬁnding closed-form cutoffs that minimize mean response time for general job size distributions is still wide open [ 93]. Question: How can we analyze SITA given that we know the cutoffs? Answer: Once we are given size cutoffs, the analysis of SITA (under a Poisson arrival process) is very straightforward. Because the size of the incoming job is drawn at random from the size distribution, G, we can view the splitting of jobs into queues as probabilistic Poisson splitting of the arrival process. The ith queue can then be modeled as an M/G i/1 queue, where Girepresents the job size distribution of jobs arriving at queue i. An example is provided in Exercise 24.1. Question: How does the performance of SITA and LWL =M/G/k compare? Answer: This is a surprisingly difﬁcult question. Part of the problem, of course, is that neither SITA (with unknown cutoffs) nor LWL is analytically tractable in closed form.We start with some intuitions about each policy and then move on to what results existin the literature. One advantage of the LWL policy over any other policy is that it is ideal at keeping servers utilized. This can be seen by viewing LWL as M/G/k. It is impossible under LWL for one server to have zero jobs while another server has a job queueing. One advantage of the SITA policy is that it is ideally suited to reducing variability at each queue.",3028
24.1 Task Assignment for FCFS Server Farms,"Suppose that the original job size distribution, G, has high variability. Under most policies, this same high variability is transferred to all the queues. This is problematic because we know, from the P-K formula (Chapter 23), that queueing delay is directly proportional to the variability of the job size distribution. SITA speciﬁcally divides up the job size distribution so that each queue sees only a portion of the domainof the original distribution, greatly decreasing the job size variability at each queue.Another way of putting this is that SITA provides short jobs protection from long jobs. Because most jobs in computing-based systems are short jobs, and because long jobs can be very, very long, isolating the many short jobs from long jobs greatly reduces mean response time. The SITA policy and its variants have been part of the common wisdom for a long time and have been the focus of many papers (see Section 24.4 for references). Because of SITA’s beneﬁts in reducing job size variability, for a very long time it was believed that SITA, or some SITA-like variant, was far superior to LWL =M/G/k with respect 416 task assignment policies for server farms to mean response time when the job size variability was very high. Many papers speciﬁcally compared the performance of SITA to LWL and found that as job sizevariability is increased , SITA becomes far superior to LWL. Figure 24.3 illustrates SITA’s superiority on a server farm with k=2 servers. The job size distribution shown is a Bounded Pareto ( k,p,α) with α=1.4. The resource requirement is R=0.95, equivalent to ρ=0.95/2.C2is increased while holding E[S]ﬁxed by increasing the upper limit, p, while decreasing the lower limit, k. The SITA mean response times are computed analytically by ﬁrst numerically deriving theoptimal splitting cutoff. The LWL mean response times are not analytically tractable, so we use a (very loose) upper bound on LWL performance, given in [ 157]. Figure 24.3 shows the effect on mean response time, E[T],a sC2is increased, under LWL and SITA. According to the ﬁgure, SITA is far superior to LWL. Although the results for LWL are loose, the trend of SITA’s superiority over LWL is in good agreement with simulation results and those in earlier research papers. 1001021041061080200040006000800010000 C2E[T] SITA LWL Figure 24.3. Expected response time, E[T], for SITA and LWL versus C2in a 2-server system with Bounded Pareto job size distribution with α=1.4and resource requirement R=0.95. To more clearly illustrate SITA’s superiority, we consider a server farm, again with k= 2servers, where this time R=1.8and the job size distribution is a Hyperexponential, H2, with unbalanced means (speciﬁcally Q=0.7fraction of the load is contained in one of the Hyperexponential branches). The advantage of using an H2is that we can analytically solve for the (nearly) exact mean response time under LWL via matrix-analytic methods, so that we do not have to use any upper bound. The H2also lends itself nicely to increasing C2while holding E[S]constant.",3058
24.1 Task Assignment for FCFS Server Farms,"Figure 24.4 clearly illustrates SITA’s superiority over LWL for this H2job size distribution. Despite comparisons such as those depicted in Figures 24.3 and24.4 which show that SITA outperforms LWL by orders of magnitude for high job size variability, a proof of SITA’s superiority over LWL never materialized. SITA itself is difﬁcult to analyze, even for Poisson arrivals, because in general there is no closed-form expression forthe optimal size cutoffs and for the resulting response time. Furthermore, LWL (whichis equivalent to M/G/k) is in general only approximable. Thus, many of the existingcomparisons have used simulation to assert their claims or have compared responsetime only under heavy-trafﬁc regimes. 24.1 task assignment for fcfs server farms 417 10010110210301020304050 C2E[T] SITA LWL Figure 24.4. Expected response time, E[T], for SITA and LWL versus C2in a 2-server system withR=1.8and job size distribution H2with unbalanced branches ( Q=0.7). In 2009, a surprising result was proven, showing that the common wisdom is actually wrong [90]: There are cases where SITA is not superior to LWL under high C2, and in fact, SITA is provably unboundedly worse than LWL as C2→∞ in some regimes. An example of such a regime is provided in Figure 24.5. 10010510100200040006000800010000 C2E[T] SITA LWL Figure 24.5. Expected response time, E[T], for SITA and LWL versus C2in a 2-server system with Bounded Pareto job size distribution with α=1.6andR=0.95. Figure 24.5 considers a server farm identical to that of Figure 24.3, except that the Bounded Pareto parameter αhas changed from α=1.4toα=1.6. As in the case of Figure 24.3, the mean response time for SITA is computed analytically, while we use an upper bound from [ 157] for the mean response time for LWL. This time, however, the comparison between SITA and LWL looks very different. For lower C2, SITA still improves on LWL; however, there is a crossover point, at sufﬁciently high C2, after which SITA’s response time diverges, whereas LWL’s response time converges. This crossover point is actually at a much lower C2than it appears in the graph, because the upper bound for LWL is loose. This crossover point, after which SITA’s response time diverges but LWL’s response time converges, was not observed in prior work (which mostly relies on simulation, nu- merical methods, heavy-trafﬁc approximations or 2-moment M/G/2 approximations),possibly because the earlier literature did not consider the very high C2regions, thus (incorrectly) concluding that SITA is always superior to LWL. 418 task assignment policies for server farms Question: But why would SITA be inferior to LWL under high job size variability? Isn’t SITA speciﬁcally designed to combat high variability? Answer: Consider a server farm with two hosts, and the Bounded Pareto (k,p,α )job size distribution from Figure 24.5 asp→∞ andC2→∞ . SITA needs to place its size cutoff somewhere. If it places the size cutoff at any ﬁnite value, x, then the ﬁrst host sees a job size distribution with ﬁnite variance (because sizes range from ktox); however, the second host sees a job size distribution with inﬁnite variance (because sizes range from xto∞,a sp→∞ ).",3196
24.1 Task Assignment for FCFS Server Farms,"Since mean response time is a weighted sum of the response time at the two hosts, the mean response time under SITA will tend toinﬁnity as C2→∞ . Note that we can instead make the cutoff, x, increase with p. This however, means that as p→∞ , the ﬁrst host experiences inﬁnite variability, which again means that SITA has inﬁnite mean response time. By contrast, under LWL performance is only bad if two big jobs arrive near to each other, blocking off both servers. But the probability of such a bad event can be verylow if the resource requirement is sufﬁciently light (e.g., R<1with 2 servers). In this case the second server is not really needed, and is thus available to serve shorter jobs if one server gets blocked with a long job. In general, for a system with kservers, we deﬁne the number of spare servers as Number spare servers =k−⌈R⌉. These spare servers can be extremely effective in combating variability. Even if C2 for the job size distribution approaches inﬁnity, the spare servers can be used to let the smaller jobs have a “freeway” so that they do not get stuck behind large jobs, allowing the response time of LWL to converge. One might think that SITA could similarly beneﬁt from spare servers, but the strict routing in SITA makes it unable to enjoy this beneﬁt. Question: But why was there a difference between the Bounded Pareto with α=1.4, shown in Figure 24.3, and the Bounded Pareto with α=1.6, shown in Figure 24.5, given that both cases were run with one spare server? Answer: The Bounded Pareto with α=1.4has a fatter tail, implying there are more medium and large jobs. This increases the probability of a “bad event” where two large jobs arrive at near the same time. It turns out that in this case one spare server is insufﬁcient for LWL. The difference is captured more precisely in the 3/2moment of the job size distribution. Observe that E/bracketleftbig S3 2/bracketrightbig is inﬁnite for α=1.4, whereas E/bracketleftbig S3 2/bracketrightbig is ﬁnite for α=1.6. Theorem 24.2 explains that the 3/2moment of Sis crucial in understanding the response time of the M/G/2 (LWL). Theorem 24.2 [155,156,157,158] For (almost) all job size distributions with r.v. S, the mean response time of the M/G/2 is bounded (ﬁnite) if and only if E/bracketleftbig S3 2/bracketrightbig is ﬁnite and there is at least one spare server. Although we do not have space to prove this theorem, in Section 24.4 we elaborate on generalizations of the result to k>2servers. Note that this stability result is very",2522
24.2 Task Assignment for PS Server Farms,"24.2 task assignment for ps server farms 419 different from an M/G/1, whose mean response time is ﬁnite if and only if E[S2]is ﬁnite. Summary This section has dealt with ﬁnding task assignment policies for server farms in the case where jobs are not preemptible and job size variability is high. Our discussion covers only the highlights of a vast body of literature in the area. The main pointis that task assignment is non-obvious and can be counterintuitive. Many common,well-known policies, such as RANDOM, ROUND-ROBIN, and JSQ, are virtuallyworthless when job size variability is high. Furthermore, it is difﬁcult to rank the policies: As we have seen, sometimes SITA can be farsuperior to LWL, and sometimes the reverse is true. Even a seemingly innocuous and obvious goal like “load balancing”is questionable, because SITA can perform far better when the load across servers ispurposely unbalanced. Finally, the analysis of task assignment policies is often verydifﬁcult and is still in its infancy. We have collected some important references inSection 24.4. Question: So far we have only considered the case of high job size variability. Suppose that instead the job size variability is very low. How do the policies that we haveconsidered compare in this situation? Answer: When job sizes are Deterministic (e.g., all jobs have size 1), the ROUND- ROBIN policy is optimal, because the arrivals to a server are maximally spaced out; in fact, if job sizes and interarrival times are both Deterministic, then no job will bedelayed under ROUND-ROBIN, assuming that the system is not in overload. The JSQ policy will actually end up doing the same thing as ROUND-ROBIN, because the shortest queue will be that which has not received a new job in the longest time. By thesame logic, LWL will end up doing the same thing as ROUND-ROBIN. In contrast, RANDOM will sometimes make the “mistake” of sending two consecutive arrivalsto the same queue, incurring some delay. SITA will reduce to RANDOM, becauseall jobs have the same size. Even with occasional mistakes by RANDOM, we expectmean response time to be very low. To see this, consider the case of RANDOM withDeterministic job sizes and Poisson arrivals. By Poisson splitting, each queue becomesan M/D/1 queue, which we know has only half the delay of an M/M/1. 24.2 Task Assignment for PS Server Farms We now turn to a very different model of a server farm. Figure 24.6 depicts a queueing model of a web server farm. Here the incoming requests are HTTP requests. These must be immediately dispatched to one of the server hosts, because they are connections thatneed immediate attention. Requests are fully preemptible in that any request can bestopped and restarted where we left off. Given that this is a network-based application, running on TCP, it is important that the service seem immediate and constant. Forthis reason, we cannot have requests waiting in a FCFS queue. Instead, each host 420 task assignment policies for server farms time-shares among all the requests in its queue, so that each HTTP request receives “constant” service. This scheduling is modeled as Processor-Sharing (PS).",3154
24.2 Task Assignment for PS Server Farms,"PS PS PSHigh-speed RouterT ask Assi gnment Policy Incomin g  jobs Figure 24.6. Server farm model with PS scheduling at hosts. There are many common high-speed routers used for dispatching HTTP requests in a web server farm. Some examples are Cisco’s LocalDirector [ 42], IBM’s Network Dispatcher [ 140], and F5’s BIG-IP [ 21]. The job size distribution for websites is known to be highly variable and heavy-tailed [ 47,48]. To ease the analysis, we assume that the arrival process is a Poisson process with average rate λand that job sizes are i.i.d. Assuming a Poisson arrival process is not necessarily unrealistic, particularly if the arrival process is the merge of many disparate users. However, our assumptions that job sizes are independent of each other and independent of the interarrival times are not true in practice, as pointed out in several papers, [ 70,47,169]. As before, we assume k identical servers and use Sto denote the job size, where E[S]=1 μ. The system load is denoted by ρ=λ kμand the resource requirement by R=λ μ. Given the huge prevalence of web server farms, it is important to consider what task assignment policies are best for the PS server farm model and how they compare. We again consider the policies in Table 24.2; all except for the M/G/k (which by deﬁnition uses a FCFS queue) are reasonable options for a PS server farm. Let’s see how thesecompare. Question: Consider ﬁrst the RANDOM policy and the SITA policy. Recall that for the FCFS server farm, the SITA policy was far superior to RANDOM when the job size distribution was highly variable. How do these policies compare for the PS serverfarm, again assuming high job size variability? Hint: Analyzing SITA of course depends on the size cutoffs. It turns out that, in contrast to FCFS server farms, the optimal size cutoffs for PS server farms are those thatbalance load between the servers (see Exercise 24.2). Thus the load at every server is ρ, just like the overall system load. It is therefore easiest to express the response time of each policy in terms of ρ. Hint: Both RANDOM and SITA experience Poisson splitting, because the size cutoffs in SITA can be viewed as sending a fraction, pi, of jobs to server i. Answer: For RANDOM, we note that an arrival goes to a random queue with load ρ and arrival rate λ/k. By Poisson splitting, this random queue is an M/G/1/PS queue, 24.2 task assignment for ps server farms 421 but the mean response time for M/G/1/PS is the same as that of M/M/1/FCFS (see Chapter 22). Thus, the random arrival goes to a queue with (on average)ρ 1−ρjobs. By Little’s Law, its response time at this queue is then E[T]RANDOM=1 λ/k·ρ 1−ρ=k λ·ρ 1−ρ. For SITA, WLOG assume that the job size distribution ranges from 0to∞and that the size cutoffs are s1,s2,...s k−1, where jobs in the interval (0,s1)go to host 1, jobs of size (si−1,si)go to host i, and jobs of size (sk−1,∞)go to host k. The fraction of jobs that go to host iispiwhere pi=/integraltextsi si−1f(t)dt, where f(t)is the density of the job size distribution. The load at queue iisρ(see the ﬁrst hint). By Poisson splitting, queue iis an M/G/1/PS queue (see second hint). The arrival rate into queue iisλi, where λi=λpi. Putting these facts together we have E[T|job goes to host i]SITA=1 λi·ρ 1−ρ. E[T]SITA=k/summationdisplay i=1pi·E[T|job goes to host i] =k/summationdisplay i=1pi·1 λi·ρ 1−ρ =k/summationdisplay i=11 λ·ρ 1−ρ =k λ·ρ 1−ρ. Thus we have that E[T]RANDOM=E[T]SITA. (24.2) The fact that RANDOM and SITA have the same mean response time (for server farms with PS servers) might be surprising, because these policies yield very different performance for FCFS servers. The reason that RANDOM and SITA were so differentfor server farms with FCFS servers is that RANDOM does nothing to reduce job sizevariability, whereas SITA does a lot to reduce variability. However, PS scheduling isinvariant to job size variability, and hence the beneﬁt of SITA in reducing job size variability is superﬂuous.",3988
24.2 Task Assignment for PS Server Farms,"Question: For server farms with PS servers, which is better: JSQ or LWL? Which was better for server farms with FCFS servers? Answer: Recall that for the case of server farms with FCFS servers, LWL was superior to JSQ. For FCFS servers, LWL represented the greedy policy, whereby each job was routed to the host where it would itself experience the lowest response time, namely the host with the least total work. For the case of PS servers, JSQ represents the greedy policy that routes jobs to the host where it will likely experience the lowest response time. Speciﬁcally, under JSQ, each job is routed to the host where it will time-share with the fewest jobs. By contrast, 422 task assignment policies for server farms knowing the total work at a PS host does not necessarily have any bearing on the job’s response time at that host. Unfortunately, analyzing JSQ is no easier for a PS server farm than for a FCFS server farm, even when the job size distribution is Exponential. Modeling JSQ requirestracking the number of jobs at each queue, so that we can determine to which host anarrival should be routed. But tracking the number of jobs in each queue necessitates a state space that grows unboundedly in kdimensions (one for each queue), making it intractable. The problem is only ampliﬁed for LWL where we need to track the total work at each queue. One idea for analyzing JSQ in a PS server farm is to approximate the dependence between the queues while only tracking what is going on in a single oneof the k queues, WLOG queue 1 [ 79]. The dependence is captured by making the arrival rate into queue 1 be dependent on the number of jobs at queue 1. For example, the average arrival rate into queue 1 should be λ/k. However, if queue 1 currently has 0jobs, then the arrival rate into queue 1 should be greater than λ/k, because it is likely that the other queues have more jobs than queue 1. Likewise, if queue 1 currently has many jobs, thenthe arrival rate into queue 1 will be less than λ/k, because the other queues likely have fewer jobs. By deriving the correct load-dependent arrival rate into queue 1, one canapproximate the inﬂuence of the other k−1queues on queue 1. Finally, since queue 1 was chosen WLOG, the delay experienced by an arrival to queue 1 is the system delay. A recent ﬁnding is that JSQ is surprisingly (nearly) insensitive to job size variability for PS server farms [ 79]. At ﬁrst, this may seem to follow from the insensitivity of the M/G/1/PS queue. However, there is more to it than that, because LWL, as we will soon see, is not at all insensitive to job size variability for PS server farms. A proof of thenear insensitivity of JSQ has not yet been found, as of the time of writing of this book. Figure 24.7 shows simulation results for the performance of all the task assign- ment policies we have considered over a range of job size distributions, described in Det Exp Bim−1 Bim−2Weib−1 Weib−2E[N] 56789 JSQLWLROUND−ROBIN OPT−0RANDOM = SITA Figure 24.7. Simulation results for a server farm with two PS hosts, under different task as- signment policies.",3099
24.2 Task Assignment for PS Server Farms,"The x-axis shows a variety of job size distributions (described in Table 24.3) in order of increasing variability from left to right. The y-axis depicts the mean number of jobs per host of the server farm, under each job size distribution. The server farm load is ρ=0.9. 24.2 task assignment for ps server farms 423 Table 24.3. Job size distributions, each with mean 2, but increasing variance from top to bottom Distribution Mean Variance Deterministic: point mass at 2 20 Erlang-2: sum of two Exp (1)random variables 2 2 Exponential: Exp (0.5)random variable 2 4 Bimodal-1:/braceleftbigg 1w.p.0.9 11w.p.0.129 Weibull-1: (shape parameter 0.5, scale parameter 1)2 2 0 Weibull-2: (shape parameter1 3, scale parameter1 3)2 7 6 Bimodal-2:/braceleftbigg 1 w.p.0.99 101 w.p.0.0129 9 Table 24.3.1Each distribution has mean 2, but the distributions have increasing vari- ance, ranging from a variance of 0for the Deterministic distribution to a variance of 99 for the Bimodal-2 distribution. As we consider distributions with higher and higher variance, we see that the performance of ROUND-ROBIN and LWL both deteriorate.By contrast, the performance of SITA, RANDOM, and JSQ appear insensitive to thejob size variability (JSQ is not actually insensitive, because there is a 1 percent variation, not visible by eye). The JSQ policy is clearly the best of the policies we have consideredthus far. To gauge the optimality of JSQ, we also compare policies against the OPT-0 policy. The OPT-0 policy, introduced in [ 25], assigns each incoming job so as to minimize the mean response time for all jobs currently in the system, assuming that there are 0 future arrivals . Note that we are not being greedy from the perspective of the incoming job, but rather trying to minimize across all the jobs in the system. This policy is followed for each successive incoming arrival. Although the JSQ policy is far simpler than OPT-0, its performance is within about 5 percent of OPT-0, for all job size distributions in the table. Thus the JSQ policy appears to be near optimal. Summary This section has dealt with ﬁnding task assignment policies for server farms in the case where jobs are preemptible, the scheduling at the servers is PS, and job size variability ishigh. Unlike the previous section that dealt with FCFS scheduling at the servers, there ispresently very little literature on this topic, see [ 6], [79], and [ 101], probably because the operations research community deals far less with PS servers than with FCFS servers. The main point of this section is that task assignment is very different for server farms composed of PS servers as compared to FCFS servers. Whereas JSQ is a pretty badpolicy for server farms of FCFS servers, because of its ineffectiveness in alleviatingdelays created by high job size variability, JSQ is an excellent policy for server farmsof PS servers. Similarly, SITA, a top performer for server farms with FCFS servers, is 1The Weibull distribution has p.d.f. f(t)=α λ/parenleftbigt λ/parenrightbigα−1e−(t λ)α ,f o rt>0,w h e r e α>0is called the shape parameter and λ>0is called the scale parameter; see [ 181]. The parameters that we chose in the table result in heavy-tailed distributions.",3219
24.3 Optimal Server Farm Design,"424 task assignment policies for server farms among the worst performers for server farms with PS servers. Under server farms of PS servers, job size variability is not a big problem, and some policies, like JSQ, arenearly insensitive to job size variability. The analysis of server farms with PS servers is a wide open area, full of open problems. For example, we did not even discuss the very interesting problem of task assignmentpolicies for the case of heterogeneous servers. 24.3 Optimal Server Farm Design We now turn to the more theoretical question of how to optimally design a server farm if one is allowed to choose both the task assignment policy and the scheduling policy at the individual hosts; both these decisions are shown in Figure 24.1. This is a theoretical question, because typically the scheduling policy at the individual hosts is dictated by the operating system at the servers and the application. To give ourselves maximumﬂexibility, we further assume that jobs are fully preemptible and that we know a job’ssize when it arrives (of course we do not know future jobs). Finally, we allow ourselvesthe ﬂexibility of having a central queue at the router, if we want one. As usual, weassume a job size distribution with high variability, mean job size E[S], and a Poisson arrival process with average rate λ. Unfortunately, there exists almost no stochastic analysis in the area of optimal server farm design. All the work in the area of optimal server farm design deals with worst- case analysis and competitive ratios. In worst-case analysis , one is no longer looking at the performance of a policy, P, under a Poisson arrival process with i.i.d. job sizes taken from some distribution, as we have been assuming. Instead, one imagines an adversary who can generate any arrival sequence, where the arrival sequence consists of arrival times of jobs and their sizes. The policy Pis now evaluated on each possible arrival sequence and is compared with the optimal policy for that arrival sequence. Speciﬁcally, we imagine some algorithm OPT that behaves optimally on each arrival sequence. We do not know what OPT looks like, and it does not have to be consistent across arrival sequences (that is, OPT can follow a different algorithm on each arrivalsequence); we just use OPT to denote the best possible solution for everyarrival sequence. Now consider the whole space of possible arrival sequences. Foreach arrival sequence, A, consider the following ratio: rP(A)=E[T(A)]P E[T(A)]OPT, whereE[T(A)]Pis the expected response time of policy Pon arrival sequence A. Then the competitive ratio of policyPis deﬁned as Competitive ratio of P=m a x ArP(A). In worst-case analysis, the higher the competitive ratio of a policy, the “worse” that policy is. Note that a policy Pcan have a high competitive ratio even if it performs poorly on just a single arrival sequence. 24.3 optimal server farm design 425 Worst-case analysis can yield a very different ranking of policies than that obtained by the stochastic analysis described in most of this book.",3070
24.3 Optimal Server Farm Design,"A policy Pcan be viewed as very poor in a worst-case sense, because it performs badly on one particular arrival sequence, but that arrival sequence can be a very low-probability event in a stochastic sense. Question: Returning to the question of optimal server farm design, what are good routing/scheduling policy choices? Hint: For the case of a single queue, with fully preemptible jobs, where we know the size of the job, what is the best scheduling policy on every arrival sequence? Answer: In Exercise 2.3, we proved that the SRPT policy, which always (preemptively) runs that job with the shortest remaining processing time, is optimal with respect to mean response time, for the case of a single queue. This result was originally provedin [159] and holds under any arrival sequence of job sizes and arrival times. The optimality of SRPT for a single queue inspires the server farm conﬁguration shown in Figure 24.8. It is like an M/G/k, except that the central queue is served in SRPT order. Speciﬁcally, the khosts are always serving those kjobs with the currently shortest remaining processing times. Suppose, WLOG, that server iis working on a job with remaining processing requirement ri, where ri>rj, for all active servers j. Then, if a job comes in with shorter remaining time than ri, that arrival is immediately put into service at the ith server, and the prior job being served at the ith server is put back into the queue. We refer to this as the Central-Queue-SRPT policy. SRPT Incomin g jobs Figure 24.8. Server farm with Central-Queue-SRPT policy. The Central-Queue-SRPT policy looks very good. Because at every moment of time thekjobs with shortest remaining processing time are those in service, the server farm behaves very much like a single queue with a server that is ktimes the speed. Question: Is Central-Queue-SRPT optimal in the worst-case sense? That is, does Central-Queue-SRPT minimize E[T]on every arrival sequence? Answer: Sadly, the answer is no. The following is an example of a “bad” arrival sequence, for the case of a 2-server system, where Central-Queue-SRPT does not produce the minimal mean response time. This is adapted from [ 119]: rAt time 0, 2 jobs of size 29arrive, as well as 1 job of size 210. rAt time 210, 2 jobs of size 28arrive, as well as 1 job of size 29. rAt time 210+29, 2 jobs of size 27arrive, as well as 1 job of size 28. rAt time 210+29+28, 2 jobs of size 26arrive, as well as 1 job of size 27. rA n ds of o r t h ... 426 task assignment policies for server farms Let’s name our two servers, server A and server B. The optimal algorithm, at time 0, will run the 2 jobs of size 29on server A and will simultaneously run the job of size 210 on server B. By time 210, all work that arrived at time 0will be complete. At time 210, the optimal algorithm will run the 2 jobs of size 28on server A and will simultaneously run the job of size 29on server B, and so forth. The point is that the optimal algorithm is always able to pack the jobs in such a way that the servers are both fully utilized at all times.",3068
24.3 Optimal Server Farm Design,"By contrast, Central-Queue-SRPT makes a mess of this arrival sequence. At time 0,i t tries to run one of the jobs of size 29on server A and the other job of size 29on server B, because these are the jobs with smallest remaining time. Only when these complete does Central-Queue-SRPT start to run the job of size 210, leaving one of the servers idle. Unfortunately, this does not leave enough time to complete the job of size 210, which must be preempted at time 210when the next batch of jobs comes in. Central-Queue- SRPT continues its mistakes, by now running one of the jobs of size 28on server A and the other job of size 28on server B. Only when these complete does it start to run the job of size 29. Unfortunately, there is not enough time for the job of size 29to complete be- fore the new batch of jobs arrive, etc. Central-Queue-SRPT packs the jobs badly, so that the two servers are not both fully utilized; hence, resources are wasted and jobs do not complete. Although the Central-Queue-SRPT algorithm performs particularly badly on this ar- rival sequence, Leonardi and Raz [ 119] prove that it is still the best possible online algorithm from a worst-case competitive-ratio perspective. It is shown in [ 119] that the competitive ratio of Central-Queue-SRPT is proportional to log/parenleftbigb s/parenrightbig , where bis the biggest job size possible and sis the smallest job size possible, and that no online algorithm can improve on this competitive ratio by more than a constant multiplicative factor. It is important to note that, although the Central-Queue-SRPT algorithm is not optimal in a worst-case sense, that does not mean that it is not optimal in a stochastic sense. For example, it might be the best possible policy given a Poisson arrival process and i.i.d. job sizes from any general distribution. Unfortunately, we do not knowthe answer to this question, because no one to date has been able to analyze theCentral-Queue-SRPT policy from a stochastic perspective, even under a Poisson arrivalprocess and Exponentially distributed job sizes. The closest approximation to this is [89], which analyzes an M/PH/k queue with an arbitrary number of preemptive priority classes, where jobs are prioritized in order of shortest expected remaining time. Unfortunately, the results in [ 89] are numerical in form; no closed-form analysis exists. Analyzing Central-Queue-SRPT stochastically is an important open problem inqueueing. A related open problem is the question of optimal task assignment under the restriction that jobs need to be immediately dispatched to hosts, meaning that they cannot be held in a central queue. This restriction is of practical importance, because, in manyapplications, like web servers, the request needs to be assigned to a host that can immediately establish a connection with the client. In the case where jobs need to be 24.3 optimal server farm design 427 immediately assigned to hosts, it is optimal to run SRPT scheduling at the individual hosts.2Thus we have the architecture shown in Figure 24.9. SRPT SRPT SRPTHigh-speed RouterT ask Assi gnment Policy Incomin g  jobs Figure 24.9. Server farm with immediate dispatch and SRPT scheduling at the hosts. Question: Given SRPT scheduling at the individual hosts as in Figure 24.9, what is a good (immediate dispatch) task assignment policy for minimizing mean responsetime? Hint: SRPT is very effective at getting short jobs out. Answer: Simple RANDOM task assignment is not a bad policy here, because each queue then looks like an M/G/1/SRPT queue with arrival rate λ/k and mean job size E[S]. The idea proposed independently by [ 9] and by [ 49] is to go a step further and make sure that the short jobs are spread out over all the SRPT servers, so that the servers can each be working on getting as many short jobs out as possible. Speciﬁ- cally, the IMD algorithm in [ 9] divides jobs into size classes (small, medium, large, etc.) and then assigns each incoming job to the server with the smallest number of jobs in that size class. The point is to make sure that each server has some smalls,some mediums, and some larges, so that their SRPT scheduling can be maximallyeffective. Avrahami and Azar [ 9] prove that when the server farm in Figure 24.9 is run with the IMD task assignment policy, the performance is on the order of that achieved by Central-Queue-SRPT in a worst-case sense, meaning that the two algorithms result incompetitive ratios within a constant factor of each other. An exact stochastic analysisof IMD is not known, although an approximation is given in [ 49]. Summary This section has looked at server farm conﬁgurations using “optimal” task assignment/ scheduling policy pairings. Almost all the available analysis is worst-case analysis. 2Using proof by contradiction, one can argue that not running SRPT scheduling at the host will only increase mean response time.",4905
24.4 Readings and Further Follow-up,"428 task assignment policies for server farms Unfortunately, there is almost no stochastic analysis known for any of the models that we considered. This is also a wide-open area. A reader interested in working on suchanalysis should ﬁrst read Chapters 32and33, which consider SRPT and related variants for a single-server system. 24.4 Readings and Further Follow-up Below we list additional references on the topic of task assignment for server farms. More on SITA and Its Variants for Server Farms with FCFS Servers It is not clear where the idea of size-based task assignment originated, because it has been part of the common wisdom for a long time. Size-based splitting was usedin the Cornell Theory Center [ 99]. The SITA policy was formally introduced by Harchol-Balter, Crovella, and Murta in [ 83]. In a follow-up paper [ 82], Harchol-Balter introduced a variant of SITA called TAGS that does not require knowing the size of the job, but nevertheless achieves response times close to those of SITA. The SITA policyand its variants have been the focus of many papers including [ 99,83,82,177,50, 134,41,172,65,32,11,59,36,161]. Because of SITA’s beneﬁts in reducing job size variability, for a very long time it was believed that SITA, or some SITA-like variant,was far superior to LWL =M/G/k with respect to mean response time when the job size variability was very high. Many papers speciﬁcally compared the performance of SITA to LWL and found that, as job size variability is increased , SITA becomes far superior to LWL [ 32,41,50,65,82,83,134,172,177]. Although the above papers suggest that SITA should be superior to LWL under high job size variability, [ 90] ﬁnds that the opposite can actually be true for certain job size distributions and loads, as explained in this chapter. This work was further extended in [ 91], where variants of SITA were considered that combine the strengths of SITA and LWL. For example [ 91] considers an M/G/2 server farm, where the top server only serves small jobs, but the bottom server can serve any job, referred to as Hybrid . Surprisingly, [ 91] proves that even Hybrid can sometimes be inferior to LWL. More on M/G/k and G/G/k The mean response time for the M/G/k, and hence also G/G/k, remains a longstand- ing open problem in the queueing literature [ 76]. After the Lee and Longton [ 118] approximation in 1959, many other authors proposed alternative simple closed-formapproximations for mean waiting time; see [ 97,98,112,132,26,196]. Unfortunately, all of these closed-form approximations also involve only the ﬁrst 2 moments of thejob size distribution, which is shown to be insufﬁcient in [ 76]. There are several key analytical papers that are concerned with the G/G/k under high job size variability. Scheller-Wolf and Sigman [ 156,155] prove an upper bound on mean delay in a G/G/k system where this upper bound does not depend on any moment 24.4 readings and further follow-up 429 of service time higher than thek+1 kmoment, and it particularly does not depend on the variance of job size. The [ 155] result requires that the resource requirement, R, is not too high: R<⌊k/2⌋(where R=kρ). However, [ 156] generalizes the result to allow for higher load, R<k−1. The converse of the [ 156,155] results was presented by Scheller-Wolf and Vesilo in [ 158] for a large class of distributions. It is known that ifR>k−1, then the G/G/k diverges as C2→∞ [157], where C2is the squared coefﬁcient of variation of the job size. Whitt [ 184] and Foss and Korshunov [ 64] consider a G/G/2 and study the delay tail behavior when job size is heavy-tailed. They ﬁnd that for low load, the delay tail grows like the tail of the equilibrium distribution, squared, whereas for high load the delay tail grows like the tail of the equilibrium distribution. These results are consistent with[155] and [ 158]. More on JSQ For the case of server farms with PS servers, there has been very little analysis of JSQ, see [ 79]. However, there is a substantive simulation study by Bonomi [ 25] that examines both JSQ and a few policies that improve slightly over JSQ (5 percent improvement) by exploiting knowledge of the remaining service times of jobs. By contrast, there is a lot of work on JSQ for server farms with FCFS scheduling at the servers. For workloads with non-decreasing failure rate, where job sizes are notknown a priori, the JSQ policy is provably optimal [ 180,194,52]. As we have pointed out, however, JSQ is far from optimal for FCFS servers with highly variable job sizes [83,82]. Almost all papers analyzing JSQ for server farms with FCFS servers are limited to k=2servers, an Exponential job size distribution, and the mean response time metric. Even here, the papers are largely approximate and often require truncation of the state space or of some inﬁnite sums [ 108,61,73,44,146,122,3]. Sometimes the results are exact, but are not computationally efﬁcient and do not generalize to higher values of k [27]. For analyzing JSQ with more than k=2 servers, for the case of server farms with FCFS servers, again with Exponential job sizes, only approximations exist. Nelsonand Philips [ 128] use the following idea: They look at the steady-state probability of the M/M/k queue (with a central queue) as an estimate for the total number of jobs in the JSQ/FCFS system; they then assume that the jobs in the system are dividedequally (within 1) among each of the queues. Lin and Raghavendra [ 120] follow the approach of approximating the number of busy servers by a Binomial distribution andthen also assume that the jobs are equally divided among each of the queues (within 1). Both approximations are surprisingly accurate, with reported accuracy in the 2 percent to8 percenterror range. There are also some numerical methods papers that do not lead to a closed-form solution, but are accurate and computationally efﬁcient for not-too-large k; see for example [ 2,122,4].",5932
24.5 Exercises,"430 task assignment policies for server farms Finally, Bramson, Lu, and Prabhakar [ 30] consider the limiting regime where the number of queues goes to inﬁnity ( k→∞ ). In this regime they prove that, for any ﬁxed number of queues, the numbers of jobs at each of the queues become independent. This allows them to derive various performance metrics, including queue lengths. Cycle Stealing in Server Farms The performance of server farms can be improved dramatically by allowing servers to share their work. Cycle stealing is the idea of allowing an idle server to take on some work from a busy server’s queue. Analyzing the performance of a server farm with cycle stealing has the same difﬁculties as analyzing JSQ, because one needs to trackthe number of jobs at each server, resulting in a Markov chain that grows unboundedlyin kdimensions. Even for k=2 this is only approximable. There are a long list of approximations for different variants of cycle stealing, including approximations based on truncating the state space along one of the dimensions [ 74,170,171]; approximations based on boundary-value methods [ 55,113,43]; heavy-trafﬁc techniques [ 17,63]; approximations based on the idea of Dimensionality Reduction of Markov chains [86,136,89,88,192,20,137,138,87,135]; and others [ 168,193]. 24.5 Exercises 24.1 Server Farm with Size-Interval-Task-Assignment We are given a server farm with 2 identical FCFS hosts. Arrivals into the system occur according to a Poisson process with rate λ. Job sizes follow a power-law distribution, denoted by random variable S, where P{S>x}=x−2.5,f o r 1≤x<∞. Small jobs (those of size <10) are routed to the ﬁrst server, and large jobs (those of size ≥10) are routed to the second server. (a) Derive the mean response time, E[T], for this system. (b) What would E[T]be if the job size distribution were changed to P{S>x}=x−1.5,f o r1≤x<∞. 24.2 PS Server Farm Consider a server farm with 2 identical PS hosts and SITA task assignment. Arrivals into the system occur according to a Poisson process with rate λ. Job sizes follow some (general) distribution. Prove that the SITA cutoff which minimizes mean response time is that which balances load between the two hosts. 24.3 Hybrid Server Farm We are given a server farm with 2 identical hosts. Arrivals into the system occur according to a Poisson process with rate λ. Job sizes are denoted by the random variable S, with p.d.f. fS(t), where 0≤t≤∞ , and c.d.f. FS(t)= P{S<t}. Because our job size distribution FShas high variability, we decide to combat this by using a variant of size-interval scheduling, where small jobs are sent to server 1, where they are scheduled in FCFS order, and large jobs are sentto server 2, where they are scheduled according to PS. Assume that the size 24.5 exercises 431 cutoff is chosen such that load is balanced between “small” and “large” jobs. Speciﬁcally, ρ=λE[S] 2represents both the load of the server farm and the load at each host. Suppose that this (balanced-load) size cutoff is 10. Thus a job is considered “small” if its size is less than 10, and is called “large” otherwise. FCFS PS Poisson ( λ) Write an expression for E[T], the mean response time experienced by an arriving job, as a function of ρ,λ,fS(t), andFS(t). 24.4 Equivalence of LWL and M/G/k Assume that LWL and M/G/k are fed the same arrival sequence of jobs and are both run on kservers. Assume also that ties are resolved the same way in both systems. Prove by induction that each job is served by the same server in both the systems. Furthermore, the job begins and ends service at the same time in both systems. 24.5 One Fast Machine versus Two Slow Ones Consider the question of whether one fast machine or two slow ones is better for minimizing mean waiting time, E[TQ]. Each slow machine works at half the rate of the single fast machine. Speciﬁcally, a job that requires sseconds of processing time on the fast machine will require 2sseconds of processing time on a single slow machine. (a) Back in Chapter 14, we addressed this question for the M/M/k, where job sizes were drawn from an Exponential distribution. Which architecture (one fast or two slow) was superior there? (b) Does the answer change when the job size distribution is not Exponential? Speciﬁcally, consider the following distribution of job sizes: r100 101fraction of the jobs have service requirement (size) 0.01 seconds when run on a slow machine. These are called small jobs. r1 101fraction of the jobs have service requirement (size) 1 second when run on a slow machine. These are called large jobs. Observe that this job size distribution has the heavy-tail property, whereby the 1 percent largest jobs comprise about half the total load. Assume jobs arrive according to a Poisson process with rate λ, and consider two ways of processing the workload: 1. Use a single “fast” machine: M/G/1. 2. Use two slow machines and split the incoming jobs so that small jobs go to machine 1 and large jobs go to machine 2. Compute E[TQ]as a function of λin both of these cases. Which case results in a lower E[TQ]? Explain what is going on. If we had deﬁned the job size distribution to be less heavy-tailed, would the answer change? 432 task assignment policies for server farms 24.6 To Balance Load or Not to Balance Load? The purpose of this problem is to determine whether load balancing between two identical FCFS hosts is always a good idea for minimizing E[TQ], or whether we might want to purposely unbalance load. Assume that jobs arrive from outside according to a Poisson process with rate λ, where S denotes the job size, and the system load is ρ=λE[S] 2=0.5. Assume a Bounded Pareto (k=.0009,p=1 010,α=0.5)job size distribution with mean 3,000. (a) First consider the SITA-E task assignment policy, where the size cutoff, x, is chosen to equalize the load at the two hosts (E stands for “equalize load”). i. What is the cutoff xunder SITA-E? ii. What fraction of jobs are sent to each host under SITA-E? iii. What is the mean delay, E[TQ], under SITA-E? iv. What is E[TQ]under RANDOM, and how does this compare with E[TQ]under SITA-E? (b) Returning to SITA-E, now purposely unbalance the load by dropping x, the SITA-E cutoff. i. Try different values of xand record the corresponding E[TQ].A p - proximately how low should xbe to minimize E[TQ]? ii. What is the load at each host under this new cutoff x? iii. What fraction of jobs are sent to each host under this new cutoff x? 24.7 A Better SITA-E? Based on [ 10]. Consider a server farm with two identical FCFS hosts and SITA-E task assignment (see Exercise 24.6). Eitan proposes a new cutoff heuristic: rather than ﬁnding cutoffs which balance load, we instead de- rive cutoffs which equalize the expected number of queued jobs, E[NQ], at each host. Determine whether Eitan’s idea is useful by evaluating it on the workload from Exercise 24.6: Assume that jobs arrive from outside ac- cording to a Poisson process, with system load ρ=λE[S] 2=0.5. Assume aBP(k=.0009,p=1 010,α=0.5)job size distribution with mean 3,000. Which cutoff scheme (balanced load or Eitan’s scheme) is better for minimiz-ing overall mean delay, E[TQ]? How does Eitan’s heuristic for ﬁnding cutoffs compare with using the optimal cutoff? 24.8 Additional Recommended Problem Exercise 21.7 on understanding the effect of job size variability in an M/G/2 system is recommended as well.",7399
Chapter 25 Transform Analysis. 25.1 Definitions of Transforms and Some Examples,"CHAPTER 25 Transform Analysis This chapter is a very brief introduction to the wonderful world of transforms. One can think of the transform of a random variable as an onion. This onion is an expressionthat contains inside it all the moments of the random variable. Getting the momentsout of the onion is not an easy task, however, and may involve some tears as the onionis peeled, where the “peeling process” involves differentiating the transform. The ﬁrst moment is stored in the outermost layer of the onion and thus does not require toomuch peeling to reach. The second moment is stored a little deeper, the third momenteven deeper (more tears), etc. Although getting the moments is painful, it is entirelystraightforward how to do it – just keep peeling the layers. Transforms are a hugely powerful analysis technique. For example, until now we have only learned how to derive the mean response time, E[T], for the M/G/1. However, by the end of the next chapter, we will be able to derive the transform of T, which will allow us to obtain any desired moment of T. The subject of transforms is very broad. In this chapter we only cover a small subset, namely those theorems that are most applicable in analyzing the performance of queues. We use transforms heavily in analyzing scheduling algorithms in Part VII. 25.1 Deﬁnitions of Transforms and Some Examples Deﬁnition 25.1 The Laplace transform ,Lf(s), of a continuous function, f(t), t≥0, is deﬁned as Lf(s)=/integraldisplay∞ 0e−stf(t)dt. You can think of sas just being some parameter, where the Laplace transform is a function of s. When we speak of the Laplace transform of a continuous random variable (r.v.), X, we are referring to the Laplace transform, Lf(s), of the p.d.f., fX(·), associated with X. We write/tildewideX(s)to denote the Laplace transform of X. Observe that if Xis a continuous r.v. and f(t),t≥0, is the p.d.f. of X, then /tildewideX(s)=Lf(s)=E/bracketleftbig e−sX/bracketrightbig . 433 434 transform analysis Example: Derive the Laplace transform of X∼Exp(λ): /tildewideX(s)=Lf(s)=/integraldisplay∞ 0e−stλe−λtdt=λ/integraldisplay∞ 0e−(λ+s)tdt=λ λ+s Example: Derive the Laplace transform of X=a, where ais some constant: /tildewideX(s)=Lf(s)=e−sa Example: Derive the Laplace transform of X∼Uniform (a, b),a, b≥0: /tildewideX(s)=Lf(s)=/integraldisplay∞ 0e−stf(t)dt =/integraldisplayb ae−st1 b−adt =/parenleftbigg−e−sb s+e−sa s/parenrightbigg1 b−a =e−sa−e−sb s(b−a) (Observe that here f(t)is deﬁned to be 0when it is outside the (a, b)range.) Question: How do we know that the Laplace transform as deﬁned necessarily con- verges? Answer: (Partial) It does if f(t)is a p.d.f. of some non-negative random variable and s≥0. To see this observe that e−t≤1, for all non-negative values of t. Thus e−st=/parenleftbig e−t/parenrightbigs≤1, assuming that sis non-negative. Thus, Lf(s)=/integraldisplay∞ 0e−stf(t)dt≤/integraldisplay∞ 01·f(t)dt=1. Deﬁnition 25.2 The z-transform ,Gp(z), of a discrete function, p(i),f o ri=0, 1,2,... is deﬁned as: Gp(z)=∞/summationdisplay i=0p(i)zi. Observe that the z-transform is a polynomial in z. When we speak of the z-transform of a discrete r.v. X, we are referring to the z-transform of the p.m.f., pX(·), associated 25.1 deﬁnitions of transforms and some examples 435 withX. We write/hatwideX(z)to denote the z-transform of X. Observe that if Xis a discrete r.v. and p(i),i=0,1,2,..., is its p.m.f., then /hatwideX(z)=Gp(z)=E/bracketleftbig zX/bracketrightbig . Example: Derive the z-transform of X∼Binomial (n, p): /hatwideX(z)=Gp(z)=n/summationdisplay i=0/parenleftbiggn i/parenrightbigg pi(1−p)n−izi =n/summationdisplay i=0/parenleftbiggn i/parenrightbigg (zp)i(1−p)n−i =(zp+( 1−p))n Example: Derive the z-transform of X∼Geometric (p): /hatwideX(z)=Gp(z)=∞/summationdisplay i=1p(1−p)i−1zi =zp∞/summationdisplay i=1(z(1−p))i−1 =zp 1−z(1−p) Deﬁnition 25.3 The random variable Atwill be used to denote the number of arrivals by time t, where the arrival process is Poisson (λ). Example : Derive the z-transform of At: /hatwiderAt(z)=Gp(z)=∞/summationdisplay i=0(λt)ie−λtzi i. =e−λt∞/summationdisplay i=0(λtz)i i. =e−λt·eλtz =e−λt(1−z) Deﬁnition 25.4 The random variable ASwill be used to denote the number of arrivals by time S, where Sis a random variable (typically denoting service time), and the arrival process is Poisson (λ).",4344
25.2 Getting Moments from Transforms Peeling the Onion,"436 transform analysis Example: Derive the z-transform of AS: /hatwiderAS(z)=∞/summationdisplay i=0P{AS=i}zi =∞/summationdisplay i=0/parenleftbigg/integraldisplay∞ 0P{AS=i|S=t}fS(t)dt/parenrightbigg zi =∞/summationdisplay i=0/parenleftbigg/integraldisplay∞ 0e−λt(λt)i i.fS(t)dt/parenrightbigg zi =/integraldisplay∞ 0e−λtfS(t)∞/summationdisplay i=0(λtz)i i.dt =/integraldisplay∞ 0e−λtfS(t)eλtzdt =/integraldisplay∞ 0e−λ(1−z)tfS(t)dt =LS(λ(1−z)) =/tildewideS(λ(1−z)) (25.1) (We will see a quicker way to derive /hatwiderAS(z)soon.) 25.2 Getting Moments from Transforms: Peeling the Onion Theorem 25.5 LetXbe a continuous r.v. with p.d.f. f(t),t≥0. Then E[Xn]=(−1)ndnLf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0. Even if f(t)is not a p.d.f., it still holds that /integraldisplay∞ t=0tn·f(t)dt=(−1)ndnLf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0. Note: If the above moments are not deﬁned at s=0, one can instead consider the limit as s→0, where evaluating the limit may require using L’Hospital’s rule. Proof e−st=1−(st)+(st)2 2.−(st)3 3.+... e−stf(t)=f(t)−(st)f(t)+(st)2 2.f(t)−(st)3 3.f(t)+... 25.2 getting moments from transforms: peeling the onion 437 Lf(s)=/integraldisplay∞ 0e−stf(t)dt =/integraldisplay∞ 0f(t)dt−/integraldisplay∞ 0(st)f(t)dt+/integraldisplay∞ 0(st)2 2.f(t)dt−/integraldisplay∞ 0(st)3 3.f(t)dt+... =1−sE[X]+s2 2.E/bracketleftBig X2/bracketrightBig −s3 3.E/bracketleftBig X3/bracketrightBig +... dLf(s) ds=−E[X]+sE/bracketleftBig X2/bracketrightBig −3s2 3.E/bracketleftBig X3/bracketrightBig +... dLf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=−E[X] d2Lf(s) ds=E/bracketleftBig X2/bracketrightBig −sE/bracketleftBig X3/bracketrightBig +... d2Lf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=E/bracketleftBig X2/bracketrightBig We can see from the original Taylor series expansion that each time we take another derivative, we get a higher moment, with alternating sign. Example: Compute the kth moment of X∼Exp(λ): /tildewideX(s)=Lf(s)=λ λ+s E[X]=−dLf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=−−λ (λ+s)2/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=1 λ E/bracketleftbig X2/bracketrightbig =(−1)2d2Lf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=d ds/parenleftbigg−λ (λ+s)2/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=2λ (λ+s)3/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=2 λ2 E/bracketleftbig Xk/bracketrightbig =(−1)kdkLf(s) ds/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=k.λ (λ+s)k+1/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0=k. λk Theorem 25.6 ForXa discrete r.v. with p.m.f. p(i),i=0,1,2,..., the sequence /braceleftBig G(n) p(z)/vextendsingle/vextendsingle z=1:n≥1/bracerightBig provides the moments of X, as follows: G/prime p(z)|z=1=E[X] G/prime/prime p(z)|z=1=E[X(X−1)] G/prime/prime/prime p(z)|z=1=E[X(X−1)(X−2)] G(n) p(z)|z=1=E[X(X−1)(X−2)···(X−n+1 ) ] Note: If the above moments are not deﬁned at z=1, one can instead consider the limit as z→1, where evaluating the limit may require using L’Hospital’s rule. 438 transform analysis Proof Here we illustrate how the moments pop out of the sequence. The proof can be obtained formally via induction. Gp(z)=∞/summationdisplay i=0p(i)zi G/prime p(z)=d dz/parenleftBigg∞/summationdisplay i=0p(i)zi/parenrightBigg =d dz/parenleftBigg∞/summationdisplay i=1p(i)zi/parenrightBigg =∞/summationdisplay i=1ip(i)zi−1 G/prime p(z)/vextendsingle/vextendsingle z=1=∞/summationdisplay i=1ip(i)=E[X] G/prime/prime p(z)=d dz/parenleftBigg∞/summationdisplay i=1ip(i)zi−1/parenrightBigg =d dz/parenleftBigg∞/summationdisplay i=2ip(i)zi−1/parenrightBigg =∞/summationdisplay i=2i(i−1)p(i)zi−2 G/prime/prime p(z)/vextendsingle/vextendsingle z=1=∞/summationdisplay i=2i(i−1)p(i)=E[X(X−1)] G/prime/prime/prime p(z)=d dz/parenleftBigg∞/summationdisplay i=2i(i−1)p(i)zi−2/parenrightBigg =d dz/parenleftBigg∞/summationdisplay i=3i(i−1)p(i)zi−2/parenrightBigg =∞/summationdisplay i=3i(i−1)(i−2)p(i)zi−3 G/prime/prime/prime p(z)/vextendsingle/vextendsingle z=1=∞/summationdisplay i=3i(i−1)(i−2)p(i)=E[X(X−1)(X−2)] Example: Compute the variance of X∼Geometric (p): /hatwideX(z)=zp 1−z(1−p) E[X]=d dz/parenleftbiggzp 1−z(1−p)/parenrightbigg/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1=p (1−z(1−p))2/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1=1 p E/bracketleftbig X2/bracketrightbig =/hatwideX/prime/prime(z)/vextendsingle/vextendsingle/vextendsingle z=1+E[X]=2p(1−p) (1−z(1−p))3/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1+1 p =2(1−p) p2+1 p=2−p p2 Var(X)=E/bracketleftbig X2/bracketrightbig −(E[X])2=1−p p2",4750
25.3 Linearity of Transforms,"25.3 linearity of transforms 439 Example: Use transforms to compute the ﬁrst moment of AS, the number of arrivals during a service time, where S∼Exp(μ). We show here two ways to do this. It is good to know both. The ﬁrst way is by expanding the transform and then differentiating it: /hatwiderAS(z)=/tildewideS(λ(1−z)) =μ μ+λ(1−z) /hatwiderAS/prime(z)=μλ (μ+λ(1−z))2 E[AS]=/hatwiderAS/prime(z)/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1=μλ μ2=λ μ The second way does not expand the transform, so the chain rule needs to be applied. E[AS]=/hatwiderAS/prime(z)/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1 =d dz/tildewideS(λ(1−z))/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1 =/tildewideS/prime(λ(1−z))/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1·(−λ)/vextendsingle/vextendsingle/vextendsingle/vextendsingle z=1 =/tildewideS/prime(0)·(−λ) =−E[S]·(−λ) =λ μ 25.3 Linearity of Transforms Theorem 25.7 LetXandYbe continuous, independent random variables with p.d.f.x(t),t≥0, andy(t),t≥0, respectively. Let Z=X+Ywhere z(t),t≥0, is the p.d.f. of Z. Then the Laplace transform of Zis given by /tildewideZ(s)=/tildewideX(s)·/tildewideY(s). (25.2) In particular, if X1,...,X nare i.i.d. random variables, and Z=X1+···+Xn, then/tildewideZ(s)=(/tildewideX(s))n. Let the convolution of x(·)andy(·)beg=x⊗y, where g(t)=/integraldisplayt 0x(t−k)y(k)dk. Then the Laplace transform of g(t), denoted by Lg(s), is given by Lg(s)=Lx⊗y(s)=Lx(s)Ly(s), (25.3) even when XandYare not independent (although g(t)only equals z(t)when X⊥Y). 440 transform analysis Proof LetX⊥Y, andZ=X+Y. Then /tildewideZ(s)=/integraldisplay∞ 0e−stz(t)dt =/integraldisplay∞ 0e−st/integraldisplayt k=0z(t|Y=k)·y(k)dk dt (25.4) =/integraldisplay∞ 0e−st/integraldisplayt k=0x(t−k|Y=k)·y(k)dk dt (25.5) =/integraldisplay∞ 0e−st/integraldisplayt k=0x(t−k)·y(k)dk dt (25.6) =/integraldisplay∞ k=0y(k)/integraldisplay∞ t=ke−stx(t−k)dt dk (25.7) =/integraldisplay∞ k=0y(k)e−sk/integraldisplay∞ t=ke−s(t−k)x(t−k)dt dk =/integraldisplay∞ k=0y(k)e−sk/integraldisplay∞ v=0e−svx(v)dv dk (letting v=t−k,dv=dt) =Ly(s)·Lx(s) =/tildewideY(s)·/tildewideX(s) (25.8) Question: In proving ( 25.2), where was the independence of XandYused? Answer: In moving from ( 25.5)t o( 25.6). Question: The proof of ( 25.3) should notrequire that XandYare independent. How is this possible? Answer: The proof of ( 25.3) starts on line ( 25.6) above. It therefore does not depend onXandYbeing independent. Here is an alternative proof of ( 25.2), assuming that XandYare independent: Proof /tildewideZ(s)=E/bracketleftbig e−sZ/bracketrightbig =E/bracketleftbig e−s(X+Y)/bracketrightbig =E/bracketleftbig e−sX·e−sY/bracketrightbig =E/bracketleftbig e−sX/bracketrightbig ·E/bracketleftbig e−sY/bracketrightbig (because X⊥Y) =/tildewideX(s)·/tildewideY(s) Theorem 25.8 LetXandYbe discrete independent random variables. Let Z= X+Y. Then the z-transform of Zis given by/hatwideZ(z)=/hatwideX(z)·/hatwideY(z).",2984
25.4 Conditioning,"25.4 conditioning 441 Proof The proof follows exactly the lines of the proof of Theorem 25.7 and can again be done in two ways; see Exercise 25.1. Example: LetX∼Binomial (n,p)andY∼Binomial (m, p)be independent random variables. What is the distribution of X+Y? /hatwideZ(z)=/hatwideX(z)·/hatwideY(z) =(zp+( 1−p))n(zp+( 1−p))m =(zp+( 1−p))m+n Observe that (zp+( 1−p))m+nis the z-transform of a Binomial random variable with parameters m+nandp. Thus, the distribution of X+Yis Binomial (m+n,p). 25.4 Conditioning Theorem 25.9 LetX,A, andBbe continuous random variables where X=/braceleftbiggAwith probability p Bwith probability 1−p. Then /tildewideX(s)=p·/tildewideA(s)+( 1−p)·/tildewideB(s). Proof /tildewideX(s)=E/bracketleftbig e−sX/bracketrightbig =E/bracketleftbig e−sX/vextendsingle/vextendsingleX=A/bracketrightbig ·p+E/bracketleftbig e−sX/vextendsingle/vextendsingleX=B/bracketrightbig ·(1−p) =pE/bracketleftbig e−sA/bracketrightbig +( 1−p)E/bracketleftbig e−sB/bracketrightbig =p/tildewideA(s)+( 1−p)/tildewideB(s) Theorem 25.10 LetX,A, andBbe discrete random variables where X=/braceleftbiggAwith probability p Bwith probability 1−p. Then /hatwideX(z)=p·/hatwideA(z)+( 1−p)·/hatwideB(z). 442 transform analysis Proof /hatwideX(z)=E/bracketleftbig zX/bracketrightbig =E/bracketleftbig zX/vextendsingle/vextendsingleX=A/bracketrightbig ·p+E/bracketleftbig zX/vextendsingle/vextendsingleX=B/bracketrightbig ·(1−p) =E/bracketleftbig zA/bracketrightbig ·p+E/bracketleftbig zB/bracketrightbig ·(1−p) =p/hatwideA(z)+( 1−p)/hatwideB(z) We can generalize Theorems 25.9 and25.10 . Theorem 25.11 is a generalization of Theorem 25.9. The generalization for Theorem 25.10 follows similarly. Theorem 25.11 LetYbe a continuous random variable, and let XYbe a continu- ous random variable that depends on Y. Then, if fY(y)denotes the density function ofY, we have that /tildewidestXY(s)=/integraldisplay∞ y=0/tildewiderXy(s)fY(y)dy. Proof /tildewidestXY(s)=E/bracketleftbig e−sXY/bracketrightbig =/integraldisplay∞ y=0E/bracketleftbig e−sXY/vextendsingle/vextendsingleY=y/bracketrightbig ·f Y(y)dy =/integraldisplay∞ y=0E/bracketleftbig e−sXy/bracketrightbig ·fY(y)dy =/integraldisplay∞ y=0/tildewiderXy(s)·fY(y)dy Example Recall the lengthy derivation of /hatwiderAS(z), resulting in ( 25.1). We now show a much faster derivation via conditioning. We condition on Sas follows: /hatwiderAS(z)=/integraldisplay∞ 0/hatwiderAS(z|S=t)fS(t)dt =/integraldisplay∞ 0/hatwiderAt(z)fS(t)dt =/integraldisplay∞ 0e−λ(1−z)tfS(t)dt =/tildewideS(λ(1−z)) (25.9)",2537
25.8 Readings,"25.5 distribution of response time in an m/m/ 1 443 25.5 Distribution of Response Time in an M/M/1 Suppose we want to derive the distribution of the response time Tfor the M/M/1. We can leverage the fact that we know the distribution of N, the number in system, to get the Laplace transform of T. LetTkbe the response time, given that the arrival ﬁnds kjobs in the system. Then, by Theorem 25.9 and its generalizations, we have /tildewideT(s)=∞/summationdisplay k=0/tildewiderTk(s)·P(kin system ). Now observe that Tk=S1+S2+···+Sk+Sk+1, where Siis the size of the ith job in the system, and Sk+1is the size of the arrival. Since the Si’s are i.i.d., by Theorem 25.7, /tildewiderTk(s)=/parenleftBig /tildewideS(s)/parenrightBigk+1 =/parenleftbiggμ s+μ/parenrightbiggk+1 . Finally, /tildewideT(s)=∞/summationdisplay k=0/parenleftbiggμ s+μ/parenrightbiggk+1 ·ρk(1−ρ) =(1−ρ)μ s+μ·∞/summationdisplay k=0/parenleftbiggμ s+μ·ρ/parenrightbiggk =(1−ρ)μ s+μ·1 1−μρ s+μ =(1−ρ)μ s+μ·s+μ s+μ−μρ =μ−λ s+(μ−λ). Question: What does this say about the distribution of T? Answer: TM/M/1∼Exp(μ−λ). 444 transform analysis 25.6 Combining Laplace and z-Transforms Theorem 25.12 (Summing a Random Number of i.i.d. Random Variables) Let Z=Y1+Y2+...+YX, where the Yi’s are i.i.d. continuous r.v. ’s, and where Xis a discrete random variable, where X⊥Yi,∀i.L e t/hatwideX(z)be the z-transform of X, and let/tildewideY(s)be the Laplace transform of Yi. Then /tildewideZ(s)=/hatwideX/parenleftBig /tildewideY(s)/parenrightBig . Example: Derive the Laplace transform of a Poisson (λ)number of i.i.d. Exp (μ) random variables. Recall that for X∼Poisson (λ)we have that /hatwideX(z)=e−λ(1−z). Recall likewise that for Y∼Exp(μ)we have that /tildewideY(s)=μ s+μ. From this it follows that /tildewideZ(s)=/hatwideX/parenleftBig /tildewideY(s)/parenrightBig =e−λ(1−z)/vextendsingle/vextendsingle/vextendsingle z=μ s+μ=e−λ(1−μ s+μ)=e−λs s+μ. Proof (Theorem 25.12 )Let/tildewideZ(s|X=n)denote the Laplace transform of Z given that X=n. Then, by Theorem 25.7,/tildewideZ(s|X=n)=/parenleftBig /tildewideY(s)/parenrightBign .N o w ,b y conditioning, /tildewideZ(s)=∞/summationdisplay n=0P{X=n}/tildewideZ(s|X=n) =∞/summationdisplay n=0P{X=n}/parenleftBig /tildewideY(s)/parenrightBign =/hatwideX/parenleftBig /tildewideY(s)/parenrightBig . Question: Can we apply Theorem 25.12 to a sum of a random variable number of discrete random variables? 25.7 more results on transforms 445 Answer: Yes, the same proof works, and the ﬁnal result is then /hatwideZ(z)=/hatwideX/parenleftBig /hatwideY(z)/parenrightBig . 25.7 More Results on Transforms Normally we look at the Laplace transform of the p.d.f., but we could also ask what is the Laplace transform of any function. Theorem 25.13 considers the Laplace transform of the c.d.f. and relates that to the Laplace transform of the p.d.f. Theorem 25.13 Consider a p.d.f., b(·), where B(·)is the cumulative distribution function corresponding to b(·). That is, B(x)=/integraldisplayx 0b(t)dt. Let /tildewideb(s)=Lb(t)(s)=/integraldisplay∞ 0e−stb(t)dt. Let /tildewideB(s)=LB(x)(s)=/integraldisplay∞ 0e−sxB(x)dx=/integraldisplay∞ 0e−sx/integraldisplayx 0b(t)dtdx. Then /tildewideB(s)=/tildewideb(s) s. Proof /tildewideB(s)=/integraldisplay∞ x=0e−sx/integraldisplayx t=0b(t)dt dx =/integraldisplay∞ x=0e−st·e−s(x−t)/integraldisplayx t=0b(t)dt dx =/integraldisplay∞ t=0b(t)e−stdt/integraldisplay∞ x=te−s(x−t)dx =/integraldisplay∞ t=0b(t)e−stdt/integraldisplay∞ y=0e−sydy =/tildewideb(s)·1 s Here is one last little bit of information that comes in handy when differentiating transforms.",3584
25.9 Exercises,"446 transform analysis Theorem 25.14 For all random variables, X, /tildewideX(0) = 1 and/hatwideX(1) = 1 . 25.8 Readings There is a lot more that can be said on transforms. For an entire book on the use of transforms in probability modeling, see [ 71]. 25.9 Exercises 25.1 Sums of Discrete Random Variables LetXandYbe discrete independent random variables. Let Z=X+Y. Prove that the z-transform of Zis given by/hatwideZ(z)=/hatwideX(z)·/hatwideY(z). 25.2 Sum of Poissons LetX1∼Poisson (λ1). LetX2∼Poisson (λ2). Suppose X1⊥X2. LetY= X1+X2.H o wi s Ydistributed? Prove it using z-transforms. Note that the parameter for the Poisson denotes its mean. 25.3 Moments of Poisson LetX∼Poisson (λ).D e r i v e E[X(X−1)(X−2)···(X−k+1 ) ] for k=1,2,3,... 25.4 Moments of Binomial LetX∼Binomial (n,p).D e r i v e E[X(X−1)(X−2)···(X−k+1 ) ] fork=1,2,3,... 25.5 Convergence of z-Transform LetpX(i)represent the p.m.f. of a discrete, non-negative r.v. X, and let /hatwideX(z)=/summationtext∞ i=0pX(i)zidenote the z-transform of X. Prove that if |z|≤1, then/hatwideX(z)converges. Speciﬁcally, show that /hatwideX(z)is bounded from above and below. 25.6 Sum of Geometric Number of Exponentials LetN∼Geometric (p). LetXi∼Exp(μ), where the Xi’s are independent of each other and of N. LetSN=/summationtextN i=1Xi. Prove that SNis Exponentially distributed and derive the rate of SN. (a) First do this using δ-step arguments. (b) Now do this again using transforms via Theorem 25.12 . (c) Suppose we are given a Poisson process, where packets are colored “blue” with probability p. What does the above result tell us about the distribution of the spacing between blue packets? 25.7 Practice with Laplace Transforms: A Useful Identity LetXbe an arbitrary random variable. Let Y∼Exp(λ), where XandYare independent. Prove that P{X<Y}=/tildewideX(λ). 25.9 exercises 447 25.8 Review of M/M/1 (a) What do we know about the distribution of N, the number of jobs in an M/M/1? [Hint: It is not quite a Geometric, but it can be expressed as aGeometric plus or minus something.] (b) Given your previous answer, what are E[N]andVar(N)? (c) What do we know about the distribution of T, the M/M/1 response time? (d) Given your previous answer, what are E[T]andVar(T)? (e) Recall the derivation in this chapter for the Laplace transform of T. Follow a similar approach to derive the Laplace transform of TQ, the waiting time for the M/M/1. (f) How can you check that your answer for /tildewiderTQ(s)is correct, given that you know/tildewideT(s)? 25.9 Downloading Files You need to download two ﬁles: ﬁle 1 and ﬁle 2. File 1 is available viasource A or source B. File 2 is available only via source C. The time todownload ﬁle 1 from source A is Exponentially distributed with rate 1. The time to download ﬁle 1 from source B is Exponentially distributed with rate 2. The time to download ﬁle 2 from source C is Exponentially distributed withrate 3. You decide to download from all three sources simultaneously, in the hope that you get both ﬁle 1 and ﬁle 2 as soon as possible. Let Tdenote the time until you get both ﬁles. What is/tildewideT(s)? 25.10 Two-Sided Laplace Transform In the case where a distribution can take on negative values, we deﬁne theLaplace transform as follows: Let Xbe a random variable with density function f(t),−∞<t<∞: /tildewideX(s)=Lf(s)=/integraldisplay∞ −∞e−stf(t)dt LetX∼Normal (0,1)be the standard Normal. Show that /tildewideX(s)=es2 2. 25.11 Transforms Derivation of Burke’s Theorem In an M/M/1, when the server is busy, jobs depart at rate μ. However, when the M/M/1 is idle, then no jobs depart. Thus, the interdeparture times are either dis-tributed Exp (μ)(when the server is busy), or Exp (λ)+Exp(μ)(when idle) – this latter term comes from having to wait for an arrival and then for that arrivalto depart. It is not at all clear how having interarrival times switch between these modes could form a Poisson (λ)departure process. LetTdenote the time between departures. Prove that T∼Exp(λ)by deriving its Laplace transform via conditioning. 25.12 M/M/2/3 In the M/M/2/3, jobs arrive according to a Poisson process with rate λ. There are 2 servers, each serving at rate μ, and a single central queue; however, there is only room for 3 jobs total (one waiting job and two serving jobs). 448 transform analysis When an arrival ﬁnds 3 jobs already in the system, the arrival is dropped; see Figure 25.1. LetTdenote the response time for the M/M/2/3. Derive /tildewideT(s). Poisson ( λ)μ μ Figure 25.1. The M/M/2/3. 25.13 Busy Period in M/M/1 Derive the duration of a busy period in an M/M/1 queue with arrival rate λand service rate μ. A busy period, B, is the time from when a job arrives at an idle system until the system is ﬁrst empty again. (Obviously, the number of jobs may go up and down a lot in between going from state 1 to state 0.) (a) First derive E[B]. How does E[B]compare with E[T]for the M/M/1? (b) At this point, you may be wondering if the busy period is Exponentially distributed. Find out by deriving the Laplace transform of the busy period, /tildewideB(s). [Hint: Conditioning helps. Also, at the very end, you may need to make use of the fact that /tildewideB(0) = 1 ]. 25.14 Transform of Seand Moments of Excess1 Consider a renewal process where Srepresents the time between renewals. F(x)andf(x)are the c.d.f. and p.d.f. for S. We use Seto denote the excess ofS(a.k.a. the equilibrium distribution of S), andFe(x)andfe(x)to denote its c.d.f. and p.d.f. Your job is to calculate the ﬁrst 2 moments of excess: E[Se] andE[S2 e]. (a) Use Renewal-Reward to derive Fe(k), the time-average fraction of time thatSe<k. (b) Differentiate your result in (a) to derive fe(k). You should get fe(k)=F(k) E[S]. (25.10) (c) Derive/tildewiderSe(s)=Lfe(s)and simplify to get /tildewiderSe(s)=1−/tildewideS(s) sE[S]. (25.11) (d) Differentiate /tildewiderSe(s)appropriately to determine the ﬁrst 2 moments of Se. 25.15 Heuristic Proof of Central Limit Theorem via Transforms In this problem, you will derive a heuristic proof of the Central Limit Theorem (CLT). Let X1,X2,...be a sequence of i.i.d. random variables, each with meanμand variance σ2. CLT says that the distribution of X1+X2+···+Xn−nμ σ√n(25.12) 1Warning: the result of this problem will be used repeatedly throughout the rest of the book. 25.9 exercises 449 tends to the standard Normal as n→∞ . Speciﬁcally, P/braceleftbiggX1+X2+···+Xn−nμ σ√n≤a/bracerightbigg →1√ 2π/integraldisplaya −∞e−x2/2dx,asn→∞. The high-level idea in our approach is to show that the Laplace transform of (25.12 ) roughly converges to the Laplace transform of the standard Normal distribution, as given in Exercise 25.10 . Showing that the two transforms are the same implies that ( 25.12 ) and the standard Normal agree on all moments, thus having the same distribution. Let S=X1+X2+···+Xn√n. (a) Start with the case where μ=0andσ2=1. i. Show that /tildewideS(s)≈/parenleftbigg 1−sE[X]√n+s2E[X2] 2n/parenrightbiggn . ii. Using what you know about μandσ2, show that /tildewideS(s)→/tildewiderN(0,1)(s),asn→∞. (b) Now generalize your solution to arbitrary μandσ. 25.16 M/M/2 Transform For the M/M/2 with arrival rate λ, where each server serves at rate μ, derive: /hatwideN(z),/hatwiderNQ(z), and/tildewiderTQ(s). The z-transforms are obtained directly from the limiting probabilities on the number of jobs in the system. The Laplace trans- form is obtained by conditioning on the number of jobs seen by an arrival. This same approach can be used to derive the M/M/k transform.",7523
Chapter 26 MG1 Transform Analysis. 26.1 The z-Transform of the Number in System,"CHAPTER 26 M/G/1 Transform Analysis In this chapter we derive the Laplace transform of the response time for an M/G/1 queue. Among other beneﬁts, the transform allows us to get moments of responsetime. We follow the two-step outline shown in Figure 26.1 that involves ﬁrst computing the z-transform of the number of jobs in the M/G/1, /hatwideN(z)(see Section 26.1), and then using that to get the Laplace transform of the response time for the M/G/1, /tildewideT(s)(see Section 26.2). Note that we cannot simply use Little’s Law to make the conversion, because it applies only to means. STE P 1: Section 26.1 Derive N(z)^STE P 2: Section 26.2 Derive T(s)~ Figure 26.1. Two-step outline. 26.1 The z-Transform of the Number in System We deﬁne /hatwideN(z)=∞/summationdisplay i=0πM/G/1 izi. (26.1) HereπM/G/1 i denotes the long-run fraction of time that there are ijobs in the M/G/1. We sometimes write simply πiwhen the context is clear. We could get /hatwideN(z),i fw ek n e w πM/G/1 i. Question: How can we get πM/G/1 i? Can we do the same thing we did for the M/M/1? Answer: (Attempt 1) For the M/M/1, we created a CTMC, where the state was the current number of jobs, and then we solved the CTMC. It is not obvious how to do this for the M/G/1 because the service times are not Exponential. To create a Markov chain, we need to know that the time until we leave a state does not depend on history,such as how much time we have already spent in the state. Yet for an M/G/1, the timeuntil a job departs could certainly depend on how long it has been running so far (think decreasing failure rate, as in Chapter 20). So we need another idea for getting πM/G/1 i. Here is a hint: 450 26.1 the z-transform of the number in system 451 Hint: Sometimes it is easier to think about the embedded discrete-time Markov chain (DTMC) that ignores the time spent at each state. How can we use this? Answer: (Attempt 2) The solution is to consider the M/G/1 only at points in time where a departure occurs. The state of the chain is deﬁned to be the number of jobs at the server at the time of the last departure . We can form a stochastic process X1,X2,X3,...,X i,..., where Xidenotes the number of jobs left behind at the time of the ithdeparture. This is the embedded discrete-time Markov chain. In the embedded DTMC, there is a probability (not a rate) of moving from state to state, which we deﬁne shortly. Letπembed i denote the limiting probability of being in state iof the embedded DTMC. This is the fraction of M/G/1 departures that leave behind ijobs. Question: How do πembed i andπM/G/1 i compare? Answer: They are the same: πembed i=πM/G/1 i Recall from Chapter 13that the probability that a departure leaves behind ijobs(di) is equal to the probability that an arrival sees ijobs(ai), but by PASTA this in turn is equal to the proportion of time that there are ijobs(pi). Thus it sufﬁces to derive πembed i and use that as πM/G/1 i in (26.1). To derive πembed i we solve the embedded DTMC. Question: What is Pijfor the embedded DTMC process: X1,X2,X3,...? Warning : Be careful. The sequence of states followed by the embedded DTMC is just a subset of those followed by the original M/G/1, because we consider only those states left behind by a departure of the M/G/1. Answer: Ifj<i−1, thenPij=0. Forj≥i−1, where i/negationslash=0,w eh a v e Pij=P{jjobs at time of next departure |ijobs at time of current departure } =P{j−i+1arrivals during a job’s service time, S} =/integraldisplay xP{j−i+1arrivals during time x}·P{service time of job =x} =/integraldisplay xe−λx(λx)j−i+1 (j−i+1 ) .fS(x)dx. Observe that P0j=P1jbecause we have to wait for an arrival before the next departure can occur. When that new arrival departs, there will be a probability, P1j, of transitioning to state j(where state jdenotes the state of having jjobs left behind by the last departure). 452 m/g/ 1transform analysis Now that we have Pijfor the embedded DTMC, we can get πembed i from the stationary equations: πembed j=/summationdisplay iπembed iPij,/summationdisplay iπembed i=1 (26.2) Unfortunately, given the complexity of the expressions for Pij, trying to solve these simultaneous equations does not seem very appealing. What we really want is a way to determine /hatwideN(z)=∞/summationdisplay i=0πM/G/1 i·zi=∞/summationdisplay i=0πembed i·zi(26.3) without having to ever ﬁgure out a closed-form formula for πembed i. A New Idea. Here is how to achieve this. We will express πj=πM/G/1 j=πembed j=P{M/G/1 departure leaves jjobs in system } in terms of aj=P{jarrivals during S}. Once we do this, we will be able to express /hatwideN(z)= z-transform of number of jobs in system as seen by departure in terms of /hatwideAS(z)= z-transform of number of jobs which arrive during service S. This is good because we already know /hatwideAS(z)from ( 25.9), which will allow us to skip over actually deriving the πj’s. We will follow three steps: Step 1: Express πjin terms of aj, P0j=aj Pij=aj−i+1,1≤i≤j+1 where aj=/integraldisplay∞ 0e−λx(λx)j j.·fS(x)dx. Thus we have that πj=π0aj+j+1/summationdisplay i=1πiaj−i+1. (26.4) 26.1 the z-transform of the number in system 453 Step 2: Multiply every term of ( 26.4)b yzj, so that we can express /hatwideN(z)in terms of /hatwideAS(z). πj=π0aj+j+1/summationdisplay i=1πiaj−i+1 ∞/summationdisplay j=0πjzj=π0∞/summationdisplay j=0ajzj+∞/summationdisplay j=0j+1/summationdisplay i=1πiaj−i+1zj /hatwideN(z)=π0/hatwideAS(z)+∞/summationdisplay i=1∞/summationdisplay j=i−1πiaj−i+1zj =π0/hatwideAS(z)+∞/summationdisplay i=1πizi−1∞/summationdisplay j=i−1aj−i+1zj−i+1 =π0/hatwideAS(z)+1 z∞/summationdisplay i=1πizi∞/summationdisplay u=0auzu(where u=j−(i−1)) =π0/hatwideAS(z)+1 z/parenleftBig /hatwideN(z)−π0/parenrightBig ·/hatwideAS(z) z/hatwideN(z)=zπ0/hatwideAS(z)+/hatwideN(z)/hatwideAS(z)−π0/hatwideAS(z) /hatwideN(z)=(z−1)π0/hatwideAS(z) z−/hatwideAS(z) All that is left is to determine π0. Question: We already know that π0=1−ρ, where ρ=λE[S]is the fraction of time that the server is busy. But suppose that you were working on a problem where you did not know π0. What would you do then? Answer: You could try to set z=1in the expression in Step 2 for /hatwideN(z)and then solve forπ0. Note that it is often the case when you do this that you need to use L’Hospital’s rule...sometimes repeatedly. For this example in Step 2, you can immediately see that 1 = lim z→1/hatwideN(z)=0 0 = lim z→1(z−1)π0/hatwideA/prime S(z)+π0/hatwideAS(z) 1−/hatwideA/prime S(z) =π0 1−λE[S] ⇒π0=1−λE[S]=1−ρ.",6504
26.2 The Laplace Transform of Time in System,"454 m/g/ 1transform analysis So we have ﬁnally /hatwideN(z)=/hatwideAS(z)(1−ρ)(z−1) z−/hatwideAS(z). (26.5) Step 3: Substitute in our known formula for /hatwideAS(z). Recall that from ( 25.9) /hatwideAS(z)=/tildewideS(λ−λz). (26.6) Substituting this into Equation ( 26.5)w eh a v e /hatwideN(z)=/tildewideS(λ−λz)(1−ρ)(1−z) /tildewideS(λ−λz)−z. (26.7) 26.2 The Laplace Transform of Time in System Our goal is to get /tildewideT(s), using the fact that we know /hatwideN(z). To do this, ﬁrst consider again the equation we have seen so many times: /hatwideAS(z)=/tildewideS(λ−λz), (26.8) where ASis the number of Poisson arrivals within service time S. What we want is a result about T. Question: Equation ( 26.8) holds for any r.v. S(review the derivation of ( 25.9)). What random variable would you like to substitute for S? Answer: Let’s substitute TforSin (26.8): /hatwideAT(z)=/tildewideT(λ−λz) (26.9) Equation ( 26.9) equates the Laplace transform of T(what we want) to the z-transform ofAT. Question: Is there a nicer name for AT? Answer: ATis the number of arrivals during T, which is equivalently the number of jobs in the system as seen by a departure. So AT=N, where Nis the number of jobs seen by a departure. Hence, /tildewideT(λ−λz)=/hatwideAT(z)=/hatwideN(z). (26.10) Substituting in Equation ( 26.7)f o r/hatwideN(z), into ( 26.10 ), we get /tildewideT(λ−λz)=/tildewideS(λ−λz)(1−ρ)(1−z) /tildewideS(λ−λz)−z. (26.11) 26.2 the laplace transform of time in system 455 We now make a simple change of variables. Let s=λ−λz. z=1−s λ. Then ( 26.11 ) becomes /tildewideT(s)=/tildewideS(s)(1−ρ)/parenleftbigs λ/parenrightbig /tildewideS(s)−1+s λ. Or equivalently, /tildewideT(s)=/tildewideS(s)(1−ρ)s λ/tildewideS(s)−λ+s. (26.12) We are done. Now we can differentiate ( 26.12 ) with respect to sto get all moments ofT. This is done in Exercise 26.2. You will see that you need to apply L’Hospital’s rule twice when differentiating just to get the mean. So it is not so easy, but it is straightforward. Question: How could we get the Laplace transform of TQ? Answer: Observe T=S+TQ. So /tildewideTQ(s)=/tildewideT(s) /tildewideS(s)=(1−ρ)s λ/tildewideS(s)−λ+s. (26.13) One thing that may seem surprising is that the above expression for /tildewideTQ(s)does not in- volveSe, the excess of S. The excess is in there – it just takes a few more steps to extract. Recall from ( 25.11 ) that the Laplace transform for the excess is /tildewiderSe(s)=1−/tildewideS(s) sE[S]. We can then express /tildewideTQ(s)in terms of/tildewiderSe(s)as follows: /tildewideTQ(s)=(1−ρ)s λ/tildewideS(s)−λ+s =1−ρ λ/parenleftBig/tildewideS(s)−1 s/parenrightBig +1 =1−ρ ρ/parenleftBig/tildewideS(s)−1 sE[S]/parenrightBig +1 =1−ρ 1−ρ/tildewiderSe(s)(26.14)",2731
26.3 Readings. Chapter 27 Power Optimization Application,"456 m/g/ 1transform analysis We will discuss some cool properties of ( 26.14 ) in Chapter 30, after we have covered some scheduling results, which will provide insight into interpreting ( 26.14 ). 26.3 Readings This material in this chapter borrows from three excellent texts [ 110,149,45]. 26.4 Exercises 26.1 M/H 2/1 Transform You are given an M/G/1 queue where the job size, S, has an H2distribution: S∼/braceleftBigg Exp(μ1) with probability p Exp(μ2) with probability 1−p (a) Derive E[TQ]. (b) Derive/tildewiderTQ(s). 26.2 Variance of Response Time for the M/G/1 Derive Var(TQ)for the M/G/1 by differentiating /tildewideTQ(s). 26.3 z-Transform of NQ In this chapter we derived /hatwideN(z), the z-transform of the number of jobs in system in an M/G/1. Suppose that we instead wanted /hatwiderNQ(z), the z-transform of the number of jobs queued. Show how to get that from /hatwideN(z). 26.4 Distributional Little’s Law for M/G/1 and M/G/c Consider an M/G/1 queue with average arrival rate λ, where Ndenotes the number of jobs in the system and Tdenotes the response time. The Distribu- tional Little’s Law states that, for all integers k≥1, E[N(N−1)(N−2)···(N−k+1 ) ]= λkE/bracketleftbig Tk/bracketrightbig (26.15) (a) Derive ( 26.15 ) from ( 26.10 ). [Hint: Differentiate.] (b) Does the law also hold if Nis replaced by NQandTbyTQ? (c) Now consider an M/G/c, with arrival rate λ, but look only at the queue portion of this system. What can you say about how the moments of NM/G/c Q are related to the moments of TM/G/c Q ? The Distributional Little’s Law is very powerful in settings like the M/H 2/c, where we can derive moments of NQvia matrix-analytic methods, but have no easy way to get moments of TQ. 26.5 M/M/2 Transform In this chapter, we saw how to convert /hatwideN(z)to/tildewideT(s)for the M/G/1. In this problem, you will apply this same technique to the M/M/2. First derive /hatwiderNQ(z)for the M/M/2. Then convert /hatwiderNQ(z)to/tildewiderTQ(s)using the approach in Exercise 26.4. This same approach can be applied to derive the M/M/k waiting time transform.",2082
27.1 The Power Optimization Problem,"CHAPTER 27 Power Optimization Application This chapter combines and applies many analytical techniques we have studied thus far (Renewal-Reward, general transform analysis, and M/G/1 response time analysis)toward analyzing the problem of power management of a single server. The goal is to understand when a server should be turned off to save on power (sometimes called “power napping”) and when it should be left on. In Section 27.1 we provide background on powering a server and state the speciﬁc power optimization problem that we address. To solve this problem, we ﬁrst need to develop two more analysis topics. The ﬁrst topic is busy period analysis for the M/G/1. We have touched on busy periods in the exercise sections of prior chapters, but in Section 27.2, we go into much more depth in describing busy periods, including different types of busy periods and the Laplace transform of the busy period. The second topic is the analysis of an M/G/1 with setup time , where the ﬁrst job starting a busy period incurs an extra delay, known as the setup time. Setup times have also been discussed in earlier exercises; however, in Section 27.3 we consider their effect on the M/G/1. Finally, in Section 27.4, we combine the analyses in Sections 27.2 and27.3 to solve our power optimization problem. 27.1 The Power Optimization Problem Consider the operation of a single-server system, speciﬁcally an M/G/1/FCFS queue. Thus far, we have only been concerned about the response time of the system. We nowdiscuss the power usage. We distinguish between three states that a server can be in: ON: The server is on and is busy serving a job. The server burns power at a rate of Pon. IDLE: The server is on and available, but is currently idle. The server burns power at a rate of Pidle. OFF: The server is off. In the ON state, a server might burn power at a rate of 240 Watts1(i.e.,Pon= 240 ). In the OFF state, a server burns 0 Watts. 1All the numbers given here involving power measurements and setup costs are based on measurements in our data center lab at Carnegie Mellon University during the year 2011. 457 458 power optimization application Question: At what rate would you guess that power is burned when the server is in the IDLE state? Answer: Surprisingly, the answer is that Pidleis almost as much as Pon.A nI D L Es e r v e r typically burns power at a rate of about Pidle= 180 Watts. Thus a server running at loadρburns power at an average rate of E[Power]=ρ·240Watts+( 1−ρ)·180Watts. Because this seems very wasteful when ρis low, the obvious idea is to turn off the server when it is idle. Question: What is wrong with turning off a server when it is idle? Answer: There is a huge setup cost to turning a server back on. Thesetup cost is the cost required to transition a server from the OFF state to the ON state. ( Note: there is no cost for transitioning from the IDLE state to the ON state). The setup cost consists of two components: a time component and a power component. The exact setup time varies depending on the type of application and server. However,a setup time of 200 seconds or so is not at all uncommon for most data center servers,and it can be much higher. The second component is power: During the entire setuptime, the server is burning power at a rate of Pon. Given the setup cost, it is no longer obvious that one wants to turn off the server when it becomes idle. From the perspective of solely minimizing response time, one neverwants to turn off the server. From a power perspective, if the setup cost is not too highrelative to mean job size, one may want to turn off the server when it goes idle. The power optimization problem aims to resolve this power/response time tradeoff. Speciﬁcally, we would like to maximize the Performance-per-Watt (Perf/W): Performance-per-Watt =1 E[Power]·E[Response Time ] That is, we want to minimize both mean response time and mean power. In this chapter, we do not solve the general power management problem. However, we do analyze and compare two simple policies: ON/OFF – Under this policy, the server is switched to the OFF state immediately when it goes idle. When a job arrives, the server is then turned on, involving a setupcost. ON/IDLE – Under this policy, the server is never turned off. Hence it moves between the ON state and the IDLE state. Our goal is to determine the parameter regime (in terms of ρand setup cost) under which the ON/OFF policy is superior to the ON/IDLE policy with respect to Perf/W.",4496
27.2 Busy Period Analysis of MG1,"27.2 busy period analysis of m/g/ 1 459 27.2 Busy Period Analysis of M/G/1 An important component in overall power usage is understanding how long the server is busy. In the case of a single-server system, the busy period is deﬁned to be the time from when the server ﬁrst becomes busy until the server ﬁrst goes idle. If one looks at an M/G/1 over time, one can see that the M/G/1 alternates between being in the“busy” state and the “idle” state. We use Bto denote the length of a single busy period. Throughout, we assume that the average arrival rate is λ, that job sizes are denoted by the r.v. S, and that load is ρ=λE[S]. Question: What is the distribution of the length of an idle period? Answer: The length of an idle period is distributed Exp (λ), because the idle period is just the time until an arrival occurs, see Figure 27.1. busy busy busy idle idleB B B Exp( λ) Exp( λ) Figure 27.1. Busy and idle periods. Busy periods are hard to describe because they are recursive . Consider a single busy period, started by a job, j, of size S. If no new arrivals come in while jruns, then the length of the busy period is just S. However, any new arrival that occurs while jruns will need to run once jcompletes and will create the opening for more new arrivals to occur while it runs. Speciﬁcally, if a single job j/primearrives before jcompletes, then the length of the busy period is S+B, where Sis the time for job jandBis the busy period created by job j/prime. Likewise, if two jobs j/primeandj/prime/primearrive before jcompletes, then they each start their own busy period. In this case the length of the busy period isS+B1+B2, where B1⊥B2andBi∼B,i=1,2. The job that starts the initial busy period is often referred to as the parent , and the jobs that arrive during a busy period are often called the offspring . Each offspring can be viewed as starting its own busy period. It may look like a single busy period never ends. But we know that is not true, because the system is idle 1−ρfraction of the time. When we talk about the busy period, B, we implicitly assume that all jobs during the busy period come from the same job size distribution. However, in general, one can also talk about a busy period started by a ﬁxed amount of work, x, which is present when the server ﬁrst turns on, where all future jobs have size S. The duration of such a busy period is denoted by B(x). Our ﬁrst goal is to derive /tildewideB(s), the Laplace transform of B. It turns out that to fully deﬁne B, we need to ﬁrst look at B(x). 460 power optimization application Question: How can we write a general expression for B(x)? Feel free to use Bwithin your expression. Hint: LetAxdenote the number of Poisson arrivals that occur during time x. Answer: B(x)=x+Ax/summationdisplay i=1Bi (27.1) where the Bi’s are independent and are each distributed identically to B. That is, we start with the job of size xand then each arrival during that time xcan be thought of as starting its own busy period, where that busy period is a busy period started by an arbitrary job of random size S. Observe an important property of busy periods: B(x+y)=B(x)+B(y), (27.2) meaning that a busy period started by x+ywork can be viewed as a busy period started by xwork, followed by a busy period started by ywork. Equation ( 27.1) does not look like it is helping us get any closer to getting B, but it is. The next step is to derive the Laplace transform of B(x). Question: How can we use ( 27.1) to derive an expression for /tildewideB(x)(s)? Hint: Use the fact that we know /hatwiderAx(z). Answer: Taking the Laplace transform of ( 27.1), we have /tildewideB(x)(s)=/tildewidex·⎛ ⎝/tildewiderAx/summationdisplay i=1Bi⎞⎠ =e −sx·/hatwiderAx/parenleftBig /tildewideB(s)/parenrightBig (by Theorem 25.12 ). Now we can use our knowledge of /hatwiderAx(z), from ( 25.1) to get /hatwiderAx/parenleftBig /tildewideB(s)/parenrightBig =e−λx(1−/tildewideB(s)). And so, /tildewideB(x)(s)=e−sx·e−λx(1−/tildewideB(s))=e−x(s+λ−λ/tildewideB(s)). (27.3) Equation ( 27.3) provides an expression for the Laplace transform of B(x). The next step is to uncondition , by integrating over all x, to turn ( 27.3) into an expression for the Laplace transform of Bas follows: /tildewideB(s)=/integraldisplay∞ 0/tildewideB(x)(s)fS(x)dx=/integraldisplay∞ 0e−x(s+λ−λ/tildewideB(s))fS(x)dx Question: Is there a nicer way of writing the above expression? 27.2 busy period analysis of m/g/ 1 461 Answer: Yes, /tildewideB(s)=/tildewideS/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig . (27.4) Equation ( 27.4) deﬁnes the transform of Bin terms of itself. Unfortunately, this is the best we can do. Fortunately, this is sufﬁcient to get the moments of B. We do this next. The ﬁrst moment, E[B], is given by E[B]=−/tildewideB/prime(s)|s=0=−/tildewideS/prime/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0·/parenleftBig 1−λ/tildewideB/prime(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle/vextendsingle s=0 =−/tildewideS/prime(0 +λ−λ(1))(1 + λE[B]) =−/tildewideS/prime(0)(1 + λE[B]) =E[S]( 1+ λE[B]). Solving for E[B], we get E[B]=E[S] 1−λE[S]=E[S] 1−ρ. (27.5) To get the second moment, we differentiate /tildewideB/prime(s)again and evaluate the result at s=0. This yields E/bracketleftbig B2/bracketrightbig =/tildewideB/prime/prime(s)|s=0=d ds/bracketleftBig /tildewideS/prime/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig/parenleftBig 1−λ/tildewideB/prime(s)/parenrightBig/bracketrightBig/vextendsingle/vextendsingle/vextendsingle s=0 =/tildewideS/prime/prime(0)/bracketleftBig 1−λ/tildewideB/prime(0)/bracketrightBig2 +/tildewideS/prime(0)/parenleftBig −λ/tildewideB/prime/prime(0)/parenrightBig =E/bracketleftbig S2/bracketrightbig/bracketleftbig 1+λE[B]/bracketrightbig2+λE[S]E/bracketleftbig B2/bracketrightbig . Substituting E[B]=E[S] 1−ρand solving for E[B2]we get E/bracketleftbig B2/bracketrightbig =E[S2] (1−ρ)3. (27.6) Question: What role does the variability of Splay in the mean busy period duration, E[B], and how does this compare to its role in mean response time, E[T]?W h yi s there a difference? Answer: The variability of Splays a key role in E[T]due to the Inspection Paradox and the effect of E[Se](see Chapter 23). By contrast, E[B]does not involve an E[Se] component, because there are no jobs already in service when the busy period starts; thus there is no “excess” to contend with. The variability of Bis naturally affected by the variability of S, because Bis a sum of S’s, and in general the ith moment of Bis dependent on the ith moment of S. By contrast, the ith moment of Tis dependent on the (i+1)th moment of S. Now that we understand standard busy periods, consider how we can modify this analysis to derive different types of busy periods. For example, let BWdenote the",6821
27.3 MG1 with Setup Cost,"462 power optimization application length of a busy period started by Wwork, where Wis a random variable and the jobs in the busy period have size S. Question: What is the transform of BW? Answer: Starting with ( 27.3), we have that /tildewideB(x)(s)=e−x(s+λ−λ/tildewideB(s)) /tildewidestBW(s)=/integraldisplay∞ 0/tildewideB(x)(s)fW(x)dx =/integraldisplay∞ 0e−x(s+λ−λ/tildewideB(s))fW(x)dx =/tildewiderW/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig . Question: What is the mean length of BW? Answer: E[BW]=E[W] 1−ρ. (27.7) This result follows from the following calculation: E[BW]=−/tildewidestBW/prime(s)/vextendsingle/vextendsingle/vextendsingle s=0=−/tildewiderW/prime/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle s=0·/parenleftBig 1−λ/tildewideB/prime(s)/parenrightBig/vextendsingle/vextendsingle/vextendsingle s=0 =−/tildewiderW/prime(0 +λ−λ(1))(1 + λE[B]) =−/tildewiderW/prime(0)(1 + λE[B]) =E[W]( 1+ λE[B]) Substituting E[B]=E[S] 1−ρ, we get E[BW]=E[W] 1−ρ. Intuitively, ( 27.7) can be viewed as the size of the job (or work) starting the busy period, E[W], scaled up by a factor,1 1−ρ, related to the load of jobs that make up the busy period. The higher the load, ρ=λE[S], the more jobs that arrive during Wand the longer the busy period. 27.3 M/G/1 with Setup Cost We now switch gears and consider a different problem: How does setup cost affect response time? Suppose that the ﬁrst job to start each busy period experiences an initial setup time, I, before its service is started, where Iis a continuous random variable. Here Idenotes the time required to “initialize” or power up the server, switching it from being in the OFF state to the ON state. Again we are dealing with an M/G/1 with job sizes denotedby r.v. S. 27.3 m/g/ 1with setup cost 463 Our goal is to derive the Laplace transform of Tsetup Q, where Tsetup Qis the delay experi- enced by an arrival into an M/G/1 with setup cost I. A few remarks before diving into the derivation: First, observe that the setup cost, I, affects more than just the job that starts the busy period; many jobs could arrive during the setup time itself, all of which have to wait for the machine to ﬁnish powering up. Question: What is the mean duration of a busy period in an M/G/1 with setup I? Answer: We can think of the busy period, Bsetup, as a busy period that is started by total work, I+S, where Iis the setup time and Sis the size of the job starting the busy period. Then by ( 27.7), we have E[Bsetup]=E[I]+E[S] 1−ρ. (27.8) Equation ( 27.8) can also be viewed as a sum of two terms, where the ﬁrst is a busy period started by the setup time and the second is a standard M/G/1 busy period, which starts after the setup busy period is over. Looking at things that way, we have E[Bsetup]=E[I] 1−ρ+E[B]. Question: In an M/G/1 with setup I, what fraction of time is the server busy? Here “busy” includes setting up, because that too requires power. Answer: Clearly, the answer is no longer simply ρ. Letρsetupdenote the fraction of time that the server is busy for the M/G/1 with setup I. To determine ρsetup, we think in terms of renewals. The server is busy forE[I]+E[S] 1−ρtime (where ρ=λE[S]), followed by a period of length1 λof being idle, and then the cycle repeats itself. By the Renewal- Reward theorem (Theorem 23.4), it sufﬁces to look at the fraction of time that the server is busy during one cycle: ρsetup=E[Busy during cycle ] E[Cycle time ]=E[I]+E[S] 1−ρ E[I]+E[S] 1−ρ+1 λ =λE[I]+ρ λE[I]+ρ+1−ρ =λE[I]+ρ λE[I]+1. (27.9) We are now ready to derive /tildewideTsetup Q(s). We follow the same approach used for the M/G/1 without setup, by looking at the embedded DTMC, as in Chapter 26. Again πidenotes the probability that the last departure left behind ijobs, which by PASTA is equal to the time-average probability that there are ijobs. There is only one difference: The transition probabilities for leaving the 0 state must reﬂect the initial cost. Let aj=P{jarrivals in Sseconds} 464 power optimization application and let a/prime j=P{jarrivals in S+Iseconds}. Then Pij=aj−i+1,fori>0andP0j=a/primej. Thus we can write πj=π0a/primej+j+1/summationdisplay i=1πiaj−i+1 ∞/summationdisplay j=0πjzj=π0∞/summationdisplay j=0a/primejzj+∞/summationdisplay j=0j+1/summationdisplay i=1πiaj−i+1zj /hatwideNsetup(z)=π0/hatwideAS+I(z)+1 z∞/summationdisplay i=1πizi∞/summationdisplay j=i−1aj−i+1zj−i+1 =π0/hatwideAS(z)/hatwideAI(z)+1 z/parenleftBig /hatwideNsetup(z)−π0/parenrightBig /hatwideAS(z) ⇒/hatwideNsetup(z)=π0z/hatwideAS(z)/hatwideAI(z)−/hatwideAS(z) z−/hatwideAS(z). (27.10) We now continue to follow the approach in Chapter 26to convert/hatwideNsetup(z)to/tildewideTsetup(s) by following the usual sequence of observations: /hatwideAS(z)=/tildewideS(λ(1−z)),for any S ⇒/hatwideATsetup(z)=/tildewideTsetup(λ(1−z)),setting S=Tsetup ⇒/hatwideNsetup(z)=/tildewideTsetup(λ(1−z)),sinceATsetup=Nsetup ⇒/tildewideTsetup(λ(1−z)) =π0z/hatwideAS(z)/hatwideAI(z)−/hatwideAS(z) z−/hatwideAS(z),by (27.10 ) ⇒/tildewideTsetup(λ(1−z)) =π0z/tildewideS(λ(1−z))/tildewideI(λ(1−z))−/tildewideS(λ(1−z)) z−/tildewideS(λ(1−z)) ⇒/tildewideTsetup(s)=π0(1−s/λ)/tildewideS(s)/tildewideI(s)−/tildewideS(s) 1−s/λ−/tildewideS(s),vias=λ(1−z) =π0(λ−s)/tildewideS(s)/tildewideI(s)−λ/tildewideS(s) λ−s−λ/tildewideS(s) Hence, /tildewideTsetup Q(s)=/tildewideTsetup(s) /tildewideS(s)=π0·λ−(λ−s)/tildewideI(s) s−λ+λ/tildewideS(s). (27.11)",5418
27.4 Comparing ONIDLE versus ONOFF,"27.4 comparing on/idle versus on/off 465 Question: What is π0? Answer: From ( 27.9), we have π0=1−ρsetup=1−λE[S] 1+λE[I]. (27.12) Substituting π0into ( 27.11 ) yields /tildewideTsetup Q(s)=1−λE[S] 1+λE[I]·λ−(λ−s)/tildewideI(s) s−λ+λ/tildewideS(s) =(1−ρ)s s−λ+λ/tildewideS(s)·λ−(λ−s)/tildewideI(s) (1 +λE[I])s =/tildewiderTQM/G/1(s)·λ−(λ−s)/tildewideI(s) (1 +λE[I])s. (27.13) To get the mean, we differentiate ( 27.13 ) and also apply L’Hospital’s rule to get: E[TQ]setup=λE[S2] 2(1−ρ)+2E[I]+λE[I2] 2(1 + λE[I]). (27.14) Question: What is the effect of setup when the setup, I, is Exponentially distributed? Answer: In the case of I∼Exp(α),w eh a v e E[I2]=2(E[I])2, which reduces to E[TQ]setup=E[TQ]+E[I]. (27.15) Thus, in the case where I∼Exp(α), the setup cost is just an additive cost. The delay for the M/G/1 with setup in ( 27.13 ) and (27.14) can be written in terms of two distinct components, the ﬁrst involving delay for an M/G/1 without setup and the second involving just some setup-related terms. It is really neat (and rare) when results decompose in such a pretty way. Such results are referred to as decomposition results. 27.4 Comparing ON/IDLE versus ON/OFF We are now ready to derive the mean power consumption and mean response time for the ON/OFF and ON/IDLE power management policies. The analysis of ON/IDLE is simple. The response time is just that of an M/G/1 queue. The power is Ponwhen the server is busy and Pidlewhen it is idle. Hence we have E[Power]ON/IDLE=ρPon+( 1−ρ)Pidle (27.16) E[T]ON/IDLE=λE[S2] 2(1−ρ)+E[S] (27.17) where ρ=λE[S]. The analysis of ON/OFF is more involved, but at this point we have all the computations we need. With respect to power, the server might be in one of three states: ON, inSETUP, or OFF. When the server is ON or in SETUP, the power used is Pon. Otherwise 466 power optimization application the power is zero. Fortunately, we already know the fraction of time that the server is busy from ( 27.9). Hence we have E[Power]ON/OFF=ρsetup·Pon=λE[I]+ρ λE[I]+1·Pon, (27.18) where ρ=λE[S]andE[I]represents the expected setup time. The response time under ON/OFF is just the response time for an M/G/1 with setup, which we have from ( 27.14 ), namely E[T]ON/OFF=λE[S2] 2(1−ρ)+2E[I]+λE[I2] 2(1 + λE[I])+E[S]. (27.19) These two formulas allow us to compare the ON/IDLE and ON/OFF policies with respect to the following Perf/W metric: Performance-per-Watt =1 E[Power]·E[Response Time ]. Table 27.1 compares our policies for a range of values of ρ=0.1,0.3,0.5,0.7,0.9 andE[I]=1 8,1 4,1 2,1,2,4,8. Throughout, we assume E[S]=1 ,E[S2]=2 0 , and E[I2]=5E[I]2(there is no particular reason for choosing these values). Table 27.1 shows the ratio of Perf/W under ON/IDLE versus that under ON/OFF. When the ratio exceeds 1, then the ON/IDLE policy is better (has higher Perf/W), and when the ratio is less than 1, then the ON/OFF policy is better. Looking at the table, wesee that, under low load and low setup time, the ON/OFF policy is about 6 times better(ratio is 0.152), whereas under low load and high setup time, the ON/IDLE policy is almost 5 times better. It makes sense that, as the setup time increases, ON/IDLE will become preferable, because turning OFF the server becomes costly. Table 27.1. ThePerformance-per-WattON/IDLE Performance-per-WattON/OFFratio E[I]=1 8E[I]=1 4E[I]=1 2E[I]=1 E[I]=2 E[I]=4 E[I]=8 ρ=0.1 0.152 0.177 0.231 0.361 0.705 1.708 4.720 ρ=0.3 0.404 0.445 0.528 0.702 1.085 1.964 3.962 ρ=0.5 0.612 0.652 0.726 0.866 1.130 1.645 2.674 ρ=0.7 0.787 0.815 0.865 0.950 1.092 1.340 1.803 ρ=0.9 0.935 0.945 0.963 0.990 1.032 1.099 1.219 When the ratio is <1, the ON/OFF policy is superior. What is more surprising is the effect of load. One would expect that increasing theload makes ON/OFF perform worse, relative to ON/IDLE, because under high load itdoes not pay to turn the server OFF and suffer the setup cost. This intuition is true, provided that the setup cost is not too high. However, when the setup cost is high, the reverse trend seems to happen – namely as the load increases, ON/IDLE’s superiorityover ON/OFF decreases. This could be due to the fact that the values of E[T]and E[Power]are just so high under both policies when both setup costs and load are high that the ratios of the policies become closer to each other.",4303
27.5 Readings. 27.6 Exercises,"27.6 exercises 467 27.5 Readings The formulas ( 27.13 ) and ( 27.14 ) for the M/G/1 with setup time were ﬁrst obtained in [182]. Setup time is also known as exceptional ﬁrst service in the queueing literature. The material in this chapter, on the M/G/1 with setup times, was applied by a former student, Brian Gold, in the well-known paper, “PowerNap: Eliminating Server IdlePower” [ 124]. Although this chapter only dealt with a single-server queue, it is natural to ask how policies like ON/OFF might perform in a multi-server system, like the M/M/k system,for example. Surprisingly, analyzing the M/M/k with setup cost is a very difﬁcultproblem. The exact analysis is not yet known, but approximations exist in [ 68]. 27.6 Exercises 27.1 Review of Formulas Throughout, assume that you have an M/G/1 (FCFS) queue, except in part (j), where M/M/1 is stated. The average arrival rate is λ, andSrepresents job size. Ten quantities are given, labeled (a) through (j). Many of these quantities areequivalent. Your job is to form them into equivalence classes. (a) E[AT]: mean number of arrivals during response time T (b)E[AS]: mean number of arrivals during time S (c)E[N]: mean number of jobs in the system (d)E[TQ]: mean queueing time (e)ρ: load (f)E[W]: mean work in system (g)λ·E[T]: product of arrival rate and mean response time (h)E[N]−E[NQ]: mean number of jobs in service (i)E[B]: mean duration of busy period (j)E[TM/M/1]: mean response time in M/M/1 queue 27.2 Server Vacations Imagine you are running a shop with a lazy server. The server serves customersin an M/G/1 queue when there are customers in the shop. However, when the shop is empty, the server walks next door to get coffee. The time to get coffeeis denoted by Vand is known as a server vacation . When the server returns from getting coffee, there may or may not be new customers queued, waiting for the server. If there is no one waiting when the server returns, the server goes to get another cup of coffee, and this continues until the server ﬁnds someone in the queue. Assume that “vacation times” are i.i.d. instances of V. LetTM/G/1/Vacdenote the response time in an M/G/1 with Vacations. Prove the following decomposition result: /tildewideTM/G/1/Vac(s)=/tildewideTM/G/1(s)·/tildewideVe(s) where Veis the excess of V. [Hint: Follow the derivation of M/G/1/setup in this chapter.] 468 power optimization application 27.3 Shorts-Only Busy Period Consider an M/G/1 queue where job sizes have p.d.f. f(·)and c.d.f. F(·). Deﬁne a job to be “short” if its size is <tand “long” otherwise. Suppose that short jobs have preemptive priority over long ones. That is, whenever there is a short job in the system, there can never be a long job in service. We deﬁne a “short busy period” to be a busy period started by a short job, con- taining only short jobs. Derive the mean and Laplace transform of a short busyperiod. 27.4 ON/OFF for M/M/ ∞ Consider a very large data center, comprising tens of thousands of servers, as is common in companies like Google, Facebook, and Microsoft. Such a datacenter might be approximated by an M/M/ ∞system, where there is no queue and all jobs are immediately served (see Section 15.2). To save power, when a server goes idle, we assume that it is immediately shut off. When a job arrives, it needs to turn on a server, requiring setup time I, where I∼Exp(α).I fa server, s1, is in setup mode and another server, s2, becomes free, then the job waiting for s1goes to s2. At this point, server s1is shut off. The effect of setup times for the M/M/ ∞was ﬁrst derived in [ 68], where the following beautiful decomposition property was observed. Here λis the outside arrival rate, μis the service rate at each server, and R=λ μ. P{iservers are busy & jservers are in setup } =P{iservers are busy }·P{jservers are in setup }(27.20) where P{iservers are busy }=e−R·Ri i.(27.21) P{jservers in setup }=Cj/productdisplay /lscript=1λ λ+/lscriptα(27.22) That is, the number of busy servers follows a Poisson distribution with mean R, just as in an M/M/ ∞without setup, and is independent of the number of servers in setup. In this problem, you will verify the above result: (a) Draw the CTMC for the M/M/ ∞with setup, where the states are (i, j)as deﬁned above. (b) Write the balance equation for state (i,j)and verify that the above formulas satisfy the balance equation. (c) Equation ( 27.21 ) makes intuitive sense because the long-run number of busy servers should not be affected by the fact that servers ﬁrst need a setup; hence a Poisson (R)distribution is reasonable. What is the intuition for equation ( 27.22 )? [Hint: Assume that there are always exactly Rservers that are busy and draw a birth-death chain representing the number of servers that are in setup, given that assumption.] 27.6 exercises 469 27.5 Number of Jobs Served during M/M/1 Busy Period LetNBdenote the number of jobs served during an M/M/1 busy period. (a) Derive E[NB]. (b) Derive the z-transform: /hatwiderNB(z). Determine the ﬁrst and second moments ofNBby carefully differentiating your transform. 27.6 Number of Jobs Served during M/G/1 Busy Period LetNBdenote the number of jobs served during an M/G/1 busy period. Derive the z-transform: /hatwiderNB(z). Determine the ﬁrst and second moments of NBby carefully differentiating your transform. 27.7 Number of Jobs Served during M/G/1 Busy Period with Setup Time This problem builds on Exercise 27.6. Consider an M/G/1 system where the server shuts off whenever it goes idle and where there is a generally distributed setup time, denoted by I, needed to turn on a server if an arrival ﬁnds the server off. Let Nsetup Bdenote the number of jobs served during a busy period of this M/G/1/setup system. Derive the z-transform:/hatwideNsetup B(z). Then derive its mean,E/bracketleftbig Nsetup B/bracketrightbig , and provide intuition for this result. In your derivations, be careful to distinguish between Nsetup B andNB. Both refer to the number of jobs served during a busy period, but the former is a busy period in an M/G/1/setup, whereas the latter is a busy period in an M/G/1. 27.8 A New Power-Saving Policy: DelayedOff This problem builds on Exercise 27.7. Anshul suggests the following power- saving policy for an M/G/1 system. When the server becomes idle, rather than turning off the server immediately, we set a timer of duration twait. The server idles until either the timer goes off, in which case the server is shut off, or until there is a new arrival, in which case the server resumes running. The goal of this policy, called DelayedOff , is to obviate the setup cost by not turning off the server every time that it goes idle. Your job is to evaluate the DelayedOff policy, and to determine how much power is saved over policies like ON/OFF and ON/IDLE and what the optimal twaitconstant should be. Here are the parameters you should assume: The server consumes power at rate 240 Watts when on, 180 Watts when idle, and 0 Watts when off. Arrivals occur with average rate λ. When an arrival ﬁnds the server off, it requires a setup cost to get it on. The setup time is denoted by the general random variable I. Power is consumed at a rate of 240 Watts during the entire period I. In expressing your solution you may use ρ=λE[S]or ρsetup=λE[I]+ρ λE[I]+1. (a) Derive mean response time, E[T], for the DelayedOff policy. (b) Derive E[Power]for the DelayedOff policy. (c) Which value of twaitminimizes E[T]? (d) Which value of twaitminimizes E[Power]? (e) Does the DelayedOff policy make sense for the M/G/1 queue? The DelayedOff policy ends up being very powerful in multi-server systemswith the appropriate routing, see [ 67]. 470 power optimization application 27.9 ON/OFF for M/M/1 [This is a repeat of Exercise 15.10 .] The analysis of the ON/OFF policy in this chapter was based on using transforms. For this problem, we revisit the ON/OFF policy, this time for an M/M/1, with average arrival rate λand service rate μ, where the setup time is distributed as Exp (α). This time, the approach is to set up a Markov chain for the system and derive the following quantities: (a) limiting probabilities for all states (b) limiting probability that the number of jobs in the system exceeds k (c) mean response time For each of these quantities, compare with the case of an M/M/1 without setuptime.",8335
Part VII Smart Schedulingin the MG1,"PART VII Smart Scheduling in the M/G/1 PartVIIis dedicated to scheduling. Scheduling is an extremely important topic in designing computer systems, manufac- turing systems, hospitals, and call centers. The right scheduling policy can vastly reduce mean response time without requiring the purchase of faster machines. Scheduling canbe thought of as improving performance for free . Scheduling is also used to optimize performance metrics other than mean response time, such as “fairness” among users, and to provide differentiated levels of service where some class of jobs is guaranteed lower mean delay than other classes. Stochastic scheduling analysis, even in the case of the M/G/1 queue, is not easy and is omitted from most textbooks. A notable exception is the 1967 Conway, Maxwell, andMiller book, Theory of Scheduling [45], which beautifully derives many of the known scheduling analyses. In this part, we study scheduling in the M/G/1 queue, where Gis continuous with ﬁnite mean and variance. We are interested in mean response time, the transform of response time, and other metrics like slowdown and fairness. Throughout we are interested in the effects of high variability in job size distribution. Scheduling policies can be categorized based on whether the policy is preemptive or non-preemptive. A policy is preemptive if a job may be stopped partway through its execution and then resumed at a later point in time from the same point where it was stopped (this is also called preemptive-resume ). A policy is non-preemptive if jobs are always run to completion. Scheduling policies can be differentiated further based on whether the policy assumes knowledge of the job sizes. The chapters are organized as follows. Chapter 28covers the different performance metrics commonly used in evaluating scheduling policies. Chapter 29considers non-preemptive scheduling policies that do not make use of job size. Examples are First- Come-First-Served, RANDOM, and Last-Come-First-Served. Chapter 30considers preemptive scheduling policies that do not make use of job size. Examples includeProcessor-Sharing, Preemptive-Last-Come-First-Served, and Foreground-Backgroundscheduling (also known as Least-Attained-Service). Chapter 31considers non- preemptive policies that make use of size. These include Shortest-Job-First and non-preemptive priority queues. Chapters 32and33consider preemptive policies that make use of size. These include Preemptive-Shortest-Job-First and Shortest-Remaining-Processing-Time. Also included are preemptive priority queues. 471",2566
Chapter 28 Performance Metrics. 28.2 Commonly Used Metrics for Single Queues,"CHAPTER 28 Performance Metrics This is a very short chapter that explains some performance metrics that will be used in evaluating the different scheduling policies that we will study in this part. In ourdiscussion below, we will be assuming an open system with some arbitrary outside arrival process. 28.1 Traditional Metrics We have already been using the following traditional performance metrics: E[T]:mean response time or “mean time in system” E[TQ]=E[T]−E[S]:mean waiting time or “wasted” time, also known as mean delay or mean queuing time E[N]:mean number in system E[NQ]:mean number in queue Question: Suppose someone tells you they have a super scheduling algorithm that improves mean waiting time in their system by a factor of 100. Before you buy thealgorithm, what question should you ask? Hint: Just because E[TQ]improves by a factor of 100, does E[T]necessarily improve by a comparable factor? Answer: In fact, you need to know the mean job size, E[S], so you can determine the beneﬁt to E[T]. Suppose E[S]>E[TQ]. Then an improvement in E[TQ]by a factor of 100,000 still yields less than a factor of 2 improvement in E[T]. More typically, we have E[TQ]/greatermuchE[S], so improvements in E[TQ]translate to comparable improvements in E[T]. 473",1259
Chapter 29 Scheduling Non-Preemptive Non-Size-Based Policies,"474 performance metrics 28.2 Commonly Used Metrics for Single Queues Suppose you have a single queue. Consider these two metrics: Work in system: remaining work left to do in the system Utilization of device: fraction of time that the device is busy Deﬁne an arrival sequence as a sequence of arrival times and job sizes. Question: Suppose you are told that two scheduling policies, run on the same arrival sequence, result in the same work in system over all time and the same device utilization.Does that mean that the two policies also have the same mean response time? Deﬁnition 28.1 Awork-conserving scheduling policy is one that always performs work on some job when there is a job in the system. Also, the policy does not createnew work (e.g., by re-running parts of jobs). Observe that “work in system” is the same across all work-conserving scheduling policies, and so is the server utilization. Let’s reformulate the question then. Question: Do all work-conserving scheduling policies have the same mean response time? Answer: No. Consider two work-conserving policies AandB. Suppose policy A serves the shortest available job ﬁrst, so that only a few big jobs are left, whereas B serves the longest available job ﬁrst, so that many more jobs are left. Then E[N]is much higher for policy B, and by Little’s Law, E[T]is thus higher for B. 28.3 Today’s Trendy Metrics Deﬁnition 28.2 The slowdown of a job is its response time divided by its size: Slowdown =T S. Observe that the slowdown of a job is always at least 1. Question: Why is mean slowdown preferable to mean response time? Answer: Ideally, one wants the response time of a job to be correlated with the job’s size. We would like small jobs to have small response times and big jobs to have bigresponse times. We would like to make sure the slowdown of every job is no more than, say, 10. Question: But why does knowing mean slowdown is low tell us anything about the max slowdown? 28.4 starvation/fairness metrics 475 Answer: If we know E[Slowdown ]=2 , then we know there cannot be many jobs with slowdown much greater than 3. In particular, fewer than half the jobs can have slowdown greater than or equal to 3 (note that all jobs have slowdown of at least 1). Fewer than 1/4of the jobs can have slowdown of at least 5. Fewer than1 n−1fraction of jobs can have slowdown of at least n. So by making the mean slowdown low, we have also restricted the fraction of jobs with very high slowdowns, which means that few jobs have response time too much greater than their service requirement. There are many other performance metrics of interest. Variability in response time, Var(T), and variability in slowdown, Var(Slowdown ), are sometimes even more important to system designers than mean metrics. This is why we often derive the Laplace transform of response time, rather than just the mean. Another metric of importance is the tail behavior of response time (or tail of slowdown). This is deﬁned as the probability that the response time exceeds some levelx, namely P{T>x}. Understanding the tail behavior is very important in setting Service Level Agreements (SLA’s), where a company might be willing to pay to ensure that their response time stays below xwith probability 95 percent. Unfortunately, tail behavior is often not easy to derive. Boxma and Zwart [ 28] survey recent research in understanding the tail behavior of different scheduling policies. 28.4 Starvation/Fairness Metrics The increasing popularity of mean slowdown as a performance metric has led some researchers to worry that certain scheduling policies might be achieving low meanslowdown at the expense of starving the few big jobs. For example, the Shortest- Remaining-Processing-Time (SRPT) policy results in low mean slowdown because most jobs are small and they get treated well, at the expense of delaying large jobs. Question: What performance metric will tell us if jobs are being starved? Answer: We recommend looking at mean slowdown as a function of job size .F o r example, consider asking “What is the expected slowdown of jobs of size x?” or “What is the expected slowdown of the max job size?” or “What is the expected slowdown of jobs in the 99th percentile of the job size distribution?” We use E[Slowdown (x)]to denote the expected slowdown of a job of size x. We might then say that scheduling policy Pis “starving some jobs” or at least “treating some jobs unfairly” if the expected slowdown of a job of size xis higher under policy P than it is under Processor-Sharing (PS), for some x. We compare with PS because PS provides equal expected slowdown to all jobs (this statement will become more clear when we get to Chapter 30) and hence is considered “fair.” We likewise might say that a scheduling policy Pis “fair” even if it does not provide equal expected slowdown to all job sizes, as long as E[Slowdown (x)]under policy Pis lower than that under PS, for all x. 476 performance metrics Starvation is often a deceptive thing. Consider the following example. Question: Suppose I tell you that switching from scheduling policy A to scheduling policy B resulted in strictly improving the response time of almost all jobs and in nojob ending up with a worse response time under policy B than under A. Is this possible? Answer: Sure it is. Consider the case of a single server, where njobs all arrive at time 0and have size 1. Under Processor-Sharing, they each have response time of n.N o w we switch to FCFS. The response time of n−1of the jobs strictly improves. The response time of one job stays the same. No job has a worse response time. Section 33.4 proves more counterintuitive results on fairness, such as the “All-Can- Win” theorem for SRPT scheduling. 28.5 Deriving Performance Metrics In the next few chapters, we consider various scheduling policies for the M/G/1 queue.Typically, for every scheduling policy we derive E[T](mean time in system) and E[T(x)](mean time in system for a job of size x). Question: How can we derive E[Slowdown ],g i v e nE[T]andE[T(x)]? Hint: It isnotE[T]/E[S]. Answer: First derive the mean slowdown for a job of size xas follows: E[Slowdown (x)] =E/bracketleftbiggT S/vextendsingle/vextendsingle/vextendsingle/vextendsinglejob has size S=x/bracketrightbigg =E/bracketleftbiggT(x) x/bracketrightbigg =1 xE[T(x)]. Notice that we were able to pull out the xbecause it is just a constant. Now we use E[Slowdown (x)]to get mean slowdown: E[Slowdown ]=/integraldisplay xE[Slowdown|job has size x]fS(x)dx =/integraldisplay xE[Slowdown( x)]fS(x)dx =/integraldisplay x1 xE[T(x)]fS(x)dx To derive the transform of response time, we typically ﬁrst derive the transform of T(x)and then integrate that to get the transform of response time, as follows: /tildewideT(s)=/integraldisplay x/tildewideT(x)(s)fS(x)dx Similarly, for the transform of slowdown, we ﬁrst derive the transform of Slowdown (x) and then integrate that. 28.6 readings 477 28.6 Readings The fairness metric that we use here was introduced in [ 12]. The slowdown metric has received very little attention in the world of scheduling until recently, see [ 100] and the references therein.",7148
29.1 FCFS LCFS and RANDOM,"CHAPTER 29 Scheduling: Non-Preemptive, Non-Size-Based Policies This chapter and all the remaining chapters focus on scheduling for the case of an M/G/1 queue. We always assume ρ<1and that Gis continuous with ﬁnite mean and ﬁnite variance. Every scheduling policy we consider is work-conserving (i.e., whenever there is a job to be worked on, some job will receive service). Deﬁnition 29.1 Anon-preemptive service order is one that does not preempt a job once it starts service (i.e., each job is run to completion). This chapter focuses on non-preemptive scheduling policies that do not make use of knowing a job’s size. 29.1 FCFS, LCFS, and RANDOM The following three non-preemptive policies do not assume knowledge of job size: FCFS: When the server frees up, it always chooses the job at the head of the queue to be served and runs that job to completion. LCFS (non-preemptive): When the server frees up, it always chooses the last job to arrive and runs that job to completion. RANDOM: When the server frees up, it chooses a random job to run next. Question: When would one use LCFS? Answer: Consider the situation where arriving jobs get pushed on a stack, and therefore it is easiest to access the job that arrived last (e.g., the task at the top of the pile on my desk.). Question: Which of these three non-preemptive policies do you think has the lowest mean response time? Answer: It seems like FCFS should have the best mean response time because jobs are serviced most closely to the time they arrive, whereas LCFS may make a job wait a very long time. However, surprisingly, it turns out that all three policies have exactlythesame mean response time. In fact, an even stronger statement can be made. Theorem 29.2 [45]All non-preemptive service orders that do not make use of job sizes have the same distribution of the number of jobs in the system. 478 29.1 fcfs, lcfs, and random 479 Corollary 29.3 All non-preemptive service orders that do not make use of job sizes have the same E[N], and hence the same E[T]. Question: Does this mean that all these policies also have the same E[Slowdown]? Answer: See Exercise 29.2. Question: Any ideas for how the proof for Theorem 29.2 might go? Hint: It will help to recall the embedded DTMC formulation for the M/G/1/FCFS queue. The idea is to look at the M/G/1 queue just at the point of departures. Answer: For the M/G/1/FCFS queue in Chapter 26, we let the current state be the number of jobs in the M/G/1 system at the time of the last departure. The sequence of states{Xi,i≥0}forms a DTMC, where, for i>0, Pij=Probability that when leave state iwe next go to state j =P/braceleftbigg The next departure will leave behind jjobs, given that the last departure left behind ijobs/bracerightbigg =P{j−i+1jobs arrive during the service time S} =/integraldisplay xP{j−i+1arrivals during time x}fS(x)dx =/integraldisplay xe−λx(λx)j−i+1 (j−i+1 ) .fS(x)dx. The limiting probability, πi, for this DTMC process speciﬁes the fraction of jobs that leave behind ijobs. This in turn, by PASTA (see Chapter 13), equals the limiting probability that there are ijobs in the M/G/1. Question: So, having recalled this argument for M/G/1/FCFS, what would the argu- ment be like to determine the limiting number of jobs in the system for M/G/1/LCFS? Answer: The argument does not change at all when the service order is LCFS. In fact it is the same analysis for anyservice order that does not make use of job size. Question: Why do we require that the scheduling policy not make use of size? Answer: If you used size in determining which job got to serve next, then that would affect the distribution of the number of jobs that arrive during one service time. Question: Consider again the set of all non-preemptive scheduling policies that do not make use of size. Is Var(T)the same for all these policies? Answer: No. Observe that LCFS can generate some extremely high response times because we have to wait for the system to become empty to take care of that ﬁrst arrival. It turns out that, in agreement with intuition, we have Var(T)FCFS<Var(T)RANDOM<Var(T)LCFS. 480 scheduling: non-preemptive, non-size-based policies We already know how to derive Var(T)FCFS. We now show how to derive Var(T)LCFS. We do this by computing the Laplace transform of waiting time, /tildewideTLCFS Q(s). Before we begin, it helps to recall a few formulas from Chapter 27and Exercise 25.14 . B(x)= length of busy period started by a job of size x =x+Ax/summationdisplay i=1Bi,where Ax= number arrivals by x /tildewideB(x)(s)=e−x(s+λ−λ/tildewideB(s)) B=length of busy period made up of jobs of size S /tildewideB(s)=/integraldisplay∞ x=0/tildewideB(x)(s)fS(x)dx=/tildewideS/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig BW=length of busy period made up of jobs of size S, started by work W /tildewidestBW(s)=/tildewiderW/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig Se=excess of S /tildewiderSe(s)=Lfe(s)=1−/tildewideS(s) sE[S] Consider an arrival into the M/G/1/LCFS queue. Conditioning on whether the arrival sees an empty system or a busy system, we can immediately write /tildewideTLCFS Q(s)=( 1−ρ)·/tildewideTLCFS Q(s|idle)+ρ·/tildewideTLCFS Q(s|busy). (29.1) Question: What is/tildewideTLCFS Q(s|idle)? Answer: If the arrival sees an empty system, then the waiting time is zero, so /tildewideTLCFS Q(s|idle)=1. Question: How long does the arrival wait if it ﬁnds the server busy? Answer: At ﬁrst one might think that the waiting time is just the excess of a service time,Se, because the arrival has to wait for the job in service to ﬁnish serving. This is, however, not quite correct, because more jobs may arrive during Se, and those jobs have precedence over our arrival. In fact, the waiting time for our arrival is the lengthof a busy period started by a job of size Se. /tildewideTLCFS Q(s|busy)=/tildewiderSe/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig =1−/tildewideS/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig /parenleftBig s+λ−λ/tildewideB(s)/parenrightBig E[S] =1−/tildewideB(s)/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig E[S]",6074
29.2 Readings. Chapter 30 Preemptive Non-Size-Based Policies,"29.3 exercises 481 Returning to ( 29.1)w eh a v e /tildewideTLCFS Q(s)=( 1−ρ)·/tildewideTLCFS Q(s|idle)+ρ·/tildewideTLCFS Q(s|busy) =( 1−ρ)+ρ·1−/tildewideB(s)/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig E[S] =( 1−ρ)+λ(1−/tildewideB(s))/parenleftBig s+λ−λ/tildewideB(s)/parenrightBig. From this transform, we can derive the second moment of waiting time, E/bracketleftbig T2 Q/bracketrightbig .W e ﬁnd that E/bracketleftbig T2 Q/bracketrightbigLCFS=λE[S3] 3(1−ρ)2+(λE[S2])2 2(1−ρ)3. In comparison, for FCFS scheduling we saw E/bracketleftbig T2 Q/bracketrightbigFCFS=λE[S3] 3(1−ρ)+(λE[S2])2 2(1−ρ)2. So E/bracketleftbig T2 Q/bracketrightbigLCFS=E/bracketleftbig T2 Q/bracketrightbigFCFS·1 1−ρ. Thus, although the mean waiting times are the same for FCFS and LCFS, the second moment of waiting time differs by a factor that depends on ρ, but not on the job size distribution. Under high loads, the second moment of waiting time under LCFS becomes very high compared with the second moment of waiting time under FCFS. 29.2 Readings Theorem 29.2 was taken from [ 45], Section 8.5. Very few books analyze scheduling policies in a stochastic setting. However, two good ones with lots of insights are [45,111]. 29.3 Exercises 29.1 Reviewing LCFS Derive the mean queueing time under LCFS, E[TQ]LCFS. Derive this by con- ditioning on whether an arrival ﬁnds the system busy or idle, but without using transforms. 29.2 Non-Preemptive, Non-Size-Based Policies In this chapter, we saw that the FCFS, LCFS and RANDOM scheduling disciplines all have the same distribution of the number of jobs in the systemfor an M/G/1 queue. How do they compare with respect to mean slowdown(again, for an M/G/1)? Prove your answer.",1706
30.1 Processor-Sharing PS,"CHAPTER 30 Scheduling: Preemptive, Non-Size-Based Policies This chapter is about preemptive scheduling policies that do not make use of knowing a job’s size or its priority class. Deﬁnition 30.1 A policy is preemptive if a job may be stopped partway through its execution and then resumed at a later point in time from the same point where itwas stopped (this is also called preemptive-resume ). We deﬁne three preemptive scheduling policies during this chapter, none of which make use of job size. The policies are Processor-Sharing (PS) (Section 30.1), Preemptive- Last-Come-First-Served (PLCFS) (Section 30.2), and Generalized Foreground- Background (FB) (Section 30.3). 30.1 Processor-Sharing (PS) 30.1.1 Motivation behind PS In Chapter 29, we saw that all non-preemptive, non-size-based scheduling policies for the M/G/1 result in the same distribution on N⇒sameE[N]⇒sameE[T]⇒sameE[TQ]. Thus all non-preemptive, non-size-based service orders for the M/G/1 have E[T]equal to that for M/G/1/FCFS, namely E[T]=λE[S2] 2(1−ρ)+E[S]. We also saw that for all these policies, E[T(x)] =x+λE[S2] 2(1−ρ). (Note:E[TQ(x)] =E[TQ]for all x.) The problem is that this mean response time can be very high when E[S2]is high (job size variability is high). Intuitively, short jobs queue up behind long jobs, resulting in long delays. In particular, the mean slowdown, E[Slowdown( x)] =E[T(x)] x,i sv e r y high for small x. Processor-Sharing, by contrast, is not negatively affected by high job size variability. Question: Why are short jobs not affected by long ones under PS? 482 30.1 processor-sharing (ps) 483 Answer: When a short job arrives, it immediately time-shares with all the jobs in the system. It does not have to wait for long jobs to ﬁnish. Historically, CPU scheduling has always involved time-sharing, where each job is given a tiny quantum and the CPU takes turns serving jobs in a round-robin fashion. Ifthe quantum size goes to zero, we get the Processor-Sharing abstraction. There are two reasons, historically, why PS is used in CPU scheduling. The ﬁrst is that PS allows short jobs (which require just a few quanta of service) to get out quickly. Because PS helps the many short jobs ﬁnish quickly, it should in theory also help reduce E[T]and particularly E[Slowdown ], as compared to FCFS. The other reason for PS is that time-sharing the CPU might allow an increase of overall system throughput in a multi-resource system. Imagine, for example, a multi-resource system, including a CPU, disk, memory, etc. It is useful to have many jobs running simultaneously (rather than just one job at a time), because jobs requiring different resources can be overlappedto increase throughput. But PS is not better than FCFS for every arrival sequence. Question: Give an example of an arrival sequence for which PS is worse than FCFS for both E[T]andE[Slowdown ]? Answer: Consider two jobs, both arriving at time 0, and both having size 1: E[T]FCFS=1.5E[Slowdown ]FCFS=1.5 E[T]PS=2 E[Slowdown ]PS=2 Question: We have seen that PS does not outperform FCFS on every arrival sequence. Can we say that M/G/1/PS outperforms M/G/1/FCFS with respect to expected response time in a stochastic setting?",3194
30.1 Processor-Sharing PS,"If so, what conditions, if any, are needed on G? Answer: Recall that we proved in Chapter 22that the distribution of the number of jobs in the M/G/1/PS system is the same as that in an M/M/1/FCFS system (for any Coxian distribution G). Hence the mean number of jobs and mean response time are the same for the M/G/1/PS and the M/M/1/FCFS. So M/G/1/PS is better in expectation than M/G/1/FCFS exactly when M/M/1/FCFS is better than M/G/1/FCFS, namely when C2 G>1, where C2 Gis the squared coefﬁcient of variation of G. In summary, it is the fact that the mean response time for PS is insensitive to job size variability that makes PS so powerful in practice. 30.1.2 Ages of Jobs in the M/G/1/PS System Deﬁnition 30.2 The ageof a job is the total service it has received so far. 484 scheduling: preemptive, non-size-based policies By deﬁnition, 0≤age(j)≤size(j), where age (j)denotes the age of job jand size (j) denotes the (original) size of job j. Although the steady-state number of jobs in the M/G/1/PS and M/M/1/FCFS queues is the same, P{nin system}=ρn(1−ρ), the distribution of the ages of their jobs is very different. Under FCFS, the jobs in queue all have age 0 and the job in service (if there is one) has age (and excess) distributed according to the equilibrium distribution, where the equilibrium distribution has probability density function, fe(·), deﬁned by fe(x)=F(x) E[S]. (30.1) Hence Sdenotes job size, f(·)is the job size p.d.f. of arriving jobs, and F(x)=/integraltext∞ xf(t)dtis the probability that an arriving job has size ≥x(see Exercise 25.14 for the derivation and Chapter 23for more intuition). Question: Can you guess at how the ages of the jobs in PS are distributed? Answer: Under PS, all jobs are worked on simultaneously, and thus an arrival sees every job through an Inspection Paradox. It therefore is unsurprising that an arrival to the M/G/1/PS ﬁnds that alljobs in the system have i.i.d. ages, distributed according to the equilibrium distribution. Theorem 30.3 For the M/G/1/PS queue, given there are njobs in the system, their ages are independent and have distribution density fe(·). Furthermore, the departure process is a Poisson process with rate λ. Proof The proof of this theorem is sketched in [ 149]. The proof is very technical and does not provide intuition, so we have not repeated it here. The basic idea is to makea guess about the reverse process, whereby we guess that the excesses of jobs in thereverse process are distributed according to the equilibrium distribution, and then we prove that this guess satisﬁes the balance equations. 30.1.3 Response Time as a Function of Job Size We now show that in the M/G/1/PS, every job has the same expected slowdown. Theorem 30.4 E[T(x)]M/G/1/PS=x 1−ρ. 30.1 processor-sharing (ps) 485 Corollary 30.5 E[Slowdown( x)]PS=1 1−ρ E[Slowdown]PS=1 1−ρ The remainder of this section is devoted to proving Theorem 30.4. Recall Little’s Law for red jobs: “The average number of red jobs in the system equals the average arrival rate of red jobs multiplied by the average time a red job spends in the system.” To ﬁgure out the mean time in system for a job of size x, we thus need to ﬁgure out the mean number of jobs in the system with size x.",3231
30.1 Processor-Sharing PS,"(Note that we are talking here about “original size” x, not “remaining service requirement” x). Question: Can we express the expected number of jobs in the system with size between xandx+hasE[N]f(x)h+o(h)? Answer: No. Although original job sizes are drawn from distribution density f(·), the sizes of those jobs in the system have a p.d.f. possibly different from f(·), because PS ﬁnishes off small jobs more quickly. Let f(·)= job size p.d.f. for arriving jobs. fsys(·)= job size p.d.f. for jobs in the system. Question: Sadly, we do not know anything about the probability that a job in the system has size, say, w. However, we do know the probability that a job in the system has age w. Can we use this? Answer: Yes. Our approach will be to condition on the job’s age: fsys(w)=/integraldisplayw x=0fsys(w|job has age x)·P{job has age x} =/integraldisplayw x=0fsys(w|job has age x)·fe(x)dx, by Theorem 30.3 =/integraldisplayw x=0f(w|job has size ≥x)·fe(x)dx =/integraldisplayw x=0f(w) F(x)·fe(x)dx =/integraldisplayw x=0f(w) E[S]dx, by (30.1) =wf(w) E[S] 486 scheduling: preemptive, non-size-based policies So fsys(w)=f(w)·w E[S]. (30.2) Question: Explain the intuition behind ( 30.2). Answer: In (30.2), the factor that f(w)gets weighted by isw E[S]. When wis small compared to E[S], this factor is less than 1. When wis large compared to E[S], this factor is greater than 1. This indicates that more large jobs are going to be in the system than would be true under f(w). Using ( 30.2), we have, for small h, E[Number of jobs in system with (original) size ∈(x, x+h)] =E[N]·fsys(x)·h+o(h) =ρ 1−ρ·x·f(x) E[S]·h+o(h) =λ 1−ρ·x·f(x)·h+o(h). E[Rate of arrivals of jobs into system with size ∈(x, x+h)] =λ·f(x)h+o(h). Now applying Little’s Law, we have E[Time in system for jobs with (original) size ∈(x, x+h)] =λ 1−ρ·x·f(x)·h+o(h) λ·f(x)h+o(h) =λ 1−ρ·x·f(x)+o(h) h λ·f(x)+o(h) h =λ 1−ρ·x·f(x) λ·f(x)ash→0 =x 1−ρ. Hence we have shown that E[T(x)]M/G/1/PS=x 1−ρ, completing the proof of Theorem 30.4. 30.1 processor-sharing (ps) 487 30.1.4 Intuition for PS Results Consider Theorem 30.4 and its corollary. These say that the expected slowdown for a job of size xunder the M/G/1/PS is a constant , independent of the size x. Remember that for non-preemptive non-size-based scheduling, the mean slowdown for small jobs was greater than the mean slowdown for large jobs. By contrast, under PS, all jobshave same slowdown. For this reason, people always refer to PS as fair scheduling . In Chapter 28, we discussed what would be a good metric for evaluating whether a policy, like SRPT, is starving big jobs. The criterion we advocate using is to determine mean slowdown of big jobs under SRPT and see whether the big jobs have much higher mean slowdown under SRPT than they would have under PS, which produces equalslowdown for all jobs. We will discuss fairness in detail in Chapter 33. Question: What is the intuition behind Theorem 30.4? Hint: An arrival sees E[N]=ρ 1−ρ jobs in the system. Answer: The arrival is slowed by a factor ofE[N]+1 , where E[N]+1=ρ 1−ρ+1=1 1−ρ. Thus, any arrival of size xshould take E[T(x)] =x·1 1−ρtime to leave the system. (This is not a proof, just intuition.) Question: What else that we have studied recently has the formx 1−ρ? Answer: E[B(x)] =x 1−ρis the expected length of a busy period started by a job of sizex. Thus the mean response time for a job of size xfor the M/G/1/PS queue is also equal to the mean length of a busy period started by a job of size x. Although this may lead one to think that the response time under M/G/1/PS is really just a busy period duration, higher moment analysis shows this not to be true. Remark: Although results for E[T]PSandE[T(x)]PSare really simple and beautiful, this is not true for Var(T)PS, which cannot even be expressed in a closed form. There are still theses being written today on the M/G/1/PS queue. There are pretty solutions whenGis Deterministic, and obviously when it is Exponential, but not for much else (see Section 30.4). 30.1.5 Implications of PS Results for Understanding FCFS Recall the transform equation for waiting time (delay) in the M/G/1/FCFS queue from (26.14 ): /tildewiderTQFCFS(s)=1−ρ 1−ρ/tildewiderSe(s)(30.3)",4215
30.2 Preemptive-LCFS,"488 scheduling: preemptive, non-size-based policies Remember that we needed an entire chapter (all of Chapter 26) to prove this result. We now rederive this result in one page. We start by writing ( 30.3) as a summation. Question: How can we express ( 30.3) as a sum? Answer: /tildewiderTQFCFS(s)=( 1−ρ)∞/summationdisplay k=0/parenleftBig ρ/tildewiderSe(s)/parenrightBigk =∞/summationdisplay k=0(1−ρ)ρk/parenleftBig /tildewiderSe(s)/parenrightBigk . (30.4) Question: What does/parenleftBig /tildewiderSe(s)/parenrightBigk represent? Answer:/parenleftBig /tildewiderSe(s)/parenrightBigk is the Laplace transform of/summationtextk i=1S(i) ewhere the S(i) e,f o r1≤ i≤k, represent i.i.d. instances of Se. Kleinrock, vol. I [ 110] writes that no one has been able to explain the curious for- mulation of/tildewiderTQFCFS(s)g i v e ni n( 30.4). Indeed it seems quite strange to see the term ρk(1−ρ)within an expression for the M/G/1/FCFS queue. Question: Using what we have learned about PS, explain in four lines why /tildewiderTQFCFS(s)=∞/summationdisplay k=0(1−ρ)ρk/parenleftBig /tildewiderSe(s)/parenrightBigk . Answer: LetWFCFSdenote the stationary work in an M/G/1/FCFS system. WFCFSis the same as the work in system as witnessed by a Poisson arrival. This in turn equals the delay experienced by a Poisson arrival under FCFS. LetWPSdenote the stationary work in an M/G/1/PS system. /tildewiderTQFCFS(s)=/tildewiderWFCFS(s) =/tildewiderWPS(s)(both FCFS and PS are work-conserving) =∞/summationdisplay k=0/tildewiderWPS(s|arrival sees kjobs)·P{arrival sees kjobs} =∞/summationdisplay k=0/parenleftBig /tildewiderSe(s)/parenrightBigk ·ρk(1−ρ) That completes the derivation of the M/G/1/FCFS delay transform. 30.2 Preemptive-LCFS Another preemptive non-size-based scheduling policy is Preemptive-LCFS (PLCFS) , deﬁned as follows: Whenever a new arrival enters the system, it immediately preempts the job in service. Only when that arrival completes does the preempted job get toresume service. 30.2 preemptive-lcfs 489 Question: What do you recall about the performance of the (non-preemptive) LCFS policy? Answer: It was identical in performance to FCFS – and thus not very good for highly variable job size distributions. Question: Any guesses as to what the performance of PLCFS will be like? Answer: We will prove the following theorem: Theorem 30.6 E[T(x)]PLCFS=x 1−ρ E[Slowdown(x)]PLCFS=1 1−ρ The remainder of this section is devoted to proving Theorem 30.6. The derivation is actually quite simple and instructive. We derive the mean, E[T(x)], here, and in Exercise 30.6 we will derive the full transform, which will yield additional insight. Consider a particular tagged job of size x. Key Observation: Once a job is interrupted, it will not get back the processor until all jobs arriving after that point are completed (refer to Figure 30.1). start jobn+2end jobn+2end jobn+1end jobntimejobn+2 jobn+1 jobn start jobnstart jobn+1 Figure 30.1. Jobs under Preemptive-LCFS. Question: So how long will it be, on average, from when our tagged job is interrupted until it gets back the processor? Answer: We can think of the point when our job gets interrupted as marking the beginning of a busy period in an M/G/1 queue, because the job will not resume until the interruption, and all work that arrives during its busy period, completes. So, E[Time until job gets back processor ]=E[Length of busy period ]=E[S] 1−ρ. Note: The mean length of the busy period is the same regardless of the service order in the M/G/1 so long as the service order is work-conserving.",3564
30.3 FB Scheduling,"490 scheduling: preemptive, non-size-based policies Question: What is E[# times our tagged job gets interrupted ]? Answer: Because our job has size x, the expected number of times it will be interrupted is just λx, the expected number of arrivals during time x. Let Wasted-Time (x)refer to the time the tagged job is in the system but not serving. E[Wasted-Time (x)] =E[# times tagged job is interrupted ]·E[length of interruption ] =λx·E[S] 1−ρ =ρx 1−ρ E[T(x)] =x+E[Wasted-Time (x)] =x+ρx 1−ρ=x 1−ρ E[Slowdown (x)] =1 1−ρ Thus although the PLCFS policy looks very different from PS, its mean performance is the same as for PS – even its mean performance on jobs of size x.W eh a v en o w completed the proof of Theorem 30.6. Question: Can you see any advantage to using PLCFS over PS? Answer: PLCFS offers the same expected performance with many fewer preemptions. Question: Exactly how many preemptions will we have under PLCFS? Answer: Each job creates two preemptions – one when it arrives and one when it departs. Thus we have only two preemptions per job in PLCFS, whereas in a real- world implementation of PS, with small quantum sizes, the number of preemptionscan be much higher. If preemptions actually have a cost, then PLCFS wastes less timedoing them, as compared with PS. 30.3 FB Scheduling So far, all the preemptive non-size-based scheduling policies we have seen produce the same mean slowdown for all job sizes: E[Slowdown (x)] =1 1−ρ Wouldn’t it be nice if we could somehow get lower slowdowns for the smaller jobs, sothat we could drop our mean slowdown? Question: But how can we give preference to the smaller jobs if we do not know job size? 30.3 fb scheduling 491 Answer: Wedoknow a job’s age (the service it has received so far), and age is an indication of the job’s remaining CPU demand. If the job size distribution has DFR (decreasing failure rate), as does the Pareto distri- bution, then the greater the job’s age, the greater its expected remaining demand. Sowe should give preference to jobs with low age (younger jobs), and this will have theeffect of giving preference to jobs that we expect to ﬁnish quickly. UNIX does this using Multi-Level Processor-Sharing (MLPS), also called Foreground- Background scheduling. There are two queues served by the same one server, where queue 1 is high priority and queue 2 is low priority. All jobs start out in queue 1. Jobs in queue 1 are run using PS. When a job hits a certain age a, it is moved to queue 2. Jobs in queue 2 get service only when queue 1 is empty. We will study this idea in the limit as the number of queues goes to inﬁnity. This limiting algorithm is called Generalized Foreground-Background (FB) scheduling and is deﬁned as follows: rThe job with the lowest CPU age gets the CPU to itself. rIf several jobs have same lowest CPU age, they share the CPU using PS. This algorithm is known in the literature both under the name FB and under the name Least-Attained-Service (LAS). Question: Consider the following arrival sequence: rAt time 0, a job (customer) of size 3 arrives. rAt time 1, a job (customer) of size 2 arrives. rAt time 2, a job (customer) of size 1 arrives. When will each of these complete under FB? Answer: The size 1 job leaves at time 3; the size 2 job leaves at time 5; and the size 3 job leaves at time 6, as shown in Figure 30.2. time 45 6size 0 1123 23 Figure 30.2. State of system at several points in time under FB scheduling. As jobs (customers) are worked on, they start to “disappear.” When a job becomes “invisible,” it departs. The performance improvement of FB over PS obviously has to do with how good a pre- dictor age is of remaining size, which depends on the distribution of job sizes. Ourgoal is to compute E[T(x)]FB. Before we start, let’s work through a small mathematical exercise that will come in handy later. 492 scheduling: preemptive, non-size-based policies Letf(y)be the probability density function (p.d.f.) for our size distribution. Deﬁne fx(y)to be the p.d.f. for the transformed size distribution, where each job of size >x has been replaced by a job of size x, as shown in Figure 30.3. Replace by size x x xAll jobs of size >  x are replaced by size xf(y) size sizefx(y) Figure 30.3. Original p.d.f., f(y), and the transformed p.d.f., fx(y). IfSxdenotes the job size under the transformed distribution, then E[Sx]=/integraldisplayx 0yf(y)dy+x(1−F(x))(integration by parts)=/integraldisplayx 0F(y)dy. E[Sn x]=/integraldisplayx 0ynf(y)dy+xn(1−F(x))(integration by parts)=/integraldisplayx 0yn−1F(y)dy. Utilization :ρx=λE[Sx]. Now let us return to the problem of deriving E[T(x)]FB. Let jobxdenote a job of size x. To derive E[T(x)]FB, think about all the units of work that have to get done before jobxcan leave the system: (1)xunits (this is just the size of job x). (2) The expected remaining work in the system when job xarrives, except that in doing this computation we need to pretend that every job in the system has a service requirement no more than x. That is, every job of size >x is assumed to have size x, for the purpose of computing the remaining work in the system when job xarrives. To understand this, realize that from job x’s viewpoint, a job jwith size >x looks exactly like it has size x, because once job jreaches age xit will never again affect job x. So in totaling the expected remaining work in 30.3 fb scheduling 493 the system that will affect job x, we need to shrink each job’s size to x. If a job has already reached age ≥x, we just ignore that job, because it will not receive service until after job xcompletes. (3) The expected work due to new arrivals while job xis in the system, where again jobs are counted only by how much they can affect job x. We use Sxin determining quantities (2) and (3) in E[T(x)]FB: Derivation of (2): Item (2) basically says that when job xarrives into the system, it looks at all jobs through “transformer glasses” (see Figure 30.4), which “decapitate” each job of size >xto form to a job of size x. Then we total the remaining work in the transformed system. x x Figure 30.4. Transformer glasses for FB. Claim 30.7 If the queue is using FB scheduling, then the remaining work in the suddenly transformed system is the same as if we had simply transformed each job at the instant it arrived to the system. Proof Let system A be the original system, no transformations. Let system B be a system where each job is transformed the instant it arrives. Whenever system B is working, system A is also working on a job of age <x. The only time system A is working on a job of age >xis when both (i) system B is idle and (ii) all jobs in system A have age >x. Thus, if we walked up to system A at any moment and suddenly put on our transformer glasses, system A would look just like system B. Thus, (2) is asking for the remaining work in a system doing FB scheduling where each job is transformed immediately on arrival. In other words, (2) is asking for theremaining work in an FB system where the job size is Sx. Question: But what is the remaining work in such a system? Answer: Remember, the remaining work in any work-conserving system is the same as any other, so we may as well ask what is the expected remaining work in a M/G/1/FCFS 494 scheduling: preemptive, non-size-based policies where the job size is Sx. But this is simply E[Remaining work in M/G/1/FCFS ]=E[TQ]M/G/1/FCFS=λE[S2 x] 2(1−ρx). So (2) =λE[S2 x] 2(1−ρx). Derivation of (3): To derive (3), observe that (3) =E[# arrivals during T(x)]·E[size of arrivals as viewed by job x] =λE[T(x)]FBE[Sx]. So, E[T(x)]FB= (1) + (2) + (3) =x+λE[S2 x] 2(1−ρx)+λE[T(x)]FBE[Sx] =x+λE[S2 x] 2(1−ρx)+ρxE[T(x)]FB. Now collecting the E[T(x)]FBterms together we have E[T(x)]FB(1−ρx)=x+λE[S2 x] 2(1−ρx). So E[T(x)]FB=x+λE[S2 x] 2(1−ρx) 1−ρx(30.5) =x(1−ρx)+1 2λE[S2 x] (1−ρx)2. (30.6) Expression ( 30.5) gives us another way of thinking about E[T(x)]FB– as the mean length of a busy period. Consider a busy period started by only the job itself ( x) plus the “relevant” work that it ﬁnds in the system when it arrives/parenleftbigg λE[S2 x] 2(1−ρx)/parenrightbigg , where all jobs arriving during the busy period have job sizes Sx. Then ( 30.5) is the mean length of that busy period (see Section 27.2). Several interesting results regarding FB will be explored in the exercises: rIf the job size distribution has DFR, then younger jobs have lower remaining service times, so E[T]FB<E[T]PS as expected; see [ 189] for a formal proof.",8483
30.5 Exercises,"30.4 readings 495 rIf the job size distribution has increasing failure rate (IFR), then younger jobs have higher remaining service time, so favoring the younger jobs (as FB does) isbad and E[T]FB>E[T]PS as expected. rIf the job size distribution has constant failure rate (Exponentially distributed),then remaining time is independent of age, so we might expect that E[T]FB=E[T]PS. In Exercise 30.3, you will prove this equality for the Exponential distribution. rAlso for an Exponential job size distribution, we will see in Exercise 30.2 that E[Slowdown ]FB<E[Slowdown ]PS. Question: Why would the slowdown under FB, under an Exponential job size distribution, be strictly smaller than under PS, although their mean response timesare equal? Answer: Here is a heuristic argument: Under an Exponential workload, age is independent of remaining time. So, biasing toward jobs with small ages does not favor jobs with small remaining service requirement, and remaining service requirement is what affects E[T]. However, biasing toward jobs with small ages does slightly favor jobs with smaller expected original size. So FB is in essence giving slight preference to short jobs even under the Exponential distribution, and this is what improves E[Slowdown ]. 30.4 Readings Athough the M/G/1/PS has simple solutions for E[T]andE[T(x)], the variance of response time, Var(T), is far more difﬁcult to analyze and is not known in a simple closed form. For those interested in learning more, a good place to start is the survey paper by Yashkov and Yashkova [ 197]. There are also many variants of PS in the literature, which allow for time-sharing with different weights, including Discriminatory Processor-Sharing (DPS) and Generalized Processor-Sharing (GPS).A survey of these and other variants is given in [ 1]. Foreground-Background (FB) scheduling, also known as Least-Attained-Service (LAS), has received a lot of attention, both analytically and from a practical per-spective. On the analytical front, we recommend the thesis by Misja Nuijens [ 133] and [ 143]. On the implementation front, FB has been used for IP ﬂow scheduling; see [144,142]. Policies like PS and FB that do not make use of size are sometimes called blind ; see [60]. Additional references on all these scheduling policies can be found in Adam Wierman’s thesis [ 188]. 496 scheduling: preemptive, non-size-based policies 30.5 Exercises 30.1 Review of Scheduling Formulas Match each of the following 12 expressions to oneof the formulas (a) through (g). Read the glossary to make sure you understand all the expressions. (1)E[T]M/G/1/FCFS(7)E[T]M/M/1/FB (2)E[T]M/G/1/PS(8)ρ (3)E[T]M/G/1/LCFS(9)E[B]M/G/1/FCFS (4)E[T]M/G/1/PLCFS(10)E[B]M/M/1/FCFS (5)E[T]M/M/1/FCFS(11)E[Se] (6)E[T]M/M/1/PS(12)E[W]M/G/1/FCFS Formulas: (a)λE[S](b)E[S2] 2E[S](c)E[S] 1−ρ(d)ρ 1−ρE[Se](e)ρ 1−ρE[Se]+E[S] (f)E[Se] 1−ρ(g) None of the above Glossary: ρ=load = fraction of time server is busy T=response time B=busy period duration λ=average arrival rate S=service requirement for jobs Se=excess of S W=work seen by an arrival into the queue 30.2 Comparison of FB and PS Scheduling Policies Consider an M/G/1 server with load ρ=0.8. Consider two job size distribu- tions: (a) Exponential distribution with mean 3,000 (b) Bounded Pareto distribution BP(k= 332 .067,p=1 010,α=1.1)with mean 3,000 For each distribution, compute E[T]andE[Slowdown ]under both FB and PS scheduling. Use a symbolic math package to do the computations.1 30.3 FB versus PS under Exponential Workloads In Exercise 30.2 you should have found that the mean response time under FB and under PS was the same if the job size distribution was Exponential. In the chapter, we gave intuition for why this might be true. Prove formally that this should be the case. [Hint: There is an ugly long proof and a very beautifulshort proof.] 30.4 Starvation under FB Consider an M/G/1 server with load ρ=0.8. Consider two job size distribu- tions: 1The following link provides all the functions that you will need already coded for use with MathematicaTM: http://www.cs.cmu.edu/ ∼harchol/PerformanceModeling/software.html. 30.5 exercises 497 (a) Exponential distribution with mean 3,000. (b) Bounded Pareto distribution, BP(k= 332 .067,p=1 010,α=1.1), with mean 3,000. The FB policy favors small jobs (or those that are expected to be small). In this way it improves on the performance of PS. However, there is a fear that thisbeneﬁt may come at the cost of causing large jobs to suffer unfairly. In thisproblem, we compare the mean slowdown of large jobs under FB and underPS to study the effect of this unfairness. You will need to use a symbolic math package (use the link in Footnote 1). (a) Compare the mean slowdown of a job in the 90th percentile under FB and under PS. (b) Compare the mean slowdown of a job in the 99th percentile under FB and under PS. (c) What is the ﬁrst percentile where a job does worse under FB than under PS? (d) Explain why so few jobs suffer under FB. 30.5 Analysis of Preemptive-LCFS This question develops a clearer understanding of PLCFS.(a) Determine the Laplace transform for time in system under PLCFS, /tildewideT(s)PLCFS. Follow exactly the approach we used in the chapter where we ﬁrst consider the response time of a job of size xand then look at how many times that job gets interrupted and what the contribution of each such interruption looks like. (b) Use this transform to determine the ﬁrst 2 moments of response time. (c) You should notice something very simple about your transform. It should look identical to a transform that you derived recently. This will give you a new way of looking at PLCFS. Explain why this alternative, simpler, view of PLCFS is also correct. 30.6 M/G/1/FB Transform In this chapter we derived the mean response time for FB. Use the same arguments to derive the transform of response time. 30.7 Database Performance Bianca observes that her database throughput drops when she runs too many transactions concurrently (this is typically due to thrashing). She also observes that if she runs too few transactions concurrently, her database throughputdrops as well (this is often due to insufﬁcient parallelism). To capture theseeffects, Bianca models her time-sharing database system as an M/M/1/PSqueue with load-dependent service rate, μ(n), where ndenotes the number of concurrent transactions. The function μ(n)is shown in Figure 30.5. (a) Solve for the mean response time under Bianca’s M/M/1/PS system. As- sume arrival rate λ=0.9. [Hint: Use a Markov chain.] (b) Bianca has a great idea: Rather than allow all transactions into the database as before, she decides to allow at most 4 transactions to run concurrently in the database, where all remaining transactions are held in a FCFS queue. Bianca’s new queueing architecture is shown in Figure 30.6. Compute the mean response time for Bianca’s new architecture, again assuming 498 scheduling: preemptive, non-size-based policies (n) n 01123 23456789 1 0 Figure 30.5. Service rate in the database changes depending on number of concurrent trans- actions, n, staying constant at 1 for n≥6. Ignore non-integral values of n. λ=0.9, and Exponentially distributed service times with rates from Fig- ure30.5. What is the intuition behind Bianca’s hybrid FCFS/PS architec- ture? PS MPL = 4(n) λFCFS Figure 30.6. Processor-Sharing with limited multiprogramming level, MPL =4. (c) Varun suggests that if the job size distribution is highly variable (much more variable than an Exponential), it may be better to increase the MPL to more than 4, even though that causes the service rate to drop. What is the intuition behind Varun’s suggestion? [Hint: Observe that Bianca’s FCFS/PS architecture has some properties of FCFS and some properties of PS.] If you would like to learn more about analyzing the limited Processor-Sharing system in Figure 30.6, we recommend [ 77,198,199].",7903
Chapter 31 Scheduling Non-Preemptive Size-Based Policies. 31.1 Priority Queueing,"CHAPTER 31 Scheduling: Non-Preemptive, Size-Based Policies Until now, we have only considered scheduling policies that do not have any knowledge of the job sizes. In this chapter and the next two chapters, we will look at size-basedscheduling policies, starting with non-preemptive size-based policies (this chapter)and followed by preemptive size-based policies (next two chapters). The size-basedpolicies that we will be studying include the following: SJF – (non-preemptive) Shortest-Job-First (Chapter 31) PSJF – Preemptive-Shortest-Job-First (Chapter 32) SRPT – (preemptive) Shortest-Remaining-Processing-Time (Chapter 33) It will be convenient to evaluate these size-based policies as special cases of priority queueing, so we start by analyzing priority queues, which are important in their own right. Size-based scheduling is a very important topic, which is why we devote three chapters to it. The proper size-based scheduling policy can greatly improve the performanceof a system. It costs nothing to alter your scheduling policy (no money, no newhardware), so the performance gain comes for free. The above size-based policies areimplemented in real systems. For web servers serving static content, SRPT schedulinghas been implemented in the Linux kernel to schedule HTTP requests [ 92]. It has also been used to combat transient overload in web servers [ 162]. Priority queues are likewise prevalent in computer systems. Prioritization of jobs is used in databases toprovide differentiated levels of service, whereby high-priority transactions (those thatbring in lots of money) are given priority over low-priority transactions (those thatare less lucrative). Prioritization can be implemented in different ways in database servers, sometimes internally by scheduling the database lock queues, and sometimes externally by limiting the multiprogramming level in the database to favor high-prioritytransactions; see [ 123,164,163] and the references therein. 31.1 Priority Queueing We now describe a model for an M/G/1 priority queue. Arriving jobs are divided into n priority classes, where class 1is the highest priority and class nis the lowest priority. Classkjob arrivals form a Poisson process with rate λk=λ·pk, where/summationtextn k=1pk=1. The service time distribution for a job of class khas moments E[Sk]andE[S2 k]. 499 500 scheduling: non-preemptive, size-based policies priority 1 jobs1st priority 2nd priority nth prioritypriority 2 jobs priority n jobs Figure 31.1. When a server frees up, it takes the job at the head of the highest priority, non-empty queue. We can picture the M/G/1 priority queue as maintaining a separate (imaginary) queue for each class. When the server becomes free, it always chooses the job at the head ofthe highest priority non-empty queue to work on, as shown in Figure 31.1. We consider two types of priority queueing: 1. Non-Preemptive Priority Queueing – Once a job starts running, it cannot be preempted, even if a higher priority job comes along. 2. Preemptive Priority Queueing – The job in service is preempted if a higher priority job arrives, and the higher priority job is then served. No work is lost. Question: What are some examples where non-preemptive priority queueing is used and where preemptive priority queueing is used? Answer: Non-preemptive priority queueing is used whenever a job cannot be stopped once it has started running. For example, airline ticket counters want to ticket the ﬁrst-class customers before the coach customers, but once they start ticketing a coachcustomer, they cannot stop midway if a ﬁrst-class customer arrives. Preemptive priority queueing is often used for job scheduling in computer systems. Interactive jobs get precedence over batch jobs and can preempt a running batch job. Notation We always write the priority in parentheses. Class 1 jobs have highest priority; class 2 next highest priority, etc. Class njobs have lowest priority. As you can probably guess, priority will eventually become related to size; a job’s size will be its priority, where a job of size xhas priority over a job of size yifx<y ,f o r real-valued xandy. Sk=size of priority kjob E[NQ(k)] = average number of priority kjobs in the queue E[TQ(k)] = average time in queue for priority kjobs",4276
31.2 Non-Preemptive Priority,"31.2 non-preemptive priority 501 E[T(k)] = average time in system for priority kjobs λk=λ·pk=average arrival rate of jobs of priority k ρk=λkE[Sk]=contribution to the load due to jobs of priority k We will require that the server utilization, ρ, is less than 1: n/summationdisplay i=1ρi=n/summationdisplay i=1λiE[Si]=n/summationdisplay i=1λ·piE[Si]=λE[S]=ρ<1. Note that S, as usual, represents an arbitrary job’s size. Hence, E[S]=n/summationdisplay k=1pkE[Sk];E/bracketleftbig S2/bracketrightbig =n/summationdisplay k=1pkE/bracketleftbig S2 k/bracketrightbig ;E[Se]=E/bracketleftbig S2/bracketrightbig /E[S]2 31.2 Non-Preemptive Priority We will use a “tagged-job” type of argument to derive the performance of a non- preemptive M/G/1 priority queue. It will help greatly to review the “tagged-job” argu-ment for the M/G/1/FCFS queue from Chapter 23before reading this section. Deriving TQ(1)– Time in Queue for Jobs of Priority 1 Consider a priority 1 arrival. That arrival has to wait for both (i) The job currently in service, if there is one. (ii) All jobs of priority 1 in queue when the job arrives. E[TQ(1)] = P{Server busy}·E[Se]+E[NQ(1)]·E[S1] =ρ·E[Se]+E[TQ(1)]·λ1·E[S1] =ρ·E[Se]+E[TQ(1)]·ρ1 =ρ·E[Se] 1−ρ1 Deriving TQ(2)– Time in Queue for Jobs of Priority 2 Consider a priority 2 arrival. That arrival has to wait for (i) The job currently in service, if there is one. (ii) All jobs of priority 1 or 2 in queue when the job arrives. (iii) All jobs of priority 1 that arrive while the new job is waiting (not in service). E[TQ(2)] = ρ·E[Se]+E[NQ(1)]·E[S1]+E[NQ(2)]·E[S2] +E[TQ(2)]·λ1E[S1] =ρ·E[Se]+E[TQ(1)]·ρ1+E[TQ(2)]·ρ2+E[TQ(2)]·ρ1 502 scheduling: non-preemptive, size-based policies E[TQ(2)]·(1−ρ1−ρ2)=ρE[Se]+ρ1·E[TQ(1)] E[TQ(2)]·(1−ρ1−ρ2)=ρE[Se]+ρ1·ρE[Se] 1−ρ1=ρE[Se] (1−ρ1) E[TQ(2)] =ρE[Se] (1−ρ1)(1−ρ1−ρ2) Deriving TQ(k)– Time in Queue for Jobs of Priority k Consider a priority karrival. That arrival has to wait for (i) The job currently in service, if there is one. (ii) All jobs of priority 1,2,...,k in queue when the job arrives. (iii) All jobs of priority 1,2,...,k−1that arrive while the new job is waiting. After some algebra, we can show by induction that E[TQ(k)]NP-Priority=ρE[Se]/parenleftBig 1−/summationtextk i=1ρi/parenrightBig/parenleftBig 1−/summationtextk−1 i=1ρi/parenrightBig. Finally, substituting in the formula for E[Se], from ( 23.9), we have E[TQ(k)]NP-Priority=ρE[S2] 2E[S]/parenleftBig 1−/summationtextki=1ρi/parenrightBig/parenleftBig 1−/summationtextk−1 i=1ρi/parenrightBig. (31.1) Interpreting the Formula for E[TQ(k)]NP-Priority Question: Explain the difference between the formula for E[TQ(k)]NP-Priorityand the formula for E[TQ]FCFS. Answer: Recall that for the M/G/1/FCFS queue E[TQ]FCFS=ρE[S2] 2E[S] 1−ρ. Recall in the tagged job analysis for the M/G/1/FCFS queue that the numerator, ρE[S2] 2E[S], is due to waiting for the job in service. Speciﬁcally, this numerator represents the probability that there is a job in service ( ρ) multiplied by the expected remaining time on that job given that there is a job in service (E[Se]=E[S2] 2E[S]). This is also the case in the numerator for the M/G/1/NP-Priority queue. Recall next that in the M/G/1/FCFS queue, the denominator, 1−ρ, is due to waiting for the jobs already in the queue. In the M/G/1/NP-Priority formula, the denominator 31.2 non-preemptive priority 503 has two components. The /parenleftBigg 1−k/summationdisplay i=1ρi/parenrightBigg term can be thought of as the contribution due to waiting for jobs in the queue of higher or equal priority. Observe that a job of class konly needs to wait behind those jobs in the queue of class up to k. The /parenleftBigg 1−k−1/summationdisplay i=1ρi/parenrightBigg term can be thought of as the contribution due to those jobs that arrive after our job, but have strictly higher priority than our tagged job (i.e., jobs of class 1tok−1arriving after our job). This second part of the denominator obviously does not occur underFCFS. Question: Now compare what happens to high-priority jobs (low k) under non- preemptive priority queueing versus under FCFS. Hint: E[TQ(k)]NP-Priority≈1 (1−/summationtextk i=1ρi)2·ρE[S2] 2E[S]. E[TQ(k)]FCFS=E[TQ]FCFS=1 1−ρ·ρE[S2] 2E[S]. Answer: TheE[TQ(k)]NP-Priorityformula has the disadvantage of the squared denom- inator, due to having to wait behind later arrivals. However it has the advantage of onlyseeing load due to jobs of class kor less. Here is the point: Suppose kis low (i.e., we have a high-priority job). Then, k/summationdisplay i=1ρi/lessmuchρ. So E[TQ(k)]NP-Priority<E[TQ]FCFS. Now let’s suppose that the job’s priority is related to its size, where the smaller the job is, the higher its priority. Recall that if the service time distribution has the heavy-tailproperty, then the largest 1 percentof the jobs make up most of the load. Thus, even for higher values of k(but not the max k) we have that k/summationdisplay i=1ρi/lessmuchρ. So E[TQ(k)]NP-Priority<E[TQ]FCFS,",4973
31.3 Shortest-Job-First SJF,"504 scheduling: non-preemptive, size-based policies even for higher values of k. Of course, for a job of class n, NP-Priority is worse than FCFS, because of the squared term in the denominator. Question: H o wd ow eg e t E[TQ]NP-Priority,g i v e nE[TQ(k)]? Answer: E[TQ]NP-Priority=n/summationdisplay k=1E[TQ(k)]·pk=n/summationdisplay k=1E[TQ(k)]·λk λ. 31.3 Shortest-Job-First (SJF) One way of assigning priorities is as a function of the job size. Question: If your goal is minimizing mean response time, which do you think should have higher priority: the large jobs or the small ones?Answer: The small ones. See Exercise 31.1. Shortest-Job-First (SJF) is a non-preemptive scheduling policy (once a job is running, it is never interrupted). Whenever the server is free, it chooses to work on the job with thesmallest size . Question: How can we analyze the performance of SJF given what we have just seen? Answer: We can use our results for non-preemptive priority queueing. We model SJF by having an inﬁnite number of priority classes, where the smaller the job, the higherits priority. Analysis of SJF Consider again the situation of npriority classes. Let’s assume that the job sizes range between x0=0andxn. Deﬁne boundary points x1,x2,...x n−1such that x0<x 1<x 2<···<x n−1<x n. Assign all jobs of size ∈(xk−1,xk)to class k, as shown in Figure 31.2. Then, E[TQ(k)]NP-Priority=ρE[S2] 2E[S]·1/parenleftBig 1−/summationtextk−1 i=1ρi/parenrightBig/parenleftBig 1−/summationtextk i=1ρi/parenrightBig whereE[TQ]NP-Priority=n/summationdisplay k=1pk·E[TQ(k)]. Class 1 0 x1 x2 x3 xn–1 xnClass 2 Class 3 Class n Figure 31.2. Deﬁning classes based on job size. 31.3 shortest-job-first (sjf) 505 Observe that pk, the fraction of jobs in class k, equals F(xk)−F(xk−1), where F(xn)=1 , andF(x0)=0 . So far we have not used anything but the original NP- Priority formulas. Now consider the situation where n→∞ andxk−xk−1→0. That is, the number of classes, n, is allowed to grow to ∞, in such a way that (xk−xk−1)becomes arbitrarily small∀k. We are interested in the expected waiting time for a job of size xk.A sn→∞ , Load of jobs in class 1tok→Load of jobs of size <x k k/summationdisplay i=1ρi=λk/summationdisplay i=1piE[Si]→λ/integraldisplayxk t=0tf(t)dt. Load of jobs in class 1tok−1→Load of jobs of size <x k−1 k−1/summationdisplay i=1ρi=λk−1/summationdisplay i=1piE[Si]→λ/integraldisplayxk−1 t=0tf(t)dt→λ/integraldisplayxk t=0tf(t)dt. So, E[TQ(x)]SJF=ρE[S2] 2E[S]·1 (1−λ/integraltextx t=0tf(t)dt)2. (31.2) And E[TQ]SJF=/integraldisplayxn x=0E[TQ(x)]f(x)dx =ρE[S2] 2E[S]·/integraldisplayxn x=0f(x)dx (1−λ/integraltextx t=0tf(t)dt)2. (31.3) Now, let’s compare SJF with FCFS for a job of size x. To do this, we ﬁrst need to deﬁne a term. Deﬁnition 31.1 Let ρx=λ/integraldisplayx t=0tf(t)dt. (31.4) The term ρxdenotes the load composed of jobs of size 0tox. Note that we can express ρxequivalently as ρx=λF(x)/integraldisplayx t=0tf(t) F(x)dt, (31.5) which shows more explicitly that we are multiplying the arrival rate of jobs of size no more than x, namely λF(x), by the expected size of jobs of size no more than x, namely/integraltextx t=0tf(t) F(x)dt. Note:ρxis different from ρx, which we saw in the FB policy analysis.",3219
Chapter 32 Scheduling Preemptive Size-Based Policies,"506 scheduling: non-preemptive, size-based policies Rewriting ( 31.2) using ρx,w eh a v e E[TQ(x)]SJF=ρE[S2] 2E[S]·1 (1−ρx)2. By comparison we have, for FCFS: E[TQ(x)]FCFS=ρE[S2] 2E[S]·1 1−ρ. Observe that ρxis typically much less than ρ. For small jobs (small x),E[TQ(x)]SJF should be lower than E[TQ(x)]FCFS. For very large jobs, E[TQ(x)]SJFis higher than E[TQ(x)]FCFSbecause of the squared factor in the denominator. If the service time distribution is heavy-tailed, then E[TQ(x)]SJFis only higher for the very, very large jobs. Because most jobs are small, E[TQ]SJF<E[TQ]FCFS. 31.4 The Problem with Non-Preemptive Policies Question: Nonetheless, we claim that SJF is still a poor choice of scheduling policies in the case of a heavy-tailed job size distribution, when trying to minimize mean time in queue. Why is this? Answer: The expression for mean time in queue contains an E[S2]term, and in heavy-tailed job size distributions, the variance is huge. It would be much better to use a scheduling policy whose mean delay does not involve an E[S2]term. For example, we might use the PS, PLCFS, or FB policies that we discussed in the last chapter. Question: What about the mean time in queue for really small jobs? Answer: Even for small jobs, performance is still affected by the variance in the job size distribution. True, a system with high load ρmay appear as if it has low load from the perspective of a small job; however, the variance in the job size distribution can dominate everything. So even a small job may not do well under SJF. Question: Explain intuitively (without using the formula) why it is that even a small job is not expected to do well under SJF. Answer: A small job can still get stuck behind a big job, if the big job started running before the small job got there. So what we really need in order to get good performance is the ability to preempt jobs. This is the topic of the next chapter.Question: What can be done if preemption is not available? Answer: The ability to preempt jobs is, in fact, so important that in cases where preemption is not naturally available, it pays to take up extra time to checkpoint the job, saving its state, so that it can be stopped and restarted again from that point. 31.5 exercise 507 Question: But what if checkpointing is not available either? It seems one has no choice then but to run jobs to completion? Answer: If the job size variability is high enough and one does not know how long a job is going to take, it can actually be better to kill a running job after some time, given that there are other jobs queued up. This may seem foolish, because the killed job willeventually have to be restarted from scratch, and this creates extra work. However, if there are many jobs queued up, they are likely to include many short jobs, and meanresponse time will improve by letting those short jobs get a chance to run. This is theidea behind the TAGS policy [ 82]. 31.5 Exercise 31.1 Why Small Jobs Should Get Priority Consider an M/G/1 system with non-preemptive priority scheduling. Suppose there are two customer classes of jobs – S (small) and L (large) – with arrival ratesλSandλLand mean job size E[SS]andE[SL], where E[SS]<E[SL]. Prove that, to minimize the mean waiting time over all jobs, we should give class S jobs priority over class L jobs. Do this by deriving E[TQ]NP-Priorityfor the case where S has priority and for the case where L has priority.",3432
32.1 Motivation. 32.2 Preemptive Priority Queueing,"CHAPTER 32 Scheduling: Preemptive, Size-Based Policies In this chapter, we discuss preemptive scheduling policies that make use of knowing the size of the job. As in the last chapter, we start by deﬁning and evaluating preemptivepriority queueing, and then we extend that analysis to the Preemptive-Shortest-Job-First(PSJF) scheduling policy. 32.1 Motivation Recall that we can divide scheduling policies into non-preemptive policies and pre-emptive policies. Question: What is discouraging about the mean response time of all the non-preemptive scheduling policies that we have looked at? Answer: They all have an E[S2]factor that comes from waiting for the excess of the job in service. This is a problem under highly variable job size distributions. We have also looked at preemptive policies. These tend to do better with respect to mean response time under highly variable job size distributions. Not all of these haveequal performance, however. Preemptive policies like PS and PLCFS that do not makeuse of size have mean response time equal to that of M/M/1/FCFS; namely, they areinsensitive to the job size distribution beyond its mean. This is already farbetter than non-preemptive scheduling policies, when the job size distribution has high variability.However, preemptive policies that make use of size or age can do even better by biasingtoward jobs with small size. So far, we have seen this only for the FB scheduling policythat favors jobs with small age. In this chapter and the next, we will examine policiesthat make use of a job’s (original) size and remaining size. 32.2 Preemptive Priority Queueing We start with preemptive priority queueing. As in the non-preemptive case, we assume the following: rThere are nclasses. rClass 1 has highest priority. rClasskjobs arrive according to a Poisson process with rate λk=λ·pk. rClasskjobs have service requirements with moments E[Sk]andE[S2 k]. rThe load of class kisρk=λk·E[Sk]. 508 32.2 preemptive priority queueing 509 At every point in time, the server is working on the highest priority job in the system. Preemptive priority queueing differs from non-preemptive queueing in that whenevera job arrives with a higher priority than the job currently in service, the job in ser-vice is preempted and the higher priority job begins service. No work is lost underpreemptions. One application of preemptive priority queueing is a network where a number of differ- ent packet streams with different priorities are trying to use the same communicationlink. Each stream consists of a sequence of packets. Only one stream ﬂows through thecommunication link at a time. If a higher priority stream starts up, the current streamsuspends its service and waits for the higher priority stream to ﬁnish. We will compute E[T(k)]P-Priority, the mean time in system for a job of priority kin a system with preemptive priority. To do this, imagine a job of priority kentering the system and consider all the work that must be completed before the job can leave thesystem. This work is made up of three components: 1.",3064
32.1 Motivation. 32.2 Preemptive Priority Queueing,"E[Sk]– the mean service time for a job of priority class k 2.the expected time required to complete service on all jobs of priority 1tok already in the system when our arrival walks in 3.the expected total service time required for all jobs of priority 1tok−1that arrive before our arrival leaves Observe that component (3) is simply (3) =k−1/summationdisplay i=1E[T(k)]·λi·E[Si]=E[T(k)]k−1/summationdisplay i=1ρi. But, how do we compute component (2)? Question: Can we do what we did in the case of non-preemptive priority, namely, add up the expected number of jobs in each class for classes 1tok, each weighted by the mean job size for that class? Answer: No. The jobs in queue may already have been partially worked on (remember, this is a preemptive queue). To determine (2), we make the following arguments: (2) =/parenleftBigExpected remaining work in the system due to only jobs of priority 1through k./parenrightBig =/parenleftBiggTotal expected remaining work in preemptive priority system if the system only ever had arrivals of priority 1through k(because jobs of class >kdo not affect jobs of class 1through k)./parenrightBigg =⎛ ⎜⎝Total expected remaining work in system if the system only ever had arrivals of class 1through kandthe scheduling order was any work- conserving order; for example, FCFS (because all work-conservingpolicies have the same remaining work).⎞ ⎟⎠ 510 scheduling: preemptive, size-based policies =/parenleftBigE/bracketleftbig TQ/bracketrightbigunder FCFS scheduling order, where the system only has arrivals of class 1through k/parenrightBig =/summationtextk i=1ρi 1−/summationtextki=1ρi·/summationtextki=1p i FkE[S2 i] 2/summationtextki=1p i FkE[Si],where Fk=k/summationdisplay i=1pi This can be simpliﬁed a bit as follows: (2) =λ/summationtextki=1piE[Si] 1−/summationtextki=1ρi·/summationtextki=1piE[S2 i] 2/summationtextki=1piE[Si]=λ/summationtextki=1piE[S2 i] 2(1−/summationtextki=1ρi)=/summationtextki=1ρiE[S2 i] 2E[Si] 1−/summationtextki=1ρi. So, ﬁnally, adding (1) and (2) and (3), we have E[T(k)]P-Priority=E[Sk]+/summationtextki=1ρiE[S2 i] 2E[Si] 1−/summationtextki=1ρi+E[T(k)]k−1/summationdisplay i=1ρi E[T(k)]/parenleftBigg 1−k−1/summationdisplay i=1ρi/parenrightBigg =E[Sk]+/summationtextki=1ρiE[S2 i] 2E[Si] 1−/summationtextki=1ρi E[T(k)]P-Priority=E[Sk] 1−/summationtextk−1 i=1ρi+/summationtextki=1ρiE[S2 i] 2E[Si] (1−/summationtextk−1 i=1ρi)(1−/summationtextki=1ρi).(32.1) Interpretation of E[T(k)]P-Priority We now look for a way to interpret ( 32.1). For preemptive service disciplines, one can view the time in system of a job as divided into two components: 1.the time until the job ﬁrst starts serving (also called waiting time ), denoted by Wait 2.the time from when the job ﬁrst receives some service, until it leaves the system (also called residence time ), denoted by Res Question: Is residence time the same as service time? Answer: No. The residence time is a lot longer. It includes all interruptions. Question: Consider the expression ( 32.1) for the mean time in system for a job of class kunder preemptive priority queueing.",3095
32.1 Motivation. 32.2 Preemptive Priority Queueing,"What does the ﬁrst term E[Sk] 1−/summationtextk−1 i=1ρi(32.2) represent? Answer: This represents the mean residence time of the job of class k,E[Res(k)].Y o u should recognize this formula as being the expected length of a busy period started by a job of size E[Sk], where the only jobs that are allowed in the busy period (after the ﬁrst job) are those of class 1through k−1. 32.2 preemptive priority queueing 511 Observe that once the job of class kstarts to serve, it can only be interrupted by jobs of class 1through k−1. The time until our job of class kcan leave is thus the length of the busy period created by those interruptions of class 1through k−1. Question: Now explain the second term in ( 32.1). Answer: By deﬁnition, the remaining term in ( 32.1)i s E[Wait(k) ]=/summationtextk i=1ρiE[S2 i] 2E[Si]/parenleftBig 1−/summationtextk−1 i=1ρi/parenrightBig/parenleftBig 1−/summationtextk i=1ρi/parenrightBig, representing the mean time until the job of priority kﬁrst receives service. Note that this term is almost identical to E[TQ(k)]for the non-preemptive priority queue ( 31.1), except that the numerator (corresponding to excess of the job in service) now represents only excess due to jobs of class 1through k.1This is clear, because a job in service of class greater than kwill just be immediately preempted. It is sometimes convenient to rewrite ( 32.1)a s E[T(k)]P-Priority=E[Sk] 1−/summationtextk−1 i=1ρi+λ 2/summationtextk i=1piE[S2 i] (1−/summationtextk−1 i=1ρi)(1−/summationtextki=1ρi).(32.3) Question: Recall that in the case of non-preemptive priority and SJF, we found that a high priority job (or a “small” job in SJF) does not necessarily obtain good performance because it still has to combat the variability in the job size distribution. Is that the casehere as well? Answer: No. Observe that both terms in E[T(k)]P-Prioritydepend only on the ﬁrst k priority classes, as we would expect, as compared with the non-preemptive priority system. This means that a high priority (low k) job in preemptive priority queueing really does win, even in a high-variability job size distribution, because it only sees the variability 1In the non-preemptive case, we had E/bracketleftbig TQ(k)/bracketrightbigNP-Priority=ρE[S2] 2E[S]/parenleftBig 1−/summationtextk i=1ρi/parenrightBig/parenleftBig 1−/summationtextk−1 i=1ρi/parenrightBig. The denominator of this expression is equal to that for the preemptive priority queue. The numerator of this expression can be viewed as ρE/bracketleftbig S2/bracketrightbig 2E[S]=λ 2E/bracketleftbig S2/bracketrightbig =λ 2n/summationdisplay i=1piE/bracketleftbig S2 i/bracketrightbig =n/summationdisplay i=1λi·E/bracketleftbig S2 i/bracketrightbig 2=n/summationdisplay i=1ρi/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright ↑ Probability there is a job in service of class i·Expected excess for job in service of class i/bracehtipdownleft/bracehtipupright/bracehtipupleft/bracehtipdownright E/bracketleftbig S2 i/bracketrightbig 2E[Si]. Thus for the non-preemptive priority queue, all nclasses (rather than just kclasses) contribute to the excess.",3125
32.3 Preemptive-Shortest-Job-First PSJF,"512 scheduling: preemptive, size-based policies created by the ﬁrst kclasses and not the variability of the entire distribution. Also, it sees only the load created by the ﬁrst kclasses and not the entire system load (this latter property is also true for non-preemptive priority and SJF). 32.3 Preemptive-Shortest-Job-First (PSJF) The PSJF policy is deﬁned similarly to the SJF (Shortest-Job-First) policy, except that the size-based priorities are enforced preemptively. Thus at any moment in time, thejob in service is the job with the smallest original size. A preemption only occurs when a new job arrives whose size is smaller than the original size of the job in service. Question: How can we analyze the mean response time of PSJF? Answer: There are two approaches. We cover both here. The ﬁrst approach is to make use of our results for scheduling with preemptive priority classes, where we assume that a job’s class is its size, and we take the limit as thenumber of classes goes to inﬁnity. Starting with the preemptive priority response timefor class k,(32.3), E[T(k)]P-Priority=E[Sk] 1−/summationtextk−1 i=1ρi+λ 2/summationtextk i=1piE[S2 i] (1−/summationtextk−1 i=1ρi)(1−/summationtextki=1ρi), and performing the same limiting operations as we did in analyzing SJF (where we imagine that jobs of size xform one “class” and that there are an inﬁnite number of classes), we have E[T(x)]PSJF=x 1−ρx+λ 2/integraltextx 0f(t)t2dt (1−ρx)2, (32.4) where f(t)is the p.d.f. of job size, S, andρx=λ/integraltextx 0tf(t)dtis deﬁned to be the load made up by jobs of size less than x, see ( 31.4). Now let’s pretend that we did not have a preemptive priority class formula and look at how we could have derived the mean response time for PSJF from scratch. We start by breaking up response time into waiting time and residence time: E[T(x)]PSJF=E[Wait(x) ]PSJF+E[Res(x)]PSJF Here Wait(x) represents the time until job xreceives its ﬁrst bit of service, and Res(x) represents the time from when job xreceives its ﬁrst bit of service until it is complete. Question: What is E[Res(x)]PSJF? Answer: Res(x) is just the duration of a busy period started by a job of size x, where the only jobs that make up this busy period are jobs of size ≤x. Thus E[Res(x)]PSJF=x 1−ρx. Question: Can we also think of E[Wait(x) ]PSJFas a busy period duration? 32.3 preemptive-shortest-job-first (psjf) 513 Answer: Yes. When a job of size xwalks in, it sees some work. However, not all the work that it sees is relevant to it. The only relevant work is that made up by jobs of (original) size ≤x. Let’s call that work Wx.N o w , Wait(x) can be viewed as the length of a busy period started by a phantom job of size Wx, where the only jobs that make up this busy period are jobs of size ≤x. x x Figure 32.1. Transformer glasses for PSJF. Whereas in FB, the transformer glasses truncate all jobs of size >x to size x, in PSJF, the transformer glasses make jobs of size >x invisible. Question: What is E[Wx]PSJF? Answer: This is the work in the system as seen when job xputs on transformer glasses that make anyone whose (original) size is greater than xinvisible (see Fig. 32.1). But given that the policy is PSJF (so jobs of size ≤xare always worked on before jobs of size >x), we see that this is the same as the amount of work under PSJF, where the only jobs allowed into the system are jobs of size ≤x. However, because PSJF is work-conserving, this is the same as the amount of work in an FCFS system where the only jobs in the system are jobs of size ≤x. But that work is the same as the time-in-queue in an FCFS system where the only jobs in the system are jobs of size ≤x. We will use the random variable Sxto denote the size of a job of size ≤x. The density ofSxisf(t) F(x)where f(t)is the density of S. So, E[Wait(x) ]PSJF=E[Wx] 1−ρx(mean length of busy period ) =E[TQ|where job sizes are Sx] 1−ρxFCFS =λF(x)E[S2 x] 2(1−ρx) 1−ρx",3915
32.4 Transform Analysis of PSJF,"514 scheduling: preemptive, size-based policies =λF(x)/integraltextx 0t2f(t) F(x)dt 2(1−ρx)2 =λ/integraltextx 0t2f(t)dt 2(1−ρx)2. (32.5) Thus E[T(x)]PSJF=x 1−ρx+λ/integraltextx 0t2f(t)dt 2(1−ρx)2, just like ( 32.4). 32.4 Transform Analysis of PSJF We now derive the Laplace transform of the response time of the M/G/1/PSJF queue. Before reading this, it is helpful to review Section 27.2. Let T=Response time . T(x)=Response time for a job of size x. Given the Laplace transform of T(x), we can get the transform for Tby conditioning on job size as follows: /tildewideT(s)=/integraldisplay x/tildewideT(x)(s)f(x)dx. Thus we only need to determine /tildewideT(x)(s): /tildewideT(x)(s)=/tildewiderWait(x) (s)·/tildewiderRes(x)(s), (32.6) where Wait(x) denotes the waiting time of a job of size xandRes(x) denotes the residence time of a job of size x. Both these quantities will be analyzed in terms of busy periods. We need the following notation: λx=λF(x)=arrival rate of jobs of size ≤x Sx=arbitrary size of a job whose size is ≤x Note:E[Sx]=/integraldisplayx 0tf(t) F(x)dt ρx=λxE[Sx]=λ/integraldisplayx 0tf(t)dt=load made up of jobs of size ≤x Wx=work in system made up of jobs of size ≤x Bx=duration of busy period of jobs of size ≤xonly Ax y=number of arrivals of size ≤xduring time y 32.4 transform analysis of psjf 515 Question: Pop Quiz: What is /tildewiderBx(s)? Answer: /tildewiderBx(s)=/tildewiderSx/parenleftBig s+λx−λx/tildewiderBx(s)/parenrightBig . We are now ready to describe /tildewiderWait(x) (s)and/tildewiderRes(x)(s). Res(x) =duration of a busy period started by a job of size xmade up by arrivals of size≤x Question: Is/tildewiderRes(x)(s)=/tildewiderBx(s)? Answer: No. Both BxandRes(x) are busy periods composed of jobs of size ≤x. However, the starting job in Bxis any job of size ≤x, whereas Res(x) must start with a job of size exactly x. Res(x) =x+Ax x/summationdisplay i=1B(i) x(B(i) xis theith busy period ) /tildewiderRes(x)(s)=e−sx·/hatwiderAx x(/tildewiderBx(s)) =e−sx·e−(λx)x(1−/tildewiderBx(s)) =e−x(s+λx−λx/tildewiderBx(s))(32.7) Now we move on to Wait(x) . Wait(x) =duration of a busy period started by Wx, where the only arrivals are of size≤x /tildewiderWait(x) (s)=/tildewiderWx/parenleftBig s+λx−λx/tildewiderBx(s)/parenrightBig (32.8) Question: What do we know about /tildewiderWx(s)? Answer: Wx=work in PSJF system made up by jobs of size ≤x =work in PSJF system if there only existed those jobs of size ≤xand no others =work in FCFS system if there only existed jobs of size ≤xand no others =queueing time in FCFS system where there are only jobs of size ≤x Hence, from ( 26.13 ), using Sx,λx, andρx,w eh a v e /tildewiderWx(s)=(1−ρx)s λx/tildewiderSx(s)−λx+s. (32.9)",2710
32.5 Exercises,"516 scheduling: preemptive, size-based policies Combining equations ( 32.9), (32.8), (32.7), and ( 32.6), we have the Laplace transform of response time for jobs of size xunder PSJF: /tildewideT(x)PSJF (s)=/tildewiderWait(x) (s)·/tildewiderRes(x)(s) =/tildewiderWx/parenleftBig s+λx−λx/tildewiderBx(s)/parenrightBig ·e−x(s+λx−λx/tildewiderBx(s)) =(1−ρx)/parenleftBig s+λx−λx/tildewiderBx(s)/parenrightBig ·e−x(s+λx−λx/tildewiderBx(s)) λx/tildewiderSx/parenleftBig s+λx−λx/tildewiderBx(s)/parenrightBig −λx+/parenleftBig s+λx−λx/tildewiderBx(s)/parenrightBig 32.5 Exercises 32.1 Warmup: Preemptive Priority Queue Consider an M/M/1 with npreemptive priority classes, where class ijobs arrive with rate λi. Assume that all job sizes are Exponentially distributed with mean1. Use the formulas in this chapter to derive a very simple expression for the mean response time of the kth class. 32.2 The cμ-Rule (Contributed by Urtzi Ayesta) Suppose you have a single-server queue with n classes of jobs and Exponential service times. Class ijobs arrive with some average rate λiand have mean service time1 μi. Assume that there is a holding cost,ci, associated with class i, meaning that a class ijob incurs a cost of ci dollars for every second that it spends in the system. Let E[Nπ i]denote the mean number of jobs of class iunder some scheduling policy π. LetE[Wπ i] denote the mean total work of all class ijobs in the system under scheduling policy π. LetCost(π)=/summationtextn i=1ciE[Nπ i]denote the mean operational cost under policy π;E[Nπ]denote the mean number of jobs in the system under policy π; andE[Tπ]denote the mean response time under policy π. Without loss of generality, assume that c1μ1>c2μ2>···>cnμn Letcμdenote the policy that gives preemptive priority to jobs in order of their class (class 1has priority over class 2, which has priority over class 3, etc.), i.e., the class with the highest product of c·μgets highest priority. Observe that it makes sense to give these jobs priority because they either have a high holding cost, or are small, or both. Thecμ-Rule states that the cμpolicy is optimal for minimizing Cost(π), over all policies π, where we limit ourselves to policies that do not know the exact sizes of jobs, only the mean size for that class. This exercise will lead you through a very simple proof of the cμ-Rule. The key idea in the proof is to ﬁrst show that the cμpolicy minimizes a certain sum of work and then to translate the work result into a result about Cost(π). (a) If we set all the costs to be the same, i.e., ci=c,∀i, what does the cμ-Rule say about mean response time? 32.5 exercises 517 (b) Explain via sample-path arguments why the following work sum inequality holds for all policies π: j/summationdisplay i=1E[Wcμ i]≤j/summationdisplay i=1E[Wπ i]∀j (32.10) (c) Prove the following simple identity, where the ai’s and bi’s are constants andan+1=0: n/summationdisplay i=1aibi=n/summationdisplay i=1(ai−ai+1)i/summationdisplay j=1bj (32.11) (d) Prove that Cost(cμ)=n/summationdisplay i=1ciE[Ncμ i]≤n/summationdisplay i=1ciE[Nπ i]=Cost(π) for all policies π. To do this, you will need to ﬁrst translate E[Ni]into E[Wi], by observing that E[Wπ i]=E[Nπ i]·1 μ(why?? ) Then apply both ( 32.11 ) and ( 32.10 ) to produce the result.",3278
Chapter 33 Scheduling SRPT and Fairness. 33.1 Shortest-Remaining-Processing-Time SRPT,"CHAPTER 33 Scheduling: SRPT and Fairness In this chapter, we introduce Shortest-Remaining-Processing-Time (SRPT) scheduling. SRPT is even superior to the PSJF policy that we saw in the last chapter, because ittakes a job’s remaining service requirement into account, not just the original job size . We also compare all the scheduling policies that we have studied so far with respect to mean response time as a function of load and the variability of the job size distribution.Finally, we study the fairness of SRPT by comparing it to the (fair) PS policy and proving the All-Can-Win theorem. 33.1 Shortest-Remaining-Processing-Time (SRPT) Under SRPT, at all times the server is working on that job with the shortest re- maining processing time. The SRPT policy is preemptive so that a new arrival willpreempt the current job serving if the new arrival has a shorter remaining processing time. Observe that, under SRPT, once a job, j, starts running, it can only be preempted by a new arrival whose size is shorter than j’s remaining time. In particular, any jobs that are in the system with j, while jis running, will never run before j completes.Remember that in Exercise 2.3we proved that SRPT achieves the lowest possible mean response time on every arrival sequence. In this section, we analyze the mean response time for SRPT in the M/G/1 setting. Question: Can we look at SRPT as some type of preemptive priority system with classes? Answer: No.The problem is that in SRPT a job’s priority is its “remaining” size, which changes as the job ages. The preemptive priority model does not allow jobs to change priorities while in queue. It turns out that the response time analysis of SRPT is somewhat involved. The proof is outlined in two different ways in the Schrage and Miller paper from 1966 [ 160]. In this section we give another sketch of the proof of response time for SRPT. This sketch may feel precise, but it is missing a few details. In Section 33.2, we ﬁll in these missing details. 518 33.1 shortest-remaining-processing-time (srpt) 519 We start by looking at the ﬁnal result and then try to understand where each term comes from: E[T(x)]SRPT=E/bracketleftBiggTime until job of size xﬁrst receives service (waiting time)/bracketrightBigg +E/bracketleftBiggTime from when job ﬁrst receives service until it is done (residence time)/bracketrightBigg =E[Wait(x) ]+E[Res(x)] =λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2+/integraldisplayx t=0dt 1−ρt, where ρx=λ/integraltextx 0tf(t)dtas in ( 31.4). Understanding the Residence Time Recall that the term representing mean residence time for the preemptive priority queue for a job of class kwas E[Sk] 1−/summationtextk−1 i=1ρi. This term represents the job size, slowed down by the load of all jobs of higher priority than itself. If we just tried to translate this directly to the continuous case we would have the mean residence time for a job of size xunder PSJF; namely, E[Res(x)]PSJF=x 1−ρx, which represents a busy period started by a job of size x(“jobx”) and consisting of only jobs of size ≤x. By contrast, in SRPT, a job of size xhas mean residence time /integraldisplayx t=0dt 1−ρt. To understand this expression, ﬁrst observe that in SRPT, a job’s “priority” increases as it ages. Thus the factor by which the job is slowed down, once it has started service,should depend on its remaining service requirement, t, and should be related to the load of all jobs of size less than t. Now think of the job of size xas broken intox dt pieces of size dteach. The job starts out with remaining time xand slowly receives service. Consider the time required for the job to move from having t+dtremaining service time to tremaining service time. This is a busy period, started by dtwork, where only jobs of size <tare included in the busy period, because they are the ones that have priority over our job. The length of such a busy period is exactlydt 1−ρt. The ﬁrst busy period, needed for the job to decrease from remaining size xto remaining size(x−dt), takes a long time, because almost every job counts in the busy period. 520 scheduling: srpt and fairness However the later busy periods, needed for the job to decrease from say x/2to (x/2−dt), go a lot faster, because only smaller jobs count. The residence time of job xis just the sum (integration) of all these busy periods. Understanding the Waiting Time Let’s now think about the intuition behind the expression for waiting time: E[Wait(x) ]=λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2 Question: If you ignore the second term in the numerator, what does this expression remind you of? Answer: Ignoring the second term in the numerator, we have exactly the mean waiting time from the M/G/1/PSJF; see ( 32.5). Recall that the mean waiting time from the M/G/1/PSJF is the duration of a busy period, started by Wx, the total remaining work in the system from jobs of size ≤x, and made up of all new arrivals of size ≤xthat occur during Wx. (Recall that E[Wx]PSJF=λ 2/integraltextx t=0t2f(t)dt 1−ρxand that E[Wait(x) ]PSJF= E[Wx]PSJF 1−ρx.) The mean waiting time for SRPT also looks like such a busy period; however, the work starting the busy period includes an extra term: λ 2x2F(x) Question: What is this extra term? Why does it occur? Answer: It looks like all jobs of original size >x (the jobs that occur with probability F(x)) are contributing x2to the SRPT expression. To understand this, observe that in PSJF only jobs of size <x can contribute to job x’s waiting time. By contrast, in SRPT alljobs contribute to job x’s waiting time. However, the big jobs only contribute at most xto job x’s waiting time, because job xonly sees the big jobs once their remaining time is reduced to x. Question: Does the numerator of E[Wait(x) ]SRPTremind you of another distribution we have seen? Answer: Yes, it is like the Sxjob size, which we used for FB scheduling, where jobs of size >x are transformed into jobs of size x; see Section 30.3. In SRPT, the numerator in the waiting time expression isλ 2E[S2 x], as in FB; see ( 30.6). However, the denominator of the SRPT expression involves ρxas in PSJF, not ρxas in FB, because only jobs of size ≤xare allowed to enter the busy period.",6221
33.2 Precise Derivation of SRPT Waiting Time,"33.2 precise derivation of srpt waiting time 521 In fact, SRPT is related to both FB and to PSJF. The exact relationship will become clearer in the next section. 33.2 Precise Derivation of SRPT Waiting Time∗ Section 33.1 provided a proof sketch for response time of SRPT. The derivation of Res(x) was precise. We now make the derivation of Wait(x) precise as well. LetWSRPT x denote the work that an arrival of size xﬁnds in the system that is “relevant” to itself (i.e., work in the system that will run before the arrival of size xgets to start running). Then Wait(x) is simply a busy period started by WSRPT x, where the only jobs allowed to enter are those of size ≤x. Hence, E[Wait(x) ]SRPT=E[WSRPT x] 1−ρx. (33.1) We spend the rest of the section analyzing E[WSRPT x].WSRPT x is composed of two types of jobs: Type a: These are jobs that job xﬁnds in the system of (original) size ≤x. Type b: These are jobs that job xﬁnds in the system of (original) size >x that now have remaining size ≤x. If all we had to worry about was work made up of type ajobs, this would be an easy problem. The work made up of type ajobs is the same as WPSJF x. Unfortunately, we also have type bjobs. Question: How many jobs can there be of type b? Answer: There can be at most one job of type b. Furthermore, no more type b’s will enter the system until job xhas left the system entirely. The difﬁculty in analyzing the work made up of type aandbjobs lies in the strangeness of the type bjobs. From the perspective of job x, jobs of type bappear at the server, having size x, according to some non-Poisson process, where there can only be at most one type bjob in the system at a time. The fact that there can only be one type bjob is particularly at odds with respect to all the analysis techniques we have used so far. To determine the total work in the system made up of type aand type bjobs, we use the following trick: We imagine that our queueing system is broken into two pieces, thequeue part and the server part . Note that by deﬁnition there can only be one job of either type in the server at a time. We imagine type bjobs as arriving directly into the server, whereas all other jobs arrive at the queue. We also imagine type bjobs as always having priority over type ajobs, so that they never leave the server once they are in there. That is, they always run to completion. Making type bjobs have priority over type ajobs does not change the amount of work in the system, but it does allow us to ensure that type b’s never enter the queue part . ∗Warning: This is a difﬁcult section and can be skipped. 522 scheduling: srpt and fairness Thus we can think of the queue part as a system made up of only type ajobs and theserver part as consisting of jobs from distribution Sxfrom the FB analysis (this includes both the type ajobs and the type bjobs). We call this system of a’s and b’s “system X.” Our goal is to understand the work in system X. This work is the same as the delay experienced ( TQ) by an arrival of type ainto system X, if we now pretend that all arrivals of type aare of equal priority with respect to each other and hence are served FCFS. We now use a tagged-job argument to determine the mean delay for a type aarrival into system X. Note that we cannot simply pretend that system Xis a regular FCFS queue, because type bjobs only enter the server. Hence we cannot just apply the P-K formula, and we instead need to do the tagged-job analysis from scratch. A type aarrival to system Xwill see some number of jobs in the queue, NQ. These will all be of type a. Hence their size can be represented by Sx, which denotes the job size for jobs of size ≤xonly. The probability that a type aarrival sees a job in service is ρx, where ρx=λE[Sx](as in the FB policy). To understand why this is so, we think about the server as a separate system and look at it from a Renewal-Reward perspective. It is important to note that every single job eventually enters the server. However, the jobs of size >x that enter the server enter it as being size x. Thus, the job size distribution of jobs entering the server is Sx, and the fraction of time that the server is busy is ρx. Going back to our type aarrival, that (Poisson) arrival sees time-average behavior; namely, with probability ρxit sees a busy server, and the expected remaining service time of the job serving is the expected excess of Sx. Putting these together we have E[TQ]=E[NQ]·E[Sx]+ρxE[Excess of Sx] =E[TQ]λF(x)·E[Sx]+ρx·E[Excess of Sx] =E[TQ]ρx+ρx·E[Excess of Sx] =ρxE[Excess of Sx] 1−ρx =ρx 1−ρx·E[S2 x] 2E[Sx] =λE[Sx] 1−ρx·E[S2 x] 2E[Sx] =λ 1−ρx·E[S2 x] 2 =λ 2·/integraltextx 0t2f(t)dt+F(x)·x2 1−ρx.",4670
33.3 Comparisons with Other Policies,"33.3 comparisons with other policies 523 This expression for E[TQ]represents WSRPT x. Hence, returning to ( 33.1), we have E[Wait(x) ]SRPT=E[WSRPT x] 1−ρx=λ 2·/integraltextx 0t2f(t)dt+F(x)·x2 (1−ρx)2 as desired. 33.3 Comparisons with Other Policies Let’s return to the formula for SRPT response time: E[T(x)]SRPT=λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2+/integraldisplayx t=0dt 1−ρt.(33.2) We can make several immediate observations. First, observe that the response time for a job of size xis not inﬂuenced by the variance of the entire job size distribution, but rather just by the variance of the distribution up to size x.E[T(x)]is also not inﬂuenced by the entire load, but rather just by the load made up of jobs of size ≤x. Also, once our job of size xstarts receiving service, the only inﬂuencing factor is the load made up of jobs of size less than the current remaining service time of our job. This explains why small jobs (small size x) do so well under SRPT. 33.3.1 Comparison with PSJF It’s clear that the waiting time for SRPT is greater than that for PSJF because of the extrax2term in the numerator. In contrast, the residence time for SRPT is clearly better than that for PSJF, because a job only has to wait for those jobs smaller than its current remaining service requirement under SRPT, whereas it has to wait behind all jobs smaller than its original size in PSJF. Compare ( 32.4) with ( 33.2) and imagine integrating over all x. It turns out that this beneﬁt in E[Res(x)]makes SRPT superior to PSJF with respect to overall mean response time, E[T], where E[T]is the weighted integral of E[T(x)]over all x. 33.3.2 SRPT versus FB Without looking at the formulas, it might not seem obvious how SRPT and FB compare. SRPT and FB are in a sense complements. In SRPT, a job gains priority as it receivesmore service. Its response time can be thought of as a snowball rolling downhill, which at ﬁrst rolls slowly, but gains momentum and moves faster and faster. In FB, the reverse is true. A job has highest priority when it ﬁrst enters. As time goes on, itloses priority. One might imagine that the performance of SRPT and FB are somehowrelated. Lemma 33.1 shows that, on every job size x, SRPT beats FB. Lemma 33.1 In an M/G/1, for all xand for all ρ, E[T(x)]SRPT≤E[T(x)]FB. 524 scheduling: srpt and fairness Proof The proof follows from the fact that both the mean residence time and the mean waiting time are lower under SRPT as compared with FB. In the case of mean waiting time, SRPT and FB have the same numerator, but FB has a (1−ρx)2term in the denominator, as compared to (1−ρx)2in SRPT, where ρx>ρx. E[T(x)]FB=x(1−ρx)+1 2λE/bracketleftbig Sx2/bracketrightbig (1−ρx)2 =x 1−ρx+1 2λ/parenleftbig/integraltextx 0y2f(y)dy+x2F(x)/parenrightbig (1−ρx)2 ≥x 1−ρx+1 2λ/parenleftbig/integraltextx 0y2f(y)dy+x2F(x)/parenrightbig (1−ρx)2 ≥/integraldisplayx t=0dt 1−ρt+1 2λ/integraltextx 0y2f(y)dy+1 2λx2F(x) (1−ρx)2 =E[T(x)]SRPT 33.3.3 Comparison of All Scheduling Policies At this point we have derived at least E[T(x)]for all scheduling policies. However, it is not obvious just from looking at these formulas how these policies compare with respect to overall mean response time, E[T]– most of us are not born doing triple nested integrals in our heads :-). To facilitate understanding, we have evaluated all the formulas for E[T]using Math- ematica for the different policies. Mean response time as a function of load is given in Figure 33.1, and mean response time as a function of C2is given in Figure 33.2. In both ﬁgures, we have used a Weibull job size distribution. The Weibull, deﬁned by E[T] ρ5 4 3 2 0.2 0.4 0 0.8 0.6 1.016789FCFS SJF PS = PLCFSSRPTFB PSJFFCFS SJF PS = PLCFS SRPTFB PSJF Figure 33.1. Mean response time as a function of load for the M/G/1 with various scheduling policies. The job size distribution is a Weibull with mean 1andC2=1 0 .",3889
33.4 Fairness of SRPT,"33.4 fairness of srpt 525 FCFS SJF PS = PLCFS SRPTPSJFFBE[T] C25 4 3 2 0.2 0.4 0 0.8 0.6 1.016789 FCFS SJF PS = PLCFS SRPTFB PSJF Figure 33.2. Mean response time as a function of variability ( C2) for the M/G/1 with various scheduling policies. Load is ﬁxed at ρ=0.7. The job size distribution is a Weibull with ﬁxed mean1and changing C2. F(x)=e−(x λ)α with parameters λandα>0, is convenient because when α<1,i t has decreasing failure rate (DFR) and C2can be made as high as desired. Looking at Figure 33.1, we see that the policies are ordered as we would expect. Knowing the size helps. Being able to preempt jobs helps even more. Question: The SJF policy is not so great for low loads (due to the high C2). However, it suddenly starts looking a lot better, comparatively, under high loads, even beating PS. Why is this? Answer: There is a 1−ρxterm in the denominator of E[TQ(x)]SJF, as compared with a1−ρterm in the denominator of E[T(x)]PS. That helps SJF a lot under high load. Looking at Figure 33.2, we see that under high C2, the policies are ranked as expected. Question: Why is the line for PS =PLCFS ﬂat? Answer: These policies are invariant to the variability of the job size distribution. Question: Why do policies like FB look worse for low C2? Answer: FB needs DFR to perform well, and higher DFR is coupled with higher C2. 33.4 Fairness of SRPT Although the SRPT scheduling policy is optimal with respect to mean response time and has a comparatively low second moment as well, it is rarely used for schedulingjobs. Consider for example a typical web server. 526 scheduling: srpt and fairness Question: Which scheduling policy best represents scheduling in a web server? Answer: PS. The server time-shares between HTTP requests. Both the CPU and the outgoing bandwidth are scheduled in round-robin order, approximating Processor- Sharing. This seems suboptimal, because the mean response time for PS is clearly far higher than that for SRPT. One might wonder whether there are other issues in applying SRPT. A possible objection to using SRPT is that the job size is not always known. However, for web servers serving static (GET File) requests, the sizes of these ﬁles are known by the server and accurately represent the job service requirement. Implementationof SRPT scheduling for web servers is also easy, it turns out. In [ 92,162], SRPT scheduling is implemented for an Apache web server running on Linux by modifying the Linux kernel to schedule outgoing bandwidth so as to favor HTTP requests with small remaining ﬁle size. Question: So what is the problem with using SRPT? Answer: The problem is that people deeply fear that SRPT will cause long jobs to “starve.” Now clearly, when ρ<1, no job actually starves, because every busy period is ﬁnite, so every job will eventually get to run. When people talk about “starvation,” they are really talking about jobs doing worse under SRPT than they would under a fairpolicy like PS. By fairwe mean a policy that affords every job the same expected slowdown, regardless of its size. Question: Consider the question illustrated in Figure 33.3. An M/G/1 queue is shown, where the job size distribution is a Bounded Pareto ( k= 332 ,p=1 010,α=1.1). Mr. Max size1010f(x) x 332 1010 Question: Which q ueue  does Mr. Max  prefer ? (Ass ume ρ = 0.9)PS SRPT? ?Bounded Pareto (332,1010,α = 1.1)  Figure 33.3. Which policy is best for the largest job: SRPT or PS? 33.4 fairness of srpt 527 The load is ρ=0.9. Consider now the very biggest job in the job size distribution (we call him, Mr. Max). Mr. Max is a job of size x=1 010. The question is whether Mr. Max prefers to go to an M/G/1/PS queue, or an M/G/1/SRPT queue. That is, is E[T(1010)]lower under PS scheduling or under SRPT scheduling? Discussion: Clearly small jobs should favor SRPT. By contrast, large jobs have the lowest priority under SRPT, but they get treated like equal citizens under PS, where they time-share equally with all other jobs. It therefore seems much better for Mr. Maxto go to the PS queue, where he will be treated as an equal citizen. That is, it seems that E[T(1010)]PSshould be far lower than E[T(1010)]SRPT. Answer: This intuition turns out to be wrong. In fact, for the same M/G/1 setup as in Figure 33.3, we produced Table 33.1 via MathematicaTM. As seen in Table 33.1, not only does the largest job prefer SRPT to PS, but almost all jobs (99.9999 percent ) prefer SRPT to PS by more than a factor of 2. In fact 99 percent of jobs prefer SRPT to PS by more than a factor of 5. Table 33.1. E[Slowdown( x)]under SRPT and under PS for increasing x Expected slowdown Expected slowdown Percentile of job size distribution under SRPT under PS 90 percent-tile 1.28 10 99 percent-tile 1.62 1099.99 percent-tile 2.69 10 99.9999 percent-tile 4.73 10 99.999999 percent-tile 8.50 1099.99999999 percent-tile 9.53 10100 percent-tile (Mr. Max) 9.54 10 But how can this be? Can every job really do better in expectation under SRPT than under PS? The answer is YES, and not just for the Bounded Pareto job size distribution. Theorem 33.2 (All-Can-Win [ 12])Given an M/G/1, if ρ<1 2, then,∀x, E[T(x)]SRPT≤E[T(x)]PS. The All-Can-Win theorem says that every single job (every x) prefers SRPT to PS in expectation, assuming ρ<1 2. Remarkably, the All-Can-Win theorem holds for all job size distributions G.F o rm a n y G, the restriction on ρis much looser. In fact, for the Bounded Pareto distribution with α=1.1, shown in Figure 33.3, the All-Can-Win theorem holds whenever ρ<0.96. Question: Do you have any intuition for whythe All-Can-Win theorem should hold? Answer: Here is the intuition. First realize that, although it seems that large jobs are ignored under SRPT, this is only the case until the large job gets some service. Once a large job starts to get some service, it gains priority over other jobs. In the end, even thelargest job will have a period where it has highest priority. Now imagine that load is 528 scheduling: srpt and fairness light. Then it seems plausible that the E[Wait(x) ]component of SRPT is low, because an incoming job often ﬁnds the system empty. In this case, the E[Res(x)]component could be a major part of a job’s response time under SRPT. Now compare with PS.PS has no Wait(x) component, only a Res(x) . However, the Res(x) component for PS is clearly way higher than that for SRPT. Thus, it seems plausible that under light loadconditions even a job of large size xcould do worse under PS than under SRPT. Here is the formal proof: Proof (All-Can-Win) E[T(x)]SRPT≤E[T(x)]PS /arrowdblbothv λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2+/integraldisplayx t=0dt 1−ρt≤x 1−ρ /arrowdblbothv λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2≤x 1−ρ−/integraldisplayx t=0dt 1−ρt /arrowdblbothv λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2≤/integraldisplayx t=0dt 1−ρ−/integraldisplayx t=0dt 1−ρt /arrowdblbothv λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2≤/integraldisplayx t=0ρ−ρt (1−ρ)(1−ρt)dt Now, because /integraldisplayx t=0ρ−ρt (1−ρ)(1−ρt)dt >/integraldisplayx t=0ρ−ρt (1−ρ)dt, it sufﬁces to show that λ 2/integraltextx t=0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2≤/integraldisplayx t=0ρ−ρt (1−ρ)dt. Before showing this, we observe, using integration-by-parts, that /integraldisplayx t=0ρ−ρt (1−ρ)dt=1 1−ρ/parenleftbigg (ρ−ρt)t/vextendsingle/vextendsinglet=x t=0+/integraldisplayx 0tρ/prime tdt/parenrightbigg =(ρ−ρx)x 1−ρ+λ/integraltextx 0t2f(t)dt 1−ρ. So it sufﬁces to show that λ 2/integraltextx 0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2≤(ρ−ρx)x 1−ρ+λ/integraltextx 0t2f(t)dt 1−ρ.",7555
33.5 Readings,"33.5 readings 529 We further observe that x(ρ−ρx)=λx/integraldisplay∞ xtf(t)dt > λx2(1−F(x)). Thus it sufﬁces to show that λ 2/integraltextx 0t2f(t)dt+λ 2x2(1−F(x)) (1−ρx)2≤λx2(1−F(x)) 1−ρ+λ/integraltextx 0t2f(t)dt 1−ρ. From the above expression, it sufﬁces to show that 2(1−ρx)2>1−ρ. Because ρ>ρ x, it sufﬁces to show that 2(1−ρx)2>1−ρx. Dividing both sides by 1−ρx, we see that this is clearly true when ρx<1 2, which is true by the theorem assumption that ρ<1 2. We have shown that fairness is counterintuitive. A seemingly “unfair” policy, like SRPT, can outperform a fair policy, like PS, in expectation, on every job size. 33.5 Readings There is a lot of recent work on fairness of scheduling policies. The proof techniquefrom Section 33.2 is illustrated more generally in [ 191]. Many references and further results can be found in the thesis of Adam Wierman [ 188], in [ 190], and in a wonderful book by Hassin and Haviv [ 96].",935
Bibliography,"Bibliography [1] S. Aalto, U. Ayesta, S. Borst, V . Misra, and R. N ´u˜nez Queija. Beyond processor sharing. Performance Evaluation Review , 34(4):36–43, 2007. [2] I.J.B.F. Adan, G.J. van Houtum, and J. van der Wal. Upper and lower bounds for the waiting time in the symmetric shortest queue system. Annals of Operations Research , 48:197–217, 1994. [3] I.J.B.F. Adan, J. Wessels, and W.H.M. Zijm. Analysis of the symmetric shortest queue problem. Stochastic Models , 6:691–713, 1990. [4] I.J.B.F. Adan, J. Wessels, and W.H.M. Zijm. Matrix-geometric analysis of the shortest queue problem with threshold jockeying. Operations Research Letters , 13:107–112, 1993. [5] A.O. Allen. Probability, Statistics, and Queueing Theory with Computer Science Applications . Academic Press, 2nd edition, 1990. [6] E. Altman, U. Ayesta, and B. Prabhu. Load balancing in processor sharing systems. Telecom- munication Systems , 47(1–2):35–48, 2011. [7] E. Arthurs and J.S. Kaufman. Sizing a message store subject to blocking criteria. In Proceedings of the Third International Symposium on Modeling and Performance Evaluation of Computer Systems , pages 547–564, 1979. [8] S. Asmussen. Applied Probability and Queues . Springer-Verlag, 2nd edition, 2003. [9] N. Avrahami and Y . Azar. Minimizing total ﬂow time and total completion time with imme- diate dispatching. In Proceedings of the Annual ACM Symposium on Parallel Algorithms and Architectures (SPAA) , pages 11–18, 2003. [10] E. Bachmat and A. Natanzon. Analysis of the large number of hosts asymptotics of SITA queues. In Workshop on Mathematical Performance Modeling and Analysis (MAMA) , 2012. [11] E. Bachmat and H. Sarfati. Analysis of size interval task assignment policies. Performance Evaluation Review , 36(2):107–109, 2008. [12] N. Bansal and M. Harchol-Balter. Analysis of SRPT scheduling: investigating unfairness. InProceedings of the 2001 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 279–290. Cambridge, MA, June 2001. [13] A. Barak, S. Guday, and R.G. Wheeler. The Mosix Distributed Operating System: Load Bal- ancing for Unix . Springer Verlag, 1993. [14] P. Barford and M.E. Crovella. Generating representative web workloads for network and server performance evaluation. In Proceedings of the 1998 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 151–160, July 1998. [15] L.A. Barroso and U. H ¨olzle. The case for energy-proportional computing. Computer , 40(12):33–37, 2007. [16] F. Baskett, K.M. Chandy, R.R. Muntz, and F. Palacios-Gomez. Open, closed and mixed net- works of queues with different classes of customers. Journal of the ACM , 22:248–260, 1975. [17] S.L. Bell and R.J. Williams. Dynamic scheduling of a system with two parallel servers in heavy trafﬁc with complete resource pooling: asymptotic optimality of a continuous review threshold policy. Annals of Applied Probability , 11(3):608–649, 2001. [18] D. Bertsekas and R. Gallager. Data Networks . Prentice Hall, 1992. [19] D. Bertsimas and D. Nakazato. The distributional Little’s law and its applications.",3107
Bibliography,"Operations Research , 43(2):298–310, 1995. 531 532 bibliography [20] A. Bhandari, A. Scheller-Wolf, and M. Harchol-Balter. An exact and efﬁcient algorithm for the constrained dynamic operator stafﬁng problem for call centers. Management Science , 54(2):339–353, 2008. [21] Big-IP. F5 Products. http://www.f5.com/products/big-ip. [22] D.P. Blinn, T. Henderson, and D. Kotz. Analysis of a wi-ﬁ hotspot network. In International Workshop on Wireless Trafﬁc Measurements and Modeling , pages 1–6, June 2005. [23] G. Bolch, S. Greiner, H. de Meer, and K.S. Trivedi. Queueing Networks and Markov Chains . John Wiley and Sons, 2006. [24] A. Bondi and W. Whitt. The inﬂuence of service-time variability in a closed network of queues. Performance Evaluation , 6(3):219–234, 1986. [25] F. Bonomi. On job assignment for a parallel system of processor sharing queues. IEEE Trans- actions on Computers , 39(7):858–869, 1990. [26] O. Boxma, J. Cohen and N. Huffels. Approximations in the mean waiting time in an M/G/s queueing system. Operations Research , 27:1115–1127, 1979. [27] O.J. Boxma and J.W. Cohen. Boundary Value Problems in Queueing System Analysis .N o r t h Holland, 1983. [28] O.J. Boxma and B. Zwart. Tails in scheduling. Performance Evaluation Review , 34(4):13–20, 2007. [29] M. Bramson. Stability of Queueing Networks . Springer Verlag, 2008. [30] M. Bramson, Y . Lu, and B. Prabhakar. Randomized load balancing with general service time distributions. In Proceedings of the 2010 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems . New York, NY , pages 275–286, June 2010. [31] P. Bratley, B. Fox, and L. Schrage. A Guide to Simulation . Springer-Verlag, 2nd edition, 1983. [32] J. Broberg, Z. Tari, and P. Zeephongsekul. Task assignment with work-conserving migration. Parallel Computing , 32:808–830, 2006. [33] S.L. Brumelle. A generalization of L=λW to moments of queue length and waiting times. Operations Research , 20:1127–1136, 1972. [34] P.J. Burke. The output of a queueing system. Operations Research , 4(6):699–704, 1956. [35] J. P. Buzen. Computational algorithms for closed queueing networks with exponential servers. Communications of the ACM , 16(9):527–531, 1973. [36] V . Cardellini, E. Casalicchio, M. Colajanni, and P.S. Yu. The state of the art in locally distributed web-server systems. ACM Computing Surveys , 34(2):1–49, 2002. [37] J.M. Carlson and J. Doyle. Highly optimized tolerance: a mechanism for power laws in designed systems. Physical Review E , 60:1412–1427, 1999. [38] H. Chen and D.D. Yao. Fundamentals of Queueing Networks . Springer, 2001. [39] H. Chen and M. Frank. State dependent pricing with a queue. IIE Transactions , 33(10): 847– 860, 2001. [40] G.L. Choudhury, K.K. Leung, and W. Whitt. Calculating normalization constants of closed queueing networks by numerically inverting their generating functions. Journal of the ACM , 42(5):935–970, 1995. [41] G. Ciardo, A. Riska, and E. Smirni. Equiload: a load balancing policy for clustered web servers. Performance Evaluation , 46:101–124, 2001. [42] Cisco Systems LocalDirector. http://www.cisco.com/warp/public/cc/pd/cxsr/400/index.shtml.",3160
Bibliography,"[43] J.W. Cohen and O.J. Boxma. Boundary Value Problems in Queueing System Analysis . North- Holland Publishing, 1983. [44] B.W. Conolly. The autostrada queueing problem. Journal of Applied Probability , 21:394–403, 1984. [45] R.W. Conway, W.L. Maxwell, and L.W. Miller. Theory of Scheduling . Addison-Wesley, 1967. bibliography 533 [46] M.E. Crovella, R. Frangioso, and M. Harchol-Balter. Connection scheduling in web servers. InUSENIX Symposium on Internet Technologies and Systems , pages 243–254, Boulder, CO, October 1999. [47] M.E. Crovella and A. Bestavros. Self-similarity in World Wide Web trafﬁc: evidence and possible causes. In Proceedings of the 1996 ACM Sigmetrics International Conference on Measurement and Modeling of Computer Systems , pages 160–169, May 1996. [48] M.E. Crovella, M.S. Taqqu, and A. Bestavros. Heavy-tailed probability distributions in the world wide web. In A Practical Guide To Heavy Tails , chapter 1, pages 1–23. Chapman & Hall, New York, 1998. [49] D. Down and R. Wu. Multi-layered round robin scheduling for parallel servers. Queueing Systems: Theory and Applications , 53(4):177–188, 2006. [50] M. El-Taha and B. Maddah. Allocation of service time in a multiserver system. Management Science , 52(4):623–637, 2006. [51] M. El-Taha and S. Stidham. Sample-Path Analysis of Queueing Systems . Kluwer Academic Publisher, Boston, 1999. [52] A. Ephremides, P. Varaiya, and J. Walrand. A simple dynamic routing problem. IEEE Trans- actions on Automatic Control , 25(4):690–693, 1980. [53] R. Fagin, A. Karlin, J. Kleinberg, P. Raghavan, S. Rajagopalan, R. Rubinfeld, M. Sudan, and A. Tomkins. Random walks with back buttons. Annals of Applied Probability , 11(3):810–862, 2001. [54] M. Faloutsos, P. Faloutsos, and C. Faloutsos. On power-law relationships of the internet topology. In Proceedings of SIGCOMM , pages 251–262, 1999. [55] G. Fayolle and R. Iasnogorodski. Two coupled processors: the reduction to a Riemann-Hilbert problem. Zeitschrift fur Wahrscheinlichkeitstheorie und vervandte Gebiete , 47:325–351, 1979. [56] A. Feldmann and W. Whitt. Fitting mixtures of exponentials to long-tailed distribu- tions to analyze network performance models. Performance Evaluation , 31(8):963–976, 1998. [57] W. Feller. An Introduction to Probability Theory and Its Applications , volume I. John Wiley and Sons, 3rd edition, 1968. [58] W. Feller. An Introduction to Probability Theory and Its Applications , volume II. John Wiley and Sons, 2nd edition, 1971. [59] H. Feng, V . Misra, and D. Rubenstein. Optimal state-free, size-aware dispatching for hetero- geneous M/G-type systems. Performance Evaluation , 62:475–492, 2005. [60] H. Feng, V . Misra, and D. Rubenstein. PBS: A uniﬁed priority-based scheduler. In Proceedings of the 2007 ACM Sigmetrics International Conference on Measurement and Modeling of Computer Systems , pages 203–214, June 2007. [61] L. Flatto and H.P. McKean. Two queues in parallel. Communications on Pure and Applied Mathematics , 30:255–263, 1977. [62] Flushing away Unfairness. The Economist , July 8, 2010. [63] R.D. Foley and D. McDonald. Exact asymptotics of a queueing network with a cross-trained server.",3172
Bibliography,"In Proceedings of INFORMS Annual Meeting , Applied Probability Cluster, October 2003. [64] S. Foss and D. Korshunov. Heavy tails in multi-server queue. Queueing Systems , 52:31–48, 2006. [65] B. Fu, J. Broberg, and Z. Tari. Task assignment strategy for overloaded systems. In Proceedings of the Eighth IEEE International Symposium on Computers and Communications , pages 1119– 1125, 2003. [66] R. G. Gallager. Discrete Stochastic Processes . Kluwer Academic Publishers, 1996. 534 bibliography [67] A. Gandhi, V . Gupta, M. Harchol-Balter, and M. Kozuch. Optimality analysis of energy- peformance trade-off for server farm management. Performance Evaluation , 11:1155–1171, 2010. [68] A. Gandhi, M. Harchol-Balter, and I. Adan. Server farms with setup costs. Performance Evaluation , 67(11):1123–1138, 2010. [69] A. Gandhi, M. Harchol-Balter, R. Das, and C. Lefurgy. Optimal power allocation in server farms. In ACM Sigmetrics 2009 Conference on Measurement and Modeling of Computer Systems , pages 157–168, 2009. [70] S. Ghosh and M. Squillante. Analysis and control of correlated web server queues. Computer Communications , 27(18):1771–1785, 2004. [71] W.C. Gifﬁn. Transform Techniques in Probability Modeling . Academic Press, 1975. [72] J.J. Gordon. The evaluation of normalizing constants in closed queueing networks. Operations Research , 38(5):863–869, 1990. [73] W.K. Grassmann. Transient and steady state results for two parallel queues. Omega , 8:105–112, 1980. [74] L. Green. A queueing system with general use and limited use servers. Operations Research , 33(1):168–182, 1985. [75] D. Gross and C.M. Harris. Fundamentals of Queueing Theory . John Wiley and Sons, 3rd edition, 1998. [76] V . Gupta, J. Dai, M. Harchol-Balter, and B. Zwart. On the inapproximability of M/G/k: why two moments of job size distribution are not enough. Queueing Systems: Theory and Applications , 64(1):5–48, 2010. [77] V . Gupta and M. Harchol-Balter. Self-adaptive admission control policies for resource-sharing systems. In ACM Sigmetrics 2009 Conference on Measurement and Modeling of Computer Systems , pages 311–322, 2009. [78] V . Gupta, M. Harchol-Balter, A. Scheller-Wolf, and U. Yechiali. Fundamental characteristics of queues with ﬂuctuating load. In Proceedings of the 2006 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 203–215, 2006. [79] V . Gupta, M. Harchol-Balter, K. Sigman, and W. Whitt. Analysis of join-the-shortest-queue routing for web server farms. Performance Evaluation 64(9–12):1062–1081, 2007. [80] P.R. Halmos. Measure Theory . Graduate Texts in Mathematics. Springer, 2000. [81] M. Harchol-Balter. Network Analysis without Exponentiality Assumptions . PhD thesis, Univer- sity of California, Berkeley, 1996. [82] M. Harchol-Balter. Task assignment with unknown duration. Journal of the ACM , 49(2):260– 288, 2002. [83] M. Harchol-Balter, M.E. Crovella, and C. Murta. On choosing a task assignment policy for a distributed server system. IEEE Journal of Parallel and Distributed Computing , 59:204–228, 1999. [84] M. Harchol-Balter and A. Downey. Exploiting process lifetime distributions for dynamic load balancing.",3172
Bibliography,"In Proceedings of the 1996 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 13–24, Philadelphia, May 1996. [85] M. Harchol-Balter and A. Downey. Exploiting process lifetime distributions for dynamic load balancing. ACM Transactions on Computer Systems , 15(3):253–285, 1997. [86] M. Harchol-Balter, C. Li, T. Osogami, A. Scheller-Wolf, and M. Squillante. Cycle stealing under immediate dispatch task assignment. In 15th ACM Symposium on Parallel Algorithms and Architectures , pages 274–285, San Diego, June 2003. [87] M. Harchol-Balter, C. Li, T. Osogami, A. Scheller-Wolf, and M. Squillante. Task assignment with cycle stealing under central queue. In 23rd International Conference on Distributed Computing Systems , pages 628–637, Providence, RI, May 2003. bibliography 535 [88] M. Harchol-Balter, T. Osogami, and A. Scheller-Wolf. Robustness of threshold policies in a beneﬁciary-donor model. Performance Evaluation Review , 33(2):36–38, 2005. [89] M. Harchol-Balter, T. Osogami, A. Scheller-Wolf, and A. Wierman. Multi-server queueing systems with multiple priority classes. Queueing Systems: Theory and Applications , 51(3– 4):331–360, 2005. [90] M. Harchol-Balter, A. Scheller-Wolf, and A. Young. Surprising results on task assignment in server farms with high-variability workloads. In ACM Sigmetrics 2009 Conference on Measurement and Modeling of Computer Systems , pages 287–298, 2009. [91] M. Harchol-Balter, A. Scheller-Wolf, and A. Young. Why segregating short jobs from long jobs under high variability is not always a win. In Forty-Seventh Annual Allerton Conference on Communication, Control, and Computing , University of Illinois, Urbana-Champaign, pages 121–127, October 2009. [92] M. Harchol-Balter, B. Schroeder, N. Bansal, and M. Agrawal. Size-based scheduling to improve web performance. ACM Transactions on Computer Systems , 21(2):207–233, 2003. [93] M. Harchol-Balter and R. Vesilo. To balance or unbalance load in size-interval task allocation. Probability in the Engineering and Informational Sciences , 24(2):219–244, 2010. [94] P.G. Harrison. On normalizing constants in queueing networks. Operations Research , 33:464– 468, 1985. [95] P.G. Harrison. Reversed processes, product forms and a non-product form. Linear Algebra and Its Applications , 386:359–381, 2004. [96] R. Hassin and M. Haviv. To Queue or not to Queue . Kluwer Academic Publishers, 2003. [97] P. Hokstad. Approximations for the M/G/m queue. Operations Research , 26(3):510–523, 1978. [98] P. Hokstad. The steady state solution of the M/K 2/mqueue. Advances in Applied Probability , 12(3):799–823, 1980. [99] S. Hotovy, D. Schneider, and T. O’Donnell. Analysis of the early workload on the Cornell Theory Center IBM SP2. Technical Report 96TR234, Cornell Theory Center, January 1996. [100] E. Hyyti ¨a, S. Aalto, and A. Penttinen. Minimizing slowdown in heterogeneous size-aware dispatching systems. In Proceedings of the 2012 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems . London, U.K., pages 29–40, June 2012. [101] E. Hyyti ¨a, J. Virtamo, S.",3104
Bibliography,"Aalto, A. Penttinen. M/M/1-PS queue and size-aware task assignment. Performance Evaluation , 68:1136–1148, 2011. [102] J.R. Jackson. Jobshop-like queueing systems. Management Science , 10(1):131–142, 1963. [103] G. Jain. A Rate Conservation Analysis of Queues and Networks with Work Removal .P h D thesis, Columbia University, IEOR Department, 1996. [104] R. Jain. The Art of Computer Systems Performance Analysis . John Wiley and Sons, 1991. [105] S. Karlin and H. M. Taylor. A First Course in Stochastic Processes . Academic Press, 2nd edition, 1975. [106] F. P. Kelly. Reversibility and Stochastic Networks . John Wiley and Sons, 1979. [107] A. Khinchin. Mathematical theory of a stationary queue. Matematicheskii Sbornik , 39(4):73– 84, 1932. [108] J.F.C. Kingman. Two similar queues in parallel. Biometrika , 48:1316–1323, 1961. [109] J. Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM , 46(5):604–632, 1999. [110] L. Kleinrock. Queueing Systems, Volume I: Theory . Wiley-Interscience Publication, 1975. [111] L. Kleinrock. Queueing Systems, Volume II. Computer Applications . John Wiley & Sons, 1976. [112] J. K ¨ollerstr ¨om. Heavy trafﬁc theory for queues with several servers. I. Journal of Applied Probability , 11:544–552, 1974. [113] A. Konheim, I. Meilijson, and A. Melkman. Processor-sharing of two parallel lines. Journal of Applied Probability , 18:952–956, 1981. 536 bibliography [114] J.F. Kurose and K.W. Ross. Computer Networking: A Top-Down Approach Featuring the Internet . Pearson Education, 2003. [115] G. Latouche and V . Ramaswami. Introduction to Matrix Analytic Methods in Stochastic Mod- eling . ASA-SIAM, Philadelphia, 1999. [116] A.M. Law and W.D. Kelton. Simulation Modeling and Analysis . McGraw-Hill Companies, 2000. [117] E. Lazowska, J. Zahorjan, G. Graham, and K. Sevcik. Quantitative System Performance: Computer System Analysis Using Queueing Network Models . Prentice Hall, 1984. [118] A.M. Lee and P.A. Longton. Queueing process associated with airline passenger check-in. Operations Research Quarterly , 10:56–71, 1959. [119] S. Leonardi and D. Raz. Approximating total ﬂow time on parallel machines. In Proceedings of the Annual ACM Symposium on Theory of Computing (STOC) , pages 110–119, 1997. [120] H.C. Lin and C.S. Raghavendra. An analysis of the join the shortest queue (JSQ) policy. InProceedings of the 12th International Conference on Distributed Computing Systems , pages 362–366, 1992. [121] J.D.C. Little. A proof of the queueing formula L=λW.Operations Research , 9:383–387, 1961. [122] J.C.S. Lui, R.R. Muntz, and D.F. Towsley. Bounding the mean response time of the minimum expected delay routing policy: an algorithmic approach. IEEE Transactions on Computers , 44(12):1371–1382, 1995. [123] D. McWherter, B. Schroeder, N. Ailamaki, and M. Harchol-Balter. Improving preemp- tive prioritization via statistical characterization of OLTP locking. In Proceedings of the 21st International Conference on Data Engineering , pages 446–457. San Francisco, April 2005. [124] D. Meisner, B. Gold, and T. Wenisch. Powernap: Eliminating server idle power.",3136
Bibliography,"In Proceedings of ASPLOS , pages 205–216, 2009. [125] D.A. Menasc ´e, V .A.F. Almeida, and I.W. Dowdy. Capacity Planning and Performance Mod- eling . Prentice Hall, 1994. [126] M. Miyazawa. Rate conservation laws: a survey. Queueing Systems , 15(1–4):1–58, 1994. [127] R. Nelson. Probability, Stochastic Processes, and Queueing Theory . Springer-Verlag, 1995. [128] R.D. Nelson and T.K. Philips. An approximation to the response time for shortest queue routing. Performance Evaluation Review , 17:181–189, 1989. [129] M.F. Neuts. Probability distributions of phase type. In Liber Amicorum Prof. Emeritus H. Florin . University of Louvain, Belgium, pages 173–206, 1975. [130] M.F. Neuts. Matrix-Geometric Solutions in Stochastic Models . Johns Hopkins University Press, 1981. [131] Normal Distribution Table for Finite Mathematics. www.zweigmedia.com/RealWorld/ normaltable.html. [132] S.A. Nozaki and S.M. Ross. Approximations in ﬁnite-capacity multi-server queues with Poisson arrivals. Journal of Applied Probability , 15(4):826–834, 1978. [133] M. Nuijens. The Foreground-Background Queue . PhD thesis, Universiteit van Amsterdam, 2004. [134] K. Oida and K. Shinjo. Characteristics of deterministic optimal routing for a simple trafﬁc control problem. In Performance, Computing and Communications Conference, IPCCC , pages 386–392, February 1999. [135] T. Osogami and M. Harchol-Balter. Closed form solutions for mapping general distributions to quasi-minimal PH distributions. Performance Evaluation , 63(6):524–552, 2006. [136] T. Osogami, M. Harchol-Balter, and A. Scheller-Wolf. Analysis of cycle stealing with switching times and thresholds. In Proceedings of the 2003 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 184–195, San Diego, June 2003. bibliography 537 [137] T. Osogami, M. Harchol-Balter, and A. Scheller-Wolf. Analysis of cycle stealing with switching times and thresholds. Performance Evaluation , 61(4):374–369, 2005. [138] T. Osogami, M. Harchol-Balter, A. Scheller-Wolf, and L. Zhang. Exploring threshold-base policies for load sharing. In Forty-Second Annual Allerton Conference on Communication, Control, and Computing , pages 1012–1021, University of Illinois, Urbana-Champaign, October 2004. [139] L. Page, S. Brin, R. Motwani, and T. Winograd. The pagerank citation ranking: bringing order to the web. Technical Report 1999–66, Stanford InfoLab, November 1999. [140] M. Pistoia and C. Letilley. IBM WebSphere Performance Pack: Load Balancing with IBM SecureWay Network Dispatcher , International Technical Support Organization, October 1999. [141] F. Pollaczek. ¨Uber eine aufgabe der wahrscheinlichkeitstheorie. Mathematische Zeitschrift , 32:64–100, 1930. [142] I.A. Rai, E. W. Biersack, and G. Urvoy-Keller. Size-based scheduling to improve the perfor- mance of short TCP ﬂows. IEEE Network , January 2005. [143] I.A. Rai, G. Urvoy-Keller, and E.W. Biersack. Analysis of LAS scheduling for job size distri- butions with high variance. In Proceedings of the ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 218–228, 2003.",3121
Bibliography,"[144] I.A. Rai, G. Urvoy-Keller, and E.W. Biersack. LAS scheduling approach to avoid bandwidth hogging in heterogeneous TCP networks. Lecture Notes in Computer Science , 3079:179–190, 2004. [145] S. Raman and S. McCanne. A model, analysis, and protocol framework for soft state-based communication. In Proceedings of SIGCOMM , pages 15–25, 1999. [146] B.M. Rao and M.J.M. Posner. Algorithmic and approximation analyses of the shorter queue model. Naval Research Logistics , 34:381–398, 1987. [147] M. Reiser and S. Lavenberg. Mean-value analysis of closed multichain queueing networks. Journal of the ACM , 27(2):313–322, 1980. [148] S.M. Ross. Simulation . Academic Press, 2002. [149] S.M. Ross. Stochastic Processes . John Wiley and Sons, New York, 1983. [150] S.M. Ross. Introduction to Probability Models , 9th edition, Elsevier, New York, 2007. [151] C.H. Sauer and K.M. Chandy. Computer Systems Performance Modeling . Prentice-Hall, 1981. [152] C.H. Sauer and K.M. Chandy. Approximate analysis of central server models. IBM Journal of Research and Development , 19:301–313, 1975. [153] R.S. Schassberger. On the waiting time in the queueing systems GI/G/1. Annals of Mathematical Statistics , 41:182–187, 1970. [154] R.S. Schassberger. Warteschlangen . Springer-Verlag, 1973. [155] A. Scheller-Wolf and K. Sigman. New bounds for expected delay in FIFO GI/GI/c queues. Queueing Systems , 28:169–186, 1997. [156] A. Scheller-Wolf. Further delay moment results for FIFO multiserver queues. Queueing Sys- tems, 34:387–400, 2000. [157] A. Scheller-Wolf and K. Sigman. Delay moments for FIFO GI/GI/s queues. Queueing Systems , 25:77–95, 1997. [158] A. Scheller-Wolf and R. Vesilo. Structural interpretation and derivation of necessary and suf- ﬁcient conditions for delay moments in FIFO multiserver queues. Queueing Systems , 54:221– 232, 2006. [159] L.E. Schrage. A proof of the optimality of the shortest remaining processing time discipline. Operations Research , 16:687–690, 1968. [160] L.E. Schrage and L. W. Miller. The queue M/G/1 with the shortest remaining processing time discipline. Operations Research , 14:670–684, 1966. 538 bibliography [161] B. Schroeder and M. Harchol-Balter. Evaluation of task assignment policies for supercomput- ing servers: the case for load unbalancing and fairness. Cluster Computing: The Journal of Networks, Software Tools, and Applications , 7(2):151–161, 2004. [162] B. Schroeder and M. Harchol-Balter. Web servers under overload: how scheduling can help. ACM Transactions on Internet Technologies , 6(1):20–52, 2006. [163] B. Schroeder, M. Harchol-Balter, A. Iyengar, and E. Nahum. Achieving class-based QoS for transactional workloads. In Proceedings of the 22nd International Conference on Data Engineering Poster Paper , pages 153–155, Atlanta, GA, April 2006. [164] B. Schroeder, M. Harchol-Balter, A. Iyengar, E. Nahum, and A. Wierman. How to deter- mine a good multi-programming level for external scheduling. In Proceedings of the 22nd International Conference on Data Engineering , pages 60–70, Atlanta, GA, April 2006. [165] B. Schroeder, A. Wierman, and M.",3112
Bibliography,"Harchol-Balter. Open versus closed: a cautionary tale. In Proceedings of Networked Systems Design and Implementation (NSDI) , 2006. [166] A. Shaikh, J. Rexford, and K.G. Shin. Load-sensitive routing of long-lived IP ﬂows. In Pro- ceedings of ACM SIGCOMM , pages 215–226, September 1999. [167] K. Sigman. Lecture Notes borrowed from Karl Sigman’s Stochastic Processes Class, 2005. [168] M.S. Squillante, C.H. Xia, D.D. Yao, and L. Zhang. Threshold-based priority policies for parallel-server systems with afﬁnity scheduling. In Proceedings of the IEEE American Control Conference , pages 2992–2999, June 2001. [169] M.S. Squillante, D.D. Yao, and L. Zhang. Internet trafﬁc: periodicity, tail behavior and perfor- mance implications. E. Gelenbe, editor, Systems Performance Evaluation: Methodologies and Applications , pages 23–37, CRC Press, 2000. [170] D.A. Stanford and W.K. Grassmann. The bilingual server system: a queueing model featuring fully and partially qualiﬁed servers. INFOR , 31(4):261–277, 1993. [171] D.A. Stanford and W.K. Grassmann. Bilingual server call centers. D.R. McDonald and S.R.E. Turner, editors, Analysis of Communication Networks: Call Centers, Trafﬁc and Performance , pages 31–47, American Mathematical Society, 2000. [172] Z. Tari, J. Broberg, A. Zomaya, and R. Baldoni. A least ﬂow-time ﬁrst load sharing approach for a distributed server farm. Journal of Parallel and Distributed Computing , 65:832–842, 2005. [173] Y .C. Tay. Analytical Performance Modeling for Computer Systems . Morgan & Claypool Pub- lishers, 2010. [174] E. Thereska. Enabling What-If Explorations in Systems . PhD thesis, Carnegie Mellon Univer- sity, 2007. [175] E. Thereska, M. Abd-El-Malek, J.J. Wylie, D. Narayanan, and G.R. Ganger. Informed data distribution selection in a self-predicting storage system. In Proceedings of the International Conference on Autonomic Computing (ICAC’06) , pages 187–198, June 2006. [176] G.B. Thomas and R.L. Finney. Calculus and Analytic Geometry . Addison-Wesley, 9th edition, June 1996. [177] N. Thomas. Comparing job allocation schemes where service demand is unknown. Journal of Computer and System Sciences , 74:1067–1081, 2008. [178] H.C. Tijms. A First Course in Stochastic Models . John Wiley and Sons, 2003. [179] K.S. Trivedi. Probability and Statistics with Reliability, Queueing and Computer Science Applications . Prentice-Hall, 1982. [180] R.W. Weber. On optimal assignment of customers to parallel servers. Journal of Applied Probability , 15:406–413, 1978. [181] Weibull Distribution. Characteristics of the Weibull. http://www.weibull.com/hotwire/issue14/ relbasics14.htm. [182] P.D. Welch. On a generalized M/G/1 queueing process in which the ﬁrst customer of each busy period receives exceptional service. Operations Research , 12:736–752, 1964. bibliography 539 [183] W. Whitt. A review of L=λW and extensions. Queueing Systems , 9:235–268, 1991. [184] W. Whitt. The impact of a heavy-tailed service-time distribution upon the M/GI/s waiting-time distribution. Queueing Systems , 36:71–87, 2000. [185] W. Whitt. Approximating a point process by a renewal process: two basic methods.",3145
Bibliography,"Operations Research , 30:125–147, 1982. [186] W. Whitt. Open and closed models for networks of queues. AT&T Bell Laboratories Technical Journal , 63(9):1911–1979, 1984. [187] W. Whitt. Blocking when service is required from several facilities simultaneously. AT&T Bell Laboratories Technical Journal , 64(8):1807–1856, 1985. [188] A. Wierman. Scheduling for Today’s Computer Systems: Bridging Theory and Practice .P h D thesis, Carnegie Mellon University, 2007. [189] A. Wierman, N. Bansal, and M. Harchol-Balter. A note on comparing response times in M/GI/1/FB and M/GI/1/PS queues. Operations Research Letters , 32(1):73–76, 2004. [190] A. Wierman and M. Harchol-Balter. Classifying scheduling policies with respect to unfairness in an M/GI/1. In Proceedings of the 2003 ACM Sigmetrics Conference on Measurement and Modeling of Computer Systems , pages 238–249, San Diego, CA, June 2003. [191] A. Wierman, M. Harchol-Balter, and T. Osogami. Nearly insensitive bounds on SMART scheduling. In ACM Sigmetrics 2005 Conference on Measurement and Modeling of Computer Systems , pages 205–215, 2005. [192] A. Wierman, T. Osogami, M. Harchol-Balter, and A. Scheller-Wolf. How many servers are best in a dual-priority M/PH/k system? Performance Evaluation , 63(12):1253–1272, 2006. [193] R.J. Williams. On dynamic scheduling of a parallel server system with complete resource pooling. D.R. McDonald and S.R.E. Turner, editors, Analysis of Communication Networks: Call Centers, Trafﬁc and Performance . American Mathematical Society, pages 49–72, 2000. [194] W. Winston. Optimality of the shortest line discipline. Journal of Applied Probability , 14:181– 189, 1977. [195] R.W. Wolff. Stochastic Modeling and the Theory of Queues . Prentice-Hall, 1989. [196] D.D. Yao. Reﬁning the diffusion approximation for the M/G/m queue. Operations Research , 33:1266–1277, 1985. [197] S.F. Yashkov and A.S. Yashkova. Processor sharing: a survey of the mathematical theory. Automation and Remote Control , 68(9):1662–1731, 2007. [198] J. Zhang. Limited Processor Sharing Queues and Multi-server Queues . PhD thesis, Georgia Institute of Technology, 2009. [199] J. Zhang, J.G. Dai, and B. Zwart. Diffusion limits of limited processor sharing queues. Annals of Applied Probability , 21:745–799, 2011. [200] D. Zwillinger. CRC Standard Mathematical Tables and Formulae . Chapman & Hall, 31st edition, 2003.",2383
Index,"Index AS,223,435,442 At,435 Ax y,514 B,248,459 Bx,514 C2,207 Di,110 Dmax,116 N,15 NQ,15 PQ,260 Pblock,261 Pij,131 R,259,420 S,14 Se,403 Sx,514 Sx,492 T,14 TQ,15 Wx,513 Z,21 λ,14 λi,298 λx,514 μ,14 πj,135 ρ,100 ρ, for multi-server system, 259,269,420 ρi,100 ρx,505 ρx,492 τi,225 an,242 dn,242 ni,305 o(δ),212 pj,148 pn,242 r(t),208 Accessible states, 150 Acyclic networks, 293 Admission control, 246Age of service, 403 All-Can-Win Theorem, 527 Aloha protocol, 195 Aperiodic, 88,183 Aperiodic chain, 150 Arrival rate, 14 Time-varying, 366 Arrival Theorem, 337 Proof of, 339 Asymptotic analysis, 116 Balance equations, 170,234 Batch system, 22 Bayes Law, 36 BCMP, 380 FCFS servers, 381 PLCFS servers, 384 PS servers, 382 Bidirectional chain, 185 BigIP, 420 Bimodal, 423 Binomial distribution, 67 Birth-death process, 236 Blocking probability, 257 Bottleneck device, 119 Bottleneck Law, 110 Bounded Pareto distribution, 353,357, 358 Burke’s Theorem, 288 Alternative proof, 290 Proof of, 289 Via transforms, 447 Busy period Expectation, 248,406,448 M/G/1 Moments, 461 Number of jobs served during, 469 Transform, 459,461 With setup time, 469 M/M/∞,406 M/M/1 Number of jobs served during, 468 Transform, 448 Shorts-only, 467 541 542 index cμ-Rule, 516 Caching, 204 Capacity provisioning, 272,274,277,seeOne fast or many slow Catalan numbers, 187 Central Limit Theorem, 61,356 Heuristic proof via transforms, 448 Central subsystem, 22 Chebyshev’s Inequality, 91 Class-based service rates FCFS servers, 330,381 PS servers, 383 Classed Jackson network, 314 Class-based service rates, 330 Examples, 322,325,326,329 Limiting probabilities, 318 Closed Jackson network, 333,345 Limiting probabilities, 335 Closed networks, 20 Batch system, 96 Interactive system, 96,345 M/M/2, 284 Performance of, 284,294 Terminal-driven system, 96 Cloud service center, 309 Communicating states, 150 Communication networks, 381 Compatible time-sharing system, 265 Competitive ratio, 424 Congestion management, 280 Connection-oriented network, 312 Constant failure rate, 350 Convergence, 79 Convergence almost surely, 80 Convergence in probability, 82 Convergence with probability 1, 80 Correlation, 67 Coupon collection, 70 Covariance, 67 Coxian distribution, 380,383,385 CPU process lifetimes, 208,349 CSMA/CD, 196 CTMC, seeMarkov chains Cycle stealing, 430 D/D/1, 404 Damage caused by forest ﬁres, 356 Database modeling, 497 Decreasing failure rate, 208,354 Delta-step proof ( δ-step), 209,212,213, 219 Departure process, 289,291,451 Device demand, 110 DFR, seeDecreasing failure rateDimensionality reduction, 430 Dispatcher, 408 Distributional Little’s Law, 111,456 Doubling arrival and service rates, 5,240,405 Doubly stochastic matrix, 145 DTMC, seeMarkov chains E2distribution, 364 E2/M/1, 365 Embedded DTMC, 286,451,479 Empirical measurements, 350 Human wealth, 356 IP ﬂow durations, 356 Natural disasters, 356 Phone call durations, 356 Web ﬁle sizes, 355 Wireless session times, 356 Ensemble average, 84,86 200 Equilibrium distribution, 396,403 Distribution, 407 Transform, 448 Equivalence between Geometric and Exponential, 209,211 Ergodic, 88,164 Ergodic theorem of Markov chains, 164, 178 Ergodicity, 148 Erlang-2, 423 Erlang-B formula, 257 Erlang-C formula, 261 Erlang-k distribution, 360 Exceptional ﬁrst service, 280 Excess of random variable, 396 Distribution, 407 Expectation, 401 Transform, 448 Excess of service, 396,402 Expected number of visits to state, 157 Expected time to k failures, 185 Exponential distribution, 206,350 Exponential phases, 360 Failure rate function, 208,222 Failures and repair, 407 Fairness, 356,475 All-Can-Win Theorem, 527 Fair scheduling, 487,526 Feedback in network, 307,308 Fibonacci sequence, 205 Financial application, 185 Finite buffer space, 282 First-Come-First-Served (FCFS), 478 Flow time, 14 Forced Flow Law, 106 index 543 Forward chain, 286 Fractional moments, 70 Frequency-division multiplexing, 241,263 G/G/k, 428 Stability, 428 Gambler’s ruin, 160 General service times, 383 Generalized Erlang, 360 Generating random variables Accept/Reject method, 72 Inverse-Transform method, 70 Generator matrix, 368 Geometric distribution, 69,209 Google’s PageRank algorithm, 190,191 Dead end, 192 Implementation, 195 Spider trap, 193 Grabbing multiple servers simultaneously, 308, 309 H2distribution, 361 Hair salon, 282 Heavy-tail property, 354,358 Heterogeneous servers, 266,268 High-variability job sizes, 408 Honeypot, 223 HTTP request scheduling, 356 HTTP request times, 355 Human wealth, 356 Hyperexponential distribution, 361,377,378 Decreasing failure rate, 362,378 Degenerate, 362 Hypoexponential, 360 Immediate dispatching, 408 Increasing failure rate, 208 Increasing number of servers, 276 Independent increments, 214 Indicator random variables, 56 Inﬁnite variance, 354 Insensitivity results, 257,278 Inspection Paradox, 395,402 Interactive closed system, 21 Interarrival time, 14 IP ﬂow durations, 356 Irreducible, 88,183 Irreducible chain, 150 Jackson network, 297,305 Acyclic, 293 Arrival process into server, 299 Classed, seeClassed Jackson network Example, 306Limiting probabilities, 305 Local balance, 301 Product form, 304 Total arrival rate into server, 298 With load-dependent service rates, 344 With M/M/k queues, 344 Job Age, 349,403 Lifetime, 349 Remaining lifetime, 349 Size, 14,349 Job migration, 349 Criterion, 355 Join-Shortest-Queue, seeTask assignment policy Kendall notation, 236,253 Kleinrock’s independence assumption, 381 Laplace transform, 433 Conditioning, 441 Linearity, 439 Moments, 436,439 Sum of random number of random variables, 444 Two-sided, 447 Last-Come-First-Served (LCFS), 478 Law of large numbers Strong, 84 Weak, 83 Least-Work-Left, seeTask assignment policy Limited processor-sharing, 498 Limiting distribution, 136,140 Limiting probabilities as rates, 168 Limiting probability, 134,135,136,140,242 As seen by arrival, 242 As seen by departure, 242 Little’s Law, 95,98 Distributional, 111,456 For closed systems, 96,101,112 For open systems, 95 For red jobs, 101 For waiting time, 100 Little-o, o(δ),211 Load, 18 Resource requirement, R,259,273 System utilization, ρ,259,269 Load balancer, 408 Load balancing, 349 Load balancing versus unbalancing, 267,268, 415,432 Load in multi-server system, 273 Load-dependent service rates, 344 Local balance, 301,318,333,386 544 index LocalDirector, 420 Log-log plot, 351 M∗/E∗ 2/1,372 Mt,366 Mt/M/1, 366 M/E 2/1,364 M/E k/1,398 M/H 2/1,364,398 M/H 2/2,378 With setup time, 378 M/BP/1/PS, 394 M/Cox/1/PS, 385 M/D/1, 398,404 M/G/∞,278 Insensitivity, 278 M/G/1, 395 Busy period, 459,461 Different job types, 405 Failures and repair, 407 Laplace transform of response time, 450, 488 Low utilization, 404 Mean time in queue, 397 Priority queue, seePriority queue Special busy periods, 462 Stability, 419 Tagged-job argument, 397 Time in queue, 404 Variability in service time, 405 Variance time in queue, 404,456 With setup time Mean, 465 Transform, 464 Z-transform of number in queue, 456 Z-transform of number in system, 450 M/G/1/PS, 385,394 Ages of jobs, 484 M/G/2, 418 Stability, 418 M/G/k, 413,428 Inaccuracy of approximations, 413 Lee-Longton approximation, 413 M/M/∞,266,271 Busy period, 406 With setup time, 468 M/M/1, 236 Busy period, 448 Busy period mean, 248 Departure process, 289,291 Finite capacity, 246 Number in queue, 246 Number in system, mean, 239 Number in system, variance, 239Response time, distribution, 248,443,447 Response time, mean, 239 Simulation of, 246 Threshold queue, 249 With feedback loop, 307 With setup time, 280,465 M/M/1/N, 246 M/M/1/PS, 384 M/M/2 Heterogeneous servers, 266,268 Transform analysis, 449,456 With setup time, 378 M/M/2/3, 447 Example, 265 M/M/k, 253,258 Capacity provisioning, 272 Departure process, 289 Distribution time in queue, 277 Expected number busy, 259,262 Expected number in queue, 262 Increasing number of servers, 276 Mean time in queue, 270 Mean time in queue given delayed, 270 Probability of queueing, PQ,261 Resource requirement, R,259 System utilization, ρ,259,269 Transform analysis, 449,456 M/M/k/k, 253,255 Blocking probability, 256 Erlang-B formula, 257 Insensitivity result, 257 M/PH/1, 377 Markov chains Accessible states, 150 Aperiodic, 150,183 Balance equations, 170,234 Communicating states, 150 Continuous-time (CTMC), 130,225 View 1, 226 View 2, 227 Converting CTMC to DTMC, 229,234, 235 Discrete-time (DTMC), 129,130 Ergodic, 164 Ergodic theorem, 164,178 Ergodicity, 148 Expected number of visits to state, 157 Finite-state, 131,138,189 Gambler’s ruin, 160 Inﬁnite-state, 139 Irreducible, 150,183 Limiting distribution, 135,136,139,140 Limiting distribution equals stationary distribution, 136,140 index 545 Limiting probabilities, 134,135,136,139, 140 Limiting probabilities as rates, 168 Markovian property, 130,225 n-step transition probabilities, 133 Null recurrent, 162 Periodic, 171 Positive recurrent, 162,183 Powers of P,133 Random walk, 160 Recurrent chain, 161 Recurrent state, 156,157 Recurrent versus transient, 188 Semi-Markov process, 406 Solution via generating functions, 201,205 Stationary distribution, 136,140 Stationary equations, 136 Stationary property, 131 Steady state, 137 Summary theorem, 165 Symmetric random walk, 163 Time average, 166 Time average versus ensemble average, 88, 148 Time between visits to state, 153,164,406 Time to empty, 204 Time until leave state, 226 Time-reversibility equations, 171,254 Time-reversible, 170,254 Transient chain, 159,161 Transient state, 156,157 Transition probability matrix, 131 Markov-modulated Poisson process, 366 Markov’s Inequality, 91 Markovian property, 130,225 Matching moments of distribution, 361, 363 Matrix-analytic method, 359,366 Generator matrix, 368 M/PH/1, 377 Time-varying load, 377 Max of Exponentials, 223,224 Mean value analysis (MV A), 337,340 Memoryless, 207,222 Memoryless distribution, 209 Method of phases, 359 Method of stages, 359 Migrating jobs, 349 Migrating old jobs, 355 Minimum of Exponentials, 212 Modiﬁcation analysis, 114,118,124 Multiple resources at once, 309 Multiprogramming level (MPL), 21,23 For Processor-Sharing, 497Network Dispatcher, 420 Network of PS servers, 391,393 Network of workstations, 349,383 Network with two job types, 326 Non-Markovian arrival process, 366 Normal approximation, 68 Null recurrent, 162 One fast or many slow, 7,263,431 Open networks, 16 Open versus closed systems, 123,247,267 Operational laws, 93 Asymptotic analysis, 116 Bottleneck Law, 110 Combining operational laws, 107,112 Forced Flow Law, 106 Little’s Law, 95,98 For closed systems, 101,112 For mean slowdown, 113 For red jobs, 101 For waiting time, 100 Modiﬁcation analysis, 118,124 Response Time Law, 103 Utilization Law, 100 Packet-routing network, 312 Parallel jobs, 308 Pareto distribution, 352,355,415 PASTA, 242,243,338 Performance metrics, 473 Performance-per-Watt, 458 Periodic chains, 171,189 Phase-type distribution, 359,362 Phone call durations, 356 Poisson Number of arrivals during S, 223 Poisson approximation to Binomial, 67 Poisson Arrivals See Time Averages (PASTA), 242,243,398 Application to simulations, 244 Poisson process, 213,222 Deﬁnition 1, 215 Deﬁnition 2, 215 Deﬁnition 3, 217 Independent increments, 214 Merging processes, 218 Number of arrivals during service, 223,435 Poisson splitting, 218 Stationary increments, 215 Uniformity, 221 Pollaczek-Khinchin (P-K) formula, 404 Positive correlation, 67 Positive recurrent, 88,162,183 Power laws in Internet, 355 546 index Power management, 457 Dynamic power management, 111 Performance-per-Watt, 466 Policies DelayedOff, 469 ON/IDLE, 458,465 ON/OFF, 458,466,469 Power allocation, 125 Server farm, 467 Setup cost, 458 Power-law distribution, 352 Preemptive-resume, 482 Pricing for queues, 279 Priority queue, 499 Non-preemptive, 500,502 Preemptive, 500,508 Probability Alternative deﬁnition of expectation, 69 Bayes Law, 36,68 Bernoulli distribution, 38 Binomial distribution, 39 Conditional independence, 68 Conditional probability, 33 Conditional random variables, 49 Conditionally independent events, 34 Conditioning, 53 Covariance, 67 Expectation, 44 Expectation of product, 48,65 Expectation of quotient, 65 Expected time to kfailures, 185 Exponential distribution, 42 Geometric distribution, 39 Independent events, 34 Independent random variables, 48 Indicator random variables, 56 Law of Total Probability, 35,53 Linear transformation property, 60 Linearity of Expectation, 54 Markov’s Inequality, 91 Mutually exclusive events, 32 Normal distribution, 57,68 Pareto distribution, 43 Poisson distribution, 40 Random variable Continuous, 37 Discrete, 37 Sum of Geometric number of Exponentials, 223 Sum of random number of random variables, 62,187 Variance, 46 Variance of sum, 56,65 Process migration, 349Processor with failures, 205 Processor-Sharing, 380 Product form, 304,311,318,330,333,380, 392,394 Program analysis example, 132 Limiting distribution, 145 Quality of Service, 67 Quick versus slow customers, 329 R a i s i n gm a t r i xt op o w e r , 133 Random, seeTask assignment policy, 478 Random walk, 160 Randomized chess, 186 Recurrent chain, 161 Recurrent state, 156,157 Recurrent versus transient, 188 Relationship between closed and open systems, 25 Reliability Max of Exponentials, 223,224 Min of Exponentials, 212 Remaining service requirement, 518 Remote execution, 349 Renewal process, 167,399 Renewal theorem, 167 Renewal-Reward theorem, 400 Renewal-Reward theory, 399,406 Repair facility, 330 Repair facility example, 131,133,138 Rerouting IP ﬂows, 356 Residence time, 510,519 Residual distribution, 396 Residue classes, 173,189 Resource requirement, R,273 Response time, 14 95th percentile, 277 Response time in closed system, 22 Response Time Law for Closed Systems, 103 Reverse chain, 285,286 Reverse process, 286 Round-Robin, seeTask assignment policy Routing Class-based, 311,326 Routing probability, 297 Sample mean, 357 Sample path, 80 Sample variance, 357 Scheduling Comparison of policies, 524 Fairness, seeFairness First-Come-First-Served (FCFS), 10 Foreground-Background (FB), 490 index 547 Response time, 494 Transform, 497 Last-Come-First-Served (LCFS), 10 Transform, 481 Least-Attained-Service (LAS), 491 Limited Processor-Sharing, 497 Minimizing mean slowdown, 125 Non-preemptive, 410,478,479,481 Preemptive, 482 Preemptive-LCFS (PLCFS), 488 Response time, 489 Transform, 497 Preemptive-Shortest-Job-First (PSJF), 512 Transform, 514 Processor-Sharing (PS), 382,483 Response time, 486 Random, 10,478 RS policy, 113 Shortest-Job-First (SJF), 499,505 Shortest-Remaining-Processing-Time (SRPT), 26,113,356,519 SRPT beats FB, 523 Starvation, 356,475 Work-conserving policy, 474 Scheduling web requests, 356,499 Scherr’s thesis, 265 Security application, 223 Semi-Markov process, 406 Server farm, 408 FCFS servers, 410 Optimal design, 424 PS and FCFS servers, 430 PS servers, 391,419,430 Task assignment, seeTask assignment in server farms Service rate, 14 Service requirement, 14 Setup cost, 11,458 Setup time, 280,378,465,468 Simulation Generating random variables, 70 M/BP/1, 357 M/M/1, 78 Pareto, 358 Sample mean, 357 Sample variance, 357 Time average versus ensemble average, 90 Size-Interval-Task-Assignment (SITA), seeTask assignment policy Slotted Aloha protocol, 196 Slowdown, 26,474,481 Sojourn time, 14Solving recurrences via generating functions, 201 Square-root stafﬁng, 274,277 Squared coefﬁcient of variation, C2,65,207, 359 Stability, 26 M/G/2, 418 Minimum number of servers needed, 273 Single queue, 15,419 Starvation, 475,496 Stationary distribution, 136,140 Stationary equations, 136 Stationary increments, 215 Stationary property, 131 Statistical multiplexing, 241 Steady state, 137 Stirling’s approximation, 155 Stochastic process, 130 Stopping time, 187 Strong Law of Large Numbers, 84,167 Sum of Geometric number of Exponentials, 223 With transforms, 446 Sum of random number of random variables, 62,187 With transforms, 444 Supercomputer center, 308 SURGE, 355 Symmetric random walk, 163,187,188 SYNC, 356 System utilization, ρ,259,269 Tagged-job argument, 396 Tail of response time, 475 Tandem queue, 291 With ﬁnite buffers, 282 Task assignment in server farms, 9,408 Dynamic, 412 Load balancing, 267 Load balancing versus unbalancing, 267,268 Static, 412 Task assignment policy, 408 Central queue, 411 Central-Queue-SRPT, 425 Comparison, 423 Cycle stealing, 430 Hybrid, 428 IMD, 427 Join-Shortest-Queue (JSQ), 429 For PS servers, 422 Least-Work-Left (LWL), 412,431 M/G/k, 411,431 OPT-0, 423 Random policy, 410 548 index Task assignment policy ( cont. ) Round-Robin policy, 410 SITA versus LWL, 416 Size-Interval-Task-Assignment (SITA), 414 Optimal size cutoffs, 414 TAGS, 428 Under low variability, 419 TCP ﬂow scheduling, 356 Think time, 21 Threshold queue, 146,249 Throughput, 17 Throughput in closed system, 23 Throughput of device, 18 Throwing away servers, 267 Time average, 84,86,166 Time average versus ensemble average, 88,148 Time between visits to state, 153,164,406 Time in system, 14 Time-reversibility, 170,288,294 Time-reversibility equations, 171,254 Time to empty, 204 Time until kconsecutive failures, 70 Time-sharing, 380 Time-sharing CPU, 382 Time-varying arrival rate, 366 Time-varying load, 377 Transient chain, 159,161 Transient state, 156,157 Transition probability matrix, 131 Transmission time, 382 Turnaround time, 14 Umbrella problem example, 132,133,139 Unbounded queue example, 142UNIX process lifetime, 349 Distribution, 350 Empirical measurements, 350 Utilization, 17,100 Derivation of, 100 Utilization Law, 19,100 Utilization of device, 18 Utilization of multi-server system, 273 Vacation of server, 467 Variability in service time, 377,378,403, 405 Variance, 46 Waiting time, 510 Wald’s equation, 187 Walk on undirected weighted graph, 186 Weak Law of Large Numbers, 83,91 Web ﬁle sizes, 355 Web server farm, 419 Weibull distribution, 423,524,525 What-if questions, 93,114 Wireless session times, 356 Work in system, 474 Work-conserving policy, 474 Worst-case analysis, 424 Z-transform, 201,434 Conditioning, 441 For solving recurrences, 201 Linearity, 440 Moments, 437 Sum of random number of random variables, 444",18171

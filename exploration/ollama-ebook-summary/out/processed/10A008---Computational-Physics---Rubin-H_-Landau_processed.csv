Title,Text,Character Count
Cover,Computational Physics,21
Contents,"Computational Physics Problem Solving with Python Fourth Edition Rubin H. Landau Manuel J. P√°ez Cristian C. Bordeianu (D) With contributions by Guangliang He Authors Prof. Rubin H. Landau OregonStateUniversity Corvallis OR 97331 UnitedStatesofAmerica Prof. Manuel J. P√°ez DepartamentoFisica UniversaddeAntioquia Medellin Colombia Prof. Cristian C. Bordeianu‚Ä† UniversityofBucharest Str.Micanr.7 jud.Suceav 725100 Romania Cover Image: ¬©PASIEKA/GettyImagesAllbookspublishedby WILEY-VCH arecarefully produced.Nevertheless,authors,editors,andpublisher donotwarranttheinformationcontainedinthese books,includingthisbook,tobefreeoferrors.Readers areadvisedtokeepinmindthatstatements,data, illustrations,proceduraldetailsorotheritemsmay inadvertentlybeinaccurate. Library of Congress Card No.: appliedfor British Library Cataloguing-in-Publication Data Acataloguerecordforthisbookisavailablefrom theBritishLibrary. Bibliographic information published by the Deutsche Nationalbibliothek TheDeutsche Nationalbibliothekliststhispublicationinthe DeutscheNationalbibliografie;detailedbibliographic dataareavailableontheInternetat <http://dnb.d-nb.de >. ¬©2024WILEY-VCHGmbH,Boschstra√üe12,69469 Weinheim,Germany Allrightsreserved(includingthoseoftranslationinto otherlanguages).Nopartofthisbookmaybe reproducedinanyform‚Äìbyphotoprinting,microfilm, oranyothermeans‚Äìnortransmittedortranslatedinto amachinelanguagewithoutwrittenpermissionfrom thepublishers.Registerednames,trademarks,etc. usedinthisbook,evenwhennotspecificallymarked assuch,arenottobeconsideredunprotectedbylaw. Print ISBN: 978-3-527-41425-3 ePDF ISBN: 978-3-527-84332-9 ePub ISBN: 978-3-527-84331-2 Typesetting Straive,Chennai,India v Contents Preface xvii Acknowledgments xix Part I Basics 1 1 Introduction 3 1.1 ComputationalPhysicsandScience 3 1.2 ThisBook‚ÄôsSubjects 4 1.3 VideoLectureSupplements 4 1.4 ThisBook‚ÄôsCodesandProblems 5 1.5 OurLanguage:ThePythonEcosystem 6 1.6 TheEasyWay:PythonDistributions 6 2 Software Basics 9 2.1 MakingComputersObey 9 2.2 ComputerNumberRepresentations 11 2.2.1 IEEEFloating-PointNumbers 12 2.2.1.1 ExamplesofIEEERepresentations 15 2.2.2 PythonandtheIEEE754Standard 17 2.3 PythonMiniTutorial 18 2.3.1 StructureandFunctions 18 2.3.2 VariableTypesandOperators 19 2.3.3 BooleanandControlStructures 20 2.3.4 PythonListsasArrays 21 2.3.5 PythonI/O 23 2.3.6 Python‚ÄôsAlgebraicTools 24 2.4 ProgrammingWarmup 25 2.4.1 ProgramDesign 26 2.4.2 FirstProgrammingSteps 27 2.4.3 OverandUnderflowExercises 28 2.4.4 MachinePrecision 29 2.4.5 Experiment:YourMachine‚ÄôsPrecision 30 2.5 Python‚ÄôsVisualizationTools 30 viContents 2.5.1 Visual(VPython)‚Äôs2DPlots 31 2.5.2 Matplotlib‚Äôs2DPlots 32 2.5.3 Matplotlib‚Äôs3DSurfacePlots 35 2.5.4 Matplotlib‚ÄôsAnimations 36 2.6 PlottingExercises 36 2.7 CodeListings 38 3 Errors and Uncertainties 44 3.1 TypesofErrors 44 3.1.1 CourtingDisaster:SubtractiveCancelation 46 3.1.2 SubtractiveCancelationExercises 46 3.1.3 Round-OffErrors 48 3.1.4 Round-OffErrorAccumulation 48 3.2 ExperimentalErrorInvestigation 49 3.3 ErrorswithPowerSeries 52 3.3.1 ImplementationandAssessment 53 3.3.2 ErrorinSpecularReflection 54 3.4 ErrorsinBesselFunctions 55 3.4.1 NumericalRecursion(Method) 55 3.4.2 ImplementationandAssessment:RecursionRelations 57 3.5 CodeListing 58 4 Monte Carlo Simulations 59 4.1 RandomNumbers 59 4.1.1 RandomNumberGeneration 60 4.1.2 ComputingaRandomSequence 62 4.2 SimulatingaRandomWalk 63 4.2.1 RandomWalkImplementation 64 4.2.2 RandomWalksinaBrain 65 4.2.3 RandomProteinFolding 67 4.3 SpontaneousDecay 68 4.3.1 DiscreteDecayModel 69 4.3.2 TheExponentialDecayApproximation 70 4.3.3 DiscreteDecaySimulation 70 4.3.4 DecayImplementationandVisualization 71 4.4 TestingandGeneratingRandomDistributions 71 4.5 CodeListings 73 5 Differentiation and Integration 78 5.1 DifferentiationAlgorithms 78 5.1.1 ForwardDifference 78 5.1.2 CentralDifference 79 5.2 ExtrapolatedDifference 80 5.2.1 SecondDerivatives 81 5.2.1.1 Assessment 81 5.3 IntegrationAlgorithms 83 Contents vii 5.3.1 BoxCounting 83 5.3.2 TrapezoidRule 84 5.3.3 Simpson‚ÄôsRule 85 5.3.4 SimpleIntegrationErrorEstimates 86 5.3.5 Higher-OrderAlgorithms 88 5.4 GaussianQuadrature 89 5.4.1 MappingGaussianPoints 90 5.4.2 GaussianQuadratureDerivation ‚äô90 5.5 MonteCarloIntegrations 91 5.5.1 StoneThrowingImplementation 92 5.5.2 IntegrationErrorInvestigation 93 5.6 MeanValueandN‚ÄìDIntegration 94 5.6.1 10-DMCErrorInvestigation 95 5.6.2 Implementation:10-DMonteCarloIntegration 95 5.7 MCVarianceReduction 96 5.8 ImportanceSamplingandvonNeumannRejection 96 5.9 CodeListings 97 6 Trial-and-Error Searching and Data Fitting 100 6.1 QuantumBoundStatesI 100 6.2 BisectionSearch 101 6.2.1 BisectionExercises 102 6.3 Newton‚ÄìRaphsonSearch 102 6.3.1 Search +Backtracking 104 6.4 MagnetizationSearch 105 6.5 DataFitting 107 6.5.1 LagrangeFitting 109 6.5.2 CubicSplineInterpolation 109 6.5.3 CubicSplineQuadrature 111 6.6 FittingExponentialDecay 112 6.7 Least-SquaresFitting 113 6.7.1 Least-SquaresImplementation 114 6.7.2 LinearQuadraticFit 116 6.7.2.1 LinearQuadraticFitAssessment 118 6.8 NonlinearFittoaResonance 118 6.9 CodeListings 120 7 Matrix Computing and N‚ÄìD Searching 123 7.1 MassesonaStringandN‚ÄìDSearching 123 7.2 MatrixGeneralities 126 7.3 MatricesinPython 129 7.3.1 ListsasArrays 129 7.3.2 NumPyMatrices 130 7.3.3 NumPyLinearAlgebraLibrary 134 7.4 Exercise:TestsBeforeUse 136 7.5 SolutiontoStringProblem 139 viiiContents 7.6 SpinStatesandHyperfineStructure 139 7.7 SpeedingUpMatrixComputing ‚äô141 7.7.1 Vectorization 141 7.7.2 SpeedupExercises 143 7.8 CodeListing 144 8 Differential Equations and Nonlinear Oscillations 147 8.1 NonlinearOscillators 147 8.2 ODEReview 149 8.2.1 Order 149 8.2.2 OrdinaryandPartial 149 8.2.3 LinearandNonlinear 150 8.2.4 InitialandBoundaryConditions 150 8.3 DynamicFormofODEs 150 8.4 ODEAlgorithms 152 8.4.1 Euler‚ÄôsRule 152 8.4.2 Runge‚ÄìKuttaRule 153 8.4.3 Adams-Bashful-MoultonPredictor-CorrectorRule 155 8.4.4 Assessment:rk2 versusrk4versusrk45 156 8.5 SolutionforNonlinearOscillations 157 8.5.1 PrecisionAssessmentviaEConservation 158 8.6 Extensions:NonlinearResonances,Beats,Friction 159 8.6.1 Friction 159 8.6.2 ResonancesandBeats 159 8.6.3 Time-DependentForces 160 8.7 CodeListings 161 Part II Data Science 165 9 Fourier Analyses 167 9.1 FourierSeries 167 9.1.1 SawtoothandHalf-WaveFunctions 169 9.1.2 Exercises:FourierSeriesSummations 170 9.2 FourierTransforms 170 9.3 DiscreteFourierTransforms 172 9.3.1 Aliasing 174 9.3.2 Assessments 176 9.3.3 TransformingNonperiodicFunctions 178 9.4 NoiseFiltering 178 9.4.1 NoiseReductionviaAutocorrelation 178 9.4.2 AutocorrelationFunctionExercises 181 9.4.3 FilteringwithTransforms 181 9.4.4 DigitalFilters:WindowedSincFilters ‚äô183 9.5 FastFourierTransform ‚äô185 9.5.1 BitReversal 187 Contents ix 9.6 FFTImplementation 189 9.7 FFTAssessment 190 9.8 CodeListings 190 10 Wavelet and Principal Components Analysis 193 10.1 PartI:WaveletAnalysis 193 10.2 WavePacketsandUncertaintyPrinciple 195 10.2.1 WavePacketExercise 196 10.3 Short-TimeFourierTransforms 197 10.4 WaveletTransforms 198 10.4.1 GeneratingWaveletBasisFunctions 198 10.4.2 ContinuousWaveletTransforms 201 10.5 DiscreteWaveletTransforms ‚äô203 10.5.1 PyramidScheme ‚äô205 10.5.2 DaubechiesWaveletsFilters ‚äô209 10.5.3 DWTExercise ‚äô212 10.6 PartII:PrincipalComponentsAnalysis 213 10.6.1 Multi-dimensionalDataSpace 214 10.6.2 WondersoftheCovarianceMatrix 215 10.6.3 DemonstrationofPrincipalComponentAnalysis 218 10.6.4 PCAExercises 219 10.7 CodeListings 220 11 Neural Networks and Machine Learning 224 11.1 PartI:BiologicalandArtificialNeuralNetworks 225 11.1.1 ArtificialNeuralNetworks 226 11.2 ASimpleNeuralNetwork 226 11.2.1 CodingANeuron 227 11.2.2 BuildingASimpleNetwork 227 11.2.3 TrainingASimpleNetwork 228 11.2.4 DecreasingtheError 230 11.2.5 CodingandRunningASimpleNetwork 232 11.3 AGraphicalDeepNet 232 11.4 PartII:MachineLearningSoftware 234 11.4.1 TensorFlowInstallationandExecution 235 11.5 TensorFlowandSkLearnExamples 235 11.5.1 PreprocessingwithScikit-learn 238 11.5.1.1 GradientTape 239 11.5.2 LinearFittoHubble‚ÄôsData 239 11.6 MLClustering 240 11.6.1 ReadingFileswithPanda 242 11.6.2 ClusteringwithPerceptrons 242 11.6.3 ClusteringwithStochasticGradientDescent 243 11.7 Keras:Python‚ÄôsDeepLearningAPI 244 11.8 ImageProcessingwithOpenCV 244 xContents 11.8.1 BackgroundSubtraction 246 11.9 ExploreMLDataRepositories 247 11.10 CodeListings 247 12 Quantum Computing (G.",8360
Contents,"He, Coauthor) 254 12.1 DiracNotationinQuantumMechanics 254 12.2 FromBitstoQubits 255 12.2.1 MultipleQubitStates 256 12.3 EntangledandSeparableStates 257 12.3.1 PhysicsExercise:TwoEntangledDipoles 258 12.4 LogicGates 260 12.4.1 1-QubitGates 261 12.4.2 2-QubitGates 262 12.4.3 EntanglementviaGates 263 12.4.4 3-QubitGates 264 12.5 AnIntrotoQCProgramming 264 12.5.1 HalfandFullAdders 269 12.6 Accessingthe IBM Quantum Computer 270 12.6.1 IBMQuantumComposer 270 12.7 QiskitPlusIBMQuantum 272 12.7.1 AFullAdder 274 12.7.2 IBMQuantumExercises 275 12.8 TheQuantumFourierTransform 275 12.8.1 1-QubitQFT 276 12.8.2 2-QubitQFT 276 12.8.3 n-QubitQFT ‚äô277 12.9 Oracle +Diffuser =Grover‚ÄôsSearchAlgorithm 278 12.9.1 Grover‚ÄôsImplementation 280 12.10 Shor‚ÄôsFactoring ‚äô281 12.11 CodeListings 284 Part III Applications 289 13 ODE Applications; Eigenvalues, Scattering, Trajectories 291 13.1 QuantumEigenvaluesforArbitraryPotentials 291 13.1.1 Model:NucleoninaBox 292 13.2 Algorithm:ODESolver +Search 293 13.2.1 NotRecommended:MatchlessSearching 294 13.2.2 NumerovAlgorithmforSchr√∂dingerODE‚®Ä294 13.2.3 Implementation:EigenvaluesviaODESolver +BisectionAlgorithm 295 13.2.4 Explorations 296 13.3 ClassicalChaoticScattering 296 13.3.1 ModelandTheory 297 13.3.2 Implementation 298 13.3.3 Assessment 299 Contents xi 13.4 ProjectileMotionwithDrag 299 13.4.1 Assessment 300 13.5 2-and3-BodyPlanetaryOrbits 301 13.5.1 PlanetsviaTwoofNewton‚ÄôsLaws 301 13.5.2 TheDiscoveryofNeptune 302 13.6 CodeListings 303 14 Fractals and Statistical Growth Models 307 14.1 TheSierpi¬¥ nskiGasket 308 14.1.1 MeasuringFractalDimension 309 14.2 GrowingPlants 310 14.2.1 Self-AffineConnection 310 14.2.2 Barnsley‚ÄôsFern 311 14.2.3 Self-AffineTrees 312 14.3 BallisticDeposition 312 14.4 LengthofBritishCoastline 313 14.4.1 BoxCountingAlgorithm 314 14.4.2 CoastlineExercise 315 14.5 CorrelatedGrowth 317 14.6 Diffusion-LimitedAggregation 318 14.6.1 FractalofDLAorPollock 319 14.7 FractalsinBifurcations 320 14.8 CellularAutomataFractals 320 14.9 PerlinNoiseAddsRealism ‚äô321 14.9.1 RayTracingAlgorithms 323 14.10 CodeListings 324 15 Nonlinear Population Dynamics 329 15.1 TheLogisticMap,ABugPopulationModel 329 15.1.1 ExploringMapProperties 331 15.1.1.1 StablePopulations 331 15.1.2 FixedPoints 332 15.1.3 PeriodDoubling,Bifurcations 332 15.1.4 MappingImplementation 333 15.2 Chaos 333 15.3 BifurcationDiagrams 333 15.3.1 BifurcationDiagramImplementation 335 15.3.2 FeigenbaumConstants 335 15.3.3 OtherMaps 336 15.4 MeasuresofChaos 336 15.4.1 LyapunovCoefficients‚®Ä336 15.4.2 ShannonEntropy 338 15.5 CoupledPredator‚ÄìPreyModels‚®Ä338 15.5.1 Lotka‚ÄìVolterraModel 339 15.5.2 Predator‚ÄìPreyChaos 340 15.5.3 LVMwithPreyLimit 342 xiiContents 15.5.4 LVMwithPredationEfficiency 342 15.5.5 LVMImplementationandAssessment 343 15.5.6 TwoPredators,OnePrey 344 15.6 CodeListings 344 16 Nonlinear Dynamics of Continuous Systems 348 16.1 TheChaoticPendulum 348 16.1.1 FreePendulumOscillations 349 16.1.2 AnalyticSolutionasEllipticIntegrals 349 16.1.3 FreePendulumImplementationandTest 350 16.2 PhaseSpace 351 16.3 ChaoticExplorations 354 16.3.1 PhaseSpaceWithoutVelocities 356 16.3.2 ChaoticBifurcations 357 16.3.3 FourierorWaveletAnalysis 357 16.4 OtherChaoticSystems 358 16.4.1 TheDoublePendulum 358 16.4.2 Billiards 359 16.4.3 MultipleScatteringCenters 360 16.4.3.1 HardDiskScattering 361 16.4.4 LorenzAttractors 361 16.4.5 vanderPoolOscillator 363 16.4.6 TheDuffingOscillator 363 16.5 CodeListings 364 17 Thermodynamics Simulations and Feynman Path Integrals 365 17.1 AnIsingMagneticChain 365 17.1.1 StatisticalMechanics 367 17.1.1.1 AnalyticSolution 367 17.2 MetropolisAlgorithm 368 17.2.1 MetropolisExercise 369 17.2.2 EquilibrationandThermodynamicProperties 370 17.2.3 Explorations 371 17.3 FastEquilibrationviaWang‚ÄìLandauSampling ‚äô372 17.3.1 WLSImplementation 373 17.4 PathIntegralQuantumMechanics ‚äô374 17.4.1 Bound-StateWaveFunction 376 17.5 LatticePathIntegration 377 17.5.1 ATime-SavingTrick 380 17.6 Implementation 381 17.6.1 PathIntegrationExercise 382 17.6.2 QuantumBouncer ‚äô383 17.6.3 PathIntegralBouncerExercises 384 17.7 CodeListings 385 Contents xiii 18 Molecular Dynamics Simulations 391 18.1 MD VersusThermodynamics 394 18.2 Initial,Boundary,andLarge rConditions 394 18.3 VerletAlgorithms 396 18.3.1 ImplementationandExercise 397 18.3.2 Analysis 398 18.4 MDfor16Particles 400 18.5 CodeListing 402 19 General Relativity 408 19.1 Einstein‚ÄôsFieldEquations 408 19.1.1 CalculatingtheRiemannandRicciTensors 410 19.1.2 RiemannandRicciTensorProblems 410 19.1.3 EventHorizons 411 19.2 GravitationalDeflectionofLight 412 19.2.1 GravitationalLensing 413 19.3 PlanetaryOrbitsinGRGravity 414 19.3.1 Newton‚ÄôsPotentialCorrected 414 19.3.2 OrbitComputationviaEnergyConservation 414 19.3.3 PrecessionofthePerihelionofMercury 416 19.4 VisualizingWormholes 418 19.5 Problems 420 19.6 CodeListings 420 20 Integral Equations 425 20.1 NonlocalPotentialBinding 425 20.2 Momentum-SpaceSchr√∂dingerEquation 425 20.2.1 IntegraltoMatrixEquations 426 20.2.2 Delta-ShellPotential 428 20.2.3 WaveFunction(Exploration) 429 20.3 ScatteringinMomentumSpace ‚äô429 20.3.1 Schr√∂dingertoLippmann‚ÄìSchwingerEquation 429 20.3.2 SingularIntegralEvaluations 430 20.3.3 SingularIntegralEquationstoMatrixEquations 431 20.3.4 Solution 432 20.3.5 Exercises 433 20.3.6 ScatteringWaveFunction(Exploration) 434 20.4 CodeListings 434 Part IV PDE Applications 437 21 PDE Review, Electrostatics and Relaxation 439 21.1 Review 439 xivContents 21.2 Laplace‚ÄôsEquation 441 21.2.1 FourierSeriesSolution 442 21.2.2 FourierSeriesasanAlgorithm 443 21.3 Finite-DifferenceAlgorithm 444 21.3.1 RelaxationandOverrelaxation 446 21.4 AlternateCapacitorProblems 447 21.4.1 Implementation 449 21.5 ElectricFieldVisualization 449 21.6 CodeListings 450 22 Heat Flow and Leapfrogging 452 22.1 TheParabolicHeatEquation 452 22.1.1 SolutionasAnalyticExpansion 453 22.2 TimeStepping(Leapfrog)Algorithm 454 22.2.1 VonNeumannStabilityCondition 455 22.2.2 Implementation 456 22.2.3 AssessmentandVisualization 456 22.3 Newton‚ÄôsRadiativeCooling 457 22.4 TheCrank‚ÄìNicolsonAlgorithm 458 22.4.1 SolutionviaTridiagonalMatrix ‚äô460 22.4.2 Crank‚ÄìNicolsonImplementation 461 22.5 CodeListings 462 23 String and Membrane Waves 464 23.1 AVibratingString‚ÄôsHyperbolicWaveEquation 464 23.1.1 SolutionasNormal-ModeExpansion 465 23.2 Time-SteppingAlgorithm 466 23.3 vonNeumannStabilityAnalysis 468 23.3.1 ImplementationandAssessment 469 23.4 BeyondTheSimpleWaveEquation 469 23.4.1 IncludingFriction 469 23.4.2 IncludingVariableTensionandDensity 470 23.4.3 WavesonCatenary 471 23.4.4 CatenaryAssessment 472 23.4.5 IncludingNonlinearTerms 473 23.5 VibratingMembrane(2DWaves) 474 23.6 AnalyticalSolution 475 23.7 NumericalSolution 476 23.8 CodeListings 478 24 Quantum Wave Packets and EM Waves 480 24.1 Time-DependentSchr√∂dingerEquation 480 24.2 Split-TimeAlgorithm 482 24.2.1 Implementation 482 24.2.1.1 Animation 483 24.2.2 WavePacketsinOtherWells 484 Contents xv 24.3 SpecialSchr√∂dingerAlgorithm 484 24.4 QuantumChaos 485 24.4.1 QuantumBilliards 486 24.4.2 ThreeDisksScattering 487 24.5 E&MWaves:FiniteDifferenceTimeDomain 488 24.6 Maxwell‚ÄôsEquations 488 24.7 Split-TimeFDTD 489 24.7.1 ImplementationandAssessment 491 24.8 MoreE&MProblems 492 24.8.1 CircularlyPolarizedWaves 492 24.8.2 WavePlates 493 24.8.3 AlgorithmandExercise 494 24.8.4 TwinLeadTransmissionLine 495 24.9 CodeListings 496 25 Shock and Soliton Waves 501 25.1 TheContinuityandAdvectionEquations 502 25.2 ShockWavesviaBurgers‚ÄôEquation 503 25.2.1 Lax‚ÄìWendroffAlgorithm 504 25.2.2 ImplementationandAssessment 505 25.3 IncludingDispersion 505 25.4 KdeVSolitons 506 25.4.1 AnalyticSolution 507 25.4.2 Algorithm 508 25.4.3 Implementation 509 25.4.4 Exploration:PhaseSpaceSolitonsandSolitonCrossings 509 25.5 PendulumChainSolitons 510 25.5.1 IncludingDispersion 511 25.6 ContinuumLimit,theSine-GordonEquation 512 25.6.1 AnalyticSolution 513 25.6.2 Numeric2DSolitons(Pulsons) 513 25.6.3 Implementation 514 25.7 CodeListings 516 26 Fluid Hydrodynamics 518 26.1 Navier‚ÄìStokesEquation 518 26.2 FlowThroughParallelPlates 520 26.3 Navier‚ÄìStokesDifferenceEquation 522 26.3.1 SuccessiveOverrelaxationAlgorithm 523 26.4 VorticityFormofNavier‚ÄìStokesEquation 523 26.4.1 VorticityDifferenceEquation 525 26.4.2 BeamBoundaryConditions 526 26.5 AssessmentandExploration 527 26.5.1 Explorations 529 26.6 CodeLisitings 529 xviContents 27 Finite Element Electrostatics ‚äô531 27.1 ThePotentialofTwoMetalPlates 531 27.1.1 AnalyticSolution 531 27.2 FiniteElementMethod 532 27.2.1 WeakFormofPDE 532 27.2.2 GalerkinSpectralDecomposition 533 27.2.3 SolutionviaLinearEquations 534 27.2.4 ImposingtheBoundaryConditions 536 27.3 1DFEMProblems 536 27.4 2DFEMExercises 537 27.5 CodeListings 539 Appendix Codes and Animations 543 References 546 Index 555",8731
Preface,"xvii Preface Whenthefirsteditionof Computational Physics waspublishedin1997,whowouldhave thought that we would be doing it again in 2024? Back then, we hoped that our writing might encourage the inclusion of more computation into the physics curriculum. Now, computationalphysics(CP)coursesaretaughtwidely(ifonlymorewithourbook.).Yet, whenMartinPreussofWileyaskedifwemightbeinterestedinafourthedition,thethought ofgettingtoworkwithsomerecentdevelopmentsincomputationwasjusttooappealing forustoresist.Andso,hereweare. And who would have thought that our youngest coauthor, Christian Bordeianu, who joinedusforthesecondandthirdeditions,wouldnotbearoundforthisone.Itissosad thatwemustwritewithouthisenthusiasm,knowledge,goodnature,andfriendship. Thiseditioncontinueswiththethreemainthemesofpreviousones: 1) ThatthereisvaluewhenfirstlearningCPtosurveyabroadrangeoftopicsinvarious specialties. 2) ThatthebestwaytolearnCPisbydoingitonacomputerwithexamples,exercises,and problems. 3) That CP is part of computational science, which means that we are presenting CP as amixtureofphysics,appliedmathematics,andcomputerscience,tryingnottoshort- changethelattertwo. Thiseditionhasentirelynewchaptersonneuralnetworksandmachinelearning,quan- tumcomputing(withGuangliangHe),andgeneralrelativity,aswellasanexpandedcov- erageofprincipalcomponentanalysesandPythonprogramming.Finally,therehasbeen editingthroughoutthetexttoimproveclarityandorganization.Thiseditionalsocontin- uesouradvocacyofacompiled-typeprogramminglanguage,andespeciallyPython,asthe bestvehicleforlearningCP.ThisisincontrasttocomputingenvironmentssuchasMat- labandMathematica,wherethemathematics,algorithms,anddetailsarekept‚Äúunderthe hood.‚ÄùIfcomputationalresultsaretobescientificallysound,webelieveitrequiresaphysi- cisttounderstandthealgorithms,theirconnectionstomathematics,physics,thelogicofa program,and,especially,thelimitsanduncertaintiesofthecomputation.Nevertheless,we appreciatehowtime-consumingandfrustratingdebuggingprogramsmaybe,especiallyfor beginners,andsoweprovidethereaderwithalargenumberofcodesinthetextandonline at:sites.science.oregonstate.edu/ ‚àºlandaur/Books/Problems/Codes/.Ourhopeisthatthis xviii Preface leaves time for exploration, extensions, and analysis. It also provides experience in the modern work environment, in which one must incorporate new developments into the preexistingdevelopmentsofothers. Tomakeroomforthenew,wehave(sadly)removedsomeoftheoldonesthatwerein previouseditions.However,thosematerialscanstillbefoundinaJupyterNotebookversion of the previous edition online at sites.science.oregonstate.edu/‚àºlandaur/Books/CPbook/ eBook/. Therearealsovideolecturesatsites.science.oregonstate.edu/‚àºlandaur/Books/CPbook/ eBook/Lectures/andonYouTube‚Äôs Landau Computational Physics Course atwww.youtube. com/playlist?list =PLnWQ_pnPVzmJnp794rQXIcwJIjwy7Nb2U. Thesevideosandtheconcordantslidescovermostofthetopicsinthetextandmaybe helpfulinblendedorhybridcourses. Wehopeyouenjoyourworkandwelookforwardtoyourcomments. Tucson,May2024 Rubin H. Landau, Tucson Medellin,May2024 Manuel J. P√°ez, Medellin Planning the first edition.",3104
Acknowledgments,"xix Acknowledgments Immature poets imitate; mature poets steal . ‚ÄîT.S.Elliot Previouseditionsofthisbookandourcomputationalphysicscourseswouldnothavebeen possiblewithoutfinancialsupportfromtheNationalScienceFoundation‚ÄôsCCLI,EPIC,and NPACIprograms,andthePhysicsDepartmentofOregonStateUniversity.Thankyou,we hopewehavemadeyouproud. Our CP developments have followed the pioneering paths paved by Thompson, Gould and Tobochnik, Christian, and Press et al. Indubitably, we have borrowed material from themandmadeitourownwithnofurtherthought. WewishtoacknowledgevaluablecontributionsbyGuangliangHe,HansKowallik,Sally Haerer (video lecture modules), Paul Fink (deceased) Oscar A. Restrepo, Jaime Zuluaga, andHenriJansen.Itisourpleasuretoacknowledgetheinvaluablefriendship,encourage- ment,helpfuldiscussions,andexperienceswehavehadwithmanycolleaguesandstudents over the years. We are particularly indebted to Guillermo Avenda√±o-Franco, Saturo S. Kano, Melanie Johnson, Jon Maestri (deceased), David McIntyre, Shashikant Phatak, ViktorPodolskiy,C.E.Yaguna,andZlatcoDimcovic.And,finally,it‚Äôsbeenapleasureto workwithMartinPreuss,AswiniMurugadass,andJudyHowarthatWileyagain. Inspiteofeveryone‚Äôsbestefforts,therearestillerrorsandconfusingstatementsinthe bookandcodesforwhichwearetoblame.",1274
Part I Basics,1 Part I Basics,15
Chapter 1 Introduction. 1.2 This Books Subjects,"3 1 Introduction Beginnings are hard . ‚ÄîChaim PotokNothing is more expensive than a start . ‚ÄîFriedreich Nietzsche We start this book with a description of how computational physics (CP) Ô¨Åts into the broader Ô¨Åeld of computational science, and how CP Ô¨Åts into physics. We describe the subjects we cover, the coordinated video lectures, and how the book may be used in a CP course. Finally, we get down to business by discussing the Python language and its many packages, some of which we‚Äôll use. In Chapter 2we give an introduction to Python programming, and in Chapter 7we examine Python‚Äôs treatment of matrices . 1.1 Computational Physics and Science AsillustratedinFigure1.1,weviewCPasabridgethatconnectsphysics,computerscience (CS),andappliedmathematics.WhereasCSstudiescomputingforitsownintrinsicinter- est and develops the hardware and software tools that computational scientists use, and whileappliedmathematicsdevelopsandstudiesthealgorithmsthatcomputationalscien- tists use, CP focuses on using all of that to do better and new physics. Furthermore, just asanexperimentalistmustunderstandmanyaspectsofanexperimenttoensurethather measurementsareaccurateandbelievable,soshouldeveryphysicistundertakingacom- putation understand the CS and math well enough to ensure that her computations are accurateandprecise. AsCPhasmatured,weseeitnotonlyasabridgeamongdisciplines,butalsoasaspecialty containing core elements of its own, such as data-mining tools, computational methods, andaproblem-solvingmindset.Tous,CP‚Äôscommonalityoftoolsandviewpointwithother computationalsciencesmakesitagoodtraininggroundforstudents,andawelcomechange fromtheoverspecializationfoundinsomuchofphysics. As part of this book‚Äôs emphasis on problem solving, we strive to present the subjects withinaproblem-solvingparadigm,asillustratedontherightofFigure1.1.Oursisahands- on, inquiry-based approach in which there are problems to solve, a theory or an appro- priatemodel to apply,an appropriatealgorithmto use, andan assessment ofthe results. Computational Physics: Problem Solving with Python ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH",2171
1.5 Our Language The Python Ecosystem,"41 Introduction Scientific truth Scientific problem solvingMath techniquesPhysics application C P CS hard/software Simulation TheoryExperiment Figure 1.1 On the left a view of computational physics as a discipline encompassing physics, applied mathematics, and computer science. On the right is a broader view of computational physics Ô¨Åtting into various components of scientiÔ¨Åc problem solving. Thisapproachcanbetracedbacktothepost-WorldWarIIresearchtechniquesdevelopedat USnationallaboratories.Theydeservethecreditforextendingthetraditionalexperimental andtheoreticalapproachesofphysicstoalsoincludesimulation.Recentdevelopmentshave alsointroducedpowerfuldataminingtools,suchasneuralnetworks,artificialintelligence, andquantumcomputing. 1.2 This Book‚Äôs Subjects WedonotintendthisbooktobeascholarlyexpositionofthefoundationsofCP.Instead, we employ a learn-by-doing approach with many exercises, problems, and ready-to-run codes.WesurveymanyofthesubjectsthatconstituteCPatalevelappropriateforunder- graduateeducation,exceptmaybeforthelatterpartsofsomechapters.Ourexperienceis thatmanygraduatestudentsandprofessionalsmayalsobenefitfromthissurveyapproach inwhichabasicunderstandingofabroadrangeoftopicsfacilitatesfurtherin-depthstudy. Chapters 1‚Äì8 cover basic numerics, ordinary differential equations with (many) appli- cations,matrixcomputingusingwell-developedlinearalgebralibraries,andMonte-Carlo methods. Some powerful data mining tools such as discrete Fourier transforms, wavelet analysis,principalcomponentanalysis,andneuralnetworksarecoveredinthemiddleof thebook. A traditional way to view the materials in this text is in terms of their use in courses. Foraone-quarterclass,weusedapproximatelythefirst-thirdofthetext,withitsemphasis oncomputingtoolfamiliaritywithacompiledlanguage[CPUG,2009].Thelattertwo-thirds ofthetext,withitsgreateremphasisonphysics,hastypicallybeenusedinatwo-quarter (20-week)course.Whatwithmanyofthetopicstakenfromresearch,thesematerialscan easilybeusedforafullyear‚Äôscourse,andforsupplementaryresearchprojects. 1.3 Video Lecture Supplements As an extension of the concept of a ‚Äútext,‚Äù we provide some 60 video lecture modules (asinFigure1.2)thatcoveralmosteverytopicinthe 1.4 This Book‚Äôs Codes and Problems 5 Figure 1.2 A screenshot from a lecture module showing a dynamic table of contents, a talking head, video controls, a slide with live scribbling, and some old man. (Originally in Flash, now as mpegs.) a mix of Flash, Java, HTML, and mpeg, but with Flash no longer supported, we provide themasmp4videosandPDFslides.Theyareavailableonourwebsite:https://sites.science .oregonstate.edu/~landaur/Books/CPbook/eBook/Lectures, as well as on our YouTube channelunder Landau Computational Physics Course :https://www.youtube.com/playlist? list=PLnWQ_pnPVzmJnp794rQXIcwJIjwy7Nb2U. Thevideolecturescanbeusedtoprevieworreviewmaterials,aspartofanonlinecourse, orinablendedcourseinwhichtheyreplacesomelectures,therebyfreeinguptimeforlab workwiththeinstructor. 1.4 This Book‚Äôs Codes and Problems Separatefromtheproblemsandexercisesthroughoutthetext,almosteverychapterstarts off with a keynote ‚Äú Problem‚Äù that leads into the various steps in computational prob- lemsolving(Figure1.1).Theadditionalproblemsandexercisesdistributedthroughoutthe chaptersareessentialingredientsforlearning,andaremeanttobeworkedthrough.This entailsstudyingthetext,writing,debugging,andrunningprograms,visualizingtheresults, andexpressinginwordswhathasbeenperformed,andwhatcanbeconcluded.Weasked ourstudentstowriteupminilabreportscontaining Equationssolved Numericalmethod Codelisting Visualization Discussion Critique Although we recognize that programming is a valuable skill for scientists, we also knowthatitisincrediblyexactingandtime-consuming.Inordertolightentheworkload, we provide programs for most of the problems in the text ,bothattheendofeachchapterand onlineat:",3875
1.6 The Easy Way Python Distributions,"61 Introduction A complete list is given in the Appendix. We recommend that these codes be used as guidesforthereaderwhenwritingtheirownprograms,or,attheleast,testedandextended tosolvetheproblemathand.Wehavebeentoldthatlearninghowtousesomeoneelse‚Äôs codeisavaluableworkplaceskilltodevelop;aswithprogramsencounteredinaworkplace, theyshouldbeunderstoodbeforeuse. 1.5 Our Language: The Python Ecosystem Thecodesinthiseditionof Computational Physics employthecomputerlanguage Python. PreviouseditionshaveemployedJava,Fortran,andC,andusedpost-computationtoolsfor visualization.1Python‚Äôscombinationoflanguagepluspackagesnowmakesitthestandard fortheexplorativeandinteractivecomputingthattypifiespresent-dayscientificresearch. Althoughvaluableforresearch,wehavealsofoundPythontobethebestlanguageyet forteachingandlearningCP.Itisfree,robust(programsdon‚Äôtcrash),portable(programs run without modifications on various devices), universal (available for most every com- putersystem),hasacleansyntaxthatpermitsrapidlearning,hasdynamictyping(changes data types automatically as needed), has high-level, built-in data types (such as complex numbers),andbuilt-invisualization.Furthermore,becausePythonisinterpreted,students canlearnthelanguagebyexecutingandanalyzingindividualstatementswithinaninter- activeshell,orwithinanotebookenvironment,orbyrunninganentireprograminonefell swoop.Finally,itiseasytousethemyriadoffreePythonpackagessupportingnumerical algorithms,state-of-the-artvisualizations,aswellasspecializedtoolkitsthatrivalthosein MatlabandMathematica/Maple.Anddidwemention,allofthisisfree? Althoughwedonotexpectthereaderstobeprogrammingexperts,itisessentialtobeable torunandmodifythesamplecodesinthisbook.ForlearningPython,werecommendthe onlinetutorials[PyTut,2023;Pguide,2023;Plearn,2023],thebook[Langtangen,2016],and themanybooksinthe‚ÄúPythonforScientistsandEngineers‚Äùgenre.Forgeneralnumerical methods,[Press et al.,2007]isthestandard,andfuntoread.TheNITSDigitalLibraryof MathematicalFunctions[NIST,2022]isaconvenientreferenceformathematicalfunctions andnumericalmethods. PythonhasdevelopedrapidlysinceitsfirstimplementationinDecember1989[History, 2022].TherapiddevelopmentsofPythonhaveledtoasuccessionofnewversionsandthe inevitableincompatibilities.Thecodespresentedinthebookareinthepresentstandard, Python3.ThemajordifferencefromPython2istheprintstatement: 1>>> print ‚ÄôHello, World.‚Äô #P y t h o n2 >>> print(‚ÄôHello, World.‚Äô ) #P y t h o n3 1.6 The Easy Way: Python Distributions ThePythonlanguageplusitsfamilyofpackagescompriseaveritableecosystemforcom- puting. A package, or library, or module, is a collection of related methods, or classes of 1 Allofourcodes,eventheoldones,areavailableonline. 1.6 The Easy Way: Python Distributions 7 methods,thatareassembledanddesignedtoworktogether.Inclusionoftheappropriate packagesextendsthelanguagetomeetthespecializedneedsofvariousscienceandengi- neering disciplines [CiSE, 2015]. The Python Package Index [PyPi, 2023], a repository of freePythonpackages,currentlycontains425,320projectsand7,313,641files.Inthisbook, weuse: Jupyter Notebooks: Aweb-based,interactivePythoncomputingenvironmentcombining live code, type-set equations, narrative text, visualizations, and whatever. Some of our programs( .ipynbsuffix)weredevelopedinJupyter,andourprogramsusingVpython work only within Jupyter. There is a previous edition of this text in notebook form at sites.science.oregonstate.edu/~landaur/Books/CPbook/eBook. TheinteractivePythonshell, IPythoncanalsobeusedwithinJupyter. Numpy (Numerical Python): A comprehensive library of mathematical functions, random number generators, linear algebra routines, Fourier transforms, and most everything else. Permits the use of fast, high-level multidimensional arrays (explained inChapter7).Thesuccessortoboth NumericandNumArray,NumPyisusedbyVisual andMatplotlib. Matplotlib (Mathematics Plotting Library): A 2D and 3D graphics library that uses NumPy,producespublication-qualityfiguresinavarietyofhardcopyformats,andthat permitsinteractivegraphics.SimilartoMatlab‚Äôsplotting(exceptMatplotlibisfreeand doesn‚Äôtneeditslicenserenewedyearly). Pandas (Python Data Analysis Library): A collection of high-performance, user- friendlydatastructures,anddataanalysistools(usedinChapter11). SymPy (Symbolic Python): A system for symbolic mathematics using pure Python (no external libraries) that provides a simple computer algebra system including calculus, differential equations, etc. Similar to Maple or Mathematica, with the Sage packagebeingevenmorecomplete.ExamplesinSection2.3.6. Visual (Vpython): The Python language plus the no-longer-supported Visualgraph- ics module (superseded by GlowScript). Particularly easy for creating educational 3D demonstrations and animations. Still useful as Web Vpython and within Jupyter Notebooks. Although most Python packages are free, there is true value for both users and ven- dors to distribute a collection of packages that have been engineered and tuned to work welltogether,andthatcanbeinstalledinonefellswoop.(ThisissimilartowhatRedHat andDebiandistributionsdoforLinux.)Thesedistributionscanbethoughtofascomplete, Pythonecosystemsandarehighlyrecommended.Inparticular,allyoureallyneedtodoto getstartedwithPythoncomputingforthisbookistoload: AnaConda: A free Python distribution including more than 8000 packages for science, mathematics,engineering,machinelearning,anddataanalysis.Anacondainstallsinits owndirectoryandsorunsindependentlyfromotherPythoninstallationsonyourcom- puter.Goto https://www.anaconda.com/products/distributiontodownloadAnaconda. Onceyouinstall Anaconda,theNavigatorshouldopen,anditwillletyouchooseallthat youwillneed. Spyder IDE: TheScientificPYthonDevelopmentEnviRonment.AnIntegratedDevelop- mentEnvironment(IDE)withadvancedediting,interactivetestingofcode,debugging, andmore. 81 Introduction Jupyter Notebook: TheWeb-basedinteractivecomputingnotebookenvironmentusedfor editingandrunningtype-set-likedocuments,whilealsorunningPythoncodewithinthe documents.Aswehavealreadysaid,anotebook( .ipyn)versionofanearliereditionof thistextisat sites.science.oregonstate.edu/~landaur/Books/CPbook/eBook. Powershell Prompt: Apowerfulterminalthatruns condacommandsundertheWindows shellenvironments cmd.exe(CommandPrompt)and powershell.exe .Applehasa Ter- minalappwhereyouwillfindacommandprompt. Conda:ApackagemanagementandenvironmentsystemincludedinAnacondathatfinds, installs,andupdatespackagesandtheirdependenciesforyou. InChapter11wedescribehowtoloadandrunGoogle‚Äôs TensorFlow packageformachine learning, and in Chapter 12 we describe how to load and run the Quantum Computing packages, Cirq, IBM Quantum ,and Qiskit.",6648
Chapter 2 Software Basics. 2.1 Making Computers Obey,"9 2 Software Basics This chapter discusses the computing basics of communications, number representations, Python programming, and visualizations. Since we want to do science, there is a particular emphasis on the limits of Ô¨Çoating point arithmetic . 2.1 Making Computers Obey Thebestprogramsarewrittensothatcomputingmachinescanperformthemquickly andsothathumanbeingscanunderstandthemclearly.Aprogrammerisideallyan essayistwhoworkswithtraditionalaestheticandliteraryformsaswellasmathemati- calconcepts,tocommunicatethewaythatanalgorithmworksandtoconvinceareader thattheresultswillbecorrect. ‚ÄîDonaldE.Knuth Asanthropomorphicasyourviewofyourcomputermaybe,keepinmindthatcomputers alwaysdoexactlyastheyaretold.Thismeansthatyoumusttellthemexactlyeverything youwantthemtodo.Ofcourse,theprogramsyourunmayhavetobeatsuchahighlevel withsuchconvolutedlogicthatyoumaynothavetheendurancetofigureoutthedetailsof justwhattheyaretellingthecomputertodo,butitisalwayspossibleinprinciple(except maybenotwithAI).Soyourfirst problemistoobtainenoughunderstandingsothatyou feelsufficientlyincontrol,nomatterhowillusionary,tofigureoutwhatthecomputeris doing. Beforeyoutellthecomputertoobeyyourorders,youneedtounderstandthatlifeisnot simpleforcomputers.Theinstructionstheyunderstandareina basicmachinelanguage1 thattellsthehardwaretodothingslikemoveanumberstoredinonememorylocationto anotherlocation,ortodosomesimplebinaryarithmetic.Veryfewcomputationalscientists talk to computers in a language computers can understand. When writing and running programs, we usually communicate through shells,i nhigh-levellanguages (Python, Java, Fortran, and C), or through problem-solving environments (Maple, Mathematica, and Matlab). Eventually, our commands or programs are translated into the basic machine languagethatthehardwareunderstands. 1 TheBeginner‚ÄôsAll-PurposeSymbolicInstructionCode(BASIC)programminglanguageoftheoriginal PCsshouldnotbeconfusedwithbasicmachinelanguage. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 102 Software Basics Ashellisacommand-lineinterpreter ,thatis,asetofsmallprogramsrunbyacomputer thatrespondstothecommands(thenamesoftheprograms)thatyoukeyin.Usuallyyou open a special window to access the shell, and this window is called a shell as well. It is helpfultothinkoftheseshellsastheouterlayersofthecomputer‚Äôsoperatingsystem(OS)in Figure2.1,withinwhichliesa kernelofelementaryoperations.(Theuserseldominteracts directlywiththekernel,exceptpossiblywheninstallingprogramsorwhenbuildinganOS fromscratch.)Itisthejoboftheshelltorunprograms,compilers,andutilitiesthatdothings likemovingandcopyingfiles.Therecanbedifferenttypesofshellsonasinglecomputer, ormultiplecopiesofthesameshellrunningatthesametime. Operatingsystemshavenamessuchas Unix,Linux,DOS,MacOS ,andMSWindows .An operatingsystem isnomorethanagroupofprogramsusedbythecomputertocommunicate withusersanddevices,tostoreandreaddata,andtoexecuteprograms.TheOStellsthe computerwhattodoinanelementaryway.TheOSviewsyou,otherdevices,andprograms asinputdataforittoprocess;inmanyways,itistheindispensableofficemanager.Whileall thismayseemcomplicated,thepurposeoftheOSistoletthecomputerdothenitty-gritty worksothatyoucanthinkhigher-levelthoughtsandcommunicatewiththecomputerin somethingclosertoyournormaleverydaylanguage. When you submit a program to your computer in a high-level language , the computer mayuseacompilertoprocessit.A compilerisanotherprogramthattreatsyourprogram as a foreign language and uses a built-in dictionary and set of rules to translate it into basicmachinelanguage.Asyoucanprobablyimagine,thefinalsetofinstructionsisquite detailed and long, and the compiler may make several passes through your program to decipheryourlogicandtranslateitintoafastcode.Thetranslatedstatementsforman object orcompiledcode,andwhen linkedtogetherwithotherneededsubprograms,forma load modulethatcanbe loadedintothecomputer‚Äôsmemoryandread,understood,andfollowed bythecomputer. Languages such as FortranandCuse compilers to read your entire program and then translateitintobasicmachineinstructions.InterpretedlanguagessuchasPython, BASIC, andMapletranslateor interpreteachlineofyourprogramasitisentered,andthuspermit GUI Shell Utilities Kernel WindowsHardware AppsProgram developmentFigure 2.1 A schematic view of a computer‚Äôs kernel and shells. The hardware is in the center surrounded by increasingly higher-level software.",4476
2.2.1 IEEE FloatingPoint Numbers,"2.2 Computer Number Representations 11 line-by-lineinteractions.Compiledlanguagesusuallyleadtomoreefficientprogramsand permittheuseofvastsubprogramlibraries.Interpretedlanguagesgiveamoreimmediate responsetotheuserandtherebyappear‚Äúfriendlier.‚ÄùThePythonandJavalanguagesare actuallyamixofthetwo.Whenyoufirstcompileyourprogram,Pythoninterpretsitinto anintermediate,universal bytecode,whichgetsstoredasa .pycor.pyofile.Thisfilecanbe transportedtoandusedonothercomputers,althoughnotwithdifferentversionsofPython. Then,whenyourunyourprogram,Pythonrecompilesthebytecodeintoamachine-specific andfast-runningcompiledcode. 2.2 Computer Number Representations Computersmaybepowerful,buttheyarefinite.Aproblemincomputerdesignishowto representanarbitrarynumberusingafiniteamountofmemoryspace,andthenhowtodeal withthelimitationsarisingfromthisrepresentation.Asaconsequenceofcomputermem- oriesbeingbasedonthemagneticorelectronicrealizationsofaspinpointingupordown, themostelementaryunitsofcomputermemoryarethetwobinaryintegers( bits)0and1. Thismeansthatallnumbersarestoredinmemoryin binaryform,thatis,aslongstringsof zerosandones.Accordingly, Nbitscanstoreintegersintherange [0,2N],yetbecausethe signoftheintegerisrepresentedbythefirstbit(azerobitforpositivenumbers),theactual rangeforN-bitintegersdecreasesto [0,2N‚àí1]. Longstringsofzerosandonesarefineforcomputers,butareawkwardforhumans.For thisreason,binarystringsareconvertedto octal,decimal,orhexadecimal numbersbefore theresultsarecommunicatedtopeople.Octalandhexadecimalnumbersarenicebecause theconversionmaintainsprecision,butnotallthatnicebecauseourdecimalrulesofarith- metic do not work for them. Converting to decimal numbers makes the numbers easier forustoworkwith,butunlesstheoriginalnumberisapowerof2,someprecisionislost. Adescriptionofaparticularcomputer‚Äôssystemorlanguagenormallystatesthe wordlength , thatis,thenumberofbitsusedtostoreanumber.Thelengthisoftenexpressedin bytes, (amouthfulofbits)where 1byte ‚â°1Bdef=8bits. Memoryandstoragesizesaremeasuredinbytes,kilobytes,megabytes,gigabytes,terabytes, andmegabytes(1015).Somecareshouldbetakenherebythosewhochosetocomputesizes indetailbecauseKdoesnotalwaysmean1000: 1Kdef=1KB=210bytes=1024bytes . (2.1) This is often (and confusingly) compensated for when memory size is stated in K, for example, 512K=29bytes=524,288bytes √ó1K 1024bytes. Conveniently,1byteisalsotheamountofmemoryneededtostoreasingleletterlike‚Äúa,‚Äù whichaddsuptoatypicalprintedpagerequiring ‚àº3kB. Thememorychipsinsomeolderpersonalcomputersused8-bitwords,withmodernPCs using64bits.Thismeantthatthemaximumintegerwasarathersmall27=128(7because 122 Software Basics 1bitisusedforthesign).Using64bitspermitsintegersintherange1‚Äì263‚âÉ1019.While at first this may seem like a large range, it really is not when compared to the range of sizesencounteredinthephysicalworld.Asacaseinpoint,thesizeoftheuniversecom- paredtothesizeofaprotoncoversascaleof1041.Tryingtostoreanumberlargerthanthe hardwareorsoftwarewasdesignedfor( overflow)wascommononoldermachines,butis lesssonow.Anoverflowissometimesaccompaniedbyaninformativeerrormessage,and sometimesnot.",3102
2.2.1 IEEE FloatingPoint Numbers,"2.2.1 IEEE Floating-Point Numbers Realnumbersarerepresentedoncomputersineither fixed-point orfloating-point notation. Fixed-point notation can be used for numbers with a fixed number of places beyond the decimalpoint(radix)orforintegers.Ithastheadvantagesofbeingabletouse two‚Äôscomple- mentarithmeticandbeingabletostoreintegersexactly.2Inthefixed-pointrepresentation withNbitsandwithatwo‚Äôscomplementformat,anumberisrepresentedas Nfix=sign√ó(ùõºn2n+ùõºn‚àí12n‚àí1+¬∑¬∑¬∑+ùõº020+¬∑¬∑¬∑+ùõº‚àím2‚àím), (2.2) wheren+m=N‚àí2.Thatis,1bitisusedtostorethesign,withtheremaining( N‚àí1)bits usedtostorethe ùõºivalues(thepowersof2areunderstood).Theparticularvaluesfor N,m, andnaremachine-dependent.Integersaretypically4bytes(32bits)inlengthandinthe range ‚àí2147483648 ‚â§4-Binteger ‚â§2147483647 . (2.3) Anadvantageoftherepresentation(2.2)isthatyoucancountonallfixed-pointnumbers having the same absolute error of 2‚àím‚àí1(the term left off the right-hand end of (2.2)). The corresponding disadvantage is that smallnumbers (those for which the first string ofùõºvaluesarezeros)havelarge relativeerrors.Forthatreason,relativeerrorsinthereal worldtendtobemoreimportantthanabsoluteones;integersareusuallyusedforcounting purposesandinspecialapplications(likebanking). Most scientific computations use double-precision floating-point numbers with 64b=8B.Thefloating-pointrepresentation ofnumbersoncomputersisabinaryversion ofwhat is commonlyknownas scientificorengineeringnotation . For example,the speed of lightc=+2.99792458 √ó10+8m/s in scientific notation and +0.299792458 √ó10+9or 0.299795498E09m/sinengineeringnotation.Ineachofthesecases,thenumberinfront iscalledthe mantissaandcontainsnine significantfigures .Thepowertowhich10israised iscalledthe exponent,withtheplussigninfrontasareminderthatthesenumbersmaybe negative. Floating-point numbers are stored on the computer as a concatenation (juxtaposition) ofasignbit,anexponent,andamantissa.Becauseonlyafinitenumberofbitsarestored, the set of floating-point numbers that the computer can store exactly, machine numbers (thehashmarksinFigure2.2),ismuchsmallerthanthesetofrealnumbers.Inparticular, machine numbers have a maximum and a minimum (the shading in Figure 2.2). If you 2T h etwo‚Äôscomplement ofabinarynumberisthevalueobtainedbysubtractingthenumberfrom2Nforan N-bitrepresentation.Becausethissystemrepresentsnegativenumbersbythetwo‚Äôscomplementofthe absolutevalueofthenumber,additionsandsubtractionscanbemadewithouttheneedtoworkwiththe signofthenumber. 2.2 Computer Number Representations 13 Figure 2.2 The limits of single-precision Ô¨Çoating-point numbers and the consequences of exceeding these limits (not to scale). The hash marks represent the values of numbers that can be stored; storing a number in between these values leads to truncation errors. The shaded areas correspond to over- and underÔ¨Çow.UnderflowTruncation Overflow Overflow 0 ‚Äì10+38‚Äì10+38‚Äì10‚Äì4510‚Äì45 exceedthemaximum,anerrorconditionknownas overflowoccurs;ifyoufallbelowthe minimum,anerrorconditionknownas underflowoccurs.Inthelattercase,thesoftware andhardwaremaybesetupsothatunderflowsaresettozerowithoutyourevenbeingtold.",3097
2.2.1 IEEE FloatingPoint Numbers,"Incontrast,overflowsusuallyhaltaprogram‚Äôsexecution. Theactualrelationbetweenwhatisstoredinmemoryandthevalueofafloating-point numberissomewhatindirect,withtherebeinganumberofspecialcasesandrelationsused overtheyears.Infact,inthepast,eachcomputerOSandeachcomputerlanguagecontained theirownstandardsforfloating-pointnumbers.Differentstandardsmeantthatthesame program running correctly on different computers could give different results. Although theresultsusuallywereonlyslightlydifferent,theusercouldneverbesureifthelackof reproducibilityofatestcasewasasaresultoftheparticularcomputerbeingusedortoan errorintheprogram‚Äôsimplementation. In1987,theInstituteofElectricalandElectronicsEngineers(IEEE)andtheAmerican NationalStandardsInstitute(ANSI)adoptedtheIEEE754standardforfloating-pointarith- metic.Whenthestandardisfollowed,youcanexpecttheprimitivedatatypestohavethe precisionandrangesgiveninTable2.1.Inaddition,whencomputersandsoftwareadhere to this standard, and most do now, you are guaranteed that your program will produce identicalresultsondifferentcomputers.Nevertheless,becausetheIEEEstandardmaynot producethemostefficientcodeorthehighestaccuracyforaparticularcomputer,some- timesyoumayhavetoinvokecompileroptionstodemandthattheIEEEstandardbestrictly Table 2.1 The IEEE 754 standard for primitive data types. Name Type Bits Bytes Range boolean Logical 11 8trueorfalse char String 16 2 ÃÅ‚ßµu0000ÃÅ‚ÜîÃÅ‚ßµuFFFFÃÅ(ISO Unicode) byte Integer 8 1 ‚àí128‚Üî+127 short Integer 16 2 -32,768‚Üî+32,767 int Integer 32 4 -2,147,483,648‚Üî+2,147,483,647 long Integer 64 8 -9,223,372,036,854,775,808‚Üî9,223,372,036, 854,775,807 float Floating 32 4 ¬±1.401298 √ó10-45‚Üî¬±3.402923 √ó10+38 double Floating 64 8 ¬±4.94065645841246544 √ó10-324‚Üî ¬±1.7976931348623157 √ó10+308 142 Software Basics followedforyourtestcases.Afteryouknowthatthecodeisokay,youmaywanttorunwith whatevergivesthegreatestspeedandprecision. ThereareactuallyanumberofcomponentsintheIEEEstandard,anddifferentcomputer orchipmanufacturersmayadheretoonlysomeofthem.Furthermore,asPythondevelops, it may not follow all standards, but it probably will in time. Normally, a floating-point numberxisstoredas xfloat=( ‚àí1)s√ó1.f√ó2e‚àíbias, (2.4) thatis,withseparateentitiesforthesign s,thefractionalpartofthemantissa f,andthe exponentialfield e.Allpartsarestoredinbinaryformandoccupyadjacentsegmentsofa single32-bitwordforsingles,ortwoadjacent32-bitwordsfordoubles.Thesign sisstored asasinglebit,with s=0or1forapositiveoranegativesign.Eightbitsareusedtostorethe exponente,whichmeansthat ecanbeintherange0 ‚â§e‚â§255.Theendpoints, e=0and e=255,arespecialcases(Table2.2). Normalnumbers have0<e<255,andwiththem,the conventionistoassumethatthemantissa‚Äôsfirstbitisa1,soonlythefractionalpart fafter thebinarypoint isstored.Therepresentationsfor subnormalnumbers andforthespecial casesaregiveninTable2.2. Note that the values ¬±INFand NaNare not numbers in the mathematical sense, that is, objects that can be manipulated or used in calculations to take limits and such. Rather, they are signals to the computer and to you that something has gone awry and that the calculationshouldprobablystopuntilyoustraightenthingsout.Incontrast,thevalue ‚àí0 canbeusedinacalculationwithnoharm.Somelanguagesmaysetunassignedvariables to‚àí0asahintthattheyhaveyettobeassigned,althoughitisbestnottocountonthat. Astheuncertainty(error)isonlyinthemantissaandnottheexponent,theIEEErepre- sentationsensurethatallnormalfloating-pointnumbershavethesamerelativeprecision. Becausethefirstbitofafloatingpointnumberisassumedtobe1,itdoesnothavetobe stored,andcomputerdesignersneedonlyrecallthatthereisa phantombit theretoobtain an extra bit of precision. During the processing of numbers in a calculation, the first bit ofanintermediateresultmaybecomezero,butthisischangedbeforethefinalnumberis stored.Torepeat,fornormalcases,theactualmantissa(1 .finbinarynotation)containsan implied1precedingthebinarypoint. Finally,inordertoguaranteethatthestoredbiasedexponent eisalwayspositive,afixed number calledthe biasis addedto theactual exponent pbeforeitisstoredas thebiased Table 2.2 Representation scheme for normal and abnormal IEEE singles. Number name Values of s,e,a n df Value of single Normal 0 <e<255 (‚àí1)s√ó2e‚àí127√ó1.f Subnormal e=0,f‚â†0 (‚àí1)s√ó2‚àí126√ó0.f Signedzero( ¬±0)e=0,f=0 (‚àí1)s√ó0.0 +‚àû s=0,e=255,f=0 +INF ‚àí‚àû s=1,e=255,f=0 -INF Notanumber s=u,e=255,f‚â†0 NaN",4335
2.2.1.1 Examples of IEEE Representations,"2.2 Computer Number Representations 15 exponente.Theactualexponent,whichmaybenegative,is p=e‚àíbias. (2.5) 2.2.1.1 Examples of IEEE Representations There are two basic IEEE floating-point formats, singles and doubles. Singlesorfloatsis shorthandfor single-precisionfloating-pointnumbers ,anddoublesisshorthandfor double- precisionfloating-pointnumbers .(InPython,however,floatsaredoubleprecision.)Singles occupy32bitsoverall,with1bitforthesign,8bitsfortheexponent,and23bitsforthefrac- tionalmantissa(whichgives24-bitprecisionwhenthephantombitisincluded).Doubles occupy64bitsoverall,with1bitforthesign,10bitsfortheexponent,and53bitsforthe fractionalmantissa(for54-bitprecision).Thismeansthattheexponentsandmantissasfor doublesarenotsimplydoublethoseoffloats,asweseeinTable2.1.(Inaddition,theIEEE standardalsopermits extendedprecision thatgoesbeyonddoubles,butthisisallcompli- catedenoughwithoutgoingintothatrightnow.) Toseetheschemeinpractice,considerthe32-bitrepresentation(2.4): se f Bitposition 31 30 23 22 0 Thesignbit sisinbitposition31,thebiasedexponent eisinbits30‚Äì23,andthefractional partofthemantissa fisinbits22‚Äì0.Because8bitsareusedtostoretheexponent eand because28=256,ehastherange 0‚â§e‚â§255. (2.6) Thevalues e=0and255arespecialcases.Withbias =12710,thefullexponent p=e10‚àí127, (2.7) and,asindicatedinTable2.1,singleshavetherange ‚àí126‚â§p‚â§127. (2.8) Themantissa fforsinglesisstoredasthe23bitsinpositions22‚Äì0.For normalnumbers , thatis,numberswith0 <e<255,fisthefractionalpartofthemantissa,andthereforethe actualnumberrepresentedbythe32bitsis Normalfloating-pointnumber =( ‚àí1)s√ó1.f√ó2e‚àí127. (2.9) Subnormalnumbers havee=0,f‚â†0.Forthese, fistheentiremantissa,sotheactualnum- berrepresentedbythese32bitis Subnormalnumbers =( ‚àí1)s√ó0.f√ó2e‚àí126. (2.10) The23bits m22‚àím0,whichareusedtostorethemantissaofnormalsingles,correspond totherepresentation Mantissa =1.f=1+m22√ó2‚àí1+m21√ó2‚àí2+¬∑¬∑¬∑+m0√ó2‚àí23, (2.11) with0.fusedforsubnormalnumbers.Thespecial e=0representationsusedtostore ¬±0 and¬±‚àûaregiveninTable2.2. 162 Software Basics Toseehowthisworksinpractice(Figure2.2),thelargestpositivenormalfloating-point numberpossiblefora32-bitmachinehasthemaximumvalue e=254(thevalue255being reserved)andthemaximumvaluefor f: Xmax=01111111011111111111111111111111 =(0)(11111110 )(11111111111111111111111 ), (2.12) wherewehavegroupedthebitsforclarity.Afterputtingallthepiecestogether,weobtain thevalueshowninTable2.1: s=0,e=11111110 =254,p=e‚àí127=127, f=1.11111111111111111111111 =1+0.5+0.25+¬∑¬∑¬∑‚âÉ2, ‚áí(‚àí1)s√ó1.f√ó2p=e‚àí127‚âÉ2√ó2127‚âÉ3.4√ó1038. (2.13) Likewise,thesmallestpositivefloating-pointnumberpossibleissubnormal( e=0)witha singlesignificantbitinthemantissa: 00000000000000000000000000000001 . (2.14) Thiscorrespondsto s=0,e=0,p=e‚àí126=‚àí126 f=0.00000000000000000000001 =2‚àí23 ‚áí(‚àí1)s√ó0.f√ó2p=e‚àí126=2‚àí149‚âÉ1.4√ó10‚àí45. (2.15) Insummary,single-precision(32-bitor4-byte)numbershavesixorsevendecimalplaces ofsignificanceandmagnitudesintherange 1.4√ó10‚àí45‚â§singleprecision ‚â§3.4√ó1038. (2.16) Doublesarestoredastwo32-bitwords,foratotalof64bits(8B).Thesignoccupies1bit, theexponent e,11bits,andthefractionalmantissa,52bits: s e f f(cont.) Bitposition 6362 52 51 32 31 0 Asweseehere,thefieldsarestoredcontiguously,withpartofthemantissa fstoredin separate32-bitwords.Theorderofthesewords,andwhetherthesecondwordwith fisthe mostorleastsignificantpartofthemantissa,ismachine-dependent.Fordoubles,thebias isquiteabitlargerthanforsingles, Bias=11111111112=102310, (2.17) sotheactualexponent p=e‚àí1023. The bit patterns for doubles are given in Table 2.3, with the range and precision given inTable2.1.Torepeat,ifyouwriteaprogramwithdoubles,then64bits(8bytes)willbe usedtostoreyourfloating-pointnumbers.Doubleshaveapproximately16decimalplaces ofprecision(1partin252)andmagnitudesintherange 4.9√ó10‚àí324‚â§doubleprecision ‚â§1.8√ó10308. (2.18)",3779
2.3 Python Mini Tutorial,"2.2 Computer Number Representations 17 Table 2.3 Representation scheme for IEEE doubles. Number name Values of s,e,a n df Value of double Normal 0 <e<2047 (‚àí1)s√ó2e‚àí1023√ó1.f Subnormal e=0,f‚â†0 (‚àí1)s√ó2‚àí1022√ó0.f Signedzero e=0,f=0 (‚àí1)s√ó0.0 +‚àû s=0,e=2047,f=0 +INF ‚àí‚àû s=1,e=2047,f=0 -INF Notanumber s=u,e=2047,f‚â†0 NaN Ifasingle-precisionnumber xislargerthan2128,afaultconditionknownasan overflow occurs(Figure2.2).If xissmallerthan2‚àí128,anunderflowoccurs.Foroverflows,theresult- ingnumber xcmayendupbeingamachine-dependentpattern,notanumber(NAN),or unpredictable.Forunderflows,theresultingnumber xcisusuallysettozero,althoughthis canusuallybechangedviaacompileroption.(Havingthecomputerautomaticallyconvert underflowsto zero is usually a good path to follow;convertingoverflowsto zero may be thepathtodisaster.)Sincetheonlydifferencebetweentherepresentationsofpositiveand negativenumbersonthecomputeristhesignbitofonefornegativenumbers,thesame considerationsholdfornegativenumbers. In our experience, serious scientific calculations almost always require at least 64-bit (double-precision)floats .Andifyouneeddoubleprecisioninonepartofyourcalculation, youprobablyneeditallover,whichmeansdouble-precisionlibraryroutinesformethods andfunctions. 2.2.2 Python and the IEEE 754 Standard Python has been changing in recent years, and while in the past it did not adhere to all aspectsoftheIEEE754standard,itdoesnowalmostcompletely.Probablythemostrelevant differencefromthestandardisthat Pythondoesnotsupportsingle(32bit)precisionfloating- pointnumbers .Sowhenwedealwithadatatypecalleda floatinPython,itistheequiv- alentofadoubleintheIEEEstandard.Becausesinglesareinadequateformostscientific computing,thisisnotalossforus.Howeverbewary,ifyouswitchovertoJavaorCyou shoulddeclareyourvariablesas doublesandnotas floats.WhilePythoneliminatessingle- precisionfloats,itaddsanewdatatype complexfordealingwithcomplexnumbers.Com- plexnumbersarestoredaspairsofdoublesandarequiteusefulinphysics. The details of how closely Python adheres to the IEEE 754 standard depend upon the detailsofPython‚ÄôsuseoftheCorJavalanguagetopowerthePythoninterpreter.Inpartic- ular,withtherecent64-bitarchitecturesforCPUs,therangemayevenbegreaterthanthe IEEEstandard,andtheabnormalnumbers( ¬±INF, NaN)maydiffer.Likewise,theexactcon- ditionsforoverflowsandunderflowsmayalsodiffer.Thatbeingthecase,theexploratory exercisestofollowbecomeallthatmoreinterestingbecausewecannotsaythatweknow whatresultsyoushouldobtain.",2468
2.3.4 Python Lists as Arrays,"182 Software Basics 2.3 Python Mini Tutorial ThereisanofficialPythontutorialat docs.python.org/3/tutorial/ andthatisagoodplaceto goifyouarestartingwithPython.Inthissection,wejusthighlightsomebasicsthatshould helpyoubetterunderstandourprograms.Infact,studyingtheprogramsisagoodwayto learn,andwerecommendit.Inaddition,Chapter7discussescomputingwithmatricesand howbesttodoitwithPython. 2.3.1 Structure and Functions WefindPythontobetheeasiestprogramminglanguagetolearnandworkwith.Thisfol- lows, in part, from its use of whitespace and indentation to construct code structures, in contrasttoJavaandC,whichusebracesandsemicolons.Forexample,herewedefineand callafunction: defDefunct(x,j): # Defines the function 2i=1 max=1 0 while(i<max): print(i) 6 i=i+1 returni‚àóx‚àó‚àój Defunct(x,3) # Calls the function Here defisareservedkeywordandisfollowedbythefunctionname,andtwoarguments arebeingpassedtothefunction.Notehowthespacingsandindentationsareusedtodefine thestructureswithintheprogram,thatthecolon:isneededtodefinethefunctionandthe controlstructure,andthatthehash#isusedforcomments.Theblanklineisignoredby Pythonandisthereforclarity;youshouldusemanyinordertomaketheprogram‚Äôsstruc- ture evident. So, while there are no special characters here to separate statements (other than the newlinecontrol character), Python does use the backslash ‚ßµas a continuation characterforlongstatements: T[ix, 1] = T[ix, 0] + cons ‚àó(T[ix+1, 0] \ +T [i x‚àí1, 0]‚àí2.‚àóT[ix,0]) Python contains many built-in functions. Here are some of the ones from the C math library(insomecasesneedinga math.prefix): factorial(x) expo(x) Ô¨Çoor(x) mod(x, y) log(x[, base]) log10(x) pow(x, y) sqrt(x) MacOS(x) basin(x) atan(x) atan2(y, x) cos(x) sin(x) tan(x) degrees(x) radians(x) cosh(x) sinh(x) tanh(x) cosh(x) sinh(x) tanh(x) ref(x) gamma(x) Alsousefularethemathematicalandcomputerconstants: math.pi math.e math.inf math.nan 2.3 Python Mini Tutorial 19 2.3.2 Variable Types and Operators Variables in Python are symbols to which values are assigned. You can use almost any nameforyourvariable,butnotanyofthebuilt-infunctionnames,reservedwords,orthese keywords: False def if raise None del import return True elf in try and else is while as except lambda with assert Ô¨Ånally nonlocal yield break for not class form or continue global pass Variablenamescancontainletters,numbers,andtheunderscore_,buttheycannotstart withanumberorcontainspaces.Thevariables‚Äôvaluesareassignedwithasingleequalsign: Label = \""Voltage\"" # A string 2x=2 5 # An integer Python supports integers ( int), floating point numbers ( Ô¨Çoats), complex numbers (complex),booleans( bool),andstrings( str).Integersarecreatedwhentheyareassigned withoutadecimalpoint,whilefloatsarecreatedwhenassignedwithdecimalpoints.The divisionoftwointegersreturnsafloat,aswellasmixedarithmeticwithfloatsandintegers: >>> 6/3 22.0 >>>3/6 # Note round off 0. >>> 3./6 # Mixed types 60.50000 Notethat,incontrasttolanguagessuchasJavaandC,youdonotdeclarethevariabletype before using it. However, Python will change the variable type depending upon how it‚Äôs used: >>> i = 3 2>>>print(i) 3 >>> i = 12. ‚àói >>>print(i) 636.0000 Acomplexnumber zusestwofloatstostoretherealandimaginaryparts: >>>importmath # import math\"" for complex 2>>> x = 2 >>> y = 3 >>> z = complex(x,y) # Assign a complex number >>>print(z.real, z.imag) 62., 3. 202 Software Basics Onecanalsorepresentacomplexnumberinpolarcoordinates cmath.phase(z) # The phase phi 2>>> phase ( complex(‚àí1.0, 0.0)) 3.141592653589793 abs(z) # Modulus uses usual abs function >>> 1.0 Thefunction cmath.polar(z) convertsacomplexnumberintothepolarrepresentation (r,ùúô), whilethefunction cmath.rect(r, phi) convertsthepolarrepresentationintoaCartesianone. Astringisaseriesofcharactersthatistobeunderstoodliterally.Forexample: S= \""A string using double quotes\"" S= \""A string using single quotes\"" 3S= ‚ÄôIt\‚Äôs possible to escape a quote‚Äô \""\""\"" From \""Computational Physics\"" Problem Solving with Python \""\""\"" # Double within triple quotes Soeithersingle,double,ortriplequotesareusedtosetoffthestring.Inthelasttwolines,the internaldoublequotesarekeptaspartofthestring,andtriplequotesareusedtocontinue thestringtoanadditionalline.Youcanaccessindividualelementsofastringviaanindex beginningat0: S= \""\""Problem Solving With Python \""\"" print(S[0]) #P 3print(S[1]) #r print(S[‚àí1])#n Slicingisatechniquetoextractasubstringfromwithinastring: S= \""\""Problem Solving With Python \""\"" print(S[0:3]) #P r o MathOperators: +addition, ‚àísubtraction, * multiplication, / division,  percent modulus/remainder, ** exponentiation ComparisonOperators: ==Equals, . =Notequals, >Greaterthan, <Lessthan, >= Greaterthanorequalto, <=Lessthanorequalto. CommonAssignmentOperators: =+ =addandassign, ‚àí=subtractandassign, * =multiplyandassign, /=divideandassign 2.3.3 Boolean and Control Structures Booleanvariablescanhavethevalues TrueorFalse: 2.3 Python Mini Tutorial 21 >>> 1<2 2False >>> 2 > 1 True >>>bool(2 > 1) 6True Theifstatementexecutesablockiftheconditionismet(notecolon:andindent): ifcondition: 2if‚àíblock Theif‚Ä¶elsestatement chooses which block to execute (note colon:, semicolon;, and indent): ifcondition: 2if‚àíblock; else: else‚àíblock; Finally,the if‚Ä¶elif‚Ä¶elsestatementpermitsthechoicefromamongseveralblocks: if‚àícondition: if‚àíblock elif elif ‚àícondition1: 4elif‚àíblock1 elif elif ‚àícondition2: elif‚àíblock2 ... 8else: else‚àíblock Pythonalsosupports forloops: >>>forindexin range (1, 3): print(index) 31 2 3 andwhileloops: whilecounter <max: print(counter) 3counter += 1 2.3.4 Python Lists as Arrays Alistis Python‚Äôs built-in sequence of numbers or arbitrary objects. Although called a ‚Äúlist‚Äù it is similar to what other computer languages call an ‚Äúarray‚Äù. (In Section 7.3.2, we will describe a higher-level arraydata type available with the NumPypackage.) Pythoninterpretsasequenceofordereditems, L=l0,l1,‚Ä¶,N‚àí1,asalistandrepresentsit withasinglesymbol L: 222 Software Basics 1 >>> L = [1 , 2 , 3] #C r e a t el i s t >>> L[0] # Print element 0 (first) 3 1 # Python output >>> L # Print entire list 5 [1, 2, 3] # Output >>> L[0]= 5 # Change element 0 7 >>> L [5, 2, 3] 9 >>>len(L) # Length of list 3 11 >>>foritemsinL:printitems # For loop over items 5 13 2 3 Observethatsquarebracketswithcommaseparators,[1,2,3],areusedforlists,andthata squarebracketisalsousedtoindicatetheindexforalistitem,asinline2, L[0].Theitems inlistsare mutableorchangeable.Immutableobjectsincludeintegers,floats,strings,and tuples;afterastringofthemhasbeendefined,itscontentscannotbechanged.Aswesee inline7inthe Lcommand,anentirelistcanbereferencedasasingleobject,inthiscase, toprintit. Pythonalsohasanotherbuilt-inlistdatatypeknownasa tuplewhoseelementsarenot mutable (they also process faster than lists). Tuples are indicated by round parenthesis (..,..,.),withindividualelementsstillreferencedbysquarebrackets: >>> T = (1 , 2 , 3 , 4) # Create a tuple list 2 >>> T[3] # Print element 3 4 4 >>> T # Print entire tuple (1, 2, 3, 4) 6 >>> T[0] = 5 # Attempt to change element 0 Traceable (most recent call last): 8 T[0] = 5 Error: ‚Äôtuple‚Äô objectdoesnotsupport item assignment NotePython‚Äôserrormessagewhenwetriedtochangeanelementofatuple. Manylanguagesrequireyoutospecifythesizeofanarraybeforeyoucanstoreobjects init.Incontrast,Pythonlistsare dynamic,whichmeansthattheirsizesadjustasneeded. Inaddition,whilealistisessentiallyone-dimensionalbecauseitisasequence,acompound listcanbecreatedinPythonwiththeindividualelementsthemselvesaslists: 1 >>> L = [[1,2], [3,4], [5,6]] # A list of lists >>> L 3 [[1, 2], [3, 4], [5, 6]] >>> L[0] # The first element 5 [1, 2] Pythoncanperformalargenumberofoperationsonlists,forexample: Operation Effect Operation Effect L=[1,2,3,4] Formlist L1+L2 Concatenatelists L[i] ithelement len(L) LengthoflistL iinL TrueifiinL L[i:j] Slicefromitoj",7765
2.4.5 Experiment Your Machines Precision,"2.3 Python Mini Tutorial 23 Operation Effect Operation Effect foriinL Iterationindex L.append(x) AppendxtoendofL L.count(x) Numberofx‚ÄôsinL L.index(x) Locationof1stxinL L.remove(x) Remove1stxinL L.reverse() ReverseelementsinL L.sort() OrderelementsinL 2.3.5 Python I/O Outputting variables to the screen is easy, but as mentioned in Chapter 1, it differs in Python2and3: >>>print ‚ÄôHello, World.‚Äô #P y t h o n2 Hello, World 3>>>print(‚ÄôHello, World.‚Äô )#P y t h o n3 ‚ÄôHello, World.‚Äô Herethe ‚â´>indicatesthatwewereworkinginaninteractiveshell.Inputtingfromthekey- boardisaccomplishedwiththe inputcommand: name =input(\""Hello, What‚Äôs your name?\"" ) print(\""That‚Äôs nice \"" +n a m e+ \""thank you\"" ) age =input(\""How old are you?\"" ) 4print(\""So, you are already \"" + astr(age) + \"" years old, \"" +n a m e+ \"".\"") This is what we have done in the program AreaFormatted.py in Listing 2.11. This shows that we can print the value of a variable just by giving its name. We also see in AreaFormatted.py thatwecaninputstrings(literalnumbersandletters)byeitherenclosing thestringinquotes(singleordouble),orbyusingthe raw_input(Python2)or input(Python 3)commandwithoutquotes. AreaFormatted.py alsoshowshowtoinputbothastringand numbersfromafile. Python uses its default format when you print a float by giving just its name, with the formatvaryingdependingontheprecisionofthenumber.Youcancontroltheformatifyou like.Toprintfloatsyouneedtospecifyhowmanydigits(places)afterthedecimalpointare desired,andhowmanyspacesoverallshouldbeusedforthenumber: print(\""x= percent6.3f, Pi= percent9.6f, Age= percentd  \"" ) percent( x ,m a t h . p i ,a g e ) print(\""x= percent6.3f,  percent(x), \"" Pi= percent9.6f, \""  percent(math.pi), \"" Age= percentd \"" percent(age),\""  ) x = 12.345, Pi = 3.141593, Age=39 # Output from either Here the  percent6.3fformats a float (which is a double in Python) to be printed in fixed-point notation(the f)withthreeplacesafterthedecimalpointandwithsixplacesoverall(one placeforthedecimalpoint,oneforthesign,oneforthedigitbeforethedecimalpoint,and threeforthedecimal).Thedirective  percent9.6fhassixdigitsafterthedecimalplaceandnine overall.Toprintaninteger,youneedtospecifyonlythetotalnumberofdigits(thereisno decimalpart),andwedothatwiththe  percentd(dfordigits)format. 242 Software Basics The  percentsymbolintheseoutputformatsindicatesaconversionfromthecomputer‚Äôsinternal formattothatusedforoutput.Noteabovethatwehavealsousea ‚ßµndirectivetoindicatea newline.Otherdirectives,someofwhicharedemonstratedin Directives.py inListing2.12, are: ‚ßµ\""doublequote ‚ßµ0NNNoctalNNN ‚ßµ‚ßµbackslash ‚ßµaalert(bell) ‚ßµbbackspace ‚ßµcnomoreoutput ‚ßµfformfeed ‚ßµnnewline ‚ßµrcarriageret ‚ßµthorizontaltab ‚ßµvverticaltab  percent percentasingle percent NoticeinListing2.11howwereadfromthekeyboard,aswellasfromafile,andthenoutput tobothscreenandfile.Beware,ifyoudonotcreatethefile Name.dat,theprogramwillissue (‚Äúthrow‚Äù)anerrormessageofthesort: Error: [Error 2] No such file or directory: ‚ÄôName.dat‚Äô . 2.3.6 Python‚Äôs Algebraic Tools Whilethisbook‚ÄôsfocusismainlyontheuseofPythonfornumericalsimulations,thatis nottodiscounttheimportanceofcomputationalsymbolicmanipulations.Pythonactually has(atleast)twopackagesthatcanbeusedforsymbolicmanipulations,andtheyarequite different.AsindicatedinSection1.6,the Sagepackageisverymuchinthesameclassas Maple and Mathematica. Sages‚Äôs notebook interface lets users create publication-quality text,runprograms,ormanipulateequationssymbolically.YetSageisabigandpowerful packagethatgoesbeyondpurePythonbyincludingmultiplecomputeralgebrasystems,as wellasvisualizationtools,andmore.UsingthemultiplefeaturesofSagecangettobequite complicated,and,infact,bookshavebeenwrittenandworkshopstaughtontheuseofSage. WerefertheinterestedreadertotheonlineSageDocumentationpage www.sagemath.org/ help.html.",3787
2.4.5 Experiment Your Machines Precision,"TheSymPypackage for symbolic manipulations runs within a regular Python shell, verymuchlikeanyotherPythonpackage.Itcanbedownloadedfrom github.com/sympy/ sympy/releases ,oryoucanusetheCanopydistributionthatincludesSymPy.Nowwegive somesimpleexamplesofSymPy‚Äôsuse,butreallyyoushouldstartwiththe SymPyTutorial , docs.sympy.org/latest/tutorial/ . To start, we‚Äôll take some derivatives to show that SymPy knowscalculus: 1>>>fromSymPyimport ‚àó >>> x, y = symbols( ‚Äôx y‚Äô) >>> y = diff ( tan (x) ,x) ; y # y = derivative tan(x) $\tan^2(x) + 1$ 5>>> y = diff (5 ‚àóx‚àó‚àó4+7 ‚àóx‚àó‚àó2, x, 1); y # Deriv, 1 optional $20 x^3 + 14 x$ >>> y = diff (5 ‚àóx‚àó‚àó4+7‚àóx‚àó‚àó2, x, 2); y #$d^2y/dx^2 $ $2\, (30 x^2 + 7)$ WeseethatwefirstimportmethodsfromSymPy, andthenuse the symbolscommandto declare the variables xandyas algebraic. The rest is rather obvious, with diffbeing the derivativeoperator,andthe xargumentindicatingthederivativewithrespectto x.Nowlet‚Äôs tryexpansions: 2.4 Programming Warmup 25 >>>fromSymPyimport ‚àó >>> x, y = symbols( ‚Äôx y‚Äô) >>> z = (x + y) ‚àó‚àó8; z 4$(x + y)^8$ >>> expand(z) $x^8 + 8 x^7 y + 28 x^6 y^2 + 56 x^5 y^3 + 70 x^4 y^4 + 56 x^3 y^5 + 28 x^2 y^6 + 8 x y^7 + y^8$ SymPyalsoknowsaboutinfiniteseries,anddifferentexpansionpoints: >>> sin (x) . series (x , 0) #$\sin x$series about 0 2$x‚àíx^3/6 + x^5/120 + \mathcal{O}(x^6)$ >>> sin (x) . series (x ,10) #$\sin x$about x= 10 $\sin(10) + x\cos(10) ‚àíx^2 \sin(10)/2 ‚àíx^3 \cos(10)/6 + x^4 \sin(10)/24 + x^5 \cos(10)/120 +\mathcal{O}(x^6)$ >>> z = 1/ cos (x) ; z # Division, not inverse 6$1/\cos(x)$ >>> z . series (x , 0) #E x p a n d $1/\cos x $about$x=0$ $1 + x^2/2 + 5 x^4/24 + \mathcal{O}(x^6)$ Oneoftheclassicdifficultieswithcomputeralgebrasystemsisthateveniftheansweris correct,itmaynotlooksimple,andthusisnottoouseful.SymPyhasthefunctions simplify, factor, collect, cancel ,and aparttohelpmakeitsoutputeasiertounderstand: >>> factor (x ‚àó‚àó2‚àí1) $(x‚àí1) (x + 1)$ # A nice answer >>> factor (x ‚àó‚àó3‚àíx‚àó‚àó2+x‚àí1) 4$(x‚àí1) (x^2 + 1)$ >>> simplify((x ‚àó‚àó3+x ‚àó‚àó2‚àíx‚àí1)/(x ‚àó‚àó2+2 ‚àóx+1 ) ) $x‚àí1$ # Much better. >>> simplify(x ‚àó‚àó3+3‚àóx‚àó‚àó2‚àóy+3‚àóx‚àóy‚àó‚àó2+y‚àó‚àó3) 8$x^3 + 3 x^2 y + 3 x y^2 + y^3$ #N oh e l p . >>> factor (x ‚àó‚àó3+3‚àóx‚àó‚àó2‚àóy+3‚àóx‚àóy‚àó‚àó2+y‚àó‚àó3) $(x + y)^3$ # Much better. >>> simplify(1 + tan(x) ‚àó‚àó2) 12$\cos(x)^{( ‚àí2)}$ >>> simplify(2 ‚àótan(x)/(1+tan(x) ‚àó‚àó2)) $\sin(2 x)$ 2.4 Programming Warmup BeforewegoontoseriousCPwork,wewanttoestablishthatyourlocalcomputeriswork- ingrightforyou.Assumethatcalculatorshavenotyetbeeninvented,andthatyouneeda programtocalculatetheareaofacircle.Youmighttry read radius #I n p u t calculate area of circle # Numerics printarea # Output Theinstruction calculate area of circle hasnomeaningtomostcomputers,soweneed tospecifyan algorithm,thatis,asetofrulesforthecomputertofollow: 1read radius #I n p u t PI = 3.141593 # Set constant area = PI ‚àór‚àór # Algorithm printarea # Output 262 Software Basics Thisisbetter.HereisourPythonprogram Area.py,andyoushouldensurethatitrunsfor you.Thisisasimpleprogramthatoutputstothescreen,withitsinputbuiltintothepro- gram. # Area.py: Area of a circle , simple program frommathimportpi N=1 4r=1 .",3083
2.4.5 Experiment Your Machines Precision,"C=2 . ‚àópi‚àór A=p i ‚àór‚àó‚àó2 print(‚ÄôProgram number =‚Äô ,N , ‚Äô \ nr ,C ,A=‚Äô ,r ,C ,A ) 2.4.1 Program Design Programmingisawrittenartthatblendselementsofscience,mathematics,andcomputer scienceintoasetofinstructionsthatpermitacomputertoaccomplishadesiredtask.And now, with published scientific results increasingly relying on computation, it is increas- inglyimportantthatthesourceversionofyourprogramitselfbeavailabletootherssothat theycanreproduceyourresults.Reproducibilitymaynotbeasexcitingasanewdiscovery, but it is an essential ingredient in science [Hinsen, 2013]. In addition to the grammar of acomputerlanguage,ascientificprogramshouldincludeanumberofessentialelements toensuretheprogram‚Äôsvalidityandusability.Aswithotherarts,wesuggestthatuntilyou knowbetter,youfollowsomesimplerules.Agoodprogramshould: ‚óèGivethecorrectanswers. ‚óèBeclearandeasytoread,withtheactionofeachparteasytoanalyze. ‚óèDocumentitselfforthesakeofreadersandtheprogrammer. ‚óèBeeasytouse. ‚óèBebuiltupoutofsmallprogramsthatcanbeindependentlyverified. ‚óèBeeasytomodifyandrobustenoughtokeepgivingcorrectanswersaftermodification anddebugging. ‚óèDocumentthedataformatsused. ‚óèUsetrustedlibraries. ‚óèBepublishedorpassedontootherstouseandtodevelopfurther. Oneattractionof object-orientedprogramming isthatitenforcestheserulesautomatically. Anelementarywaytomakeanyprogramcleareristo structureitwithindentation,skipped lines,andstrategicallyplacedbraces.Thisisdonetoprovidevisualcluesastothefunctionof thedifferentprogramparts(the‚Äústructures‚Äùinstructuredprogramming).Pythonactually usesindentationsasstructureelements.Althoughthespacelimitationsofaprintedpage keepusfrominsertingasmanyblanklinesaswewouldprefer,werecommendthatyoudo aswesayandnotaswedo. We findflowcharts, such as the basic and the detailed ones in Figure 2.3 for projectile motion,usefulinplanningthechronologicalorderfortheessentialstepsinaprogram,and alsoprovidingagraphicaloverviewofthecomputation.Aflowchartisnotmeanttobea detaileddescriptionofaprogram,butinsteadisavisualizationofaprogram‚Äôslogicalflow. Werecommendthatyoudrawaflowchartor(secondbest)writeapseudocodebeforeyou 2.4 Programming Warmup 27 Initialize constants Basic calculations Loop over time EndStore g, V0, Œ∏ Calculate R, T Loop over time Calculate x(t), y(t) Print x, y ‚ÄúNot Yet Fired‚Äù End‚ÄúGrounded‚Äù0 < t < T ? t < 0 ? N YN Y Figure 2.3 A Ô¨Çowchart illustrating a program to compute projectile motion. On the left are the basic components of the program, and on the right are some of its details. When writing a program, Ô¨Årst map out the basic components, then decide upon the structures, and Ô¨Ånally Ô¨Åll in the details. This is called top-down programming . writeaprogram. Pseudocode islikeatextversionofaflowchartthatleavesoutdetailsand insteadfocusesonthelogicandstructures: 1# A flowchart for projectile motion Store g, Vol, andtheta Calculate R andT Begin time loop 5Print out \""not yet fired\"" ift<0 Print out \""grounded\"" ift>T Calculate , printx(t)andy(t) Print out error message ifx>R ,y>H 9End time loop End program 2.4.2 First Programming Steps 1) Togainsomeexperiencewithyourcomputersystem,useaneditortoentertheprogram Area.pythatcomputestheareaofacircle(yes,weknowyoucancopyandpasteit,but don‚Äôt).",3197
2.4.5 Experiment Your Machines Precision,"Save your program to a file in your home (personal) directory. Note: For those whoarefamiliarwithPython,youmaywanttoentertheprogram AreaFormatted.py in Listing2.11thatproducesformattedoutput. 2) Compileandexecutetheappropriateversionof Area.py. 3) Experimentwithyourprogram.Forexample,seewhathappensifyouleaveoutdecimal pointsintheassignmentstatementfor r,ifyouassign requaltoablank,orifyouassigna lettertor.Remember,itisunlikelythatyouwill‚Äúbreak‚Äùorhurtthecomputerbymaking amistake,anditisgoodtoseehowthecomputerrespondswhensomethingiswrong. 282 Software Basics 4) Changetheprogramsothatitcomputesthevolume4 3ùúãr3ofasphereandprintsitout with the proper name. Save the modified program to a file in your personal directory andgiveitthename Vol.py. 5) Openandexecute Vol.pyandcheckthatyourchangesarecorrectbyrunninganumber oftrialcases.Goodinputdataare r=1andr=10. 6) Revise Area.pysothatittakesinputfromafilenamethatyouhavemadeup,thenoutputs inadifferentformattoanotherfileyouhavecreated,andthenreadsfromthelatterfile. 7) Seewhathappenswhenthedatatypeusedforoutputdoesnotmatchthetypeofdata inthefile(e.g.,floatingpointnumbersarereadinasintegers). 8) Revise Area.pysothatitusesamainmethod(whichdoestheinputandoutput)anda separatefunctionormethodforthecalculation.Checkthatyouobtainthesameanswers asbefore. 2.4.3 Over and UnderÔ¨Çow Exercises 1) Considerthe32-bitsingle-precisionfloating-pointnumber A: s e f Bitposition 3130 23 22 0 Value 000001110 10100000000000000000000 a) Whatarethebinaryvaluesforthesign s,theexponent e,andthefractionalmantissa f.(Hint:e10=14.) b) Determinedecimalvaluesforthebiasedexponent eandthetrueexponent p. c) Showthat A‚Äôsmantissaequals1.625000. d) Determinethefullvalueof A. 2) Writeaprogramthatdeterminesthe underflow andoverflowlimits(withinafactor of2)forPythononyourcomputer.Here‚Äôsasamplepseudocode under = 1. over = 1. 3begin do N times under = under/2. over = over ‚àó2. write out: loop number, under, over 7end do Youmayneedtoincrease Nifyourinitialchoicedoesnotleadtounderflowandoverflow. Ifyouwanttobemorepreciseregardingthelimitsofyourcomputer,trymultiplyingand dividingbyanumbersmallerthan2. 1) Checkwhereunder-andoverflowoccurfordouble-precisionfloating-pointnumbers. Giveyouranswerindecimals. 2) Checkwhereunder-andoverflowoccurforfloats. 3) Checkwhereunder-andoverflowoccurforintegers. Note:Thereisnoexponentstored for integers, so the smallest integer corresponds to the most negative one. To deter- minethelargestandsmallestintegers,youmustobserveyourprogram‚Äôsoutputasyou 2.4 Programming Warmup 29 explicitlypassthroughthelimits.Youaccomplishthisbycontinuallyaddingandsub- tracting1.(Inasmuchasintegerarithmeticuses two‚Äôscomplement arithmetic,youshould expectsomesurprises.) 2.4.4 Machine Precision A recurring concern of computational scientists is that the floating-point representation usedtostorenumbersisoflimitedprecision.Ingeneralfora32-bit-wordmachine, single- precision numbers are good to 6‚Äì7 decimal places, while doubles are good to 15‚Äì16 places . Toseehowlimitedprecisionaffectscalculations,considerthesimplecomputeradditionof twosingle-precisionnumbers: 7+1.0√ó10‚àí7=? (2.19) Thecomputerfetchesthesenumbersfrommemoryandstoresthebitpatterns 7=01000001011100000000000000000000 , (2.20) 10‚àí7=00110000011010110101111111001010 , (2.21) inworkingregisters (piecesoffast-respondingmemory).Becausetheexponentsarediffer- ent,itwouldbeincorrecttoaddthemantissas,andsotheexponentofthesmallernumberis madelargerwhileprogressivelydecreasingthemantissaby shiftingbits totheright(insert- ingzeros)untilbothnumbershavethesameexponent: 10‚àí7=00110000101101011010111111100101 (0) =00110001000110101101011111110010 (10) (2.22) ¬∑¬∑¬∑ =01000001000000000000000000000000 (0001101¬∑¬∑¬∑0 ‚áí 7+1.0√ó10‚àí7=7. (2.23) Because there is no room left to store the last digits, they are lost, and after all this hard worktheadditionjustgives7astheanswer;anexampleofthetruncationerrorindicated inFigure2.2.Inotherwords,becausea32-bitcomputerstoresonly6or7decimalplaces, iteffectivelyignoresanychangesbeyondthesixthdecimalplace. Theprecedinglossofprecisioniscategorizedbydefiningthe machineprecision ùúñmasthe maximumpositivenumberthat,onthecomputer,canbeaddedtothenumberstoredas1 withoutchangingthatstored1: 1c+ùúñmdef=1c, (2.24) wherethesubscript cisareminderthatthisisacomputerrepresentationof1.Consequently, anarbitrarynumber xcanbethoughtofasrelatedtoitsfloating-pointrepresentation xcby xc=x(1¬±ùúñ), |ùúñ|‚â§ùúñm, (2.25) wheretheactualvalueof ¬±ùúñisnotknown(butcanbedetermined).Inotherwords,except forpowersof2thatarerepresentedexactly,weshouldassumethatallsingle-precisionnum- berscontainanerrorinthesixthdecimalplace,andthatalldoubleshaveanerrorinthe 15thplace.And,asisalwaysthecasewitherrors,wemustassumethatwereallydonot",4724
2.5.2 Matplotlibs 2D Plots,"302 Software Basics knowwhattheerroris,forifweknew,thenwewouldeliminateit.Consequently,theargu- ments we are about to put forth regarding errors should be considered approximate, but that‚Äôstypicalforknownunknowns. 2.4.5 Experiment: Your Machine‚Äôs Precision Writeaprogramtodeterminethemachineprecision ùúñmofyourcomputersystemwithina factorof2.Asamplepseudocodeis 1eps = 1. begin do N times eps = eps/2. # Make smaller one = 1. + eps # Write loop number, one, eps 5end do APythonimplementationisgiveninListing2.13,whileamorepreciseonewouldworkat thebytelevel. 1) Determineexperimentallytheprecisionofdouble-precisionfloats. 2) Determineexperimentallytheprecisionofcomplexnumbers. It‚Äôs good to remember that to print out a number in decimal format, the computer must makeaconversionfromitsinternalbinaryrepresentationtodecimal.Thisnotonlytakes time,butunlessthenumberisanexactpowerof2,leadstoalossofprecision.Soifyouwant atrulypreciseindicationofthestorednumbers,youshouldavoidconversiontodecimals andinsteadprintthemoutinoctal( ‚ßµ0NNN)orhexadecimal( 0x)format. 2.5 Python‚Äôs Visualization Tools IfIcan‚Äôtpictureit,Ican‚Äôtunderstandit . ‚ÄîAlbertEinstein Inthesectionstofollowwediscusstoolstovisualizedataproducedbysimulationsandmea- surements.Whereasotherbooksmaychoosetorelegatethisdiscussiontoanappendix,ornot toincludeitatall,webelievethatvisualizationissuchanintegralpartofCP,andsousefulfor yourworkintherestofthisbook,thatwehaveplacedithere,rightupfront.Wedescribethe useofMatplotlib[Matplotlib ,2023]andVpython/Visual . Generalities One of the most rewarding aspects of computing is visualizing the results. Whileinthepastthiswasperformedwith2Dplots,inmoderntimesitisregularpractice to use 3D (surface) plots, volume rendering (dicing and slicing), animations, and virtual reality(gaming)tools.Thesetypesofvisualizationsareoftenbreathtakinglybeautifuland mayprovidedeepinsightsintoproblemsbylettingusseeand‚Äúhandle‚Äùthefunctionswith whichweareworking.Visualizationalsoassistsinthedebuggingprocess,thedevelopment ofphysicalandmathematicalintuition,andtheall-aroundenjoymentofwork. Inthinkingaboutwaystoviewyourresults,keepinmindthatthepointofvisualization istomakethephysicsclearerandtocommunicateyourworktoothers.Itfollowsthenthat 2.5 Python‚Äôs Visualization Tools 31 youshouldmakeallfiguresasclear,informative,andself-explanatoryaspossible,especially ifyouwillbeusingtheminpresentationswithoutcaptions.Thismeanslabelsforcurvesand datapoints,atitle,andlabelsontheaxes.3Afterthis,youshouldstudyyourvisualization andaskwhethertherearebetterchoicesforunits,rangesofaxes,colors,style,andsoon, thatmightgetthemessageacrossbetterandprovidemoreinsight.Andtrytorememberthat those colors which look great on your monitor may turn into uninformative grays when printed. Considering the complexity of human perception and cognition, there may not beasinglebestwaytovisualizeaparticulardataset,andsosometrialanderrormaybe necessaryto‚Äúsee‚Äùwhatworksbest. 2.5.1 Visual (VPython)‚Äôs 2D Plots Vpython(PythonplustheVisualpackage)isasimplewaytogettocreatePythonvisual- izationsanditwasusedtocreatemanyofthevisualizationsinthisbook.Itsdevelopment endedin2006andhasbeensupersededby WebVpython .However,youcanstillrunVpython programsasWebVpythonorwithinaJupyterNotebook. InFigure2.4,wepresenttwoplotsproducedbytheprogram EasyVisual.py inListing2.1.",3319
2.5.2 Matplotlibs 2D Plots,"Noticethattheplottingtechniqueistocreatefirsttheplotobjects Plot1and Plot2,andthen toaddthepointstotheobjects,one-by-one,andthenusethe plotmethodtoplottheobjects. (Incontrast,Matplotlibcreatesavectorofpointsandthenplotstheentirevectorinonefell swoop.) It is often a good idea to place several plots in the same figure. The program 3GraphVisual.py inListing2.2doesthatandproducesthegraphontheleftofFigure2.5.On yourcomputerscreenyouwillseewhiteverticalbarscreatedwith gears,reddotscreated with grots,andayellowcurvecreatedwith curve. Animations Creating animations with Visual is essentially just making the same 2D plotoverand overagain,with each one ata slightlydifferingtime,and then placingthe plotsontopofeachother.Whenperformedproperly,thisgivestheimpressionofmotion. Several of our sample codes produce animations, for example, HarmosAnimate.py and 3Danimate.py . Three frames produced by HarmosAnimate.py are shown on the right of Figure 2.4 Screen dumps of two x-yplots produced by EasyVisual.py using the Visual package. Theleftplot uses default parameters while the right plot uses user-supplied options. 3 Althoughthismaynotneedsaying,placetheindependentvariable xalongtheabscissa(horizontal),and thedependentvariable y=f(x)alongtheordinate. 322 Software Basics Figure 2.5 Left: Output from the program 3GraphVisual.py that places three different types of 2D plots on one graph using Visual. Right: Three frames from a Visual animation of a quantum mechanical wave packet produced with HarmosAnimate.py. Figure2.5.Themajorportionsofthesecodesdealwiththesolutionofpartialdifferential equations, which need not concern us (yet). The part which makes the animation issimple: PlotObj= curve(x=xs, color=color.yellow, radius=0.1) ... 3whileTrue: # Runs forever rate(500) ps[1:‚àí1] = ... psi[1:‚àí1] = .. 7PlotObj.y = 4 ‚àó(ps‚àó‚àó2+p s i ‚àó‚àó2) Here PlotObjisacurvethatgetscontinuallybuiltfromwithinawhileloopandthusappears tobemoving.Notethatbeingabletoplotpointsindividuallywithouthavingtostorethem allinanarrayforalltimeskeepsthememorydemandoftheprogramquitesmallandis fast. 2.5.2 Matplotlib‚Äôs 2D Plots Matplotlib is a powerful plotting package that lets you create 2D and 3D graphs, his- tograms, power spectra, bar charts, error charts, scatter plots, and what not, all directly from within your Python program. Matplotlib is free, uses the sophisticated numerics of NumPy and LAPACK, and, believe it or not, is easy to use. Since Matplotlib is not part of standard Python, you must import the entire Matplotlib package, or individual methods,intoyourprogram.Weusuallydothatinourcodesbyimporting pylab,whichis amodulethatprovidesbothMatplotlibandNumPypackages.Here,from EasyMatPlot.py , ishowwedoit: 1frompylabimport ‚àó # Load Matplotlib Min = ‚àí5.; Max = +5.; Npoints= 500 Del = (Max ‚àíMin) / Points x = arrange(Min, Max, Del) 5y= s i n ( x ) ‚àósin(x ‚àóx) # f(x array) label( ‚Äôx‚Äô); label( ‚Äôf(x)‚Äô); title( ‚Äô f(x) vs x‚Äô ) text(‚àí1.75, 0.75, ‚ÄôMatplotlib   Example‚Äô ) #T e x to np l o t 2.5 Python‚Äôs Visualization Tools 33 plot(x, y, ‚Äô-‚Äô,l w = 2 ) 9grid(True) # Form grid show() Matplotlib commands are by design similar to the plotting commands of MATLAB, a commercialproblem-solvingenvironmentthatisparticularlypopularinengineering.Asis true for MATLAB, Matplotlib assumes that you have placed the xandyvalues that you wish to plot into 1D arrays (vectors), and then plots the entire vectors in one fell swoop. MatplotlibusesthepowerfulNumPy arrayobjecttostorethedata,whichwediscussfurther in Chapter 7.",3497
2.5.2 Matplotlibs 2D Plots,"As you can see, NumPy‚Äôs arrangemethod constructs an array covering ‚Äúa range‚Äùbetween Maxand Mininstepsof Del.Becausethelimitsarefloating-pointnumbers, sotoowillbethe xi‚Äôs.Andbecause xisanarray, y = -sin(x)*cos(x) isautomaticallyonetoo. Theactualplottingisperformedwiththe plotcommand,withadash‚Äò-‚Äôindicatingaline, and lw=2settingthelinewidth.TheresultisshownontheleftofFigure2.6,withthedesired labelsandtitle.The show()commandproducesthegraphonyourdesktop.Morecommands aregiveninTable2.4.Wesuggestyoutryoutsomeoftheoptionsandtypesofplotspossible. InListing2.5,wegivethecode GradesMatplot.py ,andontherightofFigure2.6weshowits output.Thisisnotasimpleplot.Herewerepeatthe plotcommandseveraltimesinorder toplotseveraldatasetsonthesamegraph,andtoplotboththedatapointsandthelines connectingthem.OnLine3weimportMatplotlib(pylab),andonLine4weimportNumPy, whichweneedforthe arraycommand.Seeingthatwehaveimportedtwopackages,weadd thepylabprefixtothe plotcommandssothatPythonknowswhichpackagetouse. Inordertoplaceahorizontallinealong y=0,onlines10and11wecreateadatasetasan arrayofxvalues,‚àí1‚â§x‚â§5,andacorrespondingarrayof yvalues,yi‚â°0.Wethenplotthe horizontalonline12.Next,weplacefourmorecurvesonthefigure.Firstonlines14‚Äì15we createdataset0,thenplotthepointsasbluecircles(grayonthepage) ‚Äôbo‚Äô,andconnectthe pointswithgreen( ‚Äôg‚Äô)lines.Onlines19‚Äì21wecreateandplotanotherdatasetasared( ‚Äôr‚Äô) line(grayonthepage).Finally,onlines23‚Äì25wedefineunequalloweranduppererrorbars andplacethemontheplot.Wefinishbyaddinggridlines(Line27)and showingtheplot onthescreen. ‚Äì1‚Äì6‚Äì4‚Äì20GPAf(x)246 012 Y ears in college xGrade inflation f(x) vs x 1. 0 0.5 0.0 ‚Äì0.5 ‚Äì1 .0 ‚Äì6 ‚Äì4 ‚Äì2 0 2 4MatPlotLib example 6 345 Figure 2.6 Matplotlib plots. Left: Output of EasyMatPlot.py (Listing 2.3) showing a simple, x-y plot.Right: Output from GradesMatPlot.py that places two sets of data points, two curves, and unequal upper and lower error bars, all on one plot. 342 Software Basics Table 2.4 Some common Matplotlib commands. Command Effect Command Effect plot(x,y,‚Äò-‚Äô,lw =2) x-ylinewidth2 myPlot.setYRange( ‚àí8.,8.) Set yrange show() Showgraph myPlot.setSize(500,400) Sizeinpixels label(‚Äòx‚Äô) x-axislabel pyplot.semilogx Epilog xplot label(‚Äòf(x)‚Äô) y-axislabel pyplot.semilogy Epilog yplot title(‚Äòfvs.x‚Äô) Addtitle grid(True) Drawgrid text(x,y,‚Äòs‚Äô) Addtext sat(x,y)myPlot.setColor(false) Black&White myPlot.addPoint Add (x,y)to0 myPlot.setButtons(true) Forzoombutton (0,x,y,true) connect myPlot.addPoint Add (x,y)to1, myPlot.fillPlot() Fitrangestodata (1,x,y,false) noconnect pyplot.errorbar Point +errorbar myPlot.setImpulses(true,0) Vertlines,set0 pyplot.clf() Clearfigure pyplot.contour Contourlines pyplot.scatter Scatterplot pyplot.bar Barcharts pyplot.polar Polarplot pyplot.gca Forcurrentaxis myPlot.setXRange Set xrange pyplot.acorr Autocorrelation (‚àí1.,1.) Oftenthescienceisclearerifthereareseveralcurvesinoneplot,and,severalplotsinone figure.Matplotlibletsyoudothiswiththe plotandthe subplotcommands.Forexample, inMatPlot2figs.py inListing2.6andFigure2.7,wehaveplacedtwocurvesinoneplot,and thenoutputtwodifferentfigures,eachcontainingtwoplots.Thekeyhereisarepetitionof thesubplotcommand: figure(1) # The 1st figure 2subplot(2,1,1) # 2 rows, 1 column, 1st subplot subplot(2,1,2) # 2 rows, 1 column, 2nd subplot f(x) f(x)f(x)0.00.20.40.60.81. 0 exp(‚Äì x/4)*sin( x)sin^2(x)*cos^2(x^2) ‚Äìsin( x)*cos( x^2) ‚Äì6 ‚Äì4 ‚Äì2 0 x24 ‚Äì 6 ‚Äì2‚Äì101234‚Äì0.5 ‚Äì1 .00.00.51. 0 ‚Äì4 ‚Äì2 0 x246 ‚Äì4 ‚Äì2 0 x2466 ‚Äì6 ‚Äì60246810f(x)12 ‚Äì4 ‚Äì2 0exp(‚Äì x/2)*sin^2(x) 246 x Figure 2.7 LeftandRight Columns show two separate outputs, each of two Ô¨Ågures, produced by MatPlot2Ô¨Ågs.py. (We used the slider button to add some space between the upper and lower plots).",3672
2.5.4 Matplotlibs Animations,"2.5 Python‚Äôs Visualization Tools 35 The listing is self-explanatory, with sections that set the plotting limits, that create each figure,andthencreatethegrid. ScatterPlots Sometimesweneedascatterplotofdata,andmaybeevenacurvethrownin aswell.InFigure5.4,weshowascatterplotcreatedwiththecode PondMapPlot.py inListing 2.7.Thekeystatementshereareoftheform ax.plot(ox, yo, ‚Äôbo‚Äô, markersize=3) ,which inthiscaseaddsabluepoint(grayonthepage)ofsize3. 2.5.3 Matplotlib‚Äôs 3D Surface Plots A2Dplotofthepotential V(r)=1‚àïrversusrisfineforvisualizingtheradialdependenceof thepotentialfieldsurroundingasinglecharge,butifyouwanttovisualizeadipolepotential suchasV(x,y)=[B+C(x2+y2)‚àí3‚àï2]x,youneeda3D,orsurface,visualization.Yougetthat bycreatingaworldinwhichthe zdimension(mountainheight)isthevalueofthepotential, andthexandyaxesdefinetheplanebelowthemountain.Asthesurfaceyouarecreating isa3Dobject,itisnottrulypossibletodrawitonaflatscreen,andsodifferenttechniques areusedtogivetheimpressionofthreedimensionstoourbrains.Thatisaccomplishedby rotatingtheobject(grabbingitwithyourmouse),shadingit,employingparallax,andother tricks. InFigure2.8,weshowawire-frameplot(left)andacoloredsurface-plus-wire-frameplot (right).Theseareobtainedfromtheprogram Simple3Dplot.py inListing2.8.Notethatthere isanextraimportof Axes3DfromtheMatplotlibtoolkitneededfor3Dplotting.Lines8and 9 are the usual creation of xandyarrays of floats using arrange. Line 11 uses the meshed methodtosetuptheentirecoordinatematrixgridfromthe xandycoordinatevectorswith avectoroperation,andline12constructstheentire Zsurfacewithanothervectoroperation. Theremainderoftheprogramisself-explanatory,with figbeingtheplotobject, axthe3D axesobject,and plot_airframe and plot_surface creatingwireframewireframeandsurface plots,respectively.Anothertypeof3Dplotthatisparticularlyusefulwhenexaminingdata oftheform (xi,yj,zk),isascatterplotintoa3Dvolume.InListing2.9,wegivetheprogram Scatter3dPlot.py that created the plot in Figure 2.9. This program, which is taken from the Matplotlibdocumentation,uses theNumPy randomnumber generator,withthe 111 notationbeingahand-me-downfromMATLABindicatinga1 √ó1√ó1grid. 1. 0 0.5 0.0z xy‚Äì0.5 ‚Äì1 .0 ‚Äì3 ‚Äì3‚Äì2‚Äì10123 ‚Äì2‚Äì101231. 0 0.5 0.0z xy‚Äì0.5 ‚Äì1 .0 ‚Äì3 ‚Äì3‚Äì2‚Äì10123 ‚Äì2‚Äì10123 Figure 2.8 Left: A 3D wire frame. Right: A colored surface plot with wire frame. Both are produced by the program Simple3dplot.py using Matplotlib.",2388
2.6 Plotting Exercises,"362 Software Basics X LabelX22 24 26 2830 32 34Y LabelY ‚Äì20020406080100120‚Äì50‚Äì40‚Äì30‚Äì20‚Äì100 ‚Äì60Z LabelZ Figure 2.9 A 3D scatter plot produced by the program Scatter3dPlot.py using Matplotlib. Finally, the program FourierMatplot.py , written by Oscar Estrepe, performs a Fourier reconstruction of a saw tooth wave, with the number of waves included controlled by the viewer via a slider bar, as shown in Figure 2.10. (We discuss Fourier transforms in Chapter9.)Theslidermethodisincludedviatheextralines: 1frommatplotlib.widgets importSlider ... shortwaves = Slider(airwaves, ‚Äô# Waves‚Äô , 1, 20, valinit=T) ... 5snumwaves.on_changed(update) 2.5.4 Matplotlib‚Äôs Animations Matplotlibcanalsocreateanimations,althoughnotassimplyasVpython.TheMatplotlib examples page gives a number of them. We have included some Matplotlib animation codesintheCodesdirectory,andshowasamplecodefortheheatequationinListing2.10. Here too, most of the code deals with solving a partial differential equation, which need notinterestusyet.Theanimationiscarriedoutatthebottomofthecode. 2.6 Plotting Exercises 1) We encourage you to make your own plots and personalize them by trying out other commands and by including further options in the commands. The Matplotlib docu- mentationisextensiveandavailableontheWeb.Asanexercise,explore: 2.6 Plotting Exercises 37 0.0 0.5 1 .0 1 .5 2.0 2.5 TimeFourier synthesis of sawtooth function # Waves 9.00‚Äì4‚Äì3‚Äì2‚Äì10Signal1234 3.0 Figure 2.10 A comparison of a saw tooth function to the sum of its Fourier components, with the number of included waves varied interactively by a Matplotlib slider. FourierMatplot.py produced this output and was written by Oscar Estrepe. FL FR FL= 0.00FR= 600.00 ddx Figure 2.11 Left: A beam and a box supported at two points. Right: A screenshot from the animation showing the forces on the beam as the weight moves. a) howtozoominandzoomoutonsectionsofaplot, b) howtosaveyourplotstofilesinvariousformats, c) howtoprintupyourgraphs, d) theoptionsavailablefromthepull-downmenus, e) howtoincreasethespacebetweensubplots, f) andhowtorotateandscalethesurfaces. 2) AsshowninFigure2.11,abeamoflength L=10mandweight W=400Nrestsontwo supportsatadistance d=2mapart.Aboxofweight Wb=800N,initiallyabovetheleft support,slidesfrictionlesslytotherightwithavelocity ùë£=7m/s. a) Writeaprogramthatcalculatestheforcesexertedonthebeambytherightandleft supportsastheboxslidesalongthebeam. b) Extendyourprogramsothatitcreatesananimation,orjustaseriesofstills,show- ing the forces and the position of the block as the box slides along the beam. In Figure2.11,leftwepresentascreenshotcapturedfromoneofouranimations. c) Extendthetwo-supportproblemtoaboxslidingtotherightonabeamwithathird supportundertherightedgeofthebeam.",2734
2.7 Code Listings,"382 Software Basics 2.7 Code Listings Listing2.1 EasyVisual.py Producestwodifferent2DplotsusingtheVisualpackage. # EasyVisual.py: Simple graph object using Visual 2 fromvisual.graph import ‚àó # Import Visual 4 Plot1 = gcurve(color = color.white) # gcurve method forxinarange(0., 8.1, 0.1): #xr a n g e 6 Plot1.plot( pos = (x, 5. ‚àócos(2. ‚àóx)‚àóexp(‚àí0.4‚àóx)) )#P l o tp t s graph1 = gdisplay(width=600, height=450,\ 8 title= ‚ÄôVisual 2-D Plot‚Äô , xtitle= ‚Äôx‚Äô, ytitle= ‚Äôf(x)‚Äô,\ foreground = color.black, background = color.white) 10 Plot2 = gdots(color = color.black) #D o t s forxinarange( ‚àí5., +5, 0.1 ): 12 Plot2.plot(pos = (x, cos(x))) Listing 2.2 3GraphVisual.py Produces a 2D x-y plot with the Matplotlib and NumPy packages. 2 # 3GraphVisual.py: 3 plots in the same figure , with bars, dots and curve 4 fromvisualimport ‚àó fromvisual.graph import ‚àó 6 string = \""blue: sinÀÜ2(x), white: cosÀÜ2(x), red: sin(x)*cos(x)\"" 8 graph1 = gdisplay(title=string , xtitle= ‚Äôx‚Äô, ytitle= ‚Äôy‚Äô) y1 = gcurve(color=color.yellow, delta=3) # Curve 10 y2 = gvbars(color=color.white) # Vertical bars y3 = gdots(color=color.red, delta=3) #D o t s 12 forxinarange( ‚àí5, 5, 0.1): #a r a n g ef o rf l o a t s y1.plot( pos=(x, sin(x) ‚àósin(x)) ) 14 y2.plot( pos=(x, cos(x) ‚àócos(x)/3.) ) y3.plot( pos=(x, sin(x) ‚àócos(x)) ) Listing2.3 3Dshapes.py ProducesasampleofVPython‚Äôs3Dshapes. 2 # 3Dshapes.py: Some 3 ‚àíD Shapes of VPython 4 fromvisualimport ‚àó 6 graph1 = display(width=500, height=500, title= ‚ÄôVPython 3-D Shapes‚Äô ,range=10) sphere(pos=(0,0,0), radius=1, color=color.green) 8 sphere(pos= (0,1, ‚àí3), radius=1.5, color=color.red) arrow(pos=(3,2,2), axis=(3,1,1), color=color.cyan) 10 cylinder(pos=( ‚àí3,‚àí2,3), axis=(6, ‚àí1,5), color=color.yellow) cone(pos=( ‚àí6,‚àí6,0), axis=( ‚àí2,1,‚àí0.5), radius=2, color=color.magenta) 12 helix(pos=( ‚àí5,5,‚àí2), axis=(5,0,0), radius=2, thickness=0.4, color=color.orange) ring(pos=( ‚àí6,1,0), axis=(1,1,1), radius=2, thickness=0.3, color=(0.3,0.4,0.6)) 14 box(pos=(5, ‚àí2,2), length=5, width=5, height=0.4, color=(0.4,0.8,0.2)) pyramid(pos=(2,5,2), size=(4,3,2), color=(0.7,0.7,0.2)) 16 ellipsoid(pos=( ‚àí1,‚àí7,1), axis=(2,1,3), length=4, height=2, width=5, color=(0.1,0.9,0.8)) Listing2.4 EasyMatPlot.py Producesa2D x-yplotusingtheMatplotlibpackage(which includestheNumPypackage). # EasyMatPlot.py: Simple use of matplotlib ‚Äôs plot command 2 frompylabimport ‚àó # Load Matplotlib 2.7 Code Listings 39 4 Xmin = ‚àí5.; Xmax = +5.; Npoints= 500 6 DelX = (Xmax ‚àíXmin) / Npoints x = arange(Xmin, Xmax, DelX) 8 y= s i n ( x ) ‚àósin(x ‚àóx) # F(x array) print(‚Äôarange => x[0], x[1],x[499]= percent8.2f  percent8.2f  percent8.2f‚Äô  percent(x[0],x[1],x[499])) 10 print(‚Äôarange => y[0], y[1],y[499]= percent8.2f  percent8.2f  percent8.2f‚Äô  percent(y[0],y[1],y[499])) print(\""  Now doing the plotting thing, look for Figure 1 on desktop\"" ) 12 xlabel( ‚Äôx‚Äô); ylabel( ‚Äôf(x)‚Äô); title( ‚Äô f(x) vs x‚Äô ) text(‚àí1.75, 0.75, ‚ÄôMatPlotLib   Example‚Äô ) #T e x to np l o t 14 plot(x, y, ‚Äô-‚Äô,l w = 2 ) grid(True) # Form grid 16 show() Listing2.5 GradesMatPlot.py Producesa2D x-yplotusingtheMatplotlibpackage. # Grade.py: Using Matplotlib ‚Äôs plot command with multi data sets & curves 2 importpylab as p # Matplotlib 4 fromnumpyimport ‚àó 6 p.title( ‚ÄôGrade Inflation‚Äô ) # Title and labels p.xlabel( ‚ÄôYears in College‚Äô ) 8 p.ylabel( ‚ÄôGPA‚Äô) 10 xa = array([ ‚àí1, 5]) # For horizontal line ya = array([0, 0]) #\"" \"" 12 p.plot(xa, ya) # Draw horizontal line 14 x0 = array([0, 1, 2, 3, 4]) # Data set 0 points y0 = array([ ‚àí1.4, +1.1, 2.2, 3.3, 4.0]) 16 p.plot(x0, y0, ‚Äôbo‚Äô) # Data set 0 = blue circles p.plot(x0, y0, ‚Äôg‚Äô) # Data set 0 = line 18 x1 = arange(0, 5, 1) # Data set 1 points 20 y1 = array([4.0, 2.7, ‚àí1.8,‚àí0.9, 2.6]) p.plot(x1, y1, ‚Äôr‚Äô) 22 errTop = array([1.0, 0.3, 1.2, 0.4, 0.1]) # Asymmetric error bars 24 errBot = array([2.0, 0.6, 2.3, 1.8, 0.4]) p.errorbar(x1, y1, [errBot, errTop], fmt = ‚Äôo‚Äô) # Plot error bars 26 p.grid(True) # Grid line 28 p.show() # Create plot on screen Listing2.6 MatPlot2figs.py ProducesthetwofiguresshowninFigure2.7.Eachfigure containstwoplotswithoneMatplotlibfigure. # MatPlot2figs.py: plot of 2 subplots on 1 fig & 2 separate figs 2 frompylabimport ‚àó # Load Matplotlib 4 Xmin = ‚àí5.0; Xmax = 5.0; Npoints= 500 6 DelX= (Xmax ‚àíXmin)/Npoints # Delta x x1 = arange(Xmin, Xmax, DelX) #x 1r a n g e 8 x2 = arange(Xmin, Xmax, DelX/20) # Different x2 range y1 =‚àísin(x1) ‚àócos(x1 ‚àóx1) # Function 1 10 y2 = exp( ‚àíx2/4.) ‚àósin(x2) # Function 2 print(\""  Now plotting, look for Figures 1 &2 on desktop\"" ) 12 figure(1) # Figure 1 subplot(2,1,1) # 1st subplot in first figure 14 plot(x1, y1, ‚Äôr‚Äô,l w = 2 ) xlabel( ‚Äôx‚Äô); ylabel( ‚Äôf(x)‚Äô); title( ‚Äô-sin(x)*cos(xÀÜ2)‚Äô ) 16 grid(True) # Form grid subplot(2,1,2) # 2nd subplot in first figure 18 plot(x2, y2, ‚Äô-‚Äô,l w = 2 ) xlabel( ‚Äôx‚Äô) # Axes labels 402 Software Basics 20 ylabel( ‚Äôf(x)‚Äô) title( ‚Äôexp(-x/4)*sin(x)‚Äô ) 22 figure(2) # Figure 2 subplot(2,1,1) # 1st subplot in 2nd figure 24 plot(x1, y1 ‚àóy1, ‚Äôr‚Äô,l w = 2 ) xlabel( ‚Äôx‚Äô); ylabel( ‚Äôf(x)‚Äô); title( ‚ÄôsinÀÜ2(x)*cosÀÜ2(xÀÜ2)‚Äô ) # form grid 26 subplot(2,1,2) # 2nd subplot in 2nd figure plot(x2, y2 ‚àóy2, ‚Äô-‚Äô,l w = 2 ) 28 xlabel( ‚Äôx‚Äô); ylabel( ‚Äôf(x)‚Äô); title( ‚Äôexp(-x/2)*sinÀÜ2(x)‚Äô ) grid(True) 30 show() # Show graphs Listing2.7 PondMatPlot.py ProducesthescatterplotandthecurveshowninFigure5.4 inChapter5. # PondMatPlot.py: Monte ‚àíCarlo integration via vonNeumann rejection 2 importnumpy as np, matplotlib.pyplot as plt 4 N = 100; Npts = 3000; analyt = np.pi ‚àó‚àó2 6 x1 = np.arange(0, 2 ‚àónp.pi+2 ‚àónp.pi/N,2 ‚àónp.pi/N) xi = []; yi = []; xo = []; yo = [] 8 fig ,ax = plt.subplots() y1 = x1 ‚àónp.sin(x1) ‚àó‚àó2 # Integrand 10 ax.plot(x1, y1, ‚Äôc‚Äô, linewidth=4) ax.set_xlim ((0, 2 ‚àónp.pi)) 12 ax.set_ylim((0, 5)) ax.set_xticks([0, np.pi, 2 ‚àónp.pi]) 14 ax.set_xticklabels([ ‚Äô0‚Äô,‚Äô$\pi$‚Äô,‚Äô2$\pi$‚Äô]) ax.set_ylabel( ‚Äô$f(x) = x\,\sinÀÜ2 x $‚Äô, fontsize=20) 16 ax.set_xlabel( ‚Äôx‚Äô,fontsize=20) fig.patch.set_visible(False) 18 deffx(x): returnx‚àónp.sin(x) ‚àó‚àó2 # Integrand 20 j=0 # Inside curve counter xx = 2.",5954
2.7 Code Listings,"‚àónp.pi ‚àónp.random.rand(Npts) #0=<x<=2 p i 22 yy = 5 ‚àónp.random.rand(Npts) #0=<y<=5 foriin range (1,Npts): 24 if(yy[i] <= fx(xx[i])): # Below curve if(i<=100): xi.append(xx[i]) 26 if(i<=100): yi.append(yy[i]) j +=1 28 else: if(i<=100): yo.append(yy[i]) 30 if(i<=100): xo.append(xx[i]) boxarea = 2. ‚àónp.pi ‚àó5. #B o xa r e a 32 area = boxarea ‚àój/(Npts ‚àí1) # Area under curve ax.plot(xo,yo, ‚Äôbo‚Äô,markersize=3) 34 ax.plot(xi,yi, ‚Äôro‚Äô,markersize=3) ax.set_title( ‚ÄôAnswers: Analytic =  percent5.3f, MC =  percent5.3f‚Äô  percent(analyt,area)) 36 plt .show() Listing2.8 Simple3Dplot.py ProducestheMatplotlib3DsurfaceplotsinFigure2.8. # Simple3Dplot.py: matplotlib 3D plot you can rotate and scale via mouse 2 importmatplotlib.pylab as p 4 frommpl_toolkits.mplot3d importAxes3D 6 print(\""Please be patient, I have packages to import &points to plot\"" ) delta = 0.1 8 x = p.arange( ‚àí3., 3., delta ) y = p.arange( ‚àí3., 3., delta ) 10 X, Y = p.meshgrid(x, y) 2.7 Code Listings 41 Z=p .s i n( X ) ‚àóp.cos(Y) # Surface height 12 fig = p.figure() # Create figure ax = Axes3D(fig) #P l o t sa x e s 14 ax.plot_surface(X, Y, Z) # Surface ax.plot_wireframe(X, Y, Z, color = ‚Äôr‚Äô) # Add wireframe 16 ax.set_xlabel( ‚ÄôX‚Äô) ax.set_ylabel( ‚ÄôY‚Äô) 18 ax.set_zlabel( ‚ÄôZ‚Äô) p.show() # Output figure Listing2.9 Scatter3dPlot.py Producesa3DscatterplotusingMatplotlib3Dtools. \"" Scatter3dPlot.py from matplotlib examples\"" 2 importnumpy as np 4 frommpl_toolkits.mplot3d importAxes3D importmatplotlib.pyplot as plt 6 defrandrange(n, vmin, vmax): 8 return(vmax‚àívmin) ‚àónp.random.rand(n) + vmin fig = plt.figure() 10 ax = fig.add_subplot(111, projection= ‚Äô3d‚Äô) n = 100 12 forc, m, zl, zh in[(‚Äôr‚Äô,‚Äôo‚Äô,‚àí50,‚àí25), ( ‚Äôb‚Äô,‚ÄôÀÜ‚Äô,‚àí30,‚àí5)]: xs = randrange(n, 23, 32) 14 ys = randrange(n, 0, 100) zs = randrange(n, zl, zh) 16 ax.scatter(xs, ys, zs, c=c, marker= m) ax.set_xlabel( ‚ÄôX Label‚Äô ) 18 ax.set_ylabel( ‚ÄôY Label‚Äô ) ax.set_zlabel( ‚ÄôZ Label‚Äô ) 20 plt .show() Listing 2.10 EqHeatAnimateMat.py Produces an animation of a cooling bar using Matplotlib. 2 # EqHeat.py Animated heat equation soltn via fine differences 4 fromnumpyimport ‚àó importnumpy as np 6 importmatplotlib.pyplot as plt importmatplotlib.animation as animation 8 Nx = 101 10 Dx = 0.01414 Dt = 0.6 12 KAPPA = 210. # Thermal conductivity SPH = 900. # Specific heat 14 RHO = 2700. # Density cons = KAPPA/(SPH ‚àóRHO) ‚àóDt/(Dx ‚àóDx); 16 T=n p .z e r o s( ( N x , 2 ), float) # Temp @ first 2 times 18 definit(): forixin range (1, Nx ‚àí1): # Initial temperature 20 T[ix, 0] = 100.0; T[0, 0] = 0.0 #B a re n d sT=0 22 T[0, 1] = 0. T[Nx‚àí1, 0] = 0. 24 T[Nx‚àí1, 1] = 0.0 init() 26 k=range(0,Nx) fig = plt.figure() # Figure to plot 28 # select axis; 111: only one plot, x,y, scales given 422 Software Basics ax = fig.add_subplot(111, autoscale_on=False, xlim=( ‚àí5, 105), ylim=( ‚àí5, 110.0)) 30 ax.grid() # Plot grid plt.ylabel( \""Temperature\"" ) 32 plt.title( \""Cooling of a bar\"" ) line , = ax.plot(k, T[k,0], \""r\"",l w = 2 ) 34 plt.plot([1,99],[0,0], \""r\"",lw=10) plt.text(45,5, ‚Äôbar‚Äô,fontsize=20) 36 defanimate(dum): 38 forixin range (1, Nx ‚àí1): T[ix, 1] = T[ix, 0] + cons ‚àó(T[ix + 1, 0] + T[ix ‚àí1, 0]‚àí2.0‚àóT[ix, 0]) 40 line.set_data(k,T[k,1] ) forixin range (1, Nx ‚àí1): 42 T[ix, 0] = T[ix, 1] # 100 position row @ t =m returnline , 44 ani = animation.FuncAnimation(fig , animate,1) # Animation plt .show() Listing2.11 AreaFormatted.py DoesI/Otoandfromkeyboard,aswellasfromafile.",3379
2.7 Code Listings,"ItworkswitheitherPython2or3byswitchingbetween raw_input andinput.Notetoread fromafileusingCanopy,youmustrightclickinthePythonrunwindowandchoose Change toEditorDirectory . 1# AreaFormatted: Python 2 or 3 formated output, keyboard input, file input fromnumpyimport ‚àó fromsysimportversion 5if int(version[0])>2: # Python 3 uses input, not raw_input raw_input =input name =raw_input (‚ÄôKey in your name: ‚Äô ) # raw_input strings print(\""Hi \"",name) 9radius = eval(raw_input (‚ÄôEnter a radius: ‚Äô )) # For numerical values print(‚Äôyou entered radius=  percent8.5f‚Äô  percentradius) # formatted output print(‚ÄôEnter new name and r in file Name.dat‚Äô ) # raw_input strings inpfile = open(‚ÄôName.dat‚Äô ,‚Äôr‚Äô) #R e a df r o mf i l eN a m e . d a t 13forlineininpfile: line = line.split() # Splits components of line name = line [0] # First entry in the list print(\"" Hi  percent10s\""  percent(name)) # print Hi + first entry 17r=float(line[1]) # convert string to float print(\"" r =  percent13.5f\""  percent(r)) # convert to float &print inpfile.close() A=m a t h.p i ‚àór‚àó‚àó2 21print(\""Done, look in A.dat \"" ) outfile = open(‚ÄôA.dat‚Äô,‚Äôw‚Äô) outfile.write( ‚Äôr=  percent13.5f ‚Äô  percent(r)) outfile.write( ‚ÄôA =  percent13.5f ‚Äô  percent(A)) 25outfile.close() print(‚Äôr =  percent13.5f‚Äô  percent(r) , ‚Äô, A =  percent13.5f‚Äô  percent(A)) # Screen output print(‚Äô  Now example of integer input ‚Äô ) age=int(eval(raw_input (‚ÄôNow key in your age as an integer: ‚Äô ))) 29print(\""age:  percent4d years old, you don‚Äôt look it. \""  percent(age)) print(\""Enter and return a character to finish\"" ) s=raw_input () Listing2.12 Directives.py Illustratesformattingviadirectivesandescapecharacters. # Directives.py illustrates escape and formatting characters importsys 3print(\""hello  \"" ) print(\""\t it‚Äôs me\"" ) # tabulator b=7 3 print(\""decimal 73 as integer b =  percentd \""  percent(b))# for integer 7print(\""as octal b =  percento\""  percent(b)) #o c t a l 2.7 Code Listings 43 print(\""as hexadecimal b =  percentx \""  percent(b)) # works hexadecimal print(\""learn \\""Python\\"" \"" ) # use of double quote symbol print(\""shows a backslash \\\"" ) # use of \\ 11print(‚Äôuse of single \‚Äô quotes \‚Äô ‚Äô ) # print single quotes Listing2.13 Limits.py Determinesmachineprecisionwithinafactorof2.Notehowwe skip a line at the beginning of each class or method and how we align the closing brace verticallywithitsappropriatekeyword(initalics) # Limits.py: determines approximate machine precision 2 N=1 0 eps = 1.0 foriin range (N): 6eps = eps/2 one_Plus_eps = 1.0 + eps print(‚Äôeps = ‚Äô ,e p s , ‚Äô, one + eps = ‚Äô , one_Plus_eps)",2572
Chapter 3 Errors and Uncertainties. 3.1 Types of Errors,"44 3 Errors and Uncertainties To err is human, to forgive divine . ‚ÄîAlexander Pope Whether you are careful or not, errors and uncertainties are integral parts of a computation. In this chapter we examine some of the errors and uncertainties that may occur in compu- tations. Although we do not keep repeating a mantra about watching for error, the lessons of this chapter apply to all other chapters as well . 3.1 Types of Errors Some errors are the ones that humans inevitably make, but some are introduced by the computer. Computer errors arise because of the limited precision with which computers storenumbers,orbecausealgorithmsormodelsarenotperfect.Althoughitstiflescreativity tokeepthinking‚Äúerror‚Äùwhenapproachingacomputation,itcertainlyisawasteoftime andbadsciencetoworkwithresultsthataremeaningless(‚Äúgarbage‚Äù)becauseoferrors. Let‚Äôssaythatyouhaveaprogramofhighcomplexity.Togaugewhyerrorsshouldbeof concern,imaginethatyourprogramhasthelogicalflow start‚ÜíU1‚ÜíU2‚Üí¬∑¬∑¬∑‚ÜíUn‚Üíend, (3.1) whereeachunit Uimightbeastatementorastep.Ifeachunithasprobability pofbeing correct,thenthejointprobability Pofthewholeprogrambeingcorrectis P=pn.Let‚Äôsalso saywehaveamedium-sizedprogramwith n=1000stepsandthattheprobabilityofeach stepbeingcorrectisalmostone, p‚âÉ0.9993.Thismeansthatyouendupwith P‚âÉ1 2,thatis, afinalanswerthatisaslikelywrongasright(notagoodwaytobuildabridge).Theproblem isthat,asascientist,youwantaresultthatiscorrect‚Äîoratleastinwhichtheuncertainty issmallandofknownsize,evenifthecodeexecutesmillionsofsteps. Fourgeneraltypesoferrorsexisttoplagueyourcomputations: 1. Blundersorbadtheory: typographicalerrorsenteredwithyourprogramordata,run- ningthewrongprogram,orhavingafaultinyourreasoning(theory),usingthewrong datafile,andsoon.(Ifyourblundercountstartsincreasing,itmaybetimetogohome ortakeabreak.) ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 3.1 Types of Errors 45 2. Random errors: imprecision caused by events such as fluctuations in electronics, cosmicrays,orsomeonepullingaplug.Thesemayberare,butyouhavenocontrolover themandtheirlikelihoodincreaseswithrunningtime;whileyoumayhaveconfidence ina20-secondcalculation,aweek-longcalculationmayhavetoberunmultipletimes tocheckreproducibility. 3. Approximationerrors: imprecisionarisingfromsimplifyingthemathematicssothat aproblemcanbesolvedonthecomputer.Theyincludethereplacementofinfiniteseries byfinitesums,infinitesimalintervalsbyfiniteones,andvariablefunctionsbyconstants. Forexample, sin(x)=‚àû‚àë n=1(‚àí1)n‚àí1x2n‚àí1 (2n‚àí1).(mathematicallyexact), ‚âÉN‚àë n=1(‚àí1)n‚àí1x2n‚àí1 (2n‚àí1).+Óà±(x,N)(algorithm). (3.2) HereÓà±(x,N)is the approximation error, and it is the ignored series from N+1t o‚àû. Sinceapproximationerrorarisesfromthealgorithmweusetoapproximatethemathe- matics,itisalsocalled algorithmicerror .Foragoodalgorithm,theapproximationerror shoulddecreaseas Nincreases,andshouldvanishinthe N‚Üí‚àûlimit.Specificallyfor (3.2),becausethescalefor Nissetbythevalueof x,asmallapproximationerrorrequires N‚â´x.SoifxandNarecloseinvalue,theapproximationerrorwillbelarge. 4. Round-off errors: imprecision arising from the finite number of digits used to store floating-pointnumbers.These‚Äúerrors‚Äùareanalogoustotheuncertaintyinthelabora- tory measurement of a physical quantity. The overall round-off error accumulates as thecomputerhandlesmorenumbers,thatis,asthenumberofstepsinacomputation increases.Thismaycausesomealgorithmstobecome unstablewithaconcordantrapid increaseinerror.Insomecases,round-offerrormaybecomethemajorcomponentin youranswer,leadingtowhatcomputerexpertscall garbage. Forexample,ifyourcomputerkeptfourdecimalplaces,thenitwillstore1 3as0.3333and 2 3as0.6667,wherethecomputerhas‚Äúroundedoff‚Äùthelastdigitin2 3.Accordingly,ifwe askthecomputertodoassimpleacalculationas2( 1 3) ‚àí2 3,itwouldyield 2( 1 3) ‚àí2 3=0.6666‚àí0.6667=‚àí0.0001 ‚â†0. (3.3) So although the result may be small, it is not 0, and if we repeat this type of calcula- tionmillionsoftimes,thefinalanswermightnotbesmall(smallgarbagebegetslarge garbage). When considering the precision of calculations it is good to recall our discussion in Chapter 2 of significant figures. For computational purposes, let us consider how the computermaystorethefloating-pointnumber a=11223344556677889900 =1.12233445566778899 √ó1019. (3.4) Becausetheexponentisstoredseparatelyandisasmallnumber,wemayassumethatit willbestoredinfullprecision.Incontrast,someofthedigitsofthemantissamaybetrun- cated.Indoubleprecision,themantissaof awillbestoredintwowords,the mostsignificant partrepresenting the decimal 1.12233,and the leastsignificantpart 44556677.The digits",4641
3.1.1 Courting Disaster Subtractive Cancelation. 3.1.2 Subtractive Cancelation Exercises,"46 3 Errors and Uncertainties beyond7arelost.Asweshallseesoon,whenweperformcalculationswithwordsoffixed length,itisinevitablethaterrorswillbeintroduced(atleast)intotheleastsignificantparts ofthewords. 3.1.1 Courting Disaster: Subtractive Cancelation Calculations employing numbers that are stored approximately can only be expected to yieldapproximateanswers.Todemonstratetheeffectofthistypeofuncertainty,wemodel thecomputerrepresentation xcoftheexactnumber xas xc‚âÉx(1+ùúñx). (3.5) Hereùúñxis the relative error in xc, which we expect to be of a similar magnitude to the machine precision ùúñm. If we apply this notation to the simple subtraction a=b‚àíc,w e obtain a=b‚àíc‚áíac‚âÉbc‚àícc‚âÉb(1+ùúñb)‚àíc(1+ùúñc) ‚áíac a‚âÉ1+ùúñbb a‚àíc aùúñc. (3.6) Weseefrom(3.6)thattheresultingerrorin aisessentiallyaweightedaverageoftheerrors inbandc,withnoassurancethatthelasttwotermswillcancel.Ofspecialimportancehere is the observation that the error in the answer acincreases when we subtract two nearly equalnumbers( b‚âÉc)becauseaisthensmall,andwearesubtractingoffthemostsignifi- cantpartsofbothnumbersandleavingtheerror-proneleast-significantparts: ac adef=1+ùúña‚âÉ1+b a(ùúñb‚àíùúñc)‚âÉ1+b amax(|ùúñb|,|ùúñc|). (3.7) Thisshowsthateveniftherelativeerrorsin bandccancelsomewhat,theyaremultiplied by the large number b‚àïa, which can significantly magnify the error. Because we cannot assumeanysignfortheerrors,wemustassumetheworst. Theorem Ifyousubtracttwolargenumbersandendupwithasmallone,thesmallone islesssignificantthanthelargenumbers. Wehavealreadyseenanexampleofsubtractivecancelationinthepowerseriessumma- tionforsin x‚âÉx‚àíx3‚àï3.+¬∑¬∑¬∑forlargex.Asimilareffectoccursfor e‚àíx‚âÉ1‚àíx+x2‚àï2.‚àí x3‚àï3.+¬∑¬∑¬∑forlargex.Herethefirstfewtermsarelargebutofalternatingsign,leadingtoan almosttotalcancelationinordertoyieldthefinalsmallresult.Inthiscase,subtractivecan- celationcanbeeliminatedbyusingtheidentity e‚àíx=1‚àïexandthenevaluating ex,although round-offerrorwillstillremain. 3.1.2 Subtractive Cancelation Exercises 1) Remember backinhighschoolwhenyoulearnedthatthequadraticequation ax2+bx+c=0 (3.8) hasananalyticsolutionthatcanbewrittenaseither x1,2=‚àíb¬±‚àö b2‚àí4ac 2aorx‚Ä≤ 1,2=‚àí2c b¬±‚àö b2‚àí4ac. (3.9) 3.1 Types of Errors 47 Inspectionof(3.9)indicatesthatsubtractivecancelation(andconsequentlyanincrease in error) arises when b2‚â´4ac, as then the square root and its preceding term nearly cancelforoneoftheroots. a) Writeaprogramthatcalculatesallsolutionsforarbitraryvaluesof a,b,andc. b) Investigate how errors in your computed answers become large as the subtractive cancelationincreases,andrelatethistotheknownmachineprecision. Hint:Agood testcaseutilizes a=1,b=1,c=10‚àín,n=1,2,3,‚Ä¶. 2) Aswehaveseen,subtractivecancelationoccurswhensummingaserieswithalternating signs.Asanotherexample,considerthefinitesum S(1) N=2N‚àë n=1(‚àí1)nn n+1. (3.10) Ifyousumtheevenandoddvaluesof nseparately,yougettwosums: S(2) N=‚àíN‚àë n=12n‚àí1 2n+N‚àë n=12n 2n+1. (3.11) All terms are positivein this formwith just a singlesubtraction at the end of the cal- culation.Yeteventhisonesubtractionanditsresultingcancelationcanbeavoidedby combiningtheseriesanalyticallytoobtain S(3) N=N‚àë n=11 2n(2n+1). (3.12) Althoughallthreesummations S(1),S(2),andS(3)aremathematicallyequal,theymay givedifferentnumericalresults. 1) Writeadouble-precisionprogramthatcalculates S(1),S(2),andS(3). 2) Assume S(3)tobetheexactanswer.Makealog‚Äìlogplotoftherelativeerror versusthe numberofterms,thatis,oflog10|(S(1) N‚àíS(3) N)‚àïS(3) N|versuslog10(N).Startwith N=1 andworkupto N=1,000,000.(Recallthatlog10x=lnx‚àïln10.)Thenegativeofthe ordinateinthisplotgivesanapproximatevalueforthenumberofsignificantfigures. 3) Seewhetherstraight-linebehaviorfortheerroroccursinsomeregionsofyourplot. Thisindicatesthattheerrorisproportionaltoapowerof N. 3) Inspiteofthepowerofyourtrustycomputer,calculatingthesumofevenasimpleseries mayrequiresomethoughtandcare.Considerthetwoseries S(up)=N‚àë n=11 n,S(down)=1‚àë n=N1 n. (3.13) Bothseriesarefiniteaslongas Nisfinite,andwhensummedanalyticallybothgivethe sameanswer.Nonetheless,becauseofround-offerror,thenumericalvalueof S(up)will notbepreciselythatof S(down). a) Writeaprogramtocalculate S(up)andS(down)asfunctionsof N. b) Makealog‚Äìlogplotof (S(up)‚àíS(down))‚àï(|S(up)|+|S(down)|)versusN. c) Observethelinearregimeonyourgraphandexplainwhythedownwardsumisgen- erallymoreprecise.",4260
3.1.3 RoundOff Errors. 3.2 Experimental Error Investigation,"48 3 Errors and Uncertainties 3.1.3 Round-Off Errors Let‚Äôs startbyseeinghowerrorarisesfromasingledivisionofthecomputerrepresentations oftwonumbers: a=b c‚áíac=bc cc=b(1+ùúñb) c(1+ùúñc), ‚áíac a=1+ùúñb 1+ùúñc‚âÉ(1+ùúñb)(1‚àíùúñc)‚âÉ1+ùúñb‚àíùúñc, ‚áíac a‚âÉ1+|ùúñb|+|ùúñc|. (3.14) Here we have ignored the very small ùúñ2terms, and have added the absolute value of the errors since we can‚Äôt assume that good fortune will lead to errors canceling each other. Because we add the errors in absolute value, this same rule holds for multiplication. Equation(3.14)isjustthebasicruleoferrorpropagationfromelementarylaboratorywork: Youaddtheuncertaintiesineachquantityinvolvedinananalysistoarriveattheoverall uncertainty. We can even generalize this model to estimate the error in the evaluation of a general functionf(x),thatis,thedifferenceinthevalueofthefunctionevaluatedat xandatxc: Óà±=f(x)‚àíf(xc) f(x)‚âÉdf(x)‚àïdx f(x)(x‚àíxc). (3.15) So,forexample, f(x)=‚àö 1+x,df dx=1 21‚àö 1+x=1 4f(x)(x‚àíxc) (3.16) ‚áíÓà±‚âÉ1 2‚àö 1+x(x‚àíxc)=x‚àíxc 2(1+x). (3.17) If we evaluate this expression for x=ùúã‚àï4 and assume an error in the fourth place of x, weobtainasimilarrelativeerrorof1.5 √ó10‚àí4in‚àö 1+x. 3.1.4 Round-Off Error Accumulation Thereisausefulmodelforapproximatinghowround-offerroraccumulatesinacalculation involvingalargenumberofsteps.AsillustratedinFigure3.1,weviewtheerrorineachstep ofacalculationasaliteral‚Äústep‚Äùina randomwalk ,thatis,awalkforwhicheachstepisina R 1 Œîy1 Œîy2Œîx1 2 34NFigure 3.1 A schematic of the Nsteps in a random walk simulation that ends up a distance R=‚àö Nfrom the origin. Notice how the Œîx‚Äôs for each step add vectorially. 3.2 Experimental Error Investigation 49 randomdirection.AswewillderiveandsimulateinChapter4,thetotaldistance Rcovered inNstepsoflength r,is,ontheaverage, R‚âÉ‚àö Nr. (3.18) Byanalogy,thetotalrelativeerror ùúñroarisingafter Ncalculationalstepseachwithmachine precisionerror ùúñmis,ontheaverage, ùúñro‚âÉ‚àö Nùúñm. (3.19) Iftheround-offerrorsinaparticularalgorithmdonotaccumulateinarandommanner, thenadetailedanalysisisneededtopredictthedependenceoftheerroronthenumberof stepsN.Insomecases,theremaybenocancellation,andtheerrormayincreaseas Nùúñm. Evenworse,insomerecursivealgorithms,wheretheerrorgenerationiscoherent,suchas theupwardrecursionforsphericalBesselfunctions,theremaybean N.increaseinerror. 3.2 Experimental Error Investigation Algorithms playavitalroleincomputationalphysics.Your problemistotakeanalgorithm anddecide 1) Doesitconverge,andifso,howfast? 2) Evenifitconverges,aretheanswersprecise? 3) Howexpensive(time-consuming)isthealgorithm? Your first thought might be ‚ÄúWhat a dumb problem. All algorithms converge if you let them run long enough. If you want more precision, then just let them run longer.‚Äù Well,somealgorithmsmaybeasymptoticexpansionsthatjustapproximateafunctionin certainregionsofparameterspace,andconvergeonlyuptoapoint.Yetevenifauniformly convergentpowerseriesisusedasthealgorithm,includingmoretermsmaydecreasethe algorithmicerrorbutincreasetheround-offerror.Andbecauseround-offerrorseventually divergetoinfinity,thebestwecanhopeforisa‚Äúbest‚Äùapproximation. Goodalgorithmsare good not only because fewer steps take less time, but also because fewer steps produces less round-offerror . Let‚Äôsassumethatanalgorithmtakes Nstepstofindagoodanswer.Asaruleofthumb, theapproximation(algorithmic)errordecreasesrapidly,oftenassomeinversepowerofthe numberoftermsused: ùúñapp‚âÉùõº NùõΩ. (3.20) HereùõºandùõΩareempiricalconstantsthatchangefordifferentalgorithmsandmaybeonly approximatelyconstant,andeventhenonlyas N‚Üí‚àû.Thefactthattheerror mustfalloff forlargeNisjustastatementthatthealgorithmworks. Incontrasttoalgorithmicerror,round-offerrorgrowsslowlyandsomewhatrandomly withN. If the round-off errors in each step of the algorithm are not correlated, then we knowfrompreviousdiscussionthatwecanmodeltheaccumulationoferrorasarandom walkwithstepsizeequaltothemachineprecision ùúñm: ùúñro‚âÉ‚àö Nùúñm. (3.21) 50 3 Errors and Uncertainties This is the slow growth with Nthat we expect from round-off error. The total error in a computationisthesumofthetwotypesoferrors: ùúñtot=ùúñapp+ùúñro (3.22) ùúñtot‚âÉùõº NùõΩ+‚àö Nùúñm. (3.23) For smallNweexpectthefirsttermtobethelargerofthetwo,butas Ngrowsitwillbe overcomebytheever-increasinground-offerror. Asanexample,inFigure3.2,wepresentalog‚Äìlogplotoftherelativeerrorinnumerical integrationusingtheSimpsonintegrationrule(Chapter5).Weusethelog10oftherelative errorbecauseitsnegativetellsusthenumberofdecimalplacesofprecisionobtained.1Letus assume Óà≠istheexactanswerand A(N)thecomputedanswer.If Óà≠‚àíA(N) Óà≠‚âÉ10‚àí9,then log10||||Óà≠‚àíA(N) Óà≠||||‚âÉ‚àí9. (3.24) We see in Figure 3.2 that the error does show a rapid decrease for small N, consistent withaninversepowerlaw(3.20).Inthisregion,thealgorithmisconverging.As Nkeeps increasing,theerrorstartstolooksomewhaterratic,withaslowincreaseontheaverage. In accordance with (3.22), in this region, round-off error has grown larger than the approximationerrorandwillcontinuetogrowforincreasing N.Clearlythen,thesmallest total error will be obtained if we can stop the calculation at the minimum near 10‚àí14, thatis,when ùúñapprox‚âÉùúñro. In realistic calculations you would not know the exact answer; after all, if you did, then why would you bother with the computation? However, you may know the exact answerforasimilarcalculation,andyoucanusethatsimilarcalculationtoperfectyour numerical technique. Alternatively, now that you understand how the total error in a computation behaves, you should be able to look at a table or, better yet, a graph like 10 10010‚Äì1310‚Äì9 N| Relative error |Approximation error Round off error Figure 3.2 A log‚Äìlog plot of relative error versus the number of points used for a numerical integration. The ordinate value of ‚àº10‚àí14at the minimum indicates that ‚àº14 decimal places of precision are obtained before round-off error begins to build up. Notice that while the round-off error does Ô¨Çuctuate indicating a statistical aspect of error accumulation, on the average it is increasing but more slowly than did the algorithm‚Äôs error decrease. 1 Mostcomputerlanguagesuseln x=logex.Yetbecause x=alogax,wehavelog10x=lnx‚àïln10. 3.2 Experimental Error Investigation 51 Figure3.2,ofyouransweranddeducethemannerinwhichyouralgorithmisconverging. Specifically, at some point, you should see that the mantissa of the answer changes only in the less significant digits, with that place moving further to the right of the decimal pointasthecalculationexecutesmoresteps.Eventually,however,asthenumberofsteps becomes even larger, round-off error leads to a fluctuation in the less significant digits, withagradualincreaseontheaverage.Itisbesttoquitthecalculationbeforethisoccurs. Based upon this understanding, an approach to obtaining the best approximation is to deducewhenyouranswerbehaveslike(3.22).Todothat,wecall Óà≠theexactanswerand A(N)thecomputedanswerafter Nsteps.Weassumethatforlargeenoughvaluesof N,the approximationconvergesas A(N)‚âÉÓà≠+ùõº NùõΩ, (3.25) thatis,theround-offerrortermin(3.22)isstillsmall.Wethenrunourcomputerprogram with 2Nsteps, which should give a better answer, and use that answer to eliminate the unknown Óà≠: A(N)‚àíA(2N)‚âÉùõº NùõΩ. (3.26) Toseeiftheseassumptionsarecorrectanddeterminewhatlevelofprecisionispossiblefor thebestchoiceof N,plotlog10|[A(N)‚àíA(2N)]‚àïA(2N)|versuslog10N,similartowhatwe haveperformedinFigure3.2.Ifyouobtainarapidstraight-linedrop-off,thenyouknow youareintheregionofconvergenceandcandeduceavaluefor ùõΩfromtheslope.As Ngets larger,youshouldseethegraphchangefromastraight-linedecreasetoaslowincreaseas round-offerrorbeginstodominate.Agoodplacetoquitisbeforethis.Inanycase,nowyou understandtheerrorinyourcomputationandthereforehaveachancetocontrolit. Asanexampleofhowdifferentkindsoferrorsenterintoacomputation,weassumewe knowtheanalyticformfortheapproximationandround-offerrors: ùúñapp‚âÉ1 N2,ùúñro‚âÉ‚àö Nùúñm, (3.27) ‚áíùúñtot=ùúñapprox+ùúñro‚âÉ1 N2+‚àö Nùúñm. (3.28) Thetotalerroristhenaminimumwhen dùúñtot dN=‚àí2 N3+1 2ùúñm‚àö N=0, (3.29) ‚áíN5‚àï2=4 ùúñm. (3.30) Foradouble-precisioncalculation( ùúñm‚âÉ10‚àí15),theminimumtotalerroroccurswhen N5‚àï2‚âÉ4 10‚àí15‚áíN‚âÉ1099,‚áíùúñtot‚âÉ4√ó10‚àí6. (3.31) Inthiscasemostoftheerrorisasaresultofround-offandisnotapproximationerror. Seeingthatthetotalerrorismainlyround-offerror ‚àù‚àö N,anobviouswaytodecrease theerroristouseasmallernumberofsteps N.Letusassumewedothisbyfindinganother algorithmthatconvergesmorerapidlywith N,forexample,onewithapproximationerror behavinglike ùúñapp‚âÉ2 N4. (3.32)",8330
3.4 Errors in Bessel Functions,"52 3 Errors and Uncertainties Thetotalerrorisnow ùúñtot=ùúñro+ùúñapp‚âÉ2 N4+‚àö Nùúñm. (3.33) Thenumberofpointsforminimumerrorisfoundasbefore: dùúñtot dN=0‚áíN9‚àï2‚áíN‚âÉ67‚áíùúñtot‚âÉ9√ó10‚àí7. (3.34) Theerrorisnowsmallerbyafactorof4,withonly1/16asmanystepsneeded.Subtleare thewaysofthecomputer.Inthiscase,thebetteralgorithmisquickerand,byusingfewer steps,produceslessround-offerror. Exercise Estimatetheerrorforadouble-precisioncalculation. 3.3 Errors with Power Series A classic numerical problem is the summation of a series to evaluate a function. As an example,considertheinfiniteseriesforsin x: sinx=x‚àíx3 3.+x5 5.‚àíx7 7.+¬∑¬∑¬∑ ( exact). (3.35) Yourproblemis to use just this series to calculate sin xforx<2ùúãandx>2ùúã, with an absolute error in each case of less than 1 part in 108. While in a mathematical sense an infiniteseriesisexactandalwaysconverges,itisnotanalgorithmbecausecomputerscan‚Äôt sumaninfinitenumberofterms.Analgorithmwouldbethefinitesum sinx‚âÉN‚àë n=1(‚àí1)n‚àí1x2n‚àí1 (2n‚àí1).(algorithm ). (3.36) Buthowdowedecidewhentostopsumming?(Donoteventhinkofsaying,‚ÄúWhenthe answeragreeswithatableorwiththebuilt-inlibraryfunction.‚Äù)Oneapproachwouldbe tostopsummingwhenthenexttermissmallerthantheprecisiondesired.Clearlythen, ifxislargethiswouldrequireverylarge N.Infact,forverylarge x,onewouldhavetogo faroutintheseriesbeforethetermsevenstarttodecrease,letalonetheseriesasawhole converges. Weshouldalsobewaryofthealgorithm(3.36)becauseitwouldhaveuscalculate x2n‚àí1 and then divide that by (2n‚àí1).. This is not good computation. On the one hand, both (2n‚àí1).andx2n‚àí1canindividuallygetverylargeandtherebycauseoverflows,despitethe fact that their quotient may be small. On the other hand, powers and factorials are very expensive(time-consuming)toevaluateonthecomputer.Consequently,abetterapproach istouseasinglemultiplicationtorelatethenexttermintheseriestothepreviousone: (‚àí1)n‚àí1x2n‚àí1 (2n‚àí1).=‚àíx2 (2n‚àí1)(2n‚àí2)(‚àí1)n‚àí2x2n‚àí3 (2n‚àí3). ‚áínthterm=‚àíx2 (2n‚àí1)(2n‚àí2)√ó(n‚àí1)thterm. (3.37) While we might want to insure absolute accuracy for sin x, that is not easy to do. What iseasytodoistoassumethattheerrorinthesummationisapproximatelythelastterm 3.3 Errors with Power Series 53 summed(thisassumesnoround-offerror).Toobtainarelativeerrorof1partin108,we thenwouldstopthecalculationwhen ||||nthterm sum||||<10‚àí8, (3.38) where‚Äúterm‚Äùisthelasttermkeptintheseries(3.36)and‚Äúsum‚Äùistheaccumulatedsumof alltheterms.Ingeneral,youarefreetopickanytolerancelevelyoudesire,althoughifitis toocloseto,orsmallerthan,machineprecision,yourcalculationmaynotbeabletoattain it.Apseudocodeforperformingthesummationis term = x, sum= x, eps = 10^( ‚àí8) # Initialize do 2do term = ‚àíterm ‚àóx‚àóx/(2n‚àí1)/(2 ‚àón‚àí2); #N e ww r to l d sum=sum+t e r m #A d dt e r m while abs (term/sum)>e p s # Break iteration end do 3.3.1 Implementation and Assessment 1) Write a program that implements this pseudocode for the indicated xvalues. Start with a tolerance of 10‚àí8as in (3.38). Present the results as a table with headings xNs u m |sum‚Äìsin(x) |/sin(x),where sin(x)isthevalueobtainedfromthebuilt-in function Math.sin(x) (you may assume that the built-in function is exact). The last columnhereistherelativeerrorinyourcomputation. 2) Showthatforsufficientlysmallvaluesof x,youralgorithmconverges(thechangesin sumaresmallerthanyourtolerancelevel)andthattheseriesconvergestothecorrect answer. 3) Comparethenumberofdecimalplacesofprecisionobtainedwiththatexpectedfrom (3.38). 4) Withoutusingtheidentitysin (x+2nùúã)=sin(x),showthatthereisarangeofsome- whatlargevaluesof xforwhichthealgorithmconverges,butthatitconvergestothe wronganswer. 5) Observe how significant subtractive cancelations occur when large terms are added together to give small answers. In particular, print out the near-perfect cancellation aroundn‚âÉx‚àï2. 6) Showthatasyoukeepincreasing x,youwillreacharegimewherethealgorithmstops converging. 7) Nowmakeuseoftheidentitysin (x+2nùúã)=sin(x)tocomputesin xforlargexvalues wheretheseriesotherwisewoulddiverge. 8) Byprogressivelyincreasing xfrom1to10,andthenfrom10to100,useyourprogramto determineexperimentallywhentheseriesstartstoloseaccuracyandwhenitnolonger converges. 9) Makeaseriesofgraphsoftheerror versusNfordifferentvaluesof x.Youshouldget curvessimilartothoseinFigure3.3. 10) Repeatthecalculationusinga‚Äúbad‚Äùversionofthealgorithm(onethatcalculatesfac- torials)andcomparetheanswers. 11) Setyourtoleranceleveltoanumbersmallerthanmachineprecisionandseehowthis affectsyourconclusions. 54 3 Errors and Uncertainties 05 1 0 1 5 2 0 Number of terms in series1e-091e-060.001110001e+06Error Figure 3.3 The error in the summation of the series for e‚àíxversus N for various xvalues. The values of xincrease vertically for each curve. Note that a negative initial slope corresponds to decreasing algorithmic error with N, and that the dip indicates a rapid convergence followed by a rapid increase in error. (courtesy of J. Wiren.) Notethatbecausethisseriessummationissuchasimple,correlatedprocess,theround-off errordoesnotaccumulaterandomlyasitmightforamorecomplicatedcomputation,and wedonotobtaintheerrorbehavior(3.25).Wewillseethepredictederrorbehaviorwhen weexamineintegrationinChapter5. 3.3.2 Error in Specular ReÔ¨Çection Foraperfectlyreflectingsurface,thebasiclawofopticstellsusthattheangleofincidence equalstheangleofreflection(Figure3.4left.Ifnolightisabsorbedduringareflection,a lightraywouldcontinuetoreflectendlessly(Figure3.4right).Withanoriginplacedatthe centerofthecircularmirror,welocatetheraybytheangle ùúÉ.Foraninitialangle ùúô<ùúã,the angleincreasesby2 ùúôaftereachreflection: ùúÉnew=ùúÉold+2ùúô. (3.39) Œ∏ œï œï Figure 3.4 Left: Specular reÔ¨Çection within a circular mirror in which the incident angle equals the angle of reÔ¨Çection. Right: InÔ¨Ånite internal reÔ¨Çections between two circular mirrors.",5712
3.4.1 Numerical Recursion Method,"3.4 Errors in Bessel Functions 55 Althoughthisappearstoindicatethat ùúÉincreasesendlessly,theadditionorsubtractionof 2ùúãtoùúÉdoesnotchangethelocationonthecircle,andsoif ùúô‚àïùúãisarationalnumber, ùúô ùúã=n m, (3.40) theraywillfalluponitselfandformageometricfigure(Figure3.4right). 1) Determinethepathfollowedbyalightrayforaperfectlyreflectingmirror. 2) Plotthelighttrajectoriesforarangeofvaluesfortheinitialangle ùúô. 3) Repeatthepreviouscalculationusingjustfourplacesofprecision.Youcandothisby usingthePythoncommand round,forinstance, round(1.234567,4) = 1.234. Youshould findthatasignificantrelativeerroraccumulates.Asinlargeandcomplicatedcalcula- tionswithmanystepsandfiniteprecision,thistypeoferrorincreasesasthenumberof calculationalstepsincreases. 3.4 Errors in Bessel Functions Accumulatinground-offerrorsoftenlimitstheabilityofaprogramtocalculateaccurately. YourproblemistocomputethesphericalBesselandNeumannfunctions jl(x)andnl(x). Thesefunctionsare,respectively,theregular/irregular(nonsingular/singularattheorigin) solutionsofthedifferentialequation x2f‚Ä≤‚Ä≤(x)+2xf‚Ä≤(x)+[x2‚àíl(l+1)]f(x)=0. (3.41) The spherical Bessel functions are related to the Bessel function of the first kind by jl(x)=‚àö ùúã‚àï2xJn+1‚àï2(x).Theyoccurinmanyphysicalproblems,suchastheexpansionofa planewaveintosphericalpartialwaves, eik‚ãÖr=‚àû‚àë l=0il(2l+1)jl(kr)Pl(cosùúÉ). (3.42) Figure3.5showswhatthefirstfew jllookslike,andTable3.1givessomeexplicitvalues. Forthefirsttwo lvalues,theexplicitformsare j0(x)=+sinx x,j1(x)=+sinx x2‚àícosx x(3.43) n0(x)=‚àícosx x.n1(x)=‚àícosx x2‚àísinx x. (3.44) 3.4.1 Numerical Recursion (Method) Theclassicwaytocalculate jl(x)wouldbebysummingitspowerseriesforsmallvaluesof x‚àïlandsummingitsasymptoticexpansionforlarge x‚àïlvalues.Theapproachweadopthere isbasedonthe recursionrelations jl+1(x)=2l+1 xjl(x)‚àíjl‚àí1(x),(up), (3.45) jl‚àí1(x)=2l+1 xjl(x)‚àíjl+1(x),(down). (3.46) 56 3 Errors and Uncertainties 0.0 2.0 4.0 6.0 8.0 10.0 12.0 x0.0 ‚Äì0.20.20.40.60.81.0jl (x)l = 0 l = 1 l = 3 Figure 3.5 The Ô¨Årst four spherical Bessel functions jl(x) as functions of x. Notice that for small x, the values for increasing lbecome progressively smaller. Table 3.1 Approximate values for spherical Bessel functions (from Maple). xj3(x) j5(x) j8(x) 0.1+9.51851971910‚àí6+9.61631023110‚àí10+2.90120010210‚àí16 1+9.00658111810‚àí3+9.25611586210‚àí05+2.82649880210‚àí08 10‚àí3.94958449810‚àí2‚àí5.55345116210‚àí02+1.25578023610‚àí01 Equations (3.45) and (3.46) are the same mathematical relation, one written for upward recurrence from small to large lvalues, and the other for downward recurrence from largelto smalll. We shall see that with just a few additions and multiplications, recur- rence relations permit rapid, simple computation of the entire set of jlvalues for fixed x andalll. Torecurupwardin lforfixedx,westartwiththeknownformsfor j0andj1(3.43)anduse (3.45).Asyouwillproveforyourself,thisupwardrecurrenceusuallyseemstoworkatfirst, butthenfails.Thereasonforthefailurecanbeseenfromtheplotsof jl(x)andnl(x)versus x(Figure3.5).Ifwestartat x‚âÉ2andl=0,weseethataswerecur jluptolarger lvalues with (3.45), we are essentially taking the difference of two ‚Äúlarge‚Äù functions to produce a ‚Äúsmall‚Äù value for jl. This process suffers from the dreaded subtractive cancelation that always reduces precision. As we continue recurring, we take the difference of two small functions,eachwithlargeerrors,andproduceayetsmallerfunctionwithayetlargererror. Afterawhile,weareleftwithonlyround-offerror(garbage).",3431
Chapter 4 Monte Carlo Simulations,"3.4 Errors in Bessel Functions 57 Tobemorespecific,letuscall j(c) lthenumericalvaluewecomputeasanapproximation forjl(x).Evenifwestartwithpure jl,afterashortwhilethecomputer‚Äôslackofprecision effectivelymixesinabitof nl(x): j(c) l=jl(x)+ùúñnl(x). (3.47) Thisisinevitablebecauseboth jlandnlsatisfythesamedifferentialequationand,onthat account,thesamerecurrencerelation.Theadmixtureof nlbecomesaproblemwhenthe numericalvalueof nl(x)ismuchlargerthanthatof jl(x)becauseevenaminusculeamount ofaverylargenumbermaybelarge. Thesimplesolutiontothisproblem( Miller‚Äôsdevice )istouse(3.46)fordownwardrecur- sion ofthe jlvalues starting at a largevalue l=L. This avoidssubtractive cancelation by takingsmallvaluesof jl+1(x)andjl(x)andproducingalarger jl‚àí1(x)byaddition.Whilethe error may still behave like a Neumann function, the actual magnitude of the error will decreasequickly as we move downward to smaller lvalues. In fact, if we start iterating downward with arbitrary values for j(c) L+1andj(c) L, after a short while we will arrive at the correctldependenceforthisvalueof x.Althoughtheprecisevalueof j(c) 0soobtainedwill notbecorrectbecauseitdependsuponthearbitraryvaluesassumedfor j(c) L+1andj(c) L,the relativevalueswillbeaccurate.Theabsolutevaluesarefixedfromtheknownvalue(3.43), j0(x)=sinx‚àïx.Becausetherecurrencerelationisalinearrelationbetweenthe jlvalues,we needonlynormalizeallthecomputedvaluesvia jN l(x)=jc l(x)√ójanal 0(x) jc 0(x). (3.48) Accordingly,afteryouhavefinishedthedownwardrecurrence,youobtainthefinalanswer bynormalizingall j(c) lvaluesbasedontheknownvaluefor j0. 3.4.2 Implementation and Assessment: Recursion Relations A program implementing recurrence relations is most easily written using subscripts. Ifyouneedtopolishuponyourskillswithsubscripts,youmaywanttostudyourprogram Bessel.pyinListing3.1beforewritingyourown. 1) Writeaprogramthatuses bothupwardanddownwardrecursion to calculate jl(x)for thefirst25 lvaluesforx=0.1,1,and10. 2) Tuneyourprogramsothatatleastonemethodgives‚Äúgood‚Äùvalues(meaningarelative error‚âÉ10‚àí10).SeeTable3.1forsomesamplevalues. 3) Showtheconvergenceandstabilityofyourresults. 4) Comparetheupwardanddownwardrecursionmethods,printingout l,j(up) l,j(down) l,and therelativedifference |j(up) l‚àíj(down) l|‚àï(|j(up) l|+|j(down) l|). 5) Theerrorsincomputationdependon x,andforcertainvaluesof x,bothupanddown recursionsgivesimilaranswers.Explainthereasonforthis. 58 3 Errors and Uncertainties 3.5 Code Listing Listing 3.1 Bessel.py Determines spherical Bessel functions by downward recursion (youshouldmodifythistoalsoworkbyupwardrecursion). # Bessel.py fromvisualimport ‚àó 3fromvisual.graph import ‚àó Xmax = 40. Xmin = 0.25 7step = 0.1 # Global class variables order = 10; start = 50 # Plot j_order graph1 = gdisplay(width = 500, height = 500, title = ‚ÄôSperical Bessel, \ L = 1 (red), 10‚Äô ,xtitle = ‚Äôx‚Äô, ytitle = ‚Äôj(x)‚Äô,\ 11 xmin=Xmin,xmax=Xmax,ymin= ‚àí0.2,ymax=0.5) funct1 = gcurve(color=color.red) funct2 = gcurve(color=color.green) 15defdown (x, n, m): # Method down, recurs downward j = zeros( (start + 2), float) j[m + 1] = j[m] = 1. # Start with anything forkin range (m, 0, ‚àí1): 19 j[k‚àí1] = ( (2. ‚àók+1 . )/ x ) ‚àój[k]‚àíj[k+ 1] scale = (sin(x)/x)/j[0] # Scale solution to known j[0] returnj[n] ‚àóscale 23forxinarange(Xmin, Xmax, step): funct1.plot(pos = (x, down(x, order, start))) forxinarange(Xmin, Xmax, step): 27funct2.plot(pos = (x, down(x,1,start)))",3387
4.1.1 Random Number Generation,"59 4 Monte Carlo Simulations This chapter starts with a discussion of how computers generate numbers that appear random, but really aren‚Äôt, and how we can test for that. We then explore how these pseudorandom numbers are used to incorporate the element of chance into simulations. We do this Ô¨Årst by simulating a random walk, and then by simulating the spontaneous decay of an atom or nucleus. In Section 5.5, we show how to use these random numbers to evaluate integrals, and in Chapter 17, we investigate the use of random numbers to simulate thermal processes and the Ô¨Çuctuations inherent in quantum systems . Somepeopleareattractedtocomputingbecauseofitsdeterministicnature;it‚Äôsnicetohave aplaceinone‚Äôslifewherenothingislefttochance.Barringmachineerrorsorundefined variables,yougetthesameoutputeverytimeyoufeedyourprogramthesameinput.Nev- ertheless, many computer cycles are used for Monte Carlo calculations that at their very core include elements of chance. These are calculations in which random-like numbers generated by the computer are used to simulatenatural random processes, such as ther- mal motion or radioactive decay, or to solve equations on the average. Indeed, much of computationalphysics‚Äôgreatachievementshavecomeaboutfromtheabilityofcomputers tosolvepreviouslyintractableproblemsusingtheseso-calledMonteCarlotechniques. 4.1 Random Numbers W edefinea sequencer1,r2,‚Ä¶asrandomiftherearenocorrelationsamongthenumbers. Yetbeingrandomdoesnotmeanthatallthenumbersinthesequenceareequallylikely tooccur.Ifallthenumbersinasequenceareequallylikelytooccur,thenthesequenceis calleduniform,whichdoesn‚Äôtnecessarilymeanthatitisrandom.Toillustrate,1,2,3,4, ‚Ä¶ isuniform,butprobablynotrandom.Further,itispossibletohaveasequenceofnumbers that,insomesense,arerandombuthaveveryshort-rangecorrelationsamongthemselves, forexample, r1,(1‚àír1),r2,(1‚àír2),r3,(1‚àír3),‚Ä¶ (4.1) haveshort-rangebutnotlong-rangecorrelations. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 604 Monte Carlo Simulations Mathematically,thelikelihoodofanumberoccurringisdescribedbyadistributionfunc- tionP(r),whereP(r)dris the probability of finding rin the interval [r,r+dr].Auni- formdistributionmeansthat P(r)=aconstant.Thestandardrandom-numbergeneratoron computersgeneratesuniformdistributionsbetween0and1.Inotherwords,thestandard random-numbergeneratoroutputsnumbersinthisinterval,eachwithanequalprobabil- ity,yeteachindependentofthepreviousnumbers.Asweshallsee,numberscanalsobe morelikelytooccurincertainregionsthanother,yetstillberandom. By their very nature, computers, being deterministic devices, cannot generate random numbers.Becausecomputedrandomnumbermustcontaincorrelations,theyarenottruly random. Although it may be a bit of work, if we know a computed random number rm anditsprecedingnumbers,thenitshouldbepossibletofigureout rm+1.Forthisreason, computersaresaidtogenerate pseudorandomnumbers (yetwithourincurablelazinesswe won‚Äôtbothersaying‚Äúpseudo‚Äùallthetime).Whilemoresophisticatedgeneratorsdoabet- ter job at hiding the correlations, experience shows that if you look hard enough, or use pseudorandomnumberslongenough,youwillbeabletodiscerncorrelations.Aprimitive alternative to generating random numbers is to read in a table of truly random numbers generatedbynaturallyrandomprocessessuchasradioactivedecay,ortoconnectthecom- putertoanexperimentaldevicethatmeasuresrandomevents.Thesealternativesarenot idealforproductionwork,buthaveactuallybeenusedasacheckintimesofdoubt. 4.1.1 Random Number Generation Thelinear congruent orpower residue method is the common way of generating a pseu- dorandomsequenceofnumbers0 ‚â§ri‚â§M‚àí1overtheinterval [0,M‚àí1].Toobtainthe next random number ri+1, you multiply the present random number riby the constant a, add another constant c, take themodulusbyM, and then keep just the fractional part (remainder):1 ri+1def=(ari+c)modM=remainder(ari+c M) . (4.2) Thevaluefor r1(theseed)isfrequentlysuppliedbytheuser.The modoperatorisusually builtintothesoftware,forexample,inPythonit‚Äôsthepercentsign percent. Remaindering isessen- tiallyabit-shiftoperationthatendsupwiththeleastsignificantpartoftheinputnumber, andtherebycountsontherandomnessofround-offerrorstogeneratearandomsequence. Forexample, c=1,a=4,M=9,andr1=3producesthesequence r1=3, (4.3) r2=(4√ó3+1)mod9=13mod9 =rem13 9=4, (4.4) r3=(4√ó4+1)mod9=17mod9 =rem17 9=8, (4.5) r4=(4√ó8+1)mod9=33mod9 =rem33 9=6, (4.6) r5‚àí10=7,2,0,1,5,3. (4.7) 1 Youmayobtainthesameresultforthemodulusoperationbysubtracting Muntilanyfurther subtractionswouldleaveanegativenumber;whatremainsisthe remainder. 4.1 Random Numbers 61 Wethusobtainasequenceoflength M=9,afterwhichtheentiresequencerepeats.Ifwe wantnumbersintherange [0,1],wedividethe r‚ÄôsbyM=9: 0.333,0.444,0.889,0.667,0.778,0.222,0.000,0.111,0.555,0.333.(4.8) Thisisstillasequenceoflength9,butisnolongerasequenceofintegers.Ifrandomnum- bersintherange [A,B]areneeded,youonlyneedto scale: xi=A+(B‚àíA)ri,0‚â§ri‚â§1,‚áíA‚â§xi‚â§B. (4.9) Asaruleofthumb: Beforeusingarandom-numbergeneratorinyourprograms,youshould check its range and that it produces numbers that ‚Äúlook‚Äù random (we‚Äôll explain further). Althoughnotamathematicalproof,youshouldalwaysmakeagraphicaldisplayofyour randomnumbers.Yourvisualcortexisquiterefinedatrecognizingpatternsandwilltell you immediately if there is a pattern in your random numbers. For instance, Figure 4.1 showsgeneratedsequencesfrom‚Äúgood‚Äùand‚Äúbad‚Äùgenerators.Itisclearwhichisnotran- dom(althoughifyoulookhardenoughattherandompoints,yourmindmaywellpickout patternstheretoo). Thelinearcongruentmethod(4.2)producesintegersintherange [0,M‚àí1]andtherefore becomescompletelycorrelatedifaparticularintegercomesupasecondtime(thewhole cyclethenrepeats).Inordertoobtainalongersequence, aandMshouldbelargenumbers, butnotsolargethattheproduct ari‚àí1overflows.Onacomputerusing48-bitintegerarith- metic,thebuilt-inrandom-numbergeneratormayuse Mvaluesaslargeas248‚âÉ3√ó1014.A 32-bitgeneratormayuse M=231‚âÉ2√ó109.Ifyourprogramusesapproximatelythismany randomnumbers,youmayneedtoreseed(startthesequenceoveragainwithadifferent initialvalue)duringintermediatestepstoavoidthecyclerepeating. Your computer probably has random-number generators that are better than the one youwillcomputewiththepowerresiduemethod.InPythonweuse random.random() ,the MesennaTwistergenerator.Werecommendthatyouusethebestoneyoucanfindrather than write your own. To initialize a random sequence, you need to plant a seed in it. In 0 50 100 150 200 250 x050100150200250y 0 50 100 150 200 250 x Figure 4.1 Left: A plot of successive random numbers (x,y)=(ri,ri+1)generated with a deliberately ‚Äúbad‚Äù generator. Right: A plot generated with the built in random number generator. While the plot on the right is not proof that the distribution is random, the plot on the left is proof enough that the distribution is not random.",6893
4.2.2 Random Walks in a Brain,"624 Monte Carlo Simulations Python the statement random.seed(None) seeds the generator with the system time (see Walk.pyinListing4.1). M=248,c=B(base16)=13(base8), (4.10) a=5DEECE66D (base16)=273673163155 (base8). (4.11) 4.1.2 Computing a Random Sequence Forscientificworkwerecommendusinganindustrial-strengthrandom-numbergenerator. To see why, here we assess how bada careless application of the power residue method canbe. 1) Write a simple program to generate random numbers using the linear congruent method(4.2). 2) For pedagogical purposes, try the unwise choice: (a,c,M,r1)=(57,1,256,10). Deter- minetheperiod,thatis,howmanynumbersaregeneratedbeforethesequencerepeats. 3) Takeyourpedagogicalsequenceofrandomnumbersandlookforcorrelationsbyobserv- ingclusteringonaplotofsuccessivepairs (xi,yi)=(r2i‚àí1,r2i),i=1,2,‚Ä¶.(Donotcon- nectthepointswithlines.)Youmay‚Äúsee‚Äùcorrelations(Figure4.1),whichmeansthat youshouldnotusethissequenceforseriouswork. 4) MakeyourownversionofFigure4.2;thatis,plot riversusi. 5) Testthebuilt-inrandom-numbergeneratoronyourcomputerforcorrelationsbyplot- tingthesamepairsasabove.(Thisshouldbegoodforseriouswork.) 00.20.40.60.81 0 20 40 60 80 100Random number r Sequence number Figure 4.2 A plot of a uniform pseudorandom sequence riversus i . The points are connected to make it easier to follow the order. While this does not prove that a distribution is random, it at least shows the range of values and that there is Ô¨Çuctuation. 4.2 Simulating a Random Walk 63 6) Testthelinearcongruentmethodagainwithreasonableconstantslikethosein(4.10) and(4.11).Comparethescatterplotyouobtainwiththatofthebuilt-inrandom-number generator.(Thisshouldbegoodforsemi-seriouswork.) 4.2 Simulating a Random Walk Consideraperfumemoleculereleasedinthefrontofaclassroom.Sooneveryonecansmell it.Amoleculecollidesrandomlywithothermoleculesintheairandeventuallyreachesyour nosedespitethefactthatyouarehiddeninthelastrowbehindanewspaper.Your problem istodeterminehowmanycollisions,ontheaverage,aperfumemoleculemakesintraveling adistanceR.Youaregiventhefactthatamoleculetravelsanaverage( root-mean-square ) distancerrmsbetweencollisions. Thereareanumberofwaystosimulatearandomwalkwith(surprise,surprise)different assumptionsleadingtodifferentbehaviors.Wewillpresentasimplemodelfora2Dwalk, andendupwithamodelfor normaldiffusion .Theresearchliteratureisfullofdiscussionsof variousversionsofarandomwalk.Forexample,Browningmotioncorrespondstothelimit inwhichtheindividualsteplengthsapproachzero,andwithnotimedelaybetweensteps. Additionalrefinementsincludecollisionswithinamovingmedium( abnormaldiffusion ), includingthevelocitiesoftheparticles,orevenpausingbetweensteps.Modelssuchasthese arediscussedinChapter14, Fractals&StatisticalGrowth . In our random-walk simulation (Figure 4.3) an artificial walkertakes sequential steps withthedirectionofeachstep independent ofthedirectionofthepreviousstep.Westartat theoriginandtake Nstepsinthe XYplaneoflengths(notcoordinates) (Œîx1,Œîy1),(Œîx2,Œîy2),(Œîx3,Œîy3),‚Ä¶,(ŒîxN,ŒîyN). (4.12) Althougheachstepmaybeinadifferentdirection,thedistancesalongeachCartesianaxis just add algebraically.",3117
4.2.2 Random Walks in a Brain,"Accordingly, the radial distance Rfrom the starting point after N stepsis R2=( Œîx1+Œîx2+¬∑¬∑¬∑+ŒîxN)2+(Œîy1+Œîy2+¬∑¬∑¬∑+ŒîyN)2 =Œîx2 1+Œîx2 2+¬∑¬∑¬∑+Œîx2 N+2Œîx1Œîx2+2Œîx1Œîx3+2Œîx2Œîx1+¬∑¬∑¬∑ +(x‚Üíy). (4.13) Ifthewalkisrandom,theparticleisequallylikelytotravelinanydirectionateachstep. Ifwetaketheaverageofalargenumberofsuchrandomsteps,allthecrosstermsin(4.13) Figure 4.3 Left: A schematic of the Nsteps in a random walk simulation that end up a distance Rfrom the origin. Notice how the Œîx‚Äôs for each step add vectorially. Right:A simulated walk in 3D from Walk3D.py . X Y ZR 1Œîy1 Œîy2Œîx1 2 34N 644 Monte Carlo Simulations willvanish,andwewillbeleftwith R2 rms=‚ü®R2‚ü©‚âÉ‚ü®Œîx2 1+Œîx2 2+¬∑¬∑¬∑+Œîx2 N+Œîy2 1+Œîy2 2+¬∑¬∑¬∑+Œîy2 N‚ü© =‚ü®Œîx2 1+Œîy2 1‚ü©+‚ü®Œîx2 2+Œîy2 2‚ü©+¬∑¬∑¬∑ =N‚ü®r2‚ü©=Nr2 rms, ‚áíRrms‚âÉ‚àö Nrrms, (4.14) whererrms=‚àö ‚ü®r2‚ü©istheroot-mean-square(RMS) stepsize. Tosummarize,ifthewalkisrandom,thenweexpectthatafteralargenumberofsteps theaverage vectordistancefromtheoriginwillvanish: ‚ü®‚ÉóR‚ü©=‚ü®x‚ü©‚Éói+‚ü®y‚ü©‚Éój‚âÉ0. (4.15) YetRrms=‚àö ‚ü®R2 i‚ü©doesnotvanish.Equation(4.14)indicatesthattheaverage scalardistance from the origin is‚àö Nrrms, where each step is of average length rrms. In other words, the vector endpoint will be distributed uniformly in all quadrants, and so the displacement vectoraveragestozero,buttheaveragelengthofthatvectordoesnot.Forlarge Nvalues,‚àö Nrrms‚â™Nrrms(thevalueifallstepswereinonedirectiononastraightline),butdoes notvanish.Inourexperience,computationalsimulationsagreewiththistheory,butrarely perfectly,withthelevelofagreementdependinguponthedetailsofhowtheaveragesare takenandhowtherandomnessisbuiltintoeachstep. 4.2.1 Random Walk Implementation Theprogram Walk.pyinListing4.1isasamplerandom-walksimulation.Itskeyelementis therandomvaluesforthe xandycomponentsofeachstep, x += (random.random() ‚àí0.5) ‚àó2. #‚àí1=<x=<1 y += (random.random() ‚àí0.5) ‚àó2. #‚àí1=<y=<1 where here we have omitted the scaling factor that normalizes each step to length 1. Whenusingyourcomputertosimulatearandomwalk,youshouldexpecttoobtain(4.14) onlyastheaveragedisplacement,averagedovermanytrials,notnecessarilyastheanswer for each trial. You final answer will depend on just how you take your random steps (Figure4.4right). Startattheoriginandtakea2Drandomwalkwithyourcomputer: 1) To increase the amount of randomness, independently choose random values for Œîx‚Ä≤ andŒîy‚Ä≤intherange [‚àí1,1].Thennormalizethemsothateachstepisofunitlength Œîx=1 LŒîx‚Ä≤,Œîy=1 LŒîy‚Ä≤,L=‚àö Œîx‚Ä≤2+Œîy‚Ä≤2. (4.16) 2) Useaplottingprogramtodrawmapsofseveralindependent2Drandomwalks,eachof 1000steps.Basedonyoursimulations,commentonwhethertheresultslooklikewhat youwouldexpectarandomwalktolooklike. 3) If you have your walker taking Nsteps in a single trial, then conduct a total number K‚âÉ‚àö Noftrials.Eachtrialshouldhave Nstepsandstartwithadifferentseed. 4.2 Simulating a Random Walk 65 7 Random walks Distance vs Steps 0100200300 0 100 200 300 sqrt(N)R ‚Äì40.0‚Äì40.0‚Äì20.020.040.0 0.0 ‚Äì20.0 0.0 20.0 40.0 Figure 4.4 Left: The steps taken in seven 2D random walk simulations. Right: The distance covered in two walks of Nsteps using different schemes for including randomness.",3058
4.2.2 Random Walks in a Brain,"The theoretical prediction (4.14) is the straight line. 4) Calculatethemeansquaredistance R2foreachtrialandthentaketheaverageof R2for allyourKtrials: ‚ü®R2(N)‚ü©=1 KK‚àë k=1R2 (k)(N). (4.17) 5) Checkthevalidityoftheassumptionsmadeinderivingthetheoreticalresult(4.14)by checkinghowwell ‚ü®ŒîxiŒîxj‚â†i‚ü© R2‚âÉ‚ü®ŒîxiŒîyj‚ü© R2‚âÉ0. (4.18) Doyourcheckingforbothasingle(long)runandfortheaverageovertrials. 6) PlottheRMSdistance, Rmrs=‚àö ‚ü®R2(N)‚ü©asafunctionof‚àö N.V aluesof Nshouldstart withasmallnumber,where R‚âÉ‚àö Nisnotexpectedtobeaccurate,andendataquite largevalue,wheretwoorthreeplacesofaccuracyshouldbeexpectedontheaverage. 7)‚äôRepeattheprecedingandfollowinganalysisfora3Dwalkaswell. 4.2.2 Random Walks in a Brain Ithasrecentlybeenrealizedthatunderstandingthebraingoesbeyondjustunderstanding thenetworksofneuronsinit,toalsounderstandingtheeffectsofthefluid-filledextracellu- larspacesbetweentheneurons[Nicholson,2022].2Thisisimportantforunderstandingthe molecular diffusion of radiographers, drugs, metabolites, and molecular signals within thebrain. 2 FurtherdiscussionofthebrainmaybefoundinChapter11, NeuralNetsandArtificialIntelligence . 664 Monte Carlo Simulations Figure 4.5 Fifty 2D random walk simulations exploring the diffusion of chemical probes within the brain from ([Nicholson, 2022] with permission from AIP publishing). The walks take 1500 equal-size steps with each walk assigned to one of six colors. Left: The walks with no impediments. Right: Circular impediments representing extracellular spaces that block out regions inaccessible to the walks. Random-walksimulations,liketheoneswehavealreadyexamined,haveprovidedunder- standingofdiffusionwithinthebrain.Specifically,theleftofFigure4.5presentsresearch resultsfor50randomwalksof1500equal-sizestepswithinabrainmodel,witheachwalk assignedtooneofsixcolorsNicholson[2022].Notethestrikingsimilarityofthesewalksto thosewehaveshownontheleftofFigure4.4.OntherightofFigure4.5,weshowtheresults of a model for diffusion in the brain that accounts for the extracellular spaces between neuronsbyrandomlyplacingcircularobstructionswithinthesimulationvolume. 1) TrytoreproducethesimulationshownontheleftofFigure4.5byrecordingandplotting 50walks,witheachwalkassignedtooneofsixcolors.Startthewalksattheorigin,use equal-sizedsteps,andrestrictthesimulationspacetotwodimensions. 2) As shown of the right of Figure 4.4, determine the average over all your walks of the RMSdistancecovered Rrms. 3) Takethesame2Dspacecoveredinyoursimulations,andnowinsertcircularobstruc- tionsofvariedsizes,similartothoseontherightofFigure4.5. 4) Yet again conduct and record 50 walks, with each walk assigned to one of six colors. Startthewalksattheorigin,useequal-sizedsteps,butincludeobstructionsthat stopthe walkswhentheyhitthem. 5) DetermineagaintheaverageoverallyourobstructedwalksoftheRMSdistancecovered Rrms.Theobstructionsshouldleadtoadecreased Rrms. 6) Againconductandrecord50walks,witheachwalkassignedtooneofsixcolors.Start the walks at the origin, use equal-sized steps, but include obstructions that repel,b u t don‚Äôtstop,thewalkswhentheyhit. 7) AgaindeterminetheaverageoverallyourobstructedwalksoftheRMSdistancecovered Rrms,andcomparetotheprevioustworesults.",3176
4.3.2 The Exponential Decay Approximation,"4.2 Simulating a Random Walk 67 Figure 4.6 Two self-avoiding random walks that simulate protein chains with hydrophobic (H) monomers in large dots, and polar (P) monomers in small dots. The dark dots on the right indicate regions where two H monomers are not directly connected. 8) InEinstein‚Äôs1905paper InvestigationsontheTheoryoftheBrowningMovement ,hepro- posed that the effective diffusion coefficient within a medium DR2 rms 2dt,w h e r edis the number of spatial dimensions (2 for a 2D simulation), and tis the average time for a walk.Howmuchofaneffecton Ddotheobstructionscause? 9) Repeattheproblemforathree-dimensionalvolume. 4.2.3 Random Protein Folding Aproteinisalargebiologicalmoleculemadeupofmolecularchains(theresiduesofamino acids). These chains are formed from monomers, that is, molecules that bind chemically withothermolecules.Morespecifically,thechainsconsistofnon-polarhydrophobic(H) monomersthatarerepelledbywater,andpolar(P)monomersthatareattractedbywater. The actual structure of a protein results from a folding process in which random coils of chainsrearrangethemselvesintoaconfigurationofminimumenergy.Wewanttomodel thatprocessonthecomputer. Althoughmoleculardynamics(Chapter18)maybeusedtosimulateproteinfolding,it is much slower than Monte-Carlo techniques, and even then, it is hard to find the low- est energy states. Here we create a simple Monte-Carlo simulation in which you to take arandomwalkina2Dsquarelattice[Yue etal.,1995].Attheendofeachstep,youran- domlychooseanHoraPmonomeranddropitonthelattice,withyourchoiceweighted suchthatHmonomersaremorelikelythanPones.Thewalkisrestrictedsuchthattheonly positionsavailableaftereachsteparethethreeneighboringsites,withthealreadyoccupied sitesexcluded(thisiswhythistechniqueisknownasa self-avoidingrandomwalk ). The goal of the simulation is to find the lowest energy state of a sequence of H and P monomerswithlinksofvariouslengths.Itthenmaybecomparedtothoseinnature.Just howbesttofindsuchastateisanactiveresearchtopic[Yue etal.,1995].Theenergyofa chainisdefinedas E=‚àíùúñf, (4.19) 684 Monte Carlo Simulations whereùúñisapositiveconstantand fisthenumberofH‚ÄìHneighbor notconnecteddirectly (P‚ÄìPandH‚ÄìPbondsdonotcountatloweringtheenergy).SoiftheneighbornexttoanH isanotherH,itlowerstheenergy,butifitisaPitdoesnotlowertheenergy.Weshowa typicalsimulationresultinFigure4.6.Accordingly,foragivenlengthofchain,weexpect thenaturalstate(s)ofanH‚ÄìPsequencetobethosewiththelargestpossiblenumber fof H‚ÄìHcontacts.Thatiswhatwearelookingfor. 1) Modifytherandomwalkprogramwehavealreadydevelopedsothatitsimulatesaself- avoidingrandomwalk.Thekeyhereisthatthewalkstopsatacorner,orwhenthereare noemptyneighboringsitesavailable. 2) MakearandomchoiceastowhetherthemonomerisanHoraP,withaweightingsuch thattherearemoreH‚ÄôsthanP‚Äôs. 3) Produceavisualizationthatshowsthepositionsoccupiedbythemonomers,withtheH andPmonomerindicatedbydifferentcolordots.Ourvisualization,showninFigure4.6, isproducedbytheprogram ProteinFold.py ,giveninListing4.2. 4) Afterthewalkends,recordtheenergyandlengthofthechain. 5) Runmanyfoldingsimulationsandsavetheoutputs,categorizedbylengthandenergy. 6) Examinethestate(s)oflowestenergyforvariouschainlengthsandcomparetheresults to those frommolecular dynamicsimulations and actual protein structures (available ontheWeb). 7) Doyouthinkthissimplemodelhassomemerit? 8)‚äôExtendthefoldingto3D. 4.3 Spontaneous Decay Your problemis to simulate the time dependence of the decay of a small number Nof radioactiveparticles.3Inparticular,youaretodeterminetheconnectionbetweenexponen- tialdecayand stochasticdecay(containingelementsofchance).Realizingthatexponential decayisagoodmodelonlywhenthereareverylargenumbersofparticles,theexponential modelisnolongeraccurateasthenumberofdecayingparticlesdecreases,asitalwaysdoes. Accordingly,oursimulationshouldbeclosertonaturethanistheexponentialdecaymodel (Figure4.7).Infact,ifyou‚Äúlisten‚Äùtotheoutputofthedecaysimulationcode,whatyouwill hearsoundsverymuchlikeaGeigercounter,anintuitivelyconvincingdemonstrationof therealismofthesimulation. Spontaneousdecayisanaturalprocessinwhichaparticle,withnoexternalstimulation, decays into other particles. Although the probability of decay of any one particle in any onetimeintervalisconstant,justwhenitdecaysisrandom.Inasmuchasthepresence,or decay,ofanyoneparticledoesnotinfluencethedecayofanyotherparticle,theprobability ofdecayisnotinfluencedbyhowlongtheparticlehasbeenaround,orhowmanyother particlesarestillaround.Inotherwords,theprobability Óàºofanyoneparticledecayingper unittimeintervalisaconstant,yetwhenthatparticledecays,itisgoneforever.Ofcourse, 3 SpontaneousdecayisalsodiscussedinChapter6,wherewefitittoanexponential. 4.3 Spontaneous Decay 69 0 400 800 1200 t024100,000 10,000 1,000 100 10log[N(t)] Figure 4.7 Circle: A sample containing Nnuclei, each of which has the same probability of decaying per unit time, Graphs : Semilog plots of the number of nuclei versus time for Ô¨Åve simulations with differing initial numbers of nuclei. Exponential decay would be a straight line without bumps, similar to the initial behavior for N=100,000. asthetotalnumber Nofparticlesdecayswithtime,sowillthenumberthatdecayperunit time, but the probability of any one particle decaying in some time interval remains the sameforaslongasthatparticleexists. 4.3.1 Discrete Decay Model Imaginehavingasamplecontaining N(t)radioactivenucleiattime t(Figure4.7circle).Let ŒîNbethenumberofparticlesthatdecayinsomesmalltimeinterval Œît.W econ vertthe statement‚Äútheprobability Óàºofanyoneparticledecayingperunittimeisaconstant‚Äùinto theequation Óàº=ŒîN(t)‚àïN(t) Œît=‚àíùúÜ, (4.20) ‚áíŒîN(t) Œît=‚àíùúÜN(t), (4.21) where the constant ùúÜis called the decay rate and the minus sign indicates a decreasing number.Because N(t)decreasesintime,the activityŒîN(t)‚àïŒît(sometimesalsocalledthe decayrate)alsodecreaseswithtime.Inaddition,becausethetotalactivityisproportional tothetotalnumberofparticlespresent,ittooisstochasticwithanexponential-likedecay intime.[Actually,becausethenumberofdecays ŒîN(t)isproportionaltothedifferencein randomnumbers,ittendstoshowevenlargerstatisticalfluctuationsthandoes N(t).] Equation (4.21) is a finite-differenceequation relating the experimental quantities N(t), ŒîN(t),andŒît.Althoughadifferenceequationcannotbeintegratedthewayadifferential equationcan,itcanbesimulatednumerically.Becausetheprocessisrandom,wecannot predict a single value for ŒîN(t), although we can predict the average number of decays whenobservationsaremadeonmanyidenticalsystemsof Ndecayingparticles.",6494
4.3.4 Decay Implementation and Visualization,"704 Monte Carlo Simulations 4.3.2 The Exponential Decay Approximation Whenthenumberofparticles N‚Üí‚àûandtheobservationtimeinterval Œît‚Üí0,thediffer- enceequation(4.21)becomesadifferentialequation,andweobtainthefamiliarexponen- tialdecaylaw: ŒîN(t) Œît‚àí‚àí‚àí‚àí‚ÜídN(t) dt=‚àíùúÜN(t). (4.22) This equation can be integrated to obtain the time dependencies of the total number of particlesandofthetotalactivity: N(t)=N(0)e‚àíùúÜt=N(0)e‚àít‚àïùúè, (4.23) dN dt(t)=‚àíùúÜN(0)e‚àíùúÜt=dN dt(0)e‚àíùúÜt. (4.24) Inthislimitwecanidentifythedecayrate ùúÜwiththeinverselifetime: ùúÜ=1 ùúè. (4.25) Weseefromitsderivationthatexponentialdecayisagooddescriptionofnatureforalarge number of particles, that is, when ŒîN‚àïN‚âÉ0. However, in nature, N(t)can be a small number,andinthatcasewehaveastatistical,asopposedtoacontinuousprocess.Thebasic lawofnature(4.20)isalwaysvalid,butaswewillseeinthesimulation,exponentialdecay (4.24)becomeslessandlessaccurateasthenumberofparticlesgetssmallerandsmaller. 4.3.3 Discrete Decay Simulation Aprogramforsimulatingradioactivedecayissurprisinglysimple,butnotwithoutitssub- tleties. We increase time in discrete steps of Œît, and for each time interval we count the numberofnucleithathavedecayedduringthat Œît.Thesimulationquitswhenthereareno nucleilefttodecay.Suchbeingthecase,wehaveanouterloopoverthetimesteps Œît,and aninnerloopovertheremainingnucleiforeachtimestep.Thepseudocodeissimple(asis thecode): inputN,lambda 2t=0 whileN>0 Delta = 0 fori=1 . . N 6if(r_i<lambda) Delta = Delta + 1 endfor t=t+ 1 N=N‚àíDelta 10Output t, Delta, N endwhile Whenwepickavalueforthedecayrate ùúÜ=1‚àïùúètouseinoursimulation,wearesettingthe scalefortimes.Forexample,iftheactualdecayrateis ùúÜ=0.3√ó106s‚àí1,andifwedecideto measuretimesinunitsof10‚àí6s,thenwewillchooserandomnumbers0 ‚â§ri‚â§1,which leadstoùúÜvalueslyingsomeplacenearthemiddleoftherange(e.g. ùúÜ‚âÉ0.3).Alternatively,",1812
4.4 Testing and Generating Random Distributions,"4.4 Testing and Generating Random Distributions 71 wecanuseavalueof ùúÜ=0.3√ó106s‚àí1inoursimulationandthenscaletherandomnum- bers to the range 0 ‚â§ri‚â§106. However, unless you plan to compare your simulation to experimentaldata,youdonothavetoworryaboutthescalefortime,butinsteadshould focusonthephysicsbehindtheslopesandthederivedfunctionaldependencies. Decay.pyisoursamplesimulationofspontaneousdecay.Anextensionofthisprogram, DecaySound.py , in Listing 4.3, adds a beep each time an atom decays (unfortunately this works only with Windows). When we listen to the simulation it sounds like a Geiger counter,withitsrandomnessandwithadecayratethatdecreasesintime.Thisprovides someratherconvincingevidenceoftherealismofthesimulation. 4.3.4 Decay Implementation and Visualization WriteaprogramtosimulateradioactivedecayusingthesimpleprograminListing4.3asa guide.YoushouldobtainresultssimilartothoseinFigure4.7. 1) Plot the logarithm of the number left ln N(t)and the logarithm of the decay rate lnŒîN(t)‚àïŒîtv e r s u stime. Note that the simulation measures time in steps of Œît (generationnumber). 2) Checkthatyouobtainwhatlookslikeexponentialdecaywhenyoustartwithlargeval- uesforN(0),butthatthedecaydisplaysitsstochasticnatureforsmall N(0)(largeN(0) valuesarealsostochastic;theyjustdon‚Äôtlookitatfirst). 3) Createtwoplots,oneshowingthattheslopesof N(t)versustareindependent ofN(0), andanothershowingthattheslopesareproportionaltothevaluefor ùúÜ. 4) Createaplotshowingthatwithinexpectedstatisticalvariations,ln N(t)andlnŒîN(t)are proportional. 5) Explaininyourownwordshowaprocessthatisspontaneousandrandomatitsvery heartcanleadtoexponentialdecay. 6) Howdoesyoursimulationshowthatthedecayisexponential-likeandnotapowerlaw suchasN=ùõΩt‚àíùõº? 4.4 Testing and Generating Random Distributions Since the computer‚Äôs random numbers are generated according to a definite rule, they must be correlated with each other. This can affect a simulation that assumes truly ran- domevents.Thereforeitiswisetotestarandom-numbergeneratortoobtainanumerical measureofitsuniformityandrandomnessbeforeyoustakeyourscientificreputationonit. Infact,sometestsaresimpleenoughforyoutomakeitahabittorunthemsimultaneously withyoursimulation.Intheexamplestofollow,wetestforrandomnessanduniformity. 1) Probablythemostobvious,butoftenneglected,testforrandomnessanduniformityis justtolookatthenumbersgenerated.Forexample,Table4.1presentssomeoutputfrom Python‚Äôs randommethod.Ifyoujustlookatthesenumbersyouwillknowimmediately that they all lie between 0 and 1, that they appear to differ from each other, and that thereisnoobviouspattern(like0.3333). 724 Monte Carlo Simulations Table 4.1 A table of a uniform, pseudo-random sequence rigenerated by Python‚Äôs random method. 0.04689502438508175 0.20458779675039795 0.5571907470797255 0.05634336673593088 0.9360668645897467 0.7399399139194867 0.6504153029899553 0.8096333704183057 0.3251217462543319 0.49447037101884717 0.14307712613141128 0.32858127644188206 0.5351001685588616 0.9880354395691023 0.9518097953073953 0.36810077925659423 0.6572443815038911 0.7090768515455671 0.5636787474592884 0.3586277378006649 0.38336910654033807 0.7400223756022649 0.4162083381184535 0.3658031553038087 0.7484798900468111 0.522694331447043 0.14865628292663913 0.1741881539527136 0.41872631012020123 0.9410026890120488 0.1167044926271289 0.8759009012786472 0.5962535409033703 0.4382385414974941 0.166837081276193 0.27572940246034305 0.832243048236776 0.45757242791790875 0.7520281492540815 0.8861881031774513 0.04040867417284555 0.14690149294881334 0.2869627609844023 0.27915054491588953 0.7854419848382436 0.502978394047627 0.688866810791863 0.08510414855949322 0.48437643825285326 0.19479360033700366 0.3791230234714642 0.9867371389465821 2) Aswehaveseen,aquickvisualtest(Figure4.2)involvestakingthissamelistandplot- tingitwith riasordinateand iasabscissa.Observehowthereappearstobeauniform distribution between 0 and 1 and no particular correlation between points (although youreyeandbrainwilltrytorecognizesomekindofpattern). 3) Aswehaveseen,aneffectivetestforrandomnessisperformedbymakingascatterplot of(xi=r2i,yi=r2i+1)for manyivalues. If your points have noticeable regularity, the sequenceisnotrandom.Ifthepointsarerandom,theyshoulduniformlyfillasquare withnodiscerniblepattern(acloud),asinFigure4.1. 4) Asimpletestofuniformityevaluatesthe kthmomentofadistribution: ‚ü®xk‚ü©=1 NN‚àë i=1xk i. (4.26) If the numbers are distributed uniformly, then (4.26) is approximately the moment of thedistributionfunction P(x): 1 NN‚àë i=1xk i‚âÉ‚à´1 0dx xkP(x)‚âÉ1 k+1+O( 1‚àö N) . (4.27) If(4.27)holdsforyourgenerator,thenyouknowthatthedistributionisuniform.Ifthe deviationfrom(4.27)variesas1 ‚àï‚àö N,thenyoualsoknowthatthedistributionisrandom becausethe1 ‚àï‚àö Nresultderivesfromassumingrandomness. 5) Anothersimpletestdeterminesthenear-neighborcorrelationinyourrandomsequence bytakingsumsofproductsforsmall k: C(k)=1 NN‚àë i=1xixi+k,(k=1,2,‚Ä¶). (4.28)",4900
4.5 Code Listings,"4.5 Code Listings 73 Ifyourrandomnumbers xiandxi+karedistributedwiththejointprobabilitydistribution P(xi,xi+k)=1andareindependentanduniform,then(4.28)canbeapproximatedasan integral: 1 NN‚àë i=1xixi+k‚âÉ‚à´1 0dx‚à´1 0dyxyP(x,y)=‚à´1 0dyxy=1 4. (4.29) If (4.29) holds for your random numbers, then you know that they are uniform and independent.Ifthedeviationfrom(4.29)variesas1 ‚àï‚àö N,thenyoualsoknowthatthe distributionisrandom. 6) Test your random-number generator with (4.27) for k=1,3,7a n dN=100,10000, 100000.Ineachcaseprintout ‚àö N||||||1 NN‚àë i=1xk i‚àí1 k+1||||||(4.30) tocheckthatitisoforder1. 4.5 Code Listings Listing 4.1 Walk.py Calls the random-number generator from the random package. Notethatadifferentseedisneededtoobtainadifferentsequence. 1# Walk. py Random walk with graph fromvisualimport ‚àó fromvisual.graph import ‚àó importrandom 5 random.seed(None) # Seed generator , None = > system clock jmax = 20 x= 0 . ; y = 0 . # Start at origin 9graph1 = gdisplay(width=500, height=500, title= ‚ÄôRandom Walk‚Äô , xtitle= ‚Äôx‚Äô, ytitle= ‚Äôy‚Äô) pts = gcurve(color = color.yellow) foriin range (0, jmax + 1): 13pts.plot(pos = (x, y) ) # Plot points x += (random.random() ‚àí0.5) ‚àó2. #‚àí1=<x=<1 y += (random.random() ‚àí0.5) ‚àó2. #‚àí1=<y=<1 pts.plot(pos = (x, y)) 17rate(100) Listing 4.2 ProteinFold.py Aself-avoidingrandomwalk. 1# ProteinFold .py: Self avoiding random walk # Stops in corners or occupied neighbors # energy = ‚àíf | eps , f=1 if neighbour = H, f=0 if p # Yellow dot indicates unconnected neighbor 5 fromvisualimport ‚àó;importrandom Maxx = 500; Maxy = 500; ran = 20; L = 100; m= 100; n = 100 9size = 8; size2 = size ‚àó2; nex = 0 M= []; D D= [] # Arrays for polymer & grid graph1 = display(width=Maxx, height=Maxy,title= ‚ÄôProtein Folding‚Äô , 13 range=ran) positions = points(color=color.cyan,size = 2) 744 Monte Carlo Simulations defselectcol(): # Select atom‚Äôs colors 17hp = random.random() # Select H or P ifhp<= 0.7: col = (1,0,0) # Hydrophobic color red r=2 21else: col = (1,1,1) # Polar color white r=1 returncol,r 25 deffindrest(m,length,fin,fjn): # Check links energies ener = 0 fortin range (m,length+1): # Next link not considered 29 ifDD[t][0]==fin andDD[t][1]==fjn andDD[t][2]==2: ener = 1 # Red unlinked neighbor returnener 33deffindenergy(length,DD): # Finds energy of each link energy = 0 fornin range (0,length+1): i=D D [ n ] [ 0 ] 37 j=D D [ n ] [ 1 ] cl =DD[n][2] ifcl==1:pass # if white else: #r e d 41 ifn<length+1: imin =int(i‚àí1) # Check neighbor i ‚àí1,j js =int(j) ifimin >= 0: 45 e = findrest(n+2,length ,imin,js) # Return energy 1 energy = energy + e ife==1: # Plot yellow dot at neighbour xol = 4 ‚àó(i‚àí0.5)‚àísize2 49 yol =‚àí4‚àój+size2 points(pos=(xol,yol),color=color.yellow, size=6) ima = i+1 js = j 53 ifima<=size‚àí1: # Check neighborr i+1,j e = findrest(n+2,length,ima,js) energy = energy+e ife= =1 : # Plot yellow dot at neighbor 57 xol = 4 ‚àó(i+0.5) ‚àísize2 yol =‚àí4‚àój+size2 points(pos=(xol,yol),color=color.yellow, size=6) iss = i 61 jma = j+1 ifjma<=s i z e‚àí1: # Check neighbor i , j+1 e = findrest(n+2,length,iss ,jma) energy = energy+e 65 ife= =1 : # Plot yellow dot at neighbor xol = 4 ‚àói‚àísize2 # Start at middle yol =‚àí4‚àó(j+0.5)+size2 points(pos=(xol,yol),color=color.yellow, size=6) 69 iss = i jmi = j ‚àí1 ifjmi >= 0: # Check neighbor i , j ‚àí1 e = findrest(n+2,length,iss ,jmi) 73 energy = energy +e ife==1: # Plot yellow dot at neighbour xol = 4 ‚àói‚àísize2 # Start at middle yol =‚àí4‚àó(j‚àí0.5)+size2 77 points(pos=(xol,yol),color=color.yellow, size=6) returnenergy defgrid(): # Plot grid 81forjin range (0,size): yp =‚àí4‚àój+size2 # World to screen coord foriin range (0,size): # Horizontal row xp = 4 ‚àói‚àísize2 85 positions.append(pos = (xp,yp)) 4.5 Code Listings 75 grid() length = 0 while1: # Adjust for desired number of walks 89pts2 = label(pos=( ‚àí5,‚àí18), box=0) length = 0 grid = zeros((size,size)) D=z e r o s( (L, m ,n )) 93DD = [] i=s i z e / 2 # Center of grid j=s i z e / 2 xol = 4 ‚àói‚àísize2 97yol =‚àí4‚àój+size2 col,c = selectcol() grid[i,j] = c # Particle in center M=M+[points(pos=(xol,yol),color=col, size=6)] # Red point at center 101print(\"" start \"" ) DD = DD+[[i , j , c ]] while(i>0andi<size‚àí1andj>0andj<size‚àí1and(grid[i+1,j] = =0 orgrid[i‚àí1,j] == 0 orgrid[i,j+1] == 0 orgrid[i,j ‚àí1] == 0)): 105 r = random.random() ifr<0.25 : # Probability 25 percent ifgrid[i+1,j]==0: i += 1 # Step right if empty elif0.25<randr<0.5: #S t e p l e f t 109 ifgrid[i‚àí1,j] == 0: i ‚àí=1 elif0.50<randr<0.75: #U p ifgrid[i,j ‚àí1]==0: j ‚àí=1 else: #D o w n 113 ifgrid[i ,j+1]==0: j+=1 ifgrid[i,j] == 0: col,c = selectcol() grid[i,j] = 2 # Occupy grid point 117 length += 1 # Increase length as occupied DD = DD+[[i , j , c ]] xp = 4 ‚àói‚àísize2 yp =‚àí4‚àój+size2 121 curve(pos=[(xol,yol) ,(xp,yp)]) # Connect last to new position M=M+ [points(pos=(xp,yp), color=col,size=6)] xol = xp # Start n e w line yol = yp 125 while(j = = (size ‚àí1)andi. =0andi. =( s i z e ‚àí1)): # Bottom row r1 = random.random() ifr1<0.2: # Probability 20 percent move left ifgrid[i‚àí1,j] == 0: i ‚àí=1 129 elifr1 > 0.2 andr1<0.4: # Probability 20 percent move right ifgrid[i+1,j] == 0: i += 1 else: # Probability 60 percent move up ifgrid[i,j ‚àí1] == 0: j ‚àí=1 133 ifgrid[i,j] == 0: col,c = selectcol() # Increase length grid[i,j] = 2 # Grid point occupied length += 1 137 DD = DD + [[ i , j , c ]] xp = 4 ‚àói‚àísize2 yp =‚àí4‚àój + size2 curve(pos=[(xol,yol) ,(xp,yp)]) # Line connecting new point 141 M=M +[points(pos=(xp,yp), color=col,size=6)] xol = xp yol = yp # Last row; Stop if corner or occupied neighbors if( i==0ori==(size ‚àí1))or(grid[i ‚àí1,size‚àí1].=0and grid[i+1,size ‚àí1].=0): 145 break while(j = =0 andi. =0andi. =( s i z e ‚àí1)): # First row r1 = random.random() ifr1<0.2: 149 ifgrid[i‚àí1,j] == 0: i ‚àí=1 elifr1>0.2andr1<0.4: ifgrid[i+1,j]==0: i += 1 else: 153 ifgrid[i ,j+1]==0: j += 1 764 Monte Carlo Simulations ifgrid[i ,j]==0: col,c = selectcol() grid[i,j] = 2 157 length += 1 DD = DD + [[ i , j , c ]] xp = 4 ‚àói‚àísize2 yp =‚àí4‚àój + size2 161 curve(pos=[(xol,yol) ,(xp,yp)]) M=M+ [points(pos=(xp,yp), color=col,size=6)] xol = xp yol = yp 165 ifi==(size ‚àí1)ori==0or(grid[i ‚àí1,0].=0 andgrid[i+1,0].=0): break while( i==0andj. = 0andj. = ( s i z e ‚àí1)): # First column r1 = random.random() 169 ifr1<0.2: ifgrid[i,j ‚àí1] == 0: j ‚àí=1 elifr1 > 0.2 andr1<0.4: ifgrid[i,j+1] == 0: j += 1 173 else: ifgrid[i+1,j] == 0: i += 1 ifgrid[i,j] == 0: col,c = selectcol() 177 grid[i,j] = c length += 1 DD = DD+[[i , j , c ]] xp = 4 ‚àói‚àísize2 181 yp =‚àí4‚àój + size2 curve(pos=[(xol,yol) ,(xp,yp)]) M=M +[points(pos=(xp,yp), color=col,size=6)] xol = xp 185 yol = yp ifj==(size ‚àí1)orj==0or(grid[0,j+1].=0 andgrid[0,j ‚àí1].=0): break while(i==(size ‚àí1)andj. = 0andj. = ( s i z e ‚àí1)): # Last column 189 r1 = random.random() ifr1<0.2: ifgrid[i,j ‚àí1] == 0: j ‚àí=1 elifr1 > 0.2 andr1<0.4: 193 ifgrid[i,j+1] == 0: j += 1 else: ifgrid[i‚àí1,j] == 0: i ‚àí=1 ifgrid[i,j] == 0: 197 col,c = selectcol() grid[i,j] = c length += 1 col,c=selectcol() 201 DD = DD + [[ i , j , c ]] xp = 4 ‚àói‚àísize2 yp =‚àí4‚àój + size2 curve(pos=[(xol,yol) ,(xp,yp)]) 205 M=M +[points(pos=(xp,yp), color=col,size=6)] xol = xp yol = yp ifj==(size ‚àí1)or(grid[size ‚àí1,j+1].=0 andgrid[size ‚àí1,j‚àí1].=0): 209 break label(pos=( ‚àí10,‚àí18), text= ‚ÄôLength=‚Äô ,b o x = 0 ) label(pos=(10,18,0), text= ‚ÄôClick for new walk‚Äô ,color=color.red, display=graph1) pts2.text = ‚Äô percent4s‚Äô percentlength 213label(pos=(5, ‚àí18,0), text= ‚ÄôEnergy‚Äô ,box=0) evalue=label(pos=(10, ‚àí18), box=0) #E n e r g y evalue.text = ‚Äô percent4s‚Äô percentfindenergy(length,DD) # Walk length walk print(\""energy is \"" ,findenergy(length,DD)) 217print(\""dd\"") graph1.mouse.getclick() # Detect mouse click forobjingraph1.objects: # Start n e w walk if(objispositions orobjiscurve): continue 221 obj.visible = 0 # Clear curve 4.5 Code Listings 77 Listing 4.3 DecaySound.py Simulatesspontaneousdecayinwhichadecayoccursifa randomnumberissmallerthanthedecayparameter.The winsoundpackageletsusplaya beepeachtimethereisadecay,andthisleadstothesoundofaGeigercounter. 1# DecaySound.py spontaneous decay simulation fromvisualimport ‚àó;fromvisual.graph import ‚àó;importrandom, winsound 5lambda1 = 0.005 # Decay constant max= 80.; time_max = 500; seed = 68111 number = nloop = max # Initial value graph1 = gdisplay(title = ‚ÄôSpontaneous Decay‚Äô ,xtitle= ‚ÄôTime‚Äô,\ 9 ytitle = ‚ÄôNumber‚Äô ) decayfunc = gcurve(color = color.green) fortimeinarange(0, time_max + 1): #T i m el o o p foratominarange(1, number + 1 ): # Decay loop 13 decay = random.random() if(decay <lambda1): nloop = nloop ‚àí1 #Ad e c a y winsound.Beep(600, 100) # Sound beep 17number = nloop decayfunc.plot( pos = (time, number) ) rate(30)",8537
Chapter 5 Differentiation and Integration. 5.1 Differentiation Algorithms. 5.2.1 Second Derivatives,"78 5 Differentiation and Integration We start this chapter with a short discussion of numerical differentiation, an important, if rather straight-forward, topic. We derive the algorithms for differentiation that will be used throughout the book. The majority of the chapter covers several algorithms for numerical integration, a basic tool of scientiÔ¨Åc computation. We end with a discussion of Monte Carlo integration techniques, which are fundamentally different from all the others. 5.1 Differentiation Algorithms Problem Figure 5.1 shows the trajectory of a projectile with air resistance. The dots indicatethetimes tatwhichmeasurementsweremadeandtabulated.Your problemisto determinetheprojectile‚Äôsvelocity dy‚àïdtasafunctionoftime.Notethatbecausethereis realisticairresistancepresent,thereisnoanalyticfunctiontodifferentiate. You probably did rather well in your first calculus course and feel competent at taking derivatives. However, you may never have taken derivatives of numerical data using the elementarydefinition dy(t) dtdef=lim h‚Üí0y(t+h)‚àíy(t) h. (5.1) Infact,evenacomputerwillhaveproblemswiththiskindoflimitbecauseitiswrought with subtractive cancellation; as his made smaller, the computer‚Äôs finite word length causes the numerator to fluctuate between 0 and the machine precision ùúñm, whileas the denominatorapproacheszero,overflowswilloccurs. 5.1.1 Forward Difference Themostdirectmethodfornumericaldifferentiationstartsbyexpandingafunctionina Taylorseriestoobtainitsvalueatasmallstep haway: y(t+h)=y(t)+hdy(t) dt+h2 2.d2y(t) dt2+h3 3.dy3(t) dt3+¬∑¬∑¬∑, (5.2) ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 5.1 Differentiation Algorithms 79 y(t+h)‚àíy(t) h=dy(t) dt+h 2.d2y(t) dt2+h2 3.dy3(t) dt3+¬∑¬∑¬∑. (5.3) If we ignore the h2terms in (5.3), we obtain the forward-difference algorithm for the derivative: dy(t) dt||||fddef=y(t+h)‚àíy(t) h. (5.4) AnestimateoftheerrorfollowsfromsubstitutingtheTaylorseries(5.2): dy(t) dt||||fd‚âÉdy(t) dt‚àíh 2dy2(t) dt2+¬∑¬∑¬∑. (5.5) You can think of this approximation as using two points to represent the function by a straight line in the interval from xtox+h(Figure 5.1 left). The approximation (5.4) has an error proportional to h(unless the heavens look down upon you kindly and makes y‚Ä≤‚Ä≤vanish).Wecanmaketheapproximationerror[thetermsleftoffontheRHSof(5.4)] smallerbymaking hsmaller,yetprecisionwillbelostfortoosmallan hwheny(t+h)‚âÉy(t). Totryoutthisforward-differencealgorithm,we‚Äôlltake y(t)=a+bt2.Theexactderivative isy‚Ä≤=2bt,whilethecomputedderivativeis dy(t) dt||||fd‚âÉy(t+h)‚àíy(t) h=2bt+bh. (5.6) Thisclearlybecomesagoodapproximationonlyforsmall h‚â™1‚àïb. 5.1.2 Central Difference An improvedapproximationtothederivativestartswiththebasicdefinition(5.1),or,geo- metrically,asshownontherightofFigure5.1.Now,ratherthanmakingasinglestepof h forward,weforma centraldifference bysteppingforwardhalfastepandbackwardhalfa step: dy(t) dt||||cd‚â°Dcdy(t)def=y(t+h‚àï2)‚àíy(t‚àíh‚àï2) h. (5.7) CentralForwardy(t) 0 ty(t) 0tt + ht ‚Äì h/2t + h/2 Figure 5.1 A trajectory of a projectile experiencing air resistance. Left: Forward-difference approximation (slanted line) and Right: central-difference approximation (horizontal line) for the numerical Ô¨Årst derivative at time t. (A tangent to the curve at twould yield the correct derivative.) The central difference is seen to be more accurate than the forward difference. 805 Differentiation and Integration Weestimatetheerrorinthecentral-differencealgorithmbysubstitutingtheTaylorseries fory(t+h‚àï2)andy(t‚àíh‚àï2)into(5.7): y( t+h 2) ‚àíy( t‚àíh 2) ‚âÉ[ y(t)+h 2y‚Ä≤(t)+h2 8y‚Ä≤‚Ä≤(t)+h3 48y‚Ä≤‚Ä≤‚Ä≤(t)+ùí™(h4)] ‚àí[ y(t)‚àíh 2y‚Ä≤(t)+h2 8y‚Ä≤‚Ä≤(t)‚àíh3 48y‚Ä≤‚Ä≤‚Ä≤(t)+ùí™(h4)] =hy‚Ä≤(t)+h3 24y‚Ä≤‚Ä≤‚Ä≤(t)+ùí™(h5), ‚áídy(t) dt||||cd‚âÉy‚Ä≤(t)+1 24h2y‚Ä≤‚Ä≤‚Ä≤(t)+ùí™(h4). (5.8) Theimportantdifferencebetweenthiscentral-differencealgorithmandtheforwarddiffer- enceoneisthatwhen y(t‚àíh‚àï2)issubtractedfrom y(t+h‚àï2),alltermscontaininganeven power ofhin the two Taylor series cancel. This makes the central-difference algorithm accuratetoorder h2(h3beforedivisionby h),whiletheforwarddifferenceisaccurateonly toorderh.Ifthey(t)issmooth,thatis,if y‚Ä≤‚Ä≤‚Ä≤h2‚àï24‚â™y‚Ä≤‚Ä≤h‚àï2,thenyoucanexpecttheerror incentral-differencealgorithmtobesmallerthanwiththeforwarddifferencealgorithm. If we now return to our parabola example (5.6), we will see that the central difference givestheexactderivative,independentof h: dy(t) dt||||cd‚âÉy(t+h‚àï2)‚àíy(t‚àíh‚àï2) h=2bt. (5.9) This is to be expected because the higher derivatives equal zero for a second-order polynomial. 5.2 Extrapolated Difference Since adifferentiationrulebasedonkeepingacertainnumberoftermsinaTaylorseries alsoprovidesanexpressionfortheerror(thetermsnotincluded),wecanreducethethe- oreticalerrorfurtherbyformingacombinationofapproximationswhosesummederrors extrapolate to zero. One such algorithm is the central-difference algorithm (5.7) using a half-step back and a half-step forward. A second algorithm is another central-difference approximation,butthistimeusingquarter-steps: dy(t,h‚àï2) dt||||cddef=y(t+h‚àï4)‚àíy(t‚àíh‚àï4) h‚àï2(5.10) ‚âÉy‚Ä≤(t)+h2 96d3y(t) dt3+¬∑¬∑¬∑. A combination of the two, called the extended difference algorithm , eliminates both the quadraticandlinearterms: dy(t) dt||||eddef=4Dcdy(t,h‚àï2)‚àíDcdy(t,h) 3(5.11) ‚âÉdy(t) dt‚àíh4y(5)(t) 4√ó16√ó120+¬∑¬∑¬∑. (5.12) Equation(5.11)istheextended-differencealgorithmand(5.12)isitserror,with Dcdrepre- sentingthecentral-differencealgorithm.If h=0.4andy(5)‚âÉ1,thentherewillbeonlyone",5458
5.2.1.1 Assessment,"5.2 Extrapolated Difference 81 placeofround-offerrorandthetruncationerrorwillbeapproximatelymachineprecision ùúñm;thisreallyisthebestyoucanhopefor. Whenworkingwiththese,andsimilarhigher-ordermethods,itisimportanttoremem- berthatwhiletheymayworkasdesignedforwell-behavedfunctions,theymayfailbadly forfunctionscontainingnoise,asdodatafromcomputationsormeasurements.Ifnoiseis evident,itmaybebettertofirstsmooththedata,orfitthemwithsomeanalyticfunction usingthetechniquesofChapter6,andthendifferentiate. 5.2.1 Second Derivatives Let‚Äôs saythatyouhavemeasuredtheposition y(t)versustimeforaparticle(Figure5.1). Your problemnowistodeterminetheforceontheparticle.Newton‚Äôssecondlawtellsus thatforceandaccelerationarelinearlyrelated: F=ma=md2y dt2. (5.13) Sobydeterminingthederivative d2y‚àïdt2fromthey(t)values,wedeterminetheforce. Theconcernswehaveexpressedabouterrorsinfirstderivativesareevenmoreofacon- cernforsecondderivatives,whereadditionalsubtractionsmayleadtoadditionalcancella- tions.Let‚Äôslookagainatthecentral-differencemethod: dy(t) dt||||cd‚âÉy(t+h‚àï2)‚àíy(t‚àíh‚àï2) h. (5.14) Thisalgorithmgivesthederivativeat tbymovingforwardandbackwardfrom tbyh‚àï2.As oursecondderivativealgorithm,we‚Äôlltakethecentraldifferenceofthefirstderivative: d2y(t) dt2|||||cd‚âÉy‚Ä≤(t+h‚àï2)‚àíy‚Ä≤(t‚àíh‚àï2) h ‚âÉ[y(t+h)‚àíy(t)]‚àí[y(t)‚àíy(t‚àíh)] h2(5.15) =y(t+h)+y(t‚àíh)‚àí2y(t) h2. (5.16) As we did for first derivatives, we determine the second derivative at tby evaluating the functionintheregionsurrounding t.Althoughtheform(5.16)ismorecompactandrequires fewerstepsthan(5.15),itmayincreasesubtractivecancellationbyfirststoringthe‚Äúlarge‚Äù numbery(t+h)+y(t‚àíh),andthensubtractinganotherlargenumber2 y(t)fromit.Weask youtoexplorethisdifferenceasanexercise. 5.2.1.1 Assessment Write aprogramtocalculatethesecondderivativeofcos tusingthecentral-differencealgo- rithms(5.15)and(5.16).Testitoverfourcycles.Startwith h‚âÉùúã‚àï10andkeepreducing h untilyoureachmachineprecision.Isthereanynoticeabledifferencesbetween(5.15)and (5.16)? Theapproximationerrorsinnumericaldifferentiationdecreasewithdecreasingstepsize h. In turn, round-off errors increase with decreasing step size as you have to take more 825 Differentiation and Integration stepsanddomorecalculations.RememberfromourdiscussioninChapter3thatthebest approximationoccursforan hthatminimizesthesumofapplicationandround-offerrors ùúñapp+ùúñro,andthatoccurswhen ùúñro‚âÉùúñapp. Wehavealreadyestimatedtheapproximationerrorinnumericaldifferentiationrulesby using the Taylor series expansion of y(x+h). The approximation error with the forward- differencealgorithm(5.4)is ùí™(h),whilethatwiththecentral-differencealgorithm(5.8)is ùí™(h2): ùúñfd app‚âÉy‚Ä≤‚Ä≤h 2,ùúñcd app‚âÉy‚Ä≤‚Ä≤‚Ä≤h2 24. (5.17) Toobtainaroughestimateoftheround-offerror,weobservethatdifferentiationessentially subtractsthevalueofafunctionatargument xfromthatofthesamefunctionatargument x+h,andthendividesthedifferenceby h:y‚Ä≤‚âÉ[y(t+h)‚àíy(t)]‚àïh.Ashismadecontinually smaller,weeventuallyreachtheround-offerrorlimitwhere y(t+h)andy(t)differbyjust machineprecision ùúñm: ùúñro‚âÉùúñm h. (5.18) Consequently,round-offandapproximationerrorsbecomeequalwhen ùúñro‚âÉùúñapp, (5.19) ùúñm h‚âÉùúñfd app=y(2)h 2,ùúñm h‚âÉùúñcd app=y(3)h2 24, (5.20) ‚áíh2 fd=2ùúñm y(2), ‚áíh3 cd=24ùúñm y(3). (5.21) Wetakey‚Ä≤‚âÉy(2)‚âÉy(3)(whichmaybecrudeingeneral,althoughnotbadfor etorcost)and assumedoubleprecision, ùúñm‚âÉ10‚àí15: hfd‚âÉ4√ó10‚àí8, hcd‚âÉ3√ó10‚àí5, (5.22) ‚áíùúñfd‚âÉùúñm hfd‚âÉ3√ó10‚àí8,‚áíùúñcd‚âÉùúñm hcd‚âÉ3√ó10‚àí11. (5.23) Thismayseemcontradictorybecausethebetteralgorithmleadstoalarger hvalue.Itisnot. Theabilitytousealarger hmeansthattheerrorinthecentral-differencemethodisabout 1000timessmallerthantheerrorintheforward-differencemethod. Theprogrammingfornumericaldifferentiationissimple: FD = ( y( t+h) ‚àíy(t) ) /h; // Forward diff CD = ( y( t+h/2) ‚àíy(t‚àíh/2) ) /h; // Central diff 3ED = (8 ‚àó(y(t+h/4) ‚àíy(t‚àíh/4))‚àí(y(t+h/2) ‚àíy(t‚àíh/2)))/3/h; //extra 1) Useforward-,central-,andextrapolated-differencealgorithmstodifferentiatethefunc- tionscostandetatt=0.1,1.0,and100. a) Printoutthederivativeanditsrelativeerror Óà±asfunctionsof h.Reducethestepsize huntiltheerrorequalsmachineprecision h‚âÉùúñm. b) Plotlog10|Óà±|versuslog10handcheckwhetherthenumberofdecimalplacesobtained agreeswiththeestimatesinthetext.",4132
5.3 Integration Algorithms. 5.3.4 Simple Integration Error Estimates,"5.3 Integration Algorithms 83 c) Seeifyoucanidentifyregionswherealgorithmic(seriestruncation)errordominates atlargehandround-offerroratsmall hinyourplot.Dotheslopesagreewithour model‚Äôspredictions? 5.3 Integration Algorithms Problem Integrate a Spectrum An experiment measured dN(t)‚àïdt, the number of particlesenteringacounterperunittime.Your problemistointegratethisspectrumto obtainthenumberofparticlesthatenteredthecounterinthefirstsecond: N(1)=‚à´1 0dN(t) dtdt. (5.24) 5.3.1 Box Counting Theintegrationofafunctionmayrequiresomeclevernesstodoanalytically,butisrelatively straightforwardonacomputer.Anancientwaytoperformnumericalintegrationistotake apieceofgraphpaperandcountthenumberofboxesor quadrilaterals lyingbelowacurve oftheintegrand.Forthisreason,numericalintegrationisalsocalled numericalquadrature , evenwhenitbecomesmoresophisticatedthansimpleboxcounting. TheRiemanndefinitionofanintegralisthelimitofthesumoverboxesasthewidth hof theboxapproacheszero(Figure5.2): ‚à´b af(x)dx=lim h‚Üí0[ h(b‚àía)‚àïh‚àë i=1f(xi)] . (5.25) Thenumericalintegralofafunction f(x)isapproximatedastheequivalentofafinitesum overboxesofheight f(x)andwidth ùë§i: ‚à´b af(x)dx‚âÉN‚àë i=1f(xi)ùë§i. (5.26) This is similar to the Riemann definition (5.25), except that there is no limit to an infinitesimalboxsize.Equation(5.26)isthestandardformforallintegrationalgorithms; the function f(x)is evaluated at Npoints in the interval [a,b], and the function values fi‚â°f(xi)are summed with each term in the sum weighted by ùë§i. While, in general, the sumin(5.26)givestheexactintegralonlywhen N‚Üí‚àû,itmaybeexactforfinite Nifthe Figure 5.2 The integral ‚à´b af(x)dxis the area under the graph of f(x)f r o m atob.H e r ew eb r e a ku pt h ea r e ai n t o four regions of equal widths hand Ô¨Åve integration points. ax xi + 1xi + 2b xf(x) 845 Differentiation and Integration integrandisapolynomial.Thedifferentintegrationalgorithms(alsocalledNewton-Coates formulas)amounttodifferentwaysofchoosingthepoints xiandweights ùë§i.Generally,the precisionincreasesas Ngetslarger,atleastuntilround-offerrorbecomessignificant.Since the‚Äúbest‚Äùintegrationruledependsonthespecificbehaviorof f(x),thereisnouniversally bestrule.Infact,someoftheautomatedintegrationschemesfoundinsubroutinelibraries and computational environments switch from one method to another, as well as change themethodsfordifferentintervals,untiltheyfindonesthatworkwellforeachinterval. Ingeneral,youshouldnotattemptanumericalintegrationofanintegrandthatcontainsa singularitywithoutfirstsomehowremovingthesingularity.Youmaybeabletodothisvery simply by breaking the interval down into several subintervals so the singularity is at an endpointwhereanintegrationpointisnotplaced,orbyachangeofvariable;forexample: ‚à´1 ‚àí1|x|f(x)dx=‚à´0 ‚àí1f(‚àíx)dx+‚à´1 0f(x)dx, (5.27) ‚à´1 0x1‚àï3dx=‚à´1 03y3dy,(ydef=x1‚àï3), (5.28) ‚à´1 0f(x)dx ‚àö 1‚àíx2=2‚à´1 0f(1‚àíy2)dy ‚àö 2‚àíy2,(y2def=1‚àíx). (5.29) Likewise,ifyourintegrandhasaveryslowvariationinsomeregion,youcanspeedupthe integration by changing to a variable that compresses that region and places few points there,ordividesuptheintervalandperformsseveralintegrations.Conversely,ifyourinte- grandhasaveryrapidvariationinsomeregion,youmaywanttochangetovariablesthat expandthatregiontoensurethatnooscillationsaremissed. 5.3.2 Trapezoid Rule The trapezoid and Simpson‚Äôs integration rules both use evenly spaced values of x (Figure5.3).Theyuse Npointsxi,i=1,N,evenlyspacedadistance hapartthroughoutthe integration region [a,b],a n dinclude the endpoints in the integration region. This means thatthereare (N‚àí1)intervals,eachoflength h: h=b‚àía N‚àí1,xi=a+(i‚àí1)h,i=1,N, (5.30) wherewestartourcountingat i=1.Thetrapezoidruletakeseachintegrationinterval i, andconstructsatrapezoidofwidth hinit(Figure5.3).Thisapproximates f(x)byastraight lineineachinterval i,andusestheaverageheight (fi+fi+1)‚àï2asthevaluefor f.Thearea ofeachsuchtrapezoidis ‚à´xi+h xif(x)dx‚âÉh(fi+fi+1) 2=1 2hfi+1 2hfi+1. (5.31) Intermsofourstandardintegrationformula(5.26),the‚Äúrule‚Äùin(5.31)isfor N=2points withweights ùë§i‚â°1 2(Table5.1). Inordertoapplythetrapezoidruletotheentireregion [a,b],weaddthecontributions fromeachsubinterval: ‚à´b af(x)dx‚âÉh 2f1+hf2+hf3+¬∑¬∑¬∑+hfN‚àí1+h 2fN. (5.32) 5.3 Integration Algorithms 85 a xbf(x) Trap 1 Trap 2 Trap 3 Trap 4 a xbf(x) Parabola 1Parabola 2 Figure 5.3 Different shapes used to approximate the areas under the curve. Left: Straight-line sections used for the trapezoid rule. Right: Two parabolas used in Simpson‚Äôs rule. Table 5.1 Elementary weights for uniform-step integration rules. Name Degree Elementary weights Trapezoid 1 (1,1)h 2 Simpson‚Äôs 2 (1,4,1)h 3 3 83 (1,3,3,1)3 8h Mile 4 (14,64,24,64,14)h 45 Youwillnoticethatbecausetheinternalpointsarecountedtwice(attheendofoneinterval and at the beginning of the next), they have weights of h‚àï2+h‚àï2=h, whereas the end- pointsarecountedjustonce,andonthataccounthaveweightsofonly h‚àï2.Intermsofour standardintegrationrule(5.61),wehave ùë§i={ h 2,h,‚Ä¶,h,h 2} (Trapezoidrule) . (5.33) InListing5.1,weprovideasimpleimplementationofthetrapezoidrule. 5.3.3 Simpson‚Äôs Rule Simpson‚Äôs ruleapproximatestheintegrand f(x)byaparabolawithineachequallyspaced interval(Figure5.3right): f(x)‚âÉùõºx2+ùõΩx+ùõæ. (5.34) Theareaundertheparabolaforeachintervalis ‚à´xi+h xi(ùõºx2+ùõΩx+ùõæ)dx=ùõºx3 3+ùõΩx2 2+ùõæx|||||xi+h xi. (5.35) 865 Differentiation and Integration Inordertorelatetheparameters ùõº,ùõΩ,andùõætothefunction,weconsideranintervalfrom ‚àí1to+1,inwhichcase ‚à´1 ‚àí1(ùõºx2+ùõΩx+ùõæ)dx=2ùõº 3+2ùõæ. (5.36) Butwenoticethat f(‚àí1)=ùõº‚àíùõΩ+ùõæ,f(0)=ùõæ,f(1)=ùõº+ùõΩ+ùõæ, (5.37) ‚áíùõº=f(1)+f(‚àí1) 2‚àíf(0),ùõΩ=f(1)‚àíf(‚àí1) 2,ùõæ=f(0). (5.38) Inthisway,wecanexpresstheintegralastheweightedsumoverthevaluesofthefunction atthreepoints: ‚à´1 ‚àí1(ùõºx2+ùõΩx+ùõæ)dx=f(‚àí1) 3+4f(0) 3+f(1) 3. (5.39) Seeingthatthreevaluesofthefunctionareneeded,weapplythisresulttoourproblemby evaluatingtheintegralovertwoadjacentintervals,inwhichcaseweevaluatethefunction atthetwoendpointsandinthemiddle(Table5.1): ‚à´xi+h xi‚àíhf(x)dx=‚à´xi+h xif(x)dx+‚à´xi xi‚àíhf(x)dx ‚âÉh 3fi‚àí1+4h 3fi+h 3fi+1. (5.40) Takenote:Simpson‚Äôsrulerequirestheelementaryintegrationtobeover pairsofintervals, which,inturn,requiresthatthe totalnumberofintervalsbeevenorthatthenumberofpoints Nbeodd.InordertoapplySimpson‚Äôsruletotheentireinterval,weaddupthecontributions fromeachpairofsubintervals,countingallbutthefirstandlastendpointstwice: ‚à´b af(x)dx‚âÉh 3f1+4h 3f2+2h 3f3+4h 3f4+¬∑¬∑¬∑+4h 3fN‚àí1+h 3fN. (5.41) Intermsofourstandardintegrationrule(5.26),wehave ùë§i={ h 3,4h 3,2h 3,4h 3,‚Ä¶,4h 3,h 3} (Simpson‚Äôsrule) . (5.42) Thesumoftheseweightsprovidesausefulcheckonyourintegration: N‚àë i=1ùë§i=(N‚àí1)h. (5.43) Remember,thenumberofpoints NmustbeoddforSimpson‚Äôsrule. 5.3.4 Simple Integration Error Estimates In general,youshouldchooseanintegrationrulethatgivesanaccurateanswerusingthe least number of integration points. We obtain a crude estimate of the approximation or algorithmicerror Óà±fortheequal-spacingrulesandtheirrelativeerror ùúñ,byexpanding f(x) in a Taylor series around the midpoint of the integration interval. We then multiply that errorbythenumberofintervals Ntoestimatetheerrorfortheentireregion [a,b].Forthe 5.3 Integration Algorithms 87 trapezoidandSimpson‚Äôsrulesthisyields Óà±t=O( [b‚àía]3 N2) f(2),Óà±s=O( [b‚àía]5 N4) f(4),ùúñt,s=Óà±t,s f, (5.44) whereùúñisameasureoftherelativeerror.Weseethatthethird-derivativeterminSimpson‚Äôs rulecancels(muchlikethecentral-differencemethoddoesindifferentiation).Equations (5.44)areilluminatinginshowinghowincreasingthesophisticationofanintegrationrule leadstoanerrorthatdecreaseswithahigherinversepowerof N,yetisalsoproportional to higherderivativesof f. Consequently,for smallintervalsandfunctions f(x)withwell- behaved derivatives, Simpson‚Äôs rule should converge more rapidly and be more accurate thanthetrapezoidrule. To model the round-off error in integration, we assume that after Nsteps therelative round-offerrorisrandomandoftheform ùúñro‚âÉ‚àö Nùúñm, (5.45) whereùúñmisthemachineprecision, ùúñ‚àº10‚àí7forsingleprecision,and ùúñ‚àº10‚àí15fordouble precision.Inasmuchasmostscientificcomputationsareperformedwithdoubles,wewill assumedoubleprecision.Wewanttodeterminean Nthatminimizesthetotalerror,that is,thesumoftheapproximationandround-offerrors: ùúñtot‚âÉùúñro+ùúñapp. (5.46) Thisoccurs,approximately,whenthetwoerrorsareofequalmagnitude,whichweapprox- imateevenfurtherbyassumingthatthetwoerrorsareequal: ùúñro=ùúñapp=Óà±trap,simp f. (5.47) Tocontinuethesearchforoptimum Nforageneralfunction f,wesetthescaleoffunction sizeandthelengthsbyassuming f(n) f‚âÉ1,b‚àía=1‚áíh=1 N. (5.48) Theestimate(5.47),whenappliedtothe trapezoid rule ,yields ‚àö Nùúñm‚âÉf(2)(b‚àía)3 fN2=1 N2, (5.49) ‚áíN‚âÉ1 (ùúñm)2‚àï5=( 1 10‚àí15)2‚àï5 =106, (5.50) ‚áíùúñro‚âÉ‚àö Nùúñm=10‚àí12. (5.51) Theestimate(5.47),whenappliedto Simpson‚Äôs rule ,yields ‚àö Nùúñm=f(4)(b‚àía)5 fN4=1 N4, (5.52) ‚áíN=1 (ùúñm)2‚àï9=( 1 10‚àí15)2‚àï9 =2154, (5.53) ‚áíùúñro‚âÉ‚àö Nùúñm=5√ó10‚àí14. (5.54)",8687
5.4.1 Mapping Gaussian Points,"885 Differentiation and Integration Theseresultsareilluminatinginthattheyshowhow: ‚óèSimpson‚Äôsrulerequiresfewerpointsandhaslesserrorthanthetrapezoidrule. ‚óèItispossibletoobtainanerrorclosetomachineprecisionwithSimpson‚Äôsrule(andwith otherhigher-orderintegrationalgorithms). ‚óèObtaining the bestnumerical approximation to an integral is not achieved by letting N‚Üí‚àû, but with a relatively small N‚â§1000. Larger Nonly gives you more round-off errors. 5.3.5 Higher-Order Algorithms Asinnumericaldifferentiation,wecanusetheknownfunctionaldependenceoftheerror onintervalsize htoreducetheintegrationerror.Forsimplealgorithmslikethetrapezoid andSimpson‚Äôsrules,wehavetheanalyticestimates(5.47),whileforothersyoumayhaveto experimenttodetermineanapproximate hdependence.Toillustrate,if A(h)andA(h‚àï2)are thevaluesoftheintegraldeterminedforintervals handh‚àï2,respectively,andifweassume thatthenumericalevaluationoftheintegralhasanerrorwhoseexpansionhasaleading errortermproportionalto h2, A(h)‚âÉ‚à´b af(x)dx+ùõºh2+ùõΩh4+¬∑¬∑¬∑, (5.55) thenA( h 2) ‚âÉ‚à´b af(x)dx+ùõºh2 4+ùõΩh4 16+¬∑¬∑¬∑. (5.56) Consequently,wecanmakethe h2termintheerrorvanishbycomputingtheintegralas thecombination A‚âÉ4 3A( h 2) ‚àí1 3A(h)‚âÉ‚à´b af(x)dx‚àíùõΩh4 4+¬∑¬∑¬∑. (5.57) Clearlythisparticulartrick(Romberg‚Äôsextrapolation)worksonlyifthe h2termdominates theerror. InTable5.1,wehavegiventheweightsforseveralequal-intervalrules.Weseethatthe Simpson‚Äôsruleusestwointervals,thethree-eighthsruleusesthree,andtheMilnerulefour.1 Doremember,thesearesingle-intervalrules,andwhenstrungtogethertoobtainarulefor theentireintegrationrange,thepointsthatendoneintervalandbeginthenextarecounted twice. You can easily determine the number of elementary intervals integrated over, and check whether you and we have written the weights right, by summing just the weights foranyrule.Thesumgivestheintegralof f(x)=1andmustequal htimesthenumberof intervals(whichinturnequals b‚àía): N‚àë i=1ùë§i=h√óNintervals=b‚àía. (5.58) 1 Thereis,notcoincidentally,aMileComputerCenteratOregonStateUniversity,althoughthereno longerisacentralcomputerthere 5.4 Gaussian Quadrature 89 5.4 Gaussian Quadrature It isoftenusefultorewritethebasicintegrationformula(5.26)withaweightingfunction W(x)separatefromtheintegrand: ‚à´b af(x)dx‚â°‚à´b aW(x)g(x)dx‚âÉN‚àë i=1ùë§ig(xi). (5.59) In the Gaussian quadrature approach to integration, the Npoints and weights in (5.59) are chosen to make the integration exact if g(x)were a(2N‚àí1)-degree polynomial. To obtainthisincredibleoptimization,thepoints xienduphavingaspecificdistributionover [a,b]. In general, if g(x)is smooth, or can be made smooth by factoring out some W(x) (seeTable5.2),Gaussianquadraturewillproducehigheraccuracythanthetrapezoidand Simpson‚Äôsrulesforthesamenumberofpoints.Sometimestheintegrandmaynotbesmooth because it has different behaviors in different regions, in which case you could integrate eachregionseparately,andthenaddtheresults.Infact,some‚Äúsmart‚Äùintegrationsubrou- tinesdecideforthemselveshowmanyintervalstouseandwhichruletouseineach. AlltherulesindicatedinTable5.2areaformofGaussianquadraturefollowingthegen- eralform(5.59).Wecanseethatinonecasetheweightingfunctionisanexponential,in anotheraGaussian,andinseveralcases,thereisanintegrablesingularity.Incontrastto theequallyspacedrules,thereisneveranintegrationpointattheextremesoftheintervals (aorb),withdiffering Nvaluesleadingtocompletelydifferingsetsofpointsandweights. ThederivationoftheGaussianpointswillbeoutlinedbelow,butwepointoutherethat forordinaryGaussian(Gauss‚ÄìLegendre)integration,thepoints yiturnouttobethe Nzeros oftheLegendrepolynomials,withtheweightsrelatedtothederivatives, PN(yi)=0,ùë§i=2 (1‚àíy2 i)[P‚Ä≤ N(yi)]2. (5.60) Programs to generate these points and weights are standard in mathematical function libraries,arefoundintablesAbramowitzandStegun[1972],orcanbecomputed,aswedo inour gauss.pyprogram,whichalsoscalesthepointstospanaspecifiedregion.Asacheck thatyourprogram‚Äôspointsarecorrect,youmaywanttocomparethemtothisfour-point set: ¬±yi ùë§i 0.339981043584856 0.652145154862546 0.861136311594053 0.347854845137454 Table 5.2 Types of Gaussian integration rules. Integral Name Integral Name ‚à´1 ‚àí1f(y)dyGauss ‚à´1 ‚àí1F(y)‚àö 1‚àíy2dyGauss‚ÄìChebyshev ‚à´‚àû ‚àí‚àûe‚àíy2F(y)dyGauss‚ÄìHermite ‚à´‚àû 0e‚àíyF(y)dyGauss‚ÄìLaguerre ‚à´‚àû 0e‚àíy ‚àöyF(y)dyAssociatedGauss‚ÄìLaguerre",4234
5.6.1 10D MC Error Investigation,"905 Differentiation and Integration 5.4.1 Mapping Gaussian Points Our standardintegrationrule(5.26)forthegeneralinterval [a,b]is ‚à´b af(x)dx‚âÉN‚àë i=1f(xi)ùë§i. (5.61) WithGaussianpointsandweights,the yinterval‚àí1<yi‚â§1mustbemappedontothex intervala‚â§x‚â§b.Herearesomemappingswehavefoundusefulinourwork.Inallcases, (yi,ùë§‚Ä≤ i)aretheelementaryGaussianpointsandweightsfortheinterval [‚àí1,1],andwewant toscalethe xwithvariousranges. 1)[‚àí1,1]‚Üí[a,b]uniformly, (a+b)‚àï2=midpoint: xi=b+a 2+b‚àía 2yi,ùë§i=b‚àía 2ùë§‚Ä≤ i, (5.62) ‚áí‚à´b af(x)dx=b‚àía 2‚à´1 ‚àí1f[x(y)]dy. (5.63) 2)[0‚Üí‚àû],a=midpoint: xi=a1+yi 1‚àíyi,ùë§i=2a (1‚àíyi)2ùë§‚Ä≤ i. (5.64) 3)[‚àí‚àû‚Üí‚àû],scale set by a: xi=ayi 1‚àíy2 i,ùë§i=a(1+y2 i) (1‚àíy2 i)2ùë§‚Ä≤ i. (5.65) 4)[a‚Üí‚àû],a+2b=midpoint: xi=a+2b+ayi 1‚àíyi,ùë§i=2(b+a) (1‚àíyi)2ùë§‚Ä≤ i. (5.66) 5)[0‚Üíb],ab‚àï(b+a)=midpoint: xi=ba(1+yi) b+a‚àí(b‚àía)yi,ùë§i=2ab2 (b+a‚àí(b‚àía)yi)2ùë§‚Ä≤ i. (5.67) Asyoucansee,evenifyourintegrationrangeextendsouttoinfinity,therewillbepoints at large, but not infinite xvalues. As you keep increasing the number of integration pointsN,thelastxigetslarger,butalwaysremainsfinite. 5.4.2 Gaussian Quadrature Derivation ‚äô We wanttoperformanumericalintegrationwith Nintegrationpoints: ‚à´+1 ‚àí1f(x)dx=N‚àë i=1ùë§if(xi), (5.68) wheref(x)is a polynomial of degree (2N‚àí1)or less. The unique property of Gaussian quadrature is that (5.68) will be exact, as long as we ignore the effect of round-off error. Determining the xi‚Äôs andùë§i‚Äôs require some knowledge of special functions and some 5.5 Monte Carlo Integrations 91 cleverness [Hildebrand, 1956]. The knowledge needed is the two properties of Legendre polynomials PN(x)oforderN: 1)PN(x)isorthogonaltoeverypolynomialoforderlessthan N. 2)PN(x)hasNrealrootsintheinterval ‚àí1‚â§x‚â§1. We define a new polynomial of degree equal to or less than Nobtained by dividing the integrandf(x)bytheLegendrepolynomial PN(x): q(x)def=f(x) PN(x), (5.69) ‚áíf(x)=q(x)PN(x)+r(x). (5.70) Herer(x)isan(unknown)polynomialofdegree Norless,whichwewillnotneedtodeter- mine.Ifwenowsubstitute(5.70)into(5.68),andusethefactthat PNisorthogonaltoevery polynomialofdegreelessthanorequalto N,onlythesecond, r(x),termremains: ‚à´+1 ‚àí1f(x)dx=‚à´+1 ‚àí1q(x)PN(x)dx+‚à´+1 ‚àí1r(x)dx=‚à´+1 ‚àí1r(x)dx. (5.71) Yetbecause r(x)isapolynomialofdegree Norless,wecanuseastandard Npointruleto evaluatetheintegralexactly. Nowthatweknowitispossibletointegratea (2N‚àí1)orlessdegreepolynomialwith justNpoints,wedisplaysomeclevernesstodeterminejustwhatthosepointswillbe.We substitute(5.70)into(5.68)andnotethat ‚à´+1 ‚àí1f(x)dx=N‚àë i=1ùë§iq(xi)PN(xi)+N‚àë i=1ùë§ir(xi)=N‚àë i=1ùë§ir(xi). (5.72) Theclevernessisrealizingthatifwechoosethe Nintegrationpointstobethezeros(roots)of theLegendrepolynomial PN(x),thenthefirsttermontheRHSof(5.72)willvanishbecause PN(xi)=0foreachxi: ‚à´+1 ‚àí1f(x)dx=N‚àë i=1ùë§ir(xi). (5.73) Thisisourproofthatthe Nintegrationpointsovertheinterval( ‚àí1,1)arethe Nzeros of the Legendre polynomial PN(x). As indicated in (5.60), the weights are related to the derivativeoftheLegendrepolynomialsevaluatedattherootsofthepolynomial.Weleave thederivationoftheweightstoHildebrand[1956]. 5.5 Monte Carlo Integrations Imagine yourselfasafarmerwalkingtoyourfurthermostfieldtoaddsomealgae-eating fishtoapondhavinganalgaeexplosion.Yougetthereonlytoreadtheinstructionlabel onthefishcontaineranddiscoverthatyouneedtoknowtheareaofthepondinorderto determinethecorrectnumberoffishtoadd.Your problemistomeasuretheareaofthis irregularlyshapedpondwithjustthematerialsathand[Gould etal.,2006]. It is hard to believe that Monte Carlo techniques can be used to evaluate integrals. Afterall,wedonotwanttogambleonthevalues.Whileitistruethatothermethodsare 925 Differentiation and Integration Pond Figure 5.4 Left: Throwing stones into a pond as a technique for measuring its area. The ratio of ‚Äúhits‚Äù to total number of stones thrown equals the ratio of the area of the pond to that of the box. Right: The evaluation of an integral via a Monte Carlo (stone-throwing) technique based on the ratio of areas. preferableforsingleanddoubleintegrals,itturnsoutthatMonteCarlotechniquesarebest when the dimensionality of integrations gets large. For our pond problem, we will use a samplingtechnique(Figure5.4): 1) Walkoffaboxthatcompletelyenclosesthepond,andremoveanypebbleslyingonthe groundwithinthebox. 2) Measurethelengthsofthesidesinnaturalunitslikeyour feet.Thisletsyoucalculate theareaoftheenclosingbox Abox. 3) Grab a bunch of pebbles, count their number, and then throw them up in the air in randomdirections. 4) Countthenumberofsplashesinthepond Npondandthenumberofpebbleslyingonthe groundwithinyourbox Nbox. 5) Assumingthatyouthrewthepebblesuniformlyandrandomly,thenumberofpebbles fallingintothepondshouldbeproportionaltotheareaofthepond Apond.Youdetermine thatareafromthesimpleratio Npond Npond+Nbox=Apond Abox‚áíApond=Npond Npond+NboxAbox. (5.74) 5.5.1 Stone Throwing Implementation Usesampling(Figure5.4)toperforma2Dintegrationandtherebydetermine ùúã: 1) Imagineacircularpondenclosedinasquareofside2 (r=1). 2) Weknowtheanalyticanswerthattheareaofacircle ‚àÆdA=ùúã. 3) Generateasequenceofrandomnumbers ‚àí1‚â§ri‚â§+1. 4) Fori=1toN,pick(xi,yi)=(r2i‚àí1,r2i). 5) Ifx2 i+y2 i<1,letNpond=Npond+1;otherwiselet Nbox=Nbox+1. 6) Use(5.74)tocalculatethearea,andinthisway ùúã. 7) Increase Nuntilyouget ùúãtothreesignificantfigures(wedon‚Äôtaskmuch‚Äìthat‚Äôsonly slide-ruleaccuracy). 5.5 Monte Carlo Integrations 93 10 10010‚Äì1310‚Äì910‚Äì5 10‚Äì910‚Äì5 10‚Äì710‚Äì310‚Äì1 N|Error| |Error|Trapezoid Simpson Gaussian NTrapezoid Simpson Gaussian 10 100 Figure 5.5 Log‚Äìlog plots of the error in the integration of exponential decay using the trapezoid rule, Simpson‚Äôs rule, and Gaussian quadrature versus the number of integration points N. Approximately, 15 decimal places of precision are attainable with double precision ( left), and 7 places with single precision ( right). The algorithms are seen to stop converging when round-off error (the Ô¨Çuctuating and increasing part near the bottom) starts to dominate. Listing5.3providesourcode vonNeuman.py thatperformsaMonteCarlointegrationvia stonethrowing. 5.5.2 Integration Error Investigation 1) Write a double-precision program to integrate e‚àítfrom 0 to 1 numerically using the trapezoid rule, the Simpson‚Äôs rule, Gaussian quadrature, and Monte Carlo (MC) inte- gration.Inthiscase,thereisananalyticanswerwithwhichtocompare: dN(t) dt=e‚àít‚áíN(1)=‚à´1 0e‚àítdt=1‚àíe‚àí1. (5.75) 2) Computetherelativeerror ùúñ=|(numerical-exact) ‚àïexact|ineachcase.Presentyourdata inthetabularform N ùùêTùùêSùùêG 2 ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ ... 10 ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ withspacesortabsseparatingthefields.Try Nvaluesof2,10,20,40,80,160, ....( Hint: Evennumbersmaynotbetheassumptionofeveryrule.) 3) Make a log10‚àílog10plot of the relative error ùúñversus N, as in Figure 5.5. You should observe ùúñ‚âÉCNùõº‚áílogùúñ=ùõºlogN+constant. (5.76) If your graph is similar to straight line, this means that error obeys a power law. The ordinateonyourplotwillbethenegativeofthenumberofdecimalplacesofprecision inyourcalculation. 945 Differentiation and Integration 4) Useyourplotortabletoestimatethepower-lawdependenceoftheerror ùúñonthenum- ber of points N, and to determine the number of decimal places of precision in your calculation.DothisforboththetrapezoidandSimpson‚Äôsrules,andinboththealgorith- micandround-offerrorregimes.(Notethatitmaybehardtomake Nlargeenoughto reachtheround-offerrorregimeforthetrapezoidrulebecausetheapproximationerror issolarge.) InListing5.2,wegiveasampleprogramthatperformsanintegrationwithGaussianpoints. Themethod gaussgeneratesthepointsandweightsandmaybeusefulinotherapplications aswell. 5.6 Mean Value and N‚ÄìD Integration The standard Monte Carlo technique for integration is based on the meanvaluetheorem (presumablyfamiliarfromelementarycalculus): I=‚à´b adxf(x)=(b‚àía)‚ü®f‚ü©. (5.77) Thetheoremstatestheobviousifyouthinkofintegralsasareas:Thevalueoftheintegralof somefunction f(x)betweenaandbequalsthelengthoftheinterval (b‚àía)timesthemean valueofthefunctionoverthatinterval ‚ü®f‚ü©(Figure5.6).TheMonteCarlointegrationalgo- rithmsimplyusesrandompointstoevaluatethemeanin(5.77).Withasequence a‚â§xi‚â§b ofNuniformrandomnumbers,wedeterminethe samplemean bysamplingthefunction f(x)atNpoints: ‚ü®f‚ü©‚âÉ1 NN‚àë i=1f(xi). (5.78) Thisgivesustheverysimpleintegrationrule: ‚à´b adxf(x)‚âÉ(b‚àía)1 NN‚àë i=1f(xi)=(b‚àía)‚ü®f‚ü©. (5.79) Equation (5.79) can be thought of as our standard algorithm for integration (5.26) with thepoints xichosenrandomly,andwithuniformweights ùë§i=(b‚àía)‚àïN.Seeingthatno attempthasbeenmadetoobtainanoptimalanswerforagivenvalueof N,thisdoesnot seem like it would be an efficient means to evaluate integrals; but you must admit it is simple.Ifweletthenumberofsamplesof f(x)approachinfinity, N‚Üí‚àû,orifwekeepthe numberofsamplesfiniteandtaketheaverageofinfinitelymanyruns,thelawsofstatistics f(x)f(x) xFigure 5.6 The area under the curve f(x) is the same as that under the horizontal line whose height y=‚ü®f‚ü©.",8741
5.7 MC Variance Reduction,"5.6 Mean Value and N‚ÄìD Integration 95 assureusthat(5.79)willapproachthecorrectanswer,atleastiftherewerenoround-off errors. Forreaderswhoarefamiliarwithstatistics,weremindyouthattheuncertaintyinthe valueobtainedfortheintegral IafterNsamplesof f(x)ismeasuredbythestandarddevi- ationùúéI.Ifùúéfisthestandarddeviationoftheintegrand finthesampling,thenfornormal distributionswehave ùúéI‚âÉ1‚àö Nùúéf. (5.80) Soforlarge N,theerrorinthevalueobtainedfortheintegralshoulddecreaseas1 ‚àï‚àö N. Let‚Äôssaythatwewanttocalculatesomepropertiesofasmallatomsuchasmagnesium with12electrons.Todothatweneedtointegratetheatomicwavefunctionsoverthethree coordinates for each of 12 electrons. This amounts to a 3 √ó12=36-D integral. If we use 64pointsforeachintegration,thisrequiresabout6436‚âÉ1065evaluationsoftheintegrand. Ifthecomputerwerefastandcouldevaluatetheintegrandamilliontimespersecond,this wouldtakeabout1059seconds,whichissignificantlylongerthantheageoftheuniverse (‚àº1017seconds). 5.6.1 10-D MC Error Investigation When we perform a multidimensional integration, the relative error in the Monte Carlo technique,beingstatistical,decreasesas1 ‚àï‚àö N.Thisisvalidevenifthe Npointsaredis- tributed over Ddimensions. In contrast, when we use these same Npoints to perform a D-dimensional integration as Dseparate 1D integrals using a rule such as Simpson‚Äôs, we useN‚àïDpointsforeachintegration.Forfixed N,thismeansthatthenumberofpointsused foreachintegrationdecreasesasthenumberofdimensions Dincreases,andsotheerror ineachintegration increaseswithD.Furthermore,thetotalerrorwillbeapproximately N timestheerrorineachintegral.Ifyouputthesetrendstogetheranddotheanalysisfora particularintegrationrule,youwillfindthatforadimension D‚âÉ3‚Äì4,theerrorinMonte Carlointegrationisapproximatelyequaltothatofconventionalschemes.Forlargervalues ofD,theMonteCarlomethodismoreaccurate. 5.6.2 Implementation: 10-D Monte Carlo Integration Your problemistofindawaytoperformmultidimensionalintegrationssothatyoulive longenoughtosavortheresults.Specifically,evaluatethe10Dintegral I=‚à´1 0dx1‚à´1 0dx2¬∑¬∑¬∑‚à´1 0dx10(x1+x2+¬∑¬∑¬∑+x10)2. (5.81) Checkyournumericalansweragainsttheanalyticone,155 6. Itiseasytogeneralizemeanvalueintegrationtomanydimensionsbypickingrandom pointsinamultidimensionalspace.Forexample,in2D: ‚à´b adx‚à´d cdyf(x,y)‚âÉ(b‚àía)(d‚àíc)1 NN‚àë if(xi)=(b‚àía)(d‚àíc)‚ü®f‚ü©.(5.82)",2305
5.9 Code Listings,"965 Differentiation and Integration Use a built-in random-number generator to perform the 10D Monte Carlo integration in (5.81). 1) Conduct16trialsandtaketheaverageasyouranswer. 2) Trysamplesizesof N=2,4,8,‚Ä¶,8192. 3) Plottherelativeerror versus1‚àï‚àö N,andseeifalinearbehavioroccurs. 4) Whatisyourestimatefortheaccuracyoftheintegration? 5) Showthatforadimension D‚âÉ3‚Äì4,theerrorinmultidimensionalMonteCarlointegra- tionisapproximatelyequaltothatofconventionalschemes,andthatforlargervalues ofD,theMonteCarlomethodismoreaccurate. 5.7 MC Variance Reduction Itiscommoninmanyphysicalapplicationstointegrateafunctionwithanapproximately Gaussiandependenceon x.TherapidfalloffoftheintegrandmeansthatourMonteCarlo integrationtechniquewouldrequireanincrediblylargenumberofpointstoobtaineven modest accuracy. Your problemis to make Monte Carlo integration more efficient for rapidlyvaryingintegrands. Ifthefunctionbeingintegratedneverdiffersmuchfromitsaveragevalue,thenthestan- dardMonteCarlomeanvaluemethod(5.79)shouldworkwellwithalarge,butmanageable, numberofpoints.Yetforafunctionwithalarge variance(i.e.,onethatisnot‚Äúflat‚Äù),many oftheevaluationsofthefunctionmayoccurfor xvaluesatwhichthefunctionisverysmall, andthusmakesaverysmallcontributiontothefinalvalueoftheintegral;soit‚Äôsbasically a waste of time to expend much effort in regions where the integrand is very small. The efficiency of the integration can be improved by mapping the function finto a different functiongthathasasmallervarianceovertheinterval.Weindicatetwomethodshereand referyoutoPress etal.[2007]andKoonin[1986]formoredetails. Thefirstmethodisa variancereduction inwhichwedeviseaflatterfunctionoverwhich tointegrate.Supposeweconstructafunction g(x)withthefollowingpropertieson [a,b]: |f(x)‚àíg(x)|‚â§ùúñ,‚à´b adxg(x)=J. (5.83) Wenowevaluatetheintegralofthedifference f(x)‚àíg(x)andaddtheresultto J: ‚à´b adx f(x)=‚à´b adx[f(x)‚àíg(x)]+J. (5.84) Ifwearecleverenoughtofindasimple g(x)thatmakesthevarianceof f(x)‚àíg(x)lessthan thatoff(x),wecanobtainevenmoreaccurateanswers. 5.8 Importance Sampling and von Neumann Rejection A secondmethodforimprovingMonteCarlointegrationis importancesampling ,socalled becauseitsamplestheintegrandinthemostimportantregions.Itderivesfromtheidentity I=‚à´b adx f(x)=‚à´b adxùë§(x)f(x) ùë§(x). (5.85) 5.9 Code Listings 97 Figure 5.7 The von Neumann rejection technique for generating random points with weight W(x). A random point is accepted if it lies below the curve ofW(x)and rejected if it lies above. This generates a random distribution weighted by whatever W(x) function is plotted. Accept Rejectw0 x1 xx2w2 w1w(x) If we use a probability distribution for our random numbers that incorporates ùë§(x),t h e integralcanbeapproximatedas I=‚ü®f ùë§‚ü© ‚âÉ1 NN‚àë i=1f(xi) ùë§(xi). (5.86) Theimprovementarisingfrom(5.86)isthatwithajudiciouschoiceofweightingfunction ùë§(x)‚àùf(x),wecanmake f(x)‚àïùë§(x)moreconstantandthuseasiertointegrateaccurately. Asimpleandingeniousmethodforgeneratingrandompointswithaprobabilitydistri- butionùë§(x)was deduced by von Neumann. This method is essentially the same as the rejection or sampling method used to guess the area of a pond, only now the pond has beenreplacedbytheweightingfunction ùë§(x),andthearbitraryboxaroundthelakebythe arbitraryconstant ùë§0.Imagineagraphof ùë§(x)versusx(Figure5.7).Walkoffyourboxby placingthe line ùë§=ùë§0on the graph,withtheonlyconditionbeing ùë§0‚â•ùë§(x).W en e x t ‚Äúthrow stones‚Äù at this graph and count only those splashes that fall into the ùë§(x)pond. Thatis,wegenerateuniformdistributionsin xandy‚â°Wwiththemaximum yvalueequal tothewidthofthebox ùë§0: (xi,Wi)=(r2i‚àí1,ùë§0r2i). (5.87) Wethenrejectall xithatdoesnotfallintothepond: ifWi<ùë§(xi),accept, if Wi>ùë§(xi),reject. (5.88) Thexivaluessoacceptedwillbeweightedby ùë§(x)(Figure5.7),withthelargestnumberof acceptancesoccurringwhere ùë§(x)islarge,inthiscaseformidrange x.InChapter17,we applyavariationoftherejectiontechniqueknownasthe Metropolisalgorithm . 5.9 Code Listings Listing 5.1 TrapMethods.py Integratesafunction f(y)withthetrapezoidrule.Notethat thestepsize hdependsuponthesizeofintervalhereandthattheweightsattheendsand middleoftheintervalsdiffer. 1# TrapMethods . py : trapezoid integration , a <x<b, N pts, N ‚àí1 intervals fromnumpyimport ‚àó 985 Differentiation and Integration 5deffunc(x): return5‚àó(sin(8 ‚àóx))‚àó‚àó2‚àóexp(‚àíx‚àóx)‚àí13‚àócos(3 ‚àóx) deftrapezoid(A,B,N): 9h=( B ‚àíA)/(N‚àí1) # step size sum= (func(A)+func(B))/2 #( 1 s t+l a s t ) / 2 foriin range (1, N‚àí1): sum+= func (A+i ‚àóh) 13returnh‚àósum A=0 . 5 B=2 . 3 N = 1200 17print(trapezoid(A,B,N ‚àí1)) Listing 5.2 IntegGauss.py Integrates the function f(x)via Gaussian quadrature. The points and weights are generated in the method gauss, which will be the same for other applications as well. Note that the level of desired precision is set by the parameter eps, whichshouldbesetbytheuser,asshouldthevaluefor job,whichcontrolsthemappingof thepointsontoarbitraryintervals[theyaregeneratedin( ‚àí1,1)]. 1# IntegGauss .py: Gaussian quadrature generator of pts &wts fromnumpyimport ‚àó fromsysimportversion 5 max_in = 11 # N u m b intervals vmin = 0.; vmax = 1. #I n tr a n g e s ME = 2.7182818284590452354E0 # Euler ‚Äôs const 9w = zeros( (2001), float) x = zeros( (2001), float) deff(x): # The integrand 13return(exp(‚àíx) ) defgauss(npts, job, a, b, x, w): m =i=j=t=t 1=p p=p 1=p 2=p 3=0 . eps = 3.E ‚àí14 # Accuracy : ‚àó‚àó‚àó‚àó‚àó‚àó ADJUST THIS ‚àó‚àó‚àó‚àó‚àó‚àó‚àó . 17m=int((npts + 1)/2 ) foriin range (1, m+ 1): t=c o s ( m a t h . p i ‚àó(float(i)‚àí0.25)/(float(npts) + 0.5) ) t1 = 1 21 while((abs(t‚àít1) ) >= eps): p1 = 1. ; p2 = 0. forjin range (1, npts + 1): p3 = p2; p2 = p1 25 p1 = ((2. ‚àófloat(j)‚àí1)‚àót‚àóp2‚àí(float(j)‚àí1.)‚àóp3)/(float(j)) pp = npts ‚àó(t‚àóp1‚àíp2)/(t ‚àót‚àí1.) t1 = t; t = t1 ‚àíp1/pp x[i‚àí1] =‚àít; x[npts ‚àíi] = t 29 w[i‚àí1] = 2./( (1. ‚àít‚àót)‚àópp‚àópp) w[npts ‚àíi] =w[i ‚àí1] if(job = = 0): foriin range (0, npts): 33 x[i] = x[i] ‚àó(b‚àía)/2. + (b + a)/2. w[i] =w[i] ‚àó(b‚àía)/2. if(job = = 1): foriin range (0, npts): 37 xi = x[i] x[i] = a ‚àób‚àó(1. + xi) / (b + a ‚àí(b‚àía)‚àóxi) w[i] =w[i] ‚àó2.‚àóa‚àób‚àób/( (b + a ‚àí(b‚àía)‚àóxi)‚àó(b + a ‚àí(b‚àía)‚àóxi)) if(job = = 2): 41 foriin range (0, npts): xi = x[i] x[i] = (b ‚àóx i+ b+a+a )/( 1 . ‚àíxi) w[i] =w[i] ‚àó2.‚àó(a + b)/( (1. ‚àíxi)‚àó(1.‚àíxi) ) 45defgaussint (no, min,max): quadra = 0. 5.9 Code Listings 99 gauss (no, 0, min,max,x ,w ) # Returns pts &wts fornin range (0, no): 49 quadra += f(x[n]) ‚àów[n] # Calculate integral return(quadra) foriin range (3,max\_in + 1, 2): result = gaussint(i, vmin, vmax) 53print(\""i\"",i , \"" err \"",abs(result ‚àí1+1 / M E ) ) print(\""Enter and return any character to quit\"" ) Listing 5.3 vonNeuman.py PerformsaMonteCarlointegrationviastonethrowing. # vonNeuman : Monte ‚àíCarlo integration via stone throwing importrandom 4fromvisual.graph import ‚àó N = 100 # points to plot the function graph = display(width=500,height=500,title= ‚ÄôvonNeumann Rejection Int‚Äô ) 8xsinx = curve(x= list(range(0,N)), color=color.yellow, radius=0.5) pts = label(pos=( ‚àí60,‚àí60), text= ‚Äôpoints=‚Äô ,b o x = 0 ) # Labels pts2 = label(pos=( ‚àí30,‚àí60), box=0) inside = label(pos=(30, ‚àí60), text= ‚Äôaccepted=‚Äô ,b o x = 0 ) 12inside2 = label(pos=(60, ‚àí60), box=0) arealbl = label(pos=( ‚àí65,60), text= ‚Äôarea=‚Äô,b o x = 0 ) arealbl2 = label(pos=( ‚àí35,60), box=0) areanal = label(pos=(30,60), text= ‚Äôanalytical=‚Äô ,b o x = 0 ) 16zero = label(pos=( ‚àí85,‚àí48), text= ‚Äô0‚Äô,b o x = 0 ) five = label(pos=( ‚àí85,50), text= ‚Äô5‚Äô,b o x = 0 ) twopi = label(pos=(90, ‚àí48), text= ‚Äô2pi‚Äô,box=0) 20deffx (x): returnx‚àósin(x) ‚àósin(x) # Integrand defplotfunc(): # Plot function incr = 2.0 ‚àópi/N 24foriin range (0,N): xx = i ‚àóincr xsinx.x[i] = ((80.0/pi) ‚àóxx‚àí80) xsinx.y[i] = 20 ‚àófx(xx)‚àí50 28box = curve(pos=[( ‚àí80,‚àí50), (‚àí80,50), (80,50), (80,‚àí50), (‚àí80,‚àí50)], color=color.white) #b o x plotfunc() #B o xa r e a=hxw= 5 ‚àó2pi 32j= 0 Npts = 3001 # Pts inside box analyt = (pi) ‚àó‚àó2 # Analytical integral areanal.text = ‚Äôanalytical= percent8.5f‚Äô  percentanalyt 36genpts = points(size=2) foriin range (1,Npts): # points inside box rate(500) # slow process x=2 . 0 ‚àópi‚àórandom.random() 40y=5 ‚àórandom.random() xp = x ‚àó80.0/pi ‚àí80 yp = 20.0 ‚àóy‚àí50 pts2.text = ‚Äô percent4s‚Äô percenti 44ify‚àó<‚àó=f x ( x ) : # Below curve j+ =1 genpts.append(pos=(xp,yp), color=color.cyan) inside2.text= ‚Äô percent4s‚Äô percentj 48else: genpts.append(pos=(xp,yp), color=color.green) boxarea = 2.0 ‚àópi‚àó5.0 area = boxarea ‚àój/(Npts ‚àí1) arealbl2.text = ‚Äô percent8.5f‚Äô percentarea",8290
Chapter 6 TrialandError Searching and Data Fitting. 6.2.1 Bisection Exercises,"100 6 Trial-and-Error Searching and Data Fitting This chapter adds some more tools to our computational toolbox. First, we examine ways to solve equations via a trial-and-error search. In Chapter 8we will combine trial-and-error searching with the solution of ordinary differential equations to solve the general quantum eigenvalue problem. The second half of this chapter examines the Ô¨Åtting of curves to data. There we examine interpolating within a table of numbers, and least-squares Ô¨Åtting of a function to data, the latter often requiring a search . 6.1 Quantum Bound States I Manycomputationaltechniquesusewell-definedalgorithmsleadingtodefiniteoutcomes. Incontrast,sometechniquesusetrial-and-erroralgorithmsinwhichinternaldecisionsare madeastowhatstepstofollow,andinwhichanumberofsolutionsmaybetriedbefore oneissettledupon,ornot.(Wealreadydidsomeofthiswhenwesummedapowerseries untilthetermsbecamesmall.)Writingthistypeofprogramisusuallychallengingbecause wemustforeseeanumberofpossibleoutcomes,withthechanceoffailurealwayspresent. Probablythemoststandardprobleminquantummechanics,1istosolvefortheenergies ofaparticleofmass mboundwithina1Dsquarewellofradius a: V(x)={ ‚àíV0,for|x|‚â§a, 0,for|x|‚â•a.(6.1) Asshowninquantummechanicstexts[GottfriedandYan,2004],theenergiesofthebound statesE=‚àíEB<0withinthiswellaresolutionsofthetranscendentalequations ‚àö 10‚àíEBtan(‚àö 10‚àíEB) =‚àö EB(even), (6.2) ‚àö 10‚àíEBcotan(‚àö 10‚àíEB) =‚àö EB(odd), (6.3) whereevenandoddrefertothesymmetryofthewavefunction.Herewehavechosenunits suchthat ‚Ñè=1,2m=1,a=1,andV0=10. 1 WesolvethissameprobleminSection13.1usinganapproachthatisapplicabletoalmostanypotential, andwhichalsoprovidesthewavefunctions.Theapproachhereisspecializedtotheeigenenergiesofa squarewell. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 6.2 Bisection Search 101 Your problemisto 1) Findseveralbound-stateenergies EBforevenwavefunctions(6.2). 2) Explorehowmakingthepotentialdeeper,say,bychangingthe10toa20ora30,affects thenumberofboundstatesandtheirenergies. 6.2 Bisection Search Trial-and-errorrootfindinglooksforavalueof xforwhich f(x)‚âÉ0, (6.4) wherewefollowtheconventionofmovingwhatmight,otherwise,beontheright-hand- side(RHS)ofanequationtotheleft-handside(LHS)inordertoleavejusta0ontheRHS. Thesearchprocedurestartswithaguessedvaluefor x,substitutesthatguessinto f(x)(the ‚Äútrial‚Äù),andthenseeshowdifferenttheLHSisfromzero(the‚Äúerror‚Äù).Thealgorithmthen changesxbasedontheerror,andtriesoutthenewguessin f(x).Theprocedurecontinues untilf(x)‚âÉ0tosomedesiredlevelofprecision,oruntilthechangesin xareinsignificant, orwhenthesearchseemsendless. Themostelementarytrial-and-errortechniqueisthe bisectionalgorithm .Itisreliablebut slow.Ifyouknowsomeintervalinwhich f(x)changessign,thenthebisectionalgorithm will always converge to the root by finding progressively smaller and smaller intervals within which the zero lies. Other techniques, such as the Newton‚ÄìRaphson method we describenext,mayconvergemorequickly,butiftheinitialguessdoesnotgetyoucloseto thezero,itmaybecomeunstableandmoveoffintothewilderness. ThebasisofthebisectionalgorithmisshowninFigure6.1.Westartwithtwovaluesof x,x‚àí,andx+,betweenwhichweknowazerooccurs.(Youcandeterminethesebymaking a graph or by stepping through different xvalues and looking for a sign change.) To be specific,letussaythat f(x)isnegativeat x‚àíandpositiveat x+: f(x‚àí)<0,f(x+)>0. (6.5) (Note that it may well be that x‚àí>x+if the function changes from positive to negative asxincreases.)Thuswestartwiththeinterval x+‚â§x‚â§x‚àí,withinwhichweknowazero occurs.Asyoucanseein Bisection.py inListing6.1,thealgorithmthenpicksanew xvalue Figure 6.1 A graphical representation of the steps involved in solving for a zero of f(x) using the bisection algorithm. The bisection algorithm takes the midpoint of the interval as the new guess for x,w i t he a c hs t e pr e d u c i n g the interval size by one-half. Four steps are shown here. xx+1 x‚Äì1x+4 x‚Äì2 x‚Äì3 +0‚Äìf(x)",4010
6.3 NewtonRaphson Search,"102 6 Trial-and-Error Searching and Data Fitting equaltothemidpointoftheinterval,andthensetsanewintervalasthehalfoftheprevious intervalinwhichthesignchanged: x=(p l u s+m i n u s)/2 2if( f(x) f(plus) > 0 ) plus = x elseminus = x Thisprocesscontinuesuntilthevalueof f(x)islessthanapredefinedlevelofprecision,or untilapredefined(large)numberofsubdivisionsoccurs. TheexampleinFigure6.1showsthefirstintervalextendingfrom x‚àí=x+1tox+=x‚àí1. Wethenbisectthatintervalat x,andbecause f(x)<0atthemidpoint,weset x‚àí=x‚àí2=x andlabelit x‚àí2toindicatethesecondstep.Wethenuse x+2=x+1andx‚àí2asthenextinter- valandcontinuetheprocess.Weseethatonly x‚àíchangesforthefirstthreestepsinthis example,butthatforthefourthstep x+finallychanges.Thechangesthenbecometoosmall forustoshow. 6.2.1 Bisection Exercises 1) The first step in implementing any search algorithm is to get an idea of what your functionlookslike.Forthepresentproblemyoudothisbymakingaplotoratableof f(E)=‚àö 10‚àíEBtan(‚àö 10‚àíEB)‚àí‚àö EBversus EB. Note from your plot some approxi- matevaluesatwhich f(EB)=0.Yourprogramshouldbeabletofindmoreexactvalues forthesezeros. 2) Write a program that implements the bisection algorithm and uses it to find some solutionsof(6.2). 3)Warning:Seeingthatthetanfunctionhassingularities,somecareissuggested.Infact, yourgraphicsprogrammaynotfunctionaccuratelynearthesesingularities.Onecureis touseadifferent,butequivalent,formoftheequation.Showthatanequivalentformof (6.2)is ‚àö Ecot(‚àö 10‚àíE)‚àí‚àö 10‚àíE=0. (6.6) 4) Makeasecondplotof(6.6),whichalsohassingularitiesbutatdifferentplaces.Usethis plottochoosesome xvaluesthatbracketthezeros. 5) Afteryouhavefoundasolution,evaluate f(EB)andthusdeterminetheprecisionofyour solution. 6) ComparetherootsyoufindwiththosegivenbyMapleorMathematica. 6.3 Newton‚ÄìRaphson Search The Newton‚ÄìRaphson algorithm can find roots of the f(x)=0m o r eq u i c k l yt h a nt h e bisection method. As we see graphically in Figure 6.2, this algorithm is the equiva- lent of drawing a straight line f(x)‚âÉmx+btangent to the curve at an xvalue for whichf(x)‚âÉ0, and then using the intercept of the line with the x-axis atx=‚àíb‚àïm as an improved guess for the root. If the ‚Äúcurve‚Äù were actually a straight line, the answer would be exact; otherwise, it is a good approximation if the guess is close 6.3 Newton‚ÄìRaphson Search 103 Figure 6.2 A graphical representation of the steps involved in solving for a zero of f(x) using the Newton‚ÄìRaphson method. The Newton‚ÄìRaphson method takes the new guess as the zero of the line tangent to f(x) at the old guess. Two guesses are shown. 32 xf(x)1 enough to the root for f(x)to be nearly linear. The process continues until some set level of precision is reached or until too many guesses fail to find a root. If a g u e s si si nar e g i o nw h e r e f(x)is nearly linear (Figure 6.2), then the convergence is veryrapid. TheanalyticformulationoftheNewton‚ÄìRaphsonalgorithmstartswithanoldguess x0, andexpressesanewguess xastheoldguessplusacorrection Œîx: x0=oldguess ,Œîx=unknowncorrection (6.7) ‚áíx=x0+Œîx. (6.8) Wenext expandthe knownfunction f(x)in aTaylorseries around x0, andkeep onlythe lineartermintheexpansion: f(x=x0+Œîx)‚âÉf(x0)+df dx|||x0Œîx. (6.9) Wedeterminethecorrection Œîxbycalculatingthepointatwhichthislinearapproximation tof(x)crossesthe x-axis: f(x0)+df dx|||x0Œîx=0, (6.10) ‚áíŒîx=‚àíf(x0) df‚àïdx|x0. (6.11) Theprocedureisrepeated,startingattheimproved x,untilsomesetlevelofprecisionis obtained. The Newton‚ÄìRaphson algorithm (6.11) requires evaluation of the derivative df‚àïdxat each value of x0. In many cases, you may have an analytic expression for the derivative and can build it into the algorithm. However, especially for more complicated problems, it is simple enough to just use a numerical forward-difference approximation to the derivative: df dx‚âÉf(x+ùõøx)‚àíf(x) ùõøx, (6.12) whereùõøxissomesmallchangein xthatyouchose[differentfromthe Œîusedforsearchingin (6.11)].Whileacentral-differenceapproximationforthederivativewouldbemoreaccurate, itwouldrequireadditionalevaluationofthe f‚Äôs,andonceyoufindazero,itdoesnotmatter howyougotthere.InListing6.2,wegiveaprogram NewtonCD.py thatimplementsthesearch withthecentraldifferencederivative.",4148
6.4 Magnetization Search,"104 6 Trial-and-Error Searching and Data Fitting 2 2413 Xf(X) f(X) 1 X Figure 6.3 Two examples of how the Newton‚ÄìRaphson algorithm may fail if the initial guess is not in the region where f(x) can be approximated by a straight line. Left: A guess lands at a local extremum (minimum/maximum), that is, a place where the derivative vanishes, and so the next guess ends up at x=‚àû.Right: The search has fallen into an inÔ¨Ånite loop. The technique known as ‚Äúbacktracking‚Äù could eliminate this problem. 6.3.1 Search +Backtracking Two examples of possible problems with the Newton‚ÄìRaphson algorithm are shown in Figure 6.3. On the left, we see a case where the search takes us to an xvalue where the functionhasalocalextremum(minimumormaximum),thatis,where df‚àïdx=0.Because Œîx=‚àíf‚àï(df‚àïdx), this leads to a horizontal tangent (division by zero), and so the next guessisx=‚àû,fromwhereitishardtoreturn.Whenthishappens,youneedtostartyour search with a different guess, and pray that you do not fall into this trap again. In cases wherethecorrectionisverylarge,butmaybenotinfinite,youmaywanttotrybacktrack- ing(describedbelow),andhopethatbytakingasmallerstepyouwillnotgetintoasmuch trouble. InFigure6.3rightweseeacasewhereasearchfallsintoaninfiniteloopsurroundingthe zero,withoutevergettingthere.Asolutiontothisproblemis backtracking .Asthename implies, in cases where the new guess x0+Œîxleads to an increase in the magnitude of thefunction, |f(x0+Œîx)|2>|f(x0)|2,youcanbacktracksomewhatandtryasmallerguess, say,x0+Œîx‚àï2.Ifthemagnitudeof fstillincreases,thenyoujustneedtobacktracksome more,say,bytrying x0+Œîx‚àï4asyournextguess,andsoforth.Becauseyouknowthatthe tangent line leads to a local decrease in |f|, eventually an acceptable small enough step shouldbefound. The problem in both these cases is that the initial guesses were not close enough to the regions where f(x)is approximately linear. So again, a good plot or table may help produceagoodfirstguess.Alternatively,youmaywanttostartyoursearchwiththebisec- tion algorithm, and then switch to the faster Newton‚ÄìRaphson algorithm when you get closertothezero. Exercise 1) UsetheNewton‚ÄìRaphsonalgorithmtofindsomeenergies EBthataresolutionsof(6.2). Comparethissolutionwiththeonefoundwiththebisectionalgorithm. 2) Again,noticethatthe10inthisequationisproportionaltothestrengthofthepotential thatcausesthebinding.Seeifmakingthepotentialdeeper,say,bychangingthe10to a20ora30,producesmoreordeeperboundstates.(Notethatincontrasttothebisec- tionalgorithm,yourinitialguessmustbeclosertotheanswerfortheNewton‚ÄìRaphson algorithmtowork.) 6.4 Magnetization Search 105 3) Modify your algorithm to include backtracking and then try it out on some difficult cases. 4) Evaluate f(EB)andthusdeterminedirectlytheprecisionofyoursolution. 6.4 Magnetization Search Problem Determine M(T)the magnetization as a function of temperature for simple magneticmaterials. A collection of Nspin-1/2 particles each with magnetic moment ùúáis at temperature T. Thecollectionhasanexternalmagneticfield Bappliedtoit,andcomestoequilibriumwith NLparticlesinthelowerenergystate(spinsalignedwiththemagneticfield),andwith NU particlesintheupperenergystate(spinsopposedtothemagneticfield).TheBoltzmann distribution law tells us that the relative probability of a state with energy Eis propor- tionaltoexp (‚àíE‚àï(kBT)),wher ekBisBoltzmann‚Äôsconstant.Foradipolewithmoment ùúá, itsenergyinamagneticfieldisgivenbythedotproduct E=‚àíùúá‚ãÖB.Accordingly,spin-up particlehavelowerenergyinamagneticfieldthanspin-downparticles,andthusaremore probable. ApplyingtheBoltzmanndistributiontoourspinproblem,wehavethatthenumberof particlesinthelowerenergylevel(spinup)is NL=NeùúáB‚àï(kBT) eùúáB‚àï(kBT)+e‚àíùúáB‚àï(kBT), (6.13) whilethenumberofparticlesintheupperenergylevel(spindown)is NU=Ne‚àíùúáB‚àï(kBT) eùúáB‚àï(kBT)+e‚àíùúáB‚àï(kBT). (6.14) Asdiscussedin[Kittel,2018],wenowassumethatthemolecularmagneticfield B=ùúÜMis muchlargerthantheappliedmagneticfield,andsoreplace Bbythemolecularfield.This permitsustoeliminate Bfromtheprecedingequations.The magnetizationM (T)isgiven by the individual magnetic moment ùúátimes the net number of particles pointing in the directionofthemagneticfield: M(T)=ùúá√ó(NL‚àíNU) (6.15) =Nùúátanh(ùúÜùúáM(T) kBT) . (6.16) Notethatthisdefinitionappearstomakesensebecauseasthetemperatureapproacheszero, allspinswillbealignedalongthedirectionof B,andsoM(T=0)=Nùúá. M(T)via Searching Equation (6.16) relates the magnetization and the temperature. However,itisnotreallyasolutiontoourproblembecause MappearsontheLHSofthe equationaswellaswithinthehyperbolicfunctionontheRHS.Generally,a transcenden- talequation ofthissortdoesnothaveananalyticsolutionthatwouldgive Masafunction ofthetemperature T.Butbysortofworkingbackwardwecanfindanumericalsolution. To do that, we first express (6.16) in terms of the reduced magnetization m, the reduced 106 6 Trial-and-Error Searching and Data Fitting temperature t,andtheCurietemperature Tc: m(t)=tanh( m(t) t) , (6.17) m(T)=M(T) Nùúá,t=T Tc,Tc=Nùúá2ùúÜ kB. (6.18) Whileitisnoeasiertofindananalyticsolutionto(6.17)thanitwasto(6.16),thesimpler formof(6.17)makestheprogrammingeasier. Oneapproachtoatrial-and-errorsolutionistodefineafunction f(m,t)=m‚àítanh( m(t) t) , (6.19) andthen,foravarietyoffixed t=tivalues,searchforthose mvaluesatwhich f(m,ti)=0. (One could just as well fix the value of mtomjand search for the value of tfor which f(mj,t)=0;onceyouhaveasolution,youhaveasolution.)Eachzerosofoundprovidesa singlevalueof m(ti).Aplotoratableofthesevaluesforarangeof tivaluesthenprovides thebestwecandoforthedesiredsolution m(t). Figure6.4showsthreeplotsof f(m,t)asafunctionofthereducedmagnetization m,each plotforadifferentvalueofthereducedtemperature.Asyoucansee,otherthantheunin- terestingsolutionat m=0,thereisonlyonesolution(azero)andit‚Äôsnear m=1fort=0.5. Thereisnosolutionattheothertemperatures. 1) Findtherootof(6.19)tosixsignificantfiguresfor t=0.5usingthebisectionalgorithm. 2) Findtherootof(6.19)tosixsignificantfiguresfor t=0.5usingtheNewton‚ÄìRaphson algorithm. 3) ComparethetimeittakestofindthesolutionsforthebisectionandNewton‚ÄìRaphson algorithms. m0‚Äì1‚Äì0.8‚Äì0.6‚Äì0.4‚Äì0.200.20.4 0.5 1 1.5 2 2.5t = 0.5 t = 1 t = 2tanh( m/t) ‚Äì m Figure 6.4 A function of the reduced magnetism mat three reduced temperatures t.Az e r oo ft h i s function determines the value of the magnetism at a particular value of t.",6288
6.5 Data Fitting,"6.5 Data Fitting 107 4) Construct a plot of the reduced magnetization m(t)as a function of the reduced temperature t. 6.5 Data Fitting Data fitting is an art worthy of serious study by all scientists [Bevington and Robinson, 2003].Inthesectionstofollowwejustscratchthesurfacebyexamininghowtointerpolate withinatableofnumbersandhowtodoaleast-squaresfittodata.Wealsoshowhowtogo aboutmakingaleast-squaresfittononlinearfunctionsusingsomeofthesearchtechniques andsubroutinelibraries. Problem The cross sections measured for the resonant scattering of neutrons from a nucleusaregiveninTable6.1.Yourproblemistodeterminevaluesforthecrosssectionsat energyvalueslyingbetweenthoseinthetable. Youcansolvethisprobleminanumberofways.Thesimplestistonumerically interpolate between the values of the experimental f(Ei)given in Table 6.1. This is direct and easy, butdoesnotaccountfortherebeingexperimentalnoiseinthedata.Amoreappropriate solution(discussedinSection6.7)istofindthe bestfitofatheoreticalfunctiontothedata. Westartwithwhatwebelievetobethe‚Äúcorrect‚Äùtheoreticaldescriptionofthedata, f(E)=fr (E‚àíEr)2+Œì2‚àï4, (6.20) wherefr,Er,andŒìareunknownparameters.Wethenadjusttheparameterstoobtainthe bestfit.Thisisabestfitinastatisticalsense,butinfactmaynotpassthroughall(orany) of the data points. For an easy, yet effective, introduction to statistical data analysis, we recommendBevingtonandRobinson[2003]. These two techniques of interpolation and least-squares fitting are powerful tools that let you treat tables of numbers as if they were analytic functions, and sometimes let you deducestatisticallymeaningfulconstantsorconclusionsfrommeasurements.Ingeneral, youcanviewdatafittingas globalorlocal.Inglobalfits,asinglefunctionof xisusedto representtheentiresetofnumbersinatablesuchasTable6.1.Whileitmaybespiritually satisfyingtofindasinglefunctionthatpassesthroughallthedatapoints,ifthatfunction isnotthecorrectfunctionfordescribingthedata,thefitmayshownonphysicalbehavior (suchaslargeoscillations)betweenthedatapoints.Theruleofthumbisthatifyoumust interpolate,keepitlocalandviewglobalinterpolationswithacriticaleye. Table 6.1 Experimental values for a scattering cross section ( f(E)in the theory), each with absolute error ¬±ùúéi, as a function of energy ( xiin the theory). i 1 2345 67 8 9 Ei(MeV) 0 25 50 75 100 125 150 175 200 g(Ei)(MB) 10.6 16.0 45.0 83.5 52.8 19.9 10.8 8.25 4.7 Error(MB) 9.34 17.9 41.5 85.5 51.5 21.5 10.8 6.29 4.14 108 6 Trial-and-Error Searching and Data Fitting ConsiderTable6.1asordereddata.Wecalltheindependentvariable xanditstabulated valuesxi(i=1,2,‚Ä¶), and assume that the dependent variable is the function g(x), with tabulatedvalues gi=g(xi).Weassumethat g(x)canbeapproximatedasan (n‚àí1)th-degree polynomialineachinterval i: gi(x)‚âÉa0+a1x+a2x2+¬∑¬∑¬∑+an‚àí1xn‚àí1. (6.21) Seeingthatourfitislocal,wedonotassumethatone g(x)canfitallthedatainthetable, butinsteaduseadifferentpolynomial,thatis,adifferentsetof aivalues,foreachinterval. Eachpolynomialwillbeoflowdegree,andmultiplepolynomialswillbeneededtospan theentiretable.Ifsomecareistaken,thesetofpolynomialssoobtainedwillbehavewell enough to be used in further calculations without introducing much unwanted noise or discontinuitiesin g(x)oritsderivatives. TheclassicinterpolationformulawascreatedbyLagrange.Hefiguredoutaclosed-form expressionthatdirectlyfitsthe( n‚àí1)orderpolynomial(6.21)to nvaluesofthefunction g(x)evaluatedatthepoints xi.Theformulaforeachintervaliswrittenasthesumofpoly- nomials: g(x)‚âÉg1ùúÜ1(x)+g2ùúÜ2(x)+¬∑¬∑¬∑+gnùúÜn(x), (6.22) ùúÜi(x)=n‚àè j(‚â†i)=1x‚àíxj xi‚àíxj=x‚àíx1 xi‚àíx1x‚àíx2 xi‚àíx2¬∑¬∑¬∑x‚àíxn xi‚àíxn. (6.23) Forthreepoints,(6.22)providesasecond-degreepolynomial,whileforeightpointsitgives aseventh-degreepolynomial.Forexample,assume wearegiventhepointsandfunction values x1‚àí4=(0,1,2,4)g1‚àí4=( ‚àí12,‚àí12,‚àí24,‚àí60). (6.24) With four points, the Lagrange formula determines a third-order polynomial that repro- duceseachofthetabulatedvalues: g(x)=(x‚àí1)(x‚àí2)(x‚àí4) (0‚àí1)(0‚àí2)(0‚àí4)(‚àí12)+x(x‚àí2)(x‚àí4) (1‚àí0)(1‚àí2)(1‚àí4)(‚àí12) +x(x‚àí1)(x‚àí4) (2‚àí0)(2‚àí1)(2‚àí4)(‚àí24)+x(x‚àí1)(x‚àí2) (4‚àí0)(4‚àí1)(4‚àí2)(‚àí60), ‚áíg(x)=x3‚àí9x2+8x‚àí12. (6.25) Asacheckweseethat g(4)=43‚àí9(42)+32‚àí12=‚àí60,g(0.5)=‚àí10.125. (6.26) Ifthedatacontainlittlenoise,thispolynomialcanbeusedwithsomeconfidencewithin therangeofthedata,butwithriskbeyondtherangeofthedata. Notice that Lagrange interpolation makes no restriction that the points xibe evenly spaced.Usually,theLagrangefitismadetoonlyasmallregionofthetablewithasmall value ofn,despitethefactthattheformulaworksperfectlywellforfittingahigh-degree polynomial to the entire table. The difference between the value of the polynomial evaluatedatsome xandthatoftheactualfunctioncanbeshowntobethe remainder Rn‚âÉ(x‚àíx1)(x‚àíx2)¬∑¬∑¬∑(x‚àíxn) n.g(n)(ùúÅ), (6.27)",4693
6.5.1 Lagrange Fitting. 6.5.2 Cubic Spline Interpolation,"6.5 Data Fitting 109 whereùúÅliessomewhereintheinterpolationinterval.Whatissignificanthereisthatwesee thatifsignificanthighderivativesexistin g(x),thentheremaindercanbeverylarge.For example,atableofnoisydatawouldhavesignificantlyhighderivatives. 6.5.1 Lagrange Fitting Consider the experimental neutron scattering data in Table 6.1. The expected theoretical functionalformthatdescribesthesedatais(6.20),andourempiricalfitstothesedataare showninFigure6.5. 1) Writeasubroutinetoperforman n-pointLagrangeinterpolationusing(6.22).Treat nas anarbitraryinputparameter.(Youmayalsodothisexercisewiththesplinefitsdiscussed inSection6.5.2.) 2) Use the Lagrange interpolation formula to fit the entire experimental spectrum with onepolynomial.(Thismeansthatyoumustfitallninedatapointswithan8thdegree polynomial.)Thenusethisfittoplotthecrosssectioninstepsof5MeV. 3) Useyourgraphtodeducetheresonanceenergy Er(yourpeakposition)and Œì(thefull widthathalf-maximum).Compareyourresultswiththosepredictedbyatheoristfriend, (Er,Œì) = (78,55)MeV. 4) AmorerealisticuseofLagrangeinterpolationisforlocalinterpolationwithasmallnum- berofpoints,suchasthree.Interpolatetheprecedingcross-sectionaldatain5-MeVsteps usingthree-pointLagrangeinterpolationforeachinterval.(Notethattheendintervals maybespecialcases.) 5) Wedeliberatelyhavenotdiscussed extrapolation ofdatabecauseitcanleadtoserious systematicerrors;theansweryougetmaywelldependmoreonthefunctionyouassume thanonthedatayouinput.Addsomeadventuretoyourlifeandusetheprogramsyou havewrittentoextrapolatetovaluesoutsideTable6.1.Compareyourresultstothethe- oreticalBreit‚ÄìWignershape(6.20). Thisexampleshowshoweasyitistogowrongwithahigh-degree-polynomialfittodata witherrors.Althoughthepolynomialisguaranteedtopassthroughallthedatapoints,the representationofthefunctionawayfromthesepointscanbequiteunrealistic.Usingalow- order interpolation formula, say, n=2 or 3, in each interval usually eliminates the wild oscillations,butmaynothaveanytheoreticaljustification.Iftheselocalfitsarematched togethercarefully,aswediscussinthefollowingsectiononcubicsplineinterpolation,then a rather continuous curve results. Nonetheless, you must recall that if the data contain errors,acurvethatactuallypassesthroughthemmayleadyouastray.Wediscusshowto dothisproperlywithleast-squarefittinginSection6.7. 6.5.2 Cubic Spline Interpolation If you have followed our suggestions and tried to interpolate the resonant cross section withLagrangeinterpolation,thenyousawthatfittingparabolas(three-pointinterpolation) withinatablemayavoidtheerroneousandpossiblycatastrophicdeviationsofahigh-order formula.(Atwo-pointinterpolation,whichconnectsthepointswithstraightlines,maynot leadyoufarastray,butitisrarelypleasingtotheeyeorprecise.)Asophisticatedvariation 110 6 Trial-and-Error Searching and Data Fitting 0 50 100 150 200 E (MeV)020406080 Cross sectionData Lagrange Cubic splines Parabola (lst sq) Figure 6.5 Three Ô¨Åts to data. Dashed : Lagrange interpolation using an 8th degree polynomial; Short dashes : cubic splines Ô¨Åt; Long dashed : Least-squares parabola Ô¨Åt. of ann=4 interpolation,known as cubicsplines , often leads to surprisingly smooth and eye-pleasing fits. In this approach (Figure 6.5), cubic polynomials are fit to the function ineachinterval,withtheadditionalconstraintthatthefirstandsecondderivativesofthe cubicsbecontinuousfromoneintervaltothenext.Thiscontinuityofslopeandcurvature makesthesplinefitparticularlyeye-pleasing.Theanalyticapproachisanalogoustousing aflexiblesplinedraftingtool(aleadwirewithinarubbersheath),fromwhichthemethod drawsitsname. Theseriesofcubicpolynomialsobtainedbyspline-fittingatableofdatacanbeintegrated and differentiated, and is guaranteed to have well-behaved derivatives. The existence of meaningfulderivativesisanimportantconsideration.Asacaseinpoint,iftheinterpolated functionisapotential,youcantakethederivativetoobtaintheforce.Thecomplexityof simultaneouslymatchingpolynomialsandtheirderivativesoveralltheinterpolationpoints leadstomanysimultaneouslinearequationstobesolved.Thismakessplinesunattractive forhandcalculations,yeteasyforcomputersand,notsurprisingly,popularinbothcalcu- lationsandcomputerdrawingprograms.Toillustrate,thesmoothsolidcurveinFigure6.5 isasplinefit. Thebasicapproximationofsplinesistherepresentationofthefunction g(x)inthesubin- terval[xi,xi+1]withacubicpolynomial: g(x)‚âÉgi(x),forxi‚â§x‚â§xi+1, (6.28) gi(x)=gi+g‚Ä≤ i(x‚àíxi)+1 2g‚Ä≤‚Ä≤ i(x‚àíxi)2+1 6g‚Ä≤‚Ä≤‚Ä≤ i(x‚àíxi)3. (6.29) Thisrepresentationmakesitclearthatthecoefficientsinthepolynomialequalthevaluesof g(x)anditsfirst,second,andthirdderivativesatthetabulatedpoints xi.Derivativesbeyond thethirdvanishforacubic.Thecomputationalchoreistodeterminethesederivativesin termsofthe Ntabulatedgivalues.Thematchingof giatthenodesthatconnectoneinterval",4753
6.7.1 LeastSquares Implementation,"6.5 Data Fitting 111 tothenextprovidestheequations gi(xi+1)=gi+1(xi+1),i=1,N‚àí1. (6.30) Thematchingofthefirst andsecondderivativesateachinterval‚Äôsboundariesprovidesthe equations g‚Ä≤ i‚àí1(xi)=g‚Ä≤ i(xi),g‚Ä≤‚Ä≤ i‚àí1(xi)=g‚Ä≤‚Ä≤ i(xi). (6.31) Theadditionalequationsneededtodetermineallconstantsareobtainedbymatchingthe thirdderivativesatadjacentnodes.Valuesforthethirdderivativesarefoundbyapproxi- matingthemintermsofthesecondderivatives: g‚Ä≤‚Ä≤‚Ä≤ i‚âÉg‚Ä≤‚Ä≤ i+1‚àíg‚Ä≤‚Ä≤ i xi+1‚àíxi. (6.32) AsdiscussedinChapter5,acentral-differenceapproximationwouldbemoreaccuratethan aforward-differenceapproximation,yet(6.32)keepstheequationssimpler. It is straightforward, although complicated, to solve for all the parameters in (6.29). We leave that to the references Thompson [1992] and Press et al. [2007]. We can see, however, that matching at the boundaries of the intervals results in only (N‚àí2) linear equations for Nunknowns. Further input is required. It usually is taken to be the boundary conditions at the endpoints a=x1andb=xN, specifically, the sec- ond derivatives there g‚Ä≤‚Ä≤(a)andg‚Ä≤‚Ä≤(b). There are several ways to determine these second derivatives: Natural spline :Setg‚Ä≤‚Ä≤(a)=g‚Ä≤‚Ä≤(b)=0;thatis,permitthefunctiontohaveaslopeattheend- pointsbutnocurvature.Thisis‚Äúnatural‚Äùbecausethederivativevanishesfortheflexible splinedraftingtool(itsendsbeingunconstrained). Input values for g‚Ä≤at the boundaries :Thecomputeruses g‚Ä≤(a)toapproximate g‚Ä≤‚Ä≤(a).If youdonotknowthefirstderivatives,youcancalculatethemnumericallyfromthetable ofgivalues. Input values for g‚Ä≤‚Ä≤at the boundaries :Knowingvaluesisofcoursebetterthanapprox- imatingthem, but it requires the user to input information.If the values of g‚Ä≤‚Ä≤are not known, they can be approximated by applying a forward-difference approximation to thetabulatedvalues: g‚Ä≤‚Ä≤(x)‚âÉ[g(x3)‚àíg(x2)]‚àï[x3‚àíx2]‚àí[g(x2)‚àíg(x1)]‚àï[x2‚àíx1] [x3‚àíx1]‚àï2. (6.33) 6.5.3 Cubic Spline Quadrature A powerfulintegrationscheme is to fit an integrand with splines, and then integratethe cubicpolynomialsanalytically.Iftheintegrand g(x)isknownonlyatitstabulatedvalues, then this is about as good an integration scheme as is possible; if you have the ability to calculate the function directly for arbitrary xvalues, then Gaussian quadrature may be preferable.Weknowthatthesplinefitto gineachintervalisthecubic(6.29) g(x)‚âÉgi+g‚Ä≤ i(x‚àíxi)+1 2g‚Ä≤‚Ä≤ i(x‚àíxi)2+1 6g‚Ä≤‚Ä≤‚Ä≤ i(x‚àíxi)3. (6.34) 112 6 Trial-and-Error Searching and Data Fitting Itiseasytointegratethistoobtaintheintegralof gforthisintervalandthentosumover allintervals: ‚à´xi+1 xig(x)dx‚âÉ( gix+1 2g‚Ä≤ ix2+1 6g‚Ä≤‚Ä≤ ix3+1 24g‚Ä≤‚Ä≤‚Ä≤ ix4)||||xi+1 xi, (6.35) ‚à´xk xjg(x)dx=k‚àë i=j( gix+1 2g‚Ä≤ ix2 i+1 6g‚Ä≤‚Ä≤ ix3+1 24g‚Ä≤‚Ä≤‚Ä≤ ix4)||||xi+1 xi. (6.36) Makingtheintervalssmallerdoesnotnecessarilyincreaseprecision,assubtractivecancel- lationsin(6.35)maygetlarge. Spline Fit of Cross Section (Implementation) Fitting a series of cubics to data is a littlecomplicatedtoprogramyourself,sowerecommendusingalibraryroutine.Wehave adapted the splint.cand the spline.cfunctions from Press et al. [2007] to produce the SplineInteract.py programshowninListing6.3. Your problemforthissectionistocarryouttheassessmentinSection6.5.1usingcubic splineinterpolationratherthanLagrangeinterpolation.",3167
6.7.1 LeastSquares Implementation,"6.6 Fitting Exponential Decay Figure6.6presentsactualexperimentaldataonthenumberofdecays ŒîNoftheùúãmeson asafunctionoftime[Stetz etal.,1973].Noticethatthetimehasbeen‚Äúbinned‚Äùintointer- valsŒît=10-ns,andthatthesmoothcurveisthetheoreticalexponentialdecayexpectedif therewereaverylargenumbersofpions(whichthere‚Äôsnot).Yourproblemistodeducethe lifetimeùúèoftheùúãmesonfromthesedata(thetabulatedlifetimeis2.6 √ó10‚àí8seconds). Assume that we start with N0particlesat time t=0 that can decay to other particles.2 Ifwewaitashorttime Œît,thenasmallnumber ŒîNoftheparticleswilldecay spontaneously , thatis,withnoexternalinfluences.Thisdecayisastochasticprocess,whichmeansthatan 0 40 80 120 t (ns)02040 NumberN(t) DataFitFigure 6.6 A reproduction of the experimental measurement of Stetz et al. [1973] giving the number of decays of ùúãmesons as a function of time since their creation. Measurements were made during time intervals (box sizes) of 10-inch width. The dashed curve is the result of a linear least-square Ô¨Åt to the log N(t). 2 SpontaneousdecayisdiscussedfurtherandsimulatedinSection4.3. 6.7 Least-Squares Fitting 113 elementofchancehelpsdeterminejustwhenadecaywilloccur,andsonotwoexperiments areexpectedtogiveexactlythesameresults.Thebasiclawofnatureforspontaneousdecay is that the number of decays ŒîNin a time interval Œîtis proportional to the number of particlesN(t)presentatthattimeandtothetimeinterval ŒîN(t)=‚àí1 ùúèN(t)Œît‚áíŒîN(t) Œît=‚àíùúÜN(t). (6.37) Hereùúè=1‚àïùúÜisthelifetimeoftheparticle,with ùúÜarateparameter.Theactualdecay rateis givenbythesecondequationin(6.37).Ifthenumberofdecays ŒîNisverysmallcompared tothenumberofparticles N,andifwelookatvanishinglysmalltimeintervals,thenthe differenceequation(6.37)becomesthedifferentialequation dN(t) dt‚âÉ‚àíùúÜN(t)=1 ùúèN(t). (6.38) This differential equation has an exponential solution for the number as well as for the decayrate: N(t)=N0e‚àít‚àïùúè,dN(t) dt=‚àíN0 ùúèe‚àít‚àïùúè=dN(0) dte‚àít‚àïùúè. (6.39) Equation(6.39)isthetheoreticalformulawewishtofittothedatainFigure6.6.Theoutput ofsuchafitisabest-fitvalueforthelifetime ùúè. 6.7 Least-Squares Fitting Bookshavebeenwrittenandcareershavebeenspentdiscussingwhatismeantbya‚Äúgood fit‚Äùtoexperimentaldata.Wecannotdojusticetothesubjecthereandreferthereaderto Bevington and Robinson [2003], Press et al. [2007], and Thompson [1992]. However, we willemphasizethreepoints: 1) Ifthedatabeingfitcontainerrors,thenthe‚Äúbestfit‚Äùinastatisticalsenseshouldnot passthroughallthedatapoints. 2) Ifthetheoryisnotanappropriateoneforthedata(e.g.,theparabolainFigure6.5),then itsbestfittothedatamaynotbeagoodfitatall.Thisisgood,forthisishowweknow thatthetheoryisnotappropriate. 3) Onlyforthesimplestcaseofalinearleast-squaresfitcanwewritedownaclosed-form solutiontoevaluateandobtainthebestfit.Morerealisticproblemsareusuallysolvedby trial-and-error searchprocedures,sometimesusingsophisticatedsubroutinelibraries. InSection6.8,weshowhowtoconductsuchanonlinearsearchusingfamiliartools. Imaginethatyouhavemeasured NDdatavaluesoftheindependentvariable yasafunction ofthedependentvariable x: (xi,yi¬±ùúéi),i=1,ND, (6.40) where¬±ùúéiistheexperimentaluncertaintyinthe ithvalueof y.(Forsimplicityweassume that all the errors ùúéioccur in the dependent variable, although this is hardly ever true [Thompson,1992]).Forourproblem, yisthenumberofdecaysasafunctionoftime,and xiisthetimes.Ourgoalistodeterminehowwellamathematicalfunction y=g(x)(also calledatheoryoramodel)candescribethesedata.Additionally,ifthetheorycontainssome 114 6 Trial-and-Error Searching and Data Fitting parametersorconstants,ourgoalisalsotodeterminethebestvaluesfortheseparameters. Weassumethatthetheoryfunction g(x)contains,inadditiontothefunctionaldependence onx, an additional dependence upon MPparameters {a1,a2,‚Ä¶,aMP}. Notice that the parameters {am}arenotvariables,inthesenseofnumbersreadfromameter,butrather arepartsofthetheoreticalmodel,suchasthesizeofabox,themassofaparticle,orthe depthofapotentialwell.Fortheexponentialdecayfunction(6.39),theparametersarethe lifetimeùúèandtheinitialdecayratedN dt(0).Weindicatethisas g(x)=g(x;{a1,a2,‚Ä¶,aMP}) =g(x;{am}), (6.41) wheretheai‚Äôsareparametersand xtheindependentvariable.",4104
6.7.1 LeastSquares Implementation,"Weusethechi-square, ùúí2,measureasagaugeofhowwellatheoreticalfunction grepro- ducesdata[BevingtonandRobinson,2003]: ùúí2def=ND‚àë i=1(yi‚àíg(xi;{am}) ùúéi)2 , (6.42) wherethesumisoverthe NDexperimentalpoints (xi,yi¬±ùúéi).Thedefinition(6.42)issuch thatsmallervaluesof ùúí2arebetterfits,with ùúí2=0occurringifthetheoreticalcurvewent through the center of every data point. Notice also that the 1 ‚àïùúé2 iweighting means that measurementswithlargererrorscontributelessto ùúí2.3Least-squaresfitting referstoadjust- ingtheparametersinthetheoryuntilaminimumin ùúí2isfound,thatis,findingacurve that produces the least value for the summed squares of the deviations of the data from thefunction g(x).Ingeneral,thisisthebestfitpossibleandthebestwaytodeterminethe parametersinatheory.The MPparameters {am,m=1,MP}thatmake ùúí2anextremumare foundbysolvingthe MPequations: ùúïùúí2 ùúïam=0,‚áíND‚àë i=1[yi‚àíg(xi)] ùúé2 iùúïg(xi) ùúïam=0,(m=1,MP). (6.43) Often, the function g(x;{am})has a sufficiently complicated dependence on the amval- uesfor(6.43)toproduce MPsimultaneousnonlinearequationsinthe amvalues.Inthese cases,solutionsarefoundbyatrial-and-errorsearchthroughthe MP-dimensionalparam- eterspace,aswedoinSection6.8.Tobesafe,whensuchasearchiscompleted,youshould checkthattheminimum ùúí2youfoundis globalandnotlocal.Onewaytodothatistorepeat thesearchforawholegridofstartingvalues,andifdifferentminimaarefound,topickthe onewiththelowest ùúí2. 6.7.1 Least-Squares Implementation Whenthedeviationsfromtheoryareasaresultofrandomerrors,andwhentheseerrorsare describedbyaGaussiandistribution,therearesomeusefulrulesofthumbtoremember. Youknowthatyourfitisgoodifthevalueof ùúí2calculatedviathedefinition(6.42)isapprox- imatelyequaltothenumberofdegreesoffreedom ùúí2‚âÉND‚àíMP,whereNDisthenumber ofdatapointsand MPisthenumberofparametersinthetheoreticalfunction.Ifyour ùúí2 ismuchlessthan ND‚àíMP,itdoesn‚Äôtmeanthatyouhavea‚Äúgreat‚Äùtheoryorreallyprecise 3 Ifyouarenotgiventheerrors,youcanguessthemonthebasisoftheapparentdeviationofthedatafrom asmoothcurve,oryoucanweighallpointsequallybysetting ùúéi‚â°1andcontinuewiththefitting. 6.7 Least-Squares Fitting 115 measurements;instead,youprobablyhavetoomanyparameters,orhaveassignederrors (ùúéivalues) that are too large. In fact, too small a ùúí2may indicate that you are fitting the randomscatterinthedataratherthanmissingapproximatelyone-thirdoftheerrorbars, asexpectediftheerrorsarerandom.Ifyour ùúí2issignificantlygreaterthan ND‚àíMP,the theorymaynotbegood,youmayhavesignificantlyunderestimatedyourerrors,oryoumay haveerrorsthatarenotrandom. TheMPsimultaneous equations (6.43) can be simplified considerably if the functions g(x;{am})dependlinearlyontheparametervalues ai,e.g., g(x;{a1,a2})=a1+a2x. (6.44) In this case (also known as linear regression ), as shown in Figure 6.7, there are MP=2 parameters,theslope a2,andtheyintercepta1.Noticethatwhilethereareonlytwoparame- terstodetermine,therestillmaybeanarbitrarynumber NDofdatapointstofit.Remember, auniquesolutionisnotpossibleunlessthenumberofdatapointsisequaltoorgreaterthan thenumberofparameters.Forthislinearcase,therearejusttwoderivatives, ùúïg(xi) ùúïa1=1,ùúïg(xi) ùúïa2=xi, (6.45) andaftersubstitution,the ùúí2minimizationequations(6.43)canbesolved: a1=SxxSy‚àíSxSxy Œî, a2=SSxy‚àíSxSy Œî, (6.46) S=ND‚àë i=11 ùúé2 i,Sx=ND‚àë i=1xi ùúé2 i,Sy=ND‚àë i=1yi ùúé2 i, (6.47) Sxx=ND‚àë i=1x2 i ùúé2 i,Sxy=ND‚àë i=1xiyi ùúé2 i,Œî=SSxx‚àíS2 x. (6.48) 0100200300400 0 400 800 1200 1600 2000 xy(x) Figure 6.7 A linear least-squares best Ô¨Åt of a straight line to data. The deviation of theory from experiment is greater than would be expected from statistics, which means that a straight line is not a good theory to describe these data.",3609
6.7.2 Linear Quadratic Fit,"116 6 Trial-and-Error Searching and Data Fitting Statistics also gives you an expression for the varianceor uncertainty in the deduced parameters: ùúé2 a1=Sxx Œî,ùúé2 a2=S Œî. (6.49) Thesearemeasuresoftheuncertaintiesinthevaluesofthefittedparametersarisingfrom theuncertainties ùúéiinthemeasured yivalues.Ameasureofthedependenceoftheparam- etersoneachotherisgivenbythe correlationcoefficient : ùúå(a1,a2)=cov(a1,a2) ùúéa1ùúéa2,cov(a1,a2)=‚àíSx Œî. (6.50) Herecov (a1,a2)isthecovariance ofa1anda2,andvanishesif a1anda2areindependent. Thecorrelationcoefficient ùúå(a1,a2)liesintherange ‚àí1‚â§ùúå‚â§1,withapositive ùúåindicating that the errors in a1anda2are likely to have the same sign, and a negative ùúåindicating oppositesigns. The preceding analytic solutions for the parameters are of the form found in statistics books,butarenotoptimalfornumericalcalculationsbecausesubtractivecancellationcan decreasetheaccuracyoftheanswers.Arearrangementoftheequationscandecreasethis typeoferror[Thompson1992]: a1=y‚àía2x,a2=Sxy Sxx,x=1 NNd‚àë i=1xi,y=1 NNd‚àë i=1yi Sxy=Nd‚àë i=1(xi‚àíx)(yi‚àíy) ùúé2 i,Sxx=Nd‚àë i=1(xi‚àíx)2 ùúé2 i. (6.51) InFit.pyinListing6.4,wegiveaprogramthatfitsaparabolatosomedata.Youcanuseit asamodelforfittingalinetodata,althoughyoucanalsouseourclosed-formexpressions forastraight-linefit. 6.7.2 Linear Quadratic Fit Asindicatedearlier,aslongasthefunctionbeingfitteddepends linearlyontheunknown parameters ai,theconditionofminimum ùúí2leadstoasetofsimultaneouslinearequations 0.40.81.21.6 1 1.2 1.4 1.6 1.8 2 xy(x)Figure 6.8 A linear least-squares best Ô¨Åt of a parabola to data. Here we see that the Ô¨Åt misses approximately one-third of the points, as expected from the statistics for a good Ô¨Åt. 6.7 Least-Squares Fitting 117 for thea‚Äôs that can be solved by hand, or on the computer using matrix techniques. To illustrate,supposewewanttofitthequadraticpolynomial g(x)=a1+a2x+a3x2(6.52) totheexperimentalmeasurements( xi,yi,i=1,ND)showninFigure6.8.Becausethis g(x)is linearintheparameters ai,thefitisstilllinear,eventhough xisraisedtothesecondpower. [However,ifwetriedtoafitafunctionoftheform g(x)=(a1+a2x)exp(‚àía3x)tothedata, then we would not be able to make a linear fit because there is not a linear dependence ona3.] Thebestfitofthisquadratictothedataisobtainedbyapplyingtheminimum ùúí2condition (6.43)forMp=3parametersand ND(stillarbitrary)datapoints.Equation(6.43)leadsto thethreesimultaneousequationsfor a1,a2,anda3: ND‚àë i=1[yi‚àíg(xi)] ùúé2 iùúïg(xi) ùúïa1=0,ùúïg ùúïa1=1, (6.53) ND‚àë i=1[yi‚àíg(xi)] ùúé2 iùúïg(xi) ùúïa2=0,ùúïg ùúïa2=x, (6.54) ND‚àë i=1[yi‚àíg(xi)] ùúé2 iùúïg(xi) ùúïa3=0,ùúïg ùúïa3=x2. (6.55) Note:Becausethederivativesareindependentoftheparameters(the a‚Äôs),theadependence arisesonlyfromthetermsinsquarebracketsinthesums,andbecausethosetermshavea lineardependenceonthe a‚Äôs,theseequationsarelinearinthe a‚Äôs. Exercise Showthataftersomerearrangement,(6.53)‚Äì(6.55)canbewrittenas Sa1+Sxa2+Sxxa3=Sy, (6.56) Sxa1+Sxxa2+Sxxxa3=Sxy, Sxxa1+Sxxxa2+Sxxxxa3=Sxxy. Herethedefinitionsofthe S‚Äôsaresimpleextensionsofthoseusedin(6.46)‚Äì(6.48)andare programmedin Fit.pyinListing6.4.Afterplacingthethreeunknownparametersintoa vectorxandtheknownthreetermsin(6.56)intoavector ‚Éób,theseequationsassumethe matrixform: A‚Éóx=‚Éób, (6.57) A=‚é° ‚é¢ ‚é¢‚é£SSxSxx SxSxxSxxx SxxSxxxSxxxx‚é§ ‚é• ‚é•‚é¶, ‚Éóx=‚é° ‚é¢ ‚é¢‚é£a1 a2 a3‚é§ ‚é• ‚é•‚é¶,‚Éób=‚é° ‚é¢ ‚é¢‚é£Sy Sxy Sxxy‚é§ ‚é• ‚é•‚é¶. The solution for the parameter vector ‚Éóxis obtained by solving the matrix equations. Although for 3 √ó3 matrices we can write out the solution in closed form, for larger problemsthenumericalsolutionrequiresamatrixcomputation.",3478
6.7.2.1 Linear Quadratic Fit Assessment. 6.8 Nonlinear Fit to a Resonance,"118 6 Trial-and-Error Searching and Data Fitting 6.7.2.1 Linear Quadratic Fit Assessment 1) Fitthequadratic(6.52)tothefollowingdatasets[givenas (x1,y1),(x2,y2),‚Ä¶].Ineach case indicate the values found for the as, the number of degrees of freedom, andthe valueofùúí2. a)(0,1) b)(0,1),(1,3) c)(0,1),(1,3),(2,7) d)(0,1),(1,3),(2,7),(3,15) 2) Findafittothelastsetofdatatothefunction y=Ae‚àíbx2. Hint:Ajudiciouschangeofvariableswillpermityoutoconvertthistoalinearfit.Does aminimum ùúí2stillhavemeaninghere? 6.8 Nonlinear Fit to a Resonance Recall how earlier in this chapter we interpolated the values in Table 6.1 in order to obtaintheexperimentalcrosssection ùúéasafunctionofenergy.Althoughwedidnotuse it, we also gave the theory describing these data, namely, the Breit‚ÄìWigner resonance formula(6.20): f(E)=fr (E‚àíEr)2+Œì2‚àï4. (6.58) Your problemistodeterminewhatvaluesfortheparameters Er,fr,andŒìin(6.58)provide thebestfittothedatainTable6.1. Since(6.58)isnotalinearfunctionoftheparameters( Er,fr,Œì),thethreeequationsthat resultfromminimizing ùúí2arenotlinearequations,andsocannotbesolvedbythetech- niquesoflinearalgebra.However,inourstudyofthemassesonastringproblemweshow howtousetheNewton‚ÄìRaphsonalgorithmtosearchforsolutionsofsimultaneousnon- linearequations.Thattechniqueinvolvedexpansionoftheequationsaboutthe previous guess to obtain a set of linear equations, and then solving the linear equations with the matrix libraries. We now use this same combination of fitting, trial-and-error searching, andmatrixalgebratoconductanonlinearleast-squaresfitof(6.58)tothedatainTable6.1. Recall that the condition for a best fit is to find values of the MPparameters amin the theoryg(x,am)thatminimize ùúí2=‚àë i[(yi‚àígi)‚àïùúéi]2.Thisleadstothe MPequations(6.43) tosolve ND‚àë i=1[yi‚àíg(xi)] ùúé2 iùúïg(xi) ùúïam=0,(m=1,MP). (6.59) Tofindtheformoftheseequationsappropriatetoourproblem,werewriteourtheoryfunc- tion(6.58)inthenotationof(6.59): a1=fr,a2=ER,a3=Œì2‚àï4,x=E, (6.60) ‚áíg(x)=a1 (x‚àía2)2+a3. (6.61) 6.8 Nonlinear Fit to a Resonance 119 Thethreederivativesrequiredin(6.59)arethen ùúïg ùúïa1=1 (x‚àía2)2+a3,ùúïg ùúïa2=‚àí2a1(x‚àía2) [(x‚àía2)2+a3]2,ùúïg ùúïa3=‚àía1 [(x‚àía2)2+a3]2. Substitutionofthesederivativesintothebest-fitcondition(6.59)yieldsthreesimultaneous equationsin a1,a2,anda3thatweneedtosolveinordertofitthe ND=9datapoints (xi,yi) inTable6.1: 9‚àë i=1yi‚àíg(xi,a) (xi‚àía2)2+a3=0,9‚àë i=1yi‚àíg(xi,a) [(xi‚àía2)2+a3]2=0, 9‚àë i=1{yi‚àíg(xi,a)}(xi‚àía2) [(xi‚àía2)2+a3]2=0. (6.62) Even without the substitution of (6.58) for g(x,a), it is clear that these three equations depend on the a‚Äôs in a nonlinear fashion. That‚Äôs okay because in Section 6.3 we derived theN-dimensionalNewton‚ÄìRaphsonsearchfortherootsof fi(a1,a2,‚Ä¶,aN)=0,i=1,N, (6.63) wherewehavemadethechangeofvariable yi‚Üíaiforthepresentproblem.Weusethat sameformalismhereforthe N=3equations(6.62)bywritingthemas f1(a1,a2,a3)=9‚àë i=1yi‚àíg(xi,a) (xi‚àía2)2+a3=0, (6.64) f2(a1,a2,a3)=9‚àë i=1{yi‚àíg(xi,a)}(xi‚àía2) [(xi‚àía2)2+a3]2=0, (6.65) f3(a1,a2,a3)=9‚àë i=1yi‚àíg(xi,a) [(xi‚àía2)2+a3]2=0. (6.66) Becausefr‚â°a1isthepeakvalueofthecross section, ER‚â°a2istheenergyatwhichthe peakoccurs,and Œì=2‚àöa3isthefullwidthofthepeakathalf-maximum,goodguessesfor thea‚Äôscanbeextractedfromagraphofthedata.Toobtaintheninederivativesofthethree f‚Äôswithrespecttothethreeunknown a‚Äôs,weusetwonestedloopsover iandj,alongwith theforward-differenceapproximationforthederivative ùúïfi ùúïaj‚âÉfi(aj+Œîaj)‚àífi(aj) Œîaj, (6.67) whereŒîajcorrespondstoasmall,say ‚â§1 percent,changeintheparametervalue. Nonlinear Fit Exercise UsetheNewton‚ÄìRaphsonalgorithmasoutlinedinSection6.8 toconductanonlinearsearchforthebest-fitparametersoftheBreit‚ÄìWignertheory(6.58)to thedatainTable6.1.Comparethededucedvaluesof (fr,ER,Œì)tothatobtainedbyinspection ofthegraph.",3682
6.9 Code Listings,"120 6 Trial-and-Error Searching and Data Fitting 6.9 Code Listings Listing 6.1 TheBisection.py codeisasimpleimplementationofthebisectionalgorithm forfindingazeroofafunction,inthiscase2cos x‚àíx. 1# Bisection .py: zero of f(x) via Bisection algorithm within [a,b] fromvpython import ‚àó eps = 1e ‚àí3; Nmax = 100; a = 0.0; b = 7.0 # Precision , [a,b] 5 deff(x):return2‚àócos(x) ‚àíx # Your function here defBisection(Xminus, Xplus, Nmax, eps): # Do not change 9foritin range (0, Nmax): x=( X p l u s+ X m i n u s ) / 2 . print(\""i t= \"",i t , \""x=\"",x , \"" f(x) =\"" ,f ( x ) ) if(f(Xplus) ‚àóf(x) > 0.): Xplus = x #C h a n g ex +t ox 13 else:X m i n u s= x #C h a n g ex ‚àíto x if(abs(f(x) ) <=eps): # Converged? print(\""  Root found with precision eps = \"" ,e p s ) break 17 ifit == Nmax ‚àí1:print(\""  No root after N iterations \"" ) returnx root = Bisection(a, b, Nmax, eps) 21print(\"" Root =\"" , root) Listing 6.2 NewtonCD.py UsestheNewton‚ÄìRaphsonmethodtosearchforazeroofthe functionf(x).Acentral-differenceapproximationisusedtodetermine fd/dx. 1# NewtonCD . py Newton Search with c e n t r a l d i f f e r e n c e frommathimportcos 5x = 1111.; dx = 3.e ‚àí4; eps = 0.002; Nmax = 100; # Parameters deff(x):return2‚àócos(x) ‚àíx# Function 9foritin range (0 , Nmax + 1) : F=f( x ) if(abs(F) ‚àó<‚àó=e p s ) : # Converged? print(\""  Root found, f(root) =\"" ,F , \"" ,e p s=\"" ,e p s ) 13 break print(\""Iteration # = \"" ,i t , \""x=\"",x , \"" f(x) = \"" ,F ) df = (f(x+dx/2) ‚àíf(x‚àídx/2))/dx # Central diff dx =‚àíF/df 17x+ = d x # N e w guess Listing 6.3 SplineInteract.py Performsacubicsplinefittodatawithinteractivecontrol. 1# SplineInteract .py Spline fit with slide to control number of points fromvisualimport ‚àó; fromvisual.graph import ‚àó; fromvisual.graph importgdisplay , gcurve 5fromvisual.controls importslider , controls , toggle x = array([0., 0.12, 0.25, 0.37, 0.5, 0.62, 0.75, 0.87, 0.99]) # input y = array([10.6, 16.0, 45.0, 83.5, 52.8, 19.9, 10.8, 8.25, 4.7]) 9n=9 ; n p=1 5 # Initialize y2 = zeros( (n), float); u= zeros( (n), float) 6.9 Code Listings 121 13graph1 = gdisplay(x=0,y=0,width=500, height=500, title= ‚ÄôSpline Fit‚Äô , xtitle= ‚Äôx‚Äô, ytitle= ‚Äôy‚Äô) funct1 = gdots(color = color.yellow) funct2 = gdots(color = color.red) 17graph1.visible = 0 defupdate(): # Nfit = 30 = output Nfit =int(control.value) 21foriin range (0, n): # Spread out points funct1.plot(pos = (x[i], y[i]) ) funct1.plot(pos = (1.01 ‚àóx[i], 1.01 ‚àóy[i]) ) funct1.plot(pos = (.99 ‚àóx[i], .99 ‚àóy[i]) ) 25 yp1 = (y[1] ‚àíy[0]) / (x[1] ‚àíx[0])‚àí(y[2]‚àíy[1])/ \ (x[2]‚àíx[1])+(y[2] ‚àíy[0])/(x[2] ‚àíx[0]) ypn = (y[n ‚àí1]‚àíy[n‚àí2])/(x[n ‚àí1]‚àíx[n‚àí2])‚àí(y[n‚àí2]‚àíy[n‚àí3])/(x[n ‚àí2]‚àíx[n‚àí3]) + (y[n‚àí1]‚àíy[n‚àí3])/(x[n ‚àí1]‚àíx[n‚àí3]) if(yp1 > 0.99e30): y2[0] = 0.; u[0] = 0. 29else: y2[0] = ‚àí0.5 u[0] = (3./(x[1] ‚àíx[0]) ) ‚àó(( y [ 1 ] ‚àíy[0])/(x[1] ‚àíx[0])‚àíyp1) foriin range (1, n‚àí1): # Decomp loop 33 sig = (x[i] ‚àíx[i‚àí1])/(x[i + 1] ‚àíx[i‚àí1]) p=s i g ‚àóy2[i‚àí1] + 2. y2[i] = (sig ‚àí1.)/p u[i] = (y[i+1] ‚àíy[i])/(x[i+1] ‚àíx[i])‚àí(y[i]‚àíy[i‚àí1])/(x[i] ‚àíx[i‚àí1]) 37 u[i] = (6. ‚àóu[i]/(x[i + 1] ‚àíx[i‚àí1])‚àísig‚àóu[i‚àí1])/p if(ypn > 0.99e30): qn = un = 0. # Test for natural else: qn = 0.5; 41 un = (3/(x[n ‚àí1]‚àíx[n‚àí2])) ‚àó(ypn‚àí(y[n‚àí1]‚àíy[n‚àí2])/(x[n ‚àí1]‚àíx[n‚àí2])) y2[n‚àí1] = (un ‚àíqn‚àóu[n‚àí2])/(qn ‚àóy2[n‚àí2] + 1.) forkin range (n‚àí2, 1, ‚àí1): y2[k] = y2[k] ‚àóy2[k + 1] + u[k] 45foriin range (1, Nfit + 2): # Begin fit xout = x[0] + (x[n ‚àí1]‚àíx[0]) ‚àó(i‚àí1)/(Nfit) klo = 0; khi = n ‚àí1 # Bisection algor while(khi‚àíklo >1): 49 k=( k h i+k l o )> >1 if(x[k] > xout): khi = k else:k l o= k h=x [ k h i ] ‚àíx[klo] 53 if(x[k] > xout): khi = k else:k l o= k h=x [ k h i ] ‚àíx[klo] a=( x [ k h i ] ‚àíxout)/h 57 b=( x o u t ‚àíx[klo])/h yout = a ‚àóy[klo] + b ‚àóy[khi] + ((a‚àóa‚àóa‚àía)‚àóy2[klo]+(b ‚àób‚àób‚àíb)‚àóy2[khi]) ‚àóh‚àóh/6 funct2.plot(pos = (xout, yout) ) c=controls(x=500,y=0,width=200,height=200) # Control via slider 61control = slider(pos=( ‚àí50,50,0), min=2 ,max= 100, action = update) toggle(pos = (0, 35, ‚àí5), text1 = \""Number of points\"" , height = 0) control.value = 2 update() 65 while1: c.interact() rate(50) # update <10/sec 69funct2.visible = 0 Listing 6.4 Fit.py Performs a least-squares fit of a parabola to data using the NumPy linagepackagetosolvethesetoflinearequations S‚Éóa=‚Éós. 1# Fit .py: Linear least square fit via matrix solution importpylab as p fromnumpyimport ‚àó;fromnumpy. linalg importinv, solve 5 122 6 Trial-and-Error Searching and Data Fitting Nd = 7 A=z e r o s( ( 3, 3 ), float); bvec = zeros((3,1), float) # Initialize ss= sx = sxx = sy = sxxx = sxxxx = sxy = sxy = sxxy = 0. 9x = array([1., 1.1, 1.24, 1.35, 1.451, 1.5, 1.92]) #xv a l u e s y = array([0.52, 0.8, 0.7, 1.8, 2.9, 2.9, 3.6]) #yv a l u e s sig = array([0.1, 0.1, 0.2, 0.3, 0.2, 0.1, 0.1]) # Error bars xRange = arange(1.0, 2.0, 0.1) #F o rp l o t s 13p.plot(x, y, ‚Äôbo‚Äô) #B l u ed a t a p.errorbar(x,y,sig) p.title( ‚ÄôLeast Square Fit of Parabola to Blue Data‚Äô ) p.xlabel( ‚Äôx‚Äô); p.ylabel( ‚Äôy‚Äô); p.grid(True) # Plot grid 17 foriin range (0, Nd): sig2 = sig[i] ‚àósig[i] ss += 1. / sig2; sx += x[i]/sig2; sy += y[i]/sig2 21 rhl = x[i] ‚àóx[i]; sxx += rhl/sig2; sxxy += rhl ‚àóy[i]/sig2 sxy += x[i] ‚àóy[i]/sig2; sxxx +=rhl ‚àóx[i]/sig2; sxxxx +=rhl ‚àórhl/sig2 A = array([ [ss,sx,sxx], [sx,sxx,sxxx], [sxx,sxxx,sxxxx] ]) bvec = array([sy, sxy, sxxy]) 25xvec = multiply(inv(A), bvec) # Invert matrix print(‚Äô  x via Inverse A ‚Äô ,x v e c , ‚Äô ‚Äô) xvec = solve(A, bvec) # Solve via elimination print(‚Äô  x via Elimination  ‚Äô ,x v e c , ‚Äô  Fit to Parabola ‚Äô ) 29print(‚Äôy(x) = a0 + a1 x + a2 xÀÜ2  a0 =‚Äô ,x [ 0 ] , ‚Äôa1 =‚Äô,x [ 1 ] , ‚Äôa2 =‚Äô,x [ 2 ] ) print(‚Äô  i xi yi yfit ‚Äô ) foriin range (0, Nd): s = xvec[0] + xvec[1] ‚àóx[i] + xvec[2] ‚àóx[i] ‚àóx[i] 33print(\""  percentd  percent5.3f  percent5.3f  percent8.7f\""  percent(i, x[i], y[i], s)) # red line is the fit , red dots the fits at y[ i ]m curve = xvec[0] + xvec[1] ‚àóxRange + xvec[2] ‚àóxRange ‚àó‚àó2 points = xvec[0] + xvec[1] ‚àóx+x v e c [ 2 ] ‚àóx‚àó‚àó2 37p.plot(xRange, curve, ‚Äôr‚Äô, x, points, ‚Äôro‚Äô) p.show()",5874
Chapter 7 Matrix Computing and ND Searching. 7.1 Masses on a String and ND Searching,"123 7 Matrix Computing and N‚ÄìD Searching This chapter discusses how to compute with matrices, and, in particular, the use of the Python matrix and linear algebra packages. The chapter ends with a discussion of how to speed up large matrix computations . 7.1 Masses on a String and N‚ÄìD Searching Problem Two masses with weights (W1,W2)=(10,20)are connected by three pieces of string with lengths (L1,L2,L3)=(3,4,4), and hung from a horizontal bar of length L=8(Figure7.1).Findtheanglesassumedbythestringsandthetensionsexertedbythe strings. Inspiteofthefactthatthisisasimpleproblemrequiringnomorethanfirst-yearphysics to formulate, the coupled transcendental equations that result are just about impossible tosolveanalytically.1Weapproachitasamatrixproblemcombinedwithatrial-and-error search. Westartwiththegeometricconstraintsthatthehorizontallengthofthestructureis L, andthatthestringsbeginandendatthesameheight(Figure7.1): L1cosùúÉ1+L2cosùúÉ2+L3cosùúÉ3=L, (7.1) L1sinùúÉ1+L2sinùúÉ2‚àíL3sinùúÉ3=0, (7.2) sin2ùúÉ1+cos2ùúÉ1=1, (7.3) sin2ùúÉ2+cos2ùúÉ2=1, (7.4) sin2ùúÉ3+cos2ùúÉ3=1. (7.5) Observethatsincewetreatsin ùúÉandcosùúÉasindependentvariables,wehaveincludedthree trigonometricidentitiesasindependentequations.Thebasicsphysics(Figure7.2)saysthat because there are no accelerations, the sum of the forces in the horizontal and vertical 1 Almostimpossibleanyway,asL.Molarhassuppliedmewithananalyticsolution. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 124 7 Matrix Computing and N‚ÄìD Searching T1L1L T2 L2T3 L3W1 W2Œ∏1Œ∏3 Œ∏2 Œ∏3Figure 7.1 Two masses with weights (W1,W2) are connected by three pieces of string of lengths(L1,L2,L3), and hung from a horizontal bar of length L. The lengths are all known, but the angles and the tensions in the strings are to be determined. Ti Ti+1 WiŒ∏i Œ∏i+1iFigure 7.2 A free-body diagram for one weight in equilibrium. Balancing the forces in the xandydirections for all weights leads to the equations of static equilibrium. directionsmustequalzero: T1sinùúÉ1‚àíT2sinùúÉ2‚àíW1=0, (7.6) T1cosùúÉ1‚àíT2cosùúÉ2=0, (7.7) T2sinùúÉ2+T3sinùúÉ3‚àíW2=0, (7.8) T2cosùúÉ2‚àíT3cosùúÉ3=0. (7.9) HereWiistheweightofmass iandTiisthetensioninstring i.Notethatbecausewedonot havearigidstructure,wecannotassumeanequilibriumoftorques. Equations(7.1)‚Äì(7.9)areninesimultaneous, nonlinearequations,whichbeingnonlinear cannotbesolvedwith linearalgebra.However,youcanextendtheNewton‚ÄìRaphsonalgo- rithmtomultipleequations,and searchforasolution.Tothateffect,werenamethenine unknownanglesandtensionsasthesubscriptedvariable yi,andplaceallofthevariables intoavector: y=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£x1 x2 x3 x4 x5 x6 x7 x8 x9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£sinùúÉ1 sinùúÉ2 sinùúÉ3 cosùúÉ1 cosùúÉ2 cosùúÉ3 T1 T2 T3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (7.10) 7.1 Masses on a String and N‚ÄìD Searching 125 Thenineequationstobesolvedarewritteninageneralformwithzerosontheright-hand sides(RHS),andalsoplacedinavector: fi(x1,x2,‚Ä¶,xN)=0,i=1,N, (7.11) f(y)=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£f1(y) f2(y) f3(y) f4(y) f5(y) f6(y) f7(y) f8(y) f9(y)‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£3x4+4x5+4x6‚àí8 3x1+4x2‚àí4x3 x7x1‚àíx8x2‚àí10 x7x4‚àíx8x5 x8x2+x9x3‚àí20 x8x5‚àíx9x6 x2 1+x2 4‚àí1 x2 2+x2 5‚àí1 x2 3+x2 6‚àí1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=0. (7.12) In words, we are looking for set of nine xivalues for which all nine fi‚Äôs vanish simul- taneously. Although these equations are not very complicated (the physics after all is elementary),thetermsquadraticin xmakethemnonlinear. The search procedure guesses a solution, expands the nonlinear equations and keeps justthelinearterms,solvesthelinearequations,andmakesabetterguessbasedonhow close the previous guess was to making f=0. The search starts with the approximate solution at any one stage called the set xi, and assumes that there are (yet unknown) corrections Œîxiforwhich fi(x1+Œîx1,x2+Œîx2,‚Ä¶,x9+Œîx9)=0,i=1,9. (7.13) Wesolvefortheapproximate Œîxi‚Äôsbyassumingthatourprevioussolutioniscloseenough totheactualonefortwotermsintheTaylorseriestobeaccurate: fi(x1+Œîx1,..,x9+Œîx9)‚âÉfi(x1,..,x9)+9‚àë j=1ùúïfi ùúïxjŒîxj=0,i=1,9. Wenowhaveasetofninelinearequationsinthenineunknowns Œîxi,whichweexpressas asinglematrixequation f1+ùúïf1‚àïùúïx1Œîx1+ùúïf1‚àïùúïx2Œîx2+¬∑¬∑¬∑+ùúïf1‚àïùúïx9Œîx9=0, f2+ùúïf2‚àïùúïx1Œîx1+ùúïf2‚àïùúïx2Œîx2+¬∑¬∑¬∑+ùúïf2‚àïùúïx9Œîx9=0, ... f9+ùúïf9‚àïùúïx1Œîx1+ùúïf9‚àïùúïx2Œîx2+¬∑¬∑¬∑+ùúïf9‚àïùúïx9Œîx9=0, or‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£f1 f2 ... f9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶+‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùúïf1‚àïùúïx1ùúïf1‚àïùúïx2¬∑¬∑¬∑ùúïf1‚àïùúïx9 ùúïf2‚àïùúïx1ùúïf2‚àïùúïx2¬∑¬∑¬∑ùúïf2‚àïùúïx9 ... ùúïf9‚àïùúïx1ùúïf9‚àïùúïx2¬∑¬∑¬∑ùúïf9‚àïùúïx9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£Œîx1 Œîx2 ... Œîx9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=0. (7.14)",4537
7.2 Matrix Generalities,"126 7 Matrix Computing and N‚ÄìD Searching Notenowthatthederivativesandthe f‚Äôsareallevaluatedatknownvaluesofthe xi‚Äôs,sothat onlythevectorofthe Œîxivaluesisunknown.Wewritethisequationinmatrixnotationas f+F‚Ä≤ùö´x=0,‚áíF‚Ä≤ùö´x=‚àíf, (7.15) ùö´x=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£Œîx1 Œîx2 ... Œîx9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶,f=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£f1 f2 ... f9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶,F‚Ä≤=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùúïf1‚àïùúïx1¬∑¬∑¬∑ùúïf1‚àïùúïx9 ùúïf2‚àïùúïx1¬∑¬∑¬∑ùúïf2‚àïùúïx9 ... ùúïf9‚àïùúïx1¬∑¬∑¬∑ùúïf9‚àïùúïx9‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶, whereweuseboldcharacterstodenotethevectorandmatrixnatureoftheequations. Theequation F‚Ä≤ùö´x=‚àífisinthestandardformforthesolutionofalinearequation(often writtenAx=b), where ùö´xis the vector of unknowns and b=‚àíf. Matrix equations are solved using the techniques of linear algebra, which we will discuss shortly. In a formal sense, the solution of (7.15) is obtained by multiplying both sides of the equation by the inverseofthe F‚Ä≤matrix: ùö´x=‚àíF‚Ä≤‚àí1f, (7.16) wheretheinversemustexistifthereistobeauniquesolution.Althoughwearedealingwith matricesnow,thissolutionisidenticalinformtothatofthe1Dproblem,equation(6.11), Œîx=‚àí (1‚àïf‚Ä≤)f.Theabstractnotationformatricesisseentorevealthesimplicitythatlies within. Aswehavenotedforthesingle-equationNewton‚ÄìRaphsonmethodinSection6.3,even ifwecanderiveanalyticexpressionsforthederivatives ùúïfi‚àïùúïxj,thereare9 √ó9=81such derivativesforthis(small)problem,andenteringthemallwouldbebothtime-consuming and error-prone. In contrast, it is straightforward to program up a forward-difference approximationforthederivatives, ùúïfi ùúïxj‚âÉfi(xj+Œîxj)‚àífi(xj) Œîxj, (7.17) where, for partial derivatives, each individual xjis varied independently, and the ùõøxjare arbitrarysmallchanges.Whileacentral-differenceapproximationforthederivativewould be more accurate, it would also require more evaluations of the f‚Äô s ,a n do n c ew efi n da solutionitdoesnotmatterhowaccurateouralgorithmforthederivativewas. Asalsodiscussedforthe1DNewton‚ÄìRaphsonmethod(Section6.3.1),themethodcan fail if the initial guess is not close enough to the zeros of all nine f‚Äôs. Thebacktracking technique(usingfractional Œîxguesses) maybeappliedhereaswell,inthepresentcase, progressivelydecreasingthecorrections Œîxiuntil |f|2=|f1|2+|f2|2+¬∑¬∑¬∑+ |fN|2becomes acceptablysmall. 7.2 Matrix Generalities Oftenaphysicaltheoryiseasiertounderstandwhenexpressedmoreabstractlywithmatri- ces, an example being the rotation of solid bodies with the inertia tensor. It should not be surprising then that scientific computing often involve matrices. This is a good thing since computers are good at continued repetition of simple instructions, and that is just 7.2 Matrix Generalities 127 whatmatrixmanipulationsinvolve.Andasphysicalsystemsgetmorerealisticandmore complex, the equations used to describe them often involves the manipulations of large matrices,whicharenohardertoprogramupthansmallones. Westronglyrecommendtheuseofthepowerfulandrobustlinearalgebralibrariesthathave been perfected over decades . Their programs are usually an order of magnitude, or more, fasterthantheelementarymethodsfoundinlinearalgebratexts,2aredesignedtominimize round-off error, and are often ‚Äúrobust,‚Äù that is, have a high chance of workingwell for a broadclassofproblems.Anadditionalvalueoflibraryroutinesisthatyoucanoftenrun thesameprogrameitheronadesktopmachineoronaparallelsupercomputer,withmatrix routinesautomaticallyadaptingtothelocalarchitecture. Themostbasicmatrixproblemisthesystemoflinearequations: Ax=b, (7.18) whereAisaknown N√óNmatrix,xisanunknownvectoroflength N,andbisaknown vectoroflength N.Theobviouswaytosolvethisequationistomultiplybothsidesbythe inverseofA: x=A‚àí1b. (7.19) Both the direct solution (7.18) as it stands, and the determination of a matrix‚Äôs inverse are standards in subroutine libraries. The direct solution via Gaussian elimination or lower‚Äìupper (LU) decomposition tends to be faster, but sometime you may want the inverseforotherpurposes. Ifyouhavetosolvethematrixequation Ax=ùúÜx, (7.20) withxanunknownvectorand ùúÜanunknownparameter,thenthesolution(7.19)willnot beofmuchhelpbecausetheRHScontainstheunknowns ùúÜandx.Equation(7.20)isthe eigenvalueproblem ,anditssolutionsexistforonlycertain,ifany,valuesof ùúÜ.T ofindthe solution,weusetheidentitymatrix Itorewrite(7.20)as [A‚àíùúÜI]x=0. (7.21) Weseethatmultiplicationof(7.21)by [A‚àíùúÜI]‚àí1yieldsthetrivialsolution x=0(trivialsolution ). (7.22) Whilethetrivialsolutionisabonafidesolution,itisnonethelesstrivial.Amoreinteresting solutionresultsfromtheconditionthatforbidsusfrommultiplyingbothsidesof(7.21)by [A‚àíùúÜI]‚àí1,namely,thenonexistenceoftheinverse.IfyourecallthatCrammer‚Äôsrulefor theinverserequiresdivisionbydet [A‚àíùúÜI],itisclearthattheinversefailstoexist(andin thiswayeigenvalues doexist)when det[A‚àíùúÜI]=0. (7.23) TheùúÜvalues that satisfy this secular equation are the eigenvalues of (7.20). If you are interested in only the eigenvalues for (7.20), you should look for a matrix routine that 2 AlthoughweprizethebookPress etal.[2007]andwhatithasaccomplished,wecannotrecommend takingmatrixsubroutinesfromit.Theyareneitheroptimizednordocumentedforeasy,stand-aloneuse, whereasthesubroutinelibrariesrecommendedinthischapterare. 128 7 Matrix Computing and N‚ÄìD Searching solves (7.23). First you need a subroutine to calculate the determinant of a matrix, and then a search routine to zero in on the solution of (7.23). Such routines are available in libraries. Manyprogrammingbugsarisefromtheimproperuseofarrays.3Thismaybeasaresultof theextensiveuseofmatricesinscientificcomputing,ortothecomplexityofkeepingtrack ofindicesanddimensions.Inanycase,herearesomerulesofthumbtoobserve: Tests:Alwaystestalibraryroutineonasmallproblemwhoseansweryouknow(suchas thetestsinSection7.4).Thenyou‚Äôllknowifyouaresupplyingitwiththerightarguments andifyouhaveallthelinksworking. Paging:Operatingsystemsstoredataandvariablesinfixed-length,contiguousblocksof memory called pagesthat are treated as single entries in a page table. If there is not enough room in RAM for a page, then the entire page gets stored in virtual memory , whichmeansitgetsplacedonaslowdisk.Thisiscalled paging.Ifyourprogramdeals with matrices that take up lots of memory, it may be near the memory limit at which pagingoccurs,andthenevenaslightincreaseinthematrix‚Äôssizemayleadtoanorder- of-magnitudeincreaseinexecutiontime.(Therearesimilarissueswithcomputercaches, whicharesmallamountsofsuperfastmemory,suchas1‚Äì8MB,thatfeedstheCPU.) Computersarefinite :Unlessyouarecareful,yourmatricesmayuseupsomuchmemory thatyourcomputationwillslowdownsignificantly,especiallyifitstartstousevirtual memory. As a case in point, let‚Äôs say that you performing some matrix calculations involving4-Dmatrices,witheachindexhavinga physicaldimension of200,forexample, A[200] [200] [200] [200] . A single array of (200)464-byte words occupies ‚âÉ16GB of memory. Processing time : Matrix operations such as inversion require on the order of N3steps forasquarematrixofdimension N.Therefore,doublingthedimensionsofa2Dsquare matrix(ashappenswhenthenumberofintegrationstepsisdoubled)leadstoan eightfold increaseinprocessingtime. Matrixstorage :Whilewethinkofmatricesasmultidimensionalblocksofstorednumbers, the computer stores them as linear strings. For instance, a matrix a[3,3]in Python, is storedinrow-majororder : a0,0a0,1a0,2a1,0a1,1a12a2,0a2,1a2,2‚Ä¶. ThisdiffersfromFortran,wheresubscriptsusuallystartat1,andwherethestorageisin column-majororder : a1,1a2,1a3,1a1,2a2,2a3,2a1,3a2,3a3,3‚Ä¶. Itisimportanttokeepthisstorageschemeinmindsincesomeroutinesassumelinear storage,andsometimesPythonandFortranprogramsgetintermixed. Minimizingstride :Stride,theamountofmemoryskippedinordertogettothenextele- mentneededinacalculation,shouldbeminimized.Forinstance,summingthediagonal elementsofamatrixtoformthetrace TrA=N‚àë i=1a(i,i) (7.24) 3 Evenavector V(N)iscalledan‚Äúarray,‚Äùalbeita1Done.",7705
7.3 Matrices in Python. 7.3.2 NumPy Matrices,"7.3 Matrices in Python 129 involves large stride because the diagonal elements are stored far apart for large N. However,thesum b(i)=a(i)+a(i+1) (7.25) has stride 1 because adjacent elements of aare accessed. The basic rule for accessing indexedvariablesis ‚óèKeepthestridelow,preferablyat1,whichinpracticemeans: ‚óèVarytherightmostindexfirstonPythonandCarrays. Accessing matrices : Sometimes your effort at elegant programming may be very inef- ficient. For example, it may be elegant to put all your data in one matrix with many indices,suchas VN,M,k,k‚Ä≤,Z,A,butitmayrequirethecomputertomakelarge stridesasyou gothroughthousandsof kandk‚Ä≤,values.Amoreefficientapproachmightbetobreak upthedataintoseveralmatrices,eachwithfewerindices,suchas VN,M,Uk,k‚Ä≤,andWZ,A. 7.3 Matrices in Python 7.3.1 Lists as Arrays Alistis Python‚Äôs built-in sequence of numbers or objects. Although called a ‚Äúlist,‚Äù it is similartowhatothercomputerlanguagescallan‚Äúarray.‚ÄùItmaybeeasierforyoutothink ofaPythonlistasacontainerthatholdsabunchofitemsinadefiniteorder.(Soonwewill describe the higher-level, and recommended, arraydata type available with the NumPy package.)Inthissection,wereviewsomeofPython‚Äôsnative listfeatures. Pythoninterpretsasequenceofordereditems, L=l0,l1,‚Ä¶,lN‚àí1,asalistandrepresents itwithasinglesymbol L: >>> L = [1 , 2 , 3] #C r e a t el i s t >>> L[0] # Print element 0 (first) 4 1 # Python output >>> L # Print entire list [1, 2, 3] # Output >>> L[0] = 5 # Change element 0 8 >>> L [5, 2, 3] >>>len(L) # Length of list 3 12 >>>foritemsinL:printitems # for loop over items 5 2 3 Observethatsquarebracketswithcommaseparatorssuchas[1,2,3]areusedforlists,and thatasquarebracketisalsousedtoindicatetheindexforalistitem,asinline2(L[0]).Lists containsequencesofarbitraryobjectsthatare mutableorchangeable.Asweseeinline7 inthe Lcommand,anentirelistcanbereferencedasasingleobject,inthiscasetoobtain itsprintout. Pythonalsohasabuilt-intypeoflist,knownasa tuple,withelementsthatarenotmuta- ble.Tuplesareindicatedbyroundparenthesis(..,..,.),withindividualelementsstillrefer- encedbysquarebrackets: 130 7 Matrix Computing and N‚ÄìD Searching >>> T = (1 , 2 , 3 , 4) # Create tuple 2>>> T[3] # Print element 3 4 >>> T (1, 2, 3, 4) # Print entire tuple 6>>> T[0] = 5 # Attempt to change element 0 Traceable (most recent call last): T[0] = 5 Error: ‚Äôtuple‚Äô object does notsupport item assignment Notetheerrormessagethatariseswhenwetrytochangeanelementofatuple. Manylanguagesrequireyoutospecifythesizeofanarraybeforeyoucanstartstoring objectsinit.Incontrast,Pythonlistsare dynamic,whichmeansthattheirsizesadjustas needed. In addition, while a list is essentially one dimensional, a compound list can be createdbyhavingtheindividualelementsthemselvesaslists: >>> L = [[1,2], [3,4], [5,6]] #Al i s t o f l i s t s >>> L 3[[1, 2], [3, 4], [5, 6]] >>> L[0] # The first element [1, 2] Herearesomemorelistoperations: Operation Effect Operation Effect L=[1,2,3,4] Formlist L1+L2 Concatenatelists L[i] ithelement len(L) Lengthoflist L iinL Trueif iinL L[i:j] Slicefrom itoj foriinL Iterationindex L.append(x) Append xtoendofL L.count(x) Numberofx‚Äôsin LL.index(x) Locationof1st xinL L.remove(x) Remove1st xinLL.reverse() Reverseelementsin L L.sort() Orderelementsin L 7.3.2 NumPy Matrices Although we have just described Python‚Äôs basic arraydata type, it is rather limited and we suggest using NumPy arrays, which converts Python lists into arrays.",3411
7.3 Matrices in Python. 7.3.2 NumPy Matrices,"In order to use NumPy,youmustimport NumPyintoyourprograms,asweshowhererunningourprogram Matrix.pyfromashell(the >>>): 1 >>>fromnumpyimport ‚àó # Import NumPy package > > > vector1 = array([1, 2, 3, 4, 5]) # Fill 1D array 3 >>>print(‚Äôvector1 =‚Äô ,vector1) # Print array (parens if Python 3) vector1 = [1 2 3 4 5] # Output 5 >>> vector2 = vector1 + vector1 # Add 2 vectors >>>print(‚Äôvector2=‚Äô ,vector2) # Print vector2 7 vector2= [ 2 4 6 8 10] # Output >>> vector2 = 3 ‚àóvector1 # Multi array by scalar 9 >>>print(‚Äô3 * vector1 = ‚Äô , vector2) # Print vector 3‚àóvector1 = [ 3 6 9 12 15] # Output 11 >>> matrix1 = array(([0,1],[1,3])) # An array of arrays >>>print(matrix1) #P r i n tm a t r i x 1 13 [[0 1] [1 3]] 7.3 Matrices in Python 131 15 >>>print(‚Äôvector1.shape= ‚Äô ,vector1.shape) vector1.shape = (5) 17 >>>print(matrix1 ‚àómatrix1) # Matrix multiply [[0 1] 19 [1 9]] We see here that we have initialized an array object, have added two 1D array objects together,andhaveprintedouttheresult.Likewise,weseethatmultiplyinganarraybya constantdoes,infact,multiplyeachelementbythatconstant(line8).Wethenconstruct a‚Äúmatrix‚Äùasa1Darrayoftwo1Darrays,andwhenweprintitout,wenotethatitdoes indeedlooklikeamatrix.However,whenwemultiplythismatrixbyitself,theresultisnot the[13 31 0] , that one normally expects from matrix multiplication. So if you need actual mathematicalmatrices,thenyouneedtouseNumPy. NowwegivesomeexamplesoftheuseofNumPy,butdoreferthereadertotheNumPy Tutorial[NumPy, 2023]andto thearticlesin ComputinginScience&Engineering [CiSE, 2015] for more information. To start, we note that a NumPy array can hold up to 32 dimensions (32 indices), but each element must be of the same type (a uniformarray). Theelementsarenotrestrictedtojustfloating-pointnumbersorintegers,butcanbeany object, as long as all elements are of this same type. (Compound objects may be useful, for example, for storing parts of data sets.) There are various ways to create arrays, with squarebrackets[ ‚Ä¶]usedforindexinginallcases.WestartwithaPythonlist(tupleswork aswell)andcreateanarrayfromit: 1 >>>fromNumPyimport ‚àó >>> a = array ( [1 , 2 , 3 , 4] ) # Array from a list 3 >>> a # Check with print array([1, 2, 3, 4]) Noticethatitisessentialtohavethesquarebracketswithintheroundparenthesesbecause thesquarebracketsproducethelistobjectwhiletheroundparenthesesindicateafunction argument.Notetoothatbecausethedatainouroriginallistwereallintegers,thecreated arrayisoneof32-bitintegerdatatypes,whichwecancheckbyaffixingthe typemethod: >>> a . dtype 2 type(‚Äôint32‚Äô) Ifwehadstartedwithfloating-pointnumbers,oramixoffloatsandint‚Äôs,wewouldhave endedupwithfloating-pointarrays: >>> b = array([1.2, 2.3, 3.4]) 2 >>> b array([ 1.2, 2.3, 3.4]) 4 >>> b . dtype type(‚Äôfloat64‚Äô ) When describing NumPy arrays, the number of ‚Äúdimensions,‚Äù dim, means the number of indices, which as we said can be as high as 32. What might be called the ‚Äúsize‚Äù or ‚Äúdimensions‚Äù of a matrix in mathematics is called the shapeof a NumPy array. 132 7 Matrix Computing and N‚ÄìD Searching Furthermore,NumPydoeshavea sizemethodthatreturnsthetotalnumberofelements.",3092
7.3 Matrices in Python. 7.3.2 NumPy Matrices,"BecausePython‚Äôslistsandtuplesareallonedimensional,ifwewantanarrayofaparticular shape,wecanattainthatbyaffixingthe reshapemethodwhenwecreatethearray.Where Python has a rangefunction to generate a sequence of numbers, NumPy has an arrange functionthatcreatesanarray,ratherthanalist.Hereweuseitandthenreshapethe1D arrayintoa3 √ó4array: 1 >>>importnumpy as np >>> np. arange (12) # List of 12 int‚Äôs in 1D array 3 a r r a y ( [ 0 ,1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 , 1 0 , 1 1 ] ) >>> np.arange(12).reshape((3,4)) # Create, shape to 3x4 array 5 array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], 7 [ 8, 9, 10, 11]]) >>> a = np.arange(12).reshape((3,4)) # Give array a name 9 >>> a array([[ 0, 1, 2, 3], 11 [ 4, 5, 6, 7], [ 8, 9, 10, 11]]) 13 >>> a . shape # Shape = ? (3L, 4L) 15 >>> a .ndim # Dimension? 2 17 >>> a . size # Size of a (number of elements)? 12 NotethatherewehaveimportedNumPyastheobject np,andthenaffixedthe arrangeand reshapemethodstothisobject.Wethencheckedtheshapeof a,andfoundittohavethree rowsandfourcolumnsoflongintegers(Python3mayjustsay int).Notetoo,asweseeon line9,NumPyusesparentheses()toindicatetheshapeofanarray,andso (3L,4L)indicates anarraywiththreerowsandfourcolumnsoflongint‚Äôs. Now that we have shapes on our minds, we should note that NumPy offers a number ofwaystochangeshapes.Forexample,wecantransposeanarraywiththe .Tmethod,or reshapeintoavector: >>>fromnumpyimport ‚àó 2 >>> a = arrange(12).reshape((3,4)) # Give array a name >>> a 4 array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], 6 [ 8, 9, 10, 11]]) >>> a .T # Transpose 8 array([[ 0, 4, 8], [1 , 5 , 9 ] , 10 [ 2, 6, 10], [ 3, 7, 11]]) 12 >>> b = a.reshape( (1,12) ) # Form vector length 12 >>> b 14 array([[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]]) Andagain, (1,12)indicatesanarraywithonerowand12columns.Yetanotherhandyway to take a matrix and extract just what you want from it is to use Python‚Äôs sliceoperator start:stop:step: totakeasliceoutofanarray: >>> a 2 array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], 4 [ 8, 9, 10, 11]]) 7.3 Matrices in Python 133 >>> a [:2 , :] # First 2 rows 6 array([[0, 1, 2, 3], [4, 5, 6, 7]]) 8 >>> a[:,1:3] # Columns 1 ‚àí3 array([[ 1, 2], 10 [5 , 6 ] , [ 9, 10]]) Note here how Python indices start counting from 0, and so 1:3 means indices 0, 1, 2 (without the 3). Slicing can be very useful in speeding up programs by picking out and placing in memory just the specific data elements from a large data set that need to be processed. This avoids the time-consuming jumping through large segments of memory, aswellasexcessivereadingfromdisk. Finally, we remind you that while all elements in a NumPy array must be of the same datatype,thatdatatypecanbecompound.Forexample,anarrayofarrays: 1 >>>fromnumpyimport ‚àó >>>M= array( [ (10, 20), (30,40), (50, 60) ] ) # Array of 3 arrays 3 >>> M array([[10, 20], 5 [30, 40], [50, 60]]) 7 >>> M. shape (3L, 2L) 9 >>> M. size 6 11 >>> M. dtype type(‚Äôint32‚Äô) Furthermore,anarraycanbecomposedofcomplexnumbersbyspecifyingthe complexdata typeasanoptiononthe arraycommand.NumPythenusesthe jsymbolfortheimaginary numberi: >>> c = array ( [ [1 , complex(2,2)], [ complex(3,2),4] ], dtype= complex ) 2 >>> c array([[ 1.+0.j, 2.+2.j], 4 [ 3.+2.j, 4.+0.j]]) InSection7.3.3,wediscussusingtruemathematicalmatriceswithNumPy,whichisone useofanarrayobject.Herewenotethatifyouwantedthefamiliarmatrixproductfrom twoarrays,youwouldusethe dotfunction,whereas *isusedforanelement-by-element (direct)product: >>> matrix1= array ( [[0 ,1] , [1 ,3]]) 2 >>> matrix1 array([[0, 1], 4 [1, 3]]) >>>print( dot(matrix1,matrix1) ) # Matrix or dot product 6 [[ 1 3] [ 3 10]] 8 >>>print(matrix1 ‚àómatrix1) # Element ‚àíby‚àíelement product [[0 1] 10 [1 9]]",3629
7.3.3 NumPy Linear Algebra Library,"134 7 Matrix Computing and N‚ÄìD Searching NumPyisactuallyoptimizedtoworkwellwitharrays,andinpartthisisbecausearrays arehandledandprocessedmuchasiftheyweresimple,scalarvariables.4Forexample,here isanotherexampleof slicing,atechniquethatisalsousedinordinaryPythonwithlistsand tuples,inwhichtwoindicesseparatedbyacolonindicatearange: fromvisualimport ‚àó 2stuff = zeros(10, float) t = arrange(4) stuff[3:7] = \sqrt(t+1) Here we start by creating the NumPy array stuffof floats, all of whose 10 elements are initialized to zero. Then we create the array tcontaining the four elements [0, 1, 2, 3] by assigning 4 variables uniformly in the range 0‚Äì4 (the ‚Äúa‚Äù in arangecreates floating- pointvariables, rangecreatesintegers).Next,weuseaslicetoassign[sqrt(0 +1),sqrt(1 +1), sqrt(2+1),sqrt(3 +1)]=[1,1.414,1.732,2]tothemiddleelementsofthe stuffarray.Note that the NumPy version of the sqrtfunction, one of many universal function ( functions) supportedbyNumPy,hastheamazingpropertyofautomaticallyoutputtinganarraywhose length is that of its argument, in this case, the array t. In general, much of the power of NumPycomesfromits broadcasting operation,anoperationinwhichvaluesareassigned tomultipleelementsviaasingleassignmentstatement.BroadcastingpermitsPythonto vec- torizearrayoperations,whichmeansthatthesameoperationcanbeperformedondifferent arrayelementsinparallel(ornearlyso).Broadcastingalsospeedsupprocessingbecause arrayoperationsuseCinsteadofPython,andwithaminimumofarraycopiesbeingmade. Hereisasimpleaspectofbroadcasting: w = zeros(100, float) w = 23.7 ThefirstlinecreatestheNumPyarray w,andthesecondline‚Äúbroadcasts‚Äùthevalue23.7to allelementsinthearray.TherearemanypossiblearrayoperationsinNumPyandvarious rulespertainingtothem;werecommendthattheserioususerexploretheextensiveNumPy documentationforadditionalinformation. 7.3.3 NumPy Linear Algebra Library ThearrayobjectsofNumPyarenotthesameasmathematicalmatrices.Fortunately,there isNumPy‚Äôs LinearAlgebra packagethattreats2Darraysasmathematicalmatrices,andalso providesasimpleinterfacetothepowerful linearalgebrapackage (LAPACK)linearalgebra library.Aswekeepsaying,thereismuchtobegainedinspeedandreliabilityfromusing theselibrariesratherthanwritingyourownmatrixroutines. Ourfirstexamplefromlinearalgebraisthestandardmatrixequation Ax=b, (7.26) wherewehaveusedaboldcharactertorepresenta1Dmatrix(avector).Equation(7.26) describesasetoflinearequationswith xanunknownvectorand Aaknownmatrix.Now wetakeAtobea3 √ó3,btobe3√ó1,andlettheprogramfigureoutthat xmustbe3 √ó1.5 4 WethankBruceSherwoodforhelpfulcommentsonthesepoints. 7.3 Matrices in Python 135 Westartbyimportingallthepackages,byinputtingamatrixandavector,andbyprinting outAandx: >>>fromnumpyimport ‚àó 2>>>fromnumpy.linalg import ‚àó >>> A = array( [ [1,2,3], [22,32,42], [55,66,100] ] ) # Array of arrays >>>print(‚ÄôA =‚Äô,A ) A=[ [ 1 2 3 ] 6[ 22 32 42] [ 55 66 100]] >>> b = array([1,2,3]) >>>print(‚Äôb =‚Äô,b ) 10b=[ 123 ] SeeingthatwehavethematricesAand b,wecangoaheadandsolve Ax=busingNumPy‚Äôs solvecommand,andthentesthowclose Ax‚àíbistoazerovector: >>>fromnumpy.linalg importsolve 2>>> x = solve (A, b) # Finds solution >>>print(‚Äôx =‚Äô,x ) x=[‚àí1.4057971 ‚àí0.1884058 0.92753623] # The solution >>>print(‚ÄôResidual =‚Äô ,d o t ( A , x ) ‚àíb) #L H S‚àíRHS 6 Residual = [4.44089210e ‚àí16 0.00000000e+00 ‚àí3.55271368e ‚àí15] Thisisreallyquiteimpressive.Wehavesolvedtheentiresetoflinearequations(byelim- ination)withjustthesinglecommand solve,performedamatrixmultiplicationwiththe singlecommand dot,didamatrixsubtractionwiththeusualoperator,andareleftwitha residualessentiallyequaltomachineprecision. Althoughtherearemoreefficientnumericalapproaches,anotherwaytosolve Ax=b (7.27) istocalculatetheinverse A‚àí1,andthenmultiplybothsidesoftheequationbytheinverse, yielding x=A‚àí1b. (7.28) 1 >>>fromnumpy. linalg import in >>> dot ( in(A), A) # Test inverse 3 array([[ 1.00000000e+00, ‚àí1.33226763e ‚àí15,‚àí1.77635684e ‚àí15], 5 [ 8.88178420e ‚àí16, 1.00000000e+00, 0.00000000e+00], [‚àí4.44089210e ‚àí16, 4.44089210e ‚àí16, 1.00000000e+00]]) 7 >>>print(‚Äôx =‚Äô, multiply( in(A), b)) x=[‚àí1.4057971 ‚àí0.1884058 0.92753623] # Solution 9 >>>print(‚ÄôResidual =‚Äô ,d o t ( A , x ) ‚àíb) 11 Residual = [ 4.44089210e ‚àí16 0.00000000e+00 ‚àí3.55271368e ‚àí15] Herewefirsttestedthat in(A)isinfacttheinverseof Abyseeingif Atimes in(A)equalsthe identitymatrix.Thenweusedtheinversetosolvethematrixequationdirectly,andgotthe sameanswerasbeforeandanerroratthelevelofmachineprecisionasbefore. 5 Don‚Äôtbebotheredbythefactthatalthoughwethinkofthesevectorsas3 √ó1,theysometimesgetprinted outas1√ó3;thinkofallthetreesbeingsaved.",4550
7.4 Exercise Tests Before Use,"136 7 Matrix Computing and N‚ÄìD Searching Oursecondexamplecomesfromfindingtheprincipal-axesofacube,andrequiresusto find a coordinate system in which the inertia tensor is diagonal. This entails solving the eigenvalueproblem, Iùùé=ùúÜùùé, (7.29) whereIistheinertiamatrix(tensor), ùùéisanunknowneigenvector,and ùúÜisanunknown eigenvalue.Theprogram Eigen.pysolvesfortheeigenvaluesandvectors,andshowshow easyitistodealwithmatrices.Hereisaninterpretiveversion: 1 >>>fromnumpyimport ‚àó >>>fromnumpy. linalg importbig 3 >>> I = array( [[2./3, ‚àí1./4], [ ‚àí1./4,2./3]] ) >>>print(‚ÄôI = ‚Äô,I ) 5 I= [[ 0.66666667 ‚àí0.25 ] 7 [‚àí0.25 0.66666667]] >>> Es, evectors = big(A) # Solves eigenvalue problem 9 >>>print(‚ÄôEigenvalues =‚Äô ,E s , ‚Äô  Eigenvector Matrix = ‚Äô , evectors) Eigenvalues = [ 0.91666667 0.41666667] 11 Eigenvector Matrix = [[ 0.70710678 0.70710678] 13 [‚àí0.70710678 0.70710678]] >>> vec = array([ evectors[0, 0], evectors[1, 0] ] ) 15 >>> LHS = dot (I , vec ) # Matrix x vector >>> RHS = Es[0] ‚àóvec # Scalar multi 17 >>>print(‚ÄôLHS - RHS =‚Äô ,L H S‚àíRHS) #T e s tf o rz e r o LHS‚àíRHS = [ 1.11022302e ‚àí16‚àí1.11022302e ‚àí16] Weseehow,aftersettingupthearray Ionline3,wesolvedforitseigenvaluesandeigenvec- torswiththesinglestatement Es, evectors = big(I) online8.Wethenextractedthefirst eigenvectoronline14,anduseit,alongwiththefirsteigenvalue,tocheckthat(7.29)isin factsatisfiedtomachineprecision. Well,wethinkbynowyouhavesomeideaofthepowerofNumPy.InTable7.1wegive somemoreNumPyoperators. 7.4 Exercise: Tests Before Use Beforeyoudirectthecomputertogooffcrunchingnumbersonamillionelementsofsome matrix,it‚Äôsagoodideatotryoutyourproceduresonasmallmatrix,especiallyoneforwhich youknowtherightanswer.Inthisway,itwilltakeyouonlyashorttimetorealizehowhard itistogetthecallingprocedureperfectlyright.Herearesomeexercises. 1) Findthenumericalinverseof A=‚é° ‚é¢ ‚é¢‚é£+4‚àí2+1 +3+6‚àí4 +2+1+8‚é§ ‚é• ‚é•‚é¶. a) Asageneralcheck,applicableevenifyoudonotknowtheanalyticanswer,check your inverse in both directions; that is, check that AA‚àí1=A‚àí1A=I, and note the number of decimal places to which this is true. This also gives you some idea of theprecisionofyourcalculation. 7.4 Exercise: Tests Before Use 137 Table 7.1 The operators of NumPy and their effects. Operator Effect Operator Effect dot(a,b[,out]) Dotproductarrays vdot(a,b) Dotproduct inner(a,b) Innerproductarrays outer(a,b) Outerproduct tensordot(a,b) Tensordotproduct einsum() Einsteinsum linalg.matrix_power(M,n) Matrixtopower nkron(a,b) Kroneckerproduct linalg.cholesky(a) Choleskydecomp linalg.qr(a) QRfactorization linalg.svd(a) Singularvaldecomp linalg.eig(a) Eigenproblem linalg.eigh(a) Hermitianeigen linalg.eigvals(a) Generaleigen linalg.eigvalsh(a) Hermitianeigenvals linalg.norm(x) Matrixnorm linalg.cond(x) Conditionnumber linalg.det(a) Determinant linalg.slogdet(a) Signandlog(det) trace(a) Diagnolsum linalg.solve(a,b) Solveequation linalg.tensorsolve(a,b) Solve ax=b linalg.lstsq(a,b) Least-squaressolve linalg.inv(a) Inverse linalg.pinv(a) Penroseinverse linalg.tensorinv(a) InverseN‚ÄìDarray b) Determinethenumberofdecimalplacesofagreementthereisbetweenyournumer- icalinverseandtheanalyticresult: A‚àí1=1 263‚é° ‚é¢ ‚é¢‚é£+52+17+2 ‚àí32+30+19 ‚àí9‚àí8+30‚é§ ‚é• ‚é•‚é¶.Isthissimilartothe errorinAA‚àí1? 2) Considerthesamematrix Aasbefore,herebeingusedtodescribethreesimultaneous linearequations, Ax=b,orexplicitly, ‚é° ‚é¢ ‚é¢‚é£a00a01a02 a10a11a12 a20a21a22‚é§ ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢‚é£x0 x1 x2‚é§ ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢‚é£b0 b1 b2‚é§ ‚é• ‚é•‚é¶. (7.30) Now the vector bon the RHS is assumed known, and the problem is to solve for the vectorx.Useanappropriatesubroutinetosolvetheseequationsforthethreedifferent xvectorsappropriatetothesethreedifferent bvaluesontheRHS: b1=‚é° ‚é¢ ‚é¢‚é£+12 ‚àí25 +32‚é§ ‚é• ‚é•‚é¶,b2=‚é° ‚é¢ ‚é¢‚é£+4 ‚àí10 +22‚é§ ‚é• ‚é•‚é¶,b3=‚é° ‚é¢ ‚é¢‚é£+20 ‚àí30 +40‚é§ ‚é• ‚é•‚é¶. Thesolutionsshouldbe x1=‚é° ‚é¢ ‚é¢‚é£+1 ‚àí2 +4‚é§ ‚é• ‚é•‚é¶,x2=‚é° ‚é¢ ‚é¢‚é£+0.312 ‚àí0.038 +2.677‚é§ ‚é• ‚é•‚é¶,x3=‚é° ‚é¢ ‚é¢‚é£+2.319 ‚àí2.965 +4.790‚é§ ‚é• ‚é•‚é¶. (7.31) 3) Considerthematrix A=[ùõºùõΩ ‚àíùõΩùõº] ,whereyouarefreetouseanyvaluesyouwantfor ùõº andùõΩ.Useanumericaleigenvaluesolvertoshowthattheeigenvaluesandeigenvectors 138 7 Matrix Computing and N‚ÄìD Searching arethecomplexconjugates x1,2=[+1 ‚àìi] ,ùúÜ1,2=ùõº‚àìiùõΩ. (7.32) 4) Useyoureigenvaluesolvertofindtheeigenvaluesofthematrix A=‚é° ‚é¢ ‚é¢‚é£‚àí2+2‚àí3 +2+1‚àí6 ‚àí1‚àí2+0‚é§ ‚é• ‚é•‚é¶. (7.33) a) Verify that you obtain the eigenvalues ùúÜ1=5,ùúÜ2=ùúÜ3=‚àí3. Beware, double roots cancauseproblems.Inparticular,thereisauniquenessissuewiththeireigenvectors becauseanycombinationoftheseeigenvectorsisalsoaneigenvector. b) Verifythattheeigenvectorfor ùúÜ1=5isproportionalto x1=1‚àö 6‚é° ‚é¢ ‚é¢‚é£‚àí1 ‚àí2 +1‚é§ ‚é• ‚é•‚é¶. (7.34) c) Theeigenvalue ‚àí3correspondstoadoubleroot.Thismeansthatthecorresponding eigenvectorsaredegenerate,whichinturnmeansthattheyarenotunique.Twolin- earlyindependentonesare x2=1‚àö 5‚é° ‚é¢ ‚é¢‚é£‚àí2 +1 +0‚é§ ‚é• ‚é•‚é¶,x3=1‚àö 10‚é° ‚é¢ ‚é¢‚é£3 0 1‚é§ ‚é• ‚é•‚é¶. (7.35) Inthiscase,it‚Äôsnotclearwhatyoureigenvaluesolverwillgivefortheeigenvectors. Trytofindarelationshipbetweenyourcomputedeigenvectorswiththeeigenvalue ‚àí3andthesetwolinearlyindependentones. 5) Imagine that your model of some physical system results in N=100 coupled linear equationsin Nunknowns: a00y0+a01y1+¬∑¬∑¬∑+a0(N‚àí1)yN‚àí1=b0, a10y0+a11y1+¬∑¬∑¬∑+a1(N‚àí1)yN‚àí1=b1, ¬∑¬∑¬∑ a(N‚àí1)0y0+a(N‚àí1)1y1+¬∑¬∑¬∑+a(N‚àí1)(N‚àí1)yN‚àí1=bN‚àí1. In many cases the aandbvalues are known, so your exercise is to solve for all the x values,taking aastheHilbertmatrixand basitsfirstcolumn: [aij]=a=[ 1 i+j‚àí1] =‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£11 21 31 4¬∑¬∑¬∑1 100 1 21 31 41 5¬∑¬∑¬∑1 101 ... 1 1001 101¬∑¬∑¬∑ ¬∑¬∑¬∑1 199‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶, (7.36) [bi]=b=[1 i] =‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 1‚àï2 1‚àï3 ... 1‚àï100‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (7.37)",5437
7.5 Solution to String Problem. 7.6 Spin States and Hyperfine Structure,"7.6 Spin States and HyperÔ¨Åne Structure 139 Comparetotheanalyticsolution ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y1 y2 ... yN‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 0 ... 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (7.38) 7.5 Solution to String Problem In Section 7.1 we set up the solution to our two masses on a string problem as a matrix problem.Nowwehavethematrixtoolsneededtosolveit.Your problemistocheckout thephysicalreasonablenessofthesolutionforavarietyofweightsandlengths.Youshould check that the deduced tensions are positive and that the deduced angles correspond to a physical geometry (e.g., with a sketch). Inasmuch as this is a realistic problem, we know that the sine and cosine functions must be less than 1 in magnitude and that the tensions should be similar in magnitude to the weights of the spheres. Our solution NewtonNDanimate.py ,whichisgiveninListing7.1,showsgraphicallythestepsinthesearch. 1) See at what point your initial guess for the angles of the strings gets so bad that the computerisunabletofindaphysicalsolution. 2) Apossibleproblemwiththeformalismwehavejustlaidoutisthatbyincorporatingthe identitysin2ùúÉi+cos2ùúÉi=1intotheequations,wemaybediscardingsomeinformation aboutthesignofsin ùúÉorcosùúÉ.IfyoulookatFigure7.1,youcanobservethatforsome valuesoftheweightsandlengths, ùúÉ2mayturnouttobenegative,yetcos ùúÉshouldremain positive. We can build this condition into our equations by replacing f7‚àíf9withf‚Ä≤s basedontheform f7=x4‚àí‚àö 1‚àíx2 1,f8=x5‚àí‚àö 1‚àíx2 2,f9=x6‚àí‚àö 1‚àíx2 3. (7.39) Seeifthismakesanydifferenceinthesolutionsobtained. 3)‚äôSolvethesimilarthree-massproblem.Theapproachisthesame,butthenumberof equationsislarger. 7.6 Spin States and HyperÔ¨Åne Structure The energylevelsofhydrogenexhibita finestructure splittingarisingfromthecouplingof theelectron‚Äôsspintoitsorbitalangularmomentum.(Or,youcanthinkofthisasthecou- plingsofmagneticmoments.)Inaddition,thesefinelysplitlevelsexhibitasmaller hyperfine splittingarisingfromthecouplingoftheelectron‚Äôsspintotheproton‚Äôsspin.InGaussian CGSunits,themagneticmomentofaparticleofcharge qisrelatedtoitsspin Sby ùùÅ=gq 2mS, (7.40) 140 7 Matrix Computing and N‚ÄìD Searching wheregistheparticle‚Äôs gfactorandmitsmass.Anelectronhas q=‚àíe,S=‚Ñè 2ùùà,g‚âÉ‚àí2,‚áíùùÅe‚âÉ( ‚àí2)‚àíe 2meùúé 2=ùúáBùùà, (7.41) ùúáB=e‚Ñè 2me=5.05082√ó10‚àí27J/T, (7.42) whereùúáBistheelectron‚ÄôsBohrmagneton.Becausetheproton‚Äôsmassis ‚àº2000timeslarger thantheelectron‚Äôsmass,theproton‚ÄôsBohrmagnetonandmagneticinteractionis ‚àº2000 timessmallerthantheelectron‚Äôs: ùúáB|p=‚àíe‚Ñè 2mp=‚àíme mpùúáB|e=‚àí1 1836.15ùúáB. (7.43) Eventhoughtheelectron‚Äôsandtheproton‚Äôsspins(internaldegreesoffreedom)existin differentspaces,theyarebothspin1/2particles,andsobothcanbe(separately)represented bythePaulimatrices: ùùà=ùúéxÃÇ ùúñx+ùúéyÃÇ ùúñy+ùúézÃÇ ùúñz, (7.44) ùúéx=[01 10] ,ùúéy=[0‚àíi i0] ,ùúéz=[10 0‚àí1] . (7.45) IntermsofthePaulimatrices,theelectron‚Äìprotoninteractionis V=Wùùàe‚ãÖùùàp=W(ùúée xùúép x+ùúée yùúép y+ùúée zùúép z). (7.46) Thespin1/2statesfortheelectronandtheproton,each,canbeeitherupordown: |ùõº‚ü©=|‚Üë‚ü©=[1 0] , |ùõΩ‚ü©=|‚Üì‚ü©=[0 1] . (7.47) 1) Verify,thatifboththeelectronandtheprotonstartoffinspin-upstates, |ùúì‚ü©=|ùõºeùõºp‚ü©, (7.48) thentheinteraction(7.46)producesthemixedstate V|ùúì‚ü©=Wùùàe‚ãÖùùàp|ùõºeùõºp‚ü©=W(ùúée xùúép x+ùúée yùúép y+ùúée zùúép z)|ùõºeùõºp‚ü© (7.49) =|ùõΩeùõΩp‚ü©+i|ùõΩeùõΩp‚ü©+|ùõºeùõºp‚ü©. (7.50) 2) Showthattheinteractionmatrixforthe |ùõºeùõºp‚ü©stateis ‚ü®ùõºeùõºp|V|ùõºeùõºp‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£W00 0 0‚àíW2W0 02W‚àíW0 00 0 W‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (7.51) 3) Useasymbolicmanipulationprogramtoshowthattheeigenvaluesof Vare: ‚àí3W(multiplicity3,tripletstate) ,W(multiplicity1,singletstate) ,(7.52) where the triplet state refers to ||S=1,mS=¬±1,0‚ü©, and the singlet state to ||S=0,mS=0‚ü©.Ourprogram Hyperfine.py isgiveninListing7.2.",3509
7.7 Speeding Up Matrix Computing. 7.7.1 Vectorization,"7.7 Speeding Up Matrix Computing ‚äô141 4) Evaluate the numerical value for the hyperfine splitting of the 1S state Bransden and Joachain[1991]: ùúà=‚ÑèŒîE=4W ‚Ñè. (7.53) ComparethistothevaluemeasuredbyBaileyandTownsend[1921]: ùúà=1420.405751800 ¬±0.000000028Hz(measured). (7.54) In addition to being one of the most accurately measured quantities in physics, you shouldfindthat(7.54)agreeswiththeory. 7.7 Speeding Up Matrix Computing ‚äô ProgramswritteninFortranandCtendtobefasterthanthosewritteninPythonbecausethe formerarecompiledlanguages(theentireprogramisprocessedinonefellswoop),while Python is interpreted line by line, although sometimes compiled. However, the NumPy linear algebra routines are mainly written in C and C ++, and are fast. In any case, here wegivesometechniquestohelpyouspeedupyourlargematrixcomputations. 7.7.1 Vectorization ApowerfulfeatureofNumPyisitshigh-level vectorization .Thisisasimpleandautomatic process in which a single operation acts on an entire array, as opposed to each element individually,andleadstoorder-of-magnitudespeedups.Ourexampleswillusesmallmatri- ces,andsowhiletherelativespeedupwillbesignificant,theabsolutesavingsoftimewill stillbesmall.However,ifyouweredealingwithverylargematrices,andespeciallydoing itofteninaprogram,thenspeedingupyourprogrammaybeworththeeffort. Hereisourcode TuneNumPy.py thatcomparesthespeedofacalculationusinga forloopto evaluateafunctionforeachof100,000elementsinanarray,versusthespeedusingNumPy‚Äôs vectoredevaluationofthatfunctionforanarrayobject: # TuneNumpy.py: Comparison of NumPy op versus for loop 2fromdateline importdateline importnumpy as np deff(x):returnx‚àó‚àó2‚àí3‚àóx+4 6x = np.arange(1e5) # An array of 100,000 integers forjin range (0, 3): # Repeat comparison three time t1 = datetime.now() y=[ f ( i ) foriinx] # The for loop 10t2 = datetime.now() print(‚Äô For for loop, t2-t1 =‚Äô ,t 2‚àít1) t1 = datetime.now() y=f ( x ) # Vectored evaluation 14t2 = datetime.now() print(‚Äô For vector function, t2-t1 =‚Äô ,t 2‚àít1) Output: Forforloop, t2 ‚àít1 = 0:00:00.384000 18For vector function , t2 ‚àít1 = 0:00:00.009000 Recall that we defined strideas the amount of memory skipped in order to get to the nextelementneededinacalculation.Itisimportanttohaveyourprogramminimizestride 142 7 Matrix Computing and N‚ÄìD Searching in order to avoid jumping through memory to find a needed value. For example, for a 1000√ó1000array,thecomputermovesonewordtogettothenextcolumn,but1000words togettothenextrow.Clearlybettertodoacolumn-by-columncalculationthanarow-by- rowone.Toseethisinaction,weentera3 √ó3arrayofintegersusingNumPy‚Äôs arangeto createa1Darray.Wethenreshapeitintoa3 √ó3array,anddeterminethestridesforrows andcolumnscalls: >>>fromnumpyimport ‚àó 2 >>> A = arange(0,90,10) >>> A 4 array([ 0, 10, 20, 30, 40, 50, 60, 70, 80]) >>> A = A.reshape((3,3)) 6 >>> A array([[ 0, 10, 20], 8 [30, 40, 50], [60, 70, 80]]) 10 >>> A. strides (12, 4) Line11tellsusthatittakes12bytes(3words)togettothesamepositioninthenextrow,but only4bytes(oneword)togettothesamepositioninthenextcolumn.It‚Äôsclearlycheaper togofromcolumntocolumnthanrowtorow. AneasywaytocutdownonmemoryjumpingistousePython‚Äôs sliceoperatorthatextracts justthedesiredpartofalist(liketakinga‚Äúslice‚Äùthroughthecenterofajellydoughnut): ListName[StartIndex:StopBeforeIndex:Step] . Theconventionisthatifnoargumentisgiven,thentheslicestartsat0andstopsattheend ofthelist.Forexample: 1 >>> A = arange(0,90,10).reshape((3,3)) >>> A 3 array([[ 0, 10, 20], [30, 40, 50], 5 [60, 70, 80]]) >>> A[:2 ,:] # First two rows (start at 2, go to end) 7 array([[ 0, 10, 20], [30, 40, 50]]) 9 >>> A[:,1:3] #C o l u m n s1 ‚àí3( s t a r ta t1 ,e n da t4 ) array([[10, 20], 11 [40, 50], [70, 80]]) 13 >>> A[ : : 2 , : ] # Every second row array([[ 0, 10, 20], 15 [60, 70, 80]]) Thisiscalled view-basedindexing ,withtheindexednotationreturninganewarrayobject thatpointstotheaddressoftheoriginaldata,asopposedtostoringthevaluesofthenew array(think‚Äúpointers‚ÄùinC).Forinstance,youcanoptimizeacalculationofforwardand centraldifferencederivativesquiteelegantly: 1 >>> x = arange(0,20,2) >>> x 3 a r r a y ( [ 0 ,2 ,4 ,6 ,8 , 1 0 , 1 2 , 1 4 , 1 6 , 1 8 ] ) >>> y = x ‚àó‚àó2 5 >>> y",4139
7.8 Code Listing,"7.7 Speeding Up Matrix Computing ‚äô143 array([ 0, 4, 16, 36, 64, 100, 144, 196, 256, 324], dtype=int32) 7 >>> dy_dx = (( y[1:] ‚àíy[:1])/(x[1:] ‚àíx[:‚àí1])) # Forward difference >>> dy_dx 9 array([ 2., 8., 18., 32., 50., 72., 98., 128., 162.]) >>> dy_dx_c = (( y[2:] ‚àíy[:‚àí2])/(x[2:] ‚àíx[:‚àí2])) # Central difference 11 >>> dy_dx_c array([ 4., 8., 12., 16., 20., 24., 28., 32.]) Wenotethatthevaluesofthederivativesaredifferentbecauseforwarddifferenceisevalu- atedatthestartoftheintervalwhilecentraldifferenceatthecenter. 7.7.2 Speedup Exercises 1)Timinganoperation importtime start = time.time() print(\""hello\"") 4end = time.time() print(end‚àístart) 2) Runthetwosimplecodeslistedbelow,timinghowlongeachtakes.Notethatalthough eachhasthesamenumberofarithmeticoperations,onetakessignificantlymoretime becauseitmakeslargejumpsthroughmemory. Sequentialcolumnreferences forj = 1, 999999; x(j) =m(1,j) // Sequential column reference Sequentialrowreferences forj = 1, 999999; 2x(j) =m(j,1) // Sequential row reference 3) Testtheeffectofstrideonyourmachinebycomparingthetimeittakestorunthesetwo programs.Runforincreasingcolumnsize idiomandcomparethetimesforloop Aversus thoseforloop B.LoopAstepsthroughthematrix vecincolumnorder,whileloop Bsteps throughinroworder.Bothloopstakeusthroughalltheelementsofthematrix,butthe strideisdifferent. LoopAbad(large)stride Dimension vec(N, M) // Stride 1 fetch (f90) 2 forj=1 ,M ; fori=1, N; Ansi = Ansi + vec(i,j) ‚àóvec(i,j) LoopBgood(small)stride 1Dimension vec(N, M) // Stride dim fetch (f90) fori=1 ,N ; forj=1, M; Ansi = Ansi + vec(i,j) ‚àóvec(i,j) 144 7 Matrix Computing and N‚ÄìD Searching 4) Thepenultimateexampleofmemoryusageislarge-matrixmultiplication: [C]=[A]√ó[B]‚áícij=N‚àë k=1aik√óbkj. (7.55) Testtheeffectofstrideonyourmachinebycomparingthetimeittakestorunthesetwo programs.Runforincreasingcolumnsize N GOODPython(minstride) 1fori=1 ,N ;{ / /R o w forj = 1, N; { // Column c(i,j) = 0.0 // Initialize fork=1 ,N ; { 5 c(i,j)=c(i,j)+a(i,k) ‚àób(k,j) }}} // Accumulate BADPython(maxstride) forj = 1, N; { // Initialization fori=1 ,N ;{ 3 c(i,j) = 0.0 } fork=1 ,N ; { fori = 1, N; {c(i,j) = c(i,j) + a(i,k) ‚àób(k,j) }}} 5) Use NumPy‚Äôs vectorized function evaluation to determine the speedup in the matrix multiplication [A][B],wherethematricescontainatleast105floating-pointnumbers. Compare the direct multiplication to application of the elementary rule for each element: [BA]ij=‚àë kaikbkj. (7.56) 6) DeterminethespeedupobtainedbyusingPythonstrippingtoreducestrideinevaluating the forward-difference and central-difference derivatives over an array of at least 105 floating-pointnumbers. 7.8 Code Listing Listing7.1 ThecodeNewtonNDanimate.py showsthestep-by-stepsearchforsolution ofthetwo-mass-on-a-stringproblemviaaNewton‚ÄìRaphsonsearch. # NewtonNDanimate.py: MultiDimension Newton Search 3fromvisualimport ‚àó fromnumpy. linalg importsolve fromvisual.graph import ‚àó 7scene = display(x=0,y=0,width=500,height=500, title= ‚ÄôString and masses configuration‚Äô ) tempe = curve(x= range(0,500),color=color.black) 11n=9 eps = 1e ‚àí3 deriv = zeros( (n, n), float) f=z e r o s (( n ) , float) 15x = array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1., 1., 1.]) 7.8 Code Listing 145 defplotconfig(): forobjinscene.objects: 19 obj.visible=0 # Erase previous configuration L1 = 3.0 L2 = 4.0 L3 = 4.0 23xa = L1 ‚àóx[3] #L 1 ‚àócos(th1) ya = L1 ‚àóx[0] # L1 sin(th1) xb = xa+L2 ‚àóx[4] #L 1 ‚àócos(th1)+L2 ‚àócos(th2) yb = ya+L2 ‚àóx[1] #L 1 ‚àósin(th1)+L2 ‚àósen(th2) 27xc = xb+L3 ‚àóx[5] #L 1 ‚àócos(th1)+L2 ‚àócos(th2)+L3 ‚àócos(th3) yc = yb ‚àíL3‚àóx[2] #L 1 ‚àósin(th1)+L2 ‚àósen(th2) ‚àíL3‚àósin(th3) mx = 100.0 # for linear coordinate transformation bx =‚àí500.0 #f r o m0 = ‚àó<‚àóx=‚àó<‚àó10 31my =‚àí100.0 #t o ‚àí500 = ‚àó<‚àóx_window=>500 by = 400.0 # same transformation for y xap = mx ‚àóxa+bx # to keep aspect ratio yap = my ‚àóya+by 35ball1 = sphere(pos=(xap,yap), color=color.cyan,radius=15) xbp = mx ‚àóxb+bx ybp = my ‚àóyb+by ball2 = sphere(pos=(xbp,ybp), color=color.cyan,radius=25) 39xcp = mx ‚àóxc+bx ycp = my ‚àóyc+by x0 = mx ‚àó0+bx y0 = my ‚àó0+by 43line1 = curve(pos=[(x0,y0),(xap,yap)], color=color.yellow,radius=4) line2 = curve(pos=[(xap,yap),(xbp,ybp)], color=color.yellow,radius=4) line3 = curve(pos=[(xbp,ybp),(xcp,ycp)], color=color.yellow,radius=4) topline = curve(pos=[(x0,y0),(xcp,ycp)], color=color.red,radius=4) 47 defF(x, f): # F function f[0] =3 ‚àóx[3] + 4 ‚àóx[4] + 4 ‚àóx[5]‚àí8.0 f[1] =3 ‚àóx[0] + 4 ‚àóx[1]‚àí4‚àóx[2] 51f[2] =x[6] ‚àóx[0]‚àíx[7] ‚àóx[1]‚àí10.0 f[3] =x[6] ‚àóx[3]‚àíx[7] ‚àóx[4] f[4] =x[7] ‚àóx[1] + x[8] ‚àóx[2]‚àí20.0 f[5] =x[7] ‚àóx[4]‚àíx[8] ‚àóx[5] 55f[6] =pow(x[0], 2) + pow(x[3], 2) ‚àí1.0 f[7] =pow(x[1], 2) + pow(x[4], 2) ‚àí1.0 f[8] =pow(x[2], 2) + pow(x[5], 2) ‚àí1.0 59defdFi_dXj(x, deriv , n): # Derivatives h=1 e‚àí4 forjin range (0, n): temp = x[j] 63 x[j] = x[j] + h/2. F(x, f) foriin range (0, n): deriv[i, j] = f[i] x[j] = temp 67forjin range (0, n): temp = x[j] x[j] = x[j] ‚àíh/2. F(x, f) 71 foriin range (0, n): deriv[i, j] = (deriv[i, j] ‚àíf[i])/h x[j] = temp foritin range (1, 100): 75 rate(1) # 1 second between graphs F(x, f) dFi_dXj(x, deriv , n) B = array([[ ‚àíf[0]], [ ‚àíf[1]], [ ‚àíf[2]], [ ‚àíf[3]], [ ‚àíf[4]], [ ‚àíf[5]],\ 79 [‚àíf[6]], [ ‚àíf[7]], [ ‚àíf[8]]]) sol = solve(deriv, B) dx = take(sol, (0, ), 1) # First column of sol foriin range (0, n): 83 x[i] = x[i] + dx[i] plotconfig() errX = errF = errXi = 0.0 foriin range (0, n): 146 7 Matrix Computing and N‚ÄìD Searching 87 if( x[i] .= 0.): errXi = abs(dx[i]/x[i]) else: errXi = abs(dx[i]) if( errXi > errX): errX = errXi if(abs(f[i]) > errF ): errF = abs(f[i]) 91 if( (errX <=eps)and(errF<=eps) ): break print(‚ÄôNumber of iterations = ‚Äô ,i t , \""  Final Solution:\"" ) foriin range (0, n): 95 print(‚Äôx[‚Äô,i , ‚Äô] = ‚Äô,x [ i ] ) Listing7.2 Hyperfine.py HyperfinesplittinginHusingsymbolicpackageSymPy. # Hyperfine.py: Hydrogen hyperfine structure using Sympy 3fromsympyimport ‚àó importnumpy as np, matplotlib.pyplot as plt W, mue, mup, B = symbols( ‚ÄôW mu_e mu_p B‚Äô ) # Symbols & Hamiltonian 7H = Matrix([[W,0,0,0],[0, ‚àíW,2‚àóW,0],[0,2 ‚àóW,‚àíW,0],[0,0,0,W]]) Hmag = Matrix([[ ‚àí(mue+mup) ‚àóB,0,0,0],[0, ‚àí(mue‚àímup) ‚àóB,0,0],[0,0, ‚àí(‚àímue+mup) ‚àóB,0], [0,0,0,(mue+mup) ‚àóB]]) # H with external B print(\""  Hyperfine Hamiltonian H =\"" ,H) 11print(\""  Eigenvalues and multiplicities of H =\"" ,H.eigenvals() ) print(\""  Hmag =\"" ,H m a g ) Htot = H + Hmag # Hamiltonian + pertubation print(\""  Htot = H + Hmag =\"" ,H t o t ) 15print(\""  Eigenvalues of matrix HB\"" ) e1, e2, e3, e4 = Htot.eigenvals() # 4 eigenvalues print(\""e 1=\"" ,e 1 , \""  e2 = \"" ,e 2 , \""  e3 = \"" ,e 3 , \""  e4 = \"" ,e 4 ) print(\""  After substitute mu_e = 1, and mu_p = 0 in eigenvalues\"" ) 19print(\""e 1=\"" ,e1.subs([(mue,1) ,(mup,0)]), \""  e2 = \"",e2.subs([(mue,1) ,(mup,0)])) print(\""e 3=\"" ,e3.subs([(mue,1) ,(mup,0)]), \""  e4 = \"" ,e4.subs([(mue,1) ,(mup,0)])) b = np.arange(0,4,0.1) E=1 23E4 =‚àíE+n p .s q r t( b ‚àó‚àó2+ 4 ‚àóE‚àó‚àó2) E3 = E ‚àíb E2 = E + b E1 =‚àíE‚àínp. sqrt(b ‚àó‚àó2+ 4 ‚àóE‚àó‚àó2) 27plt.figure() plt.plot(b,E1, label= ‚ÄôE1‚Äô); plt.plot(b,E2, label= ‚ÄôE2‚Äô) plt.plot(b,E3, label= ‚ÄôE3‚Äô); plt.plot(b,E4, label= ‚ÄôE4‚Äô) plt.legend(); plt.text( ‚àí0.4,1, ‚ÄôE‚Äô) 31plt.xlabel( ‚Äô Magnetic Field B‚Äô ) plt.title( ‚ÄôHyperfine Splitting of H Atom 1S Level‚Äô ) plt .show()",7099
Chapter 8 Differential Equations and Nonlinear Oscillations. 8.1 Nonlinear Oscillators,"147 8 Differential Equations and Nonlinear Oscillations In this chapter we develop numerical methods for solving ordinary differential equations, and focus on applying those tools to nonlinear systems. We start with simple systems that have analytic solutions, and use them to test various differential-equation solvers. We then let the oscillations become large so that nonlinear effects are important, and investigate nonlinear resonances and beating. In Chapter 16, Continuous Nonlinear Dynamics, we make a related study of the realistic pendulum and its chaotic behavior . 8.1 Nonlinear Oscillators Figure8.1showsamass mattachedtoaspringthatexertsarestoringforcetowardtheorigin, as well as a hand that exerts a time-dependent external force on the mass. The restoring forceexertedbythespringisnonlinear. Problem Solveforthemotionofthemassasafunctionoftimeforanarbitraryrestoring force.Youmayassumethemotionisconstrainedtoonedimension. This is a classical mechanics problem and so Newton‚Äôs second law provides us with the equationofmotion Fk(x)+Fext(x,t)=md2x dt2, (8.1) whereFk(x)isanarbitraryrestoringforceexertedbythespringand Fext(x,t)istheexternal force.Becausewearenottoldjusthowthespringdepartsfrombeinglinear,we‚Äôlljusttry outsomedifferentspringmodels.Asourfirstmodel,we‚Äôlllookatapotentialthatislinear forsmalldisplacements x,butbecomesnonlinearforlarge xvalues: V(x)‚âÉ1 2kx2( 1‚àí2 3ùõºx) , (8.2) ‚áíFk(x)=‚àídV(x) dx=‚àíkx(1‚àíùõºx) (8.3) ‚áímd2x dt2=‚àíkx(1‚àíùõºx), (8.4) ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 148 8 Differential Equations and Nonlinear Oscillations Fext(x,t)Fk(x) xFigure 8.1 Am a s s m(the block) attached to a spring with restoring force Fk(x)as well as driven by an external time-dependent driving force (the hand). where we have omitted the time-dependent external force. Equation (8.4) is the second- order ordinary differential equation (ODE) we need to solve. If ùõºx‚â™1, we should have essentiallyharmonicmotion,butas x‚Üí1‚àïùõºtheanharmoniceffectsshouldincrease. Wecanunderstandthebasicphysicsofthismodelbylookingatthecurvesontheleftin Figure8.2.Aslongas x<1‚àïùõº,therewillbea restoringforce andthemotionwillbeperiodic (repeatedexactlyandindefinitelyintime),thoughitmaynotbeharmonic.Iftheamplitude ofoscillationislarge,therewillbeanasymmetryinthemotiontotherightandleftofthe equilibriumposition.Andif x>1‚àïùõº,theforcewillbecomerepulsiveandthemasswillbe pushedawayfromtheorigin. Asasecondmodelofanonlinearoscillator,weassumethatthespring‚Äôspotentialfunction isproportionaltosomearbitrary evenpowerpofx: V(x)=1 pkxp,(peven). (8.5) Werequireaneven ptoensurethattheforce, Fk(x)=‚àídV(x) dx=‚àíkxp‚àí1, (8.6) contains an odd power of p, which guarantees that it is a restoringforce for positive and negative xvalues. We display some characteristics of this potential on the right in Figure8.2.Weseethat p=2 istheharmonicoscillatorandthat p=6 isnearlyasquare wellwiththemassmovingalmostfreelyuntilithitsthewallat x‚âÉ¬±1.Regardlessofthe pvalue,themotionwillbeperiodic,butitwillbeharmoniconlyfor p=2.Newton‚Äôslaw Harmonic AnharmonicV(x) x 1/Œ± Linear NonlinearUnboundVp = 2 x xVp = 6 Linear NonlinearHarmonic Anharmonic Figure 8.2 Left: The potentials of an harmonic oscillator (solid curve) and of an anharmonic oscillator (dashed curve). If the amplitude becomes too large for the anharmonic oscillator, the motion becomes unbound. Right: The shapes of the potential energy function V(x)‚àù|x|pforp=2 andp=6. The ‚Äúlinear‚Äù and ‚Äúnonlinear‚Äù labels refer to the restoring force derived from these potentials.",3600
8.2 ODE Review. 8.2.1 Order. 8.2.3 Linear and Nonlinear,"8.2 ODE Review 149 (8.1)givesthesecond-orderODEweneedtosolve: md2x dt2=Fext(x,t)‚àíkxp‚àí1. (8.7) 8.2 ODE Review The background material in this section is presented to avoid confusion over semantics. The well-versed reader may want to skim or skip it. 8.2.1 Order Ageneralformfora first-orderdifferentialequationis dy dt=f(t,y), (8.8) wherethe‚Äúorder‚ÄùreferstothedegreeofthederivativeontheLHS.Thederivativeorforce functionf(t,y)ontheRHS,isarbitrary.Forinstance,evenif f(t,y)isanastyfunctionof y andtsuchas dy dt=‚àí3t2y+t9+y7, (8.9) thisisstillafirst-orderdifferentialequation.Ageneralformfora second-order differential equationis d2y dt2+ùúÜdy dt=f( t,dy dt,y) . (8.10) The derivative function fon the RHS is arbitraryand may involveany power ofthe first derivativeaswell.Toillustrate, d2y dt2+ùúÜdy dt=‚àí3t2(dy dt)4 +t9y(t) (8.11) isasecond-orderdifferentialequation,asinNewton‚Äôslaw(8.1). Inthedifferentialequations(8.8)and(8.10),thetime tistheindependent variableandthe positionyisthedependent variable.Thismeansthatwearefreetovarythetimeatwhich we want a solution, but not the value of the position yat that time. Note that we often usethesymbol yorYforthedependentvariable,butthatthisisjustasymbolwhichmay refertoothervariables.Forexample,insomeapplications,weuse ytodescribeaposition insteadoft. 8.2.2 Ordinary and Partial Equations such as (8.1) and (8.8) are ODEs because they contain only oneindependent variable,inthesecases t.Incontrast,anequationsuchastheSchr√∂dingerequation, i‚Ñèùúïùúì(x,t) ùúït=‚àí‚Ñè2 2m[ùúï2ùúì ùúïx2+ùúï2ùúì ùúïy2+ùúï2ùúì ùúïz2] +V(x)ùúì(x,t), (8.12) containsfourindependentvariables,andthismakesita partialdifferentialequation (PDE). Thepartialderivativesymbol ùúïisusedtoindicatethatthedependentvariable ùúìdepends",1702
8.2.4 Initial and Boundary Conditions. 8.3 Dynamic Form of ODEs,"150 8 Differential Equations and Nonlinear Oscillations simultaneouslyonseveralindependentvariables.Intheearlypartsofthisbook,welimit ourselvestoordinarydifferentialequations,yetinChapters20‚Äì27,we‚Äôllexamineavariety ofPDEs. 8.2.3 Linear and Nonlinear Part of the strength of computational science is that we are no longer limited to solving linear equations. A linear equation is one in which only the first power of yordny‚àïdnt appears;anonlinearequationmaycontainhigherpowers.Forexample, dy dt=g3(t)y(t)(linear),dy dt=ùúÜy(t)‚àíùúÜ2y2(t)(nonlinear) . (8.13) Animportantpropertyoflinearequationsisthe lawoflinearsuperposition thatletsusadd differentsolutionstogethertoformnewones.Asacaseinpoint,if A(t)andB(t)aresolutions ofthelinearequationin(8.13),then y(t)=ùõºA(t)+ùõΩB(t) (8.14) isalsoasolutionforarbitraryvaluesoftheconstants ùõºandùõΩ.Incontrast,evenifwewere cleverenoughtoguessthatthesolutionofthenonlinearequationin(8.13)is y(t)=a 1+be‚àíùúÜt, (8.15) (which we invite you to verify), this wouldn‚Äôt work if we tried to obtain a more general solutionbyaddingtogethertwosuchsolutions: y1(t)=a 1+be‚àíùúÜt+a‚Ä≤ 1+b‚Ä≤e‚àíùúÜt(8.16) (whichyouweinviteyoutoverify). 8.2.4 Initial and Boundary Conditions Thegeneralsolutionofafirst-orderdifferentialequationcontainsonearbitraryconstant. Thegeneralsolutionofasecond-orderdifferentialequationcontainstwosuchconstants, andsoforth.Foranyspecificproblem,theseconstantsareusuallydeterminedbythe initial conditions.Forafirst-orderequationthesoleinitialconditionmaybetheposition y(t)at sometime.Forasecond-orderequation,thetwoinitialconditionsmaybethepositionand velocityatsometime.Regardlessofhowpowerfulthehardwareandsoftwarethatyouuti- lize,mathematicsremainsvalid,andsoyoumustknowtheinitialconditionsinorderto obtainauniquesolutiontoadifferentialequation. Inadditiontotheinitialconditions,itispossibletofurtherrestrictthesolutionsofdif- ferentialequations.Onesuchwayisby boundaryconditions thatconstrainthesolutionto havefixedvaluesattheboundariesofthesolutionspace.InChapter13,wediscusshowto extendthetechniquesofthischaptertoboundary-valueproblems. 8.3 Dynamic Form of ODEs AstandardformforODEs,whichhasproventobeusefulinbothnumericalanalysis[Press et al., 2007] and classical dynamics [Scheck, 2010; Tabor, 1989; Jos√© and Salatan, 1998], 8.3 Dynamic Form of ODEs 151 istoexpressODEsof anyorderasNsimultaneousfirst-orderODEsinthe Nunknowns, yi,i=0,N‚àí1: dy(0) dt=f(0)(t,{y(i)}), (8.17) dy(1) dt=f(1)(t,{y(i)}) (8.18) ...... dy(N‚àí1) dt=f(N‚àí1)(t,{y(i)}). (8.19) Note,fcancontainanexplicitdependenceonanyorallofthe y(i)s,butnotexplicitlyon a derivative dy(i)‚àïdt. These equations can be expressed more succinctly by use of the N- dimensionalvectors(indicatedherein boldface)yandf: dy(t)‚àïdt=f(t,y), (8.20) y=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y(0)(t) y(1)(t) ... y(N‚àí1)(t)‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶, f=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£f(0)(t,y) f(1)(t,y) ... f(N‚àí1)(t,y)‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (8.21) The utility of such compact notation is that we can study the properties of the ODEs, as wellasdevelopalgorithmstosolvethem,bydealingwiththesingleequation(8.20),with- outhavingtoworryaboutindividual y(i)‚Äôs.Toseehowthisworksinpractice,let‚Äôsconvert Newton‚Äôslaw d2x dt2=1 mF( t,x,dx dt) , (8.22) to this standard form. The rule is that the RHS may notcontain any explicit derivatives, althoughindividualcomponentsof y(i)mayrepresentderivatives.Topullthisoff,wedefine theposition xasthefirstdependentvariable y(0),andthevelocity dx‚àïdtastheseconddepen- dentvariable y(1): y(0)(t)def=x(t),y(1)(t)def=dx dt=dy(0)(t) dt. (8.23) Thesecond-orderODE(8.22)nowbecomestwosimultaneousfirst-orderODEs: dy(0) dt=y(1)(t),dy(1) dt=1 mF(t,y(0),y(1)). (8.24) Thisexpressestheacceleration[thesecondderivativein(8.22)]asthefirstderivativeofthe velocityy(1). These equations are now in the standard form (8.20), with the derivative or forcefunction fhavingthetwocomponents f(0)=y(1)(t),f(1)=1 mF(t,y(0),y(1)), (8.25) whereFmaybeanexplicitfunctionoftimeaswellasofpositionandvelocity.Tobeeven morespecific,applyingthesedefinitionstoourspringproblem(8.7),weobtainthecoupled first-orderequations dy(0) dt=y(1)(t),dy(1) dt=1 m[Fext(x,t)‚àíky(0)(t)p‚àí1], (8.26)",4064
8.4 ODE Algorithms. 8.4.2 RungeKutta Rule,"152 8 Differential Equations and Nonlinear Oscillations wherey(0)(t)isthepositionofthemassattime tandy(1)(t)isitsvelocity.Inthestandard form,thecomponentsoftheforcefunctionandtheinitialconditionsare f(0)(t,y)=y(1)(t), f(1)(t,y)=1 m[Fext(x,t)‚àík(y(0))p‚àí1], y(0)(0)=x0, y(1)(0)=ùë£0. (8.27) 8.4 ODE Algorithms TheclassicwaytosolveanODEisshowninFigure8.3.Onestartswiththeknowninitial valueofthedependentvariable, y0‚â°y(t=0),andthenusesthederivativefunction f(t,y)to advancetheinitialvalueonesmallstep hforwardintimetoproduce y(t=h)‚â°y1.Onceyou candothat,youcansolvetheODEforall tvaluesbyjustcontinuingtosteptolargertimes, onesmallhatatime.1Errorisalwaysaconcernwhenintegratingdifferentialequations becausederivativesrequiresmalldifferences,andsmalldifferencesarepronetosubtractive cancellationsandround-offerroraccumulation.Inaddition,becausethissteppingproce- dure is a continuous extrapolation of the initial conditions, with each step building on a previousextrapolation,thisissomewhatlikeacastlebuiltonsand;incontrasttointerpo- lation,therearenotabulatedvaluesonwhichtoanchoryoursolution.Itissimplestifthe timestepsusedthroughouttheintegrationremainconstantinsize,andthatismostlywhat we shall do. Industrial-strength algorithms, such as the one we discuss in Section 8.4.2, adaptthestepsizebymaking hlargerinregionswhere yvariesslowly(thisspeedsupthe integrationandcutsdownonround-offerror),andmaking hsmallerinregionswhere y variesrapidly. 8.4.1 Euler‚Äôs Rule Euler‚Äôsrule(Figure8.4)isthesimplestalgorithmforintegratingthedifferentialequation (8.8) by one step. It is just an application of the forward-difference algorithm for the derivative: dy(t) dt‚âÉy(tn+1)‚àíy(tn) h=f(t,y), (8.28) ‚áí yn+1‚âÉyn+hf(tn,yn), (8.29) whereyndef=y(tn)isthevalueof yattimetn.Weknowfromourdiscussionofdifferentiation thattheerrorintheforward-differencealgorithmis ùí™(h2),andsothenthistooistheerror inEuler‚Äôsrule. t = 0 t = Ty0y1y2y3 yN h Figure 8.3 A sequence of uniform steps of length htaken in solving a differential equation. The solution starts at time t=0, and is integrated in steps of huntil t=T. 1 Toavoidconfusion,noticethat y(n)isthenthcomponentofthe yvector,while ynisthevalueof yaftern timesteps.Yes,thereisapricetopayforeleganceinnotation. 8.4 ODE Algorithms 153 Figure 8.4 Euler‚Äôs algorithm for integration of a differential equation one step forward in time. This linear extrapolation with the slope evaluated at the initial point is seen to lead to an error Œî.Euler‚Äôs ruley(t) tntn+1Œî h Toindicatethesimplicityofthisalgorithm,weapplyittoouroscillatorproblem(8.4)for thefirsttimestep: y(0) 1=x0+ùë£0h,y(1) 1=ùë£0+h1 m[Fext(t=0)+Fk(t=0)]. (8.30) Comparethesetotheprojectileequationsfamiliarfromfirst-yearphysics, x=x0+ùë£0h+1 2ah2,ùë£=ùë£0+ah. (8.31) WeseethatwithEuler‚Äôsrule,theaccelerationdoesnotcontributetothechangeindistance (noh2term),yetitdoescontributetothechangeinvelocity(andsowillcontributebelatedly tothedistanceinthenexttimestep).Thisisclearlyasimplealgorithmthatrequiresvery smallhvaluestoobtainprecision.Yetusingsmallvaluesfor hincreasesthenumberofsteps andtheaccumulationofround-offerror,whichmayleadtoinstability.2Whereaswedonot recommendEuler‚Äôsalgorithmforgeneraluse,itiscommonlyusedtostartoffmoreprecise algorithms. 8.4.2 Runge‚ÄìKutta Rule Although no one algorithm is good for solving all ODEs, the fourth-order Runge‚ÄìKutta algorithm, rk4,oritsextensionwithadaptivestepsize, rk45,comesclose.Inspiteof rk4 beingourrecommendedstandard,wederivethesimpler rk2here,andjuststatetheresult forrk4. TheRunge‚ÄìKuttaalgorithmforintegratingadifferentialequationisbaseduponthefor- mal(exact)integralofourdifferentialequation: dy dt=f(t,y)‚áíy(t)=‚à´f(t,y)dt (8.32) ‚áíyn+1=yn+‚à´tn+1 tnf(t,y)dt. (8.33) To derive the second-order Runge‚ÄìKutta algorithm rk2(Figure 8.5 and rk2.py), we expandf(t,y)in a Taylor series about the midpointof the integration interval and retain 2 Instabilityisoftenaproblemwhenyouintegratea y(t)thatdecreasesastheintegrationproceeds, analogoustoupwardrecursionofsphericalBesselfunctions.Inthiscase,andifyouhavealinearODE,you arebestoffintegrating inwardfromlargetimestosmalltimesandthenscalingtheanswertoagreewith theinitialconditions. 154 8 Differential Equations and Nonlinear Oscillations rk2y(t) tntn+1slope tn+1/2ŒîFigure 8.5 The rk2 algorithm for integration of a differential equation uses a slope (bold line segment) evaluated at the interval‚Äôs midpoint, and is seen to lead to a smaller error than Euler‚Äôs algorithm in Figure 8.4. twotermsintheexpansion: f(t,y)‚âÉf(tn+1‚àï2,yn+1‚àï2)+(t‚àítn+1‚àï2)df dt(tn+1‚àï2)+ùí™(h2). (8.34) Since(t‚àítn+1‚àï2)raisedtoanyoddpowerisequallypositiveandnegativeovertheinterval tn‚â§t‚â§tn+1,theintegralofthe (t‚àítn+1‚àï2)termin(8.34)vanishesandweobtainthe rk2 algorithm : ‚à´tn+1 tnf(t,y)dt‚âÉf(tn+1‚àï2,yn+1‚àï2)h+ùí™(h3), (8.35) ‚áíyn+1‚âÉyn+hf(tn+1‚àï2,yn+1‚àï2)+ùí™(h3). (8.36) Wesee that while rk2containsthe same number of terms as Euler‚Äôs rule, it obtainsa higher level of precision by taking advantage of the cancellation of the ùí™(h)terms. The priceforimprovedprecisionishavingtoevaluatethederivativefunctionandthesolution y atthemiddleofthetimeinterval, t=tn+h‚àï2.Andthere‚Äôstherub,forwedonotknowthe valueofyn+1‚àï2andcannotusethisalgorithmtodetermineit.Thewayoutofthisquandary istouseEuler‚Äôsalgorithmtodetermine yn+1‚àï2: yn+1‚àï2‚âÉyn+1 2hdy dt=yn+1 2hf(tn,yn). (8.37) Puttingthepiecesalltogethergivesthecomplete rk2algorithm: yn+1‚âÉyn+k2, (rk2) (8.38) k2=hf( tn+h 2,yn+k1 2) ,k1=hf(tn,yn), (8.39) where we use boldface to indicate the vector nature of yandf. We see that the known derivativefunction fisevaluatedattheendsandthemidpointoftheinterval,butonlythe (known) initial value of the dependent variable yis required. This makes the algorithm self-starting. Asanexampleoftheuseof rk2,weapplyittoourspringproblem: y(0) 1=y(0) 0+hf(0)( h 2,y(0) 0+k1) (8.40) ‚âÉx0+h[ ùë£0+h 2Fk(0)] , (8.41)",5785
8.6 Extensions Nonlinear Resonances Beats Friction,"8.4 ODE Algorithms 155 y(1) 1=y(1) 0+hf(1)[( h 2,y0+h 2f(0),y0)] (8.42) ‚âÉùë£0+h m[ Fext( h 2) +Fk( y(1) 0+k1 2)] . (8.43) Theseequationssaythattheposition y(0)changesbecauseoftheinitialvelocityandforce, while the velocity y(1)changes because of the external force at t=h‚àï2 and the internal forceattwointermediatepositions.Weseethattheposition y(0)nowhasan h2timedepen- dence,whichatlastbringsusuptotheleveloffirst-yearphysics. Thefourth-orderRunge‚ÄìKuttamethod rk4.py(Listing8.1)obtains ùí™(h4)precisionby approximating yasaTaylorseriesuptoorder h2(aparabola)atthemidpointoftheinterval, whichagainleadstocancellationoflower-ordererror.Allinall, rk4providesanexcellent balanceofpower,precision,andprogrammingsimplicity.Withrk4therearefourinterme- diateslopes,andtheseareapproximatedwiththeEuleralgorithm: yn+1=yn+1 6(k1+2k2+2k3+k4), (8.44) k1=hf(tn,yn), k2=hf( tn+h 2,yn+k1 2) , k3=hf( tn+h 2,yn+k2 2) , k4=hf(tn+h,yn+k3). This provides an improved approximation to f(t,y)near the midpoint. Although rk4is computationallymoreexpensivethantheEulermethod,itsprecisionismuchbetter,and sometimesismadeupbytheabilitytouselargerstepsizes h. A variation of rk4, known as the Runge‚ÄìKutta‚ÄìFehling method [Mathews, 2002], or rk45, varies the step size while doing the integration with the hope of obtaining better precisionandmaybebetterspeed.Ourimplementation, rk45.py,isgiveninListing8.2. Itautomaticallydoublesthestepsizeandteststoseehowanestimateoftheerrorchanges. Iftheerrorisstillwithinacceptablebounds,thealgorithmwillcontinuetousethelarger step size and thus speed up the computation; if the error is too large, the algorithm will decrease the step size until an acceptable error is found. As a consequence of the extra informationobtainedinthetesting,thealgorithmdoesobtain ùí™(h5)precision,butsome- timesattheexpenseofextracomputingtime.Whetherthatextratimeisrecoveredbybeing abletousealargerstepsizedependsupontheapplication. 8.4.3 Adams-Bashful-Moulton Predictor-Corrector Rule AnotherapproachforobtaininghighprecisioninanODEalgorithmusesthesolutionfrom twoprevioussteps, yn‚àí2andyn‚àí1,inadditionto yn,topredict yn+1.(TheEulerand rkmeth- odsusejustonepreviousstep.)ManyofthesemethodstendtobelikeaNewton‚Äôssearch method;westartwithaguessor predictionforthenextstep,andthenuseanalgorithm, such as rk4, to check on the prediction and thereby obtain a correction. As with rk45, onecanusethecorrectionasameasureoftheerrorandthenadjustthestepsizetoobtain improved precision [Press et al., 2007]. For those readers who may want to explore such methods, ABM.pyinListing8.3givesourimplementationofthe Adams-Bashful-Moulton predictor-correctorscheme. 156 8 Differential Equations and Nonlinear Oscillations 8.4.4 Assessment: rk2 versus rk4versus rk45 Whileyouarefreetodoasyouplease,unlessyouareverycareful,werecommendthatyou donotwriteyourown rk4orrk45methods.Youwillbeusingthisalgorithmforsome high-precision work, and unless you get every fraction and method call just right, your codemayappeartoworkwell,butstillnotgivealltheprecisionthatyoucouldobtain.And sowegiveyou rk4.py,and rk45.pycodestouse.However,wedorecommendthatyou writeyourown rk2,asdoingsowillmakeitclearerastohowtheRunge‚ÄìKuttamethods work,butwithoutallthepainanddangerof rk4. 1) Writeyourown rk2method,withthederivativefunction f(t,x)aseparatemethod. 2) Useyour rk2tosolvetheequationofmotion(8.7)or(8.26).Plotboththeposition x(t) andvelocity dx‚àïdtasfunctionsoftime. 3) OnceyourODEsolverisrunning,doanumberofthingstocheckthatitisworkingwell andthatyouknowwhat hvaluestouse: a) Adjust the parameters in your potential so that it corresponds to a pure harmonic oscillator(set p=2orùõº=0).Foranoscillatorinitiallyatrest,wehaveananalytic resultwithwhichtocompare: x(t)=Asin(ùúî0t),ùë£=ùúî0Acos(ùúî0t),ùúî0=‚àö k‚àïm.",3744
8.6 Extensions Nonlinear Resonances Beats Friction,"(8.45) b) Pickvaluesof kandmsuchthattheperiod T=2ùúã‚àïùúîisanicenumberwithwhich towork(somethinglike T=1). c) Startwithastepsize h‚âÉT‚àï5andmake hsmalleruntilthesolutionlookssmooth, hasaperiodthatremainsconstantforalargenumberofcycles,andagreeswiththe analyticresult.Alwaystrytostartwithalarge hsothatyoucanseeabadsolution turngood. d) Make sure that you have exactly the same initial conditions for the analytic and numerical solutions (zero displacement, nonzero velocity), and then plot the two together.Itisgoodifyoucannottellthemapart,yetthatisnotmuchofatestsince itonlyensuresapproximatelytwoplacesofagreement. e) Trydifferentinitialvelocitiesandverifythata harmonicoscillatoris isochronous ,that is,thatitsperioddoes notchangeastheamplitudevaries. 4) Now that you know you can get a good solution of an ODE with rk2, compare the solutionsobtainedwiththe rk2,rk4,and rk45solvers. 5) MakeatableofcomparisonssimilartoTable8.1,wherewecompare rk4andrk45for thetwoequations 2yy‚Ä≤‚Ä≤+y2‚àíy‚Ä≤2=0, (8.46) y‚Ä≤‚Ä≤+6y5=0, (8.47) withinitialconditions [y(0),y‚Ä≤(0)] = [1,1].Althoughnonlinear,(8.46)doeshavetheana- lytic solution,3y(t)=1+sint. Equation (8.47) corresponds to our standard potential (8.5),with p=6.Althoughwehavenottuned rk45,Listing8.2showsthatbysetting 3 Bewarned,the rkproceduresmaybeinaccurateforthisequationifintegratedthroughthepoint y(t)=0,asthentheequationbecomes y‚Ä≤2=0,whichisproblematic. 8.5 Solution for Nonlinear Oscillations 157 Table 8.1 Comparison of ODE solvers for different equations. Eqn. no. Method Initial hNo. of Ô¨Çops Time (ms) Relative error (8.46) rk40.01 1000 5.2 2.2 √ó10‚àí8 rk451.00 72 1.5 1.8 √ó10‚àí8 (8.47) rk40.01 227 8.9 1.8 √ó10‚àí8 rk450.1 3143 36.7 5.7 √ó10‚àí11 Figure 8.6 The logarithm of the relative error in the solution of an ODE obtained with rk4 using a differing number Nof time steps over a Ô¨Åxed time interval. The logarithm approximately equals the negative of the number of places of precision. Increasing the number of steps used for a Ô¨Åxed interval is seen to lead to smaller errors.‚Äì7 ‚Äì9 ‚Äì13 log |Rel Error| TimeError in rk4 N = 5000N = 1000N = 500 i t st o l e r a n c ep a r a m e t e rt oas m a l le n o u g hn u m b e r , rk45will obtain better precision thanrk4(Figure8.6),butthatitrequires ‚àº10timesmorefloating-pointoperationsand takes‚àº5timeslonger.For(8.46),weobtainedincreasedprecisioninlesstime. 8.5 Solution for Nonlinear Oscillations Use your rk4program to study anharmonic oscillations by trying powers in the range p=2‚Äì12 for potential (8.5), or anharmonic strengths in the range 0 ‚â§ùõºx‚â§2 for poten- tial(8.2).Do notincludeanyexplicittime-dependentforcesyet.Notethatforlargevalues ofp,theforcesandaccelerationsgetlargeneartheturningpoints,andsoyoumayneeda smallerstepsize hthanthatusedfortheharmonicoscillator. 1) Check that the solution remains periodic with constant amplitude and period for all initial conditions regardless of how nonlinear you make the force. In addition, check that the maximum speed occurs at x=0 and zero velocity at the maximum |x|‚Äôs, the latterbeingaconsequenceofenergyconservation.",3051
8.6 Extensions Nonlinear Resonances Beats Friction,"2) Verifythatnonharmonicoscillatorsare nonisochronous ,thatis,thatvibrationswithdif- ferentamplitudeshavedifferentperiods(Figure8.7). 3) Explainwhytheshapesoftheoscillationschangefordifferent p‚Äôsorùõº‚Äôs. 4) Deviseanalgorithmtodeterminetheperiod Toftheoscillationbyrecordingtimesat whichthemasspassesthroughtheorigin.Notethatbecausethemotionmaybeasym- metric,youmustrecordatleast threetimestodeducetheperiod. 5) Constructagraphofthededucedperiodasafunctionofinitialamplitude. 158 8 Differential Equations and Nonlinear Oscillations 0‚Äì404Amplitude dependence, p = 7 Timex(t) Figure 8.7 The position versus time for oscillations within the potential V‚àùx7for four different initial amplitudes. Each is seen to have a different period. 6) Verifythatthemotionisoscillatory,butnotharmonic,astheenergyapproaches k‚àï6ùõº2, orforp>6. 7) Verify that for the anharmonic oscillator with E=k‚àï6ùõº2, the motion separates from oscillatorytotranslational.Seehowcloseyoucangettothis separatrixwhereasingle oscillationtakesaninfinitetime.(Thereisnoseparatrixforthepower-lawpotential.) 8.5.1 Precision Assessment via E Conservation WehavenotexplicitlybuiltenergyconservationintoourODEsolvers.Nonetheless,unless youhaveexplicitlyincludedafrictionalforce,itfollowsmathematicallyfromtheequations ofmotionthatenergymustbeaconstantforallvaluesof porùõº.Thatbeingthecase,the constancyofenergyisademandingtestofthenumerics. 1) PlotthepotentialenergyPE (t)=V[x(t)],thekineticenergyKE (t)=mùë£2(t)‚àï2,andthe totalenergy E(t)=KE(t)+PE(t),for50periods.Commentonthecorrelationbetween PE(t)andKE(t)andhowitdependsonthepotentialparameters. 2) Checkthelong-term stabilityofyoursolutionbyplotting ‚àílog10||||E(t)‚àíE(t=0) E(t=0)||||‚âÉnumberofplacesofprecision (8.48) foralargenumberofperiods(Figure8.6).Because E(t)shouldbeindependentoftime, thenumeratoristheabsoluteerrorinyoursolution,andwhendividedby E(0),becomes therelativeerror(say10‚àí11).Ifyoucannotachieve11ormoreplaces,thenyouneedto decreasethevalueof hordebug. 3) Because a particle bound by a large- poscillator is essentially ‚Äúfree‚Äù most of the time, youshouldobservethattheaverageofitskineticenergyovertimeexceedsitsaverage potentialenergy.ThisisactuallythephysicsbehindtheVirialtheoremforapower-law potential[MarionandThornton,2019]: ‚ü®KE‚ü©=p 2‚ü®PE‚ü©. (8.49)",2265
8.6.1 Friction. 8.7 Code Listings,"8.6 Extensions: Nonlinear Resonances, Beats, Friction 159 VerifythatyoursolutionsatisfiestheVirialtheorem.(Thosereaderswhohaveworked ontheperturbedoscillatorproblemcanusethisrelationtodeduceaneffective pvalue, whichshouldbebetween2and3.) 8.6 Extensions: Nonlinear Resonances, Beats, Friction Problem Sofarouroscillationshavebeenrathersimple.Wehaveignoredfrictionand have assumed that there are no external forces (hands) influencing the system‚Äôs natural oscillations.Determinethefollowing: 1) Howtheoscillationschangewhenfrictionisincluded. 2) Howtheresonancesandbeatsofnonlinearoscillatorsdifferfromthoseoflinearoscil- lators. 3) Howintroducingfrictionaffectsresonances. 8.6.1 Friction Theworldisfulloffriction,andnotallofitisbad.Whilefrictionmakesithardertopedal abikethroughthewind,italsoletsyouwalkonice,andgenerallyaddsstabilitytodynam- icalsystems.Thesimplestmodelsforfrictionalforcearecalled static,kinetic,andviscous friction: F(static) f‚â§‚àíùúásN,F(kinetic) f=‚àíùúákNùë£ |ùë£|,F(viscous) f=‚àíbùë£. (8.50) HereNisthenormalforce ontheobjectunderconsideration, ùúáandbareparameters,and ùë£is the velocity. This model for static friction is appropriatefor objects at rest, while the modelforkineticfrictionisappropriateforanobjectslidingonadrysurface.Ifthesurface islubricated,oriftheobjectismovingthroughaviscousmedium,thenafrictionalforce proportionaltosomepowerofthevelocityisabettermodel.4 1) Extendyourharmonicoscillatorcodetoincludethethreetypesoffrictionin(8.50),and observehowthemotiondiffersforeach. 2)Hint: For the simulation with static plus kinetic friction, each time the oscillator has ùë£=0,youneedtocheckthattherestoringforceexceedsthestaticforceoffriction.If not,theoscillationmustendatthatinstant.Checkthatyoursimulationterminatesat nonzeroxvalues. 3) Foryoursimulationswithviscousfriction,investigatethequalitativechangesthatoccur forincreasing bvalues: Under damped: b<2mùúî0Oscillatewithindecayingenvelope Critically damped: b=2mùúî0Nonconciliatory,finitedecaytime Over damped: b>2mùúî0Nonconciliatory,infinitedecaytime 8.6.2 Resonances and Beats Stable physical systems will oscillate if displaced slightly from their rest positions. The frequency ùúî0withwhichastablesystemexecutessmalloscillationsaboutitsrestpositions 4 TheeffectofairresistanceonprojectilemotionisstudiedinSection13.4. 160 8 Differential Equations and Nonlinear Oscillations iscalledits naturalfrequency .Ifanexternalsinusoidalforceisappliedtothissystem,and ifthefrequencyoftheexternalforceisequaltothenaturalfrequency ùúî0,thenaresonance mayoccurinwhichthesystemabsorbsenergyfromtheexternalforceandtheamplitudeof oscillationincreaseswithtime.Iftheoscillationandthedrivingforceremaininphaseover time,theamplitudeofoscillationwillincreasecontinuously,unlessthereissomemecha- nism,suchasfrictionornonlinearities,tolimitthegrowth.Ifthefrequencyofthedriving forceiscloseto,butnotexactlyequalto,thenaturalfrequencyofthesystem,thenarelated phenomena,knownas beating,mayoccur.Inbeatingthereisinterferencebetweenthenat- uraloscillationandtheexternalforce.Ifthefrequencyoftheexternaldrivingforceisvery closetothenaturalfrequency,thentheresultingmotion, x‚âÉx0sinùúît+x0sinùúî0t=( 2x0cosùúî‚àíùúî0 2t) sinùúî+ùúî0 2t, (8.51) resemblesthenaturaloscillationofthesystemattheaveragefrequencyùúî+ùúî0 2,yetwithan amplitude2 x0cosùúî‚àíùúî0 2tthatvariesslowlywitha beatfrequencyùúî‚àíùúî0 2. 8.6.3 Time-Dependent Forces Toextendoursimulationtoincludeanexternalforce, Fext(t)=F0sinùúît, (8.52) weneedtoincludeatimedependenceintheforcefunction f(t,y)ofourODEsolver. 1) Addthesinusoidaltime-dependentexternalforce(8.52)tothespace-dependentrestor- ingforceinyourprogram(donotincludefrictionyet). 2) Startwithaverylargevalueforthemagnitudeofthedrivingforce F0.Thisshouldlead tomode locking (the 500-pound-gorilla effect), where the system is overwhelmed by the driving force and, after the transients die out, the system oscillates in phase with thedriverregardlessofthedriver‚Äôsfrequency.",3900
8.6.1 Friction. 8.7 Code Listings,"3) Now lower F0until it is close to the magnitude of the natural restoring force of the system.Youneedtohavethisnearequalityforbeatingtooccur. 4) Verify that the beat frequency for the harmonic oscillator (the number of variations in intensity per unit time) equals the frequency difference (ùúî‚àíùúî0)‚àï2ùúãin cycles per second,where ùúî‚âÉùúî0. 5) Onceyouhaveavaluefor F0matchedwellwithyoursystem,makeaseriesofrunsin which you progressively increase the frequency of the driving force for the frequency rangeùúî0‚àï10‚â§ùúî‚â§10ùúî0. 6) Makeofplotofthemaximumamplitudeofoscillation versusthedriver‚Äôs ùúî. 7) Explore what happens when you make a nonlinear system resonate. If the nonlinear systemisclosetobeingharmonic,youshouldgetbeatinginplaceoftheblowupthat occursforthelinearsystem.Beatingoccursbecausethenaturalfrequencychangesas theamplitudeincreases,andthusthenaturalandforcedoscillationsfalloutofphase. Yetonceoutofphase,theexternalforcestopsfeedingenergyintothesystem,andsothe amplitudedecreases,andwiththedecreaseinamplitude,thefrequencyoftheoscillator returnstoitsnaturalfrequency,thedriverandoscillatorgetbackinphase,andtheentire cyclerepeats. 8.7 Code Listings 161 8) Investigatenowhowtheinclusionofviscousfrictionmodifiesthecurveofamplitude versusdriverfrequency.Youshouldfindthatfrictionbroadensthecurve. 9) Explainhowthecharacteroftheresonancechangesastheexponent pinthepotential V(x)=k|x|p‚àïpismadelargerandlarger.Atlarge p,themasseffectively‚Äúhits‚Äùthewall andfallsoutofphasewiththedriver,andsothedriverislesseffectiveatpumpingenergy intothesystem. 8.7 Code Listings Listing 8.1 rk4.py solvesanODEwiththeRHSgivenbythemethodf()usingrk4.The methodf()isseparatefromthealgorithm. 1# rk4.py 4th order Runge Kutta application wi built in rk4 fromvisual.graph import ‚àó 5# Initialization a=0 . b = 10. n = 100 9ydumb = zeros((2) , float); y= zeros((2), float) fReturn = zeros((2), float); k1= zeros((2), float) k2 = zeros((2) , float); k3= zeros((2), float) k4 = zeros((2) , float) 13y[0] = 3.; y[1] = ‚àí5. t=a ; h=( b ‚àía)/n; deff( t, y): # Force function 17fReturn[0] = y[1] fReturn[1] = ‚àí100.‚àóy[0]‚àí2.‚àóy[1] + 10. ‚àósin(3. ‚àót) returnfReturn 21graph1 = gdisplay(x=0,y=0, width = 400, height = 400, title = ‚ÄôRK4‚Äô, xtitle = ‚Äôt‚Äô, ytitle = ‚ÄôY[0]‚Äô,xmin=0,xmax=10,ymin= ‚àí2,ymax=3) funct1 = gcurve(color = color.yellow) graph2 = gdisplay(x=400,y=0, width = 400, height = 400, title = ‚ÄôRK4‚Äô, 25 xtitle = ‚Äôt‚Äô, ytitle = ‚ÄôY[1]‚Äô,xmin=0,xmax=10,ymin= ‚àí25,ymax=18) funct2 = gcurve(color = color.red) defrk4(t,h,n): 29k1 = [0] ‚àó(n) k2 = [0] ‚àó(n) k3 = [0] ‚àó(n) k4 = [0] ‚àó(n) 33fR = [0] ‚àó(n) ydumb = [0] ‚àó(n) fR = f(t, y) # Returns RHS‚Äô s foriin range (0, n): 37 k1[i] = h ‚àófR[i] foriin range (0, n): ydumb[i] = y[i] + k1[i]/2. k2 = h ‚àóf(t+ h/2., ydumb) 41foriin range (0, n): ydumb[i] = y[i] + k2[i]/2. k3 = h ‚àóf(t+ h/2., ydumb) foriin range (0, n): 45 ydumb[i] = y[i] + k3[i] k4 = h ‚àóf(t+ h, ydumb) foriin range (0, 2): y[i] = y[i] + (k1[i] + 2. ‚àó(k2[i] + k3[i]) + k4[i])/6. 49returny while(t<b): # Time loop if((t + h) > b): 162 8 Differential Equations and Nonlinear Oscillations 53 h=b‚àít # Last step y=r k 4 ( t, h , 2 ) t=t+h rate(30) 57funct1.plot(pos = (t, y[0]) ) funct2.plot(pos = (t, y[1]) ) Listing 8.2 rk45.py solvesanODEwiththeRHSgivenbythemethodf()usingrk4with adaptivestepsize. # rk45 .py Adaptive step size Runge Kutta fromvisual.graph import ‚àó 4 a = 0.; b = 10.",3339
8.6.1 Friction. 8.7 Code Listings,"# Error tolerance , endpoints Tol = 1.0E ‚àí8 ydumb = zeros( (2) , float) # Initialize 8y=z e r o s (( 2 ), float) fReturn = zeros( (2), float) err = zeros( (2), float) k1 = zeros( (2) , float) 12k2 = zeros( (2) , float) k3 = zeros( (2) , float) k4 = zeros( (2) , float) k5 = zeros( (2) , float) 16k6 = zeros( (2) , float) n=2 0 y [ 0 ]=1 .; y [ 1 ]=0 . 20h=( b ‚àía)/n; t = a; j = 0 h m i n=h / 6 4 ; h m a x=h ‚àó64 # Min and m a x step sizes flops = 0; Eexact = 0. ; error = 0. sum=0 . 24 deff( t, y, fReturn ): # Force function fReturn[0] = y[1] fReturn[1] = ‚àí6.‚àópow(y[0], 5.) 28 graph1 = gdisplay( width = 600, height = 600, title = ‚ÄôRK 45‚Äô, xtitle = ‚Äôt‚Äô, ytitle = ‚ÄôY[0]‚Äô) funct1 = gcurve(color = color.blue) 32graph2 = gdisplay( width = 500, height = 500, title = ‚ÄôRK45‚Äô, xtitle = ‚Äôt‚Äô, ytitle = ‚ÄôY[1]‚Äô) funct2 = gcurve(color = color.red) funct1.plot(pos = (t, y[0]) ) 36funct2.plot(pos = (t, y[1]) ) while(t<b): # Loop over time funct1.plot(pos = (t, y[0]) ) 40funct2.plot(pos = (t, y[1]) ) if(( t +h )>b) : h=b ‚àít # Last step f(t, y, fReturn) # Evaluate f , return in fReturn 44k1[0] = h ‚àófReturn[0]; k1[1] = h ‚àófReturn[1] foriin range (0, 2): ydumb[i] = y[i] + k1[i]/4 f(t + h/4, ydumb, fReturn) 48k2[0] = h ‚àófReturn[0]; k2[1] = h ‚àófReturn[1] foriin range (0, 2): ydumb[i] = y[i] + 3 ‚àók1[i]/32 + 9 ‚àók2[i]/32 f(t + 3 ‚àóh/8, ydumb, fReturn) 52k3[0] = h ‚àófReturn[0]; k3[1] = h ‚àófReturn[1] foriin range (0, 2): ydumb[i] = y[i] + 1932 ‚àók1[i]/2197 ‚àí7200 ‚àók2[i]/2197. + 7296 ‚àók3[i]/2197 f(t + 12 ‚àóh/13, ydumb, fReturn) 56k4[0] = h ‚àófReturn[0]; k4[1] = h ‚àófReturn[1] foriin range (0, 2): 8.7 Code Listings 163 ydumb[i] = y[i] + 439 ‚àók1[i]/216 ‚àí8‚àók2[i] + 3680 ‚àók3[i]/513 ‚àí 845‚àók4[i]/4104 f(t + h, ydumb, fReturn) 60k5[0] = h ‚àófReturn[0]; k5[1] = h ‚àófReturn[1] foriin range (0, 2): ydumb[i] = y[i] ‚àí8‚àók1[i]/27 + 2 ‚àók2[i]‚àí3544 ‚àók3[i]/2565 + 1859 ‚àók4[i]/4104 ‚àí11‚àók5[i]/40 f(t + h/2, ydumb, fReturn) 64k6[0] = h ‚àófReturn[0]; k6[1] = h ‚àófReturn[1]; foriin range (0, 2): err[i] = abs( k1[i]/360 ‚àí128‚àók3[i]/4275 ‚àí2197 ‚àók4[i]/75240 + k5[i]/50. + 2 ‚àók6[i]/55) if(e r r [ 0 ] <Tolorerr[1] <Tolorh<=2 ‚àóhmin ): # Accept step 68 foriin range (0, 2): y[i] = y[i] + 25 ‚àók1[i]/216. + 1408 ‚àók3[i]/2565. + 2197 ‚àók4[i]/4104. ‚àík5[i]/5. t=t + h j=j + 1 72if(e r r [ 0 ]= =0 orerr[1] == 0 ): s=0 # Trap division by 0 else: s = 0.84 ‚àópow(Tol ‚àóh/err[0], 0.25) # Reduce step 76if(s<0.75andh>2 ‚àóhmin ): h/ = 2 . # Increase step else: if(s>1 . 5 and2‚àóh<hmax ): 80 h‚àó=2 . flops = flops + 1 E=pow(y[0], 6.) + 0.5 ‚àóy[1] ‚àóy[1] Eexact = 1. 84error = abs(( E‚àíEexact)/Eexact) sum+= error print(\""<error>= \"" ,sum/flops, \"", flops = \"" , flops) Listing 8.3 ABM.py solvesanODEwiththeRHSgivenbythemethodf()usingtheABC predictor-correctoralgorithm. # A B M.py: A d a m s B M method to integrate O D E #S o l v e sy ‚Äô=( t ‚àíy)/2, with y[0] = 1 over [0, 3] 4fromvpython import ‚àó numgr = graph(x=0, y=0, width=600, height=300, xmin=0.0, xmax = 3.0, title= \""Numerical Solution\"" , xtitle= ‚Äôt‚Äô, ytitle= ‚Äôy‚Äô,y m a x = 2 . ,y m i n = 0 ) 8numsol = gcurve(color=color.red) exactgr = graph(x=0, y=300, width=600, height=300, title= \""Exact solution\"" , xtitle= ‚Äôt‚Äô, ytitle= ‚Äôy‚Äô, xmax=3.0, xmin=0.0, ymax=2.0, ymin=0) 12exsol =gcurve (color = color.cyan) n=2 4 # N steps > 3 A=0 ;B=3 . t =[0] ‚àó500; y =[0] ‚àó500; yy=[0] ‚àó4 16 deff(t, y): # R H S F function return (t‚àíy)/2.0 20defrk4(t, yy, h1): foriin range (0, 3): t= h 1 ‚àói k0 = h1 ‚àóf(t, y[i]) 24 k1 = h1 ‚àóf(t + h1/2., yy[i] + k0/2.) k2 = h1 ‚àóf(t + h1/2., yy[i] + k1/2.) k3 = h1 ‚àóf(t +h1, yy[i] + k2 ) yy[i + 1] = yy[i] + (1./6.) ‚àó(k0 + 2. ‚àók1 + 2. ‚àók2 + k3) 28 print(i,yy[ i]) returnyy[3] defABM(a , b ,N) : 164 8 Differential Equations and Nonlinear Oscillations 32# Compute 3 additional starting values using rk h=( b‚àía) / N # step t[0] = a; y[0] = 1.00; F0 = f(t[0], y[0]) forkin range (1, 4): 36 t[k] = a + k ‚àóh y[1] = rk4(t[1], y, h) # 1st step y[2] = rk4(t[2], y, h) # 2nd step y[3] = rk4(t[3], y, h) # 3rd step 40F1 = f(t[1], y[1]) F2 = f(t[2], y[2]) F3 = f(t[3], y[3]) h2 = h/24. 44forkin range (3, N): # Predictor p=y [ k ] + h 2 ‚àó(‚àí9.‚àóF0 + 37. ‚àóF1‚àí59.‚àóF2 + 55. ‚àóF3) t[k+ 1] = a +h ‚àó(k+1) # Next abscissa F4 = f(t[k+1], p) 48 y [ k + 1 ]=y [ k ]+h 2 ‚àó(F1‚àí5.‚àóF2 + 19. ‚àóF3 + 9. ‚àóF4) # Corrector F0 = F1 # Update values F1 = F2 F2 = F3 52 F 3=f(t[ k+1 ],y [ k+1 ] ) returnt,y t, y=A B M (A,B,n) 56forkin range (0, n+1): numsol.plot( t[k], y[k] ) exsol.plot( t[k], 3. ‚àóexp(‚àít[k]/2.) ‚àí2. + t[k])",4395
Part II Data Science,165 Part II Data Science,24
Chapter 9 Fourier Analyses. 9.1 Fourier Series,"167 9 Fourier Analyses This chapter discusses Fourier series and Fourier transforms. When implemented as algorithms, both become the Discrete Fourier Transform (DFT), or its fast cousin, the Fast Fourier Transform (FFT). In Chapter 14, we discuss the Short-Time Fourier Transform, and in Chapter 12, we derive the Quantum Fourier Transform, the quantum computing version of the DFT . 9.1 Fourier Series Consider againaparticleoscillatingeitherinthenonharmonicpotentialof(8.5): V(x)=1 pk|x|p,p‚â†2, (9.1) orintheperturbedharmonicoscillatorpotential(8.2), V(x)=1 2kx2( 1‚àí2 3ùõºx) . (9.2) Whilefreeoscillationsinthesepotentialsarealwaysperiodic,theyarenottrulysinusoidal. Your problemistotakethesolutionofoneofthesenonlinearoscillatorsandexpanditin aFourierseries: y(t)=b0sinùúî0t+b1sin2ùúî0t+¬∑¬∑¬∑. (9.3) Forexample,ifyouroscillatorissufficientlynonlineartobehavelikethesawtoothfunction (Figure9.1left),thentheFourierspectrumyouobtainshouldbesimilartothatshownon therightinFigure9.1. Ingeneral,whenweundertakesuchaspectralanalysiswewanttoanalyzethesteady- statebehaviorofasystem.Thismeansthatwehavetowaitfortheinitialtransientstodie out.Itiseasytoidentifyjustwhattheinitialtransientisforlinearsystems,butmaybeless apparentfornonlinearsystemsinwhichthe‚Äústeadystate‚Äùjumpsamonganumberofcon- figurations.Inthelattercase,wecouldconstructdifferentFourierspectraatdifferenttimes, asisdonewiththe Short-TimeFourierTransform tobediscussedinChapter10. Partofourinterestinnonlinearoscillationsarisesfromtheirlackofstudyintraditional physicscourses,wherejust(approximate)linearoscillationsareoftenstudied.Iftheforce ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 168 9 Fourier Analyses onaparticleisalwaystowarditsequilibriumposition(arestoringforce),thentheresulting motionwillbe periodic,butnotnecessarily harmonic.Agoodexampleisthemotioninthe highlyanharmonicpotential,suchas(9.1)with p‚âÉ10,thatproducesan x(t)lookinglikea seriesofpyramids;thismotionisperiodicbutnotharmonic. Our approach is in contrast to the traditional one in which the fundamental oscilla- tion is determined analytically, and the higher-frequency overtonesare determined by perturbation theory [Landau and Lifshitz, 1976]. We start with the full solution, and decompose it into harmonics andovertones. When we speak of fundamentals, overtones, andharmonics,wespeakofsolutionstothelinear boundary-valueproblem ,forexample,of wavesonapluckedviolinstring.Inthislattercase,andwhengiventhecorrectconditions (andenoughmusicalskill),itispossibletoexciteindividualharmonics,orsumsofthem, fromtheseries(9.3). Youmayrecallfromclassicalmechanicsthatthegeneralsolutionforavibratingsystem can be expressed as the sum of the normal modes of that system. These expansions are possibleonlyifwehave linearoperators and,consequently,the principleofsuperposition : Ify1(t)andy2(t)aresolutionsofsomelinearequation,then ùõº1y1(t)+ùõº2y2(t)isalsoasolu- tion.Theprincipleoflinearsuperpositiondoesnotholdwhenwesolvenonlinearproblems. Nevertheless,itisalwayspossibletoexpanda periodicsolutionofa nonlinearproblemin termsoftrigonometricfunctions.This is aconsequence of Fourier‚Äôstheorem beingappli- cabletoanysingle-valuedperiodicfunctionwithonlyafinitenumberofdiscontinuities. Weassumeweknowtheperiod T,thatis,that y(t+T)=y(t). (9.4) Thistellsusthe truefrequency ùúî: ùúî‚â°ùúî1=2ùúã T. (9.5) Anyperiodicfunction(oftendesignatedasthe signal)canbeexpandedasaseriesofhar- monicfunctionswithfrequenciesthataremultiplesofthetruefrequency: y(t)=a0 2+‚àû‚àë n=1(ancosnùúît+bnsinnùúît). (9.6) Thisequationrepresentsthesignal y(t)asthesimultaneoussumofpuretonesoffrequency nùúî.Thecoefficients anandbnmeasureoftheamountofcos nùúîtandsinnùúîtpresentiny(t), respectively.Theintensityor powerateachfrequencyisproportionalto a2 n+b2 n. TheFourierseries(9.6)isa‚Äúbestfit,‚Äùintheleast-squaressenseofChapter6,toanumber ofmeasurementsofthesignal.Thismeansthattheseriesconvergestothe averagebehav- ior of the signal, but misses the signal at discontinuities (at which points it converges to themean),oratsharpcorners(whereitovershoots).Ageneralfunction y(t)maycontain aninfinitenumberofFouriercomponents,althoughlow-accuracyreproductionisusually possiblewithasmallnumberofcomponents. Thecoefficients anandbnin(9.6)aredeterminedbythestandardtechniquesoforthog- onalfunctionexpansion.Tofindthem,multiplybothsidesof(9.6)bycos nùúîtorsinnùúît, integrateoveroneperiod,andprojectasingle anorbn: (an bn) =2 T‚à´T 0dt(cosnùúît sinnùúît) y(t),ùúîdef=2ùúã T. (9.7)",4520
9.1.2 Exercises Fourier Series Summations,"9.1 Fourier Series 169 t‚Äì101 y(t) 02 0‚Äì101 Y(œâ) œâ Figure 9.1 Left: A periodic sawtooth function. Right: The Fourier spectrum of frequencies contained in this function. Asseenin(Figure9.1right),the bn‚Äôsdecreaseinmagnitudeasthefrequencyincreases,and canenterwithapositiveornegativesign,thenegativesignindicatingrelativephase. Awarenessofthe symmetryofthefunction y(t)mayeliminatetheneedtoevaluateallthe expansioncoefficients.Forexample, ‚óèa0istwicetheaveragevalueof y:a0=2‚ü®y(t)‚ü©. ‚óèFor anoddfunction ,thatis,oneforwhich y(‚àít)=‚àíy(t),allancoefficientsequal0,and onlyhalfoftheintegrationrangeisneededtodetermine bn: bn=4 T‚à´T‚àï2 0dty(t)sinnùúît. (9.8) However,ifthereisnoinputsignalfor t<0,wedonothaveatrulyoddfunction,andso smallvaluesof anmayoccur. ‚óèForanevenfunction ,thatis,oneforwhich y(‚àít)=y(t),allbncoefficientequal0,andonly halftheintegrationrangeisneededtodetermine an: an=4 T‚à´T‚àï2 0dty(t)cosnùúît. (9.9) 9.1.1 Sawtooth and Half-Wave Functions The sawtooth function (Figure9.1left)isdescribedmathematicallyas y(t)=‚éß ‚é™ ‚é® ‚é™‚é©t T‚àï2,for0‚â§t‚â§T 2, t‚àíT T‚àï2,forT 2‚â§t‚â§T.(9.10) It is clearly periodic, nonharmonic, and discontinuous. Yet it is also odd and so can be representedmoresimplybyshiftingthesignaltotheleft: y(t)=t T‚àï2,‚àíT 2‚â§t‚â§T 2. (9.11) Althoughthegeneralshapeofthisfunctioncanbereproducedwithonlyafewtermsofthe Fouriercomponents,manycomponentsareneededtoreproducethesharpcorners.Asthe",1379
9.2 Fourier Transforms,"170 9 Fourier Analyses functionisodd,theFourierseriesisasineseries,and(9.7)determinesthe bnvalues: bn=2 T‚à´+T‚àï2 ‚àíT‚àï2dtsinnùúîtt T‚àï2=2 nùúã(‚àí1)n+1, (9.12) ‚áíy(t)=2 ùúã[ sinùúît‚àí1 2sin2ùúît+1 3sin3ùúît‚àí¬∑¬∑¬∑] . (9.13) The half-wave function y(t)={sinùúît,for0<t<T‚àï2, 0,forT‚àï2<t<T,(9.14) isperiodic,nonharmonic(theupperhalfofasinewave),andcontinuous,butwithdiscon- tinuousderivatives.Becauseitlacksthesharpcornersofthesawtoothfunction,itiseasier toreproducewithafiniteFourierseries.Equation(9.7)determines an=‚éß ‚é™ ‚é® ‚é™‚é©‚àí2 ùúã(n2‚àí1),nevenor0 , 0,nodd,bn={1 2,n=1, 0,n‚â†1, ‚áíy(t)=1 2sinùúît+1 ùúã‚àí2 3ùúãcos 2ùúît‚àí2 15ùúãcos4ùúît+. (9.15) 9.1.2 Exercises: Fourier Series Summations Hint:Theprogram FourierMatplot.py writtenbyOscarEstrepeperformsaFourieranal- ysisofasawtoothfunctionandproducesthevisualizationshownontherightofFigure9.1. Youmaywanttousethisprogramtohelpwiththisexercise. 1)Sawtooth function : Sum the Fourier series for the sawtooth function up to order N=2,4,10,20,andplottheresultsovertwoperiods. (a) Checkthatineachcasetheseriesgivesthemeanvalueofthefunction atthepoints ofdiscontinuity. (b) Checkthatineachcasetheseries overshootsbyabout9  percentthevalueofthefunction oneithersideofthediscontinuity(the Gibbsphenomenon ). 2)Half-wave function : Sum the Fourier series for the half-wave function up to order N=2,4,10,20,andplottheresultsovertwoperiods.(Theseriesconvergesquitewell, doesn‚Äôtit?) 9.2 Fourier Transforms Although a Fourier seriesis the right tool for approximating or analyzing periodicfunc- tions,theFourier transformorintegralistherighttoolforanalyzingnonperiodicfunctions. Weproceedfromtheseriestothetransformbyimaginingasystemdescribedbyacontin- uumof‚Äúfundamental‚Äùfrequencies,namely, wavepackets .1Whilethedifferencebetween 1 Wehavechosentimeandfrequencyastheconjugatevariableshere,butitcouldbeotherwise,suchas positionxandwavevector k. 9.2 Fourier Transforms 171 seriesandtransformsmayappearclearmathematically,whenweapproximatetheFourier integralasafinitesum,thetwobecomeequivalent. Byanalogywith(9.6),wenowimagineourfunctionorsignal y(t)expressedintermsofa continuousseriesofharmonics( inverseFouriertransform ): y(t)=‚à´+‚àû ‚àí‚àûdùúîY(ùúî)eiùúît ‚àö 2ùúã, (9.16) whereforcompactnessweuseacomplexexponentialfunction.2Theexpansionamplitude Y(ùúî)isanalogoustotheFouriercoefficients (an,bn),andiscalledthe Fouriertransform of y(t). The integral (9.16) is the inverse transform because it converts the transform to the signal.The Fouriertransform convertsthesignal y(t)toitstransform Y(ùúî): Y(ùúî)=‚à´+‚àû ‚àí‚àûdte‚àíiùúît ‚àö 2ùúãy(t). (9.17) The1‚àï‚àö 2ùúãfactorinboththeseintegralsisacommonnormalizationinquantummechan- ics, but may not be in engineering, where only a single 1 ‚àï2ùúãfactor is sometimes used. Likewise,thesignsintheexponentsarealsoconventionsthatdonotmatteraslongasyou maintainconsistency. Ify(t)isthemeasuredresponseofasystem(signal)asafunctionoftime,then Y(ùúî)isthe spectralfunction thatmeasurestheamountoffrequency ùúîpresentinthesignal.Inmany cases,itturnsoutthat Y(ùúî)isacomplexfunctionwithbothpositiveandnegativevalues, andwithpowers-of-tenvariationinmagnitude.Accordingly,itiscustomarytoeliminate someoftheextremevariationsof Y(ùúî)bymakingasemilogplotofthesquaredmodulus |Y(ùúî)|2versusùúî. This is called a powerspectrum and provides an immediate view of the amountofpowerorstrengthineachcomponent. IftheFouriertransformanditsinverseareconsistentwitheachother,weshouldbeable tosubstitute(9.16)into(9.17)andobtainanidentity: Y(ùúî)=‚à´+‚àû ‚àí‚àûdte‚àíiùúît ‚àö 2ùúã‚à´+‚àû ‚àí‚àûdùúî‚Ä≤eiùúî‚Ä≤t ‚àö 2ùúãY(ùúî‚Ä≤) (9.18) =‚à´+‚àû ‚àí‚àûdùúî‚Ä≤{ ‚à´+‚àû ‚àí‚àûdtei(ùúî‚Ä≤‚àíùúî)t 2ùúã} Y(ùúî‚Ä≤). (9.19) Forthistobeanidentity ,theterminbracesmustbethe Diracdeltafunction : ‚à´+‚àû ‚àí‚àûdtei(ùúî‚Ä≤‚àíùúî)t=2ùúãùõø(ùúî‚Ä≤‚àíùúî). (9.20) While the delta function is one of the most common and useful functions in theoretical physics,itisnotwellbehavedinamathematicalsense,andmisbehavesterriblyinacom- putationalsense.Whileitispossibletocreatenumericalapproximationsto ùõø(ùúî‚Ä≤‚àíùúî),they maywellbeborderlinepathological.Itiscertainlybetterforyoutodothedeltafunction partofanintegrationanalytically. 2 Recallthatexp (iùúît)=cosùúît+isinùúît,andwiththelawoflinearsuperpositionthismeansthatthereal partofygivesthecosineseries,andtheimaginarypartthesineseries.",4107
9.3 Discrete Fourier Transforms,"172 9 Fourier Analyses 9.3 Discrete Fourier Transforms Ify(t)orY(ùúî)is known analytically or numerically, the integral (9.16) and (9.17) can be evaluated using the integration techniques studied earlier. In practice, the signal y(t)is measured at just a finite number Nof timest. The resultant DFTis an approximation, bothbecausethesignalisnotknownforalltimes,andbecauseweintegratenumerically [BriggsandHenson,1995].Oncewehaveadiscretesetof(approximate)transformvalues, theycanbeusedtoreconstructthesignalforanyvalueofthetime.Inthisway,theDFT canbethoughtofasatechniqueforinterpolating,compressing,andextrapolatingasignal. Weassumethatthesignal y(t)issampledat (N+1)discretetimes( Ntimeintervals),with aconstantspacing Œît=hbetweentimes: ykdef=y(tk),k=0,1,2,‚Ä¶,N, (9.21) tkdef=kh,h=Œît. (9.22) Inotherwords,wemeasure y(t)onceevery hthofasecondforatotaltimeof T.Thiscorre- spondinglydefinesthesignal‚Äôsperiod Tandthesamplingrates : Tdef=Nh,s=N T=1 h. (9.23) Regardless of the true periodicity of the signal, when we choose a period Tover which to sample the signal, the mathematics will inevitablyproduce a y(t)that is periodic with periodT, y(t+T)=y(t). (9.24) Werecognizethisperiodicity,andensurethatthereareonly Nindependentmeasurements usedinthetransform,bydefiningthefirstandlast y‚Äôstobeequal: y0=yN. (9.25) Ifweareanalyzingatrulyperiodicfunction,thenthe Npointsshouldspanonecomplete period,butnotmore.Thisguaranteestheirindependence.Unlesswemakefurtherassump- tions,theNindependentdata y(tk)candeterminenomorethan Nindependenttransform valuesY(ùúîk). The time interval T(which should be the period for periodic functions) is the largest timeoverwhichwemeasurethevariationof y(t).Consequently,itdeterminesthelowest frequencycontainedinourFourierrepresentationof y(t), ùúî1=2ùúã T. (9.26) Thefullrangeoffrequenciesinthespectrum ùúînisdeterminedbythenumberofsamples taken,andbythetotalsamplingtime T=Nhas ùúîn=nùúî1=n2ùúã Nh,n=0,1,‚Ä¶,N. (9.27) Hereùúî0=0correspondstothezero-frequencyor DCcomponent ofthetransform,thatis, thepartofthesignalthatdoesnotoscillate. The DFT algorithm follows from two approximations. First, we evaluate the integral (9.17)fromtime0totime T,overwhichthesignalismeasured,andnotfrom ‚àí‚àûto+‚àû. 9.3 Discrete Fourier Transforms 173 Second,thetrapezoidruleisusedfortheintegration3: Y(ùúîn)def=‚à´+‚àû ‚àí‚àûdte‚àíiùúînt ‚àö 2ùúãy(t)‚âÉ‚à´T 0dte‚àíiùúînt ‚àö 2ùúãy(t), (9.28) ‚âÉN‚àë k=1hy(tk)e‚àíiùúîntk ‚àö 2ùúã=hN‚àë k=1yke‚àí2ùúãikn‚àïN ‚àö 2ùúã. (9.29) Tokeepthefinalnotationmoresymmetric,thestepsize hisfactoredfromthetransform Y andadiscretefunction Ynisdefined: Yndef=1 hY(ùúîn)=N‚àë k=1yke‚àí2ùúãikn‚àïN ‚àö 2ùúã,n=0,1‚Ä¶,N. (9.30) Withthissamecareinaccounting,andwith dùúî‚Üí2ùúã‚àïNh,weinvertthe Yn‚Äôs: y(t)def=‚à´+‚àû ‚àí‚àûdùúîeiùúît ‚àö 2ùúãY(ùúî), (9.31) ‚áíy(t)‚âÉN‚àë n=12ùúã Nheiùúînt ‚àö 2ùúãY(ùúîn). (9.32) Onceweknowthe Nvaluesofthetransform,wecanuse(9.32)toevaluate y(t)foranytime t.Thereisnothingillegalaboutevaluating Ynandykforarbitrarilylargevaluesof nandk, yetthereisalsonothingtobegained;becausethetrigonometricfunctionsareperiodic,we justgettheoldanswers: y(tk+N)=y([k+N]h)=y(tk), (9.33) Y(ùúîn+N)=Y([n+N]ùúî1)=Y(ùúîn). (9.34) Anotherwayofstatingthisistoobservethatnoneoftheequationschangeifwereplace ùúînt byùúînt+2ùúãn.Therearestilljust N-independentoutputnumbersfor Nindependentinputs, withthetransformandthereconstitutedsignalperiodic. Weseefrom(9.27)thatthelargerwemakethetime T=Nhoverwhichwesamplethe function,thesmallerwillbethefrequencystepsorresolution.4Accordingly,ifyouwanta smoothfrequencyspectrum,youwillneedtohaveasmallerfrequencystep2 ùúã‚àïT,which meanslongerobservationtime T.Whilethebestapproachwouldbetomeasuretheinput signalforalltimes,inpracticeameasuredsignal y(t)isoftenextendedintime(‚Äúpadded‚Äù) by adding zeros for times beyond the last measured signal; this increases the value of T artificiallyandmayleadtospuriousconclusions.Althoughonemaynotthinkofpadding asaddingnewinformationtotheanalysis,itdoesbuildintheassumptionthatthesignal hasnoexistenceattimesafterthelastmeasurement. WhileperiodicityisexpectedforaFourier series,itissomewhatsurprisingforaFourier integral,whichhasbeentoutedastherighttoolfornonperiodicfunctions.Clearly,ifwe input values of the signal for longer lengths of time, then the inherent period becomes longer, and if the repeat period Tis very long, it may be of little consequence for times 3 Thealertreadermaybewonderingwhathashappenedtothe h‚àï2withwhichthetrapezoidruleweights theinitialandfinalpoints.Actually,theyarethere,butbecausewehaveset y0‚â°yN,twoh‚àï2termshave beenaddedtoproduceone hterm. 4 SeealsoSection9.3.1wherewediscusstherelatedphenomenonofaliasing.",4510
9.3.1 Aliasing,"174 9 Fourier Analyses shortcomparedtotheperiod.If y(t)isactuallyperiodicwithperiod Nh,thentheDFTisan excellentwayofobtainingtheFourierseries.Iftheinputfunctionisnotperiodic,thenthe DFTcanbeabadapproximationneartheendpointsofthetimeinterval,asthefunction willrepeatthere;likewiseforthelowestfrequencies. TheDFTanditsinversecanbewritteninaconciseandinsightfulway,andbeevaluated efficiently,byintroducingacomplexvariable Zfortheexponentialandthenraising Zto variouspowers: yk=‚àö 2ùúã NN‚àë n=1Z‚àínkYn,Z=e‚àí2ùúãi‚àïN, (9.35) Yn=1‚àö 2ùúãN‚àë k=1Znkyk,Znk‚â°[Zn]k. (9.36) Withthisformulationthecomputerneedstocomputeonlypowersof Z.WegiveourDFT codeinListing9.1.Ifyourpreferenceistoavoidcomplexnumbers,wecanrewrite(9.35) intermsofseparaterealandimaginarypartsbyapplyingEuler‚Äôstheoremwith ùúÉdef=2ùúã‚àïN: Z=e‚àíiùúÉ,‚áíZ¬±nk=e‚àìinkùúÉ=cosnkùúÉ‚àìisinnkùúÉ, (9.37) ‚áíYn=1‚àö 2ùúãN‚àë k=1[cos(nkùúÉ)Reyk+sin(nkùúÉ)Imyk +i(cos(nkùúÉ)Imyk‚àísin(nkùúÉ)Reyk)], (9.38) yk=‚àö 2ùúã NN‚àë n=1[cos(nkùúÉ)ReYn‚àísin(nkùúÉ)ImYn +i(cos(nkùúÉ)ImYn+sin(nkùúÉ)ReYn)]. (9.39) Readers new to DFTs are often surprised when they apply these equations to practical situationsandendupwithtransforms Yhavingimaginaryparts,despitethefactthatthe signalyisreal.Equation(9.38)shouldmakeitclearthatarealsignal(Im yk‚â°0)willyield animaginarytransformunless‚àëN k=1sin(nkùúÉ)Reyk=0.Thisoccursonlyif y(t)isaneven functionover ‚àí‚àû‚â§t‚â§+‚àûandweintegrateexactly.Becauseneitherconditionholds,the DFTsofreal,evenfunctionsmayhavesmallimaginaryparts.Thisisnotasaresultofan errorinprogramming,andinfactyieldsameasureoftheapproximationerrorintheentire procedure. ThecomputationtimeforaDFTcanbereducedevenfurtherbyuseofthe FFTalgorithm, asdiscussedinSection9.5.Anexaminationof(9.35)showsthattheDFTisevaluatedasa matrixmultiplicationofavectoroflength Ncontainingthe Zvalues,byavectoroflength Nofyvalue. The time for this DFT scales like N2, while the time for the FFT algorithm scalesasNlog2N.Althoughthismaynotseemlikemuchofadifference,for N=102‚àí3,the differenceof103‚àí5isthedifferencebetweenaminuteandaweek.Forthisreason,itisthe FFTthatisoftenusedforon-linespectrumanalysis. 9.3.1 Aliasing The sampling of a signal by DFT for only a finite number of times and large Œît, limits theaccuracyofthededucedhigh-frequencycomponentspresentinthesignal.Obviously, 9.3 Discrete Fourier Transforms 175 sin(2 œÄt) sin( œÄt/2) ‚Äì101 246 7 Figure 9.2 A plot of the functions sin( ùúãt/2) and sin(2 ùúãt). If the sampling rate is not high enough, these signals may appear indistinguishable in a Fourier decomposition. If the sample rate is too low, and if both signals are present in a sample, the deduced low-frequency components may be contaminated by the higher-frequency ones. goodinformationaboutveryhighfrequenciesrequiressamplingthesignalwithsmalltime stepssothatallthewigglescanbeincluded.Whileapoordeductionofthehigh-frequency componentsmaybetolerable,ifallwecareaboutarethelow-frequencyones,theinaccurate high-frequencycomponentsmaycontaminatethededucedlow-frequencyones.Thiseffect iscalledaliasingandisthecauseoftheMoir√©patterndistortionindigitalimages. As an example, consider Figure 9.2 showing the two functions sin (ùúãt‚àï2)and sin(2ùúãt) for0‚â§t‚â§8,withtheirpointsofoverlapinbold.Ifwewereunfortunateenoughtosam- pleasignalcontainingthesefunctionsatthetimes t=0,2,4,6,8,thenwewouldmeasure y‚â°0andassumethattherewasnosignalatall.However,ifwewereunfortunateenough to measure the signal at the filled dots in Figure 9.2, where sin (ùúãt‚àï2)=sin(2ùúãt), specifi- cally,t=0,12 10,4 3,‚Ä¶,thenourFourieranalysiswouldcompletelymissthehigh-frequency components. In DFT jargon, we would say that the high-frequency component has been aliasedbythelow-frequencycomponent.Inothercases,somehigh-frequencyvaluesmay beincludedinoursamplingofthesignal,butoursamplingratemaynotbehighenoughto includeenoughofthemtoseparatethehigh-frequencycomponentproperly.Inthiscase, some high-frequency signals would be included spuriously as part of the low-frequency spectrum, and this would lead to spurious low-frequency oscillations when the signal is synthesizedfromitsFouriercomponents. Moreprecisely,aliasingoccurswhenasignalcontainingfrequency fissampledatarateof s=N‚àïTmeasurementsperunittime,with s‚â§f‚àï2.Inthiscase,thefrequencies fandf‚àí2s yieldthesameDFT,andwewouldnotbeabletodeterminethattherearetwofrequencies present.Thatbeingthecase,toavoidaliasingwewantnofrequencies f>s‚àï2tobepresent inourinputsignal.Thisisknownasthe Nyquistcriterion .Inpractice,someapplications avoidtheeffectsofaliasingbyfilteringoutthehighfrequenciesfromthesignal,andthen analyzingonlytheremaininglow-frequencypart.(Thelow-frequency sincfilterdiscussed in Section 9.4.4 is often used for this purpose.) Although filtering eliminates some high- frequencyinformation,itlessensthedistortionofthelow-frequencycomponents,andso mayleadtoimprovedreproductionofthesignal.",4764
9.3.2 Assessments,"176 9 Fourier Analyses Ifaccuratevaluesforthehighfrequenciesarerequired,thenyouwillneedtoincrease thesamplingrate sbyincreasingthenumber Nofsamplestakenwithinthefixedsampling timeT=Nh.Bykeepingthesamplingtimeconstantandincreasingthenumberofsamples taken,wemakethetimestep hsmallerandpickupthehigherfrequencies.Byincreasing thenumber Noffrequenciesthatyoucompute,youmovetheprevioushigher-frequency componentsclosertothemiddleofthespectrum,andthusawayfromtheerror-proneends. Ifweincreasethetotaltimesamplingtime T=Nhandkeephthesame,thenthesam- plingrates=N‚àïT=1‚àïhremainsthesame.Since ùúî1=2ùúã‚àïT,thismakes ùúî1smaller,which meanswehavemorelowfrequenciesrecordedandasmootherfrequencyspectrum.And aswesaid,thisisoftencarriedout,afterthefact,bypaddingtheendofthedatasetwith zeros. Exercise 1) The sampling of a signal by DFT for only a finite number of times not only limits the accuracy of the deduced high-frequency components, but also contaminates the deduced low-frequency components ( aliasing). Consider the two functions sin (ùúãt‚àï2) andsin(2ùúãt)for0‚â§t‚â§8. (a) Makegraphsofbothfunctionsonthesameplot. (b) PerformaDFTonbothfunctions. (c) Sampleattimes t=0,2,4,6,8,‚Ä¶anddrawconclusions. (d) Sampleattimes t=0,12‚àï10,4‚àï3,‚Ä¶anddrawconclusionsaboutthehigh-frequency components( Hint:Theymaybe aliasedbythelow-frequencycomponents). (e) TheNyquistcriterion statesthatwhenasignalcontainingfrequency fissampledat arateofs=N‚àïT,measurementsperunittime,with s‚â§f‚àï2,thenaliasingoccurs. Verifyspecificallythatthefrequencies fandf‚àí2syieldthesameDFT. 2) PerformaFourieranalysisofthechirpsignal y(t)=sin(60t2).AsseeninFigure10.5,this signalisnottrulyperiodic,andisbetteranalyzedwithmethodssoontobediscussed. 9.3.2 Assessments Simple analytic input :Itisalwaysgoodtodosimplechecksbeforeexaminingmorecom- plexproblems,evenifyouareusingapackage‚ÄôsFouriertool. 1) Sampletheevensignal y(t)=3cos(ùúît)+2cos(3ùúît)+cos(5ùúît). (9.40) (a) Decomposethisintoitscomponents. (b) Checkthatthecomponentsareessentiallyrealandintheratio3:2:1(or9:4:1 forthepowerspectrum). (c) Verifythatthefrequencieshavetheexpectedvalues(notjustratios). (d) Verifythecomponentssumuptogivetheinputsignal. (e) Experimenton theseparateeffects ofpickingdifferent valuesofthestep size h andofenlargingthemeasurementperiod T=Nh. 2) Sampletheoddsignal y(t)=sin(ùúît)+2sin(3ùúît)+3sin(5ùúît). (9.41) 9.3 Discrete Fourier Transforms 177 Decompose this into its components, and then check that they are essentially imaginaryand in the ratio 1:2:3 (or 1:4:9 if a power spectrum is plotted).Check thattheysumuptogivetheinputsignal. 3) Samplethemixed-symmetrysignal y(t)=5sin(ùúît)+2cos(3ùúît)+sin(5ùúît). (9.42) Decomposethisintoitscomponents,andthencheckthattheyareintheratio5:2:1 (or25:4:1ifapowerspectrumisplotted).Checkthattheysumuptogivetheinput signal. 4) Samplethesignal y(t)=5+10sin(t+2). Compareandexplaintheresultsobtainedbysampling(a)withoutthe5,(b)asgiven butwithoutthe2,and(c)withoutthe5andthe2. 5) Inourdiscussionofaliasing,weexaminedFigure9.2showingthefunctionssin (ùúãt‚àï2) andsin(2ùúãt).Samplethefunction y(t)=sin(ùúã 2t)+sin(2ùúãt) (9.43) andexplorehowaliasingoccurs.Explicitly,weknowthatthetruetransformcontains peaksatùúî=ùúã‚àï2andùúî=2ùúã.Samplethesignalataratethatleadstoaliasing,aswell asatahighersamplingrateatwhichthereisnoaliasing.ComparetheresultingDFTs ineachcaseandcheckifyourconclusionsagreewiththeNyquistcriterion. Highly nonlinear oscillator : Recall the numerical solution for oscillations of a spring withpower p=12[see(9.1)].DecomposethesolutionintoaFourierseriesanddeter- minethenumberofhigherharmonicsthatcontributeatleast10  percent;forexample,deter- minethenforwhich |bn‚àïb1|<0.1.Checkthatresumingthecomponentsreproducesthe signal. Nonlinearly perturbed oscillator :Remembertheharmonicoscillatorwithanonlinear perturbation(8.2): V(x)=1 2kx2( 1‚àí2 3ùõºx) ,F(x)=‚àíkx(1‚àíùõºx). (9.44) Forverysmall amplitudesofoscillation( x‚â™1‚àïùõº),thesolution x(t)essentiallyshould beonlythefirsttermofaFourierseries.( Warning:Theùúîyouuseinyourseriesmust correspondtothe truefrequencyofthesystem,notthe ùúî0ofsmalloscillations. 1) Wewantthesignaltocontain‚Äúapproximately10 percentnonlinearity.‚ÄùThisbeingthecase, fix your value of ùõºso thatùõºxmax‚âÉ10 percent,w h e r exmaxis the maximum amplitude of oscillation.Fortherestoftheproblem,keepthevalueof ùõºfixed. 2) DecomposeyournumericalsolutionintoadiscreteFourierspectrum. 3)Plotagr aphoftheper centageofimportanceofthefirst two,non-DCFouriercom- ponentsasafunctionoftheinitialdisplacementfor0 <x0<1‚àï2ùõº.Youshouldfind thathigherharmonicsaremoreimportantastheamplitudeincreases.Becauseboth evenandoddcomponentsarepresent, Ynshouldbecomplex.Becausea10 percenteffectin amplitudebecomesa1 percenteffectinpower,makesurethatyoumakeasemilogplotof thepowerspectrum. 4) Asalways,checkthatresummationsofyourtransformsreproducethesignal.",4765
9.3.3 Transforming Nonperiodic Functions. 9.4 Noise Filtering. 9.4.1 Noise Reduction via Autocorrelation,"178 9 Fourier Analyses 9.3.3 Transforming Nonperiodic Functions Consideranelectroninitiallylocalizedaround x=5.Amodeltodescribethis‚Äúlocalized‚Äù electronisaGaussianmultiplyingaplanewave: ùúì(x,t=0)=exp[ ‚àí1 2( x‚àí5 ùúé0)2] eik0x, (9.45) where we use natural units in which ‚Ñè=1. This wave packet is not an eigenstate of the momentumoperator p=id‚àïdx,butrathercontainsaspreadofmomenta.Your problem istoevaluatetheFouriertransform, ùúì(p)=‚à´+‚àû ‚àí‚àûdxeipx ‚àö 2ùúãùúì(x,0), (9.46) asawayofdeterminingthemomentacomponentsin(9.45). 9.4 Noise Filtering In the process of solving this problem, we examine two simple approaches: the use of auto- correlationfunctionsandtheuseoffilters.Bothapproachesfindwideapplicationsinscience, withourdiscussionnotdoingthesubjectsjustice.Wewillseefiltersagaininthediscussionof waveletsinChapter 10. Youmeasureasignal y(t)thatobviouslycontainsnoise.Your problemistodetermine thefrequenciesthatwouldbepresentinthespectrumofthesignaliftherewerenonoise. Ofcourse,onceyouhaveaFouriertransformfromwhichthenoisehasbeenremoved,you cantransformittoobtainanoise-freesignal s(t). 9.4.1 Noise Reduction via Autocorrelation We assume that the measured signal is the sum of the true signal s(t), which we wish to determine,plussomeunwelcome noisen(t): y(t)=s(t)+n(t), (9.47) One approach at removing the noise relies on the fact that noise is usually random, and thusshouldnotbecorrelatedwiththesignal.Yetwhatdowemeanwhenwesaythattwo functionsarenot correlated? Well,ifthetwotendtooscillatewiththeirnodesandpeaksin muchthesameplaces,thenthetwofunctionsareclearlycorrelated.Ananalyticmeasure ofthecorrelationoftwoarbitraryfunctions y(t)andx(t)isthecorrelationfunction c(ùúè)=‚à´+‚àû ‚àí‚àûdty(t)x(t+ùúè)‚â°‚à´+‚àû ‚àí‚àûdty(t‚àíùúè)x(t), (9.48) Hereùúè,thelagtime,isavariable,andweassumethattheaveragevaluesofthefunctions havebeensubtractedoff,sothattheyoscillatearoundzero.Evenifthetwosignalshavedif- ferentmagnitudes,iftheyhavesimilartimedependencies,exceptforonelaggingorleading theother,thenforcertainvaluesof ùúè,theintegrandin(9.48)willbepositiveforallvalues 9.4 Noise Filtering 179 oft.Forthosevaluesof ùúè,thetwosignalsinterfereconstructivelyandproducealargevalue forthecorrelationfunction.Incontrast,ifbothfunctionsoscillateindependently,regardless ofthevalueof ùúè,thenitisjustaslikelyfortheintegrandtobepositiveastobenegative,in whichcasethetwosignalsinterferedestructivelyandproduceasmallvaluefortheintegral. Beforeweapplythecorrelationfunctiontoourproblem,letusstudysomeofitsproper- ties.Weuse(9.16)toexpress c,y,andxintermsoftheirFouriertransforms: c(ùúè)=‚à´+‚àû ‚àí‚àûdùúî‚Ä≤‚Ä≤C(ùúî‚Ä≤‚Ä≤)eiùúî‚Ä≤‚Ä≤t ‚àö 2ùúã,y(t)=‚à´+‚àû ‚àí‚àûdùúîY(ùúî)e‚àíiùúît ‚àö 2ùúã, x(t+ùúè)=‚à´+‚àû ‚àí‚àûdùúî‚Ä≤X(ùúî‚Ä≤)e+iùúît ‚àö 2ùúã. (9.49) Seeingthat ùúî,ùúî‚Ä≤,andùúî‚Ä≤‚Ä≤aredummyvariables,othernamesmaybeusedforthemwithout changingtheresults.Whenwesubstitutetheserepresentationsintothedefinition(9.48)of thecorrelationfunction,andassumethattheresultingintegralsconvergewellenoughto berearranged,weobtain ‚à´+‚àû ‚àí‚àûdùúîC(ùúî)eiùúît=‚à´+‚àû ‚àí‚àûdùúî 2ùúã‚à´+‚àû ‚àí‚àûdùúî‚Ä≤Y(ùúî)X(ùúî‚Ä≤)eiùúîùúè2ùúãùõø(ùúî‚Ä≤‚àíùúî) =‚à´+‚àû ‚àí‚àûdùúîY(ùúî)X(ùúî)eiùúîùúè, ‚áíC(ùúî)=‚àö 2ùúãY(ùúî)X(ùúî), (9.50) where the last line follows because ùúî‚Ä≤‚Ä≤andùúîare equivalent dummy variables. Equation (9.50)saysthattheFouriertransformofthecorrelationfunctionoftwosignalsispropor- tionaltotheproductoftheirtransforms.(Weshallseearelatedconvolutiontheoremfor filters.) A special case of the correlation function c(ùúè)is theautocorrelation function A (ùúè)that measuresthecorrelationofatimesignalwithitself: A(ùúè)def=‚à´+‚àû ‚àí‚àûdty(t)y(t+ùúè)‚â°‚à´+‚àû ‚àí‚àûdty(t)y(t‚àíùúè). (9.51) Thisfunctioniscomputedbytakingasignal y(t)thathasbeenmeasuredoversometime period,andthenaveragingitovertimeusing, y(t+ùúè)asaweightingfunction.Thisprocess iscalledfolding,orconvoluting ,afunctionontoitself(asmightbedonewithdough).Tosee how this folding removes noise from a signal, we go back to the measured signal (9.47), whichwasthesumofpuresignalplusnoise s(t)+n(t).Asanexample,ontheupperleft inFigure9.3,weshowasignalthatwasconstructedbyaddingrandomnoisetoasmooth signal.Whenwecomputetheautocorrelationfunctionforthissignal,weobtainafunction (upperrightinFigure9.3)thatlookslikeabroadened,smoothedversionofthesignal y(t). WecanunderstandhowthenoiseisremovedbytakingtheFouriertransformof s(t)+n(t) toobtainasimplesumoftransforms: Y(ùúî)=S(ùúî)+N(ùúî), (9.52) {S(ùúî) N(ùúî)} =‚à´+‚àû ‚àí‚àûdt{s(t) n(t)} e‚àíiùúît ‚àö 2ùúã. (9.53) 180 9 Fourier Analyses 0246810 0 2 4 6 8 10 12Initial function y(t) + noise t (s)y 0.40.60.81.01.21.4√ó102 √ó1030 2 4 6 8 10 12Autocorrelation function A(T) T (s)A 0.00.51.01.52.02.53.03.5 P 0 510 15 20 25 30 35 40 45Power spectrum (with noise) Frequency10 y 02468 0 2 4 6 8 10 12Function y(t) + noise after low-pass filter t (s) Figure 9.3 From bottom left to right : A function that is a signal plus noise s(t)+n(t);t h e autocorrelation function versus time deduced by processing this signal; the power spectrum obtained from autocorrelation function; the signal plus noise after passage through a lowpass Ô¨Ålter. Becausetheautocorrelationfunction(9.51)for y(t)=s(t)+n(t)involvesthesecondpower ofy,isnotalinearfunction,thatis, Ay‚â†As+An,butinstead, Ay(ùúè)=‚à´+‚àû ‚àí‚àûdt[s(t)s(t+ùúè)+s(t)n(t+ùúè)+n(t)n(t+ùúè)]. (9.54) If we assume that the noise n(t)in the measured signal is truly random, then it should average to zero over long times and be uncorrelated at times tandt+ùúè. This being the case,bothintegralsinvolvingthenoisevanish,andso Ay(ùúè)‚âÉ‚à´+‚àû ‚àí‚àûdts(t)s(t+ùúè)=As(ùúè). (9.55) Thus,thepartofthenoisethatisrandomtendstobeaveragedoutoftheautocorrelation function,andweareleftwithanapproximationoftheautocorrelationfunctionofthepure signal. Sohowdoesthishelpus?Applicationof(9.50)with Y(ùúî)=X(ùúî)=S(ùúî)tellsusthatthe Fouriertransform A(ùúî)oftheautocorrelationfunctionisproportionalto |S(ùúî)|2: A(ùúî)=‚àö 2ùúã|S(ùúî)|2. (9.56) Thefunction |S(ùúî)|2isthepowerspectrum ofthepuresignal.Thus,evaluationoftheauto- correlationfunctionofthenoisysignalgivesusthepuresignal‚Äôspowerspectrum,whichis oftenallthatweneedtoknow.Forexample,inFigure9.3weseeanoisysignal(lowerleft, theautocorrelationfunction(lowerright,whichclearlyissmootherthan thesignal,and finally,thededucedpowerspectrum(upperleft).Noticethatthebroadbandhigh-frequency componentscharacteristicofnoiseareabsentfromthepowerspectrum. Youcaneasilymodifythesampleprogram DFTcomplex.py inListing9.1or DFTreal.py in Listing 9.2 sample program DFTcomplex.py in Listing 9.1 to compute the autocorrelation functionandthenthepowerspectrum A(ùúè).Theprogram NoiseSincFilter.py doesjustthat.",6333
9.4.2 Autocorrelation Function Exercises. 9.4.3 Filtering with Transforms,"9.4 Noise Filtering 181 9.4.2 Autocorrelation Function Exercises 1) Imagine thatyouhavesampledthepuresignal s(t)=1 1‚àí0.9sint. (9.57) Although there is just a single sine function in the denominator, there is an infinite numberofovertonesasyoucanseefromtheexpansion s(t)‚âÉ1+0.9sint+(0.9sint)2+(0.9sint)3+¬∑¬∑¬∑. (9.58) (a) ComputetheDFT S(ùúî).Makesurenottosamplejustoneperiod,butalsotocover theentireperiod.Alsomakesuretosampleatenoughtimes(finescale)toobtain goodsensitivitytothehigh-frequencycomponents. (b) Makeasemilogplotofthepowerspectrum |S(ùúî)|2. (c) Takeyourinputsignal s(t)andcomputeitsautocorrelationfunction A(ùúè)forafull rangeofùúèvalues(ananalyticsolutionisokaytoo). (d) ComputethepowerspectrumindirectlybyperformingaDFTontheautocorrela- tionfunction.Compareyourresultstothespectrumobtainedbycomputing |S(ùúî)|2 directly. 2) Addsomerandomnoisetothesignalusingarandomnumbergenerator: y(ti)=s(ti)+ùõº(2ri‚àí1),0‚â§ri‚â§1, (9.59) whereùõºisanadjustableparameterand riarerandomnumbers.Tryseveralvaluesof ùõº, fromsmallonesthatjustaddsomefuzztothesignaltolargeonesthatnearlyhidethe signal. (a) Plot your noisy data, their Fourier transform, and their power spectrum obtained directlyfromthetransformwithnoise. (b) Computetheautocorrelationfunction A(ùúè)anditsFouriertransform A(ùúî). (c) ComparetheDFTof A(ùúè)tothetruepowerspectrum.Commentontheeffectiveness ofreducingnoisebyuseoftheautocorrelationfunction. (d) Forwhatvalueof ùõºdoyouessentiallylosealltheinformationintheinput? 9.4.3 Filtering with Transforms A filter(Figure9.4)isadevicethatconvertsaninputsignal f(t)toanoutputsignal g(t),with somespecificpropertyfor g(t).Morespecifically,an analogfilter isdefinedasintegration overaninputfunction[Hartmann,1998]: g(t)=‚à´+‚àû ‚àí‚àûdùúèf(ùúè)h(t‚àíùúè)def=f(t)‚àóh(t). (9.60) Heretheasterisk ‚àóindicatesa convolution ,whichwehavealreadyseeninthediscussion oftheautocorrelationfunction.Thefunction h(t)istheunitresponse ortransferfunction of Figure 9.4 An input signal f(t)passes through a Ô¨Ålter hthat outputs the function g(t). f(t) g(t) h 182 9 Fourier Analyses thefilter;itistheresponseofthefiltertoaunitimpulse: h(t)=‚à´+‚àû ‚àí‚àûdùúèùõø(ùúè)h(t‚àíùúè). (9.61) Equation(9.60)statesthattheoutput g(t)ofafilterequalstheinput f(t)convolutedwith thetransferfunction h(t‚àíùúè).Becausetheargumentoftheresponsefunctionisdelayedby atimeùúèrelativetothatofthesignalintheintegral(9.60), ùúèiscalledthe lagtime.While theintegrationisoveralltimes,theresponseofagooddetectorusuallypeaksaroundzero time.Inanycase,theresponsemustequalzerofor ùúè>tbecauseeventsinthefuturecannot affectthepresent(causality). Theconvolutiontheorem statesthattheFouriertransformoftheconvolution g(t)ispro- portionaltotheproductofthetransformsof f(t)andh(t): G(ùúî)=‚àö 2ùúãF(ùúî)H(ùúî). (9.62) Thetheoremresultsfromexpressingthefunctionsin(9.60)bytheirtransforms,andusing the resulting Dirac delta function to evaluate an integral (essentially what we did in our discussionofthecorrelationfunction). Filtering,aswehavedefinedit,isalinearprocessinvolvingjustthefirstpowersofthe signalf.Thismeansthattheoutputatonefrequencyisproportionaltotheinputatthat frequency. The constant of proportionality between the two may change with frequency, andthussuppressspecificfrequenciesrelativetoothers,butthatconstantremainsfixedin time.Sincethelawoflinearsuperpositionisvalidforlinearfilters,iftheinputtoafilter is the sum of various functions, then the transform of the output will be the sum of the functions‚ÄôFouriertransforms. Filters that remove or decrease high-frequency components more than they do low- frequency ones, are called lowpassfilters. Those that filter out the low frequencies are calledhighpassfilters .Asimplelowpassfilteristhe RCcircuitontheleftofFigure9.5that producesthetransferfunction H(ùúî)=1 1+iùúîùúè=1‚àíiùúîùúè 1+ùúî2ùúè2, (9.63) whereùúè=RCisthetimeconstant.The ùúî2inthedenominatorleadstoadecreaseinthe responseathighfrequenciesandthereforemakesthisalowpassfilter(the iùúîaffectsonly thephase).Asimplehighpassfilteristhe RCcircuitontherightinFigure9.5thatproduces thetransferfunction H(ùúî)=iùúîùúè 1+iùúîùúè=iùúîùúè+ùúî2ùúè2 1+ùúî2ùúè2. (9.64) Weseethat H=1atlarge ùúî,yetvanishesas ùúî‚Üí0;asexpectedforahighpassfilter. In In RR CC OutOut Figure 9.5 Left:A nCRcircuit arranged as a lowpass Ô¨Ålter. Right:A nCRcircuit arranged as a highpass Ô¨Ålter.",4214
9.4.4 Digital Filters Windowed Sinc Filters,"9.4 Noise Filtering 183 Figure 9.6 A delay-line Ô¨Ålter in which the signal at different times is scaled by different amounts ci.Œ£œÑ œÑ œÑIn OutC3 C2 C1 C0 Filterscomposedofresistorsandcapacitorsarefineforanalogsignalprocessing,butfor digitalprocessingwewanta digitalfilter thathasaspecificresponsefunctionforeachfre- quencyrange.Aphysicalmodelforadigitalfiltermaybeconstructedfromadelaylinewith tapsatvariousspacingalongtheline(Figure9.6)[Hartmann,1998].Thesignalreadfrom tapnisjusttheinputsignaldelayedbytime nùúè,wherethedelaytime ùúèisacharacteristicof theparticularfilter.Theoutputfromeachtapisdescribedbythetransferfunction ùõø(t‚àínùúè), possiblywithscalingfactor cn.AsrepresentedbythetriangleontherightinFigure9.6,the signalsfromalltapsareultimatelysummedtogethertoformthetotalresponsefunction: h(t)=N‚àë n=0cnùõø(t‚àínùúè). (9.65) Inthefrequencydomain,theFouriertransformofadeltafunctionisanexponential,and so(9.65)resultsinthetransferfunction H(ùúî)=N‚àë n=0cne‚àíinùúîùúè, (9.66) wheretheexponentialindicatesthephaseshiftfromeachtap. If a digital filter is given a continuous time signal f(t)as input, its output will be the discretesum g(t)=‚à´+‚àû ‚àí‚àûdt‚Ä≤f(t‚Ä≤)N‚àë n=0cnùõø(t‚àít‚Ä≤‚àínùúè)=N‚àë n=0cnf(t‚àínùúè). (9.67) Andofcourse,ifthesignal‚Äôsinputisadiscretesum,itsoutputwillremainadiscretesum. Ineithercase,weseethatknowledgeofthefiltercoefficients ciprovidesuswithallweneed toknowaboutadigitalfilter.IfwelookbackatourworkontheDFTinSection9.3,wecan viewadigitalfilter(9.67)asaFouriertransforminwhichweusean N-pointapproximation totheFourierintegral.The cn‚Äôsthencontainboththeintegrationweightsandthevaluesof theresponsefunctionattheintegrationpoints.Accordingly,thetransformcanbeviewed asafilterofthesignalintospecificfrequencies. 9.4.4 Digital Filters: Windowed Sinc Filters ‚äô Apopularwaytoseparatethebandsoffrequenciesinasignaliswitha windowedsincfilter [Smith,1999].Thisfilterisbasedontheobservationthatanideal lowpassfilterpassesallfre- quenciesbelowacutofffrequency ùúîc,andblocksallfrequenciesabovethisfrequency.And becausetheretendstobemorenoiseathighfrequenciesthanatlowfrequencies,remov- ingthehighfrequenciestendstoremovemorenoisethansignal,althoughsomesignalis inevitablylost.OneuseforwindowedsincfiltersisinreducingaliasinginDFTsbyremov- ingthehigh-frequencycomponentofasignalbeforedeterminingitsFouriercomponents. ThegraphonthelowerrightinFigure9.1wasobtainedbypassingournoisysignalthrough asincfilter(usingtheprogram NoiseSincFilter.py ). 184 9 Fourier Analyses 001/21 1/2œâ ‚Äì1/2Figure 9.7 The rectangle function rect (ùúî)that is constant for a Ô¨Ånite frequency interval. The Fourier transform of this function is sinc( t). Ifbothpositiveandnegativefrequenciesareincluded,anideallow-frequencyfilterwill lookliketherectangularpulseinfrequencyspace: H(ùúî,ùúîc)=rect( ùúî 2ùúîc) ,rect(ùúî)={ 1,if|ùúî|‚â§1 2, 0,otherwise .(9.68) Hererect (ùúî)istherectangularfunction(Figure9.7).Althoughmaybenotobvious,arect- angularpulseinthefrequencydomainhasaFouriertransformthatisproportionaltothe sincfunction inthetimedomain[Smith,1991]: ‚à´+‚àû ‚àí‚àûdùúîe‚àíiùúîtrect(ùúî)=sinc( t 2)def=nsin(ùúãt‚àï2) ùúãt‚àï2, (9.69) wherethe ùúã‚Äôsaresometimesomitted.Consequently,wecanfilteroutthehigh-frequency componentsofasignalbyconvolutingitwithsin (ùúîct)‚àï(ùúîct),atechniquealsoknownasthe Nyquist‚ÄìShannon interpolationformula.Intermsofdiscretetransforms,thetime-domain representationofthesincfilterissimply h[i]=sin(ùúîci) iùúã. (9.70) Becauseallfrequenciesbelowthecutofffrequency ùúîcarepassedwithunitamplitude,while allhigherfrequenciesareblocked,wecanseetheimportanceofasincfilter. Inpractice,thereareanumberofproblemsinusingthesincfunctionasthefilter.First, asformulated,thefilteris noncausal;thatis,therearecoefficientsatnegativetimes,which violatescausalitybecausewedonotstartmeasuringthesignaluntil t=0.Second,inorder toproduceaperfectrectangularresponse,wewouldhavetosamplethesignalataninfinite numberoftimes.Inpractice,wesampleat (M+1)points(Meven)placedsymmetrically aroundthemainlobeofsin (ùúãt)‚àïùúãt,andthenshifttimestopurelypositivevalues: h[i]=sin[2ùúãùúîc(i‚àíM‚àï2)] i‚àíM‚àï2,0‚â§t‚â§M. (9.71) Asmightbeexpected,apenaltyisincurredformakingthefilterdiscrete;insteadoftheideal rectangularresponse,weobtainsome Gibbsovershoot ,withroundedcornersandoscilla- tionsbeyondthecorner. Therearetwowaystoreducethedeparturesfromtheidealfilter.Thefirstistoincreasethe lengthoftimesoverwhichthesignalissampled,whichinevitablyleadstolongercompute times.Theotherwayistosmoothoutthetruncationofthesincfunctionbymultiplyingit withasmoothlytaperedcurve,likethe Hammingwindowfunction : ùë§[i]=0.54‚àí0.46 cos( 2ùúãi M) . (9.72) Inthiswaythefilter‚Äôskernelbecomes h[i]=sin[2ùúãùúîc(i‚àíM‚àï2)] i‚àíM‚àï2[ 0.54‚àí0.46 cos( 2ùúãi M)] . (9.73)",4593
9.5 Fast Fourier Transform,"9.5 Fast Fourier Transform ‚äô185 Thecutofffrequency ùúîcshouldbeafractionofthesamplingrate.Thetimelength Mdeter- minesthebandwidth overwhichthefilterchangesfrom1to0. Exercise Repeattheexercisethataddedrandomnoisetoaknownsignal,thistimeusing thesincfiltertoreducethenoise.Seehowsmallyoucanmaketherelativestrengthofthe signal,andstillbeabletoseparateitfromthenoise. 9.5 Fast Fourier Transform ‚äô Wehaveseenin(9.35)thataDFTcanbewritteninthecompactform Yn=1‚àö 2ùúãN‚àë k=1Znkyk,Z=e‚àí2ùúãi‚àïN,n=0,1,‚Ä¶,N‚àí1. (9.74) Evenifthesignalelements yktobetransformedarereal, Ziscomplex,andthereforewe mustprocessbothrealandimaginarypartswhencomputingtransforms.Becauseboth n andkrange over Nintegervalues, the (Zn)kykmultiplicationsin (9.74)require some N2 multiplicationsandadditionsofcomplexnumbers.As Ngetslarge,ashappensinrealistic applications,thisgeometricincreaseinthenumberofstepsslowsdownthecomputation. In1965,CooleyandTurkeydiscoveredanalgorithm5thatreducesthenumberofoper- ationsnecessarytoperformaDFTfrom N2toroughly Nlog2N[CooleyandTukey,1965; DonnellyandRust,2005].Althoughthismaynotseemlikesuchabigdifference,itrepre- sentsa100-foldspeedupfor1000datapoints,whichchangesafulldayofprocessinginto 15min of work. Due to its widespread use (including cell phones), the FFT algorithm is consideredoneofthe10mostimportantalgorithmsofalltime. The idea behind the FFT is to utilize the periodicity inherent in the definition of the DFT(9.74)to reducethetotal numberofcomputationalsteps. Essentially,thealgorithm dividestheinputdataintotwoequalgroupsandtransformsonlyonegroup,whichrequires ‚àº(N‚àï2)2multiplications.Itthendividestheremaining(untransformed)groupofdatain halfandtransformsthem,continuingtheprocessuntilallthedatahavebeentransformed. Thetotalnumberofmultiplicationsrequiredwiththisapproachisapproximately Nlog2N. Specifically,theFFTstimeeconomyarisesfromthecomputationallyexpensivecomplex factorZnk[= [(Z)n]k]havingvaluesthatarerepeatedastheintegers nandkvarysequen- tially.Forinstance,for N=8, Y0=Z0y0+Z0y1+Z0y2+Z0y3+Z0y4+Z0y5+Z0y6+Z0y7, Y1=Z0y0+Z1y1+Z2y2+Z3y3+Z4y4+Z5y5+Z6y6+Z7y7, Y2=Z0y0+Z2y1+Z4y2+Z6y3+Z8y4+Z10y5+Z12y6+Z14y7, Y3=Z0y0+Z3y1+Z6y2+Z9y3+Z12y4+Z15y5+Z18y6+Z21y7, Y4=Z0y0+Z4y1+Z8y2+Z12y3+Z16y4+Z20y5+Z24y6+Z28y7, Y5=Z0y0+Z5y1+Z10y2+Z15y3+Z20y4+Z25y5+Z30y6+Z35y7, Y6=Z0y0+Z6y1+Z12y2+Z18y3+Z24y4+Z30y5+Z36y6+Z42y7, Y7=Z0y0+Z7y1+Z14y2+Z21y3+Z28y4+Z35y5+Z42y6+Z49y7, 5 Actually,thisalgorithmhasbeendiscoveredanumberoftimes,forinstance,in1942byDandelionand LancersDanielsonandLanczos[1942],aswellasmuchearlier 186 9 Fourier Analyses whereweinclude Z0(‚â°1)forclarity.Whenweactuallyevaluatethesepowersof Z,wefind onlyfourindependentvalues: Z0=exp(0)=+1, Z1=exp( ‚àí2ùúã 8) =+‚àö 2 2‚àíi‚àö 2 2, Z2=exp( ‚àí2‚ãÖ2iùúã 8) =‚àíi,Z3=exp( ‚àí2ùúã‚ãÖ3i 8) =‚àí‚àö 2 2‚àíi‚àö 2 2, Z4=exp( ‚àí2ùúã‚ãÖ4i 8) =‚àíZ0,Z5=exp( ‚àí2ùúã‚ãÖ5i 8) =‚àíZ1, Z6=exp( ‚àí2‚ãÖ6iùúã 8) =‚àíZ2,Z7=exp( ‚àí2‚ãÖ7iùúã 8) =‚àíZ3, Z8=exp( ‚àí2ùúã‚ãÖ8i 8) =+Z0,Z9=exp( ‚àí2ùúã‚ãÖ9i 8) =+Z1, Z10=exp( ‚àí2ùúã‚ãÖ10i 8) =+Z2,Z11=exp( ‚àí2ùúã‚ãÖ11i 8) =+Z3, Z12=exp( ‚àí2ùúã‚ãÖ11i 8) =‚àíZ0,‚Ä¶. (9.75) Whensubstitutedintothedefinitionsofthetransforms,weobtain Y0=Z0y0+Z0y1+Z0y2+Z0y3+Z0y4+Z0y5+Z0y6+Z0y7, Y1=Z0y0+Z1y1+Z2y2+Z3y3‚àíZ0y4‚àíZ1y5‚àíZ2y6‚àíZ3y7, Y2=Z0y0+Z2y1‚àíZ0y2‚àíZ2y3+Z0y4+Z2y5‚àíZ0y6‚àíZ2y7, Y3=Z0y0+Z3y1‚àíZ2y2+Z1y3‚àíZ0y4‚àíZ3y5+Z2y6‚àíZ1y7, Y4=Z0y0‚àíZ0y1+Z0y2‚àíZ0y3+Z0y4‚àíZ0y5+Z0y6‚àíZ0y7, Y5=Z0y0‚àíZ1y1+Z2y2‚àíZ3y3‚àíZ0y4+Z1y5‚àíZ2y6+Z3y7, Y6=Z0y0‚àíZ2y1‚àíZ0y2+Z2y3+Z0y4‚àíZ2y5‚àíZ0y6+Z2y7, Y7=Z0y0‚àíZ3y1‚àíZ2y2‚àíZ1y3‚àíZ0y4+Z3y5+Z2y6+Z1y7, Y8=Y0. (9.76) Weseethatthesetransformsnowrequire8 √ó8=64multiplicationsofcomplexnumbers,in additiontosomelesstime-consumingadditions.Weplacetheseequationsinanappropriate formforcomputingbyregroupingthetermsintosumsanddifferencesofthe y‚Äôs: Y0=Z0(y0+y4)+Z0(y1+y5)+Z0(y2+y6)+Z0(y3+y7), Y1=Z0(y0‚àíy4)+Z1(y1‚àíy5)+Z2(y2‚àíy6)+Z3(y3‚àíy7), Y2=Z0(y0+y4)+Z2(y1+y5)‚àíZ0(y2+y6)‚àíZ2(y3+y7), Y3=Z0(y0‚àíy4)+Z3(y1‚àíy5)‚àíZ2(y2‚àíy6)+Z1(y3‚àíy7), Y4=Z0(y0+y4)‚àíZ0(y1+y5)+Z0(y2+y6)‚àíZ0(y3+y7), Y5=Z0(y0‚àíy4)‚àíZ1(y1‚àíy5)+Z2(y2‚àíy6)‚àíZ3(y3‚àíy7), Y6=Z0(y0+y4)‚àíZ2(y1+y5)‚àíZ0(y2+y6)+Z2(y3+y7), Y7=Z0(y0‚àíy4)‚àíZ3(y1‚àíy5)‚àíZ2(y2‚àíy6)‚àíZ1(y3‚àíy7), Y8=Y0. (9.77) Notetherepeatingfactorsinsidetheparentheses,withcombinationsoftheform yp¬±yq. These symmetries are systematized by introducing the butterfly operation (Figure 9.8). Thisoperationtakesthe ypandyqdataelementsfromtheleftwingandconvertsthemto",4212
9.5.1 Bit Reversal,"9.5 Fast Fourier Transform ‚äô187 Figure 9.8 The basic butterÔ¨Çy operation in which elements ypand yqon the left are transformed into yp+Zyqandyp‚àíZyqon the right.yp ypZyp + Zyq yp ‚Äì Zyq y7Z0 Z2Z2Z0Z0Z0 Z2 Z1 Z3Z0Z0Z0 y6y5y4y3y2y1y0 y0 + y4 (y0 + y4) + Z0(y2 + y6) (y1 + y5) + Z0(y3 + y7) (y0 + y4) ‚Äì Z0(y2 + y6) (y1 + y5) ‚Äì Z0(y3 + y7) (y0 + y4) ‚Äì Z2(y2 ‚Äì y6) (y1 ‚Äì y5) ‚Äì Z2(y3 ‚Äì y7)y1 + y5 y2 + y6 y3 + y7 y0 ‚Äì y4 y1 ‚Äì y5 y2 ‚Äì y6 y3 ‚Äì y7Y7 = (y0 ‚Äì y4) ‚Äì Z2 (y2 ‚Äì y6) ‚Äì Z3 (y1 ‚Äì y5) + Z1 (y3 ‚Äì y7)Y3 = (y0 ‚Äì y4) ‚Äì Z2 (y2 ‚Äì y6) + Z3 (y1 ‚Äì y5) + Z1 (y3 ‚Äì y7)  Y5 = (y0 ‚Äì y4) + Z2 (y2 ‚Äì y6) ‚Äì Z1 (y1 ‚Äì y5) ‚Äì Z3 (y3 ‚Äì y7)Y1 = (y0 ‚Äì y4) + Z2 (y2 ‚Äì y6) + Z1 (y1 ‚Äì y5) + Z3 (y3 ‚Äì y7)Y6 = (y0 + y4) ‚Äì (y2 + y6) ‚Äì Z2 (y1 + y5) + Z2 (y3 + y7)Y2 = (y0 + y4) ‚Äì (y2 + y6) + Z2 (y1 + y5) ‚Äì Z2 (y3 + y7)Y4 = (y0 + y4) + (y2 + y6) ‚Äì  (y1 + y5) ‚Äì (y3 + y7)Y0 = (y0 + y4) + (y2 + y6) + (y1 + y5) + (y3 + y7) (y0 ‚Äì y4) + Z2(y2 ‚Äì y6) (y1 ‚Äì y5) + Z2(y3 ‚Äì y7) Figure 9.9 The butterÔ¨Çy operations performing an FFT on the eight data on the left leading to eight transforms on the right. The transforms are different linear combinations of the input data. theyp+Zyqelements in the upper- and lower-right wings. In Figure 9.9 we show what happens when we apply the butterfly operations to an entire FFT process, specifically to the pairs (y0,y4),(y1,y5),(y2,y6),a n d(y3,y7). Notice how the number of multiplications of complex numbers has been reduced: For the first butterfly operation there are 8 multiplicationsby Z0;forthesecondbutterfly,operationthereare8multiplications,and so forth, until a total of 24 multiplications are made in four butterflies. In contrast, 64 multiplicationsarerequiredintheoriginalDFT(9.76). 9.5.1 Bit Reversal The reader may have observed in Figure 9.9 that we started with 8 data elements in the order0‚Äì7,andthatafterthreebutterflyoperatorsweobtainedtransformsintheorder0,4, 2,6,1,5,3,7.Theastutereadermayfurtherhaveobservedthatthesenumberscorrespond to the bit-reversed order of 0‚Äì7. Let us look into this further. We need 3 bits to give the orderofeachofthe8inputdataelements(thenumbers0‚Äì7).Explicitly,ontheleftinTable 10.1, we give the binary representation for decimal numbers 0‚Äì7, their bit reversals, and thecorrespondingdecimalnumbers.Ontherightwegivetheorderingfor16inputdata elements,whereweneed4bitstoenumeratetheirorder.Noticethattheorderofthefirst8 elementsdiffersinthetwocasesbecausethenumberofbitsbeingreverseddiffers.Notice toothatafterthereordering,thefirsthalfofthenumbersareallevenandthesecondhalf areallodd. 188 9 Fourier Analyses Binary-reversed 0‚Äì7 Binary-reversed 0‚Äì16 Dec Bin Rev Dec rev Rev Dec rev 0 000 000 0 0000 0 1 001 100 4 1000 8 2 010 010 2 0100 4 3 011 110 6 1100 12 4 100 001 1 0010 2 5 101 101 5 1010 10 6 110 011 3 0110 6 7 111 111 7 1110 14 8 1000 0001 1 9 1001 1001 9 10 1010 0101 5 11 1011 1101 13 12 1100 0011 3 13 1101 1011 11 14 1101 0111 7 15 1111 1111 15 y7y3y5y1y6y2y4y0y0 + y4 (y0 + y4) + (y2 + y6) Y0 = (y0 + y4) + (y2 + y6)        + ( y1 + y5) + (y3 + y7) Y1 = (y0 ‚Äì y4) + Z2(y2 ‚Äì y6)        + Z1(y1 ‚Äì y5) + Z3(y3 ‚Äì y7) Y2 = (y0 + y4) ‚Äì (y2 + y6)        + Z2(y1 + y5) + Z2(y3 + y7) Y3 = (y0 ‚Äì y4) ‚Äì Z2(y2 ‚Äì y6)        + Z3(y1 ‚Äì y5) + Z1(y3 ‚Äì y7) Y4 = (y0 + y4) + (y2 + y6)        ‚Äì ( y1 + y5) ‚Äì (y3 + y7) Y5 = (y0 ‚Äì y4) + Z2(y2 ‚Äì y6)        ‚Äì Z1(y1 ‚Äì y5) ‚Äì Z3(y3 ‚Äì y7) Y6 = (y0 + y4) ‚Äì (y2 + y6)        ‚Äì Z2(y1 + y5) + Z2(y3 + y7) Y7 = (y0 ‚Äì y4) ‚Äì Z2(y2 ‚Äì y6)        ‚Äì Z3(y1 ‚Äì y5) + Z1(y3 ‚Äì y7)(y0 + y4) ‚Äì (y2 + y6) (y1 + y5) + (y3 + y7) (y1 + y5) ‚Äì (y3 + y7)(y0 ‚Äì y5) ‚Äì Z2(y2 ‚Äì y6) (y1 ‚Äì y5) + Z2(y3 ‚Äì y7) (y1 ‚Äì y5) ‚Äì Z2(y3 ‚Äì y7)(y0 ‚Äì y4) + Z2(y2 ‚Äì y6) y2 + y6 y1 + y5y0 ‚Äì y4 y2 ‚Äì y6 y3 + y7y1 ‚Äì y5 y3 ‚Äì y7Z0 Z0 Z0 Z0Z2Z0Z0 Z0 Z1 Z2 Z3Z2 Figure 9.10 A modiÔ¨Åed FFT in which the eight input data on the left are transformed into eight transforms on the right. The results are the same as in the previous Ô¨Ågure, but now the output transforms are in numerical order whereas in the previous Ô¨Ågure the input signals were in numerical order.",3987
9.7 FFT Assessment,"9.6 FFT Implementation 189 Table 9.1 Reordering for 16 data complex points. Order Input data New order Order Input data New order 00 . 0 +0.0i0.0+0.0i 88 . 0 +8.0i1.0+1.0i 11 . 0 +1.0i8.0+8.0i 99 . 0 +9.0i9.0+9.0i 22 . 0 +2.0i4.0+4.0i 10 10.0 +10.i5.0+5.0i 33 . 0 +3.0i12.0+12.0i 11 11.0 +11.0i13.0+13.0i 44 . 0 +4.0i2.0+2.0i 12 12.0 +12.0i3.0+3.0i 55 . 0 +5.0i10.0+10.i 13 13.0 +13.0i11.0+11.0i 66 . 0 +6.0i6.0+6.0i 14 14.0 +14.i7.0+7.0i 77 . 0 +7.0i14.0+14.0i 15 15.0 +15.0i15.0+15.0i ThefactthattheFouriertransformsareproducedinanordercorrespondingtothebit- reversedorderofthenumbers0‚Äì7suggeststhatifweprocessthedatainthebit-reversed order0,4,2,6,1,5,3,7,thentheoutputFouriertransformswillbeordered(seeTable10.1). We demonstrate this conjecture in Figure 9.10, where we see that to obtain the Fourier transform for the eight input data, the butterfly operation had to be applied three times. Thenumber3occursherebecauseitisthepowerof2thatgivesthenumberofdata;that is, 23=8. In general, in order for an FFT algorithm to produce transforms in the proper order,itmustreshuffletheinputdataintobit-reversedorder.Asacaseinpoint,oursample programstartsbyreorderingthe16(24)dataelementsgiveninTable9.1,andthenthefour butterflyoperationsproducesequentiallyorderedoutput. 9.6 FFT Implementation The first FFT program we are aware of was written in 1967 in Fortran IV by Norman BrunneratMIT‚ÄôsLincolnLaboratory[Higgins,1976],andwashardforustofollow.Our (easier-to-follow)PythonversionisinListing9.3.Itsinputis N=2ndatatobetransformed (FFTs always require that the number of input data are a power of 2). If the number of yourinputdataisnotapowerof2,thenyoucanmakeitsobyconcatenatingsomeofthe initialdatatotheendofyourinputuntilapowerof2isobtained;becauseaDFTisalways periodic,thisjuststartstheperiodalittleearlier.Ourprogramassignscomplexnumbers atthe16datapoints ym=m+mi,m=0,‚Ä¶,15, (9.78) reordersthedataviabitreversal,andthenmakesfourbutterflyoperations.Thedataare storedinthearray dt[max,2],withthesecondsubscriptdenotingrealandimaginaryparts. Weincreasespeedfurtherbyusingthe1Darray datatomakememoryaccessmoredirect: data[1]=dt[0,1],data[2]=dt[1,1],data[3]=dt[1,0],‚Ä¶,(9.79) which also provides storage for the output. The FFT transforms datausing the butterfly operationandstorestheresultsbackin dt[,],wheretheinputdatawereoriginal.",2326
9.8 Code Listings,"190 9 Fourier Analyses 9.7 FFT Assessment 1) Compileandexecute FFT.py.Makesureyouunderstandtheoutput. 2) Taketheoutputfrom FFT.py,inverse-transformitbacktosignalspace,andcompareit toyourinput.[Checkingthatthedoubletransformisproportionaltoitselfisadequate, althoughthenormalizationfactorsin(9.35)shouldmakethetwoequal.] 3) ComparethetransformsobtainedwithanFFTtothoseobtainedwithaDFT(youmay chooseanyofthefunctionsstudiedbefore).Makesuretocomparebothprecisionand executiontimes. 9.8 Code Listings Listing 9.1 DFTcomplex.py Usesthebuilt-incomplexnumbersofPythontocompute thediscreteFouriertransformforthesignalinmethodf(signal). # DFTcomplex.py: Discrete Fourier Transform with built in complex fromvisualimport ‚àó;fromvisual.graph import ‚àó 4importcmath # Complex math N = 100; twopi = 2. ‚àópi; h = twopi/N; sq2pi = 1./sqrt(twopi) y=z e r o s ( N + 1 , float); Ycomplex = zeros(N, complex) # Declare arrays 8SignalGraph = gdisplay(x=0, y=0, width=600, height=250, title = ‚ÄôSignal y(t)‚Äô ,\ xtitle= ‚Äôx‚Äô,ytitle= ‚Äôy(t)‚Äô, xmax=2. ‚àómath.pi , xmin=0, ymax=30, ymin= ‚àí30) SignalCurve = gcurve(color=color.yellow, display=SignalGraph) TransformGraph = gdisplay(x=0,y=250,width=600,height=250,title = ‚ÄôIm Y(omega)‚Äô , 12 xtitle = ‚Äôx‚Äô,ytitle= ‚ÄôIm Y(omega)‚Äô ,xmax=10.,xmin= ‚àí1,ymax=100,ymin= ‚àí250) TransformCurve = gvbars(delta = 0.05,color=color.red, display = TransformGraph) defSignal(y): # Signal 16h = twopi/N; x = 0. foriin range (0, N+1): y[i] = 30 ‚àócos(x) + 60 ‚àósin(2 ‚àóx) + 120 ‚àósin(3 ‚àóx) SignalCurve.plot(pos = (x, y[i])) #P l o t 20 x+ =h defDFT(Ycomplex): #D F T fornin range (0, N): zsum =complex(0.0, 0.0) 24 forkin range (0, N): zexpo = complex(0, twopi ‚àók‚àón/N) # Complex exp zsum += y[k] ‚àóexp(‚àízexpo) Ycomplex[n] = zsum ‚àósq2pi 28 ifYcomplex[n].imag .= 0: TransformCurve.plot(pos=(n,Ycomplex[n].imag)) Signal(y) # Generate signal DFT(Ycomplex) # Transform signal Listing 9.2 DFTreal.py Computes the discrete Fourier transform for the signal in methodf(signal)usingrealnumbers. # DFTreal.py: Discrete Fourier Transform using real numbers 3fromvisual.graph import ‚àó signgr = gdisplay(x=0,y=0,width=600,height=250, \ title= ‚ÄôSignal y(t)= 3 cos(wt)+2 cos(3wt)+ cos(5wt) ‚Äô ,\ 7xtitle= ‚Äôx‚Äô, ytitle= ‚Äôsignal‚Äô ,xmax=2. ‚àómath.pi ,xmin=0,ymax=7,ymin= ‚àí7) 9.8 Code Listings 191 sigfig = gcurve(color=color.yellow,display=signgr) imagr = gdisplay(x=0,y=250,width=600,height=250,\ title= ‚ÄôFourier transform imaginary part‚Äô ,xtitle= ‚Äôx‚Äô,\ 11 ytitle= ‚ÄôTransf.Imag‚Äô ,xmax=10.0,xmin= ‚àí1,ymax=20,ymin= ‚àí25) impart = gvbars(delta=0.05,color=color.red,display=imagr) N = 200 Np = N 15signal = zeros((N+1), float) twopi = 2. ‚àópi sq2pi = 1./sqrt(twopi) h = twopi/N 19dftimag = zeros((Np), float) # Im. transform deff(signal): step = twopi/N 23t= 0. foriin range (0,N+1): signal[i] = 3 ‚àósin(t ‚àót‚àót) sigfig.plot(pos=(t,signal[i])) 27 t += step deffourier(dftimag): #D F T fornin range (0,Np): imag = 0. 31 forkin range (0, N): imag += signal[k] ‚àósin((twopi ‚àók‚àón)/N) dftimag[n] = ‚àíimag ‚àósq2pi # Im transform ifdftimag[n] .=0: 35 impart.plot(pos=(n,dftimag[n])) f(signal) fourier(dftimag) Listing 9.3 FFT.py ComputestheFFTorinversetransformdependinguponthesignof sign. 1# FFT . py : FFT for complex numbers in Y [ ] [ 2 ] , returned in Y fromnumpyimport ‚àó max= 2100; points = 1026; N = 100; Switch = ‚àí1#S w i t c h = ‚àí1:Y, 1:y 5y=z e r o s ( 2 ‚àó(N+4),float); Y = zeros((N+3,2), float) deffft(N,Switch): # FFT of Y[n , 2 ] n=2 ‚àóN 9foriin range (0,N+1): #yi nYt oy j=2 ‚àói+1 y[j] = Y[i,0] #R e a lY ,o d dy [ j ] y[j+1] = Y[i,1] # Imag Y, even y[ j+1] 13j=1 # y in bit reverse order foriin range (1,n+2, 2): if(i‚àíj) < 0 : # Reorder to bit reverse tempr = y[j] 17 tempi = y[j+1] y[j] = y[i] y[j+1] = y[i+1] y[i] = tempr 21 y[i+1] = tempi m=n/2; while(m‚àí2>0 ): if(j‚àím) <= 0 : break 25 j=j‚àím m=m / 2 j=j + m ; print(\""  Bit-reversed y(t)\"" ) 29foriin range (1,n+1,2): print(\"" percent2d y[ percent2d]  percent9.5f \""  percent (i,i,y[i])) mmax = 2 while(mmax‚àín) < 0 : # Begin transform istep = 2 ‚àómmax 33 theta = 6.2831853/(1.0 ‚àóSwitch ‚àómmax) 192 9 Fourier Analyses sinth = math.sin(theta/2.0) wstpr = ‚àí2.0‚àósinth ‚àó‚àó2 wstpi = math.sin(theta) 37 wr = 1.0 wi = 0.0 formin range (1 ,mmax+1,2) : foriin range (m,n+1,istep): 41 j = i+mmax tempr = wr ‚àóy[j] ‚àíwi‚àóy[j+1] tempi = wr ‚àóy[j+1] +wi ‚àóy[j] y[j] = y[i] ‚àítempr 45 y[j+1] = y[i+1] ‚àítempi y[i] = y[i] +tempr y[i+1] = y[i+1] +tempi tempr = wr 49 wr = wr ‚àówstpr‚àíwi‚àówstpi + wr wi = wi ‚àówstpr + tempr ‚àówstpi + wi; mmax = istep foriin range (0,N): 53 j=2 ‚àói+1 Y[i,0] = y[j] Y[i,1] = y[j+1] print(‚Äô  Input   i Re y(t) Im y(t)‚Äô ) 57h=2 ‚àópi/N; x = 0. foriin range (0,N+1): # Generate signal in Y Y[i,0] = 30 ‚àócos(x) + 60 ‚àósin(2 ‚àóx) + 120 ‚àósin(3 ‚àóx) #R e a lp a r t Y[i,1] = 0. #I mp a r t 61x+ =h print(\""  percent2d  percent9.5f  percent9.5f\""  percent(i,Y[i,0],Y[i,1])) fft(N, Switch) # Call F F T, use global Y[][] print ‚Äô  Fourier Transform Y(omega)‚Äô 65print(\"" i ReY(omega) ImY(omega) \"" ) foriin range (0,N): print(\""  percent2d  percent9.5f  percent9.5f \""  percent(i,Y[i,0],Y[i,1]))",4993
Chapter 10 Wavelet and Principal Components Analysis. 10.1 Part I Wavelet Analysis,"193 10 Wavelet and Principal Components Analysis A number of techniques can extend Fourier analysis to signals whose time-dependencies change in time. Part I of this chapter introduces wavelet analysis, a Ô¨Åeld that has seen extensive development and application in areas as diverse as brain waves, stock-market trends, gravitational waves, and compression of photographic images. Part II of this chapter covers the basics of principal components analysis. This is a powerful tool for situations in which there are very large data sets, and especially those with space-time correlated variables . 10.1 Part I: Wavelet Analysis Problem YouhavesampledthesignalinFigure10.1thatseemstocontainanincreasing number of frequencies as time increases. Your problemis to undertake a spectral anal- ysis of this signal that tells you, in the most compact way possible, the amount of each frequencypresentateachinstantoftime. Hint:Althoughwewantthemethodtobegeneral enoughtoworkwithnumericaldata,forpedagogicalpurposesitisusefultoknowthatthe signalis y(t)=‚éß ‚é™ ‚é® ‚é™‚é©sin2ùúãt, for0‚â§t‚â§2, 5sin2ùúãt+10sin4ùúãt, for2‚â§t‚â§8, 2.5sin2ùúãt+6sin4ùúãt+10sin6ùúãt,for8‚â§t‚â§12.(10.1) TheFourieranalysisweusedinChapter9revealstheamountoftheharmonicfunctions sin(nùúît)andcos(nùúît)thatarepresentinasignal.Anexpansioninperiodicfunctionsisfine forstationarysignals(thosewhoseformsdonotchangeintime),buthasshortcomingsfor thetimedependenceofour problemsignal(10.1).OnesuchproblemisthattheFourier reconstruction has all frequencies nùúîoccurring simultaneously, and so does not contain timeresolution informationindicatingwheneachfrequencyoccurs.Anothershortcoming isthatalltheFouriercomponentsarecorrelated,andthatresultsinmoreinformationbeing storedthanisneededtoreconstructthesignal. ThereareanumberoftechniquesthatextendsimpleFourieranalysistononstationary signals. The idea behind wavelet analysis is to expand a signal in a complete set of functions(wavelets),eachofwhichoscillatesforafiniteperiodoftime,andeachofwhich ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 194 10 Wavelet and Principal Components Analysis 0123456789 Figure 10.1 The input time signal (10.1) we wish to analyze. The signal is seen to contain additional frequencies as time increases. The boxes are possible placements of windows for short-time Fourier transforms. ‚Äì1.0‚Äì0.50.00.51.0 1.0 ‚Äì6 ‚Äì4 ‚Äì2 0 2 4 6 tœà œàœà 0.0 ‚Äì4 0 4 t ‚Äì1.00.01.0 ‚Äì4 0 t4 0 200 400 600 800 10000.1 0 ‚Äì0.1Daub4 e6 Figure 10.2 Four possible mother wavelets that can be used to generate entire sets of daughter wavelets. Clockwise from top : Morlet (real part), Mexican hat, Daub4 e6 (explained later), and Haar. The daughter wavelets are generated by scaling and translating these mother wavelets. is centered at a different time. To give you a preview before we go into details, we show four sample wavelets in Figure 10.2. Because each wavelet is local in time, it is a wave packet,1with its time localization leading to a spectrum with a range of frequencies. Thesewavepacketsarecalled‚Äúwavelets‚Äùbecausetheyexistforonlyshortperiodsoftime [Polikar,2023]. Althoughwaveletsarerequiredtooscillateintime,theyarenotrestrictedtoaparticular functionalform[Addison,2002;GoswaniandChan,1999;Graps,1995].Asacaseinpoint, theymaybeoscillatingGaussian(Morlet:topleftinFigure10.2), Œ®(t)=e2ùúãite‚àít2‚àï2ùúé2=(cos2ùúãt+isin2ùúãt)e‚àít2‚àï2ùúé2(Morlet), (10.2) thesecondderivativeofaGaussian(Mexicanhat,topright), Œ®(t)=‚àíùúé2d2 dt2e‚àít2‚àï2ùúé2=( 1‚àít2 ùúé2) e‚àít2‚àï2ùúé2, (10.3) 1 WediscusswavepacketsfurtherinSection10.2.",3571
10.4 Wavelet Transforms,"10.2 Wave Packets and Uncertainty Principle 195 an up-and-down step function (lower left), or a fractal shape (bottom right). All of these wavelets are localizedin both time and frequency, that is, they are large for just a finite timeandcontainafiniterangeoffrequencies.Asweshallsee,translatingandscalingthese motherwavelet generatesanentiresetof childwavelets basisfunctions,withthechildren coveringdifferentfrequencyrangesatdifferenttimes. 10.2 Wave Packets and Uncertainty Principle Awavepacket orwavetrain isacollectionofwavesofdifferingfrequenciesaddedtogether insuchawayastoproduceapulseofwidth Œît.Asweshallsee,theFouriertransformofa wavepacketisapulseinthefrequencydomainofwidth Œîùúî.We‚Äôllfirststudywavepackets analytically,andthenusethemnumerically.Anexampleofasimplewavepacketisasine wave that oscillates at frequency ùúî0forNperiods (Figure 10.3 left) [Arfken and Weber, 2001]: y(t)=‚éß ‚é™ ‚é® ‚é™‚é©sinùúî0t,for |t|<Nùúã ùúî0‚â°NT 2, 0,for |t|>Nùúã ùúî0‚â°NT 2,(10.4) where we relate the frequency to the period via the usual ùúî0=2ùúã‚àïT.I nt e r m so ft h e s e parameters,thewidthofthewavepacketis Œît=NT=N2ùúã ùúî0. (10.5) TheFouriertransformofthewavepacket(10.4)isastraightforwardapplicationofthetrans- formformula(9.17): Y(ùúî)=‚à´+‚àû ‚àí‚àûdte‚àíiùúît ‚àö 2ùúãy(t)=‚àíi‚àö 2ùúã‚à´Nùúã‚àïùúî0 0dtsinùúî0tsinùúît (10.6) =(ùúî0+ùúî)sin[ (ùúî0‚àíùúî)Nùúã ùúî0] ‚àí(ùúî0‚àíùúî)sin[ (ùúî0+ùúî)Nùúã ùúî0] ‚àö 2ùúã(ùúî2 0‚àíùúî2), wherewehavedroppedafactorof ‚àíithataffectsonlythephase.Whileatfirstglance(10.6) appearstobesingularat ùúî=ùúî0,itactuallyjustpeaksthere(Figure10.3right),reflecting thepredominanceoffrequency ùúî0.Notethatalthoughthesignal y(t)appearstohaveonly onefrequency,itdoesdropoffsharplyintime(Figure10.3left),andthesecornersgive Y(ùúî) afinitewidth Œîùúî. Thereisafundamentalrelationbetweenthewidths ŒîtandŒîùúîofawavepacket.Although weuseaspecificexampletodeterminethatrelation,itistrueingeneral.Whiletheremay notbeaprecisedefinitionof‚Äúwidth‚Äùforallfunctions,onecanusuallydeduceagoodmea- sure of the width (say, within 25 percent). To illustrate, if we look at the right of Figure 10.3, it makessensetousethedistancebetweenthefirstzerosofthetransform Y(ùúî)(10.6)asthe frequencywidth Œîùúî.Thezerosoccurat ùúî‚àíùúî0 ùúî0=¬±1 N‚áíŒîùúî‚âÉùúî‚àíùúî0=ùúî0 N, (10.7) 196 10 Wavelet and Principal Components Analysis ‚Äì1.00.01.0 ‚Äì4 0 4 t œây Y 0.0 0 10 Figure 10.3 Left: A wave packet in time corresponding to the functional form (10.4) with ùúî0=5 andN=6.Right: The Fourier transform in frequency of this same wave packet. whereNisthenumberofcyclesinouroriginalwavepacket.Becausethewavepacketin timemakes Noscillationseachofperiod T,areasonablemeasureofthetimewidth Œîtof thesignaly(t)is Œît=NT=N2ùúã ùúî0. (10.8) Whentheproductsofthefrequencywidth(10.7)andthetimewidth(10.8)arecombined, weobtain ŒîtŒîùúî‚â•2ùúã. (10.9) Thegreater-thansignisusedheretoindicatethatthisisaminimum,thatis,that y(t)and Y(ùúî)extendbeyond ŒîtandŒîùúî,respectively.Nonetheless,mostofthesignalandtransform shouldfallwithintheboundsof(10.9). A relation of the form (10.9) also occurs in quantum mechanics, where it is known as theHeisenberguncertaintyprinciple ,withŒîtandŒîùúîcalledtheuncertaintiesin tandùúî.It istruefortransformsingeneral,andstatesthatasasignalismademorelocalizedintime (smaller Œît), its transform becomes less localized (larger Œîùúî). Conversely, the sine wave y(t)=sinùúî0tiscompletelylocalizedinfrequency,andconsequentlyhasaninfiniteextent intime,Œît‚âÉ‚àû. 10.2.1 Wave Packet Exercise Considerthefollowingwavepackets: y1(t)=e‚àít2‚àï2,y2(t)=sin(8t)e‚àít2‚àï2,y3(t)=(1‚àít2)e‚àít2‚àï2. (10.10) Foreachwavepacket: 1) Estimatethewidth Œît.Agoodmeasuremightbethe fullwidthathalf-maxima (FWHM) of|y(t)|. 2) UseyourDFTprogramtoevaluateandplottheFouriertransform Y(ùúî)foreachwave packet.Make bothalinearandasemilogplot(smallcomponentsareoftenimportant, yet not evident in linear plots). Make sure that your transform has a good number of closelyspacedfrequencyvaluesoverarangethatislargeenoughtoshowtheperiodicity ofY(ùúî). 3) Whataretheunitsfor Y(ùúî)andùúîinyourDFT? 4) Foreachwavepacket,estimatethewidth Œîùúî.Agoodmeasuremightbethe fullwidth athalf-maxima of|Y(ùúî)|. 10.3 Short-Time Fourier Transforms 197 5) Foreachwavepacketdetermineapproximatevaluefortheconstant Coftheuncertainty principle ŒîtŒîùúî‚â•2ùúãC. (10.11) 10.3 Short-Time Fourier Transforms The constant amplitude of the functions sin nùúîtand cosnùúîtfor all times can limit the usefulnessofFourieranalysisforreproducingsignalswhoseformchangesintime.Seeing thatthesebasisfunctionsextendoveralltimeswithaconstantamplitude,thereisconsider- ableoverlapamongthem,andthustheinformationpresentinvariousFouriercomponents are correlated. This is undesirable for data storage and compression, where you want to storeaminimumamountofinformation,andalsowanttoadjusttheamountofinforma- tionstoreddependentonthedesiredqualityofthereconstructedsignal.2Losslesscompres- sionexactlyreproducestheoriginalsignal.Youcansavespacebystoringhowmanytimes eachdataelementisrepeated,andwhereeachelementislocated.In lossycompression ,in additiontoremovingrepeatedelements,youalsoeliminatesometransformcomponents consistentwiththeuncertaintyrelation(10.9)andwiththelevelofresolutionrequiredin thereproduction.Thisleadstoevengreatercompression. InSection9.3wedefinedtheFouriertransform Y(ùúî)ofsignaly(t)as Y(ùúî)=‚à´+‚àû ‚àí‚àûdte‚àíiùúît ‚àö 2ùúãy(t)‚â°‚ü®ùúî|y‚ü©. (10.12) Asistrueforsimplevectors,youcanthinkof(10.12)asgivingtheoverlaporscalarproduct of the basis function |ùúî‚ü©=exp(iùúît)‚àï‚àö 2ùúãand the signal y(t)[notice that the complex conjugateoftheexponentialbasisfunctionappearsin(10.12)].Anotherviewof(10.12)is themappingorprojectionofthesignalinto ùúîspace.Inthislatterview,theoverlapprojects out the amount of the periodicfunction exp (iùúît)‚àï‚àö 2ùúãin the signal y(t).I no t h e rw o r d s , theFouriercomponent Y(ùúî)canbethoughtofasthecorrelationbetweenthesignal y(t) and the basis function exp (iùúît)‚àï‚àö 2ùúã. This is the same as what results from filtering the signaly(t)throughafrequencyfilter.Ifthereisnoexp (iùúît)inthesignal,thentheintegral vanishesandthereisnooutput.If y(t)=exp(iùúît),thesignalisatonlyonefrequency,and theintegralisaccordinglysingular. The signal in Figure 10.1 for our problem clearly has different frequencies present at differenttimes,andfordifferentlengthsoftime.Inthepast,thissignalmighthavebeen analyzedwithaprecursorofwaveletanalysisknownasthe short-timeFouriertransform . Withthattechnique,thesignal y(t)is‚Äúchoppedup‚Äùintodifferentsegmentsalongthetime axis,withsuccessivesegmentscenteredaboutsuccessivetimes ùúè1,ùúè2,‚Ä¶,ùúèN.Forinstance, weshowthreesuchsegmentsintheboxesofFigure10.1.Oncewehavethedissectedsignal, aFourieranalysisismadeforeachsegment.Wearethenleftwithasequenceoftransforms [Y(ST) ùúè1,Y(ST) ùúè2,‚Ä¶,Y(ST) ùúèN],oneforeachshort-timeinterval,wherethesuperscript(ST)indicates shorttime. 2 Waveletshaveproventobeahighlyeffectiveapproachtodatacompression,withtheJointPhotographic ExpertsGroup(JPEG)2000standardbeingbasedonwavelets.",6757
10.4.1 Generating Wavelet Basis Functions,"198 10 Wavelet and Principal Components Analysis Rather than chopping up a signal by hand, we can express short-time Fourier trans- formingmathematicallybyimaginingtranslatinga windowfunction ùë§(t‚àíùúè),whichiszero outsideofsomechoseninterval,overthesignalinFigure10.1: Y(ST)(ùúî,ùúè)=‚à´+‚àû ‚àí‚àûdteiùúît ‚àö 2ùúãùë§(t‚àíùúè)y(t). (10.13) Here the values of the translation time ùúècorrespond to different locations of window ùë§ overthesignal,andthewindowfunctionisessentiallyatransparentboxofsmallsizeonan opaquebackground.Anysignalwithinthewidthofthewindowistransformed,whilethe signallyingoutsidethewindowisnotseen.Notethatin(10.13),theextravariable ùúèinthe Fouriertransformindicatesthelocationofthetimearoundwhichthewindowwasplaced. Clearly,becausetheshort-timetransformisafunctionoftwovariables,asurfaceor3Dplot isneededtoviewtheamplitudeasafunctionofboth ùúîandùúè. 10.4 Wavelet Transforms Thewavelettransformofatimesignal y(t)isdefinedas Y(s,ùúè)=‚à´+‚àû ‚àí‚àûdtùúì‚àó s,ùúè(t)y(t)(wavelettransform), (10.14) and is similar in concept and notation to a short-time Fourier transform. The difference is rather than using exp (iùúît)as the basis functions, here we are using wave packets or wavelets ùúìs,ùúè(t)localized in time, such as those shown in Figure 10.2. Because each waveletislocalizedintime,eachactsasitsownwindowfunction.Becauseeachwaveletis oscillatory,eachcontainsitsownlimitedrangeoffrequencies. Equation (10.14) says that the wavelet transform Y(s,ùúè)is a measure of the amount of basisfunction ùúìs,ùúè(t)presentinthesignal y(t).Theùúèvariableindicatesthetimeportionof the signal being decomposed, while the svariable is equivalent to the frequency present duringthattime: ùúî=2ùúã s,s=2ùúã ùúî(scale-frequencyrelation). (10.15) Seeing that it is key to much that follows, it is a good idea to think about (10.15) for a moment.Ifweareinterestedinthetime detailsofasignal,thenthisisanotherwayofsaying thatweareinterestedinwhatishappeningatsmallvaluesofthe scales.Equation(10.15) indicates that small values of scorrespond to high-frequency components of the signal. Thatbeingthecase,thetimedetailsofthesignalareinthehigh-frequency,orlow-scale, components. 10.4.1 Generating Wavelet Basis Functions Theconceptualdiscussionofwaveletsisover,anditistimetogetdowntowork.Wefirst needatechniqueforgeneratingwaveletbasisfunctions,andthenweneedtodiscretizethis 10.4 Wavelet Transforms 199 technique.Asisoftenthecase,thefinalformulationwillturnouttobesimpleandshort, butitwillbeawhilebeforewegetthere. Justastheexpansionofanarbitraryfunctioninacompletesetoforthogonalfunctionsis notrestrictedtoanyparticularbasisset,sotooisthewavelettransformnotrestrictedtoany particularwaveletbasisset,althoughsomemightbebetterthanothersforagivensignal. Thestandardwaytogenerateafamilyofwaveletbasisfunctionsstartswith Œ®(t),amother oranalyzingfunctionoftherealvariable t,andthenusesittogenerate daughterwavelets. Asacaseinpoint,westartwiththemotherwavelet Œ®(t)=sin(8t)e‚àít2‚àï2. (10.16) Byscaling,translating,andnormalizingthismotherwaveletweobtaintheset ùúìs,ùúè(t)def=1‚àö sŒ®(t‚àíùúè s) =1‚àö ssin[8(t‚àíùúè) s] e‚àí(t‚àíùúè)2‚àï2s2, (10.17) andwithitwegeneratethefourwaveletbasisfunctionsdisplayedinFigure10.4.Wesee thatlargerorsmallervaluesof s,respectively,expandorcontractthemotherwavelet,while different values of ùúèshift the center of the wavelet. Because the wavelets are inherently oscillatory,thescalingleadstothesamenumberofoscillationsoccurringindifferenttime spans, which is equivalent to having basis states with differing frequencies. We see that s<1 produces a higher-frequency wavelet, while s>1 produces a lower-frequency one, both of the same shape. As we shall see, we do not need to store much information to outline the large-time-scale sbehavior of a signal (its smooth envelope ), but we do need more information to specify its short-time-scale sbehavior (details). And if we want to resolveyetfinerfeaturesinthesignal,thenwewillneedtohavemoreinformationonyet finer details. Here the division by‚àö sis made to ensure that there is equal ‚Äúpower‚Äù (or ‚Äì0.60.00.61.0 0.0 ‚Äì1.0 1.0 0.0 ‚Äì1.0‚Äì6 ‚Äì4 ‚Äì2 0 2 4 6 ‚Äì6 ‚Äì4 ‚Äì2 0 2 4 6 tŒ®Œ® Œ® Œ®s = 2, œÑ = 0 t ‚Äì4 ‚Äì2 0 2 4 6 8 10 t‚Äì0.60.00.6 ‚Äì6 ‚Äì4 ‚Äì2 0 2 4 6 ts = ¬Ω, œÑ = 0 s = 2, œÑ = 0 s = 2, œÑ = 6 Figure 10.4 Four wavelet basis functions (daughters) generated by scaling ( s) and translating ( ùúè) an oscillating Gaussian mother wavelet. Clockwise from top :(s=1,ùúè=0), (s=1/2,ùúè=0), (s=1, ùúè=6), and ( s=2,ùúè=60). Note how s<1 is a wavelet with higher frequency, while s>1 has a lower frequency than the s=1 mother. Likewise, the ùúè=6 wavelet is just a translated version of theùúè=0 one directly above it. 200 10 Wavelet and Principal Components Analysis energyorintensity)ineachregionof s,althoughothernormalizationscanalsobefound in the literature. After substituting in the definition of daughters, the wavelet transform (10.14)anditsinverse[vandenBerg,1999]are Y(s,ùúè)=1‚àö s‚à´+‚àû ‚àí‚àûdtŒ®‚àó(t‚àíùúè s) y(t)( Wavelet Transform ),(10.18) y(t)=1 C‚à´+‚àû ‚àí‚àûdùúè‚à´+‚àû 0dsùúì‚àó s,ùúè(t) s3‚àï2Y(s,ùúè)( Inverse Transform ),(10.19) wherethenormalizationconstant Cdependsonthewaveletused. Insummary,waveletbasesarefunctionsofthetimevariable t,aswellasofthetwoparam- eterssandùúè.Thetvariableisintegratedovertoyieldatransformthatisafunctionofthe timescales(frequency2 ùúã‚àïs)andwindowlocation ùúè.Youcanthinkofscaleasbeinglikethe scaleonamap(alsodiscussedinSection14.4.1inrelationtofractalanalysis)orinterms ofresolution,asmightoccurinphotographicimages.Regardlessofthewords,asweseein Chapter14,ifwehaveafractal,thenwehaveaself-similarobjectthatlooksthesameatall scalesorresolutions.Similarly,eachwaveletinasetofbasisfunctionsisself-similartothe others,butatadifferentscaleorlocation. The general requirements for a mother wavelet Œ®are [Addison, 2002; van den Berg, 1999]: 1)Œ®(t)isreal. 2)Œ®(t)oscillatesaroundzerosuchthatitsaverageiszero: ‚à´+‚àû ‚àí‚àûŒ®(t)dt=0. (10.20) 3)Œ®(t)islocal,thatis,awavepacket,andissquare-integrable: Œ®(|t|‚Üí‚àû)‚Üí0 (rapidly) ,‚à´+‚àû ‚àí‚àû|Œ®(t)|2dt<‚àû. (10.21) 4) Thetransformsoflowpowersof tvanish,thatis,thefirst pmoments: ‚à´+‚àû ‚àí‚àût0Œ®(t)dt=‚à´+‚àû ‚àí‚àût1Œ®(t)dt=¬∑¬∑¬∑=‚à´+‚àû ‚àí‚àûtp‚àí1Œ®(t)dt=0. (10.22) Thismakesthetransformmoresensitivetodetailsthantogeneralshape. Asanexampleofhowweusethe sandùúèdegreesoffreedominawavelettransform,con- sidertheanalysisofachirpsignal y(t)=sin(60t2)inFigure10.5.Weseethatasliceatthe beginningofthesignaliscomparedtoourfirstbasisfunction.(Thecomparisoniscarried outviatheconvolution ofthewaveletwiththesignal.)Thisfirstcomparisoniswithanarrow versionofthewavelet,thatis,atlowscale,andyieldsasinglecoefficient.Thecomparison atthisscalecontinueswiththenextsignalslice,andeventuallyendswhentheentiresig- nal has been covered (the top row in the figure). Then the wavelet is expanded to larger svalues,andthecomparisonsarerepeated.Eventually,thedataareprocessedatallscales andatalltimeintervals.Thenarrowsignalscorrespondtoahigh-resolutionanalysis,while thebroadsignalscorrespondtolowresolution.Asthescalesgetlarger(lowerfrequencies, lowerresolution),fewerdetailsofthetimesignalremainvisible,buttheoverallshapeor grossfeaturesofthesignalbecomeclearer.",6980
10.4.2 Continuous Wavelet Transforms,"10.4 Wavelet Transforms 201 Figure 10.5 A schematic representation of the steps followed in performing a wavelet transformation over all time displacements and scales. The dark grey signal is Ô¨Årst analyzed by evaluating its overlap with a narrow wavelet at the signal‚Äôs beginning. This produces a coefÔ¨Åcient that measures the similarity of the signal to the wavelet. The wavelet is successively shifted over the length of the signal and the overlaps are successively evaluated. After the entire signal is covered, the wavelet is expanded and the entire analysis is repeated. 10.4.2 Continuous Wavelet Transforms We want to develop some intuition as to what wavelet transforms look like before going on to apply them. Accordingly, modify the program you have been using for the Fourier transform so that it now computes the wavelet transform. In contrast to the discrete or digitalversion,thisisa continuous wavelettransform. 1) Examinetheeffectofusingdifferentmotherwavelets.Accordingly,writeamethodthat calculatesthemotherwaveletfor a) aMorletwavelet(10.2), b) aMexicanhatwavelet(10.3), c) aHaarwavelet(thesquarewaveinFigure10.2). 2) Tryoutyourtransformforthefollowinginputsignalsandseeiftheresultsmakesense: a) Apuresinewave y(t)=sin2ùúãt, b) Asumofsinewaves y(t)=2.5sin2ùúãt+6sin4ùúãt+10sin6ùúãt, c) Thenonstationarysignalforourproblem(10.1) y(t)=‚éß ‚é™ ‚é® ‚é™‚é©sin2ùúãt, for0‚â§t‚â§2, 5sin2ùúãt+10sin4ùúãt, for2‚â§t‚â§8, 2.5sin2ùúãt+6sin4ùúãt+10sin6ùúãt,for8‚â§t‚â§12.(10.23) d) Thehalf-wavefunction y(t)={ sinùúît,for0<t<T‚àï2, 0,forT‚àï2<t<T.(10.24) 3)‚äôUse(10.19)toinvertyourwavelettransformandcomparethereconstructedsignalto theinputsignal(youcannormalizethetwotoeachother).InFigure10.6weshowour reconstruction. 202 10 Wavelet and Principal Components Analysis 0‚Äì20‚Äì100Signal1020 2468 1 0 1 2 Time tInput signal Inverted transform Figure 10.6 Comparison of an input and reconstituted signal (10.23) using Morlet wavelets. The curves overlap nearly perfectly, except at the ends. InListing10.1wegiveour continuouswavelettransformation CWT.py[LangandForinash, 1998].Becausewavelets,withtheirfunctionaldependenceontwovariables,maybesome- whathardtograspatfirst,wesuggestthatyouwriteyourowncodeandincludeaportion that does the inverse transform as a check. In Section 10.5, we will describe the discrete wavelet transformation that makes optimal discrete choices for the scale and time trans- lationparameters sandùúè. Figure10.7showsthespectrumproduced fortheinputsignal (10.1) in Figure 10.1. And it works. We see predominantly one frequency at short times, twofrequenciesatintermediatetimes,andthreefrequenciesatlongertimes. 0 1 2sœÑœàs,œÑ 0 4 8 12‚Äì101 Figure 10.7 The continuous wavelet spectrum obtained by analyzing the input signal with Morlet wavelets. Observe how at small values of time ùúèthere is predominantly one frequency present, how a second, higher-frequency (smaller-scale) component enters at intermediate times, and how at larger times a still higher-frequency components enter. (Figure courtesy of Z. Diabolic.)",2984
10.5 Discrete Wavelet Transforms,"10.5 Discrete Wavelet Transforms ‚äô203 10.5 Discrete Wavelet Transforms ‚äô AswastrueforDFTs,ifatimesignalismeasuredatonly Ndiscretetimes, y(tm)‚â°ym,m=1,‚Ä¶,N, (10.25) thenwecandetermineonly N-independentcomponentsofthetransform Y.Thetrickisto remainconsistentwiththeuncertaintyprincipleaswecomputeonlythe N-independent components required to reproduce the signal. The discrete wavelet transform (DWT) evaluates the transforms with discrete values for the scaling parameter sand the time translationparameter ùúè: ùúìj,k(t)=Œ®[(t‚àík2j)‚àï2j] ‚àö 2j‚â°Œ®(t‚àï2j‚àík) ‚àö 2j(DWT), (10.26) s=2j,ùúè=k 2j,k,j=0,1,‚Ä¶. (10.27) Herejandkareintegerswhosemaximumvaluesareyettobedetermined,andwemeasure timeinintegervalues.Thischoiceof sandùúè,basedonpowersof2,iscalleda dyadicgrid arrangement,andwillbeseentoautomaticallyperformthescalingsandtranslationsatthe differenttimescalesthatareattheheartofwaveletanalysis.3TheDWTnowbecomes Yj,k=‚à´+‚àû ‚àí‚àûdtùúìj,k(t)y(t)‚âÉ‚àë mùúìj,k(tm)y(tm)h(DWT), (10.28) wherethediscretenessherereferstothewaveletbasissetand notthetimevariable.Foran orthonormalwaveletbasis,theinversediscretetransformisthen y(t)=+‚àû‚àë j,k=‚àí‚àûYj,kùúìj,k(t)(inverseDWT) . (10.29) This inversion will exactly reproduce the input signal at the Ninput points, but only if we sum over an infinite number of terms [Addison, 2002]. Practical calculations will be lessexact. Noticein(10.26)and(10.28)thatwehavekeptthetimevariable tinthewaveletbasis functionscontinuous,despitethefactthat sandùúèhavebeenmadediscrete.Thisisuseful inestablishingtheorthonormalityofthebasisfunctions, ‚à´+‚àû ‚àí‚àûdtùúì‚àó j,k(t)ùúìj‚Ä≤,k‚Ä≤(t)=ùõøjj‚Ä≤ùõøkk‚Ä≤, (10.30) whereùõøm,nistheKroneckerdeltafunction.Beingnormalizedto1meansthateachwavelet basishas‚Äúunitenergy‚Äù;beingorthogonalmeansthateachbasisfunctionisindependentof theothers.Andbecausewaveletsarelocalizedintime,thedifferenttransformcomponents havelowlevelsofcorrelationswitheachother.Altogether,thisleadstoefficientandflexible datastorage. The use of a discrete wavelet basis makes it clear that we sample the input signal at thediscretevaluesoftimedeterminedbytheintegers jandk.Ingeneral,youwanttime 3 Notethatsomereferencesscaledownwithincreasing j,incontrasttoourscalingup. 204 10 Wavelet and Principal Components Analysis TimeFrequencyFigure 10.8 A graphical representation of the relation between time and frequency resolutions (the uncertainty relation). Each box represents an equal portion of the time-frequency plane but with different proportions of time and frequency. stepsthatsamplethesignalatenoughtimesineachintervaltoobtainthedesiredlevelof precision.Aruleofthumbistostartwith100stepstocovereachmajorfeature.Ideally,the neededtimescorrespondtothetimesatwhichthesignalwassampled,althoughthismay requiresomeforethought. Consider Figure 10.8. We measure a signal at a number of discrete times within the intervals(korùúèvalues)correspondingtotheverticalcolumnsoffixedwidthalongthetime axis.Foreachtimeinterval,wewanttosamplethesignalatanumberofscales(frequencies orjvalues).However,asdiscussedinSection10.2,thebasicmathematicsofFouriertrans- forms indicates that the width Œîtof a wave packet ùúì(t)and the width Œîùúîof its Fourier transformY(ùúî)arerelatedbyanuncertaintyprinciple ŒîùúîŒît‚â•2ùúã. Thisrelationplacesaconstraintonthetimeintervalsandfrequencyintervals.Furthermore, whilewemaywantahigh-resolutionreproductionofoursignal,wedonotwanttostore moredatathanareneededtoobtainthatreproduction.Ifwesamplethesignalfortimes centeredaboutsome ùúèinanintervalofwidth Œîùúè(Figure10.8),andthencomputethetrans- formatanumberofscales sorfrequencies ùúî=2ùúã‚àïscoveringarangeofheight Œîùúî,then therelationbetweentheheightandwidthisrestrictedbytheuncertaintyrelation.Allthis meansthateachoftherectanglesinFigure10.8hasthesamearea ŒîùúîŒît=2ùúã.Theincreas- ingheightsoftherectanglesathigherfrequenciesmeansthatalargerrangeoffrequencies shouldbesampledasthefrequencyincreases.Thepremisehereisthatthelow-frequency componentsprovidethegrossor smoothoutlineofthesignalwhich,beingsmooth,does notrequiremuchdetail,whilethehigh-frequencycomponentsgivethedetailsofthesig- nal over a short time interval, and so require many components in order to record these detailswithhighresolution. Industrial-strengthwaveletanalysesdonotcomputeexplicitintegrals,butinsteadapply atechniqueknownas multiresolutionanalysis (MRA)[Mallat,1989].Wegiveanexampleof thistechniqueinFigure10.9andinthecode DWT.pyinListing10.2.Itisbasedona pyramid algorithmthatsamplesthesignalatafinitenumberoftimes,andthenpassesitsuccessively throughanumberof filters,witheachfilterrepresentingadigitalversionofawavelet. Filters were discussed in Chapter 9, where in (9.60) we defined the action of a linear filterasaconvolutionofthefilterresponsefunctionwiththesignal.Acomparisonofthe definition of a filter to the definition of a wavelet transform (10.14), shows that the two",4768
10.5.1 Pyramid Scheme,"10.5 Discrete Wavelet Transforms ‚äô205 LL H HLL LH H 22 2 Data input22 22 Figure 10.9 A eigenfrequency dyadic (power-of-2) Ô¨Ålter tree used for discrete wavelet transformations. The L boxes represent lowpass Ô¨Ålters and the H boxes represent highpass Ô¨Ålters. Each Ô¨Ålter performs a convolution (transform). The circles containing ‚Äú ‚Üì2‚Äù Ô¨Ålter out half of the signal that enters them, which is called subsampling orfactor-of-2 decimation . The signal on the left yields a transform with a single low and two high components (less information is needed about the low components for a faithful reproduction). are essentially the same. Such being the case, the result of the transform operation is a weightedsumovertheinputsignalvalues,witheachweighttheproductoftheintegration weighttimesthevalue ofthe waveletfunctionattheintegrationpoint.Therefore, rather thantabulateexplicitwaveletfunctions,asetoffiltercoefficientsisallthatisneededforDWT . In as much as each filter in Figure 10.9 changes the relative strengths of the different frequencycomponents,passingthesignalthroughaseriesoffiltersisequivalent,inwavelet language,toanalyzingthesignalatdifferentscales.Thisistheoriginofthename‚Äúmultires- olutionanalysis.‚ÄùFigure10.9showshowthepyramidalgorithmpassesthesignalthrough a series of highpass filters (H) and then through a series of lowpass filters (L). Each fil- ter changes the scale to that of the level below. Notice too, the circles containing ‚Üì2i n Figure 10.9. This operation filters out half of the signal and so is called subsampling or factor-of-2decimation .ItisthewaywekeeptheareasofeachboxinFigure10.8constantas wevarythescaleandtranslationtimes.Weconsidersubsamplingfurtherwhenwediscuss thepyramidalgorithm. Insummary,theDWTprocessdecomposesthesignalinto smoothinformationstoredin thelow-frequencycomponentsand detailedinformationstoredinthehigh-frequencycom- ponents.Because high-resolution reproductionsofsignalsrequiremoreinformationabout detailsthanaboutgrossshape,thepyramidalgorithmisaneffectivewaytocompressdata whilestillmaintaininghighresolution.Inaddition,becausecomponentsofdifferentreso- lutionsareindependentofeachother,itispossibletolowerthenumberofdatastoredby systematicallyeliminatinghigher-resolutioncomponents,iftheyarenotneeded.Theuseof waveletfiltersbuildsinprogressivescaling,whichisparticularlyappropriateforfractal-like reproductions. 10.5.1 Pyramid Scheme ‚äô WenowimplementthepyramidschemeoutlinedinFigure10.9.The HandLfilterswill be represented by matrices, which is an approximate way to perform the integrations or convolutions. Then there is a decimation of the output by one-half, and finally an inter- leaving of the output for further filtering. This process simultaneously cuts down on the numberofpointsinthedatasetandchangesthescaleandtheresolution.Thedecimation 206 10 Wavelet and Principal Components Analysis N samples N/2 d(1) CoefficientsN/2 c(1) Coefficients N/4 d(2) CoefficientsN/4 c(2) Coefficients N/8 c(3) CoefficientsN/8 d(3) Coefficients 2 d(n) Coefficients2 c(n) CoefficientsH H HH LLLLInput Figure 10.10 An input signal (top) is processed by a tree of high- and low-band Ô¨Ålters. The outputs from each Ô¨Åltering are downshifted with half the data kept. The process continues until there are only two data of high-band Ô¨Åltering and two data of low-band Ô¨Åltering. reducesthenumberofvaluesoftheremainingsignalbyone-half,withthelow-frequency partdiscardedbecausethedetailsareinthehigh-frequencyparts. AsindicatedinFigure10.10,thepyramidDWTalgorithmfollowsfivesteps: 1) Successively applies the (soon-to-be-derived) cmatrix (10.41) to the whole N-length vector, ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£Y0 Y1 Y2 Y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£c0c1c2c3 c3‚àíc2c1‚àíc0 c2c3c0c1 c1‚àíc0c3‚àíc2‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (10.31) 2) Appliesittothe N‚àï2-lengthsmoothvector. 3) Repeatstheapplicationuntilonlytwosmoothcomponentsremain. 4) Aftereachfiltering,theelementsareordered,withthenewesttwosmoothelementson top,thenewestdetailedelementsbelow,andtheolderdetailedelementsbelowthat. 5) Theprocesscontinuesuntiltherearejusttwosmoothelementsleft. 10.5 Discrete Wavelet Transforms ‚äô207 Toillustrate,herewefilterandreorderaninitialvectoroflength N=8: ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y1 y2 y3 y4 y5 y6 y7 y8‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶filter‚Üí‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£s(1) 1 d(1) 1 s(1) 2 d(1) 2 s(1) 3 d(1) 3 s(1) 4 d(1) 4‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶order‚Üí‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£s(1) 1 s(1) 2 s(1) 3 s(1) 4 d(1) 1 d(1) 2 d(1) 3 d(1) 4‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶filter‚Üí‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£s(2) 1 d(2) 1 s(2) 2 d(2) 2 d(1) 1 d(1) 2 d(1) 3 d(1) 4‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶order‚Üí‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£s(2) 1 s(2) 2 d(2) 1 d(2) 2 d(1) 1 d(1) 2 d(1) 3 d(1) 4‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (10.32) Thediscreteinversionofatransformvectorbacktoasignalvectorismadeusingthetrans- pose(inverse)ofthetransfermatrixateachstage.Forinstance, ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£c0c3c2c1 c1‚àíc2c3‚àíc0 c2c1c0c3 c3‚àíc0c1‚àíc2‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£Y0 Y1 Y2 Y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (10.33) As a more realistic example, imagine that we have sampled the chirp signal y(t)= sin(60t2)for 1024 times. The filtering process through which we place this signal is illustrated as a passage from the top to the bottom in Figure 10.10. First the original 1024 samples are passed through a single low band and a single high band (which is mathematically equivalent to performing a series of convolutions). As indicated by the down arrows, the output of the first stage is then downshifted, that is, the number is reducedbyafactorof2.Thisresultsin512pointsfromthehigh-bandfilteraswellas512 pointsfromthelow-bandfilter.Thisproducesthefirst-leveloutput.Theoutputcoefficients fromthehigh-bandfiltersarecalled {d(1) i}toindicatethattheyshowdetails,and {s(1) i}to indicatethattheyshowsmoothfeatures.Thesuperscriptindicatesthatthisisthefirstlevel ofprocessing.Thedetailcoefficients {d(1)}arestoredtobecomepartofthefinaloutput. Inthenextleveldown,the512smoothdata {s(1) i}arepassedthroughnewlow-andhigh- bandfiltersusingabroaderwavelet.The512outputsfromeacharedownshiftedtoform asmoothsequence {s(2) i}ofsize256andadetailedsequence {d(2) i}ofsize256.Againthe detailcoefficients {d(2)}arestoredtobecomepartofthefinaloutput.(Notethatthisisonly half the size of the previously stored details.) The process continues until there are only two numbers left for the detail coefficients and two numbers left for the smooth coeffi- cients.Becausethislastfilteringiscarriedoutwiththebroadestwavelet,itisofthelowest resolutionandthereforerequirestheleastinformation. In Figure 10.11, we show the actual effects on the chirp signal of pyramid filtering for variouslevelsintheprocessing.(Theprocessingiscarriedoutwith Daub4wavelets,which we will discuss soon.) At the uppermost level, the wavelet is narrow, and so convoluting thiswaveletwithsuccessivesectionsofthesignalresultsinsmoothcomponentsthatstill 208 10 Wavelet and Principal Components Analysis ‚Äì4‚Äì2024 0 10 20 30 40 50 60 70 90 110 130‚Äì 1.01.0 00 20 40 60 80 100 120 140 180 220 2 0 ‚Äì24 0 ‚Äì4 0 15 3035 45 55 65 0 4 8 12 168 4 ‚Äì40 ‚Äì8 012 0 2 ‚Äì202 34024 024‚Äì2024 56 7 810 12 1402 ‚Äì26 4 2 6 8 4 164 0 ‚Äì4 ‚Äì88 4 0 ‚Äì4 ‚Äì8 16 20 24 28 320.2 0 ‚Äì0.23 1 0 ‚Äì1 ‚Äì32 0 ‚Äì2 0 50 100 150 250 2000.04 0.02 ‚Äì0.02 ‚Äì0.04 300 350 400 450 500600 700 800 900 10000.06 0.04 0.02 01 0 ‚Äì1 0 100 200 300 400 5000.8 0.4 0 ‚Äì0.4 ‚Äì0.8 0 0.2 0.4 0.6 0.8 1.0 Figure 10.11 In successive passes, the Ô¨Åltering of the original signal at the top goes through the pyramid algorithm and produces the outputs shown. The sampling is reduced by a factor of 2 in each step. Note that in the upper graphs, we have connected the points to emphasize their continuous nature while in the lower graphs, we plot the individual output points as histograms.",7744
10.5.2 Daubechies Wavelets Filters,"10.5 Discrete Wavelet Transforms ‚äô209 contain many large high-frequency parts. The detail components, in contrast, are much smallerinmagnitude.Inthenextstage,thewaveletisdilatedtoalowerfrequency,andthe analysisisrepeated onjustthesmooth(low-band)part .Theresultingoutputissimilar,but withcoarserfeaturesforthesmoothcoefficientsandlargervaluesforthedetails.Notethat in the upper graphs we have connected the points to make the output look continuous, whileinthelowergraphs,withfewerpoints,wehaveplottedtheoutputashistogramsto make the points more evident. Eventually the downshiftingleads to just two coefficients outputfromeachfilter,atwhichpointthefilteringends. Toreconstructtheoriginalsignal(called synthesisortransformation )areversedprocess is followed: Begin with the last sequence of four coefficients, upsample them, pass them throughlow-andhigh-bandfilterstoobtainnewlevelsofcoefficients,andrepeatuntilall theNvalues of the original signal are recovered. The inverse scheme is the same as the processingscheme(Figure10.10),onlynowthedirectionofallthearrowsisreversed. 10.5.2 Daubechies Wavelets Filters ‚äô Weshouldnowbeabletounderstandthatdigitalwaveletanalysishasbeenstandardized to the point where classes of wavelet basis functions are specified not by their analytic forms, but rather by their wavelet filter coefficients . In 1988, the Belgian mathematician Ingrid Daubechies discovered an important class of such filter coefficients [Daubechies, 1995;RoweandAbbott,1995].WewillstudyjusttheDaub4classcontainingthefourcoef- ficientsc0,c1,c2,andc3. Imaginethatourinputcontainsthefourelements {y1,y2,y3,y4}correspondingtomea- surementsofasignalatfourtimes.Werepresentalowpassfilter Landahighpassfilter H intermsofthefourfiltercoefficientsas L=[ c0+c1c2+c3], (10.34) H=[ c3‚àíc2c1‚àíc0]. (10.35) To see how this works, we form an input vector by placing the four signal elements in a columnandthenmultiplytheinputby LandH: L‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=[ c0c1c2c3]‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=c0y0+c1y1+c2y2+c3y3, H‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=[ c3‚àíc2c1‚àíc0]‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=c3y0‚àíc2y1+c1y2‚àíc0y3. Weseethatifwechoosethevaluesofthe ci‚Äôscarefully,theresultof Lactingonthesignal vectorisasinglenumberthatmaybeviewedasaweightedaverageofthefourinputsignal elements.Sinceanaveragingprocesstendstosmoothoutdata,thelowpassfiltermaybe thoughtofasa smoothingfilter thatoutputsthegeneralshapeofthesignal. Inturn,weseethatifwechoosethe civaluescarefully,theresultof Hactingonthesignal vectorisasinglenumberthatmaybeviewedastheweighteddifferencesoftheinputsignal. 210 10 Wavelet and Principal Components Analysis Becauseadifferencingprocesstendstoemphasizethevariationinthedata,thehighpass filtermaybethoughtofasa detailfilterthatproducesalargeoutputwhenthesignalvaries considerably,andasmalloutputwhenthesignalissmooth. Wehavejustseenhowtheindividual LandHfilters,eachrepresentedbyasinglerow ofthefiltermatrix,outputsonenumberwhenactinguponaninputsignalcontainingfour elementsinacolumn.Ifwewanttheoutputofthefilteringprocess Ytocontainthesame number of elements as the input (four y‚Äôs in this case), we just stack the LandHfilters together: ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£Y0 Y1 Y2 Y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£L H L H‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£c0c1c2c3 c3‚àíc2c1‚àíc0 c2c3c0c1 c1‚àíc0c3‚àíc2‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (10.36) Ofcoursethefirstandthirdrowsofthe Yvectorwillbeidentical,aswillthesecondand fourth,butwewillgettothatsoon. Now wego aboutdeterminingthevaluesofthe filtercoefficients cibyplacingspecific demandsupontheoutputofthefilter.Westartbyrecallingthatinourdiscussionofdis- creteFouriertransformsweobservedthatatransformisequivalenttoarotationfromthe timedomaintothefrequencydomain.Yetweknowfromourstudyoflinearalgebrathat rotationsaredescribedbyorthogonalmatrices,thatis,matriceswhoseinversesareequal totheirtransposes.Inorderfortheinversetransformtoreturnustotheinputsignal,the transfermatrixmustbeorthogonal.Forourwavelettransformationtobeorthogonal,we musthavethe4 √ó4filtermatrixtimesitstransposeequaltotheidentitymatrix: ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£c0c1c2c3 c3‚àíc2c1‚àíc0 c2c3c0c1 c1‚àíc0c3‚àíc2‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£c0c3c2c1 c1‚àíc2c3‚àíc0 c2c1c0c3 c3‚àíc0c1‚àíc2‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1000 0100 0010 0001‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶, ‚áíc2 0+c2 1+c2 2+c2 3=1,c2c0+c3c1=0. (10.37) Twoequationsinfourunknownsarenotenoughforauniquesolution,sowenowinclude the further requirement that the detail filter H=(c3,‚àíc0,c1,‚àíc2)must output a zero if the input is smooth. We define ‚Äúsmooth‚Äù to mean that the input is constant or linearly increasing: [ y0y1y2y3]=[ 1111]or[ 0123]. (10.38) Thisisequivalenttodemandingthatthemomentsuptoorder parezero,thatis,thatwe havean‚Äúapproximationoforder p.‚ÄùExplicitly, H[ y0y1y2y3]=H[ 1111]=H[ 0123]=0, ‚áíc3‚àíc2+c1‚àíc0=0,0√óc3‚àí1√óc2+2√óc1‚àí3√óc0=0, ‚áíc0=1+‚àö 3 4‚àö 2‚âÉ0.483,c1=3+‚àö 3 4‚àö 2‚âÉ0.836, (10.39) 10.5 Discrete Wavelet Transforms ‚äô211 c2=3‚àí‚àö 3 4‚àö 2‚âÉ0.224,c3=1‚àí‚àö 3 4‚àö 2‚âÉ‚àí0.129. (10.40) ThesearethebasicDaub4filtercoefficients.Theyareusedtocreatelargerfiltermatrices byplacingtherowversionsof LandHalongthediagonal,withsuccessivepairsdisplaced twocolumnstotheright.Forexample,foreightelements, ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£Y0 Y1 Y2 Y3 Y4 Y5 Y6 Y7‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£c0c1c2c30000 c3‚àíc2c1‚àíc00000 00c0c1c2c300 00c3‚àíc2c1‚àíc000 0000 c0c1c2c3 0000 c3‚àíc2c1‚àíc0 c2c30000 c0c1 c1‚àíc00000 c3‚àíc2‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£y0 y1 y2 y3 y4 y5 y6 y7‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (10.41) Note that in order not to lose any information,the last pair on the bottom two rows is wrappedovertotheleft.Ifyouperformtheactualmultiplicationsindicatedin(10.41),you will note that the output has successive smoothanddetailedinformation. The output is processedwiththepyramidscheme. ThetimedependenciesoftwoDaub4waveletsaredisplayedinFigure10.12.Toobtain thesefromourfiltercoefficients,firstimaginethatanelementarywavelet y1,1(t)‚â°ùúì1,1(t) is input into the filter. This should result in a transform Y1,1=1. Inversely, we obtain y1,1(t)byapplyingtheinversetransformtoa Yvectorwitha1inthefirstpositionandzeros inalltheotherpositions.Likewise,the ithmemberoftheDaubechiesclassisobtainedby applyingtheinversetransformtoa Yvectorwitha1inthe ithpositionandzerosinallthe otherpositions. OntheleftinFigure10.12isthewaveletforcoefficient6(thusthee6notation).Onthe rightinFigure10.12isthesumoftwowaveletscorrespondingtothecoefficients10and58. Weseethatthetwowaveletshavedifferentlevelsofscaleaswellasdifferenttimepositions. ‚Äì0.1‚Äì0.06‚Äì0.020.020.060.1 0 400 800 1200‚Äì0.3‚Äì0.10.10.3 0 400 800 1200 Figure 10.12 Left: The Daub4 e6 wavelet constructed by inverse transformation of the wavelet coefÔ¨Åcients. This wavelet has been found to be particularly effective in wavelet analyses. Right: The sum of Daub4 e10 and Daub4 1e58 wavelets of different scale and time displacements.",6819
10.6.2 Wonders of the Covariance Matrix,"212 10 Wavelet and Principal Components Analysis Sodespitethefactthatthetimedependenceofthewaveletsisnotevidentwhenwavelet (filter)coefficientsareused,itisthere. 10.5.3 DWT Exercise ‚äô Listing10.2givesourprogramforperformingaDWTonthechirpsignal y(t)=sin(60t2). Themethod pyrancallsthe daube4methodtoperformtheDWTorinverseDWT,depending uponthevalueof sign. 1) Modifytheprogramsothatyououtputtoafilethevaluesfortheinputsignalthatyour codehasreadin.Itisalwaysimportanttocheckyourinput. 2) TrytoreproducetheleftofFigure10.11byusingvariousvaluesforthevariable nendthat controlswhenthefilteringends.Avalue nend=1024shouldproducejustthefirststepin thedownsampling(toprowinFigure11.10).Selecting nend=512shouldproducethenext row,while nend=4shouldoutputjusttwosmoothanddetailedcoefficients. 3) Reproduce the scale-time diagram shown on the right in Figure 10.11. This diagram shows the output at different scales and serves to interpret the main components of thesignalandthetimeinwhichtheyappear.Thetimelineatthebottomofthefigure corresponds to a signal of length 1 over which 256 samples were recorded. The low- band(smooth)componentsareshownontheleft,andthehigh-bandcomponentson theright. a) Thebottommostfigureresultswhen nend=256. b) Thefigureinthesecondrowupresultsfrom end=128,andwehavetheoutputfrom twofilterings.Theoutputcontains256coefficientsbutdividestimeintofourintervals andshowsthefrequencycomponentsoftheoriginalsignalinmoredetail. c) Continuewiththesubdivisionsfor end=64,32,16,8,and4. 4) Foreachofthesechoicesexceptthetopmost,dividethetimeby2andseparatetheinter- valsbyverticallines. 5) Thetopmostspectrumisyourfinaloutput.Canyouseeanyrelationbetweenitandthe chirpsignal? 6) Changethesignof signandcheckthattheinverseDWTreproducestheoriginalsignal. 7) Use the code to visualize the time dependence of the Daubechies mother function at differentscales. a) Start by performing an inverse transformation on the eight-component signal [0,0,0,0,1,0,0,0] .Thisshouldyieldafunctionwithawidthofabout5units. b) Next perform an inverse transformation on a unit vector with N=32 but with all componentsexceptthefifthequaltozero.Thewidthshouldnowbeabout25units, alargerscalebutstillcoveringthesametimeinterval. c) Continuethisprocedureuntilyouobtainwaveletsof800units. d) Finally,with N=1024,selectaportionofthemotherwaveletwithdatainthehor- izontal interval [590,800]. This should show self-similarity similar to that at the bottomofFigure10.12. 10.6 Part II: Principal Components Analysis 213 10.6 Part II: Principal Components Analysis Problem Given a dataset describing several properties of irises (flowers), separate the dataintogroupsinorderofimportance.Theproperties(incm)are [‚Äôsepal length‚Äô ,‚Äôsepal width‚Äô ,‚Äôpetal length‚Äô ,‚Äôpetal width‚Äô ] array( [5.1, 3.5, 1.4, 0.2], 3 [4.9, 3.0, 1.4, 0.2], [4.7, 3.2, 1.3, 0.2], [4.6, 3.1, 1.5, 0.2], [5.0, 3.6, 1.4, 0.2], 7 [5.4, 3.9, 1.7, 0.4], [4.6, 3.4, 1.4, 0.3], [5.0, 3.4, 1.5, 0.2], [4.4, 2.9, 1.4, 0.2], 11 [4.9, 3.1, 1.5, 0.1], [5.4, 3.7, 1.5, 0.2], [4.8, 3.4, 1.6, 0.2], [4.8, 3.0, 1.4, 0.1], 15 [4.3, 3.0, 1.4, 0.1], [5.8, 4.0, 1.2, 0.2], [5.7, 4.4, 1.5, 0.4], [5.4, 3.9, 1.3, 0.4], 19 [5.1, 3.5, 1.4, 0.3] ) WehaveindicatedthatashortcomingofFourieranalysisisthatitusesaninfinitenumber ofcomponents,thatallofthesecomponentsarecorrelated,andthusarenotindependent.",3315
10.6.2 Wonders of the Covariance Matrix,"Consequently, truncation of some of the components leads to difficulties in compression and reconstitution of the input signal. Wavelet analysis, on the other hand, is excellent at data compression, but not appropriate for high-dimensionality data sets, or for non- temporalsignals. PrincipalComponentsAnalysis(PCA) isapowerfulanalysistoolthatuses statisticstoprovideinsightintosignalsthatmaybecontainedwithina high-dimensionality , multivariate dataset. Examples of high dimensionally data include stellar spectra, brain waves,facialpatterns,andoceancurrents.Inthesecasestheremaybehundredsofdetec- torsinspace,eachofwhichrecordsseveraltypesofsignalsforweeksonend.Furthermore, thesekindsofdataareoftennoisy,andpossiblyredundant(differentdetectorsrecording correlatedsignals),andsoastatisticalapproachseemsappropriate. Variations of the PCA approach are used in many fields, where it goes by names such as the Kronen-Lo√®vet transform, the Hostelling transform, the proper orthogonal decomposition, singular value decomposition, factor analysis, empirical orthogonal functions,empiricalcomponentanalysis,andempiricalmodalanalysis[Wikipedia,2014]. The approach combines statistics with transformation theory, the latter familiar from linear algebra, to rotate from the basis vectors used to collect the data into new basis vectorsknownas principalcomponents thatlieinthedirectionofmaximalsignalstrength (‚Äúpower‚Äù)inthedataspace.Thisisanalogoustotheprincipalaxistheoremofmechanics in which the description of solid object rotations is greatly simplified when moments of inertiarelativetotheprincipalaxesareused.OurreferencesJackson[1991],Jolliffe[2002], Smith[2002],andShlens[2003]tendtoviewPCAas unsuperviseddimensionalityreduction , 214 10 Wavelet and Principal Components Analysis where ‚Äúunsupervised‚Äù refers to the absence of labels on the data, and ‚Äúreduction‚Äù to the small number of principal components that ultimately result. We prefer to view PCA as thewaytoextractthedominantdynamicscontainedincomplexdatasets. 10.6.1 Multi-dimensional Data Space It‚Äôs often helpful when dealingwith complex data to imagine an abstract vector space in whichthedataelementslie.Itisinthismulti-dimensional dataspacethatthePCAbasis vectors lie. As a simple example, consider the four detectors in Figure 10.13 observing a beam of particles passing by. Each detector records its observations over time, with the measurementsateachtimeconsideredaseparate,individualsample.Furthermore,each detectormayrecordasetof Mobservables,suchasposition,angle,intensity,thicknessof atrack,lengthofatrack, etc.ThisproducesanM-dimensionaldataspace ÓàæM.Specifically, let‚Äôssayateachinstantoftime,detectorArecordstheposition (x‚Ä≤ A,y‚Ä≤ A),andsoonfordetec- torsB‚ÄìD.Thesampleofspatialdataatthatoneinstantoftimeisthenrepresentedasan 8-Dvector: X‚Ä≤=[x‚Ä≤ ay‚Ä≤ ax‚Ä≤ by‚Ä≤ bx‚Ä≤ cy‚Ä≤ cx‚Ä≤ dy‚Ä≤ d]. (10.42) Togetanideaofthesizesofthedataspaceswithwhichwemightbedealing,ifthedetectors maketheirrecordingsfor18minutes(1080seconds)at110Hz,then1080 √ó110=118800 ofthesevectorsarecreatedin ÓàæM.Andthisisasmallproblem. Experimentaldatausuallycontainnoiseinadditiontosignalsofinterest.The variance ùúé2(z)inadatasetof Npointsisameasureofthedispersionofthedatumpointsfromtheir meanz: z=1 NN‚àë izi, (10.43) ùúé2(z)‚â°Var(z)def=1 N‚àí1N‚àë i(zi‚àíz)2.",3269
10.6.2 Wonders of the Covariance Matrix,"(10.44) Ifthedataareofhighprecision,thesignalwouldbemuchlargerthanthenoise.Inprac- tice,measurementscontainrandomandsystematicerrors,andthereforethesignal-to-noise ratio(SNR), SNR=ùúé2 signal ùúé2 noise, (10.45) maynotbelarge.PCAisagoodwaytodealwithsmallSNR.OntheleftofFigure10.14,we presentsomemade-up2Ddata (xA,yA)fromdetectorAshowingthedirectionofmaximum signalvariance ùúé2 signalalongPC1,andthedirectionofmaximumnoise(orsecondarysignal) Detector A Detector B Detector C Detector DFigure 10.13 A beam of particles being observed by four detectors. 10.6 Part II: Principal Components Analysis 215 PC1 PC2PC2ùïΩMùïΩk PC1yA XASignal NoiseœÉ2N œÉ2S Figure 10.14 Left: Samples of 2D data (xA,yA)from a detector A showing the direction of maximum signal variance ùúé2 Salong the principal component PC1basis, and the direction of noise variance ùúé2 Nalong the secondary PC2basis. Right: The same data projected onto the principal component axes. (Based on [Shlens, 2003].) variance ùúé2 noisealongPC2.Althoughatraditionalviewofstatisticsmaybethatalargevari- anceindicateshighnoise,inthePCAviewalargevarianceindicatesthatsomeinteresting dynamicsmaybeoccurringinthatdirectionindataspace. ThekeyPCAassumptionisthatthedirectionwiththelargestvariancecontainsmostof thedynamicsofinterest,andthatthedeviationofthedatafrommaximumvariancemay beduetonoise,ormaybesomelessimportantdynamics.The PC1andPC2directionsin Figure10.14arethetwoPCAbasisvectors,andarechosentomaximizetheSNRmeasured alongPC1,relativetothatalong PC2(we‚Äôllgettohowthesearedeterminedshortly).On therightofthefigureweshowthesamedataprojectedalongthe PC1andPC2axes.Here Óàækisalower-dimensionalspacecontainingthe korthonormalanduncorrelatedprincipal componentsvectors. 10.6.2 Wonders of the Covariance Matrix We have just seen graphically how PCA isolates the signal from the noise for a 2D dataset such as (x‚Ä≤ A,y‚Ä≤ A). However, our sample problem has four detectors, and thus a higher-dimensional space to analyze. We generalize one step at a time by extending the approachtoalsoincludedetectorB.Wedefinetwodatasets AandB,eachcenteredabout theirmeans, x,y,andexpressedastherowvectors: A=[a1(xa,1,ya,1)a2(xa,2,ya,2)‚Ä¶aN(xa,N,ya,N)], (10.46) B=[b1(xb,1,yb,1)b2(xb,2,yb,2)‚Ä¶bN(xb,N,yb,N)], (10.47) xa,i=x‚Ä≤ a,i‚àíx‚Ä≤,ya,i=y‚Ä≤ a,i‚àíy‚Ä≤. (10.48) Nextwecomputethevariances(10.44)foreachofthecentered( a=b=0)sets: ùúé2 A=1 N‚àí1N‚àë ia2 i,ùúé2 B=1 N‚àí1N‚àë ib2 i. (10.49) Thevarianceconceptisextendedto covariance,asameasureofthecorrelationbetweenthe centereddatain AandB: cov(A,B)def=ùúé2 ABdef=1 N‚àí1N‚àë iaibi. (10.50) 216 10 Wavelet and Principal Components Analysis Apositivecovarianceindicatesthatsignalswithin AandBtendtochangetogetherandin the same direction. A large covariance indicates a high correlation or redundancy, while azerovalueimpliesnocorrelation.Notethatthevariance(10.44)canbeviewedasaspe- cial case of the covariance, var (x)=cov(x,x), and that there is the symmetry cov (x,y)= cov(y,x).Alloftheseconceptsarecombinedintothesymmetriccovariancematrix: CAB=[ cov(A,A)cov(A,B) cov(B,A)cov(B,B)] .",3021
10.6.2 Wonders of the Covariance Matrix,"(10.51) Theseideasgeneralizedirectlytohigherdimensions.StartwiththesetsA(10.46)andB (10.47),whereweremindyouthattheelementsmaycontainanumberofmeasurements. Thecovariancematrixcanbewrittenasthevectordirectproduct(akadotproduct,matrix multiplication,ordyadic): CABdef=1 N‚àí1AB‚â°1 N‚àí1A‚äóBT. (10.52) Withthisnotation,wecangeneralizetohigherdimensionsbydefiningnew rowsubvectors containingthedatafromeachofthe Mdetectors: x1=A,x2=B,‚Ä¶,xM=M. (10.53) Wecombinetheserowvectorsintoanextended M√óNdatamatrix: X=‚é° ‚é¢ ‚é¢ ‚é¢‚é£x1 ... xM‚é§ ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£‚áìAll ‚áíAllAmeasurements ‚áìone ‚áíAllBmeasurements ‚áìtime ‚áíAllCmeasurements ‚áìmeasurements ‚áíAllDmeasurements‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (10.54) Eachrowofthismatrixcontainsallofthemeasurementsfromaparticulardetector,while eachcolumncontainsallofthemeasurementsforaparticulartime.Withthisnotation(and x=0),thecovariancematrixcanbewrittenintheconciseform C=1 N‚àí1XXT. (10.55) This can be thought of as a generalization of the familiar dot product of two 2D vectors, x‚ãÖx=xTx,asameasureoftheiroverlap. Insummary: ‚óèThecovariantmatrix Cijisthedotproductofthecenteredmeasurementsvectorfromthe ithdetector( i=A,B,‚Ä¶)withthecenteredmeasurementsvectorfromthe jthdetector. ‚óèForanytwovariablesinthedata, Cisasquaresymmetricmatrixmeasuringtherelation- shipbetweenthosevariables. ‚óèThe diagonal elements of Care the variances in the measurements from individual detectors. ‚óèThe off-diagonal elements of Care the covariances between the measurements from differentdetectors,thatis,thecorrelationsbetweendetectors. Steps in a Principal Component Analysis (Easy with NumPy) 1) As indicated in Figure 10.14, there is the assumption that the direction in which the variance is largest indicates the ‚Äúprincipal‚Äù component in the data, PC1orp1. 10.6 Part II: Principal Components Analysis 217 Table 10.1 PCA demonstration data. Data Adjusted data In PCA basis xyx y x1x2 2.5 2.4 0.69 0.49 ‚àí0.828 ‚àí0.175 0.5 0.7 ‚àí1.31 ‚àí1.21 1.78 0.143 2.2 2.9 0.39 0.99 ‚àí0.992 0.484 1.9 2.2 0.09 0.29 ‚àí0.274 0.130 3.1 3.0 1.29 1.09 ‚àí1.68 ‚àí0.209 2.3 2.7 0.49 0.79 0.913 0.175 2 1.6 0.19 ‚àí0.31 0.0991 ‚àí0.350 1.0 1.1 ‚àí0.81 ‚àí0.81 1.14 0.464 1.6 1.6 ‚àí0.31 ‚àí0.31 0.438 0.0178 1.1 0.9 ‚àí0.71 ‚àí1.01 1.22 ‚àí0.163 Consequently,PCAsearchesforthedirectionindataspaceforwhichthevarianceof X ismaximized. 2) Once p1hasbeenfound,thebasisvector p2ischosenastheorthonormalto p1. 3) The process is repeated until there are Morthonormalbasis vectors. These are the M principalcomponentsofthedata. 4) The eigenvectors and eigenvalues are ordered according to their corresponding variances. 5) Explicitly,startingwiththe M√óNdatamatrix X,amatrix Pisdeterminedsuchthat Cy=1 N‚àí1YYT=diagonal,where Y=PX. (10.56) 6) The rows of Pare the principalcomponentbasis vectors (same as the eigenvectorsof XXT). 7) Thediagonalelementsof CYarethevariancesof Xalongthecorresponding pi‚Äôs. Figure 10.15 Sample data used in our demonstration PCA analysis. xy ++ ++ + ++ + +++ 001234 12 3 4",2913
10.7 Code Listings,"218 10 Wavelet and Principal Components Analysis ‚Äì2‚Äì1012 ‚Äì2 ‚Äì1 0 1 2PC1PC2 Xy ‚Äì2‚Äì1012 ‚Äì2 ‚Äì1 0 1 2 x1x2 Figure 10.16 Left: The PCA basis vectors (eigenvectors of cov (x,y)).Right: The normalized data using the PCA eigenvectors as basis. 10.6.3 Demonstration of Principal Component Analysis We‚ÄôllleavetheanalysisoftheirisesdataatthebeginningofPartIIas yourproblem,and, instead,we‚ÄôllanalyzethesimplerdatainTable10.1[Smith,2002].Thesedata,areshown inFigure10.15as xversusy,buttheydon‚Äôthavetobespatial.Alsoshownistheanalysisof thesedataintermsofthefirsttwoprincipalcomponents.Asexpected,thefirsteigenvector pointsinthedirectionwiththelargestvariance,whilethenextvectorisorthogonaltothe first.Thereclearlyislessvariancealong PC2and,consequently,lessdynamicalimportance ofthatcomponent. Herearethestepsintheanalysis: 1)Enter data as an array :ThefirsttwocolumnsinTable10.1. 2)Subtract the mean :PCAanalysisassumesthatthedataineachdimensionhaszero mean.Accordingly,asshownincolumnstwoandthreeinTable10.1,wecalculatedthe meanforeachcolumn,( x,y),andsubtractedthemfromthedata.Theresultingadjusted dataaregiveninthethirdandfourthcolumnsofthetable. 3)Calculate the covariance matrix : var(x)=1 N‚àí1N‚àë i=1(xi‚àíx)2, (10.57) cov(x,y)=1 N‚àí1N‚àë i=1(xi‚àíx)(yi‚àíy), (10.58) C=[cov(x,x)cov(x,y) cov(y,x)cov(y,y)] =[0.6166 0.6154 0.6154 0.7166] . (10.59) 4)Compute unit eigenvector and eigenvalues of C(easy with NumPy) : ùúÜ1=1.284,ùúÜ2=0.4908, (10.60) PC1=[‚àí0.6779 ‚àí0.7352] , PC2=[‚àí0.7352 0.6789] , (10.61) 10.6 Part II: Principal Components Analysis 219 where we have ordered the eigenvalues and eigenvectors. The eigenvector with the largest eigenvalue is the principal component in the data, typically with ‚àº80 percent of the powerinthesignal. In Figure 10.16 we show the translated data and the two PCA eigenvectors of the covariancematrix(scaledtofilltheframe).Noticethat PC1,whichpointsindirection ofthemajorvariationinthedata,isessentiallyastraight-linefittothedata.The PC2 eigenvector is clearly orthogonal to PC1, and contains less signal strength. This is as shouldbe. 5)Express the data in terms of principal Components :Wenextexpressedthedatain termsoftheirtwoprincipalcomponentsbyformingtwo featurematrices : F1=[‚àí0.6779 ‚àí0.7352] ,F2=[‚àí0.6779‚àí0.7352 ‚àí0.7352 0.6779] . (10.62) HereF1keeps just the major principal component, while F2keeps the first two. The matrix gets its name because it focuses on which features of the data are being kept. Next we formed FT 2, the transpose of the feature matrix, and XT, the transpose of the translateddatamatrix X: FT 2=[‚àí0.6779‚àí0.7352 ‚àí0.7352 0.6779] , (10.63) XT=[0.69‚àí1.31 0.39 0.09 1.29 0.49 0.19 ‚àí0.81‚àí0.31‚àí0.71 0.49‚àí1.21 0.99 0.29 1.09 0.79 ‚àí0.31‚àí0.81‚àí0.31‚àí1.01] . Weexpressedthedataintermsoftheseprincipalcomponentsbymultiplying FT 2andX together: XPCA=FT 2√óXT(10.64) =[‚àí0.6779‚àí0.7352 ‚àí0.7352 0.6779] √ó[0.69‚àí1.31 0.39 0.09 1.29 0.49 0.19 ‚àí0.81‚àí0.31‚àí0.71 0.49‚àí1.21 0.99 0.29 1.09 0.79 ‚àí0.31‚àí0.81‚àí0.31‚àí1.01] =[0.828 1.78 ‚àí0.992‚àí0.274‚àí1.68‚àí0.913 0.0991 1.15 0.438 1.22 ‚àí0.175 0.143 0.384 0.130 ‚àí0.209 0.175 ‚àí0.350 0.464 0.178 ‚àí0.162] .",3063
10.7 Code Listings,"OntherightofTable10.1,thedataareplottedusingthe PC1andPC2bases.Theplot showswhereeachdatumpointsitsrelativetothetrendinthedata.Ifwehadplotted onlythefirstprincipalcomponent,allofthedatawouldfallonastraightline. 10.6.4 PCA Exercises 1) UsejusttheprincipaleigenvectorstoperformthePCAanalysisjustcompletedwithtwo eigenvectors. 2) Store data from 10 cycles of the chaotic pendulum studied in Chapter 8, but do not includetransients.PerformaPCAofthesedataandplottheresultsusingprincipalcom- ponentaxes. 220 10 Wavelet and Principal Components Analysis 10.7 Code Listings Listing 10.1 CWT.py UsesMorletwaveletstocomputethecontinuouswavelettransform ofthesumofsinefunctions.(CourtesyofZ.Diabolic.) 1# C W T.py Continuous Wavelet TF. Based on program by Zlatko Dimcovic importmatplotlib.pylab as p; frommpl_toolkits.mplot3d importAxes3D ; 5fromvisual.graph import ‚àó; originalsignal=gdisplay(x=0, y=0, width=600, height=200, \ title= ‚ÄôInput Signal‚Äô ,xmin=0,xmax=12,ymin= ‚àí20,ymax=20) 9orsigraph=gcurve(color=color.yellow) invtrgr = gdisplay(x=0, y=200, width=600, height=200, title= ‚ÄôInverted Transform‚Äô ,xmin=0,xmax=12,ymin= ‚àí20,ymax=20) invtr = gcurve(x= list(range(0,240)), display = invtrgr , color= color.green) 13iT = 0.0; fT = 12.0; W= fT ‚àíiT; N = 240; h = W/N # Need ‚àóvery ‚àósmall s for high f noPtsSig = N; noS = 20; noTau = 90; iTau = 0.; iS = 0.1; tau = iTau; s = iS 17dTau = W/noTau; dS = (W/iS) ‚àó‚àó(1./noS); maxY = 0.001; sig = zeros((noPtsSig), float) # Signal defsignal(noPtsSig, y): # Signal function 21t = 0.0; hs =W/noPtsSig; t1 =W/6.; t2 = 4. ‚àóW/6. foriin range (0, noPtsSig): ift> =i T andt<=t 1 :y [ i ] =s i n ( 2 ‚àópi‚àót) elift> =t 1 andt<=t 2 : y [ i ] = 5 . ‚àósin(2 ‚àópi‚àót) + 10. ‚àósin(4 ‚àópi‚àót); 25 elift> =t 2 andt<=f T : y[i] = 2.5 ‚àósin(2 ‚àópi‚àót) + 6. ‚àósin(4 ‚àópi‚àót) + 10. ‚àósin(6 ‚àópi‚àót) else: print(\""In signal(...) : t out of range.\"" ) 29 sys.exit(1) yy=y[i] orsigraph.plot(pos=(t,yy)) t+ =h s 33signal(noPtsSig, sig) # Form signal Yn = zeros( (noS+1, noTau+1), float) # Transform defmorlet(t, s, tau): #M o t h e r T= (t ‚àítau)/s 37 returnsin(8 ‚àóT)‚àóexp(‚àíT‚àóT/2. ) deftransform(s, tau, sig): # Find wavelet TF integral = 0. t=i T ; 41foriin range (0,len(sig) ): t+ =h integral += sig[i] ‚àómorlet(t, s, tau) ‚àóh returnintegral / sqrt(s) 45definvTransform(t, Yn): # Compute inverse s=i S # Transform tau = iTau recSig_t = 0 49foriin range (0, noS): s‚àó=d S # Scale graph tau = iTau forjin range (0, noTau): 53 tau += dTau recSig_t += dTau ‚àódS‚àó(s‚àó‚àó(‚àí1.5)) ‚àóYn[i , j ] ‚àómorlet(t,s,tau) returnrecSig_t print(\""working, finding transform, count 20\"" ) 57foriin range ( 0, noS): s‚àó=d S # Scaling tau = iT print(i) 61forjin range (0, noTau): tau += dTau # Translate Yn[i, j] = transform(s, tau, sig) 10.7 Code Listings 221 print(\""transform found\"" ) 65foriin range ( 0, noS): forjin range ( 0, noTau): ifYn[i , j ] > maxY orYn[i , j ] <‚àí1‚àómaxY : maxY =abs(Y n [ i ,j ]) #F i n dm a xY 69tau = iT s= i S print(\""normalize\"" ) foriin range ( 0, noS): 73s‚àó=d S forjin range ( 0, noTau): tau += dTau # Transform Yn[i , j ] = Yn[i , j ]/maxY 77tau = iT print(\""finding inverse transform\"" ) # Inverse TF recSigData = \""recSig.dat\"" recSig = zeros( len(sig) ) 81t = 0.0; print(\""count to 10\"" ) k c o=0 ; j=0 ; Y i n v= Y n forrsin range (0,len(recSig) ): 85recSig[rs] = invTransform(t, Yinv) #I n v e r t xx=rs/20 yy=4.6 ‚àórecSig[rs] invtr.plot(pos=(xx,yy)) 89t+ =h ifkco  percent24 == 0: j+ =1 print(j) 93kco += 1 x=list(range(1, noS + 1)) y=list(range(1, noTau + 1)) X,Y = p.meshgrid(x, y) 97 deffunctz(Yn): # Transform function z=Y n [ X ,Y ] returnz 101Z=f u n c t z( Y n ) fig = p.figure() ax = Axes3D(fig) ax.plot_wireframe(X, Y, Z, color = ‚Äôr‚Äô) 105ax.set_xlabel( ‚Äôs: scale‚Äô ) ax.set_ylabel( ‚ÄôTau‚Äô) ax.set_zlabel( ‚ÄôTransform‚Äô ) p.show() 109print(\""Done\"") Listing 10.2 DWT.py UsestheDaub4digitalwaveletsandthepyramidalgorithmtocom- putethediscretewavelettransformforthechirpsignalvaluesstoredin f[ ]. 1# D W T.py: Discrete Wavelet Transform, Daubechies , global variables fromvisualimport ‚àó fromvisual.graph import ‚àó 5 sq3 = sqrt(3); fsq2 = 4.0 ‚àósqrt(2); N = 1024 #N=2 ^ n c0 = (1+sq3)/fsq2; c1 = (3+sq3)/fsq2 # Daubechies 4 c2 = (3 ‚àísq3)/fsq2; c3 = (1 ‚àísq3)/fsq2 9transfgr1 = None # Display defchirp( xi): # Chirp signal y = sin(60.0 ‚àóxi‚àó‚àó2); 13returny; defdaube4(f, n, sign): # D W T if sign > = 0, inverse if sign <0 globaltransfgr1 , transfgr2 tr = zeros( (n + 1), float) # Temporary 17ifn<4:return 222 10 Wavelet and Principal Components Analysis mp = n/2 mp1 = mp + 1 # midpoint + 1 ifsign >= 0: #D W T 21 j=1 i=1 maxx = n/2 ifn > 128: #S c a l e 25 maxy = 3.0 miny = ‚àí3.0 Maxy = 0.2 Miny = ‚àí0.2 29 speed = 50 #F a s tr a t e else: maxy = 10.0 miny = ‚àí5.0 33 Maxy = 7.5 Miny = ‚àí7.5 speed = 8 #L o w e rr a t e iftransfgr1: 37 transfgr1.display.visible = False transfgr2.display.visible = False deltransfgr1 deltransfgr2 41 transfgr1 = gdisplay(x=0, y=0, width=600, height=400,\ title= ‚ÄôWavelet TF, down sample + low pass‚Äô , xmax=maxx,\ xmin=0, ymax=maxy, ymin=miny) transf = gvbars(delta=2. ‚àón/N,color=color.cyan,display=transfgr1) 45 transfgr2 = gdisplay(x=0, y=400, width=600, height=400,\ title= ‚ÄôWavelet TF, down sample + high pass‚Äô ,\ xmax=2 ‚àómaxx, xmin=0, ymax=Maxy, ymin=Miny) transf2 = gvbars(delta=2. ‚àón/N,color=color.cyan,display=transfgr2) 49 whilej<=n‚àí3: rate(speed) tr[i] = c0 ‚àóf[j] + c1 ‚àóf[j+1] + c2 ‚àóf[j+2] + c3 ‚àóf[j+3] #l o w‚àípass transf.plot(pos = (i, tr[i]) ) # c coefficients 53 tr[i+mp] = c3 ‚àóf[j]‚àíc2‚àóf[j+1] + c1 ‚àóf[j+2] ‚àíc0‚àóf[j+3] #h i g h transf2.plot(pos = (i + mp, tr[i + mp]) ) i+ =1 # d coefficents j+ =2 # Downsampling 57 tr[i] = c0 ‚àóf[n‚àí1] + c1 ‚àóf[n] + c2 ‚àóf[1] + c3 ‚àóf[2] #l o w‚àípass transf.plot(pos = (i, tr[i]) ) # c coefficients tr[i+mp] = c3 ‚àóf[n‚àí1]‚àíc2‚àóf[n] + c1 ‚àóf[1]‚àíc0‚àóf[2] #H i g h‚àípass transf2.plot(pos = (i+mp, tr[i+mp]) ) 61else: # Inverse D W T tr[1] = c2 ‚àóf[m p] + c1 ‚àóf[n] + c0 ‚àóf[1] + c3 ‚àóf[mp1] #L o w‚àípass tr[2] = c3 ‚àóf[m p]‚àíc0‚àóf[n] + c1 ‚àóf[1]‚àíc2‚àóf[mp1] #H i g h‚àípass j=3 65 foriin range (1, mp): tr[j] = c2 ‚àóf[i] + c1 ‚àóf[i+ m p] + c0 ‚àóf[i+1] + c3 ‚àóf[i+ mp1] #L o w j+ =1 # Upsample tr[j] = c3 ‚àóf[i]‚àíc0‚àóf[i+ m p] + c1 ‚àóf[i+1] ‚àíc2‚àóf[i+ mp1] # High 69 j+ =1 ; # Upsampling foriin range (1, n+1): f[i] = tr[i] # Copy TF to array defpyram(f, n, sign): # D W T , replaces f by TF 73if(n<4):return # Too few data nend = 4 #W h e nt o s t o p ifsign >= 0 : # Transform nd = n 77 whilend >= nend: # D o w n s a m p l e filtering daube4(f, nd, sign) nd //= 2 else: # Inverse TF 81 whilend<=n : # Upsampling daube4(f, nd, sign) nd‚àó=2 f=z e r o s (( N+1 ) , float) # Data vector 85i n x i=1 . 0 / N # For chirp signal xi = 0.0 10.7 Code Listings 223 foriin range (1, N + 1): f[i] = chirp(xi) # Function to TF 89xi += inxi; n=N # Must be 2^m pyram(f , n, 1) #T F #p y r a m ( f , n , ‚àí1) # Inverse TF",6739
11.1.1 Artificial Neural Networks,"224 11 Neural Networks and Machine Learning Automated systems should provide explanations that are technically valid, meaning- ful and useful to you and to any operators or others who need to understand the system, and calibrated to the level of risk based on the context . ‚ÄîWhite House AI Blueprint, 2022 The human brain, which has evolved (maybe) over six million years, is sometimes effective at solving problems that traditional computer programming Ô¨Ånds hard. This chapter deals with neural networks, artiÔ¨Åcial intelligence (AI), and machine learning. Part I deals with simple models for neurons and neural networks, based on those found in the brain. Part II demon- strates several state-of-the-art AI software packages, whose innards are based on neural nets. The applications are from physics, but deliberately simple, in order to demonstrate what‚Äôs inside the AI programs . Problem Developacomputermodelforaneuronandforanetworkoftheseneurons, andinvestigateifyournetworkhasthecapacitytolearn. Artificial intelligence (AI) simulates human cognitive abilities in learning and problem- solvingbycapturingthetypeoftacitknowledgethatisverydifficulttowriteintosoftware. Inrecentyears,AIhasmadegreatadvancesinpatternrecognition,decisionmaking,infer- ence, and generating controversially realistic data.1Machine Learning (ML) is a subfield of AI in which neural networks are taught by iteratively and inductively learning from teachingdata. DeepLearning isanextensionofmachinelearningthatuseslayersofneural networkstopassstatisticalassociationsfromonelayerofthenetworktothenext.Finally, generativeAI usestwoneuralnetworks,onetogeneratedata,andasecondtoevaluatethose data.Theoutputfromtheevaluationthengetsfedbackintothefirstnetworkforfurther trainingandimprovement. 1 HerbertSimonreceivedtheNobelMemorialPrizeineconomicsciencesin1978andtheTuringAward incomputersciencein1975,inpartialrecognitionforhisdevelopmentsinAI. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 11.1 Part I: Biological and ArtiÔ¨Åcial Neural Networks 225 11.1 Part I: Biological and ArtiÔ¨Åcial Neural Networks The study of neural networks began with studies of the brain. The human brain weighs about three pounds and contains approximately 1011nerve cells called neurons.T h e s e neurons are interconnected in complicated networks that somehow provide our mental capacities.AdrawingofaneuronisgivenontheleftofFigure11.1.Onthebottomofthe neuron‚Äôs cell body are branch-like dendrites that receive electrical and chemical pulses fromthesynapsesofotherneurons.Inturn,ifproperlyexcited,thecellbodysendsoffa singleelectricalpulsealongtheaxontothesynapticterminalsontop.Thepulseiscalled anaction potential , and is typically in the range 0‚Äì30 negative millivolts, with a width between1and6milliseconds. The pulses entering the cell body may be excitatory or inhibitory, which, respectively, increaseordecreasethenetvoltagethatreachesthecellbody.Thecellbodyintegratesthe incomingpulsesinavarietyofways,andifsomethresholdisreached,firesitsownpulse alongtheaxontothesynapticterminalswhereelectrochemicalinteractionswithotherden- dritestakeplace.Theprocessisbinaryinthesensethatapulseissent,ornotsent,each time with essentially the same pulse configuration. After firing, the neuron needs some timetorest. On the right of Figure 11.1, we see an actual image of the neurons in a mouse brain [Palmer, 2016; Reid et al., 2016]. This is a true biological neural network, and is seen to be a very complicated, net-like structure of neurons connected by axons, dendrites, and synapses. The sense organs pass signals to the outer layer of the brain, where neurons processthemthere.Theoutputfromtheouterlayerofthebraingetspassedontolower and lower layers in a hierarchical manner, with each layer‚Äôs processing believed to have itsownpurpose.Theprocesscontinuesuntilafinalresponseisreached,forexample,the Axon DendritesSynaptic terminals Nucleus Figure 11.1 Left: A sketch of a neuron showing dendrites, a cell body, and synaptic terminals. The dendrites transmit pulses to the cell body, where an electrical action potential originates and is sent along to synaptic terminals. Right: An electron microscope image of the network of cortical neurons in a mouse brain (adapted from [Palmer, 2016; Reid et al., 2016]).",4368
11.2.1 Coding A Neuron,"226 11 Neural Networks and Machine Learning recognitionofaface.Biologicalnetworksappeartobehighlyparallel,and,possiblyforthis reason,robust,withnosinglegroupofneuronsabsolutelyessential. 11.1.1 ArtiÔ¨Åcial Neural Networks In 1943, Warren McCullock, a psychiatrist with a deep intellectual interests in how the humanbrainworks,andWalterPitts,alogicianwithaninterestinbiologicalsciences,pro- posedalandmarkmathematicalformulationforaneuron,andforanetworkcomposedof suchneurons.Basedonthefunctionalityofthebiologicalneuron,theywentontodevelopa symbolic-logicalcalculusforhowtheirmodelneuronsinteractwitheachother[McCulloch andPitts,1943].McCullockandPittstherebyprovedmathematicallythataneuralnetcan betrainedandcanlearn.Theirneuronmodel,the McCulloch-Pittsneuron ,isstillastandard ofreferenceinthefield. ThemathematicalmodelofaMcCulloch-Pittsneuronisoftencalleda Perceptron.How- ever,thetermalsoreferstotheelectronicversionofaneuralnetworkbasedontheactual neurons‚ÄôbiologycreatedbyFrankRosenblattatCornellin1957[Rosenblatt,1958].2Rosen- blatt‚ÄôsPerceptrondisplayedtheabilitytolearn,andwasbothsensationalandcontroversial atthetime.Specifically,theperceptronwasasimulationonanIBM704that,after50trials, wasabletodistinguishpunchedcardsmarkedontheleftfromcardsmarkedontheright. Aftereachtrial,themachine‚Äôsconnectionswouldbetweaked,anditwouldbenotedifthere wasanimprovementinitsprediction,andiftherewas,thenthechangeswouldbekeptand furthertrialsmadeinanefforttoimprovethepredictions.However,thecomputingpower ofthe1950sand1960swasordersofmagnitudetoolowtoprovidetheconvincingdemon- strationofmachinelearningthatpresent-daycomputerscan,andRosenblattdiedin1971 withoutseeingthesuccessofhisideas. In analogy to a biological neuron, an artificial neural network (‚Äúnet‚Äù) processes data through multiple layers of neurons or nodes. Each node may accept several inputs, pro- cessestheminacomputingunit,and,ifsetcriteriaorthresholdisreached,outputsdata downitsaxonor edgetoothernodes.Theinternalalgorithmineachneuronusedindeci- sionmakinghaschangeableparameters,andthenetwork‚Äúlearns‚Äùbyiterativelychanging theparametricvaluesofeachneuronbasedontheaccuracyofoverallpredictions.Inthis way,differentnodesendupwithdifferentparametricvalues. 11.2 A Simple Neural Network InFigure11.2weseeasimpleartificialintelligence(AI)neuron,alsocalleda node,withtwo inputsandoneoutput.The x‚Äôsontheleftaretheinputsignalscomingfromothernodes, bW1X1 X2W2yfŒ£Figure 11.2 An AI neuron with two inputs and one output. The neuron body calculates a weighted sum of the inputs, and then processes the sum, possibly with bias band through a sigmoid function f. 2 Oneofus(RHL)recallsfondlythatWarrenMcCullockhelpedmentorhimaboutgraduateschool,and thatFrankRosenblattwasoneofhisundergraduateteachers.",2749
11.2.3 Training A Simple Network,"11.2 A Simple Neural Network 227 andtheŒ£inthecellbodydenotesaweightedsummationoftheinputsignals: Œ£=ùë§1x1+ùë§2x2. (11.1) Also within the cell body is the activationorsigmoid(S-shaped) function fthat decides, based on the value of Œ£, whether or not to fire. Consequently, the output ycan be expressedas y=f(x1ùë§1+x2ùë§2+b), (11.2) wherebisabias.Theweightsandthebiasesaretheparametersthatgetchangedduring learning.Asasimpleexample,let‚Äôssayourperceptronhasweights ùë§1=‚àí1,ùë§2=1,bias b=0,andacceptsthetwoinputvalues, x1=12,x2=8. (11.3) ThenŒ£=‚àí1√ó12+1√ó8=‚àí4,andiff(x)=x,thenthiswouldbetheneuron‚Äôsoutput y. Thebinarynatureoftheoriginalperceptronneuron,withitsoutputofonly0or1,can make building a network out of them challenging to train. A more trainable and robust network would contain sigmoid neurons in which the output is no longer restricted to 0 or1.Forexample, f(x)=1 1+e‚àíx,f(x)=tanh(x),fReLU(x)=max(0,x). (11.4) Theexponentialwouldproduceanoutputbetween0and1,thehyperbolictangentwould produceanoutputbetween ‚àí1and+1,andtheRectifiedLinearUnitoutputsthe x,ifxis positive,and0ifthe xisnegative.Forthesimplenetworkthatwewillsoondevelop,we shallusetheexponentialsigmoidfunction. 11.2.1 Coding A Neuron Exercise Below in Listing 11.1 we give a software model of single neuron coded with NumPy[Zhou,2022].Verifythatthiscodereproducesthehandcalculationabovethatgave ‚àí4asoutput. 11.2.2 Building A Simple Network InFigure11.3weshowanAInetworkcontainingthreelayers:aninputlayerontheleft, ahiddenlayerinthemiddle,andanoutputlayerontheright.Networkswithmorethan threelayersproducewhat‚Äôscalled deeplearning ,andsoournetworkmightbecalleda‚Äúshal- lowlearner.‚ÄùTheweightsforthesignalsenteringeachlayerareshown,whereitshouldbe Figure 11.3 A simple neural network with two neurons in the input layer, two neurons in the internal hidden layer, and one in the output layer.Oh1X1 X2w1 w5 w6 w4w2 w3 Input layerHidden layerOutput layerh2 228 11 Neural Networks and Machine Learning notedthattheactivationfunctionswithineachcellbodymaybealldifferent.Evenaneu- ralnetworkwithjustafewneuronscanhaveagoodnumberofconnectionsandsigmoid functions.We‚Äôllsacrificecomputingpowerforsimplicity,andmakeeachneuronidentical. Exercise Calculate by hand the expected output of the network in Figure 11.3 for x1=2,x2=3,andùë§1=0,ùë§2=1.Youshouldget O=0.7216. Thecode NeuralNet.py inListing11.1isforaneuralnetworkandmustincludetheprevious neuronclass.Checkthatitproducesanoutputof0.7216. 11.2.3 Training A Simple Network Figure 11.4 shows a flowchart for training an AI network. The network is taught by inputting predetermined training data for which the ‚Äúcorrect‚Äù output is known, and comparingthepredictedandcorrectoutputs.Onethencalculatesthe CostorLoss(whata physicistmightcall error): Cost‚â°Loss‚â°Óà∏=CorrectOutput ‚àíPredictedOutput . (11.5) ForaperfectnetworktheCostwouldbezero.ThemathematicalrelationbetweentheLoss and the network‚Äôs many parameters is generally unknown, and remains unknown even after training. During training, if the Cost is higher than some set value, the weights are tweaked by an amount based on the numerical evaluation of the derivatives of the Loss function.Thisprocess,called backpropagation ,isrepeateduntilareasonablysmallCostis obtained.Thenthemodelistestedondataithasnotseenbefore,anditstrueaccuracyis determined.Andifneedbe,furthertrainingmightbeinorder. Realisticnetworksmaycontainseveralhundrednodesforeachfeatureinthedatathat wewanttounderstand,withhundredsormorenodesineachhiddenlayer,butonlyasmall numberofnodesfortheoutput.Theoptimalnumbersfollowfromintuitionandtrialand error,sometimeswiththenumberincreasinguntilgoodresultsareobtained.Asyoucan wellimagine,fullytrainednetworksarelikeblackboxeswithmanyparametervaluesthat, inthemselves,donotexplainthestrategyusedtoobtainthecorrectanswers.Sowhileneu- ral nets are often successful and efficient at recognizing complex patterns, much as the humanbrain,theydonotprovideinsightintohowtheymadegooddecisions. Nowthatwehaveaneuralnet,let‚Äôstrainit.Ofcourseweshouldnotexpecthighperfor- mancefromthissimplenetwork,butthenagain,we‚Äôrenotputtingmuchintoit.Although Initial valuesRepeat unit minimize MSECompute MSE, mean squared error Compute gradient to change parameters Loss function stable done Figure 11.4 A Ô¨Çowchart of the steps in teaching a neural net, with the gradient of the Loss function used to minimize it. 11.2 A Simple Neural Network 229 insomesense,‚Äútraining‚Äùthenetworkisprogramming,it‚Äôsnotthekindofprogramming we‚Äôre accustomed to, where we go about modifying statements until we get things right. Rather,we,orsomealgorithm,willdoitsownthingandvarytheinternalparameters‚Äôval- ues,withthechangesbasedonhowclosethenetworkistoproducingtherightanswer.As wehavesaid,oncetrained,itisessentiallyimpossibletopredictwhatthenetworkdoes,or howit‚Äôsdoingit,bystudyingtheinternalparameters‚Äôvalues. Asasimpleexample,imaginethatyouwanttoidentify ùúãmesonsfrom ùúámesonsbased onthelengthandwidthofthetractstheyhaveleftonafilmstrip.Youstartwiththechar- acteristicsoffourtracksthathavealreadybeen(painstakingly)measuredbyeye: Track ID Length (mm) Width (mm) Particle A1 3 6 ùúã B 16 10 ùúá C1 5 9 ùúá D1 2 7 ùúã Inordertomakenumericalpredictions,welabela ùúáasa0anda ùúãasa1.Asisstandard inMLanddatamining,weconvertto mean-centereddata ,whichmeansthatwescalethe inputdatatohavezeromean(averagelength14,averagewidth8): Track ID Length ‚Äì 14 Width ‚Äì 8 Particle ID A ‚àí1 ‚àí21 B2 +20 C1 +10 D ‚àí2 ‚àí11 Nextwedefinethe Loss(11.5)asthemean-squareddifferencebetweenthecorrectanswers y(c) iandthepredictedones y(p) i: Óà∏=1 NN‚àë i( y(c) i‚àíy(p) i)2 , (11.6) whereNisthenumberofinputdata.Clearly,thesmallertheloss,thebetterthenetwork. Exercise Run the code below and check that it predicts that all of the input tracks are muons(y(p) i‚â°0). 1importnumpy as np # For N u m P y arrays defLoss(y_c, y_p): return((y_c‚àíy_p) ‚àó‚àó2).mean() # Auto mean of array 5y_c = np.array([1, 0, 0, 1]) y_p = np.array([0, 0, 0, 0]) print(Loss(y_c, y_p))",5916
11.2.4 Decreasing the Error,"230 11 Neural Networks and Machine Learning Thecodegives Óà∏=0.5,whichmeanswegottherightanswerhalfthetime(buttherewere onlytwochoices). 11.2.4 Decreasing the Error MinimizingtheLossisessentiallyidenticaltominimizinga ùúí2fittodata,whichwehave studiedinChapter6.Nowwewanttoadjusttheweights ùë§i‚Äôsandthebiases bi‚Äôstomini- mizeÓà∏.Evenforsomethingassimpleasourtwo-neuronnetworkinFigure11.3,wehave sixweightsandthreebiasestoadjust.Accordingly,anextremumin Óà∏occurswhen ùúïÓà∏ ùúïùë§i=0,i=1,‚Ä¶,6,ùúïÓà∏ ùúïbi=0,i=1,2,3. (11.7) For a complex network, there might be thousands or more of these equations, with only numericaldeterminationsofthederivativesfeasible.Thisisnotaone-timeaffair;onekeeps trainingthenetworkinhopesthatitwillmoveclosertoaminimum.Althoughtheparam- etersùë§iandbido not appear explicitly in the definition (11.6) of the Loss, the predicted valuesy(p) ido, and they are functions of the parameters in some unknown way. Accord- ingly,weusethechainrule(twice.)toobtaintheneededpartialderivatives.Forexample, because the weight ùë§1affects only the hidden neuron h1, and because there is only the singlepredictedvalue y(p) i, ùúïÓà∏ ùúïùë§1=ùúïÓà∏ ùúïy(p) iùúïy(p) i ùúïh1ùúïh1 ùúïùë§1. (11.8) Focusingonjustoneweightorbiasatatime,inthiscase ùë§1,isoftenusedintraining,with thenetworktrainedsequentiallyforeachoftheotherparameters. Wenowevaluatethesepartialderivatives.Thedefinition(11.6)ofLoss,makesthe ùúïy(p) i derivativeeasy: ùúïÓà∏ ùúïy(p) i=‚àí2 N( y(c) i‚àíy(p) i) , (11.9) wherethecorrectanswers y(c) i‚Äôsareknown,butnotthe y(p) i‚Äôs.Inthepresentcase,theoutput, y(p) out=f(ùë§5h1+ùë§6h2+b3), (11.10) makesthederivativeswithrespecttotheweightsstraightforward: ùúïy(p) out ùúïùë§5=h1df(x) dx(x=ùë§5h1+ùë§6h2+b3), (11.11) ùúïy(p) out ùúïùë§6=h2df(x) dx(x=ùë§5h1+ùë§6h2+b3). (11.12) Thederivativeofthesigmoidfunction(11.4)iseasy: f(x)=1 1+e‚àíx‚áídf(x) dx=e‚àíx (1+e‚àíx)2. (11.13) 11.2 A Simple Neural Network 231 Thenextderivativeweneed, ùúïh1‚àïùúïùë§1,followsfromourdefinitionofthe h‚Äôsandtheiruse, asshowninFigure11.3: h1=f(ùë§1x1+ùë§2x2+b1) (11.14) ‚áíùúïh1 ùúïùë§1=x1df dx(x=ùë§1x1+ùë§2x2+b1). (11.15) Nowweputallofthepiecestogether: ùúïÓà∏ ùúïùë§i=ùúïÓà∏ ùúïy(p) iùúïy(p) i ùúïùë§i=‚àí2 N( y(c) i‚àíy(p) i)ùúïy(p) i ùúïùë§i. (11.16) Thederivatives ùúïy(p) i‚àïùúïùë§idependsuponthemodelfortheneuron,andinparticular,onits sigmoidfunction f.Forourmodel,itsoneoutputis y(p) out=f(ùë§5h1+ùë§6h2+b3)=1 1+e‚àí(ùë§5h1+ùë§6h2+b3). (11.17) Forthetwo-neuronnetwork(Figure11.3),the hfunctionsare: h1=f(ùë§1x1+ùë§2x2+b1),h2=f(ùë§3x1+ùë§4x2+b2). (11.18) Nowthatwehavegonethroughsomeofthegrubbydetails,itmightbeclearthattheeval- uationoftheLossforabigrealisticnetworkisbestnotdonebyhand.Inordertocomplete ourexamplewiththeleastamountofpain,let‚Äôsalsolimitthenetwork‚Äôsinputtojustone oftheparticletracks,inthiscase,trackAwithlength x1=‚àí2,widthx2=‚àí1,andparticle y(c)=1.Furthermore,forsimplicity,let‚Äôssetalloftheweightsto1,andallofthebiasesto 0.Wethenhave h1=f(ùë§1x1+ùë§2x2+b1)=f(‚àí2‚àí1+0)=1 1+e‚àí3=0.0474, h2=f(ùë§3x1+ùë§4x2+b2)=f(‚àí2‚àí1+0)=1 1+e‚àí3=0.0474, ‚áíy(p) out=f(ùë§5h1+ùë§6h2+b3)=f(0.0474+0.0474) =1 1+e‚àí0.0948=0.524. (11.19) This prediction says that it is more likely that not that Track A is a ùúã(ID=1), but not verylikely.Thatbeingthecase,let‚Äôsadjusttheweightsandseeifitimprovesthenetwork‚Äôs prediction. To do that, we need to evaluate the derivative of the loss with respect to the parameter ùë§1(11.8): ùúïÓà∏ ùúïùë§1=ùúïÓà∏ ùúïy(p) outùúïy(p) out ùúïh1ùúïh1 ùúïùë§1, ùúïÓà∏ ùúïy(p) out=‚àí2(1‚àíy(p) out)=‚àí2(1‚àí0.524)=‚àí0.952, (11.20) ùúïy(p) out ùúïh1=ùë§5df dx(ùë§5h1+ùë§6h2+b3) =1√ódf dx(0.0474+0.0474+0)=exp(‚àí0.0948) (1+exp(0.0948))2=0.249,(11.21)",3422
11.2.5 Coding and Running A Simple Network. 11.3 A Graphical Deep Net,"232 11 Neural Networks and Machine Learning ùúïh1 ùúïùë§1=x1df dx(ùë§1x1+ùë§2x2+b1)=‚àí2df dx(‚àí2‚àí1+0)=‚àí0.0904 ‚áíùúïÓà∏ ùúïùë§1=‚àí0.952√ó0.249√ó(‚àí0.0904)=0.0214. (11.22) Atlast.Thistellsusthatifwedecrease ùë§1,thentheLoss Óà∏shouldgetsmaller,andthus yieldabetterprediction. Exercise Repeatthepredictionof y(p) outwithanincrementallydecreasing ùë§1,andobserve howthepredictionchanges. Todeterminejusthowmuchtochangetheweight,weassumethatwearecloseenough tothecorrectanswertoneedonlyafirst-ordercorrectiontotheweight: ùë§(new) 1‚âÉùë§(old) 1‚àíùúÇùúïÓà∏ ùúïùë§1. (11.23) HereùúÇiscalledthe learningrate ofthenetwork,andthemethodiscalled stochasticgradient descent(discussedfurtherinSection11.6.3).Evenforlarge-scaleproblems,theprocessis oftenmuchlikewhatwehaveworkedthroughhere,butprobablyautomated:onefocuses onasingleparameter,aswehavedonewith ùë§1,andthenrepeatstheprocessuntiltheLoss stops decreasing, or becomes too slow in its response. Then one goes on and repeats the processwitheachoftheotherweightsandbiases. 11.2.5 Coding and Running A Simple Network Listing11.3attheendofthischapterpresentsourcodeforthesimplenetwork.Itstarted withLoop n=0 Loss: 0.164 ,andendedwith Loop n=960 Loss: 0.002 . 1) Run SimpleNet.py andplottheLossversusthenumberoflearningtrials, N. 2) OnceyouhavetaughtthenetworkenoughforittoproduceasmallLoss,sayjustafew percent,determinethepredictionsitmakesonsomenewinputdata. 3) Extendoursimpletwo-nodehiddenlayernetworktoathree-nodehiddenlayer. a) Repeatthelearningexerciseusedforthetwo-nodehiddenlayernowforthethree- nodecase. b) Compare the effectiveness of learning for the two- and three-node hidden layer networks. 4) Extendoursimpletwo-nodehiddenlayernetworktoanetworkwithtwohiddenlayers, eachcontainingjusttwonodes. a) Repeatthelearningexerciseusedforanetworkwithatwo-nodehiddenlayer,now foronewithtwotwo-nodehiddenlayers. b) Compare the effectiveness of learning for the single and double two-node hidden layernetworks. 11.3 A Graphical Deep Net Wehavejustbuiltasimpleneuralnetworkwithsinglehiddenlayer,andshowedthatit‚Äôs capableoflearning,ifjustsomewhat.Now,basedonZhou[2018]andRohrer[2017],we 11.3 A Graphical Deep Net 233 ‚Äì1 ‚Äì1 110 0 ‚Äì2‚Äì2 InputHidden layer 1(h1) 1 √ó ‚Äì1 √ó + 1 √ó+ 1 √ó+= = = (h2, 1) (h2, 2) Figure 11.5 A deep neural net that classiÔ¨Åes a 4 √ó4 square into different classes. examinegraphicallya deepneuralnetwork withthreehiddenlayers.Thisnetwork,which isessentiallyanMLdecisiontree,hasbeendesignedtorecognizetheorientationofaline, anddoesitwithnoerror.Thepointhereistoseegraphically,withoutworkingthroughthe programming,howmorecomplicatedtaskscanbeaccomplishedbyneuralnetworks. TheleftofFigure11.5showsathree-hiddenlayernetworkthathasbeentaughttorec- ognizedifferentpatternswithina4 √ó4square.Thisisanexampleofhierarchicallayering inwhicheachsuccessivelayerrecognizesamorecomplexpattern.Thefirsthiddenlayer recognizesasinglepixel,thesecondlayerrecognizestwo-pixelcombinations,andsoforth. Eachcellhastwodendrites(edges)entering,andtwoleaving,withnoconnectionsbetween twoneuronsinthesamelayer,orbetweennonadjacentlayers.Thenumbersnexttoeach cellbodyaretheweightsoftheedgesappliedtothesignalstheyhavereceived. ThelargesquareontheleftofFigure11.5isthefour-pixelinput,inthiscasewithahor- izontalline.Theinputlinecanbe: horizontal: [xx ‚óΩ‚óΩ],[‚óΩ‚óΩ xx],vertical:[x‚óΩ x‚óΩ],[‚óΩx ‚óΩx],diagonal: [x‚óΩ ‚óΩx],[‚óΩx x‚óΩ],noline:[xx xx],[‚óΩ‚óΩ ‚óΩ‚óΩ]. As indicated by the white squares in Figure 11.5, each of the input layer‚Äôs four nodes is associatedwithadifferentpixellocation.Accordingly,theinputhorizontallineoccupying thetoptwopixelsinthefigureisnotidentifiedwiththetoptwonodesintheinputlayer (weight‚àí1),butisidentifiedwiththebottomtwonodes(weight +1). OntheleftofFigure11.5,weisolateHiddenLayer1anditsactioninidentifyingoneof thefourpixels.Basedontheinputtoitfromtheedges,thislayercombinessinglepixelsinto two-pixelcombinations,anddeterminesappropriateweights.Forexample,inFigure11.5 leftweseehowedgesfromthetopandthebottomnodesoftheinputlayerarefedintothe topnodeofHiddenLayer1.Onthe( h1)lineinFigure11.5b,weseehowthesetwoedges arecombinedintotherecognitionofaverticalline.Therebeingnoverticallineintheinput picture,aweightof0isrecorded.Thisisexpressedanalyticallyas x1ùë§1+x4ùë§4=( ‚àí1)(1)+(1)(1)=0. (11.24)",4173
11.4.1 TensorFlow Installation and Execution,"234 11 Neural Networks and Machine Learning OntherightofFigure11.5wedemonstratehowthetoptwonodesinHiddenLayer2are activated.Thetopnodeonline( h2,1)performsthecombination 1√ó[‚óΩx ‚óΩx]+1√ó[x‚óΩ x‚óΩ]=[‚óΩ‚óΩ ‚óΩ‚óΩ]. (11.25) Theseconddownnode( h2,2)performsthecombination ‚àí1√ó[‚óΩx ‚óΩx]+1√ó[x‚óΩ x‚óΩ]=[x‚óΩ x‚óΩ], (11.26) wherethenegationofwhiteisdefinedasblack. Thecellbodiesinthehiddenlayerscontainthe activationfunctions thatdeterminethe neurons‚Äôactionsbasedonweightedvaluesoftheinputs.Aslongasthesignaltransmitted tothenodeisnonzero,itremainsactiveandasignalgetstransmittedonward.Azero-input signalplacesthenodeinaninactivestatewithnotransmission. HiddenLayer3usesthe ReLUactivationfunction(rectifiedlinearunit)thattransmits positivesignals,butturnstheneuronoffiftheinputisnegative.Weleaveitasanexercise toworkthroughtheactionsinHiddenLayer3. Problem Here are four combinations: [X][‚óΩ],[X][X],[‚óΩ][X],[‚óΩ][‚óΩ].Build a neural networkthatcandistinguishthesecombinations. 11.4 Part II: Machine Learning Software In Part II of this chapter, we give examples of using Python with several industrial-strength ML software packages [Campesato, 2020], [Yalcin, 2021]. Preparing data for ML is often a time-consuming, and, accordingly, we also discuss a number of tools for preprocessing data. TensorFlow isafreeandpowerfulpackageofsoftwareformachinelearningviadeepneural networks.Itwasdevelopedby GoogleBrain fortheirownAIresearchanddevelopment,but in2015wasmadeavailableasopen-sourcesoftware.Themoreuser-friendlyTensorFlow2 wasreleasedin2019.WhenGoogleusesTensorFlowtheyemploytheirownTensorFlow CPU(TPU),whichisalsoavailableinthecloud.(Microsofthasalsoinvestedheavilyinto thecomputingpowerneededforAI,butit‚Äôsnotfree.)Google‚ÄôsTPUsarecapableofsome fourtrillionoperationspersecond,muchmorethananythingwewillneed.However,that amountofcomputingpowerisvaluablefortaskslikeexoplanetrecognition,atwhichAI excels, and, indeed, the absence of that power was the reason AI did not prosper in the 1950s. In general, neural networks are probably best suited to big problems, not for the smallpedagogicalproblemswe‚Äôlllookat. TensorFlow uses dataflowgraphs as its basic computational element, with each graph composedofnodesandedges(cellbodiesandaxonslikethoseinFigure11.2).The‚Äútensor‚Äù aspectofTensorFlowreferstoitsuseofarrayswithmultipleindices,liketensorsinphysics, torepresenttheedges.ThearraysarecompatiblewithPython‚ÄôsNumPy,withwhichyouare familiarfromChapter7.ThenodesinTensorFlowperformthemathematicaloperations, andtheedgestransferthedata.",2494
11.5 TensorFlow and SkLearn Examples,"11.5 TensorFlow and SkLearn Examples 235 11.4.1 TensorFlow Installation and Execution EventhoughsomeofthesedirectionsarearepeatofthoseinChapter1,somearenew,andso forthesakeofcompleteness,werepeatthemhere . InordertorunTensorFlowinteractivelyinanotebookenvironment,you‚Äôllneedafew things: ‚óèSetupanotebookenvironmentsuchasJupyter[2022].Thisgivesyouaweb-based,free, interactivecomputingplatformthatcombineslivecode,equations,text,visualizations, andmuchelse. ‚óèInstallanup-to-dateversionofPython,asavailablefromAnaConda[2022]. ‚óèInstallapackagemanager ,whichhelpsintheinstallationofalltheassociatedbitsand piecesofpackages.Werecommend[Conda,2023]withinaJupyterNotebook.Todothis, useashell(the Commandshellor PowerShell onWindows,orthe TerminalonMacs)to createtheCondaenvironment: conda create -name MyEnv whereyoumayuseanameotherthan MyEnvforyourenvironment. ‚óèFinally,you‚ÄôllneedTensorFlow.Followtheinstructionsin[Tensor,2022]. ‚óèActivateyourenvironmentbyentering: conda activate tensorflow ‚óèNexttellCondatousetheGitHubrepository conda-forge forneededpackages: conda install -c conda-forge tensorflow ‚óèOnce TensorFlow is installed, call the Anaconda Navigator and select MyEnvfrom Applications on/base(root) .Atthetopofthenavigator,therearethreeboxes.Select the middle one, which by default is base(root) , and change it to MyEnv, or whatever youhavedefinedasyourtensorflowenvironmentinJupyter.Also,whenwritinganew .ipynbnotebookinthebox New,selectyourTensorFlowenvironment( MyEnv). ‚óèOnceJupyterislaunched,select New/Python3(ipykernel)/MyEnv . ‚óèInanotebookcellenter: import tensorflow as tf andthenrun tf. ‚óèInthenextcellenter: print(tf. __version__) . Ensurethatyouhave TensorFlow 2 orT2.xandnot T1.x. 11.5 TensorFlow and SkLearn Examples Before we start using TensorFlow for some AI work, we‚Äôll run through several simple calculationswithitasacheckthatit‚Äôsinstalledandworkingproperly. Problem UseTensorFlowtocomputethemassnumber A,giventheatomicnumber Z andtheneutronnumber N. 236 11 Neural Networks and Machine Learning Asweallknow,theatomicnumber Zisthenumberofprotonsinanucleus,andthemass numberA=Z+Nisthesumofthenumberofprotonsandneutronsinanucleus.This programcalculates A,givenZandN: 1# TensorTest .py: Test TensorFlow [1]importtensorflow as tf [2] Z = tf.constant(1) # Hydrogen [3] N = tf.constant(2) # T w o neutrons = > tritium 5[4] A = tf.add(Z,N) [5]print(\""A:\"",A ) A: tf.tensor(3, shape=(), dtype=int32) Tounderstandthisoutput,here‚ÄôssomeTensorFlowspeak: ‚óèSize:Totalnumberofelementsinatensor. ‚óèAxis or Dimension: Aparticulardimensionofatensor. ‚óèRank 0 (scalar): Atensorwithonevalue,noaxis. ‚óèRank 1 (vector): Atensorwithalistofvaluesononeaxes. ‚óèRank 2 (matrix): Atensorwithalistofvaluesontwoaxes. ‚óèRank N:Atensorwith Nindices(akaorder,degree,orndims). ‚óèShape:Thelength(numberofelements)oneachaxesofatensor.Aconstanthasshape(), atensorwithdimensions[2,3]hasshape(2,3). ‚óèData types: Line6(L6)ofthelistingshownas int32.Otherdatatypesare: tf.float32 tf.float64 tf.int8 tf.int16 tf.int64 tf.uint8 tf.string tf.bool Problem UseTensorflowtocomputethemassexcessofthehydrogenisotopes. Problem Findthebindingenergyforeachoftheseven Hisotopes,andplotthebinding energiesversus A. Figure 11.6 shows the TensorFlow calculation of the hydrogen isotope mass excess, ran withinaJupyternotebook.The Zprotonsand Nneutronswithinanucleusareboundby Figure 11.6 A screenshot of a TensorFlow calculation of the mass excess of the hydrogen isotopes within a notebook environment. 11.5 TensorFlow and SkLearn Examples 237 thenuclearforce.Asaconsequence,therestenergy( mc2)ofthenucleusislessthanthe sumofitsconstituentmassesbythebindingenergy B: B=[Zm(1H)+Nmn‚àíMnuc]c2. (11.27) Atomic masses are usually stated in Daltons (Da, or u), with u defined as 1/12 the mass ofa12Catom=1.660538782 √ó10‚àí27kg‚âà931.5MeV ‚àïc2.Themassexcessisthedifference betweentheatomicmassMandutimestheatomicnumber: Massexcessdef=M‚àíAu. (11.28) Hydrogenexistsassevenisotopes,threeofwhichoccurnaturally[Haynes,2017]: NAtomic mass (u) NAtomic mass (u) 0 1.007827032 4 5.035 1 2.014101778 5 6.045 2 3.016049278 6 7.05 3 4.026 Here‚Äôsourprogram TensorBE.py thatcalculatesthemassexcessandproducestheleftpart ofFigure11.7: 1# TensorBE.py: TensorFlow calc H isotope binding E‚Äôs importtensorflow as tf importmatplotlib.pyplot as mpl 5importnumpy as np B=n p .z e r o s( 7 ) #[0 ,0 ,0 ,0 ,0 ,0 ,0] mP = tf.constant(938.2592) # Proton mass mN= tf.constant(939.5527) # Neutron mass 9mH= tf.multiply(1.00784, 931.494028) #Hm a s s i nM e V / c 2 am = tf.constant([1.007825032, 2.01401778,\ 3.016049278, 4.026, 5.035, 6.045, 7.05]) # Masses A = tf.constant([1, 2., 3., 4., 5., 6., 7.]) # Atomic numbers 13foriin range (7): C=m H+(i) ‚àómN‚àíam[ i ] ‚àó931.494028 AN = A[ i ] B[i]= C/AN 17print(\""BN :\"",B[i] ) mpl.ylabel( ‚ÄôBinding energy per nucleon (MeV)‚Äô ) mpl.xlabel( ‚ÄôAtomic mass number‚Äô ) mpl.plot(A,B) 21mpl.show() 10.00.51.01.52.02.5 0.00.51.01.52.02.5 234 Mass number3rd degree poly 4th degree polyBinding energy per nucleonBinding energy per nucleon 5 6 7 1234 Mass number567 Figure 11.7 Left: TensorFlow‚Äôs linear regression Ô¨Åt to the binding energies of seven hydrogen isotopes. Right: Third- and fourth-degree polynomial Ô¨Åts to",5164
11.5.1.1 Gradient Tape,"238 11 Neural Networks and Machine Learning 11.5.1 Preprocessing with Scikit-learn ThePythonpackage scikit-learn ,akasklearn,isalibraryofalgorithmsusedinMLforthe classification,regression(fitting),andclusteringofdata.Itisoftenusedintheprocessing oflargedatasets.Thepackageisinstalledfromashellwiththecommand: pip install scikit-learn . Here pipisPython‚Äôspackageinstaller,andit‚Äôsalsousefulforensuringthatyoursoftware isuptodate: pip upgrade scikit-learn . Problem Makeabestfit(regression)ofapolynomialtothehydrogenisotopes‚Äôbinding energiesasafunctionofatomicmassnumber. Here‚Äôsourprogram SkPolyFit.py thatusessklearn‚Äôspolynomialandlinearregressionmeth- ods,andwhichwe‚Äôlldiscussbelow: # SkPolyFit.py: Polynomial regression with sklearn 3importnumpy as np fromsklearn.preprocessing importPolynomialFeatures fromsklearn.linear_model importLinearRegression importmatplotlib.pyplot as plt 7importnumpy as np poly = PolynomialFeatures(degree=6, include_bias=False) # Degree 6 poly m A =n p . a r r a y ( [ 1 ,2 ,3 ,4 ,5 ,6 ,7 ] ) #A t o m i cm a s sn u m b e r 11poly_features = poly.fit_transform(mA.reshape( ‚àí1, 1)) #D a t a B = [0.0140, 1.1520, 2.8235, 1.8150, 1.3871, 0.9465, 1.2971] #B E / N poly_reg_model = LinearRegression() poly_reg_model.fit(poly_features , B) 15b_predicted = poly_reg_model.predict(poly_features) intcp = poly_reg_model.intercept_ , print(intcp) coefs = poly_reg_model.coef_ # Polynomial coefficients 19print(coefs) defpredict_y_value(x): y=‚àí1.91 + 1.72 ‚àóx + 0.288 ‚àó(x‚àó‚àó2)‚àí0.182 ‚àó(x‚àó‚àó3) + 0.016 ‚àó(x‚àó‚àó4) 23returny defpred_y_val(x): y=i n t c p+c o e f s [ 0 ] ‚àóx+c o e f s [ 1 ] ‚àóx‚àóx+c o e f s [ 2 ] ‚àóx‚àó‚àó3 returny 27xx = np.linspace(1,7,50) # Plot polynomial yy = predict_y_value(xx) y4 = pred_y_val(xx) fig , ax = plt.subplots() 31ax.scatter(mA,B) # Plot points plt.xlabel( ‚ÄôMass Number‚Äô ) plt.ylabel( ‚ÄôBinding Energy per nucleon‚Äô ) plt.plot(xx, yy, c = \""red\"",l a b e l = \""3rd degree poly\"" ) # Solid line 35plt.legend() plt.plot(xx, y4, label = \""4th degree poly\"" ) plt.legend() plt .show() Althoughlifewouldbesimpleriftherewereastandardwaytostorematricesandarrays, itisnotourchoicetomake.Specifically,scikit-learnworkswith2D verticalarrays ,which aredifferentfromthefamiliarNumPyarrays.Theseverticalarraysaremoreefficientwhen",2251
11.6 ML Clustering,"11.5 TensorFlow and SkLearn Examples 239 dealing with sparsematrices containing many zeros. Here‚Äôs a NumPy array and its SciPy sparsematrixversionusingcompressedrowstorage(CSR)format: NumPy Array: SciPy Sparse CSR Matrix: 2[ [1. 0. 0. 0.] (0, 0) 1.0 [0. 1. 0. 0.] (1, 1) 1.0 [0. 0. 1. 0.] (2, 2) 1.0 [0. 0. 0. 1.] ] (3, 3) 1.0 Returning to our code SkPolyFit.py in the listing above, notice the column of B values, with the mass array mAreshaped into a 2D column (the -1 on L11). On L16, intcp = poly_reg_model.intercept_ and coefs = poly_reg_model.coef_ give the intercept and the coefficients of the fitted polynomial. A third- and fourth-degree poly- nomial fit are shown on the right of Figure 11.7. Neither fit is very good, which is to be expectedsincenuclearbindingisnotasimpleprocess. 11.5.1.1 Gradient Tape WehavealreadyseeninourworkwithasimpleneuralnetworkthatMLinvolvesso-called backwardpass operationsthatrepeatacalculationusingtheoutputfromapriorexecution. Toavoidhavingtoredefine‚Äúnew‚Äùand‚Äúold‚Äùversionsofvariablesandfunctions,Tensor- Flowhasa GradientTape commandthatactslikeataperecorderthatstoresintermediate resultsforfutureuse.Here,andintheprogramstofollow,areexamplesofitsuse: # GradTape.py: Use of Tensor Flow ‚Äôs GradientTape importtensorflow as tf 3m= tf.Variable(1.5) b = tf.Variable(2.2) x = tf.Variable(0.5) y = tf.Variable(1.8) 7with tf.GradientTape() as tape: z = tf.add(tf.multiply(m, x), b) #z= m x + b loss = tf.reduce_sum(tf.square(y ‚àíz)) #( y‚àí(mx+ b ) ) ‚àó‚àó2 dloss_dx = tape.gradient(loss , x) #G r a d i e n t 11tf.print(‚ÄôdL/dx:‚Äô , dloss_dx) # Output dL/dx: 3.45000029 tf.print(2‚àó(‚àím)‚àó(y‚àí(m‚àóx+b))) # Check: output 3.45000029 Weseethat GradientTape.py hasrecordedthelossfunction Óà∏=[y‚àí(mx+b)]2,andeval- uatedthegradientof Óà∏. 11.5.2 Linear Fit to Hubble‚Äôs Data In1924,Hubblefittedastraightlineofslope ‚àº500(km/s)/Mpctohismeasurementsofthe recessionalvelocityofnebulaeversustheirdistancefromEarth[Hubble,1929].Werepeat that fitting using TensorFlow‚Äôs minimization of the Loss function. Listing 11.6 gives our program Hubble.py thatdoesthefitting,andinFigure11.8weshowtheinitialandfinal fits.Noteintheprogram: ‚óèOnL6-11thedataareenteredexplicitlyviathe tf.Variable command. ‚óèOn L17 x_trainis assigned to r,a n do nL 1 9 y_trainis set equal to the equation of a straightline, y=mx+b. ‚óèOnL25 tf.reduce_mean(tf.square(y_pred - y_true)) isusedtopredictthemean-square error. 240 11 Neural Networks and Machine Learning 0.00‚Äì20002004006008001000Step 0, Loss 307477.031250, m 24.598164 Step 290, Loss 221.644241, m 477.953796 0.25 0.50 0.75 1.00 rV 1.25 1.50 1.75 2.00 0.00 0.25 0.50 0.75 1.00 r1.25 1.50 1.75 2.00 Figure 11.8 TensorFlow‚Äôs Ô¨Årst (left) and Ô¨Ånal (right) Ô¨Åts to Hubble‚Äôs data of velocities ùë£of nebulae versus their distance r. ‚óèThe fitting is done by predicting values for y, computing the resulting loss, and then using the computed gradient of the loss function to guess new values for mand b.T h e processisrepeatedsome300times. 11.6 ML Clustering A key element in ML‚Äôs interpretation of data, and in its training of a neural network, is groupingdatainto clustersbaseduponsomecommonfeatures.Thiscanrevealsimilarities, ordifferences,inthedataelements,andcanbeusedtohighlightunusualelementswithin thedata.Ifthedataaregivenwithlabels,asinTable11.2,thenthisis supervisedlearning ; otherwise,it‚Äôs unsupervisedlearning .Nottothinkthatthisisjustbookkeeping;the cluster- ingproblemisclassifiedascomputationallydifficult( NP-hard),whichmeansitcannotbe solvedinpolynomialtime,whichmeansittakesalotofcomputingtimetosolveit. TheScikit-learn package,whichwehaveintroducedinSection11.5.1,clustersdatavia unsupervisedML.YoutellScikit-learnthenumber kofclustersyouwanttoform,andthe programsearchesthroughtheelementstofindthemostmeaningfulclusters.Anintegral Table 11.1 Data for 18 elementary particles tabulated by Index, Name, and Mass [PDG, 2023]. Index Name Mass (MeV/ c2)Index Name Mass (MeV/ c2) 1ùúà0.8√ó10‚àí610K¬±493.677 2 e 0.5110041 11 p 938.2721 3ùúá‚àí105.65 12 n 939.5654 4ùúá105.6583 13Œõ1115.683 5ùúã0134.98 14Œ£+1180.37 6ùúã+139.57 15Œ£‚àí1197.449 7ùúã‚àí139.57 16Œû01314.86 8ùúÇ547.862 17Œû‚àí1321.71 9K0497.611 18Œ©‚àí1672.45 11.6 ML Clustering 241 Table 11.2 Fourteen elementary particles and their masses. Number Name Masse Number Name Mass Number Name Mass 0 neutrino 0 7 eta 548 14 Sigma ‚àí1197 1 electron 0.5 8 K0 498 15 Xi0 1315 2m u ‚àí1069K +‚àí49416 Xi ‚àí1322 3 mu 106 10 p 938 17 Omega ‚àí1672 4 pi0 1345 11 n 940 12 Lambda 1115 5p i +1406p i ‚àí14013 Sigma +1180 part of that search is the calculation of the centroid of each cluster, that is, the location within each cluster that minimizes the squared-distance to that cluster‚Äôs elements. The learningprocesshastheprogramrepeatedlytryingoutdifferentclusters,withtheprocess endingwhenthenewcentroidsdonotmove,orafterafixednumberofcycles. Problem You are given Table 11.1 containing the masses of 18 elementary particles [PDG,2023].Formthreeclustersoftheseparticlesbasedontheirmasses. Ourprogram KmeansCluster.py isgiveninListing11.4,andFigure11.9showsthethree clusters,andtheircentroids,thatitfound.Thereclearlyisalow-masscluster,ahigh-mass cluster,andasmallmedium-masscluster.Noticeintheprogram: ‚óèOnL7-12thedataareentereddirectlyintotheprogramasaNumPyarray. ‚óèL13informs KMeansthatwewantthreecentroids,withinitialrandomelements. ‚óèL14determinestheinitialclustersby kmeans.fit . ‚óèTheprogramtriesoutdifferentclusters,andpredictsnewlocationsforthecentroids,as itlooksforaminimumintheLossfunction. ‚óèTheprogramcreatesascatterplotwiththecentroidlocationsshownasdiamonds,and thedataelementsasseparatecolorsforeachcluster. 2.502505007501000Code125015001750 5.0 7.5 10.0 12.5 15.0 17.5 Figure 11.9 Clustered elementary particles from KmeansCluster.py showing three clusters and their centroids as diamonds.",5748
11.6.1 Reading Files with Panda. 11.7 Keras Pythons Deep Learning API,"242 11 Neural Networks and Machine Learning 11.6.1 Reading Files with Panda Inthepreviousexercise,weentereddatadirectlyintotheprogram KmeansCluster.py .This really wouldn‚Äôt do for large datasets, or for analysing a number of datasets. The Python packagePandasiswhatweneed,asitprovidesanumberoftoolsformanipulatingandana- lyzingdata.Itisparticularlyusefulforinputtingdataintabular(column)form,incontrast toNumPy,whichworkswithdatainarrayform. Problem RepeatthelastproblemusingPandastoreadinthedatafromafile. Ourprogram PandaRead.py isgiveninListing11.7,whereyoumaynoticethatL7readsin theentirefile C:ElemnPart.dat fromTable11.1using‚Äúwhitespace‚Äùascolumnseparators. L8eliminatesthesuperfluous‚ÄúName‚Äùcolumn,whileonL10the Xvariableisassignedto ‚ÄúNumber,‚Äùandthe yvariableto‚ÄúMass.‚ÄùThen,asbefore, Kmeansusesthesevariablestofind threeclustersbasedonMass. 11.6.2 Clustering with Perceptrons InSection11.1.1weintroducedPerceptronsasthehistorical,artificialneuralnetinwhicha neuronfiresornot,dependingonsomethresholdvalue.Althoughperceptronsarenotstate- of-the-artAI,theyareusefulforsmallerdataframes(datastructureswiththedataarranged ina2Dtableofrowsandcolumns) . Problem YouaregivenTable11.2containing14elementaryparticlesandseveraloftheir properties. Use a Perceptron to cluster the particles into four groups, labeled by the type indexT,basedontheirproperties. The program Perceptron.py in Listing 11.5 uses Python‚Äôs sklearn package to create a perception , and then proceeds to find clusters of the particles. What‚Äôs new here is the use of a classifier algorithm that assumes an approximate linear behavior of the Loss function: Óà∏‚âÉùë§Tx+b, (11.29) anddetermines ùë§Tandbfromthetrainingdata.Thelearningroutineiteratesoverthedata, updatingtheweights ùë§via: ùë§‚Üíùë§‚àíùúÇùúïÓà∏(ùë§Txi+b,yi) ùúïùë§, (11.30) whereùúÇisthelearningrate parameter.Toprovidestabilityandprecision,thelearningrate forcycletismadetodecreasegraduallythroughthetrainingdata: ùúÇ(t)=1 ùõº(t0+t). (11.31) Someexplicitstepsof Perceptron.py programare: ‚óèL8 uses pandasto read in the columnar data, and L9-10 assigns Xto ‚ÄúMass‚Äù and y (‚ÄúName‚Äù)tothetypeindex T. 11.6 ML Clustering 243 ‚óèL13-16splitsthedataintotrainingandtestgroups,andplacesthemintoadataframe d withcolumnslabeled Typeandmass.L15specifiesaseedfortherandomnumbers,and alearningrate etabetween0and1. ‚óèThedataarescaledintostandardform(zeromeans,variance1)onL21-22,andreassigned tonewtrainingandtestingvariablesonL24-25. ‚óèL26-29importsthe perceptron ,andusesittomakeanMLfittothedata.Asistypicalfor AI,wearenotgivendetailsaboutjusthowthatisdone.The linear_model specification on L26 tells the perceptron to combine the weights of the input signals linearly, and comparetheresulttoathreshold ùúÉinordertodecidewhetheraneuronshouldfireor not: ifùúô(ùë§1x1+ùë§2x2+¬∑¬∑¬∑+ùë§mxm)>ùúÉ,fire. (11.32) Thefitismadewiththe ppn.fit(X_train_std,y_train) command,andobtainsanaccuracy 0.909(‚Äú missclasified ‚Äú)ongroup1ofthetestingdata. ‚óèTherestoftheprogramdeterminestheaccuracyofthefit,andthenoutputstheresults usingMatplotlibandcolorstodesignatetheclusters. ‚óèFigure11.10leftshowsthefourclassespredictedbythe perceptron .Thedataarecon- tainedwellwithintheirclusters,thoughnotperfectlyso. 11.6.3 Clustering with Stochastic Gradient Descent InSection11.2.4weincorporated StochasticGradientDescent (SGD)inoursimplenetwork asanoptimizationtechniquetominimizetheLoss.‚ÄúStochastic‚Äùreferstothepresenceof randomnessintheiterativesearchfortheminimum,and‚Äúgradientdescent‚Äùtotheuseof thedirectionofthegradientoftheLossfunctionasthedirectioninwhichtomoveinthe search. AsgiveninListing11.8,weagainanalyzethedatasetofthe14elementaryparticlesin Table11.2,butnowwith supervisedlearning .ThePerceptron‚Äôsclusteringoftheparticlesis nowbasedon MassandType (Number) asthelabel.Thetrainingdataareinputandplaced in random order, and then shuffled after each training period to avoid cycles. The final outputisshowninFigure11.10right,wherethedashedlines,called hyperplanes ,arethe dividinglinesbetweensubspaces.Itisseenthattheclusteringissimilartothatfoundwith thepreviousperceptron( Perceptron.py )ontheleft,butnotidentical. ‚Äì3 ‚Äì2 ‚Äì2‚Äì2‚Äì1012 0 1Test set Test set Test set Test set2 3 ‚Äì2‚Äì1012 ‚Äì1 0 1 2 ‚Äì1 0 Mass MassType Type 12 Figure 11.10 Left: Clustering of the data from Table 11.2. The Perceptron‚Äôs clustering of particles based on their Type (Number) and Mass is shown in shades of grey. Right: The clusters found with the SGD algorithm.",4374
11.8 Image Processing with OpenCV,"244 11 Neural Networks and Machine Learning 050 000100 000150 000200 000Loss250 000 250 500 750 1000 1250 1500 1750 2000 Epoch0.00‚Äì2000200400V r6008001000 0.25 0.50 0.75 1.00 1.25 1.50 1.75 2.00 Figure 11.11 Left: The decrease in Loss with increasing epochs. Right: The linear regression Ô¨Åt to Hubble‚Äôs data. 11.7 Keras: Python‚Äôs Deep Learning API [Keras, 2023] is Python‚Äôs Application Program Interface (API) for building and training deeplearning neuralnets.AsweindicatedinSection11.3,deeplearningreferstoneural netswithmultiplelayersofneuronsthroughwhichdataaretransferredsuccessivelydown throughthelayers.A layeristhebasicelementinadeepneuralnetwork;itreceivesinput information,processesitwithvariousactivationfunctions,biases,andweights,andthen passesitsoutputontoalowerlayer.A denselayerisoneinwhicheachneuroninthelayer receivesinputfrom alloftheneuronsinapreviouslayer.Computationally,theinputtoa layerisfedthenumberofneurons(units)inthepreviouslayer,theweightsfortheneurons‚Äô inputs,theiractivationfunctions,constraintsontheweights,andregularizerstooptimize theoutput.Here‚ÄôstheKerascommandtodoallthat: tf.keras.layers.Dense( units, activation = None, use_bias = True, kernel_initializer = \""glorot_uniform\"" , bias_initializer = \""zeros\"", kernel_regularizer = None, bias_regularizer = None, activity_regularizer = None, kernel_constraint = None, bias_constraint = None, ‚àó‚àókwargs ) Ourprogram Keras.pyinListing11.9againfitsastraightlinetoHubble‚Äôsdata,nowwith onedenselayer[TechBrij,2020].Figure11.11leftshowsitsoutput,whereyouwillnoticea rapiddecreaseinLossasthetraininggoesthroughthousandsofepochs.Figure11.11right showsthefinalfittothedata.Here‚Äôswhatthevariablesmean: ‚óèunits:Thedimensionoftheoutputvector. ‚óèactivation : The neurons‚Äô activation functions: sigmoid,relu(rectified linear), tanh (hyperbolictangent), selu(scaledexponentiallinearunit). ‚óèbias:thenumberaddedintotheneurons‚Äôresponses. ‚óèkernel_initializer :initializestheweightsmatrix. 11.8 Image Processing with OpenCV Problem Separateripestrawberriesfromgreenonesusingimagesofthem. 11.8 Image Processing with OpenCV 245 Figure 11.12 Left: Ripe strawberries. Right: Not so ripe strawberries. Ripe Tone0020 00040 00060 00080 000100 000120 000140 000 50 100Blue Green Red 150 200 ToneNot ripe 250 0 50 100 150 200 250020 00040 00060 00080 000100 000120 000140 000 Green RedBlue Figure 11.13 Left: The 256 tones in each of three colors for ripe strawberries. Right: The 256 tones in each of three colors for not quite ripe strawberries. MLispopularforimagerecognitionandprocessing,and OpenCVisalibraryofcomputer vision (CV) programs including modules for machine learning and neural networks. OpenCVisinstalledfromashellwithwhicheverofthesecommandsworkbest: pip install opencv-python pip install -user opencv-contrib-python ComputerimagesarecompositesofpixelsusingcombinationsofRed,Green,andBlue (RGB)colors.Typically,theamountofeachcolorpresentisrepresentedbyasinglebyte, whichpermits28=256levels(leavingoff0).Thatbeingthecase,therecanbe256 √ó256√ó 256=16,777,216RGBtones.OpenCVanalyzesanimageanddetermineshowmanypixels arepresentineachoftheRGBtones. To solve our fruit problem, consider Figure 11.12 showing some ripe, and some not so ripe,strawberries.WewanttousevisualprocessingandMLtoseparatestrawberriesinto theirdifferentstatesofripeness(orcoffeebeansintodifferentlevelsofroastings,ifyouare notafruitperson.)Wedoitbyforminghistogramsshowingtheamountofeachofthe255 tonespresent,foreachofthethreecolors.WedothisinFigure11.13,andimagineusing thedifferencesinthehistogramstoseparatethefruit.Hereisourprogramthatreadsinthe image ripe2.jpgandproducesthehistogramsinFigure11.13:",3641
11.9 Explore ML Data Repositories,"246 11 Neural Networks and Machine Learning 1importnumpy as np importcv2 as cv importmatplotlib.pyplot as plt image = cv.imread( \""c:/ripe2.jpg\"" ) #R e a di m a g e 5fig , ax =plt.subplots() hist = cv.calcHist([image], [0], None, [256], [0,256]) # 3 colors ax.plot(hist , color = ‚Äôb‚Äô, linestyle= ‚Äô-‚Äô) hist = cv.calcHist([image],[1], None,[256], [0,256]) 9ax.plot(hist , color = ‚Äôg‚Äô,linestyle= ‚Äô-.‚Äô) hist = cv.calcHist([image], [2], None, [256], [0,256]) ax.plot(hist , color = ‚Äôr‚Äô, linestyle= ‚Äô:‚Äô) plt.legend([ \""blue\"",\""green\"",\""red\""]) 13plt.title( \""ripe2\"") plt.xlim([0,256]) plt.ylim([0,150000]) plt .show() 11.8.1 Background Subtraction Anothertypeofimageprocessingremovesastaticbackgroundfromavideorecording,as mightbeneededinthesearchforexoplanetsorsupernovas.Thisisaccomplishedbylook- ingatthedifferencebetweensuccessiveimageframes,andremovingthepartsthatdonot change.Ourprogram,below,processedanavifile,andproducedFigure11.14,whereyou willseethat,otherthantherisingsmokeandthemovingpiston,thebackgroundhasbeen removed.Theprogramwaswrittenbyoneoftheauthors(MJP)foravirtualphysicscourse intheProgram@udeaatLaUniversidaddeAntioquia. importcv2 as cv sub_backg = cv.createBackgroundSubtractorMOG2() cap = cv.VideoCapture( ‚Äôc:/vapor.avi‚Äô ) 4while(1): ret , frame = cap.read() imgNoBg = sub_backg.apply(frame) #fgmask = fgbg . apply(frame) 8cv.imshow( ‚Äôframe‚Äô, frame) cv.imshow( \""no bkgr\"" , imgNoBg) k = cv.waitKey(30) & 0xff ifk == 27: break Figure 11.14 Left: One frame from an animation in which the piston is moving back and forth in front of a background image. Right: An image in which the stationary part (background) of the video has been removed.",1663
11.10 Code Listings,"11.10 Code Listings 247 11.9 Explore ML Data Repositories Tryusingsomeofthetoolspresentedhereonrealdatasets.Findonethatinterestsyou,or lookhere(someofwhichareusedincompetitions): Deep learning physics open data: www.deeplearnphysics.org/DataChallenge/ MLPhysics portal: mlphysics.ics.uci.edu/ Particle tracking challenge: www.kaggle.com/c/trackml-particle-identification 17 datasets for physics: paperswithcode.com/datasets?mod=physics Carbon nanotubes: www.kaggle.com/inancigdem/carbon-nanotubes Public datasets ‚Äì IML ‚Äì CERN: iml.web.cern.ch/public-datasets Molecular properties: www.kaggle.com/c/champs-scalar-coupling Steel defect detection: www.kaggle.com/c/severstal-steel-defect-detection 11.10 Code Listings Listing 11.1 Neuron.py, AnAIneuron. # Neuron . py : An AI neuron 2 importnumpy as np deff(x) :return1./ (1. + np.exp( ‚àíx)) # Activation function 6classNeuron : def__init__(self , weights, bias) : self.weights = weights self.bias = bias 10 deffeedforward(self , inputs) : # Process input Sum = np.dot (self.weights, inputs) + self.bias returnf(S u m) 14 weights = np.array([ ‚àí1., 1.]) #w 1= ‚àí1, w 2 = 1 bias = 0 n = Neuron(weights,bias) 18x = np.array([12,8]) # x1 = 12 , x2 = 8 print(n.feedforward(x)) # output: 0.01798620996209156 Listing 11.2 NeuralNet.py AsimpleAIneuralnetwork. # NeuralNet .py : A simple AI neural network 2 importnumpy as np deff(x) :return1./ (1. + np.exp( ‚àíx)) # Activation function 6classNeuron : def__init__(self , weights, bias) : self.weights = weights self.bias = bias 10deffeedforward(self , inputs) : # Process input Sum = np.dot (self.weights, inputs) + self.bias returnf(S u m) 14weights = np.array([ ‚àí1., 1.]) #w 1= ‚àí1, w 2 = 1 bias = 0 n = Neuron(weights,bias) x = np.array([12,8]) # x1 = 12 , x2=8 248 11 Neural Networks and Machine Learning 18print(n.feedforward(x)) # Output: 0.01798620996209156 classNeuralNetwork: #2‚àíneuron network , 2 hidden layers , 1 output def__init__(self): 22weights = np.array([0,1]) bias = 0 self.h1 = Neuron(weights, bias) # Neuron class as before self.h2 = Neuron(weights, bias) 26self.O = Neuron(weights, bias) deffeedforward(self , x): out_h1 = self.h1.feedforward(x) 30out_h2 = self.h2.feedforward(x) out_out = self.O.feedforward(np.array([out_h1, out_h2])) returnout_out network = NeuralNetwork() 34x = np.array([2, 3]) print(network.feedforward(x)) #output: 0.7216325609518421 Listing 11.3 SimpleNet.py Apythoncodeforoursimpleneuralnetwork. 1# SimpleNet .py : A simple neuron network importnumpy as np deff(x):return1/(1 + np.exp( ‚àíx)) # Sigmoid activation function 5deffprime(x): returnnp.exp( ‚àíx)/(1 + np.exp( ‚àíx))‚àó‚àó2# Sigmoid derivs defLoss(y_true, y_out): los = ((y_true ‚àíy_out) ‚àó‚àó2).mean() #print(los) 9returnlos classSimpleNet: # x _ 1 ,x _ 2i n ,h i d d e n h 1 ,h 2 ,y _ o u t def__init__(self): # R a n d o m inits 13 self.w1=np.random.normal() # Weights self.w2=np.random.normal() self.w3=np.random.normal() self.w4=np.random.normal() 17 self.w5=np.random.normal() self.w6=np.random.normal() self.b1=np.random.normal() # Biases self.b2=np.random.normal() 21 self.b3=np.random.normal() deffeedfwd(self , x): h1 = f(self .w1 ‚àóx[0] + self.w2 ‚àóx[1] + self.b1) 25 h2 = f(self .w3 ‚àóx[0] + self.w4 ‚àóx[1] + self.b2) out = f(self.w5 ‚àóh1 + self .w6 ‚àóh2 + self .b3) returnout 29deftrain (self , data, all_y_trues): learn_rate = 0.1 N = 1000 # Number of learning loops fornin range (N): 33 forx, y_true inzip(data, all_y_trues): sum_h1 = self .w1 ‚àóx[0] + self.w2 ‚àóx[1] + self.b1 h1 = f(sum_h1) sum_h2 = self .w3 ‚àóx[0] + self.w4 ‚àóx[1] + self.b2 37 h2 = f(sum_h2) sum_out = self .w5 ‚àóh1 + self .w6 ‚àóh2 + self .b3 out = f(sum_out) y_out = out 41 d_L_d_yout = ‚àí2‚àó(y_true ‚àíy_out) # Partial deriv d_yout_d_w5 = h1 ‚àófprime(sum_out) # Output neuron d_yout_d_w6 = h2 ‚àófprime(sum_out) d_yout_d_b3 = fprime(sum_out) 45 d_yout_d_h1 = self.w5 ‚àófprime(sum_out) d_yout_d_h2 = self.w6 ‚àófprime(sum_out ) d_h1_d_w1 = x[0] ‚àófprime(sum_h1) # Hidden Neuron h1 d_h1_d_w2 = x[1] ‚àófprime(sum_h1) 11.10 Code Listings 249 49 d_h1_d_b1 = fprime(sum_h1) d_h2_d_w3 = x[0] ‚àófprime(sum_h2) # Hidden Neuron h2 d_h2_d_w4 = x[1] ‚àófprime(sum_h2) d_h2_d_b2 = fprime(sum_h2) 53 # Update weights and biases self.w1 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_h1 ‚àód_h1_d_w1 #h 1 self.w2 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_h1 ‚àód_h1_d_w2 self.b1 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_h1 ‚àód_h1_d_b1 57 self.w3 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_h2 ‚àód_h2_d_w3 #h 2 self.w4 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_h2 ‚àód_h2_d_w4 self.b2 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_h2 ‚àód_h2_d_b2 self.w5 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_w5 #O u tn ‚Äô s 61 self.w6 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_w6 self.b3 ‚àí= learn_rate ‚àód_L_d_yout ‚àód_yout_d_b3 if(n percent10) == 0: #L o s sa tl o o pe n d s y_outs = np.apply_along_axis(self.feedfwd,1,data) 65 TotLoss =Loss(all_y_trues ,y_outs) #print(\"" resta \"" ,(( all_y_trues ‚àíy_outs) ‚àó‚àó2) .mean() ) #print(\""y_trues\"" , all_y_trues) print(\"" Loop n =  percentd Loss:  percent.3f\""  percent (n, TotLoss)) 69data = np.array ([[ ‚àí2,‚àí1], [25, 6], [17, 4],[ ‚àí15,‚àí6] ]) #I n p u tD a t a all_y_trues = np.array ([ 1, 0, 0, 1 ]) network = SimpleNet() #T r a i nn e t network.train(data, all_y_trues) Listing 11.4 KmeansCluster.py Clusteringofdatawithsklearn‚ÄôsKmeans.",5226
11.10 Code Listings,"# KmeansCluster.py: Clustering with sklearn ‚Äôs KMeans 2 fromsklearn.cluster importKMeans importmatplotlib.pyplot as plt importnumpy as np 6 percentmatplotlib inline X = np.array([ [1, 0], [2, 0.511], [3, 105.65], [4, 105.6583], [5, 134.98], [6, 139.57],[7,139.57],[8,547.86],[9,497.68],[10,493.677], 10[11,938.2721],[12,939.5654],[13,1115.68],[14,1180.37], [15,1197.5],[16,1314.86], [17,1321.71],[18,1672.45] ]) kmeans = KMeans(n_clusters=3, random_state=42) # 3 random centroids 14kmeans. fit (X) # Compute clustering kmeans.predict(X) # Predict closest cluster kmeans.labels_ cc = kmeans.cluster_centers_ # Cluster centers 18print(\""cc:\"",cc) fig , ax = plt.subplots() plt.xlabel( \""N\"") plt.ylabel( \""Code\"") 22plt.scatter(X[:,0],X[:,1],c=kmeans.labels_, marker= \""ÀÜ\"") plt.scatter(cc[:,0],cc[:,1],c= ‚Äôred‚Äô,m a r k e r = \""D\"")#with diamonds plt .show() Listing 11.5 Perceptron.py Sklearn‚Äôs Perceptron commandcreatesaperceptron. # Perceptron .py: Creat perceptron with sklearn 2 importpandas as pd # To read dataset importmatplotlib.pyplot as plt importnumpy as np 6 percentmatplotlib inline parts = pd.read_table( \""C:particle.dat\"" ,delim_whitespace=True) X = parts[ \""Mass\""] # X: masses 10y = parts[ ‚ÄôT‚Äô] #y :T y p e print(‚ÄôClass labels:‚Äô , np.unique(y)) # The 4 classes d={ ‚Äôcol1‚Äô:X,‚Äôcol2‚Äô:y} #d : 2‚àíD array of X &y 250 11 Neural Networks and Machine Learning dfrom sklearn.model_selection importtrain_test_split # Split array 14X_train, X_test, y_train, y_test = train_test_split( df, y, test_size=0.3, random_state=1, stratify=y) #F o r m2 ‚àíD dataframe fromsklearn.model_selection importtrain_test_split # Split array 18# Shuffle data dataf= pd.DataFrame(d) X_train, X_test, y_train, y_test = train_test_split( df, y, test_size=0.3, random_state=1, stratify=y) fromsklearn.preprocessing importStandardScaler 22sc = StandardScaler() sc.fit(X_train) X_train_std = sc.transform(X_train) X_test_std = sc.transform(X_test) 26fromsklearn.linear_model importPerceptron ppn = Perceptron(eta0=0.1, random_state=1) ppn.fit(X_train_std,y_train) #F i td a t a y_pred = ppn.predict(X_test_std) 30print(‚ÄôMisclassified examples:  percentd‚Äô  percent (y_test .= y_pred). sum()) fromsklearn.metrics importaccuracy_score print(‚ÄôAccuracy:  percent.3f‚Äô  percent accuracy_score(y_test , y_pred)) print(‚ÄôAccuracy:  percent.3f‚Äô  percent ppn.score(X_test_std, y_test)) 34frommatplotlib.colors importListedColormap fig , ax = plt.subplots() plt.xlabel( \""mass\"") plt.ylabel( \""Type\"") 38 foriin range (36): # Plot spin (0, 1, 3/2, 1/2) vs mass ify[i] = = 0: plt.scatter(X[i],y[i], c= ‚Äôred‚Äô,marker= ‚Äôx‚Äô,s=150) ify[i] = = 1: plt.scatter(X[i],y[i], c= ‚Äôblue‚Äô,marker= \""ÀÜ\"",s=150) 42ify[i] = = 3: plt.scatter(X[i],y[i], c= ‚Äôbrown‚Äô,m a r k e r= \"">\"",s=150) ify[i] = = 2: plt.scatter(X[i],y[i], c= ‚Äômagenta‚Äô ,m a r k e r = \""<\"",s=150) frommatplotlib.colors importListedColormap 46defplot_decision_regions(X, y, classifier , test_idx=None, resolution=0.01): markers = ( ‚Äôs‚Äô,‚Äôx‚Äô,‚Äôo‚Äô,‚ÄôÀÜ‚Äô,‚Äôv‚Äô) #M a r k e r sf o ra n dc o l o rm a p colors = ( ‚Äôbrown‚Äô,‚ÄôpeachPuff‚Äô ,‚Äôlightgreen‚Äô ,‚Äôgold‚Äô,‚Äôcyan‚Äô) cmap = ListedColormap(colors[:len(np.unique(y))]) 50x1_min, x1_max = X[: , 0].",3148
11.10 Code Listings,"min()‚àí1, X[:, 0]. max() + 1 x2_min, x2_max = X[: , 1]. min()‚àí1, X[:, 1]. max() + 1 xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution)) # Decision surface 54Z = classifier.predict(np.array([xx1.ravel() , xx2.ravel()]).T) Z = Z.reshape(xx1.shape) plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap) # Alpha : Transp plt.xlim(xx1. min() , xx1. max()) 58plt.ylim(xx2. min() , xx2. max()) foridx, cl inenumerate(np.unique(y)): plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],alpha=0.8,\ c=colors[idx], marker=markers[idx], label=cl,edgecolor= ‚Äôblack‚Äô) 62 iftest_idx: # Highlight test examples X_test, y_test = X[test_idx , :], y[test_idx] plt.scatter(X_test[:, 0], X_test[:, 1],edgecolor= ‚Äôblack‚Äô,\ alpha=1.0,linewidth=1, marker= ‚Äôo‚Äô,s=100, label= ‚Äôtest set‚Äô ) 66plt .show() Listing 11.6 Hubble.py AlinearfittoHubble‚ÄôsdatausingTensorFlow. # Hubble . py : Fit to Hubble dat , adapted from Campesato tensorflow 2 primer importtensorflow as tf importnumpy as np 4importmatplotlib.pyplot as plt r = tf.Variable([0.032,0.034,0.214,0.263, 0.275, 0.275, 0.45, 0.5, 0.5,\ 0.63,0.8,0.9,0.9,0.9,0.9, 1.0,1.1,1.1,1.4,1.7,2.0,2.0,2.0,2.0]) #R 8v = tf.Variable([170.,290., ‚àí130.,‚àí70.,‚àí185.,‚àí220.,200.,290.,270.,200.,300., ‚àí30.,650.,150.,500.,920.,450.,500.,500.,960. ,500.,850.,800.,1090.]) m= tf.Variable(0.) #I n i tm ,b ; y = m x + b b = tf.Variable(0. ) 12slope = 500. 11.10 Code Listings 251 bias = 0.0 step = 10 learning_rate = 0.02 16steps = 300 x_train = r print(x_train) y_train = slope ‚àóx_train + bias 20 defpredict_y_value(x): #y ( x ) y=m ‚àóx+b returny 24defsquared_error(y_pred, y_true): # Sum squared errors returntf.reduce_mean(tf.square(y_pred ‚àíy_true)) loss = squared_error(predict_y_value(x_train), y_train) 28foriin range (steps): with tf.GradientTape() as tape: predictions = predict_y_value(x_train) loss = squared_error(predictions , y_train) 32gradients = tape.gradient(loss , [m, b]) m.assign_sub(gradients[0] ‚àólearning_rate) b.assign_sub(gradients[1] ‚àólearning_rate) if(i  percent step) == 0: 36print(\""Step  percentd, Loss  percentf, m  percentf \""  percent (i, loss.numpy(),m)) y=m ‚àóx_train + b plt.xlabel( \""r Mpc\"") plt.ylabel( \""v km/s\"" ) 40plt.scatter(r, v) plt.plot(x_train, y) plt .show() Listing 11.7 PandaRead.py Atablereadwithpandas,andclusterIDwithkmeans. # PandaRead . py : Read table with pandas and use kmeans to find clusters importpandas as pd 4fromsklearn.cluster importKMeans importmatplotlib.pyplot as plt importnumpy as np parts = pd.read_table( \""C:\ElemnPart.dat\"" , delim_whitespace = True) 8data = parts.drop( \""Name\"",a x i s = 1 ) # Drop this column data.head() X = np.array(data[ \""Number\"" ]) # 1 st column y = np.array(data[ ‚ÄôMass‚Äô]) # 2nd column 12kmeans = KMeans(n_clusters = 3, random_state = 42) # R a n d o m init clusters kmeans. fit (data) # Computes clusters kmeans.predict(data) # Predict closest cluster kmeans.labels_ 16cc = kmeans.cluster_centers_ # Centroids print(cc) # Show centroids fig , ax = plt.subplots() plt.xlabel( \""N\"") 20plt.ylabel( \""Code\"") plt.scatter(X[:],y[:],c=kmeans.labels_, marker= \""ÀÜ\"") # Arrows plt.scatter(cc[:,0],cc[:,1],c= ‚Äôred‚Äô,m a r k e r = \""D\"") # Diamonds plt .show() Listing 11.8 SGDclass.py SupervisedMLclassificationviaastochasticgradientdescent algorithmfittotheLossfunction. # SGDclass.py: M L via Stochastic Gradient Descent 3fromsklearn.linear_model importSGDClassifier # StochGradDescent fromsklearn.inspection importDecisionBoundaryDisplay # Def region importpandas as pd # To read dataset 252 11 Neural Networks and Machine Learning importmatplotlib.pyplot as plt 7importnumpy as np  percentmatplotlib inline # Set matplot for notebook parts = pd.read_table( \""part.dat\"" ,delim_whitespace=True) #R e a dd a t a X = parts[ \""Mass\""] # X: masses 11y = parts[ ‚ÄôType‚Äô] # Types (integers) print(‚ÄôClass labels:‚Äô , np.unique(y)) # 4 classes d={ ‚Äôcol1‚Äô:x,‚Äôcol2‚Äô:y} # 2 column X, y array df = pd.DataFrame(d) # Form 2d DataFrame 15X = np.array(df) # DataFrame to numpy array idx = np.arange(X.shape[0]) #I n d e x0 ‚àí35 np.random.seed(13) np.random.shuffle(idx) # R a n d o m index shuffle 19X=X [i d x] #R a n d o mXo r d e r y=y [ i d x ] #R a n d o mYo r d e r colors = \""bryg\"" # 4 class colors mean = X.mean(axis=0) #C a l cm e a n 23std = X.std(axis=0) X=( X ‚àímean)/std #N o wm e a n=0 print(\""mean std\"" , mean,std) lrgd = SGDClassifier(alpha=0.001, max_iter=100).fit(X,y) 27print(lrgd) # Alpha: regularization strength ax = plt.gca() disp = DecisionBoundaryDisplay.from_estimator(lrgd,X, cmap = plt.cm.Paired, ax = ax, response_method = \""predict\"" ,x l a b e l= \""massMeV/c2\"" ,ylabel= \""Type\"") plt.axis( \""tight\"") 31print(\""lclasses\"" , lrgd.classes_) # 4 classes fori, color inzip(lrgd.classes_ , colors): # Plot training points idx = np.where(y == i) print(\""scatter\"" , X[idx,0], X[idx,1]) 35plt .",4837
11.10 Code Listings,"scatter(X[idx ,0] ,X[idx ,1] , c=color , cmap=plt .cm.Paired , edgecolor= \""black\"",s=20) plt.axis( \""tight\"") xmin, xmax = plt .xlim() 39ymin, ymax = plt .ylim() coef = lrgd.coef_ # Average weights for all steps intercept = lrgd.intercept_ 43defplot_hyperplane(c, color): defline(x0): return(‚àí(x0 ‚àócoef[c,0]) ‚àíintercept[c]) / coef[c,1], plt . plot([xmin, xmax], [line(xmin) , line(xmax)], 47 ls=\""--\"", color=color) print(lrgd.classes_) fori, color inzip(lrgd.classes_ , colors): #P l o tl i n e s print(i,color) 51plot_hyperplane(i, color) plt.legend() plt .show() Listing 11.9 Keras.py LinearfirtoHubbledatausingKeras. 1# Keras.py: Linear regression fit to Hubble data with Keras importmatplotlib.pyplot as plt importtensorflow as tf 5fromtensorflow importkeras fromkerasimportlayers fromkerasimportSequential fromkeras.layers importDense 9importnumpy as np #D a t a r = [0.032,0.034,0.214,0.263,.275,.275,.45,.5,.5,.63,.8,.9,.9,.9,.9, 1.0,1.1,1.1,1.4,1.7,2.0,2.0,2.0,2.0] # Distance Mparse 13v = [170.,290., ‚àí130.,‚àí70.,‚àí185.,‚àí220.,200.,290.,270.,200.,300., ‚àí30.,650.,150.,500.,920.,450.,500.,500.,960. ,500.,850.,800.,1090.] # Recession velocity k m/s # Create the model: Sequential() only 1 dense layer 17layer0 = tf.keras.layers.Dense(units=1,input_shape=[1]) 11.10 Code Listings 253 model = tf.keras.Sequential([layer0]) model.compile(loss= ‚Äômean_squared_error‚Äô , optimizer=tf.keras.optimizers.Adam(1)) 21history = model.fit(r,v,epochs=2000,verbose=0) plt.plot(history.history[ ‚Äôloss‚Äô]) plt.xlabel( \""Epochs number\"" ) plt.ylabel( \""Loss\"") 25plt .show() weights = layer0.get_weights() weight = weights[0][0] bias = weights[1] 29print(‚Äôweight: {} bias: {}‚Äô .format(weight, bias)) y_learned = r ‚àóweight + bias plt.scatter(r, v, c= ‚Äôblue‚Äô) plt.plot(r, y_learned,color= ‚Äôr‚Äô) 33plt .show() weights = layer0.get_weights() weight = weights[0][0] bias = weights[1] 37print(‚Äôweight: {} bias: {}‚Äô .format(weight, bias)) y_learned = r ‚àóweight + bias # Output: weight: [448.52048] bias : [ ‚àí34.726036] plt.scatter(r, v, c= ‚Äôblue‚Äô) 41plt.plot(r, y_learned,color= ‚Äôr‚Äô) plt .show()",2074
Chapter 12 Quantum Computing G. He Coauthor. 12.3.1 Physics Exercise Two Entangled Dipoles,"254 12 Quantum Computing (G. He, Coauthor) Although this is our most-recently added chapter, it is by no means the last word on Quantum Computing (QC). Seeing that QC employs its own version of Dirac notation, we start the chapter with the quantum-mechanical version of Dirac notation .1We then discuss the foun- dation of QC, namely, qubits, entanglement, and quantum gates. We introduce quantum programming and execution using the Google Cirq framework, and conclude by using the physical IBM Quantum Computer to solve some realistic problems. You may Ô¨Ånd that, much like in the early days of traditional computing, the ‚Äúprograms‚Äù for QC, using gates to process bits, are at a (painfully) low level. Further material on QC can be found in our sources [Hidary, 2021; Stolze and Suter, 2004; Nielsen and Chuang, 2010; IBMqc, 2023; Cirq, 2023] . Problem Develop several computer programs that use quantum mechanical states for storageofinformationandcomputation. 12.1 Dirac Notation in Quantum Mechanics Quantum computing (QC) uses a language based on Dirac‚Äôs quantum mechanical nota- tion.InDirac‚Äôsformalism,aquantumstateisrepresentedbya ket|ùúì‚ü©,whichisarayinan abstract,infinite,orfinite,dimensional,complexHilbertspace.(InQCwith nqubits,the dimensionwouldbe2n.)Thefamiliarwavefunction ùúì(x)istheconcrete,coordinate-space representationofthatabstractstate,andisobtainedfromitbytheinnerproduct: ùúì(x)=‚ü®x|ùúì‚ü©. (12.1) Here we have formed the product of the ket|ùúì‚ü©with thebra‚ü®x|,t of o r ma‚Äú b r a - k e t ‚Äù (bracket). In this view, the wave function ùúì(x), which is the probability amplitude of findingthestate |ùúì‚ü©atx,canbethoughtofastheprojectionof |ùúì‚ü©ontothexbasisvectors. 1 Formoreofareview,Section7.6usesspinstatesandmatrixoperatorstocalculatethehyperfine structureofhydrogen. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 12.2 From Bits to Qubits 255 TheDiracformalismalsoincludesa dualadjoint orcovectorspaceinwhichthestate |ùúì‚ü© isrepresentedbythebra ‚ü®ùúì|.The1:1correspondencebetweenketsandbrasisexpressed withtheadjointoperation ‚ü®ùúì|=|ùúì‚ü©‚Ä†. (12.2) Thescalarorinnerproduct ofthetwostates |ùúô‚ü©and|ùúì‚ü©isgivenbythebracket ‚ü®ùúô|ùúì‚ü©‚â°(ùúô,ùúì)=‚ü®ùúì|ùúô‚ü©‚àó. (12.3) Incontrast,thejuxtaposition O=|ùúô‚ü©‚ü®ùúì|isanoperator,andnotasimplescalarproduct, sinceitchangesonestateintoanother: O|ùúì‚ü©=|ùúô‚ü©=|Oùúì‚ü©. (12.4) Hereweuse Otodenoteanoperator,assume ùúì‚ü©isnormalized,andnotethatoperatorsare oftenrepresentedasmatrices,andthat,ingeneral, O|ùúì‚ü©isnotproportionalto |ùúì‚ü©. IfwewanttobeconsistentwithDiracnotation,thenadescriptionofstatesasvectorsin aspin1/2space Swouldexpressthestatesas ‚ü®S|ùúì‚ü©.Incommonpracticethebra ‚ü®S|isleft off,andtheupanddownspin1/2statesarewrittenas ùúì+=|||+1 2‚ü© =[1 0] ‚â°|0‚ü©, (12.5) ùúì‚àí=|||‚àí1 2‚ü© =[0 1] ‚â°|1‚ü©, (12.6) where |0‚ü©and|1‚ü©arethesymbolsusedinQC(presumablyasananalogytothetraditional bits 0 and1 beingrepresented as spin up andspin down). Likewise,operatorslike Oare representedby2 √ó2matrices,forexamplebythe directproduct : |||1 2‚ü©‚ü® 1 2|||=[1 0][ 10]=[10 00] .",3042
Chapter 12 Quantum Computing G. He Coauthor. 12.3.1 Physics Exercise Two Entangled Dipoles,"(12.7) 12.2 From Bits to Qubits Quantumcomputing(QC)isbasedonstoringinformationinquantummechanicalstates, andthenmanipulatingthesestatestoperformnumericaloperations.Thisisfundamentally differentfrom,andpotentiallymorepowerfulthan,thetraditionalapproachtocomputing, andmaybeespeciallyapplicableinareassuchascryptographyandsimulationofquantum systems. Inthetraditionalapproachtoacomputer‚Äôsmemory,informationisstoredusinganumber system based on the binary integers ( bits) 0 and 1. [Originally, a 0 was stored in a mag- neticcorepointingup,anda1inacorepointingdown,likethequbitsin(12.5).]Allthe rest of what gets stored consists of arrays of these bits. In the (simplest) quantum com- putermemorysystem,informationisstoredinstatesthatarecombinationsofelementary spin-like states, called quantum bits orqubits. Although it would be a major advance in miniaturizationiftheenergylevelsofneutralatomswereusedforqubits,inpracticethe storageuseselectronicdevices,suchassuperconductingACJosephsonjunctions. ThesmallestunitofinformationinQCisthequantumbitor qubit.Asinglequbitstorage unit is expressed in terms ofthe same bases vectorsused for ‚Äúspin-up‚Äù and ‚Äúspin-down‚Äù 256 12 Quantum Computing (G. He, Coauthor) z|0> |0> ‚Äì |1> y x2 |1>œÜŒ∏œà |0> + i|1> 2|0> ‚Äì i|1> 2 |0> + |1> 2Figure 12.1 The Bloch sphere, a geometric representation of a two-level quantum system (modiÔ¨Åed www.pngwing.com). quantumstates,butwiththenameschangedto0and1: |0‚ü©def=|||+1 2‚ü© =[1 0] , |1‚ü©def=|||‚àí1 2‚ü© =[0 1] . (12.8) Aqubitisdefinedasalinearcombinationofthesetwobasisstates: |ùúì‚ü©=u|0‚ü©+ùë£|1‚ü©‚â°[u ùë£] . (12.9) Hereuandùë£complexnumberssatisfyingthenormalizationcondition: |u|2+|ùë£|2=1. (12.10) Although probability conservation is important in quantum mechanics, the normaliza- tionofstatesisoftenjustanarbitraryoverallconstantappliedtothewavefunction,when needed.InQC,however,statesareuniformlyassumedtobenormalized. AsillustratedinFigure12.1,becausethestate |ùúì‚ü©isarayinanabstractvectorspace,it canhaveaconcreterepresentationasthedirectionofarayona Blochsphere withthepolar anglerepresentation: |ùúì‚ü©=cosùúÉ 2|0‚ü©+eiùúôsinùúÉ 2|1‚ü©,ùúÉ‚àà[0,ùúã],ùúô‚àà[0,2ùúã). (12.11) Accordingly,apure |0‚ü©state(ùúÉ=0)liesonthe +zaxis,andapure |1‚ü©stateliesalongthe ‚àízaxis(ùúÉ=ùúã),withcomplexcombinationsofthetwolyingsomeplaceonthesurfaceof thesphere. 12.2.1 Multiple Qubit States Consider a state ||ùúìA‚ü©within the Hilbert space HA, and a separate state ||ùúìB‚ü©within the Hilbertspace HB.Ifwewishtocombinethesetwoketsintoasinglestate,thenthecomposite wouldexistwithinanexpandedHilbertspacecreatedbythetensorproductof HAandHB, withthestatevectoralsoadirectproduct: HAB=HA‚äóHB, (12.12) ‚áí||ùúìAB‚ü©=||ùúìA‚ü©‚äó||ùúìB‚ü©, (12.13) where[a b] ‚äó[c d] def=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ac ad bc bd‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.14) 12.3 Entangled and Separable States 257 Asanexplicitexample,ifwestartwiththestates ||ùúìA‚ü©=u1|0‚ü©+ùë£1|1‚ü©, ||ùúìB‚ü©=u2|0‚ü©+ùë£2|1‚ü©,then (12.15) ||ùúìA‚ü©‚äó||ùúìB‚ü©‚â°||ùúìA‚ü©||ùúìB‚ü©=(u1|0‚ü©+ùë£1|1‚ü©)(u2|0‚ü©+ùë£2|1‚ü©)(12.16) =u1u2|00‚ü©+u1ùë£2|01‚ü©+ùë£1u2|10‚ü©+ùë£1ùë£2|11‚ü©, (12.17) where |00‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 0 0 0‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶,|01‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 1 0 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶,|10‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 1 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶,|11‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶.",3063
Chapter 12 Quantum Computing G. He Coauthor. 12.3.1 Physics Exercise Two Entangled Dipoles,"(12.18) The4-Dvectorsin(12.18)aretheappropriatebasisvectorsforatwo-qubitsystem. 12.3 Entangled and Separable States Statesformedwithadirectproduct,suchasin(12.16),arecalled separable.Forexample, a qubit in a |0‚ü©state and a different qubit also in a |0‚ü©state form the separable state ||0A‚ü©‚äó||0B‚ü©, which is usually written as just |00‚ü©. Yet qubits do not live on isolated qubit islands, so they can interact with each other. If two interacting systems are otherwise isolated,but cannotbe expressed asthe directproductof the two states,these qubits are entangled.Ifthetwosystemsarenotentangled,thentheyare separable. Entanglementmayleadtosomeprofoundconsequences.Forexample,thespin-upstate |0‚ü©andthespin-downstate |1‚ü©canbephysicallyfarfromeachother,yetstillbeentangled. Thismeansthattheupstatecannotbedescribedasjustasingleparticlestate,butmustbe describedaspartofthefullstatevectorincludingthedownstate,whereveritmaybe.Soif thetotalstatehasspinzero,andoneparticleisspinup,thentheotherparticle,eveniffar away,mustbecorrelatedandmusthavespindown.Justhowthetwoparticlescommunicate witheachotherquantummechanicallyatamacroscopicdistancesisasubjectofcurrent discussionanddebate(andthe2022NobelPrize). Let‚Äôs be more explicit about this entanglement concept. Here are two states in the 2D Hilbertspaceofcomplexnumbers ‚ÑÇ2, ||ùúìA‚ü©=[a b] , ||ùúìB‚ü©=[c d] . (12.19) Thetensorordirectproduct ofthesestatesis |Œ®‚ü©def=||ùúìA‚ü©‚äó||ùúìB‚ü©=[a b] ‚äó[c d] =‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ac ad bc bd‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.20) Thisproductstateisinthe4-DHilbertspaceofcomplexnumbers ‚ÑÇ4: |ùúì‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùë§ x y z‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.21) 258 12 Quantum Computing (G. He, Coauthor) Thestateisseparable,if,andonlyif ,ùë§z=xy.Fortheproductstatein(12.20),separability thusrequires acbd=adbc;whichisinfactthecase,andso(12.20)isseparable.Afamous exampleofentanglementisthetwo-qubit BellStates: ||ùõΩ00‚ü©=1‚àö 2(|00‚ü©+|11‚ü©), ||ùõΩ01‚ü©=1‚àö 2(|01‚ü©+|10‚ü©), (12.22) ||ùõΩ10‚ü©=1‚àö 2(|00‚ü©‚àí|11‚ü©), ||ùõΩ11‚ü©=1‚àö 2(|01‚ü©‚àí|10‚ü©). (12.23) Usethedefinitionofseparabilityandthebasisvectors(12.18)toprovethattheBellstates areentangled. Apowerfulwaytodescribethequantumstateofasystemisintermsofthe densitymatrix ùúå.Itcanbeusedtocalculateobservableswithoutresortingtowavefunctions,andispartic- ularlyusefulwhendealingwithanensembleofpurestates.Thedensitymatrixoroperator isdefinedas ùúå=‚àë ipi||ùúìi‚ü©‚ü®ùúìi||. (12.24) Herepiistheprobabilityofthepurestate ||ùúìi‚ü©beingpresentintheensemble,and,justto remindyou,theproductofakettimesabraisanoperator.Asystemconsistingofjusta purestatewouldhave pi=1. 12.3.1 Physics Exercise: Two Entangled Dipoles Twointeractingmagneticdipoles ùùàAandùùàB,separatedbyadistance r,havetheinteraction Hamiltonian: H=ùúá2 r3(ùùàA‚ãÖùùàB‚àí3ùùàA‚ãÖÃÇrùùàB‚ãÖÃÇr), (12.25) ùùàA=XAÃÇi+YAÃÇj+ZAÃÇk,ùùàB=XBÃÇi+YBÃÇj+ZBÃÇk. (12.26) Hereweemploy QC notation thatlabelsthePaulimatricesas X,Y,andZ: Xdef=ùúéx=[01 10] ,Ydef=ùúéy=[0‚àíi i0] ,Zdef=ùúéz=[10 0‚àí1] . (12.27) AndinyetmoreQCnotation,thetwodipolescanbeinthefour,directproductstates: ||0A0B‚ü©=|0A‚ü©|0B‚ü©, |0A1B‚ü©=|0A‚ü©|1B‚ü©, (12.28) |1A0B‚ü©=|1A‚ü©|0B‚ü©, |1A1B‚ü©=|1A‚ü©|1B‚ü©. (12.29) As discussed in Section 12.1, the Pauli 4 √ó4 matrices (12.27) are operators that transform states.Asweshallsee,inQCtheyrepresentBoolean logicgateswiththeproperties: X|0‚ü©=|1‚ü©,X|1‚ü©=+|0‚ü©,Y|0‚ü©=i|1‚ü©,Y|1‚ü©=‚àíi|0‚ü©, (12.30) Z|0‚ü©=|0‚ü©,Z|1‚ü©=‚àí|1‚ü©. (12.31) 12.3 Entangled and Separable States 259 Exercises 1) Showthatthesedirectproductstatesformabasisfor ‚ÑÇ4: |00‚ü©=[1 0] ‚äó[1 0] ,|01‚ü©=[1 0] ‚äó[0 1] , (12.32) |10‚ü©=[0 1] ‚äó[1 0] ,|11‚ü©=[0 1] ‚äó[0 1] . (12.33) Hint: |11‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.34) 2) Consider PandQastheoperatorsinseparateHilbertspaces, P=[p11p12 p21p22] ,Q=[q11q12 q21q22] . (12.35) Showthattheirdirectproductis P‚äóQ=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£p11q11p11q12p12q11p12q12 p11q21p11q22p12q21p12q22 p21q11p21q12p22q11p22q12 p21q21p21q22p22q21p22q22‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.36) 3) Showthatfor ÃÇr=ÃÇk,theHamiltonian(12.25)indirectproductspaceis H=ùúá2 r3(XA‚äóXB+YA‚äóYB+ZA‚äóZB‚àí3ZA‚äóZB). (12.37) 4) Showthatthedirectproduct: XA‚äóXB=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0001 0010 0100 1000‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.38) 5) Evaluatethedirectproducts YA‚äóYBandZA‚äóZBas4√ó4matrices,andtherebyshow thattheHamiltonianinthedirectproductspaceis: H=ùúá2 r3‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£‚àí200 0 022 0 022 0 000‚àí2‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.39) 6) Usealinearalgebrapackagetoshowthattheeigenvaluesof H‚àï(ùúá2‚àïr3)are4,0,‚àí2,and ‚àí2,andthatthecorrespondingeigenvectorsare: ùúô1=1‚àö 2‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 +1 +1 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=|01‚ü©+|10‚ü© ‚àö 2,ùúô2=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=|11‚ü©, (12.40)",4306
12.4.4 3Qubit Gates,"260 12 Quantum Computing (G. He, Coauthor) ùúô4=1‚àö 2‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 1 ‚àí1 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=|01‚ü©‚àí|10‚ü© ‚àö 2,ùúô3=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 0 0 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=|00‚ü©. (12.41) 7) Recallthediscussionofentanglement.Ofthefoureigenstatesjustobtained,determine whichonesareseparableandwhichonesareentangled. 8) UsetheseeigenvectorsstatesasbasisstatestoevaluatetheHamiltonianmatrix: H=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£‚ü®ùúô1|H|ùúô1‚ü©‚ü®ùúô1|H|ùúô2‚ü©‚ü®ùúô1|H|ùúô3‚ü©‚ü®ùúô1|H|ùúô4‚ü© ‚ü®ùúô2|H|ùúô1‚ü©‚ü®ùúô2|H|ùúô2‚ü©‚ü®ùúô2|H|ùúô3‚ü©‚ü®ùúô2|H|ùúô4‚ü© ‚ü®ùúô3|H|ùúô1‚ü©‚ü®ùúô3|H|ùúô2‚ü©‚ü®ùúô3|H|ùúô3‚ü©‚ü®ùúô3|H|ùúô4‚ü© ‚ü®ùúô4|H|ùúô1‚ü©‚ü®ùúô4|H|ùúô2‚ü©‚ü®ùúô4|H|ùúô3‚ü©‚ü®ùúô4|H|ùúô4‚ü©‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.42) Ifyouhavedonethiscorrectly,theHamiltonianshouldnowbediagonalwiththeeigen- valuesasthediagonalelements. InListing12.1,wepresenttheprogram Entangle.py thatperformsthenecessarylinearalge- brausingthe numpypackage.Itproducestheresults: Hamiltonian without mu^2/r^3 factor [[‚àí2000 ] [ 0220 ] 4[ 0220 ] [ 000 ‚àí2]] Eigenvalues [ 4.0000000e+00 4.4408921e ‚àí16‚àí2.0000000e+00 ‚àí2.0000000e+00] 8Eigenvectors(incolumns) [[ 0. 0. 1. 0. ] [ 0.70710678 0.70710678 0. 0. ] [ 0.70710678 ‚àí0.70710678 0. 0. ] 12[ 0. 0. 0. 1. ]] Hamiltonian inEigenvector Basis [[ 4.00000000e+00 0.00000000e+00 0.00000000e+00 6.66133815e ‚àí16] [ 0.00000000e+00 ‚àí2.00000000e+00 0.00000000e+00 0.00000000e+00] 16[ 0.00000000e+00 0.00000000e+00 ‚àí2.00000000e+00 0.00000000e+00] [ 6.28036983e ‚àí16 0.00000000e+00 0.00000000e+00 9.86076132e ‚àí32]] 12.4 Logic Gates Recallthattraditionalcomputersuseelectroniccircuitscalled logicgatestoperformbasic, logical operations on bits. More complex operations are created by combining multiple gates.Therearesixbasiclogicgates: AND,NAND,NOT,OR,NOR,XOR(exclusive OR). Forexample,herearethesymbolsthatrepresentthe ANDandXORgates,aswellasthe truth tablesthatdefinetheiroutputsaccordingtotheirinputs: Axx A 0 0 1 100 0 0 11 0 1AND Bx A 0 0 1 100 1 1 01 0 1XOR B BAx B 12.4 Logic Gates 261 Asaninstanceofhowthesegatescanbecombined,hereweconstructa half-adder from XORandANDgates: A A + BBXOR SUM CARRY ANDA CARRY 0 0 1 10 1 1 00 0 0 10 1 1B Thehalf-adderaddstwobits,andiftheanswerisgreaterthan1,itcarriesoverabittoa highermemoryposition. 12.4.1 1-Qubit Gates Insimilaritywithclassicalcomputers,quantumcomputersemploy quantumlogicgates to performelementaryoperationsonqubits.ThesegatesarerepresentedinHilbertspaceas unitaryoperators ,U||ùúìin‚ü©=||ùúìout‚ü©,whichmeanstheypreserveprobability.Thesearethe gates: State gate U:  U ‚îÇœàout‚îÇœàin Determinesthestateofaket. Pauli matrix gates: Ouroldfriendsthe Paulispinmatrices givenin(12.27)areusedasQC gates,wheretheyarerenamedas X=ùúéx,Y=ùúéy,andZ=ùúéz. NOTgate X:Thequantum NOTgateflips |0‚ü©(formerlyspinup)to |1‚ü©(formerlyspindown), andviseversa.Usedasagate,thePaulimatrix Xactsasthe NOToperator NOT, changingonestateintoanother: Xdef=ùúéx=|0‚ü©‚ü®1|+|1‚ü©‚ü®0|=[01 10] , (12.43) ‚áíX|0‚ü©=|1‚ü©,X|1‚ü©=|0‚ü©. (12.44) Yg a t e :ThePaulimatrix ùúéyactsastheYgate: Ydef=ùúéy=i(|1‚ü©‚ü®0|‚àí|0‚ü©‚ü®1|) =[0‚àíi i0] . (12.45) Zg a t e :ThePaulimatrix ùúézactsastheZgate.Itflipsthesignofthe |1‚ü©state,butleavesthe |0‚ü©stateunchanged: Zdef=ùúéz=|0‚ü©‚ü®0|‚àí|1‚ü©‚ü®1|=[10 0‚àí1] , (12.46) Z|z‚ü©=( ‚àí1)z|z‚ü©. (12.47) Aswiththequantumspin,thestates |0‚ü©and|1‚ü©aretheeigenstatesof Z. Hadamard gate H:convertsqubitsthatareeigenstatesof Ztoonesthatareeigenstates ofX: H|0‚ü©=1‚àö 2(|0‚ü©+|1‚ü©)‚â°|+‚ü©,H|1‚ü©=1‚àö 2(|0‚ü©‚àí|1‚ü©)‚â°|‚àí‚ü©, (12.48) H= (|+‚ü©‚ü®0|+|‚àí‚ü©‚ü®1|) =1‚àö 2[11 1‚àí1] . (12.49) 262 12 Quantum Computing (G. He, Coauthor) TheHgatealsocreatesequalmixturesofthe |0‚ü©and|1‚ü©basisstates,andthusisuseful intransformingclusteredqubitsintostateswithuniformsuperpositions: H|0‚ü©=1‚àö 2(|0‚ü©+|1‚ü©),H|1‚ü©=1‚àö 2(|0‚ü©‚àí|1‚ü©). (12.50) Rùùã:  RœÜ:alsocalledthe Porphasegate,rotates |1‚ü©byanangle ùúëaboutthe z-axis,whileleaving |0‚ü©untouched: Rùúë|0‚ü©=|0‚ü©,Rùúë|1‚ü©=eiùúë|1‚ü©,Rùúë=[10 0eiùúë] . (12.51) Sa n dTg a t e s : Arespecialcasesofthe Rùúëgate.Srotatesaketby ùúë=ùúã‚àï2(eiùúë=i),andT byùúô=ùúã‚àï4: S S0‚ü©=0‚ü©, S1‚ü©=i1‚ü©, (12.52) T T0‚ü©=0‚ü©, T1‚ü©=eiœÄ ‚ÅÑ 41‚ü©, (12.53) T=[10 0e x p(iùúã‚àï4)] ,S=T2=[10 0i] . (12.54) Rx,Ry,Rz:These gates perform a general rotation of qubits on the Bloch sphere by the angleùõºaroundthe x,y,orzaxes,respectively: Rx(ùõº)=e‚àíiùõºùúéx‚àï2,Ry(ùõº)=e‚àíiùõºùúéy‚àï2,Rz(ùõº)=e‚àíiùõºùúéz‚àï2. (12.55) Measurement operation:  ‚îÇœà While not a gate because it‚Äôs not unitary, theclassicalmeasurementofaquantumstateisanoft-usedoperation. Exercise UsetheBlochsphereofFigure12.1andequation(12.11)todetermine: ‚óèWhatgatetransforms |0‚ü©to(|0‚ü©+|1‚ü©)‚àï‚àö 2? ‚óèWhatgaterotates (|0‚ü©+|1‚ü©)‚àï‚àö 2byùúã‚àï2into(|0‚ü©+i|1‚ü©)‚àï‚àö 2? ‚óèWhatgaterotates |0‚ü©byùúãinto|1‚ü©? 12.4.2 2-Qubit Gates CZ (alt) ZCZ CNOT SWAP Thereisawholesetoftwo-qubitgateswiththepropertythattheircombinedactionscan approximatea4 √ó4unitarymatrixtoarbitraryprecision.InadditiontotheHadamardgate, alreadydefinedforone-qubituse,two-qubitgatesinclude SWAP,CNOT,andCZ: SWAP:Transforms |01‚ü©to|10‚ü©,thatis,itswapsthetwokets: SWAP |01‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1000 0010 0100 0001‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 1 0 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 1 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=|10‚ü©. (12.56) Inturn,SWAPtransforms |10‚ü©to|01‚ü©. 12.4 Logic Gates 263 Controlled gates: Controlledgatesacton2-qubitstates |c‚ü© |t‚ü©,where |c‚ü©isthecontrolbit and|t‚ü©isthetarget.Ifa1qubitgate Uisusedina2qubitcontrolledgatecombination CU,ithasthefollowingeffect: CU|c‚ü© |t‚ü©=|c‚ü©Uc|t‚ü©, (12.57) whereUcisaversionof Umodifiedbythecontrol. Controlled NOT,CNOT: usesonequbittocontrolitsactiononthetargetqubit.Ifthe controlqubitis0,thenthetargetisunchanged;ifthecontrolqubitis1,thenthe target qubitisflipped.Withtheleftqubitascontrol: CNOT(x,y)={ (x,y)if x=0 (x,1‚àíy)if x=1,(12.58) CNOT |10‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1000 0100 0001 0010‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 1 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=|11‚ü©. (12.59) Controlled Z, CZ: ThecontrolledZgatereversesthesignofthe |11‚ü©qubit: CZ|00‚ü©=|00‚ü©,CZ|01‚ü©=|01‚ü©,CZ|10‚ü©=|10‚ü©,CZ|11‚ü©=‚àí|11‚ü©,(12.60) CZ=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£100 0 010 0 001 0 000‚àí1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.61) Exercise DeterminetheeffectoftheCNOTgateon: |10‚ü©,|01‚ü©,|00‚ü©,and|11‚ü©. Exercise Verifytheaboveeffectsofthe CZgate. 12.4.3 Entanglement via Gates The entangled Bell states (12.22) can be created with the aforementioned gates. For example,Figure12.2showsaquantumcircuitcreatingtheBellstate ||ùõΩ00‚ü©byemploying anH(Hadamard)gatefollowedbya CNOTgate.Herewestartwiththetwoqubitstate |00‚ü©, and useHon the first qubit, leaving the second qubit unchanged. Then the CNOTgate, whichusesthefirstqubitforcontrol,andthesecondasthetarget: (1)H|0‚ü© |0‚ü©=1‚àö 2(|0‚ü©+|1‚ü©)|0‚ü©, (12.62) (2)CX1‚àö 2(|0‚ü©+|1‚ü©)|0‚ü©=1‚àö 2(|0‚ü© |0‚ü©+|1‚ü© |1‚ü©). (12.63) Figure 12.2 A quantum circuit for creating an entangled state ||ùõΩ00‚ü©. H ‚à£0‚å™ ‚à£0‚å™",6291
12.5 An Intro to QC Programming,"264 12 Quantum Computing (G. He, Coauthor) 12.4.4 3-Qubit Gates Three-qubitstatesusebasisvectorscreatedbythedirectproductsofthreekets: |ijk‚ü©=|i‚ü© |j‚ü© |k‚ü©‚â°|i‚ü©‚äó|j‚ü©‚äó|k‚ü©. (12.64) Thereare,accordingly,eightsuchstates, |000‚ü©,|001‚ü©,|010‚ü©,|011‚ü©,|100‚ü©,|101‚ü©,|110‚ü©, |111‚ü©.Forexample, |111‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 0 0 0 0 1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶,|110‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 0 0 0 1 0‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (12.65) Thismeansthatthethree-qubitgatesthatoperateonthese8-Dbasisvectorsarerepresented by8√ó8matrices. TOFFOLI ,CCNOT GATE : isanextensionofthe CNOTgatethatflipsthethirdqubit,ifand onlyifthetwofirsttwoqubitsareinthe |011‚ü©state: T|110‚ü©=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£10000000 01000000 00100000 00010000 00001000 00000100 00000001 00000010‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 0 0 0 1 0‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 0 0 0 0 0 0 1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶=|111‚ü© (12.66) 12.5 An Intro to QC Programming Now that we have the building blocks for QC, namely, qubits and gates, it‚Äôs time to put themtogetherintoprograms,aka circuits.WestartbyusingGoogle‚Äôs2018releaseof Cirq,a ‚ÄúPythonsoftwarelibraryforwriting,manipulatingandoptimizingquantumcircuits,then running them on quantum computers and quantum simulators‚Äù [Cirq, 2023]. After the simpleexamplesinthissectionimplementingthevariousgates,wewillusethepowerful IBMQuantumComputer forsomemoreadvancedprogrammingandrunningonaphysical quantumcomputer. ToinstallCirqusingAnaconda,werecommendusingthe packagemanagerconda ,which helps to install all the associated bits and pieces of packages. To do that, use a shell (the Commandshellor PowerShell onWindows,orthe TerminalonMacs)andissuethecom- mand: conda install -c psi4 cirq 12.5 An Intro to QC Programming 265 Alternatively,youcanuse piptoinstallcirq: python -m pip install -upgrade, pip python -m pip install cirq ‚óèHadamard gate: Recall,anHgateconvertseigenstatesof Ztoeigenstatesof X.Enterandrunyourfirst CirqprogramtocreateanHgatethatoperateson |0‚ü©: # Hadamard . py : Cirq program to create H gate 3importcirq # Import Cirq circuit = cirq.Circuit() # Build circuit qubit = cirq.GridQubit(0,0) # Create qubit at (0 ,0) 7circuit.append(cirq.H(qubit)) # Append Hadamard gate s = cirq.Simulator() # Initialize simulator print(‚ÄôSimulate the circuit:‚Äô ) print(circuit) # Output circuit 11results = s.simulate(circuit) # Run simulator print(results) # Output resulting kets Cirque ‚Äôs Output ---------------------------------- Simulate the circuit: 15(0,0): __________H__________ output vector: 0.707 |0> + 0.707|1> Notonlywasthatprettyeasy,butitalsogavethecorrectanswer: H|0‚ü©=1‚àö 2[11 1‚àí1][1 0] =1‚àö 2[1 1] ‚â°0.707[1 0] +0.707[0 1] . (12.67) ‚óèTwo Hadamard gates: The application of two H gates to a state should act as the identity operator. Extend the previous program to append a second Hadamard gate, now using the command a = cirq.QubitNamed(\""a\"") todefineaqubit: # TwoHgates.py: Cirq program to create 2 H gates on one line importcirq 4 circuit = cirq.Circuit() # Build circuit a = cirq.NamedQubit( ‚Äôa‚Äô) # Define named qubit circuit.append(cirq.H(a)) # Append H gate to a 8circuit.append(cirq.H(a)) # Append another H gate to a s = cirq.Simulator() # Initialize simulator print(‚ÄôSimulate the circuit:‚Äô ) print(circuit) # Output circuit 12results = s.simulate(circuit) # Run simulator print(results) # Output resulting kets Cirque ‚Äôs Output--------------------- Simulate the circuit: 16 a: _______ H________ H_______ output vector: |0> Exercise Usetheoutputof Hadamard.py tocheckthat TwoHgates.py actsastheidentity operator. ‚óèXa n dHg a t e s : WriteaprogramthatusesanXgatetoconvert |0‚ü©to|1‚ü©,andthenanHgatetocreatean eigenstateofX: 266 12 Quantum Computing (G. He, Coauthor) 00100200300Result count400500 1 Qubit state Figure 12.3 Histogram of the state formed by application of X, Z, and H gates. (If there was no noise, the heights would be equal.) # XplusH.py: Cirque program , setup X & H gates and |1> 3importcirq circuit = cirq.Circuit() # Build circuit a = cirq.NamedQubit( ‚Äôa‚Äô) # Define qubit 7circuit.append(cirq.X(a)) # Append X (NOT) gate circuit.append(cirq.H(a)) # Append H gate s = cirq.Simulator() # Initialize simulator print(‚ÄôSimulate the circuit:‚Äô ) 11print(circuit) results = s.simulate(circuit) # Run simulator print(results) ‚àí‚àí‚àí‚àí‚àí‚àí‚àíCirque Output ‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí‚àí 15Simulate the circuit:use a:_______X_____H______ output vector: 0.707|0> ‚àí0.707|1> Exercise VerifythattheoutputisaneigenstateofX. ‚óèX, Z, and H Gates and M Op: Ameasurement operatoractingonaquantumstateprovidesaclassicaloutputoftheprob- abilitydistributionofa particularmeasurement. (Recall,‚Äúgates‚Äù areunitaryoperators, while measurement operatorsare not unitary, and thus not gates.) Extend your circuit toincludeH,X,andZgates,aswellasameasurementoperatorontheresult.Runthe simulation1000timesinordertoaccumulatesomestatistics.BecauseCirqrunswithin Python,it‚ÄôseasytouseMatplotlibtoproducethevisualizationofprobabilitydistribution, aswehavedoneinFigure12.3. # X Z H M. py : Cirq Simulation with H, X, Z Gates + Measurement Op 3importcirq importmatplotlib.pyplot as plt circuit = cirq.Circuit() # Build circuit 7a = cirq.NamedQubit( ‚Äôa‚Äô) # Create qubit circuit.append(cirq.X(a)) # Append X gate circuit.append(cirq.Z(a)) # Append Z gate circuit.append(cirq.H(a)) # Append H gate 11s = cirq.Simulator() # Initialize simulator 12.5 An Intro to QC Programming 267 print(‚ÄôSimulate the circuit:‚Äô ) results = s.simulate(circuit) # Run simulator circuit.append(cirq.measure(a, key = ‚Äôresult‚Äô )) 15samples = s.run(circuit ,repetitions =1000) print(circuit) print(resultsC print(samples) 19cirq.plot_state_histogram(samples) plt .show() Cirq Output Simulate the circuit: 23a: ______X_______Z______H_______M____________ output vector: ‚àí0.707|0> + 0.707|1> result=1001110001001101001110111000100001.... Exercise DeducewhatshouldbetheeffectofsuccessiveX,Z,andHgates,andcompare withtheaboveoutput. Exercise MakesenseoftheMoperator‚Äôsoutput: result=1001110001001101001110111000100001 . . . . . ‚óèA 2-qubit Cirq circuit: Cirq contains the command q0, q1 = cirq.LineQubit.range(2) that creates a two- qubitcircuit. Exercise 1) UseCirqtocreatethecircuit: q0 q1 Z 2) Runthecircuitandverifythatitsoutputis |10‚ü©. 3) Explainwhythisistheexpectedoutput. 4) Recall the SWAP gate (a vertical line connecting qubits) that swaps one qubit with another.Extendyourprogramtoincludea SWAPgatebetweenq0andq1: q0 q1 Z Ourprogram CirqSwap.py createdthiscircuit: # CirqSwap.py: Cirq program to create & swap 2 qubits 3importcirq circuit = cirq.Circuit() q0, q1 = cirq.LineQubit. range(2) # Create two qubits 7circuit.append(cirq.X(q0)) # Append X to q0 circuit.append(cirq.Z(q1)) # Append Z to q1 circuit.append(cirq.SWAP(q0,q1)) # Swap qubits print(circuit) 11s = cirq.Simulator() # Initialize simulator print(‚ÄôSimulate the circuit:‚Äô ) results = s.simulate(circuit) # Run simulator print(results) 15 Cirque Output Simulate the circuit: output vector: |01> 268 12 Quantum Computing (G. He, Coauthor) ‚óèCNOT on 2 qubits: CNOT(q0,q1)={ (q0,q1)ifq0=0, (q0,1‚àíq1)ifq0=1.(12.68) # CirqCNOT . py : Cirq program with CNOT gate 3importcirq circuit = cirq.Circuit() q0, q1 = cirq.LineQubit. range(2) # Create two qubits 7circuit.append(cirq.X(q0)) # Append X to q0 circuit.append(cirq.Z(q1)) # Append Z to q1 circuit.append(cirq.CNOT(q0, q1)) # Append CNOT, q0 = control print(circuit) 11s = cirq.Simulator() # Initialize Simulator print(‚ÄôSimulate the circuit:‚Äô ) results = s.simulate(circuit) # Run simulator print(results) 15 Output Simulate the circuit: measurements: (no measurements) output vector: |11 > q0 q1 Z Exercise Deducewhatshouldbetheeffectof CNOTonthequbits,andcomparewith theoutput. Exercise A d daS W A Pg a t eb e f o r e CNOT, and see if the output agrees with what you wouldexpect. ‚óè3-Qubit T OFFOLI gate: Create a circuit that implements the T OFFOLI/CCNOT(controlled-controlled-not) gate. It shouldtakethreebitsasinput,andinvertthethirdbitiffthefirsttwobitsare1‚Äôs: q0 q1 q2 Z 1# CirToffoli .py: Cirq program with 3 qubit C C N O T gate importcirq 5q0, q1, q2 = cirq.LineQubit. range(3) # Create 3 qubits circuit = cirq.Circuit() # Build circuit circuit.append(cirq.X(q0)) # Append X to q0 circuit.append(cirq.Z(q2)) # Append Z to q2 9circuit.append(cirq.Toffoli (q0, q1,q2)) # Connect all 3 wi Toffoli print(circuit) # Output circuit s = cirq.Simulator() # Initialize Simulator print(‚ÄôSimulate the circuit:‚Äô ) results = s.simulate(circuit) # Run simulator 13print(results) Output Simulate the circuit: output vector: |101>",8491
12.6 Accessing the IBM Quantum Computer,"12.5 An Intro to QC Programming 269 Exercise Try all possible values for q0 and q2, and compare the output with the expected CCNOTeffect. 12.5.1 Half and Full Adders ‚óèHalf adder: Ahalf-adderaddsthequbits,q0andq1,andoutputsthesum.Italsooutputsacarrybit q2=1,ifq0=q1=1,elseq2 =0.Createahalf-addercircuitusingthreequbitsanda TOFFOLIgatefollowedbya CNOTgate: # CirqHalfAdder.py: Cirq circuit for half adder importcirq 4 q0, q1, q2 = cirq.LineQubit. range(3) # Create 3 qubits circuit = cirq.Circuit() # Build circuit circuit.append(cirq.X(q0)) # Append X to q0 8circuit.append(cirq.X(q1)) # Append X to q1 circuit.append(cirq.Toffoli(q0, q1,q2)) # Append T o f f o li to 3 qs circuit.append(cirq.CNOT(q0, q1)) # Append CNOT to q0 & q1 print(circuit) # Output circuit 12s = cirq.Simulator() # Initialize Simulator print(‚ÄôSimulate the circuit:‚Äô ) results = s.simulate(circuit) # Run simulator print(results) 16 Output Simulate the circuit output vector: |101> q0 q1 q2 Exercise Verifytheadditions:1 +1,1+0,0+1. ‚óèFull adder: Designafulladderthataddsq0 +q1,withq2asthesumandq3asthecarry.Itcanbe implementedwiththeprogramin FullAdder.py forthecircuit: q0 q1 q2 = Cinsum q3 Cout # FullAdder .py: Cirq q0+q1 full adder program 2 importcirq circuit = cirq.Circuit() # Build circuit 6q0, q1, q2,q3 = cirq.LineQubit. range(4) # Create 4 qubits circuit = cirq.Circuit() # Build circuit with qubits circuit.append(cirq.X(q0)) # Append X to q0 circuit.append(cirq.X(q1)) # Append X to q1 10circuit.append(cirq.Toffoli(q0, q1,q2)) # Append T o f f o li circuit.append(cirq.CNOT(q0, q1)) # Append CNOT to q0 , q1 circuit.append(cirq.Toffoli(q1, q2,q3)) # Append T o f f o li",1655
12.6.1 IBM Quantum Composer,"270 12 Quantum Computing (G. He, Coauthor) circuit.append(cirq.CNOT(q1, q2)) # Append CNOT to q1 , q2 14circuit.append(cirq.CNOT(q0, q1)) # Append CNOT to q0 , q1 print(circuit) s = cirq.Simulator() # Initialize Simulator print(‚ÄôSimulate the circuit:‚Äô ) 18results = s.simulate(circuit) # Run simulator print(results) Output Simulate the circuit: 22output vector: |1110> Usethisprogramtofillthistable: q0 q1 Cin Sum Cout |0‚ü©|0‚ü© |0‚ü©|1‚ü© |1‚ü©|0‚ü© |1‚ü©|1‚ü© 12.6 Accessing the IBM Quantum Computer We have just now checked, and since Amazon has yet to start selling personal quantum computers, we, instead, will go online and use the IBM Quantum [IBMqc, 2023]. Before youcanuseit,however,thereareanumberofstepstofollow: 1) Goto QUANTUM-COMPUTING.IBM.COM/LOGIN 2) Youwillneedtocreatean IBMid.Todothat,haveyourcellphoneanditsQRreaderin hand,clickon Create an IBMid account .2 Thiswillletyoulogintothe IBMQuantum ,aswellasgiveyouaccesstotutorialsand programmingtools.Followtheinstructionsonthatpageforcreatingandauthenticating youraccount.Alternatively,youmaybeabletouseyourGoogleorGitHubaccountto logintoIBMQuantum. 3) YoucanfindinstructionsonhowtorunIBMQuantumcodesat QUANTUM-COMPUTING.IBM.COM/LAB/DOCS/IQL/RUNTIME/START. Youwillbegivenatokentousetorunaprogram. 12.6.1 IBM Quantum Composer AfterloggingintotheIBMQuantum,youwillbepresentedwitha dashboard containing severalaccessroutestothecomputer.Wewilldemonstrateoneofthem.Pushingthebut- ton on the dashboard labeled Launch Composer , brings up the IBMQuantumComposer , which is shown in Figure 12.4. The Composer is a graphical tool for creating quantum circuits (programs) by dragging and dropping operators, and then running them on the IBMQuantum,orasimulator.Asseeninthefigure,theComposerisdividedintoseveral 2 Thismightnotworkforallcountries. 12.6 Accessing the IBM Quantum Computer 271 Figure 12.4 A screenshot of the dashboard for the IBM Quantum Composer, with the gates section magniÔ¨Åed . H q [0] q [1] 0.00.20.40.60.81. 0 01 00 Computational basis statesOutput state [ 0.707+0j, 0+0j, 0+0j, 0.707+0j ]œÄ/2 3œÄ/20 Phase œÄStatevector i Amplitute 10 11 Figure 12.5 Left: A Quantum Composer circuit for generating the Bell state ||ùõΩ00‚ü© .Right:T h e generated ||ùõΩ00‚ü© state vector in histogram and numerical forms. panels.Thetopleftpanel,whichwehavemagnified,presentsyouwithasetofcolorfullittle icons,eachrepresentingadifferentquantumgate,mostofwhichwehavejustdiscussed. Asanexampleofhowthisallworks,inFigure12.5,weshowtheComposer‚Äôsoutputfrom graphicalprogramthatweusedtocreatethe ùõΩ00Bellstate(12.22), ||ùõΩ00‚ü©=1‚àö 2(|00‚ü©+|11‚ü©). (12.69) On the left is the circuit that generated the state, and on the right are the two generated computational basis states, shown as both a histogram and as numbers. Here‚Äôs how our dragginganddroppingcreatedthecircuit: ‚óèWestartedbyselecting File/New,whichgaveusthefourqubits, q[0], q[1], q[2], q[3] , andasingleclassical,4-bitregister c4(cfor‚Äúclassical‚Äù). ‚óèSeeingthatweneedonlytwoqubitstoconstructthe ùõΩ00state,weeliminated q[2],q[3], and c4.",3015
12.7 Qiskit Plus IBM Quantum,"272 12 Quantum Computing (G. He, Coauthor) ‚óèNext,wedraggedthe Hadamard Hgate(definedinSection12.4)tothe q[0]line. ‚óèThenwedraggedthecontrolled-NOTgate  tothe q[0]lineaftertheHgate,withthe targetsymbolplacedonthe q[1]line. ‚óèLastly,wesavedthecircuitasthefile beta_00. ‚óèAswastobehopedfor,theoutputinFigure12.5agreeswith(12.69). A Small Caveat TheIBMQuantumemploysareversedDiracnotationinwhichqubits areorderedfromrighttoleft,thatis,as ||qn‚àí1,‚Ä¶q1q0‚ü©.SoinIBMspeak: |01‚ü©=||q1=0‚ü©‚äó||q0=1‚ü©=|01‚ü©=[1 0] ‚äó[0 1] =‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0 1 0 0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.70) 12.7 Qiskit Plus IBM Quantum Another avenue to QC is [Qiskit, 2023],an open-source software developmentkit (SDK) thatmaybeusedwiththeIBMQuantum,orwithitsbuilt-inquantumsimulator.Running onbothasimulatorandaphysicalQCisrevealing,asthesimulator,beingsoftware,may wellgivemoreaccurateresultsthananimperfectphysicalmachine. TherearedifferentwaystouseQiskit.HereweusedanAnacondawindowina Jupyter Notebook, all in MS Windows, to set up the virtual environment qiskit.W ea c t i v a t e d the environment and installed the Qiskit package, including visualization and the qiskit_ibm_provider package: conda create ‚àí‚àíname qiskit python jupyter notebook 2conda activate qiskit pip install qiskit[visualization] qiskit_ibm_provider IfyouwanttoaccessIBMQuantumfromyourlocalcomputer,thenyouwillneedan API tokenthatauthenticatesyourexternaluse.YoucancopythetokenfromtheIBMQuantum dashboard,oryoucanrunthefollowingcodetosavethetoken, api_token ,onyourlocal diskforfutureuse: 1fromqiskit_ibm_provider importIBMProvider IBMProvider.save_account(api_token) YoucannowuseyourlocalcomputertobuildaquantumcircuitandtorunitontheIBM Quantum.PlacethiscodeinaJupyterNotebooknamed beta_00: fromqiskitimportQuantumCircuit # Load needed package 2 circuit = QuantumCircuit(2) #C r e a t ea2 ‚àíq circuit # Apply H to q0 , then C N O T, q0 = control , q1 = target circuit.h(0) 6circuit.cx(0, 1) circuit.draw( ‚Äômpl‚Äô) # D r a w circuit 12.7 Qiskit Plus IBM Quantum 273 0001 10110001 101100011011 000110110.000.10.2 Re[œÅ] Im[œÅ]0.30.4 Figure 12.6 The real and imaginary part of the density matrix for the ||ùõΩ00‚ü©state computed with Qisket and the IBM Quantum. This should produce the same results as shown in Figure 12.5. Next, we‚Äôll use this same circuittocomputethestatevectoronQiskit‚Äôsquantum simulator Aer,andvisualizeitwith Qisket‚Äôs plot_state_city visualizationtool: 1fromqiskitimportAer fromqiskit.visualization importplot_state_city backend = Aer.get_backend( \""statevector_simulator\"" ) 5job = backend.run(circuit) result = job.result() statevector = result.get_statevector(circuit , decimals=3) statevector.draw(output= \""latex\"") 9plot_state_city(statevector) AsseenontheleftofFigure12.6,thisyieldstherealandimaginarypartsofthestatevector‚Äôs densitymatrix [(12.24)inSection12.3]. WenowwillrunthesamecircuitontheIBMQuantumComputer.Westartbyfinding theleastbusydevice: fromqiskit_ibm_provider importIBMProvider 3 # Select hub/group/project provider = IBMProvider(instance= \""ibm-q/open/main\"" ) # Get the least busy backend fromqiskit.providers.ibmq importleast_busy 7device = least_busy(provider.backends( filters= lambdax:int(x.configuration().n_qubits) >= 3 and not x.configuration().simulator andx.status().operational isTrue)) 11print(\""Running on current least busy device: \"" ,d e v i c e ) Nextwetranspile(translatefromonecompilertoanother)thequantumcircuitandrunit onourdefined device: 1fromqiskitimporttranspile fromqiskit.tools.monitor importjob_monitor circuit.measure_all() # Measure the two qubits 5transpiled_circuit = transpile(circuit , device)",3567
12.7.2 IBM Quantum Exercises,"274 12 Quantum Computing (G. He, Coauthor) 0 00 01 10 111000 227 24737503968 2000Count30004000 Figure 12.7 Histogram of the ||ùõΩ00‚ü©Bell state found using Qiskit and the IBM Quantum. job = device.run(tranpiled_circuit , shots=8192) job_monitor(job, interval=2) result = job.result() 9counts = result.get_counts(circuit) fromqiskit.visualization importplot_histogram plot_histogram(counts) TheoutputisshowninFigure12.7.YoumaynotethatthephysicalQuantumComputeris notaperfectquantumdevice,aswitnessedbytheexperimentalerror,namely,thesmall, butnonzero,countsforthe |01‚ü©and|10‚ü©states. 12.7.1 A Full Adder InSection12.5.1weusedGoogle‚ÄôsCirqsimulatortobuildacircuitthataddstwobits,using twoTOFFOLIgates,two CNOTgates,andfourqubits.Nowwe‚ÄôllbuildanIBMQuantumcircuit thatdoesthesamething,namelyadds xtoy.Thesimplethree-qubitcircuitthatdoesthatis shownontheleftofFigure12.8.OntherightofthefigureweshowamoreadvancedIBM Quantum implementation for adding 01 +10 using three T OFFOLI(CCX) gates, three CNOT (CX)gates,threemeasurementops,threemeasurementops,andfivequbits.Theprogram, givenbelow,startsbyinitializingthe q0,q1,andq2qubitsthatareusedtorepresent |x‚ü©,|y‚ü©, and|0‚ü©respectively.ItthenusesthefirstT OFFOLIgate,taking q0andq1asthecontroland q2asthetargetforthecarrybit.Thenacontrolled-NOTgateisusedwith q0asthecontrol andq1asthetarget.Thereadoutsofthestatesof q2andq1providetheresult x+y: 1defadder_circuit(x_in: int,y _ i n : int)‚àí> QuantumCircuit: # q [ 0 ,1 ,2 ,3 ,4 ] ‚àí‚àí> x[0 ,1] , y[0 ,1] , c s=f \""0{y_in:02b}{x_in:02b}\"" 5 qc = QuantumCircuit(5, 3) qc.initialize(s) qc.ccx(0, 2, 4) qc.cx(0, 2) 9 qc.reset(0) qc.ccx(1, 3, 0)",1618
12.8.1 1Qubit QFT,"12.8 The Quantum Fourier Transform 275 q0 q1 q2 q3 q4 c3 0 2 143[0, 1, 0, 0, 1]210 ‚à£x‚å™ ‚à£x     y‚å™ ‚à£(xy)‚å™‚à£y‚å™ ‚à£0‚å™‚à£0‚å™ ‚à£œà‚å™ Figure 12.8 Left: A quantum circuit for adding two bits. Right: The IBM Quantum version of an adder for 01 +10. qc.cx(1, 3) qc.ccx(3, 4, 0) 13 qc.cx(4, 3) qc.measure([2, 3, 0], [0, 1, 2]) returnqc 12.7.2 IBM Quantum Exercises UsetheIBMQuantumComposertoperformtheseexercises. 1) Provethat CZ|00‚ü©=|00‚ü©,CZ|01‚ü©=|01‚ü©,CZ|10‚ü©=|10‚ü©,CZ|11‚ü©=‚àí|11‚ü©. 2) DeterminetheeffectoftheCNOTgateon: |10‚ü©,|01‚ü©,|00‚ü©,and |11‚ü©. 3) CreateaquantumcircuitforcreatingtheentangledBellstate ||ùõΩ11‚ü©=1‚àö 2(|01‚ü©‚àí|10‚ü©). (12.71) 4) CreateacircuitthatdemonstratestheeffectofanHgateon |0‚ü©: H|0‚ü©=1‚àö 2[1 1] . (12.72) 5) ProvedthatacircuitwithtwoHadamardgatesactsastheidentityoperator. 6) VerifytheeffectoftheSWAPandCNOTgatesactingontwoqubits. 7) CreateacircuitthatshowshowtheT OFFOLI/CCNOTgateactingonthreequbitsinvertsthe thirdqubit,ifthefirsttwoqubitsare1‚Äôs. 8) Createacircuitfora halfadderthataddsthequbits,q0andq1,outputsthesum,aswell asacarrybitq2 =1ifq0=q1=1,elseq2 =0.Verifytheadditionsfor1 +1,1+0,0+1. 12.8 The Quantum Fourier Transform As studied in Chapter 9, the discrete Fourier transform (DFT) transforms Nvalues of a ‚Äúsignal‚Äùyk,k=0,1,‚Ä¶,N,measuredat Nequally-spacedtimes tk=kh,intoNcomplex, transformcomponents Yn.Thetransformanditsinversecanbewritteninaconciseand",1352
12.9 Oracle  Diffuser equals Grovers Search Algorithm,"276 12 Quantum Computing (G. He, Coauthor) insightfulway,andevaluatedefficiently,byintroducingacomplexvariable Zraisedtovar- iouspowers: Y=DFT(y),y=DFT‚àí1Y (12.73) Yn=1‚àö 2ùúãN‚àë k=1Znkyk,yk=‚àö 2ùúã NN‚àë n=1Z‚àínkYn, (12.74) Zdef=e‚àí2ùúãi‚àïNZnk‚â°[Zn]k. (12.75) Withthisformulation,onlyoneexplicitcomputationoftheexponentialisrequired. WenowgeneralizetheDFTtoa QuantumFourierTransform (QFT)where nqubitsare usedtocomputer2ncomponents.TheQFTtransformsasignalspacestate |y‚ü©intoatrans- formspacestate |Y‚ü©: |Y‚ü©=QFTN|y‚ü©,|y‚ü©=QFT‚àí1 N|Y‚ü© (12.76) |Y‚ü©=1‚àö NN‚àí1‚àë k=0N‚àí1‚àë l=0ylZ‚àíkl N|k‚ü©,|y‚ü©=1‚àö NN‚àí1‚àë k=0N‚àí1‚àë l=0YlZkl N|k‚ü©. (12.77) Herethesubscript NonZindicatesthenumberofbasisvectorsbeingusedand lthecom- ponents of yandY.Note, we have switched to the computer science convention of starting thesumsat0,Qiskit‚Äôsconventionforthesignofthepowerof Z,andtheabsenceofthe‚àö 2ùúã normalizationfactorsusedinChapter9 . 12.8.1 1-Qubit QFT Our1-qubitQFTcomputes N=21=2componentsvia(12.77): QFT2|0‚ü©=1‚àö 2(|0‚ü©+|1‚ü©),QFT2|1‚ü©=1‚àö 2(|0‚ü©‚àí|1‚ü©), (12.78) ‚áíQFT2|q‚ü©=1‚àö 22‚àë p=0Z‚àípq 2|p‚ü©. (12.79) Note,since Z2=‚àí1,theQFT2isthesameastheHadamardgate H,(12.48). 12.8.2 2-Qubit QFT Our2-qubitQFTcomputes N=22=4componentsvia(12.77): |Y‚ü©=QFT4|y‚ü©=1‚àö 43‚àë k=03‚àë l=0ylZ‚àíkl|k‚ü© (12.80) =1 2[(y0Z0+y1Z0+y2Z0+y3Z0)|0‚ü© +(y0Z0+y1Z‚àíl+y2Z‚àí2+y3Z‚àí3)|1‚ü© +(y0Z0+y1Z‚àí2+y2Z‚àí4+y3Z‚àí6)|2‚ü© +(y0Z0+y1Z‚àí3+y2Z‚àí6+y3Z‚àí9)|3‚ü©] 12.8 The Quantum Fourier Transform 277 ‚áíQFT4=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£‚ü®0|QFT4|0‚ü©‚ü®0|QFT4|1‚ü©‚ü®0|QFT4|2‚ü©‚ü®0|QFT4|3‚ü© ‚ü®1|QFT4|0‚ü©‚ü®1|QFT4|1‚ü©‚ü®1|QFT4|2‚ü©‚ü®1|QFT4|3‚ü© ‚ü®2|QFT4|0‚ü©‚ü®2|QFT4|1‚ü©‚ü®2|QFT4|2‚ü©‚ü®2|QFT4|3‚ü© ‚ü®3|QFT4|0‚ü©‚ü®3|QFT4|1‚ü©‚ü®3|QFT4|2‚ü©‚ü®3|QFT4|3‚ü©‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶ =1 2‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£11 1 1 1Z‚àí1Z‚àí2Z‚àí3 1Z‚àí21Z‚àí2 1Z‚àí3Z‚àí2Z‚àí1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (12.81) Note,forclaritywehaveleftoffthesubscript4on ZusedtoindicatethenumberofFourier components,thatis,here Z‚â°Z4=e‚àíiùúã‚àï2=‚àíi.Wehavealsomultipliedoutsomepowers ofZin(12.81).IntheQiskitconventionofSection12.7,thestatesare |0‚ü©=|00‚ü©, |1‚ü©=|01‚ü©, |2‚ü©=|10‚ü©, |3‚ü©=|11‚ü©. (12.82) TherulesfortheQFTarethus: QFT4|00‚ü©=H|0‚ü©‚äóH|0‚ü©,QFT4|01‚ü©=H|1‚ü©‚äóP(ùúã‚àï2)H|0‚ü©,(12.83) QFT4|10‚ü©=H|0‚ü©‚äóH|1‚ü©,QFT4|11‚ü©=H|1‚ü©‚äóP(ùúã‚àï2)H|1‚ü©,(12.84) whereHistheHadamardgate,and P(ùúÉ)isthephasegate: P(ùúÉ)=[10 0eiùúÉ] . (12.85) Puttingallofthepiecestogether,wehave QFT4beingaccomplishedwithjusttwoqubits plusfouroperations(threegatesandadirectproduct): QFT4||q1q0‚ü©=H||q0‚ü©‚äóPq0(ùúã‚àï2)H||q1‚ü©. (12.86) Figure12.9showsthecircuitbasedon(12.86),whereyoumaynotethattheswappingof theresultsoftwoqubits, H||q0‚ü©andPq0(ùúã‚àï2)H||q1‚ü©,isaccomplishedbytheSWAPgateat theend.ThesamecircuitcanbeimplementedinQiskit,aswedoinListing12.2.Thecor- rectnessofthecircuitisverifiedbyitsoutputmatchingthematrixin(12.81). Exercise Takefoursamplevalues, yk‚Äôs,ofthefunction y(t)=3cos(ùúît)+2cos(3ùúît). (12.87) 1) UseQFT4todetermine y(t)‚ÄôsFouriercomponents. 2) Whatarethefrequenciesofthededucedcomponents? 3) Checkthatthesummationofthecomponentsreproducestheinputsignal. 12.8.3 n-Qubit QFT ‚äô Givennqubits to work with, we can compute N=2ntransform components. The basis vectorsfor n-qubitsarethedirectproductsinan N-dimensionalHilbertspace: Figure 12.9 Quantum Fourier transform circuit for 2-qubits.  ‚à£q0‚å™ ‚à£q1‚å™ HH P(œÄ/2) 278 12 Quantum Computing (G. He, Coauthor) ||yn‚àí1¬∑¬∑¬∑y0‚ü©=||yn‚àí1‚ü©‚äó¬∑¬∑¬∑‚äó||y0‚ü©,yk‚àà{0,1}, (12.88) wherewearefollowingtheQiskitconvention.Thisproductcanalsobelabeledbyitsinteger representation y: y=n‚àí1‚àë k=0yk2k,‚àà{0,1,‚Ä¶,N‚àí1}, (12.89) |0‚ü©=|0‚Ä¶0‚ü©, |2‚ü©=|0‚Ä¶010‚ü©,‚Ä¶. (12.90) TheQFTofthebasisvector |y‚ü©isthen QFT2n|y‚ü©=1‚àö NN‚àí1‚àë k=0e2ùúãiyk‚àïN|k‚ü© (12.91) =1‚àö N1‚àë k0=0¬∑¬∑¬∑1‚àë kn‚àí1=0e2ùúãiyk‚àïN||kn‚àí1¬∑¬∑¬∑k0‚ü©(12.92) =1‚àö N1‚àë k0=0¬∑¬∑¬∑1‚àë kn‚àí1=0‚äón‚àí1 l=0e2ùúãiykl2l‚àín||kl‚ü©(12.93) =1‚àö N‚äón‚àí1 l=0(||kl=0‚ü©+e2ùúãi0.yn‚àíl‚àí1¬∑¬∑¬∑y0||kl=1‚ü©) =1‚àö N( |0‚ü©+e2ùúãi0.y0|1‚ü©)‚äó( |0‚ü©+e2ùúãi0.y1y0|1‚ü©) ‚äó¬∑¬∑¬∑‚äó( |0‚ü©+e2ùúãi0.yn‚àí1¬∑¬∑¬∑y0|1‚ü©)(12.94) =H||y0‚ü©‚äóPy0(ùúã‚àï2)H||y1‚ü©‚äóPy1(ùúã‚àï2)Py0(ùúã‚àï22)H||y2‚ü© ‚äó¬∑¬∑¬∑‚äóPyn‚àí2(ùúã‚àï2)¬∑¬∑¬∑Py0(ùúã‚àï2n‚àí1)H||yn‚àí1‚ü©. (12.95) Herewehaveemployedthebinaryfractionnotation: 0.xm¬∑¬∑¬∑x0def=m‚àë l=0xl2l‚àím‚àí1. (12.96) The Python‚ÄìQiskit implementation of this n-qubit QFT is amazingly short and efficient, andgiveninListing12.3.Ofcourse,QiskitalreadyhasaQFTmethod,andwecouldhave justusedit.Infact,wediduseittoverifythisimplementation. 12.9 Oracle +Diffuser =Grover‚Äôs Search Algorithm Problem Youaregivenadatabasecontaining N=2nelements,eachreferencedbyaspe- cificindex j,andthefunction fforwhich f(j)=ùõøij, (12.97) wherewehaveemployedtheKroneckerdeltafunction.Use nqubitstofinditem iinthe database. 12.9 Oracle +Diffuser=Grover‚Äôs Search Algorithm 279 Ofcourse,youcouldjuststartoutatthefirstelementandkeeptestingif f(j)=iuntilyou findj=i; but we want something faster than that. As our example, let‚Äôs say we have a databasewith16elements: jVjjVjjVjjVj 23 067 010 110 14 150 01 045 089 0 12 130 34 078 011 120 15 160 12 056 09 100 13 140 Ifwewanttosearchthroughthese16 =24elements,thenweneed n=4qubits.Andifwe wanttheelementwith j=8,thenwewanttocomeupwiththevalue90. Nowwemusttranslatethissearchintoaquantumcomputation.First,weinitializethe 4-qubitsysteminto |0‚ü©‚äón,andthenweuseadirectproductofHadamardoperatorstotrans- formthesystemintoauniformsuperpositionofstates: |ùúì‚ü©=H‚äón|0‚ü©‚äón=1‚àö NN‚àí1‚àë k=0|k‚ü©. (12.98) Now we have the stage set for a little magic. In literature, an oracle is a divine commu- nication or revelation that provides advice or prophecy. In QC, an oracle ùí™is a unitary operatororcircuitthatprovidesawaytodistinguishbetweendifferentstates.Ontheleft ofFigure12.10,weshowaschematiccircuitthatconstructsanoracle ùí™forthisparticular database,andforwhich ùí™|k‚ü©=( ‚àí1)f(k)|k‚ü©, (12.99) wheref(k)isthefunctionin(12.97).Inthemiddle( i=15)andright( i=9)ofFigure12.10 we show what‚Äôs inside the black (actually white) box shown on the left of Figure 12.10. InListing12.4wegiveaQiskitsimulatorcodeforgeneratingan oraclecircuit.InListing 12.5,wehaveanotherversionofthatcodeincludingthecallsneededtorunitontheIBM Quantum. Applyingtheoracletotheexpansion(12.98)yields: ùí™|ùúì‚ü©=1‚àö N‚àë k‚â†i|k‚ü©‚àí1‚àö N|i‚ü©. (12.100) We see that the oracle distinguishes the desired state |i‚ü©in the expansion by flipping its sign, while leaving the other states untouched. However, this hardly isolates the desired state from its brethren. Not to worry, we will now use the oracle to construct the Grover q0 q3q2q1 H H‚à£k‚å™(‚Äì1)f(k) ‚à£k‚å™ q0 q3 H Hq2q1 Figure 12.10 Left: A schematic quantum circuit for an oracle .Right:A noracle circuit for i=15. (c) An oracle circuit for i=9.",6215
12.10 Shors Factoring,"280 12 Quantum Computing (G. He, Coauthor) algorithm,whoserepeatedapplicationwillamplifytheamplitudeof |i‚ü©sothatitstandsout toadesiredlevelofprecision.Thealgorithmincorporatesthe diffuseroperatorUùúì: Uùúìdef=2|ùúì‚ü©‚ü®ùúì|‚àíI,where |ùúì‚ü©=1‚àö NN‚àí1‚àë k=0|k‚ü©. (12.101) Thediffuserhastheunusualproperty: Uùúì‚àë kùõºk|k‚ü©=‚àë k[ùõº+(ùõº‚àíùõºk)] |k‚ü©,whereùõºdef=1 N‚àë kùõºk. (12.102) Forthoseamplitude ùõºkgreater(less)thantheaverage ùõº,thediffuserdecreases(increases) theamplitudebelow(above)theaverage ùõº,toùõº‚àí(ùõºk‚àíùõº).Geometrically,thediffuser‚Äúre- flects‚Äùeachamplitude ùõºkwithrespecttotheaverage ùõº.Andsoasingleapplicationofan oracle+diffusercomboamplifiestheamplitudeof |i‚ü©relativetothatoftheothers: Uùúìùí™|ùúì‚ü©=3N‚àí4 N3‚àï2|i‚ü©+N‚àí4 N3‚àï2‚àë k‚â†ùúî|k‚ü©, (12.103) (needwepointoutthat3 N>N?).Thecombination Uùúìùí™,ofthediffuserandoracleiscalled theGroveroperator .Repeatedapplicationsoftheoperatorwillkeepincreasing |i‚ü©‚Äôsrelative amplitude,atleastuntilthenumberofapplicationsreaches ùúã‚àö N‚àï4[NielsenandChuang, 2010]. 12.9.1 Grover‚Äôs Implementation WenowuseQiskittoconstructa4-qubitimplementationofGrover‚Äôsalgorithmthatwill singleoutthe i=15elementsinthedataset.First,wecreateanoraclethatwillflipthesign forthestate |15‚ü©‚â°|1111‚ü©.Thatisaccomplishedbyplacingatriple-controlled-Zgate, HXH= Z,betweentwoHadamardgates,asshownontheleftofFigure12.10.Theoracleforother valuesoficanbebuiltbyaddingapairof Xgatesbeforeandafterthetriple-controlled-Z gate on the corresponding qubits. For example, on the right of Figure 12.10, we form an oraclefor |9‚ü©‚â°|1001‚ü©byaddingapairof Xgatesontoqubit-0. In Figure 12.11 we give a circuit for the Grover‚Äôs algorithm. In Listing 12.4 we give a program that generates a circuit for the algorithm,and then runs it on a simulator. (The diffusercodewithinisbasedonShor‚ÄôsAlgorithm[2023].)InListing12.5wegiveadriver versionofthissamecode,nowincludingthecallsneededtorunitontheIBMQuantum. q0H H UœâUœà Uœà Uœâ H H3210 3210 3210 3210 q1 q2 q3 Meas4 0123 Figure 12.11 A circuit for Grover‚Äôs Algorithm that combines an oracle (O) and a diffuser algorithm (U) that singles out the i=15 elements in a dataset. 12.10 Shor‚Äôs Factoring ‚äô281 0 0000000100100011010001010110011110001001101010111100110111101111 000000010010001101000101011001111000100110101011110011011110111194 5 5 6 4 114 6 2 5 10 7 7 52505007501000Count 080160240252 235248 222293 260282278288282 231 202244 231235 217320Count934 Figure 12.12 Left: Output of Grover‚Äôs search for i=9a sr u no nas i m u l a t o r . Right: Output of running the same program on the IBM Quantum Computer ibmq_lima . Figure 12.12 left shows the histogram resulting from running the Grover algorithm fori=9 on the simulator. We see that 926 out of 1000 trials resulted in the state |1001‚ü© (the desired i=9); this is a clear indication of the power of the algorithm. In contrast, Figure12.12-rightshowsthehistogramresultingfromrunningthecodeon ibmq_lima ,a physicalIBMQuantumcomputer.Youwillnoticethatthephysicalcomputerdoes notyield aclearlyoutstandingpeakforthe |1001‚ü©state.Thisisaconsequenceofnoiseintheelec- tronics.Thediscussionofquantumnoiseisanactiveresearchfieldthatisbeyondthescope ofthisbook.InterestedreadersarereferredtoWangandKrstic[2020]andreferencetherein. Exercise UseGrover‚Äôsalgorithmandfourqubitstosearchthetablegivenatthebegin- ningofthissection.Seeifyoucomeupwith90astheanswer. 12.10 Shor‚Äôs Factoring ‚äô What with its reliance on the computational difficulty of factoring large integers, prime numbersareanessentialelementincryptology.The primefactors ofanumberaretheprime numbers that when multiplied together result in the original number. For example, the primefactorsof30are2,3,and5,butnot6sinceit‚Äôsnotprime. Shor‚Äôsalgorithm isacom- putationaltechniqueforfindingtheprimefactorsofanintegerusingquantumgates.Dueto theefficiencyoftheQCalgorithm,thequantumcomputationisnearlyexponentiallyfaster thantheclassicalalgorithm.HerearethestepsinShor‚Äôsalgorithm[Wikipedia,2023]: 1) Pickarandominteger1 <r<N. 2) Computethegreatestcommondivisor(thePythoncommand, K=gcd(r,N)). 3) IfK‚â†1,thenKisafactorof N,andyouhavefoundafactor. 4) Useaperiod-findingmethod,tofindthesmallestperiod Tofthefunction f(x)=rx(modN),f(x+T)=f(x), (12.104) wherethe (mod)operatormakes faperiodicfunctionof x. 282 12 Quantum Computing (G. He, Coauthor) 5) IfTisodd,orif rT‚àï2=‚àí1(modN),returntostep1. 6) Else,gcd (rT‚àï2+1,N)orgcd(rT‚àï2‚àí1,N),orboth,arenontrivialfactorsofN,andyou havefoundatleastonefactor. Toillustratethealgorithm,wehavechosen N=15andwrittenthemethod Amod15.Itis giveninListing12.6,whereitcreatesaunitaryoperator Usuchthat U|y‚ü©=|Cy(modN)‚ü©,forallCcoprimewith15 . (12.105) Phase Estimation Before we can go on and implement Shor‚Äôs algorithm, we need QC methodsfor phaseestimation andperiodfinding .Westartwithphaseestimation.Let Ube aunitaryoperatorwitheigenvectors |u‚ü©andeigenvaluese2ùúãiùúô: U|u‚ü©=e2ùúãiùúô|u‚ü©. (12.106) Withoutactuallysolvingthiseigenvalueproblem,thequantumphasealgorithmprovides anestimateofthephase ùúô.Figure12.13showsacircuitthatimplementsthephasealgo- rithmusingtwoquantumregisters(computingunits).Thenumberofqubitsneededforthe tregister,theunitontop,isdeterminedbytherequiredaccuracy.Thenumberofqubitsin thesecondregisterbelowisthesameasthenumberofqubitsthat Uoperateson.Aswe see in the figure, the tregister starts with the state ||0t‚ü©, and then the H-gates transform eachqubitinthestateinto (|0‚ü©+|1‚ü©)‚àï‚àö 2.Thecontrolregister U2jleavesthesecondqubit unchanged,butchangesthe jthqubitinthefirstregisterintothestate (|0‚ü©+e2ùúãi2jùúô|1‚ü©)‚àï‚àö 2 (a‚Äúphasekickback‚Äù).Afterperformingallofthecontroloperations,the tregisterwillbe leftinthestate |0‚ü©+e2ùúãi2t‚àí1ùúô|1‚ü© 2‚äó¬∑¬∑¬∑‚äó|0‚ü©+e2ùúãi20ùúô|1‚ü© 2=1 2t‚àï22t‚àí1‚àë k=0e2ùúãikùúô|k‚ü©. (12.107) Yetwealsoknowthatforaninteger0 ‚â§s<2t,theQFTactingonthebasisstate |s‚ü©givesus QFT2t|s‚ü©=1 2t‚àï22t‚àí1‚àë k=0e2ùúãiks‚àï2t|k‚ü©. (12.108) If2tùúô=sisaninteger,thenweseethattheRHSof(12.107)isexactlythetransformfor2t components, QFT2t|s‚ü©.TheinverseQFTon QFT2t|s‚ü©revealsthevalue s: |s‚ü©=QFT‚àí1 2t[ |0‚ü©+e2ùúãi2t‚àí1ùúô|1‚ü© 2‚äó¬∑¬∑¬∑‚äó|0‚ü©+e2ùúãi20ùúô|1‚ü© 2] ,ùúô=s 2t. Even if 2tùúôis not an integer, the analysis of Nielsen and Chuang [2010] shows that the circuitestimates ùúôtoanaccuracyof t‚àí‚åà log( 2+1 2ùúñ)‚åâ bits,where ùúñistheprobabilitythat thealgorithmfails. ‚à£0t‚å™H H U20U2t‚Äì1QFT‚Äì1 ‚à£u‚å™Figure 12.13 A quantum circuit for phase estimation. 12.10 Shor‚Äôs Factoring ‚äô283 Period Finding ThesecondalgorithmweneedtoimplementShor‚Äôsalgorithmisonethat determinestheperiodofthefunction f(x)=rx(modN). (12.109) Herer<Nisapositiveinteger, randNarecoprime(have1astheonlycommonfactor), andthe(modN)operatormakes faperiodicfunctionof x.W ew anttofindthesmallest valueofTsuchthat f(x+T)=f(x),i.e.,rT(modN)=1. (12.110) LetUbeaunitaryoperatorsuchthat U|y‚ü©=|ry(modN)‚ü©. (12.111) Wedefineaneigenstateof U: ||uS‚ü©=1‚àö Tr‚àí1‚àë k=0e‚àí2ùúãiSk‚àïT|||rk(modN)‚ü©,0‚â§S‚â§T‚àí1, (12.112) U||uS‚ü©=e2ùúãiS‚àïT||uS‚ü©. (12.113) Eventhoughwedonotknowthevalueof T,orallofthedetailsofthe ||uS‚ü©state,wedo knowaneatidentity,namely: 1‚àö TT‚àí1‚àë S=0||uS‚ü©=|1‚ü©. (12.114) Soifwesettheinitialstateofthesecondquantumregisterto |1‚ü©,whichisasuperposition of||uS‚ü©‚Äôs,thequantumphaseestimationwillmeasurethephase ùúô=S T, (12.115) wheresisarandomintegerbetween0and T‚àí1.Wecannowusethe continuedfractions algorithmtodeterminethevalueof T. In Listing 12.6, we finally give our code for a quantum circuit that computes Shor‚Äôs algorithm [Shor‚Äôs Algorithm, 2023]. It combines quantum circuits for phase estimation and period-finding qpe, with the unitary operator amod15, and uses them to factor the number15.Here‚Äôsatypicaloutputfromit: 1Attempt #0 Random a = 7 Register reading: 00000000 Corresponding phase: 0.000000 5Phase: 0.0 r=1 Attempt #1 Random a = 8 9Register reading: 01000000 Corresponding phase: 0.250000 Phase: 0.25 r=4 13Found factor: 5 Found factor: 3",7628
12.11 Code Listings,"284 12 Quantum Computing (G. He, Coauthor) 12.11 Code Listings Listing 12.1 Entangle.py computes Hamiltonian, eigenvalues, and eigenvectors for entangledquantumstatesusingnumpy. # Entangle . py : Calculate entangled quantum s t a t e s 2 fromnumpyimport ‚àó;fromnumpy. linalg import ‚àó nmax = 4 6H = zeros((nmax,nmax) , float) XAXB = array([[0,0,0,1],[0,0,1,0],[0,1,0,0],[1,0,0,0]]) # sigxA . sigxB YAYB = array ([[0 ,0 ,0 , ‚àí1],[0,0,1,0],[0,1,0,0],[ ‚àí1,0,0,0]]) # sigyA . sigyA ZAZB = array([[1,0,0,0],[0, ‚àí1,0,0],[0,0, ‚àí1,0],[0,0,0,1]]) # sigzA . sigzA 10SASB = XAXB + YAYB + ZAZB ‚àí3‚àóZAZB # Hamiltonian/ factor print(‚ÄôHamiltonian without muÀÜ2/rÀÜ3 factor  ‚Äô ,SASB) es ,ev = eig(SASB) # Eigenvalues &vectors print(‚ÄôEigenvalues  ‚Äô ,es) 14print(‚ÄôEigenvectors(incolumns) ‚Äô ,ev) phi1 = (ev[0,0], ev[1,0], ev[2,0], ev[3,0]) # Extract vectors phi4 = (ev[0,1], ev[1,1], ev[2,1], ev[3,1]) phi3 = (ev[0,2], ev[1,2], ev[2,2], ev[3,2]) 18phi2 = (ev[0,3], ev[1,3], ev[2,3], ev[3,3]) basis = [phi1,phi2,phi3,phi4] # List eigenvectors foriin range (0,n m a x): # Hamiltonian in new basis forjin range (0, n m a x): 22 term = dot (SASB, basis [i ] ) H[i , j] = dot (basis [j],term ) print(‚ÄôHamiltonian in Eigenvector Basis  ‚Äô ,H ) Listing 12.2 QFT4.py A 2-qubit circuit that computes four Fourier components using Qiskit. # QFT4.py: A Qiskit program to compute a 2 ‚àíqubit QFT for 4 components 2 importmath fromqiskitimportQuantumCircuit importqiskit.quantum_info as qi 6importnumpy as np defqft2(inverse=False) ‚àí> QuantumCircuit: angle = math.pi/2 10 ifinverse isTrue: angle = ‚àíangle qc = QuantumCircuit(2) #C r e a t ea2 ‚àíqubit circuit qc.h(1) # H gate on qubit ‚àí1 qc.cp(angle, 0, 1) # Controlled phase gate 14 qc.h(0) qc.swap(0, 1) # Swap the qubits returnqc # Return circuit as gate 18if__name__ == \""__main__\"" : print(np.around(qi.Operator(qft2()).data, 3)) # Circuit matrix Listing 12.3 QFTn.py An n-qubit circuit that computes 2nFourier components using Qiskit. # Q F T.py: A Qiskit program using n ‚àíqubits for 2^n component QFT 3importmath fromqiskitimportQuantumCircuit importqiskit.quantum_info as qi fromqiskit.circuit.library importQFT 7importnumpy as np 12.11 Code Listings 285 defqft(n:int,i n v e r s e : bool= False , skip_swap: bool=F a l s e ) ‚àí> QuantumCircuit: #b u i l dan ‚àíqubit qft circuit 11angle = np.pi/2 ifinverse isTrue: angle = ‚àíangle qc = QuantumCircuit(n) 15foriin reversed (range(n)): qc.h(i) forjin range (i): qc.cp(angle/2 ‚àó‚àó(i‚àíj‚àí1), j , i) 19ifskip_swap isFalse: foriin range (math.floor(n/2)): qc.swap(i , n ‚àíi‚àí1) returnqc 23 if__name__ == \""__main__\"" : forkin range (10): print(np.max(np.abs(qi.Operator(qft(k)).data ‚àíqi.Operator(QFT(k)).data))) Listing 12.4 OracleSim.py A quantum circuit for Grover‚Äôs algorithm for i=0-15 on a simulator. # OracleSim.py: Simulator version of Qiskit code for Oracle circuit , i=0 ‚àí15 fromqiskitimportQuantumCircuit, Aer, transpile , assemble 4fromqiskit.visualization importplot_histogram fromnumpyimportmath deforacle(omega: int): # With removed ‚àí>Gate 8ifomega<0oromega >= 16: #F l i ps i g ni f | o m e g a > raiseValueError( \""Input should be betwn\"" +\""0&15, got\"" ,o m e g a ) bit_string =f \""{omega: 04b}\"" # Convert omega to bit pattern quantum_circuit = QuantumCircuit(4) # 4 bit q u a n t u m circuit 12[quantum_circuit.x(3 ‚àíidx)foridxin range (4)ifbit_string[idx]== ‚Äô0‚Äô] quantum_circuit.h( 3 ) quantum_circuit.mcx([0,1,2],3) quantum_circuit.h(3) 16[quantum_circuit.x( 3 ‚àíidx)foridxin range (4)ifbit_string[idx]== ‚Äô0‚Äô] cap_u_omega = quantum_circuit.to_gate() cap_u_omega.name= \""omega\"" # Differs returncap_u_omega 20 # diffuser .py: circuit for a diffuser with n qubits defdiffuser(n_qubits: int): # remove Gate , I ‚àí22|psi> <psi | quantum_circuit = QuantumCircuit(n_qubits) # n qubit circuit 24quantum_circuit.h( range( n_qubits)) # M a p|psi> to |0...0 > quantum_circuit.x( range(n_qubits)) # M a p|0...0 > to |1...1 > quantum_circuit.h( n_qubits ‚àí1)# Multi cntrl ‚àíz, flips sign |1...1 > quantum_circuit.mcx(list( range(n_qubits ‚àí1)),n_qubits ‚àí1) 28quantum_circuit.h(n_qubits ‚àí1) # M a p back to |0...0 > quantum_circuit.x( range( n_qubits)) quantum_circuit.h( range( n_qubits)) #M a pb a c k t o | p s i > cap_u_psi = quantum_circuit.to_gate() 32cap_u_psi.name= \""$U_{\\psi} $\"" returncap_u_psi # Grover .py : Driver code for QC Grover algorithm on simulator 36if__name__ == \""__main__\"" : cap_n=4 qc = QuantumCircuit(cap_n) qc.h(range(cap_n)) #p u ti n t o | \ p s i > 40 #R u n cap_r = math. ceil(math.pi ‚àómath.sqrt(cap_n)/4) # Iterate Grover R times foriin range (cap_r): qc.append(oracle(9) , range(cap_n)) 44 qc.append(diffuser(cap_n), range(cap_n)) qc.measure_all() 286 12 Quantum Computing (G. He, Coauthor) qc.draw(output= \""mpl\"",filename= \""grover4_circuit.png\"" ) backend=Aer.get_backend( \""aer_simulator\"" ) # Run on simulator 48transpiled_circuit = transpile(qc,backend=backend) job = backend.run(transpiled_circuit) result = job.result() histogram = result.get_counts() 52plot_histogram(histogram,filename= \""grover4_sim_histogram.png\"" ) Listing 12.5 OracleIBM.py AnIBMQuantumcircuitforGrover‚Äôsalgorithmfori=0-15. # OracleIBM.py: I B M Q C Qiskit code for Oracle circuit , i=0 ‚àí15. 2 fromqiskitimportQuantumCircuit, Aer, transpile fromqiskit.visualization importplot_histogram fromqiskit.tools importjob_monitor 6fromqiskit_ibm_provider importIBMProvider, least_busy fromnumpyimportmath deforacle(omega: int): # remove ‚àí>Gate 10 # Flip the sign if state is |omega > ifomega<0oromega >= 16: raiseValueError( \""Need input\"" +\""0 - 15, got \"" ,o m e g a ) # Convert omega into bit pattern 14 # bit_string = f \""{omega: 04b }\"" ######################## bit_string = f \""{omega:04b}\"" # print (\"" bit ‚àístring \"" , bit_string) # Start a q u a n t u m circuit of 4 qubits 18quantum_circuit = QuantumCircuit(4) [quantum_circuit.x(3 ‚àíidx)foridxin range (4)ifbit_string[idx] == ‚Äô0‚Äô] quantum_circuit.h(3) quantum_circuit.mcx([0, 1, 2], 3) 22quantum_circuit.h(3) [quantum_circuit.x(3 ‚àíidx)foridxin range (4)ifbit_string[idx] == ‚Äô0‚Äô] cap_u_omega = quantum_circuit.to_gate() cap_u_omega.name = \""$U_\\omega $\"" 26returncap_u_omega # diffuser .py: a quantum circuit for a general diffuser with n qubits defdiffuser(n_qubits: int): # remove Gate 30 # Where| psi>is the uniform superposition state # Create a circuit with n_qubits quantum_circuit = QuantumCircuit(n_qubits) # M a p|psi> to |0...0 > 34quantum_circuit.h( range(n_qubits)) # M a p|0...0 > to |1...1 > quantum_circuit.x( range(n_qubits)) # Multiply controlled ‚àíz 38 # T o flip sign for |1...1 > quantum_circuit.h(n_qubits ‚àí1) quantum_circuit.mcx(list( range(n_qubits ‚àí1)), n_qubits ‚àí1) quantum_circuit.h(n_qubits ‚àí1) 42 # M a p back from |1...1 > to |0...0 > quantum_circuit.x( range(n_qubits)) # M a p back |0...0 > to |psi> quantum_circuit.h( range(n_qubits)) 46cap_u_psi = quantum_circuit.to_gate() cap_u_psi.name = \""$U_{\\psi} $\"" returncap_u_psi 50# Grover.py: Driver code for QCGrover algorithm on simulator &IBMQuantum if__name__ == \""__main__\"" : # these 2 commented lin es only need to run once at the very beginning # token =‚Äô ‚àó‚àó‚àó‚àó‚àó‚àó‚àó‚àó‚àó‚àó‚àó ‚Äô 54 # QiskitRuntimeService . save_account(channel=\""ibm_quantum\"" , token=token , overwrite=True) cap_n = 4 # number of qubits qc = QuantumCircuit(cap_n) qc.h(range(cap_n)) #p u ti n t o | \ p s i > 58 # R u n Grover iteration for R times 12.11 Code Listings 287 cap_r = math. ceil(math.pi ‚àómath.sqrt(cap_n) / 4) foriin range (cap_r): qc.append(oracle(9) , range(cap_n)) 62 qc.append(diffuser(cap_n), range(cap_n)) qc.measure_all() qc.draw(output= \""mpl\"", filename= \""grover4_circuit.png\"" ) # Run on simulator 66backend = Aer.get_backend( \""aer_simulator\"" ) transpiled_circuit = transpile(qc, backend=backend) job = backend.run(transpiled_circuit) result = job.result() 70histogram = result.get_counts() plot_histogram(histogram, figsize=(7, 7), filename= \""grover4_sim_histogram.png\"" ) print(max(histogram, key=histogram.get)) # Load account and get provider 74provider = IBMProvider(instance= \""ibm-q/open/main\"" ) device = least_busy(provider.backends( filters= lambdax:int(x.configuration().n_qubits) >= cap_n and not x.configuration().simulator 78 andx.status().operational isTrue)) print(\""Running on least busy device:\"" ,d e v i c e ) # Transpile and run transpiled_circuit = transpile(qc, device) 82job = device.run(transpiled_circuit) job_monitor(job, interval=2) # Get result result = job.result() 86histogram = result.get_counts(qc) plot_histogram(histogram, figsize=(7, 7), filename= \""grover4_histogram.png\"" ) Listing 12.6 Shor.py AQuantumcircuitforShor‚ÄôsAlgorithm.",8564
12.11 Code Listings,"# Shor . py : Shor ‚Äô s algorithm # https:// qiskit .org/textbook/ch ‚àíalgorithms/shor .html 3 importrandom fromfractions importFraction frommathimportgcd 7fromtypingimportList fromqiskitimportQuantumCircuit, Aer, transpile , assemble fromqiskit.circuit.library importQFT 11defamod15(a_in: int,p _ i n : int)‚àí> QuantumCircuit: #M u l txa _ i nm o d1 5 ifa_innot in[ 2 ,4 ,7 ,8 ,1 1 ,1 3 ,1 4 ] : raiseValueError( \""‚Äôa_in‚Äô must be 2,4,7,8,11,13 or 14\"" ) quantum_circuit = QuantumCircuit(4) 15foriteration in range (p_in): ifa_inin[2, 13]: quantum_circuit.swap(2, 3) quantum_circuit.swap(1, 2) 19 quantum_circuit.swap(0, 1) ifa_inin[7, 8]: quantum_circuit.swap(0, 1) quantum_circuit.swap(1, 2) 23 quantum_circuit.swap(2, 3) ifa_inin[4, 11]: quantum_circuit.swap(1, 3) quantum_circuit.swap(0, 2) 27 ifa_inin[7, 11, 13, 14]: # I added 14 here foriin range (4): quantum_circuit.x(i) quantum_circuit.name = \"" percentiÀÜ percenti mod 15\""  percent( a _ i n ,p _ i n ) 31returnquantum_circuit # return the circuit defqpe(u_list: List[QuantumCircuit]) ‚àí>float:# Build phase circuit # u_list : a l i s t of QuantumCircuit 35 #[ U ÀÜ(2ÀÜ0) , U ÀÜ(2ÀÜ1), ... U ÀÜ(2ÀÜ(t‚àí1)) ] t=len(u_list) num_qubits_u = u_list[0].num_qubits # N qubits for cap_u gate 288 12 Quantum Computing (G. He, Coauthor) qc = QuantumCircuit(t + num_qubits_u, t) 39 # put the first t_count qubits into superposition foriin range (t): qc.h(i) # put the last n_u qubit into |1> state 43qc.x(t) # qiskit convention foriin range (t): # Add contr ‚àíUÀÜ{2ÀÜj} g a t e qc.append(u_list[i].to_gate().control() , [i] +[ j + tforjin range (num_qubits_u)]) 47qc.append(QFT(t, inverse=True).to_gate() , range(t)) # Inverse Q F T qc.measure( range(t),range(t)) # Finally , measure simulator = Aer.get_backend( \""aer_simulator\"" ) # Run on simulator q_obj = assemble(transpile(qc, simulator), shots=1) 51result = simulator.run(q_obj, memory=True).result() readings = result.get_memory() print(\""Register reading: \"" +r e a d i n g s [ 0 ] ) phase = int(readings[0], 2)/(2 ‚àó‚àót) 55print(\""Corresponding phase:  percentf\""  percent phase) returnphase if__name__ == \""__main__\"" : 59cap_n = 15 factor_found = False attempt = 0 while not factor_found: 63 print(\""Attempt #\"" , attempt) attempt += 1 a = random.randint(2, cap_n ‚àí1) print(\""Random a = \"" ,a ) 67 k=g c d ( a ,c a p _ n ) ifk. =1 : factor_found = 1 print(\""Found factor: \"" ,k ) 71 else: p=q p e ( [ a m o d 1 5 ( a ,2 ‚àó‚àój)forjin range (8)]) print(\""Phase: \"" ,p ) fraction = Fraction(p).limit_denominator(cap_n) 75 s, r = fraction.numerator, fraction.denominator print(\"" r=\"",r ) ifr percent2= =0 : # r is even guesses = [gcd(a ‚àó‚àó(r//2)+1, cap_n), 79 gcd(a ‚àó‚àó(r//2)‚àí1, cap_n)] forginguesses: ifgnot in[1, cap_n] and(cap_n  percent g) == 0: print(\""Found factor:  percenti\""  percentg ) 83 factor_found = True",2806
Part III Applications,289 Part III Applications,25
Chapter 13 ODE Applications Eigenvalues Scattering Trajectories. 13.2.1 Not Recommended Matchless Searching,"291 13 ODE Applications; Eigenvalues, Scattering, Trajectories Now that we have developed reliable methods to solve ODEs, we apply them to some chal- lenging problems. First, we combine our ODE solver with a search algorithm to solve the quantum eigenvalue problem for an arbitrary potential. Then we study classical scattering in a system that becomes chaotic. Finally, we look upward to balls falling out of the sky and planets that do not . 13.1 Quantum Eigenvalues for Arbitrary Potentials Problem Whatistheenergyofaparticleboundbyapotentialthatconfinesittoanatomic distance? Quantummechanicsdescribesphenomenathatoccuratatomicandsubatomic(particle) scales.Itisastatisticaltheoryinwhichtheprimeobservableistheprobabilitythataparticle is located in a region dxaround point x. Yet, usually, we solve for a wave function ùúì(x), andthencalculatetheprobabilityas Óàº=|ùúì(x)|2dx.Ifaparticleofenergy Eismovingin onedimensionandexperiencesapotential V(x), thatwavefunctionisdeterminedbyan ordinarydifferentialequation,thetime-independentSchr√∂dingerequation:1 ‚àí‚Ñè2 2md2ùúì(x) dx2+V(x)ùúì(x)=Eùúì(x). (13.1) Inpractice,wesolveforthe wavevector ùúÖ,whereitisrelatedtoboundstates( E<0)by: ùúÖ2=‚àí2m ‚Ñè2E. (13.2) TheSchr√∂dingerequationnowtakestheform d2ùúì(x) dx2‚àí2m ‚Ñè2V(x)ùúì(x)=ùúÖ2ùúì(x). (13.3) Theproblemstatesthattheparticleisbound,whichmeansthatitisconfinedtosomefinite regionofspace,which,inturn,impliesthat ùúì(x)isnormalizable.(Unboundparticlesdo 1 Theequationfor2Dor3Dmotion,orwithtime-dependence,requiresthesolutionofapartial differentialequation,asdiscussedinChapter24. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 292 13 ODE Applications; Eigenvalues, Scattering, Trajectories nothavenormalizablewavefunctions.)Theonlywaytohaveanormalizablewavefunction, isifùúì(x)decaysexponentiallyas x‚Üí¬±‚àû,whereV=0:2 ùúì(x)‚Üí{e‚àíùúÖx,forx‚Üí+‚àû, e+ùúÖx,forx‚Üí‚àí‚àû.(13.4) Insummary,althoughweknowhowtosolvetheODE(13.1)withournumericaltools,we mustalsofigureoutatechniquetodosowithintheconstraintsoftheboundaryconditions (13.4).ThisextraconditionturnstheODEproblemintoan eigenvalueproblem ,whichhas solutions(eigenvalues )foronlycertainvaluesoftheenergy EorùúÖ.Theground-stateenergy corresponds to the smallest (most negative) eigenvalue. Because the greater the number of oscillationsin a wave function,the greater is the kineticenergy of the bound particle, themorenodesinawavefunction,thehighertheenergy.Accordingly,weexpectthatthe boundstatewiththeleastenergy(ground-state)willhaveanodelesswavefunction. 13.1.1 Model: Nucleon in a Box The numerical methods we describe are capable of handling the most realistic potential shapes.Yettomakeaconnectionwiththestandardtextbookcase,andtopermitsomeana- lyticchecking,wewilluseasimplemodelinwhichthepotential V(x)in(13.1)isafinite squarewell(Figure13.1): V(x)={‚àíV0=‚àí83MeV,for|x|‚â§a=2fm, 0, for|x|>a=2fm,(13.5) wherevaluesof83MeVforthedepth,and2fmfortheradius,aretypicalfornuclear-bound states.WiththispotentialtheSchr√∂dingerequation(13.3)becomes d2ùúì(x) dx2+(2m ‚Ñè2V0‚àíùúÖ2) ùúì(x)=0,for|x|‚â§a, (13.6) d2ùúì(x) dx2‚àíùúÖ2ùúì(x)=0, for|x|>a. (13.7) Toevaluatetheratioofconstantshere,weinsert c2,thespeedoflightsquared,intoboth thenumeratorandthedenominatorandthensomefamiliarvalues: 2m ‚Ñè2=2mc2 (‚Ñèc)2‚âÉ2√ó940MeV (197.32MeVfm )2=0.0483MeV‚àí1fm‚àí2. (13.8) xmatch xV(x) ‚ÄìV0 ‚Äìa 0 a0Figure 13.1 A square well in bold, and the wave function within it. At the location xmnear the right edge of the well, the wave function computed by integration in from the left is matched to the one computed by integration in from the right (dashed curve). 2 IfwewereworkingwithaCoulombpotential,itsveryslowfalloffwouldrequireusingCoulomb functionsat ¬±‚àû,notexponentials[Landau,1996]. 13.2 Algorithm: ODE Solver +Search 293 13.2 Algorithm: ODE Solver +Search Akeyelementinsolvingforboundstatesistherealizationthatthesecond-orderODEwill havetwosolutions:onethatdecaysas x‚Üí¬±‚àû,andasecondonethatgrowsas x‚Üí¬±‚àû. Consequently,anumericalsolution,beinganapproximation,willalwayscontainsomeof each.Yetifweintegratestep-by-steponasolutionthatisincreasinginvalue,thenthebitof thedecreasingfunctionthatismixedinwillgetsmallerandsmaller,whiletheincreasing functionkeepsincreasing,andthusthesolutionbecomesmoreaccurate.Likewise,ifwe integratestep-by-steponasolutionthatisdecreasinginvalue,thenthebitoftheincreasing functionthatismixedinwillgetgreaterandgreater,whilethedecreasingfunctionkeeps decreasing,andthusthesolutionbecomeslessaccurate. AlwaystrytointegrateanODEas thefunctionisincreasing. The solution to our eigenvalue problem combines the numerical solution of the ordi- narydifferentialequation(13.3)withatrial-and-errorsearchforawavefunctionthatalso satisfiestheboundaryconditions(13.4).Thisiscarriedoutinseveralsteps: 1) Startatthefar leftatx=‚àíx‚àû‚âÉ‚àí ‚àû,wher ex‚àû‚â´a.Sincethepotential V=0inthis region, the analytic solution here is e¬±ùúÖx. Accordingly, assume that the wave function theresatisfiestheleft-handboundarycondition: ùúìL(x=‚àíx‚àû)=e+ùúÖx=e‚àíùúÖx‚àû. (13.9) 2) Use your rk4ODE solver to integrate ùúìL(x)toward the origin (to the right), from x=‚àíx‚àû,untilyoureachthe matchingradiusxm.Inthisway,weareintegrating,step-by- step,overanincreasingfunction.Theexactvalueofthismatchingradiusisnotimpor- tant, and our final solution should be independent of it. In Figure 13.1, we show a sample solution with xm‚âÉa, that is, we match just beyond the right edge of the potential.InFigure13.2,weseesomeguessesthatdonotmatch. 3) Startattheextreme right,thatis,at x=+x‚àû‚âÉ+ ‚àû,withawavefunctionthatsatisfies theright-handboundarycondition: ùúìR(x=ùúÖx‚àû)=e‚àíùúÖx=e‚àíùúÖx‚àû. (13.10) 4) Useyour rk4solvertostep ùúìR(x)intowardtheorigin(totheleft),from x=+x‚àû,until you reach the matching radius xm. In this way, we are integrating, step-by-step, over an increasing function. This means that we have integrated up to the potential well (Figure13.1). Figure 13.2 Two guesses for the energy that are either too low or too high to be an eigenvalue. We see that the low-E guess does not oscillate fast enough to match a dying exponential, while the high-E guess oscillates too fast. 0 xLow EHigh E",6093
13.2.4 Explorations,"294 13 ODE Applications; Eigenvalues, Scattering, Trajectories 5) Inorderforprobabilityandcurrenttobecontinuousat x=xm,ùúì(x),andùúì‚Ä≤(x)mustbe continuousthere.Requiringtheratio ùúì‚Ä≤(x)‚àïùúì(x),calledthe logarithmicderivative ,tobe continuousthereencapsulatesbothcontinuityconditionsintoasinglecondition,andis independentof ùúì‚Äôsnormalization. 6) Although we do not know ahead of time what value for ùúÖwill be an eigenvalue, we stillneedastartingvalueforitinordertouseourODEsolver.Suchbeingthecase,we startthesolutionwithaguess.Agoodguessforground-stateenergywouldbeavalue somewhatupfromthatatthebottomofthewell, E>‚àíV0. 7) Becauseitisunlikelythataguesswillbecorrect,theleft-andright-wavefunctionswill not quite match at x=xm(Figure 13.2). This is fine because we can use the amount ofmismatchtoimprovethenextguess.Wemeasurehowwelltherightandleftwave functionsmatchbycalculatingthedifferenceinlogarithmicderivatives: Œî(E,x)=ùúì‚Ä≤ L(x)‚àïùúìL(x)‚àíùúì‚Ä≤ R(x)‚àïùúìR(x) ùúì‚Ä≤ L(x)‚àïùúìL(x)+ùúì‚Ä≤ R(x)‚àïùúìR(x)|||||x=xm, (13.11) where the denominator is there to avoid overly large or small numbers. Next, we try adifferentenergy,notehowmuch Œî(E)haschanged,andusethechangetodeducea better guess for the energy. The search continues until the left and right ùúì‚Ä≤‚àïùúìmatch withinsomesettolerancethatdependsontheprecisioninenergydesired. 13.2.1 Not Recommended: Matchless Searching Asimplerapproachtofindingboundstatesistotryoutabunchofenergies,andforeach justintegrateoutfrom0toinfinity.Then,ifthewavefunctionhasnotblownup,youhave foundaboundstate.Theproblemwiththisapproachisthatitintegratesstep-by-stepona decreasingfunction.Thismeansthatthesmallamountofincreasingfunctionthatismixed infromthestartkeepsgettinglarger,whilethedesiredsolutionkeepsgettingsmaller,and soyouwillendupwithawavefunctioncontainingalargepercentageoferror. Alwaystry tointegrateonincreasingfunctions. 13.2.2 Numerov Algorithm for Schr√∂dinger ODE‚®Ä Wegenerallyrecommendthefourth-orderRunge‚ÄìKuttamethodforsolvingODEs.However,if theODEbeingsolveddoesnotcontainanyfirstderivatives(suchasourSchr√∂dingerequation), then it is possible to use the Numerov algorithm, which is specialized for just this situation. Whilethisalgorithmisnotasgeneralasrk4,itisof Óàª(h6),andthusspeedsupthecalculation byprovidingadditionalprecision . WestartbyrewritingtheSchr√∂dingerequation(13.3)inthegenericform, d2ùúì dx2+k2(x)ùúì=0,k2(x)=2m ‚Ñè2{E+V0,for|x|<a, E,for|x|>a,(13.12) wherek2=‚àíùúÖ2forboundstates.Observethatalthough(13.12)isspecializedtoasquare well,otherpotentialswouldhave V(x)inplaceof ‚àíV0.ThetrickintheNumerovmethod is to get extra precision in the second derivative by taking advantage of there being no first derivative dùúì‚àïdxin (13.12). We start with the Taylor expansions of the wave function, 13.2 Algorithm: ODE Solver +Search 295 ùúì(x+h)‚âÉùúì(x)+hùúì(1)(x)+h2 2ùúì(2)(x)+h3 3.ùúì(3)(x)+h4 4.ùúì(4)(x)+¬∑¬∑¬∑ ùúì(x‚àíh)‚âÉùúì(x)‚àíhùúì(1)(x)+h2 2ùúì(2)(x)‚àíh3 3.ùúì(3)(x)+h4 4.ùúì(4)(x)+¬∑¬∑¬∑, whereùúì(n)signifiesthe nthderivative dnùúì‚àïdxn.Becausetheexpansionof ùúì(x‚àíh)hasodd powers ofhappearing with negative signs, all odd powers cancel when we add ùúì(x+h) andùúì(x‚àíh)together: ùúì(x+h)+ùúì(x‚àíh)‚âÉ2ùúì(x)+h2ùúì(2)(x)+h4 12ùúì(4)(x)+Óàª(h6), ‚áíùúì(2)(x)‚âÉùúì(x+h)+ùúì(x‚àíh)‚àí2ùúì(x) h2‚àíh2 12ùúì(4)(x)+Óàª(h4). Toobtainanalgorithmforthesecondderivative,weeliminatethefourth-derivativeterm byapplyingtheoperator1 +h2 12d2 dx2totheSchr√∂dingerequation(13.12): ùúì(2)(x)+h2 12ùúì(4)(x)+k2(x)ùúì+h2 12d2 dx2[k2(x)ùúì(4)(x)] =0. (13.13) Weeliminatethe ùúì(4)termsbysubstitutingthederivedexpressionfor ùúì(2): ùúì(x+h)+ùúì(x‚àíh)‚àí2ùúì(x) h2+k2(x)ùúì(x)+h2 12d2 dx2[k2(x)ùúì(x)] ‚âÉ0.(13.14) Nowweuseacentral-differenceapproximationforthesecondderivative: h2d2[k2(x)ùúì(x)] dx2‚âÉ[ (k2ùúì)x+h‚àí(k2ùúì)x]+[(k2ùúì)x‚àíh‚àí(k2ùúì)x]. (13.15) Afterthissubstitution,weobtaintheNumerovalgorithm: ùúì(x+h)‚âÉ2[ 1‚àí5 12h2k2(x)] ùúì(x)‚àí[ 1+h2 12k2(x‚àíh)] ùúì(x‚àíh) 1+h2k2(x+h)‚àï12. (13.16) WeseethattheNumerovalgorithmusesthevaluesof ùúìatthetwoprevioussteps xand x‚àíhtomoveùúìforwardto x+h.Tostepbackwardin x,weneedonlytoreversethesign ofh.Ourimplementationofthisalgorithm, Numerov.py,isgiveninListing13.1. 13.2.3 Implementation: Eigenvalues via ODE Solver +Bisection Algorithm 1) Combine your bisection algorithm search program with your rk4or Numerov ODE solverprogramtocreateaneigenvaluesolver.Startwithastepsize h=0.04. 2) Writeamethodthatcalculatesthematchingfunction Œî(E,x)asafunctionofenergy andmatchingradius.Thismethodwillbecalledbythebisectionalgorithmprogramto searchfortheenergyatwhich Œî(E,x=2)vanishes. 3) Asafirstguess,take E‚âÉ‚àí65MeV. 4) Searchuntil Œî(E,x)changesinonlythefourthdecimalplace.Wedothisinthecode QuantumEigen.py giveninListing13.2. 5) Printoutthevalueoftheenergyforeachiteration.Thiswillgiveyouafeelastohow welltheprocedureconverges,aswellasameasureoftheprecisionobtained.Trydif- ferentvaluesforthetoleranceofthelogarithmicderivativeuntilyouareconfidentthat youareobtainingthreegooddecimalplacesintheenergy.",4793
13.3.3 Assessment,"296 13 ODE Applications; Eigenvalues, Scattering, Trajectories 6) Buildinalimittothenumberofiterationsyoupermit,withawarningiftheiteration schemefails. 7) Plot the wave function and potential on the same graph (you will have to scale one ordinate). 8) Deduce,bycountingthenumberofnodesinthewavefunction,whetherthesolution found is a ground state (no nodes) or an excited state (with nodes) and whether the solutionisevenoroddabouttheorigin(thegroundstatemustbeeven). 9) IncludeinyourversionofFigure13.1ahorizontallinewithinthepotentialindicating theenergyofthegroundstaterelativetothepotential‚Äôsdepth. 10) Increasethevalueoftheinitialenergyguessandsearchforexcitedstates.Makesureto examinethewavefunctionforeachstatefoundtoestablishthatitiscontinuous,and tocountthenumberofnodestoseeifyouhavemissedanystates. 11) Addeachnewstatefoundasanotherhorizontalbarwithinthepotential. 13.2.4 Explorations 1) Check to see how well your search procedure works by using arbitrary values for the startingenergy.Forexample,becausenobound-stateenergiescanliebelowthebottom ofthewell,try E‚â•‚àíV0,aswellassomearbitraryfractionsof V0.Ineverycaseexam- ine the resulting ground state wave function and check that it is both symmetric and continuous. 2) Increasethedepthofyourpotentialprogressivelyuntilyoufindseveralboundstates. Lookatthewavefunctionineachcase,andcorrelatethenumberofnodesinthewave functionwiththepositionoftheboundstateinthewell. 3) Explorehowabound-stateenergychangesasyouchangethedepth V0ofthewell.In particular,asyoukeepdecreasingthedepth,watchtheeigenenergymovecloserto E=0 andseeifyoucanfindthepotentialdepthatwhichtheboundstatehas E‚âÉ0. 4) Forafixedwelldepth V0,explorehowtheenergyofaboundstatechangesasthewell radiusaisvaried.Largerradiusshouldgiveincreasedbinding. 5) Solveforthewavefunctionofalinearpotential: V(x)=‚àíV0{|x|,for|x|<a, 0,for|x|>a.(13.17) Thereislesspotentialherethanforasquarewell,soyoumayexpectsmallerbinding energies and a less confined wave function. (For this potential, there are no analytic resultswithwhichtocompare.) 6) Comparetheresultsobtained,andthetimethecomputertooktogetthem,usingboth theNumerovand rk4methods. 7)Newton‚ÄìRaphson extension: Extend the eigenvalue search by using the Newton‚Äì Raphsonmethodinplaceofthebisectionalgorithm.Determinethespeedup. 13.3 Classical Chaotic Scattering Onemightexpectthattheclassicalscatteringofaprojectilefromapassivetargetwillvary smoothly.Yetexperiments(Figure13.3left)havefoundthatwhenaprojectileundergoes multipleinternalscatterings,itsfinaltrajectoryappearsunrelatedtoitsinitialone. 13.3 Classical Chaotic Scattering 297 vV(x,y ) xy bv' Œ∏ Figure 13.3 Left: A classic pinball machine in which the bumpers lead to multiple scatterings. A potential model that may support multiple internal scatterings. The incident velocity ùë£is in the y direction at an impact parameter b. After scattering, the particle moves off at an angle ùúÉ. Problem Determineifmultipleinternalscatteringsmayleadtosuchachaoticsituation. (ChaosisdiscussedmorefullyinChapter15.) 13.3.1 Model and Theory Ourmodelforscatteringfromthebumpersinpinballmachinesisapointparticlescattering fromthestationary2Dpotential[Bleher etal.,1990] V(x,y)=¬±x2y2e‚àí(x2+y2). (13.18) AsseenontherightofFigure13.3,thispotentialhasfourcircularlysymmetricpeaksin thexyplane.Theminussignin(13.18)(whichwewilldropfromnowon)wouldproduce attractive potential wells. Due to there being four peaks, it seems possible to have multi- plescatteringsinwhichtheprojectilebouncesbackandforthbetweenthepeaks,likeina pinballmachine. Thetheoryforthisproblemisclassicaldynamics.Visualizeascatteringexperimentin whichaprojectilestartsoutat (x=b,y=‚àí ‚àû )withvelocity v(Figure13.3).Thedistance biscalledthe impactparameter .Afterscatteringandmovingoutto y=+ ‚àû,theprojectile isobservedatthescatteringangle ùúÉ.Becauseafixedpotentialdoesnotrecoilandcarryoff energy,thespeedoftheprojectiledoesnotchange,onlyitsdirection. An experiment would measure the number of particles scattered at each scattering angleùúÉ. The analysis would convertthe measurements into the differential cross section ùúé(ùúÉ): ùúé(ùúÉ)=lim ŒîŒ©,ŒîA‚Üí0Nscatt(ùúÉ)‚àïŒîŒ© Nin‚àïŒîAin. (13.19) HereNscatt(ùúÉ)isthenumberofparticlesperunitoftimescatteredintothedetectoratangle ùúÉthatsubtendsasolidangle ŒîŒ©,andNinisthenumberofparticlesperunitoftimeincident onthetargetofcross-sectionalarea ŒîAin. Thedefinition(13.19)forthecrosssectionistheoneusedbyexperimentalists.Weneed not worry about applying it. Instead, we need to solve for the trajectory [x(t),y(t)]of the projectile scattering from the potential (13.18), and from that deduce the dependence of 298 13 ODE Applications; Eigenvalues, Scattering, Trajectories scatteringangle ùúÉ(b)ontheimpactparameter b.Oncewehavethatwecancalculatethe differentialcrosssection[MarionandThornton,2019]: ùúé(ùúÉ)=||||dùúÉ db||||b sinùúÉ(b). (13.20) Asyourcomputationshouldshow,thereareparametervaluesforwhich dùúÉ‚àïdbgetsvery large,orevendiscontinuous,andthisleadstochaoticcrosssections. WeneedtosolveNewton‚Äôslawfor [x(t),y(t)]inthepotential(13.18): F=ma ‚àíùúïV ùúïxÃÇi‚àíùúïV ùúïyÃÇj=md2x dt2, (13.21) ‚áí‚àí2y2x(1‚àíx2)e‚àí(x2+y2)=md2x dt2, (13.22) ‚àí2x2y(1‚àíy2)e‚àí(x2+y2)=md2y dt2. (13.23) ThepeaksofthepotentialinFigure13.3rightareat x=¬±1andy=¬±1,whereVmax=e‚àí2. Thissetstheenergyscalefortheproblem. 13.3.2 Implementation Although (13.22) and (13.23) are simultaneous second-order ODEs, we can still use our standard rk4ODEsolverandformalismbyextendingthemfromtwotofourdimensions: dy(t) dt=f(t,y), (13.24) y(0)def=x(t),y(1)def=y(t),y(2)def=dx dt,y(3)def=dy dt. (13.25) (Theorderinwhichthe y(i)sareassignedisarbitrary.)Whenappliedto(13.22)‚Äì(13.23),and expressedintermsofthe y(i)‚Äôs,wehave: f(0)=y(2), f(1)=y(3), (13.26) f(2)=‚àí1 m2y2x(1‚àíx2)e‚àí[x2+y2](13.27) =‚àí1 m2y(1)2y(0)(1‚àíy(0)2)e‚àí[y(0)2+y(1)2], (13.28) f(3)=‚àí1 m2x2y(1‚àíy2)e‚àí[x2+y2](13.29) =‚àí1 m2y(0)2y(1)(1‚àíy(1)2)e‚àí[y(0)2+y(1)2]. (13.30) To deduce the scattering angle from our calculation, we examine the trajectory of the projectileat y‚âÉ‚àû,whichwetaketobethe yvalueforwhichthepotentialhasessentially vanished, |PE|‚àïE‚â§10‚àí10.Thescatteringangleisdeducedfromthecomponentsofvelocity, ùúÉ=tan‚àí1(ùë£y ùë£x) =math.atan2(y, x) . (13.31) Here atan2isafunctionthatcomputesthearctangentinthecorrectquadrant,withouta divisionby ùë£xwhichcancauseanoverflow.",6220
13.5 2 and 3Body Planetary Orbits,"13.4 Projectile Motion with Drag 299 13.3.3 Assessment 1) Applythe rk4methodtosolvethesimultaneousODEs(13.22)and(13.23). 2) The initial conditions are(x=b,y=y‚àû),where |PE(y‚àû)|‚àïE‚â§10‚àí10. 3) Goodstartingparametersare m=0.5,ùë£y(0)=0.5,ùë£x(0)=0.0,Œîb=0.05,‚àí1‚â§b‚â§1. Youmaywanttolowertheenergyanduseafinerstepsizeonceyouhavefoundregions ofrapidvariationinthecrosssection. 4) Plotanumberoftrajectories [x(t),y(t)]thatshowusualandunusualbehaviors.Inpar- ticular,plotthoseforwhichbackanglescatteringoccurs,and,consequently,forwhich theremusthavebeensignificantmultiplescatterings. 5) Plotanumberofphasespacetrajectories [x(t), Ãáx(t)]and[y(t), Ãáy(t)].Howdothesediffer fromthoseofboundstates? 6) Determinethescatteringangle ùúÉ=atan2(Vx,Vy) bydeterminingthevelocitycompo- nents of the scattered particle after it has left the interaction region, that is, when PE‚àïE‚â§10‚àí10. 7) Identifywhichcharacteristicsofatrajectoryleadtodiscontinuitiesin dùúÉ‚àïdbandthus ùúé(ùúÉ). 8) Runthesimulationsforbothattractiveandrepulsivepotentials,andforarangeofener- gieslessthanandgreaterthan Vmax=exp(‚àí2). 9)Time delay: Anotherwaytofindunusualbehaviorinscatteringistocomputethe time delayT(b)asafunctionoftheimpactparameter b.Thetimedelayistheincreaseinthe timeittakesaparticletotravelthroughtheinteractionregionduetoitsinteractions. Lookforhighlyoscillatoryregionsinthesemilogplotof T(b),andonceyoufindsome, repeatthesimulationatafinerscalebysetting b‚âÉb‚àï10(thestructuresarefractals,as discussedinChapter14). 10) OK,nowgobackanddothisallagain,butwithanattractivepotentialthatmaynot wanttolettheprojectilegofree. 13.4 Projectile Motion with Drag Golfandbaseballplayersclaimthatballsappeartofalloutoftheskyattheendoftheirtra- jectories(sortoflikethesolidcurveinFigure13.4,whichwascomputedwiththeprogram ProjectileAir.py inListing13.3). Your problemis to determine whether there is a physics explanation for this effect, or whetheritis‚Äúallinthemind‚Äôseye.‚Äù Figure13.4showstheinitialvelocity V0andinclination ùúÉforaprojectilelaunchedfromthe origin.Ifweignoreairresistance,theprojectilehasonlytheforceofgravityactingonit,a Figure 13.4 The trajectories of a projectile Ô¨Åred with initial velocity V0in theùúÉdirection. The lower curve includes air resistance.V0Œ∏y RH xWith drag0 0 300 13 ODE Applications; Eigenvalues, Scattering, Trajectories constantacceleration ay=‚àíg=‚àí9.8m/s2,andthefamiliaranalyticsolutions: x(t)=V0cosùúÉt,y(t)=V0sinùúÉt‚àí1 2gt2, (13.32) ùë£x(t)=V0x,ùë£y(t)=V0y‚àígt, (13.33) y(x)=V0y V0xx‚àíg 2V2 0x. (13.34) Likewise,itiseasytoshowthattherange R=2V2 0sinùúÉcosùúÉ‚àïgandthemaximumheight H=1 2V2 0sin2ùúÉ‚àïg. Theparabola(13.34)forfrictionlessmotionissymmetricaboutitsmidpoint,whichdoes notresembleaballfallingoutofthesky.Toseeifairresistancewillchangethat,weinclude africtionalforce F(f)inNewton‚Äôssecondlaw: F(f)‚àímgÃÇey=md2x(t) dt2, (13.35) ‚áíF(f) x=md2x dt2,F(f) y‚àímg=md2y dt2. (13.36) Asamodelforwhatisreallymorecomplicated,weassumethatthefrictionalforceispro- portionaltosomepower noftheprojectile‚Äôsspeed[MarionandThornton,2019]: F(f)=‚àíkm|ùë£|nv |ùë£|, (13.37) wherethe ‚àív‚àï|ùë£|factorensuresthatthefrictionalforceisalwaysinadirectionopposite that of the velocity. Experiments indicate that the power nis noninteger and varies with velocity.Theequationsofmotionarethus d2x dt2=‚àíkùë£n xùë£x |ùë£|,d2y dt2=‚àíg‚àíkùë£n yùë£y |ùë£|,|ùë£|=‚àö ùë£2 x+ùë£2 y. (13.38) Orindynamicalform: dy(0) dt=y(1),dy(1) dt=1 mF(f) x(y) (13.39) dy(2) dt=y(3),dy(3) dt=1 mF(f) y(y)‚àíg, (13.40) f(0)=y(1),f(1)=1 mF(f) x,f(2)=y(3),f(3)=1 mF(f) y‚àíg. Consider three values for n, each of which represents a different model for the air resis- tance: (i)n=1 for low velocities; (ii) n=3‚àï2, for medium velocities; and (iii) n=2f o r highvelocities. 13.4.1 Assessment 1) Modifyyour rk4programsothatitsolvesthesimultaneousODEsforprojectilemotion (13.38)withfriction( n=1). 2) CheckthatyouobtaingraphssimilartothoseinFigure13.4. 3) Use(13.37)with n=1forlowvelocities, n=3‚àï2,formedium-velocities,and n=2for high-velocities.Adjustthevalueof kforthelattertwocasessuchthattheinitialforceof frictionkùë£n 0isthesameforallthreecases. 4) Whatisyourconclusionaboutballsfallingoutofthesky?",4062
13.6 Code Listings,"13.5 2- and 3-Body Planetary Orbits 301 13.5 2- and 3-Body Planetary Orbits 13.5.1 Planets via Two of Newton‚Äôs Laws Newton‚Äôsexplanationofthemotionoftheplanetsintermsofauniversallawofgravitation isoneofthegreatestachievementsofscience.Hewasabletoprovethatplanetstraveled inellipticalorbitswiththesunatonevertex,andthengoontopredicttheperiodsofthe motions.AllNewtonneededtodowasinventcalculusandpostulatethattheforcebetween aplanetofmass mandthesunofmass Mis Fg=‚àíGmM r2. (13.41) Hereris the planet-sun CM distance, Gis the universal gravitational constant, and the attractive force lies along the line connecting the planet and the sun (Figure 13.5 left). ThehardpartforNewtonwassolvingtheresultingdifferentialequations.Incontrast,the numericalsolutionisstraightforward.Evenforplanets,theequationofmotionisstill F=ma=md2x dt2. (13.42) InCartesiancomponents(Figure13.5): Fx=FgcosùúÉ=Fgx r=Fgx‚àö x2+y2, (13.43) Fy=FgsinùúÉ=Fgy r=Fgy‚àö x2+y2. (13.44) Theequationofmotion(13.42)isthustwosimultaneoussecond-orderODEs: d2x dt2=‚àíGMx (x2+y2)3‚àï2,d2y dt2=‚àíGMy (x2+y2)3‚àï2. (13.45) 1) Assumeunitssuchthat GM=1andtheinitialconditions x(0)=0.5,y(0)=0,ùë£x(0)=0.0,ùë£y(0)=1.63. (13.46) 2) ModifyyourODEsolverprogramtosolve(13.45). 3) Makesuretousesmallenoughtimestepstoachievehighprecision.Thenyoushould findthattheorbitsareclosedandfalluponthemselves. 4) Experimentwiththeinitialconditionsuntilyoufindtheonesthatproduceacircular orbit(aspecialcaseofanellipse). 5) Note the effect of progressively increasing the initial velocity until the orbits open up andtheplanetsbecomeunbound. y fy(x,y)fx f r xŒ∏Planet motion Figure 13.5 Left: The components of the gravitational force on a planet at a distance rfrom the sun. Right: The precession of a planet‚Äôs orbit for a gravitational force ‚àù1‚àïr4. 302 13 ODE Applications; Eigenvalues, Scattering, Trajectories 6) For the same initial conditions that produced the ellipse, investigate the effect of the powerin(13.41)being1 ‚àïr2+ùõºwithùõº‚â†0.Evenforsmallvaluesfor ùõº,youshouldfind thattheellipsesnowrotateorprecess(Figure13.5).(Asmallvaluefor ùõºispredictedby generalrelativity(Chapter19).) 13.5.2 The Discovery of Neptune TheplanetUranuswasdiscoveredin1781byWilliamHerschelandfoundtohaveanorbital periodofapproximately84years.Andyet,by1846,whenUranushadnotevencompleted afullorbitaroundthesun,somethingseemedwrong.ThiscouldbeexplainedifUranus was being perturbed by a yet-to-be-discovered planet lying about 50 percent further away from thesunthanUranus.TheplanetNeptunewasthusdiscoveredtheoreticallyandconfirmed experimentally.(IfPlutoisdiscardedasjustadwarfplanet,thenNeptuneisthemostdistant planetinthesolarsystem.) Assume that the orbitsof Neptune and Uranus are circular and coplanar,and that the initialangularpositionswithrespecttothe x-axisareasgiveninthistable: Mass Distance Orbitalperiod Angularposition (√ó10‚àí5Solarmasses) (AU) (Years) (in1690) Uranus 4.366244 19.1914 84.0110 ‚àº205.640 Neptune 5.151389 30.0611 164.7901 ‚àº288.380 Usethesedataandrk4tofindthevariationinangularpositionofUranuswithrespecttothe SunasaresultoftheinfluenceofNeptuneduringonecompleteorbitofNeptune.Consider Figure 13.6 A snapshot from the animated output of the code UranusNeptune.py showing: Left: The orbits of Uranus (inner circle) and of Neptune (outer circle) with the sun in the center. The arrows indicate the Uranus‚ÄìNeptune force that causes a perturbation in the orbits. Right:T h e perturbation in the angular position of Uranus as a function of time resulting from the presence of Neptune. 13.6 Code Listings 303 onlytheforcesoftheSunandNeptuneonUranus.Intheastronomicalunits, Ms=1and G=4ùúã2.Figure13.6showstheoutputofourprogramthatusedtheseconstants: G=4 ‚àópi‚àópi # AU, Msun=1 mu = 4.366244e ‚àí5 # Uranus mass 3M=1.0 #S u nm a s s mn = 5.151389e ‚àí5 # Neptune mass du = 19.1914 # Uranus Sun distance dn = 30.0611 # Neptune sun distance 7Tur = 84.0110 # Uranus Period Tnp = 164.7901 # Neptune Period omeur = 2 ‚àópi/Tur # Uranus angular velocity omennp = 2 ‚àópi/Tnp # Neptune angular velocity 11omreal = omeur urvel = 2 ‚àópi‚àódu/Tur # Uranus orbital velocity U A /yr npvel = 2 ‚àópi‚àódn/Tnp # Neptune orbital velocity UA/ yr radur = (205.64) ‚àópi/180. # in radians 15urx = du ‚àócos(radur) # init x Uranus in 1690 ury = du ‚àósin(radur) # init y Uranus in 1690 urvelx = urvel ‚àósin(radur) urvely = ‚àíurvel ‚àócos(radur) 19radnp = (288.38) ‚àópi/180.",4332
13.6 Code Listings,"# Neptune angular pos . 13.6 Code Listings Listing 13.1 QuantumNumerov.py Solvesthetime-independentSchr√∂dingerequation forbound-stateenergiesusingaNumerovmethod. 1# QuantumNumerov . py : Solve quantum bound s t a t e via Numerov algorithm # hbarc ‚àóomega=hbarc ‚àósqrt(k/ m )=19.733, r m c ‚àó‚àó2=940 MeV, k=9.4 # E =( N+1/2)hbarc ‚àóo m e g a = (N +1/2)19.733, N=0,2,4, change if N odd 5fromnumpyimport ‚àó importnumpy as np, matplotlib.pyplot as plt n = 1000; m= 2; imax = 100; Xleft0 = ‚àí10; Xright0 = 10; h = 0.02 9amin= 81.; amax = 92.; e = amin; de = 0.01; eps= 1e ‚àí4; im = 500 nl = im + 2; nr = n ‚àíim + 2; xmax = 5.0 print(\""nl, nr\"" ,nl, nr) print(h) 13xLeft = arange( ‚àí10,0.02,0.02); xRight = arange(10,0.02, ‚àí0.02) xp = arange( ‚àí10,10,0.02) # Bisection interval uL = zeros((503), float); uR = zeros([503], float) k2L = zeros([1000], float); k2R = zeros([1000], float) 17uL[0] = 0; uL[1] =0.00001; uR[0] = 0; uR[1] = 0.00001 defV(x): # Potential harmonic oscillator v=4 . 7 ‚àóx‚àóx 21returnv defsetk2(e): # Set k2L=(sqrt(e ‚àíV) ) ^2 , k2R foriin range (0,n): xLeft = Xleft0 + i ‚àóh 25 xr = Xright0 ‚àíi‚àóh fact=0.04829 #2 m ‚àóc‚àó‚àó2/hbarc ‚àó‚àó2 k2L[i] = fact ‚àó(e‚àíV(xLeft)) k2R[i] = fact ‚àó(e‚àíV(xr)) 29defNumerov (n,h,k2,u,e): setk2(e) b=(h ‚àó‚àó2)/12.0 #L&R wave functions foriin range (1,n): 33 u[i+1]=(2 ‚àóu[i] ‚àó(1‚àí5.‚àób‚àók2[i])‚àí(1+b ‚àók2[i‚àí1])‚àóu[i‚àí1])/(1+b ‚àók2[i+1]) defdiff(e): Numerov (nl ,h,k2L,uL,e) #L e f tw f Numerov (nr,h,k2R,uR,e) # Right wf 304 13 ODE Applications; Eigenvalues, Scattering, Trajectories 37f0 = (uR[nr ‚àí1] + uL[nl ‚àí1]‚àíuR[nr‚àí3]‚àíuL[nl‚àí3])/(h ‚àóuR[nr‚àí2]) returnf0 istep = 0 41x1 = arange( ‚àí10,.02,0.02); x2 = arange(10, ‚àí0.02,‚àí0.02) fig = plt.figure() ax = fig.add_subplot(111) ax.grid() 45while abs (diff(e)) > eps : # Bisection algorithm e =(amin + amax)/2 print(e,istep) ifdiff(e) ‚àódiff(amax) > 0: amax = e 49else:a m i n=e ax.clear() plt.text(3, ‚àí200, ‚ÄôEnergy=  percent10.4f‚Äô  percent(e),fontsize=14) plt.plot(x1,uL[: ‚àí2]) 53plt.plot(x2,uR[: ‚àí2]) plt.xlabel( ‚Äôx‚Äô) plt.ylabel( ‚Äôùúì(x)‚Äô,fontsize=18) plt.title( ‚ÄôR&L Wavefunctions Matched at x = 0‚Äô ) 57istep = istep+1 plt.pause(0.8) # Pause to delay figures plt .show() Listing 13.2 QuantumEigen.py Solvesthetime-independentSchr√∂dingerequationfor bound-stateenergiesusingtherk4algorithm. # QuantumEigen.py: Finds E and psi via rk4 + bisection 3#m / ( h b a r ‚àóc)‚àó‚àó2= 940 M e V/(197.33M e V ‚àífm)‚àó‚àó2 =0.4829, well width=20 fm # well depth 10 MeV, Wave function not normalized fromvisualimport ‚àó 7 psigr = display(x=0,y=0,width=600,height=300, title= ‚ÄôR&L Wavefunc‚Äô ) Lwf = curve(x= list(range(502)),color=color.red) Rwf = curve(x= list(range(997)),color=color.yellow) 11eps = 1E ‚àí3 # Precision n_steps = 501 E= ‚àí17.0 # E guess h = 0.04 15count_max = 100 Emax = 1.1 ‚àóE # E limits Emin = E/1.1 19deff(x, y, F,E): F[0] = y[1] F[1] = ‚àí(0.4829) ‚àó(E‚àíV(x)) ‚àóy[0] defV(x): 23if(abs(x)<10.):return(‚àí16.0) # Well depth else: return(0.) defrk4(t, y,h,Neqs,E): F= z e r o s ( ( N e q s ) , float) 27ydumb = zeros((Neqs) , float) k1 = zeros((Neqs) , float) k2 = zeros((Neqs) , float) k3 = zeros((Neqs) , float) 31k4 = zeros((Neqs) , float) f(t, y, F,E) foriin range (0,Neqs): k1[i] = h ‚àóF[i] 35 ydumb[i] = y[i] + k1[i]/2.",3158
13.6 Code Listings,"f(t +h/2., ydumb, F,E) foriin range (0,Neqs): k2[i] = h ‚àóF[i] 39 ydumb[i] = y[i] + k2[i]/2. f(t +h/2., ydumb, F,E) foriin range (0,Neqs): 13.6 Code Listings 305 k3[i]= h ‚àóF[i] 43 ydumb[i] = y[i] + k3[i] f(t +h, ydumb, F,E); foriin range (0,Neqs): k4[i]=h ‚àóF[i] 47 y[i]=y[i]+(k1[i]+2 ‚àó(k2[i]+k3[i])+k4[i])/6.0 defdiff(E, h): y=z e r o s( ( 2 ), float) i_match = n_steps//3 # Matching radius 51nL = i_match + 1 y [ 0 ]=1 . E ‚àí15; # Initial left w f y[1] = y[0] ‚àósqrt(‚àíE‚àó0.4829) forixin range (0,nL + 1): 55 x=h ‚àó(ix‚àín_steps/2) rk4(x, y, h, 2, E) left = y[1]/y[0] # Log derivative y [ 0 ]=1 . E ‚àí15; # slope for even; reverse for odd 59y[1] = ‚àíy[0] ‚àósqrt(‚àíE‚àó0.4829) # Initialize R w f forixin range (n_steps,nL+1, ‚àí1): x=h ‚àó(ix+1‚àín_steps/2) rk4(x, y, ‚àíh, 2, E) 63right = y[1]/y[0] # Log derivative return(( l e f t ‚àíright)/(left + right) ) defplot(E, h): # Repeat integrations for plot x=0 . 67n_steps = 1501 # # integration steps y=z e r o s( ( 2 ), float) yL = zeros((2,505), float) i_match = 500 # Matching point 71nL = i_match + 1; y [ 0 ]=1 . E ‚àí40 # Initial left w f y[1] = ‚àísqrt(‚àíE‚àó0.4829) ‚àóy[0] forixin range (0,nL+1): 75 yL[0][ix] = y[0] yL[1][ix] = y[1] x=h ‚àó(ix‚àín_steps/2) rk4(x, y, h, 2, E) 79y[0] = ‚àí1.E‚àí15 #‚àíslope : even ; reverse for odd y[1] = ‚àísqrt(‚àíE‚àó0.4829) ‚àóy[0] j=0 forixin range (n_steps ‚àí1,nL + 2, ‚àí1): # right wave function 83 x=h ‚àó(ix + 1 ‚àín_steps/2) # Integrate in rk4(x, y, ‚àíh, 2, E) Rwf.x[j] = 2. ‚àó(ix +1 ‚àín_steps/2) ‚àí500.0 Rwf.y[j] = y[0] ‚àó35e‚àí9 +200 87 j +=1 x=x‚àíh normL = y[0]/yL[0][nL] j=0 91 # Renormalize L wf &derivative forixin range (0,nL+1): x=h ‚àó(ix‚àín_steps/2 + 1) y[0] = yL[0][ix] ‚àónormL 95 y[1] = yL[1][ix] ‚àónormL Lwf.x[j] = 2. ‚àó(ix‚àín_steps/2+1) ‚àí500.0 Lwf.y[j] = y[0] ‚àó35e‚àí9+200 #F a c t o rf o rs c a l e j +=1 99forcountin range (0,count_max+1): rate(1) # Slow rate to show changes # Iteration loop E=( E m a x+E m i n )/ 2 . #D i v i d eEr a n g e 103Diff = diff(E, h) if(diff(Emax, h) ‚àóDiff > 0): Emax = E # Bisection algorithm else:E m i n = E if(abs(Diff) <eps ): break 107ifcount >3: # First iterates too irregular rate(4) plot(E, h) elabel = label(pos=(700, 400), text= ‚ÄôE=‚Äô,b o x = 0 ) 111elabel.text = ‚ÄôE= percent13.10f‚Äô  percentE ilabel = label(pos=(700, 600), text= ‚Äôistep=‚Äô ,b o x = 0 ) 306 13 ODE Applications; Eigenvalues, Scattering, Trajectories ilabel.text = ‚Äôistep= percent4s‚Äô  percentcount elabel = label(pos=(700, 400), text= ‚ÄôE=‚Äô,b o x = 0 ) # Last iteration 115elabel.text = ‚ÄôE= percent13.10f‚Äô  percentE ilabel = label(pos=(700, 600), text= ‚Äôistep=‚Äô ,b o x = 0 ) ilabel.text = ‚Äôistep= percent4s‚Äô  percentcount print(\""Final eigenvalue E = \"" ,E) 119print(\""iterations, max = \"" ,count) Listing 13.3 ProjectileAir.py Solvesforprojectilemotionwithairresistanceaswellas analyticallyforthefrictionlesscase. # ProjectileAir .py: Order dt^2 projectile trajectory + drag 3fromvisualimport ‚àó fromvisual.graph import ‚àó v0 = 22.; angle = 34.; g = 9.8; kf = 0.8; N= 5 7v0x = v0 ‚àócos(angle ‚àópi/180); v0y = v0 ‚àósin(angle ‚àópi/180) T=2 ‚àóv0y/g; H = v0y ‚àóv0y/2/g; R = 2 ‚àóv0x‚àóv0y/g graph1 = gdisplay(title= ‚ÄôProjectile with &without Drag‚Äô , xtitle= ‚Äôx‚Äô, ytitle= ‚Äôy‚Äô, xmax=R, xmin= ‚àíR/20.,ymax=8,ymin= ‚àí6.0) 11funct = gcurve(color=color.red) funct1 = gcurve(color=color.yellow) print(‚ÄôNo Drag T =‚Äô ,T,‚Äô, H =‚Äô,H,‚Äô, R =‚Äô,R) 15defplotNumeric(k): vx = v0 ‚àócos(angle ‚àópi/180.) vy = v0 ‚àósin(angle ‚àópi/180.) x=0 . 0 19y=0 . 0 dt = vy/g/N/2. print(\""  With Friction \"" ) print(\""x y \"" ) 23foriin range (N): rate(30) vx = vx ‚àík‚àóvx‚àódt vy = vy ‚àíg‚àódt‚àík‚àóvy‚àódt 27x=x+v x ‚àódt y=y+v y ‚àódt funct.plot(pos=(x,y)) print(\""  percent13.10f  percent13.10f \""  percent(x,y)) 31defplotAnalytic(): v0x = v0 ‚àócos(angle ‚àópi/180.) v0y = v0 ‚àósin(angle ‚àópi/180.) dt = 2. ‚àóv0y/g/N 35print(\""  No Friction \"" ) print(\""x y \"" ) foriin range (N): rate(30) 39 t=i ‚àódt x=v 0 x ‚àót y=v 0 y ‚àót‚àíg‚àót‚àót/2. funct1.plot(pos=(x,y)) 43 print(\""  percent13.10f  percent13.10f\""  percent(x ,y)) plotNumeric(kf) plotAnalytic()",3922
14.2 Growing Plants,"307 14 Fractals and Statistical Growth Models In this chapter we implement models that create fractals. We emphasize the simple underlying rules, the statistical aspects of the rules, and the meaning of self-similarity. To the extent that these models generate structures that look like those in nature, it is reasonable to assume that the natural processes may be following similar rules arising from some basic physics or biology . Itiscommontonoticeregularandeye-pleasingnaturalobjects,suchasplantsandsea shells,thatdonothavewell-definedgeometricpatterns.Whenanalyzedmathematically, someofthesepatternshaveadimensionthatisafractionalnumber.BenoitMandelbrot, whofirststudiedfractional-dimensionfigureswithsupercomputersatIBMResearch,gave themthename fractals[Mandelbrot,1982].Somegeometricobjects,suchasKochcurves, areexactfractalswiththesamedimensionforalltheirparts.Otherobjects,suchasbifur- cation curves of Chapter 15, are statistical fractals in which elements of randomness are mixedin,inwhichcasetheremaybedifferentdimensionsforeachpartoftheobject. Consideranabstractobjectsuchasthedensityofchargewithinanatom.Therearean infinitenumberofwaystodefinethe‚Äúsize‚Äùofthisobject.Forexample,eachmoment ‚ü®rn‚ü© isameasureofthesize,andthereisaninfinitenumberofmoments.Likewise,whenwe dealwithcomplicatedobjects,therearedifferentdefinitionsofdimension,andeachmay giveasomewhatdifferentvalue. TheHausdorff‚ÄìBesicovitch dimension df, is based on our knowledge that a line has dimension 1, a trianglehas dimension 2, anda cube has dimension 3. It seems perfectly reasonable, then, to take a mathematical formula that agrees with our experience with regularobjects,andapplyittoirregularobjects.Forsimplicity,letusconsiderobjectsthat have the same length Lon each side, as do equilateral triangles and squares, and that haveuniformdensity.Wepostulatethatthedimensionofanobjectisdeterminedbythe dependenceofitstotalmassuponitslength: M(L)‚àùLdf, (14.1) wherethepower dfisthefractaldimension .Asyoumayverify,thisruleworksforthe1D, 2D,and3Dfigureswearefamiliarwith,soitisareasonabletotryitelsewhere.When(14.1) isappliedtoirregularobjects,weendupwithfractionalvaluesfor df.Actually,wewillfind iteasiertodeterminethefractaldimension,notfromanobject‚Äôsmass,whichis extensive ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 308 14 Fractals and Statistical Growth Models (dependsonsize),butratherfromitsdensity,whichis intensive.Thedensityisdefinedas mass/lengthforalinearobject,mass/areaforaplanarobject,andmass/volumeforasolid object.Thatbeingthecase,foraplanarobjectwehypothesizethat ùúå=M(L) area‚àùLdf L2‚àùLdf‚àí2. (14.2) 14.1 The Sierpi¬¥ nski Gasket Togenerateourfirstfractal,showninFigure14.1,weplayagameofchanceinwhichwe placedotsatpointsplacedrandomlywithinatriangle[BundeandHavlin,1991].Hereare therules(whichyoushouldtryoutinthemarginsrightnow). 1) Drawanequilateraltrianglewithverticesandcoordinates: vertex1: (a1,b1);vertex2: (a2,b2);vertex3: (a3,b3). 2) Placeadotatarandompoint P=(x0,y0)withinthistriangle. 3) Findthenextpointbyselectingrandomlytheinteger1,2,or3: a) If1,placeadothalfwaybetween Pandvertex1. b) If2,placeadothalfwaybetween Pandvertex2. c) If3,placeadothalfwaybetween Pandvertex3. 4) Repeattheprocessusingthelastdotasthenew P. Mathematically,thecoordinatesofsuccessivepointsaregivenbytheformulas (xk+1,yk+1)=(xk,yk)+(an,bn) 2,n=integer(1+3ri), (14.3) whereriisarandomnumberbetween0and1,andwherethe integerfunctionoutputsthe closestintegersmallerthanorequaltotheargument.After15,000points,youshouldobtain acollectionofdotslikethoseontheleftinFigure14.1. 0100200300 0 100 200 30010,000 points A B C Figure 14.1 Left: The Sierpi¬¥ nski gasket, a statistical fractal containing 10,000 points. Note the self-similarity at different scales. Right: A geometric Sierpi¬¥ nski gasket constructed by successively connecting the midpoints of the sides of each equilateral triangle. The Ô¨Årst three steps in the process are labeled as A, B, and C. 14.1 The Sierpi¬¥ nski Gasket 309 Exercise Write a program to produce a Sierpi¬¥ nski gasket. Determine empirically the fractal dimension of your figure. Assume that each dot has mass 1 and that ùúå=CLùõº. (Youcanhavethecomputerdothecountingbydefininganarray boxofall0values,and thenbychanginga0toa1whenadotisplacedthere.) 14.1.1 Measuring Fractal Dimension The topology in Figure 14.1 was first analyzed by the Polish mathematician Sierpi¬¥ nski. Observethesamestructureoccursinasmallregionasoccursintheentirefigure.Inother words,ifthefigurehadinfiniteresolution,anypartofthefigurecouldbescaledupinsize, andwouldbesimilartothewhole.Thispropertyiscalled self-similarity . We construct a non-statistical form of the Sierpi¬¥ nski gasket by removing an inverted equilateral triangle from the center of all filled equilateral triangles (Figure 14.1 right). Thiscreatesthenextfiguretoworkon.Werepeattheprocessadinfinitum,scalingupthe trianglessoeachonehasside r=1aftereachstep.Toseewhatisunusualaboutthistype ofobject,welookathowitsdensity(mass/area)changeswithsize,andthenapply(14.2) todetermineitsfractaldimension.Assumethateachtrianglehasmass mandassignunit densitytothesingletriangle: ùúå(L=r)‚àùM r2=m r2def=ùúå0(Figure14.1A) . (14.4) Now,fortheequilateraltrianglewithside L=2,thedensityis ùúå(L=2r)‚àù(M=3m) (2r)2=3 4mr2=3 4ùúå0(Figure14.1B) . (14.5) We see that the extra white space in Figure 14.1B leads to a density that is3 4that of the previousstage.ForthestructureinFigure14.1C,weobtain ùúå(L=4r)‚àù(M=9m) (4r)2=9 16m r2=(3 4)2 ùúå0.(Figure14.1C) . (14.6) Weseethataswecontinuetheconstructionprocess,thedensityofeachnewstructureis3 4 thatofthepreviousone.Interesting.Yetin(14.2)wederivedthat ùúå‚àùCLdf‚àí2. (14.7) Equation(14.7)impliesthataplotofthelogarithmofthedensity ùúåversusthelogarithmof thelengthLforsuccessivestructuresyieldsastraightlineofslope df‚àí2=Œîlogùúå ŒîlogL. (14.8) Asappliedtoourproblem, df=2+Œîlogùúå(L) ŒîlogL=2+log1‚àílog3 4 log1‚àílog2‚âÉ1.58496. (14.9) AsisevidentinFigure14.1,asthegasketgrowslarger(andconsequentlymoremassive), itcontainsmoreopenspace.Sodespitethefactthatitsmassapproachesinfinityas L‚Üí‚àû, itsdensityapproacheszero.BecausetheSierpi¬¥ nskigaskethasaslope df‚àí2‚âÉ‚àí0.41504,it fillsspacetoalesserextentthana2Dobject,butmorethana1Dobject;itisafractalwith dimensionof ‚àº1.6.",6299
14.2.3 SelfAffine Trees,"310 14 Fractals and Statistical Growth Models 14.2 Growing Plants Itseemsparadoxicalthatnaturalprocessessubjecttochancecanproduceobjectsofsuch high regularity, symmetry, and beauty. For example, it is hard to believe that something as graceful as a fern (Figure 14.2 left) has random elements in it. Nonetheless, there is a clue here that much of the fern‚Äôs beauty arises from the similarity of each part to the whole(self-similarity),withdifferentfernssimilar,butnotidenticaltoeachother.These areallcharacteristicsoffractals.Your problemistodiscoverifasimplealgorithmincluding somerandomnesscandrawregularferns.Ifthealgorithmproducesobjectsthatresemble ferns,then,presumably,youhaveuncoveredsomeunderlyingmathematicssimilartothose responsiblefortheshapesofferns. 14.2.1 Self-AfÔ¨Åne Connection In(14.3),whichdefinesmathematicallyhowaSierpi¬¥ nskigasketisconstructed,a scaling factorof1 2ispartoftherelationofonepointtothenext.Amoregeneraltransformationof apointP=(x,y)intoanotherpoint P‚Ä≤=(x‚Ä≤,y‚Ä≤)viascalingis (x‚Ä≤,y‚Ä≤)=s(x,y)=(sx,sy)(scaling). (14.10) Ifthescalefactor s>0,anamplificationoccurs,whereasif s<0,areductionoccurs.Inour definition(14.3)oftheSierpi¬¥ nskigasket,wealsoaddedinaconstant an.Thisisatranslation operationofthegeneralform (x‚Ä≤,y‚Ä≤)=(x,y)+(ax,ay)(translation). (14.11) Anotheroperation,notusedintheSierpi¬¥ nskigasket,isa rotationbyangle ùúÉ: x‚Ä≤=xcosùúÉ‚àíysinùúÉ,y‚Ä≤=xsinùúÉ+ycosùúÉ(rotation). (14.12) This entire set of transformations, scalings, rotations, and translations, defines an affine transformation (affine denotes a close relation between successive points). The Figure 14.2 Left: A fractal fern generated by 30,000 iterations of the algorithm (14.13). Enlarging this fern shows that each frond has a similar structure. Right: A fractal tree created with the algorithm (14.16). 14.2 Growing Plants 311 transformation is still considered affine even if there are contractions and reflections. What is important is that the object created with these rules turns out to be self-similar; eachstepleadstonewpartsoftheobjectthatbearthesamerelationtotheancestorparts astheancestorsdidtotheirs.Thisiswhatmakestheobjectlooksimilaratallscales. 14.2.2 Barnsley‚Äôs Fern WeobtainaBarnsley‚Äôsfern[BarnsleyandHurd,1992]byextendingthedotsgametoone in which new points are selected using an affine connection, but with some elements of chancemixedin: (x,y)n+1=‚éß ‚é™ ‚é™ ‚é™ ‚é™ ‚é™ ‚é® ‚é™ ‚é™ ‚é™ ‚é™ ‚é™‚é©(0.5,0.27yn), with2 percentprobability , (‚àí0.139xn+0.263yn+0.57 0.246xn+0.224yn‚àí0.036),with15 percentprobability , (0.17xn‚àí0.215yn+0.408 0.222xn+0.176yn+0.0893),with13 percentprobability , (0.781xn+0.034yn+0.1075 ‚àí0.032xn+0.739yn+0.27),with70 percentprobability.(14.13) To select a transformation with probability Óàº, we select a uniform random number 0‚â§r‚â§1,andthenperformthetransformationif risinarangeproportionalto Óàº: Óàº=‚éß ‚é™ ‚é™ ‚é® ‚é™ ‚é™‚é©2 percent,r<0.02, 15 percent,0.02‚â§r‚â§0.17, 13 percent,0.17<r‚â§0.3, 70 percent,0.3<r<1.(14.14) Therules(14.13)and(14.14)canbecombinedintoone: (x,y)n+1=‚éß ‚é™ ‚é™ ‚é™ ‚é™ ‚é™ ‚é® ‚é™ ‚é™ ‚é™ ‚é™ ‚é™‚é©(0.5,0.27yn), r<0.02, (‚àí0.139xn+0.263yn+0.57 0.246xn+0.224yn‚àí0.036),0.02‚â§r‚â§0.17, (0.17xn‚àí0.215yn+0.408 0.222xn+0.176yn+0.0893),0.17<r‚â§0.3, (0.781xn+0.034yn+0.1075, ‚àí0.032xn+0.739yn+0.27),0.3<r<1.(14.15) Although(14.13)makesthebasicideaclearer(14.15),iseasiertoprogram. ThestartingpointinBarnsley‚Äôsfern(Figure14.2)is (x1,y1)=(0.5,0.0),andthepointsare generatedbyrepeatediterations.Animportantpropertyofthisfernisthatitisnotcom- pletely self-similar, as you can see by noting how different are the stems and the fronds. Nevertheless, the stem can be viewed as a compressed copy of a frond, and the fractal obtainedwith(14.13)isstill self-affine,yetwithadimensionthatvariesfromparttopartof thefern.Ourcode Fern3D.pyisgiveninListing14.1.",3716
14.4.2 Coastline Exercise,"312 14 Fractals and Statistical Growth Models 14.2.3 Self-AfÔ¨Åne Trees Nowthatyouknowhowtogrowferns,lookaroundandnoticetheregularityintrees(such as in Figure 14.2 right). Can it be that this also arises from a self-affine structure? Write a program, similar to the one for the fern, starting at (x1,y1)=(0.5,0.0), and iterate the followingself-affinetransformation: (xn+1,yn+1)=‚éß ‚é™ ‚é™ ‚é™ ‚é™ ‚é™ ‚é® ‚é™ ‚é™ ‚é™ ‚é™ ‚é™‚é©(0.05xn,0.6yn), 10 percentprobability , (0.05xn,‚àí0.5yn+1.0), 10 percentprobability , (0.46xn‚àí0.15yn,0.39xn+0.38yn+0.6),20 percentprobability , (0.47xn‚àí0.15yn,0.17xn+0.42yn+1.1),20 percentprobability , (0.43xn+0.28yn,‚àí0.25xn+0.45yn+1.0),20 percentprobability , (0.42xn+0.26yn,‚àí0.35xn+0.31yn+0.7),20 percentprobability .(14.16) 14.3 Ballistic Deposition There are a number of natural and manufacturing processes in which particles are depositedonasurfaceandformafilm.Iftheparticlesareevaporatedfromahotfilament, there would be a randomness in the emission process, even though the produced films seem quite regular. Again we suspect fractals. Your problemis to develop a model that simulatesthisgrowthprocess,andcompareyourproducedstructurestothoseobserved. TheideaofsimulatingrandomdepositionswasfirstreportedinVold[1959]intheirsimu- lationofthesedimentationofmoistspheresinhydrocarbons.WeshallexamineFamilyand Vicsek[1985]‚ÄôsmethodofsimulationthatresultsinthedepositionshowninFigure14.3. 200 100 00100200 Length Surface height Figure 14.3 A simulation of the ballistic deposition of 20,000 particles onto a substrate of length 200. The vertical height increases in proportion to the length of deposition time, with the top being the Ô¨Ånal surface. 14.4 Length of British Coastline 313 Considerparticlesfallingonto,andstickingto,ahorizontallineoflength Lcomposedof 200depositionsites.Allparticlesstartfromthesameheight,buttosimulatetheirdifferent emissionvelocities,weassumetheystartatrandomdistancesfromtheleftsideoftheline. Thesimulationconsistsofgeneratinguniformrandomsitesbetween0and L,andhaving aparticlesticktothesiteonwhichitlands.Seeingthatthephysicalsituationwouldhave columnsofaggregatesofdifferentheights,theparticlemaybestoppedbeforeitgetstoa line,oritmaybouncearoundandfallintoahole.Wethereforeassumethatifthecolumn heightatwhichtheparticlelandsisgreaterthanthatofbothitsneighbors,itwilladdto thatheight.Iftheparticlelandsinahole,orifthereisanadjacenthole,itwillfillupthe hole.Wespeedupthesimulationbysettingtheheightoftheholeequaltothemaximum ofitsneighbors.Herearethesteps: 1) Choosearandomsite r. 2) Letthearray hrbetheheightofthecolumnatsite r. 3) Makethedecision: hr={ hr+1, ifhr‚â•hr‚àí1,hr>hr+1, max[hr‚àí1,hr+1],ifhr<hr‚àí1,hr<hr+1.(14.17) Theessentialloopinthesimulationis: spot =int(random) if(spot == 0) if( coast[spot] < coast[spot+1] ) 4 coast[spot] = coast[spot+1]; elsecoast[spot]++; else if ( spot == coast.length ‚àí1) if( coast[spot] < coast[spot ‚àí1] ) coast[spot] = coast[spot ‚àí1]; 8 elsecoast[spot]++; else if ( coast[spot]<coast[spot ‚àí1] && coast[spot]<coast[spot+1] ) if(c o a s t [ s p o t ‚àí1] > coast[spot+1] ) coast[spot] = coast[spot ‚àí1]; elsecoast[spot] = coast[spot+1]; 12elsecoast[spot]++; The results of this simulation show several empty regions scattered throughout the line (Figure14.3),whichisanindicationofthestatisticalnatureofgrowingfilms.Simulations byFereydoonproducedfractalsurfacesthatreproducedtheexperimentalobservationthat theaverageheightincreaseslinearlywithtime.(Youwillbeaskedtodeterminethefractal dimensionofasimilarsurfaceasanexercise.) Exercise Extendthesimulationofrandomdepositiontotwodimensions,soratherthan makingalineofparticlesyounowdeposituponanentiresurface.",3619
14.4.2 Coastline Exercise,"14.4 Length of British Coastline In 1967 Benoit Mandelbrot asked a classic question, ‚ÄúHow long is the coast of Britain?‚Äù [Mandelbrot,1967].IfBritainhadtheshapeofColoradoorWyoming,bothofwhichhave straight-lineboundaries,itsperimeterwouldbeacurveofdimension1withfinitelength. However, coastlines are geographic, and not geometric curves, with each portion of the coastappearingsomewhatself-similartotheentirecoast.Iftheperimeterofthecoastis, 314 14 Fractals and Statistical Growth Models infact,afractal,thenitslengthiseitherinfiniteormeaningless.Mandelbrotdeducedthe dimensionofthewestcoastofBritaintobe df=1.25,whichimpliesinfinitelength.Inyour problem,weaskyoutodeterminethedimensionoftheperimeterofoneofyourfractal simulations. Thelengthofthecoastlineofanislandistheperimeterofthatisland.Whiletheconcept ofperimeterisclearforgeometricfigures,somethoughtisrequiredtogiveitmeaningfor anobjectthatmaybeinfinitelyself-similar.Letusassumethatamapmakerhasarulerof lengthr.Ifshewalksalongthecoastlineandcountsthenumberoftimes Nthatshemust placetherulerdowninorderto coverthecoastline,shewillobtainavalueforthelength L ofthecoastas Nr.Imaginenowthatthemapmakerkeepsrepeatingherwalkwithsmaller andsmallerrulers.Ifthecoastwereageometricfigure,ora rectifiablecurve ,atsomepoint thelength Lwouldbecomeessentiallyindependentof randwouldapproachaconstant. Nonetheless,asdiscoveredempiricallybyRichardson[1961]fornaturalcoastlines,suchas thoseofSouthAfricaandBritain,theperimeterappearstobeanunusualfunctionof r: L(r)‚âÉMr1‚àídf, (14.18) whereManddfare empirical constants. For a geometric figure, or for Colorado, df=1, andthelengthapproachesaconstantas r‚Üí0.Yetforafractalwith df>1,theperimeter L‚Üí‚àûasr‚Üí0.Thismeansthatasaconsequenceofself-similarity,fractalsmaybeoffinite size,buthaveinfiniteperimeters.Physically,atsomepoint,theremaybenomoredetails todiscernas r‚Üí0(say,atthequantumorComptonsizelimit),andsothelimitmaynot bephysicallymeaningful. 14.4.1 Box Counting Algorithm Consideralineoflength Lbrokenupintosegmentsoflength r(Figure14.4left).Thenum- berofsegmentsor‚Äúboxes‚Äùneededtocoverthelineisrelatedtothesize roftheboxby N(r)=L r=C r, (14.19) whereCis a constant. One definition of fractional dimension is the power of rin this expression as r‚Üí0. In our example, it tells us that the line has dimension df=1.If we nowaskhowmanylittlecirclesofradius ritwouldtaketo coverorfillacircleofarea A (Figure14.4middle),wewillfindthat N(r)=lim r‚Üí0A ùúãr2‚áídf=2, (14.20) asexpected.Likewise,countingthenumberoflittlespheresorcubesthatcanbepacked withinalargespheretellsusthataspherehasdimension df=3.Ingeneral,ifittakes N littlespheresorcubesofside r‚Üí0tocoversomeobject,thenthefractaldimension dfcan bededucedas N(r)=C(1 r)df=C‚Ä≤sdf(asr‚Üí0), (14.21) logN(r)=logC‚àídflog(r)(asr‚Üí0), (14.22) ‚áídf=‚àílim r‚Üí0ŒîlogN(r) Œîlogr. (14.23) 14.4 Length of British Coastline 315 Heres‚àù1‚àïriscalledthe scaleingeography,so r‚Üí0correspondstoaninfinitescale.To illustrate,youmaybefamiliarwiththelowscaleonamapbeing10,000mtoacentimeter, while the high scale is 100 m to a centimeter. If we want the map to show small details (sizes),weneedamapofhighscale.",3103
14.4.2 Coastline Exercise,"Forthecoastlineproblem,we‚Äôlluseboxcountingtodeterminethedimensionofaperime- ter,andnotofanentirefigure.Oncewehaveavalueforthedimension,wewillgoonand determinethelengthoftheperimetervia(14.18). 14.4.2 Coastline Exercise Ratherthanruinyoureyesfocusingonageographicmap,wesuggestusingsomethingat handthatlookslikeanaturalcoastline,namely,thetopportionofFigure14.3.Determine dfbycoveringthisfigure,oroneyouhavegenerated,withasemitransparentpieceofgraph paper,1andcountingthenumberofboxescontaininganypartofthecoastline(Figures14.4 and14.5). 1) Printyourcoastlinegraphwiththesamephysicalscale( aspectratio )fortheverticaland horizontalaxes.Thisisrequiredbecausethegraphpaperyouwilluseforboxcounting hassquareboxesandsoyouwantyourgraphtoalsohavethesameverticalandhorizon- talscales.Placeapieceofgraphpaperoveryourprintoutandlookthroughthegraph paper at your coastline. If you do not have a piece of graph paper available, or if you areunabletoobtainaprintoutwiththesameaspectratioforthehorizontalandvertical axes,addaseriesofcloselyspacedhorizontalandverticallinestoyourcoastlineprintout 2r 80 40 0040100 Figure 14.4 Examples of the use of box counting to determine fractal dimension. In the top left the ‚Äúboxes‚Äù are circles and the perimeter is being covered. In the bottom left an entire Ô¨Ågure is being covered, and on the right a ‚Äúcoastline‚Äù is being covered by boxes of two different sizes (scales). The fractal dimension can be deduced by recording the number of boxes of different scales needed to cover the Ô¨Ågures. 1 Yes,wearesuggestingapainfullyanalogtechniquebasedonthetheorythattraumaleavesalasting impression.Ifyouprefer,youcanstoreyouroutputasamatrixof1and0values,andletthecomputerdo thecounting,butthiswilltakemoreofyourtimethanbeinganalog. 316 14 Fractals and Statistical Growth Models Square ( m = 2.00) Coastline ( m = 1.3) Straight line ( m = 1.02) log(scale)0510 ‚Äì3.5 ‚Äì4 ‚Äì3 ‚Äì2.5 ‚Äì2 ‚Äì1.5 ‚Äì1log(Number boxes) Figure 14.5 Fractal dimensions of a line, box, and coastline determined by box counting. The slope at vanishingly small scale determines the dimension. andusetheselinesasyourgraphpaper.(Boxcountingshouldstillbeaccurateifboth yourcoastlineandyourgraphpaperhavethesameaspectratios.) 2) Theverticalheightinourprintoutwas17cm,andthelargestdivisiononourgraphpaper was1cm.Thissetsthescaleofthegraphas1:17,or s=17forthelargestdivisions(lowest scale).Measuretheverticalheightofyourfractal,compareittothesizeofthebiggest boxesonwhateveryouareusingasyourpieceofgraphpaper,andthusdetermineyour lowestscale. 3) Withourlargestboxesof1 √ó1cm,wefoundthatthecoastlinepassedthrough N=24 boxes,thatis,24largeboxescoveredthecoastlineat s=17.Determinehowmanyofthe largestboxes(lowestscale)areneededtocoveryourcoastline. 4) Withournextsmallerboxesof0.5 √ó0.5cm,wefoundthat51boxescoveredthecoastline at a scale of s=34. Determine how many of the midsize boxes (midrange scale) are neededtocoveryourcoastline. 5) Withoursmallestboxesof1 √ó1mm,wefoundthat406boxescoveredthecoastlineata scaleofs=170.Determinehowmanyofthesmallestboxes(highestscale)areneeded tocoveryourcoastline. 6) Equation(14.23)tellsusthatastheboxsizesgetprogressivelysmaller,wehave logN‚âÉlogA+dflogs, (14.24) ‚áídf‚âÉŒîlogN Œîlogs=logN2‚àílogN1 logs2‚àílogs1=log(N2‚àïN1) log(s2‚àïs1). (14.25) Clearly,onlytherelativescalesmatterbecausetheproportionalityconstantscancelout intheratio.Aplotoflog Nversuslogsshouldyieldastraightlinewithaslopeof df(1.23 forus).Determinethefractaldimensionforyourcoastline.Althoughonlytwopoints areneededtodeterminetheslope,useyourlowestscalepointasanimportantcheck. (Becausethefractaldimensionisdefinedasalimitforinfinitesimalboxsizes,thehighest scalepointsaremostsignificant.) 7) Using(14.18),wefindthatthelengthofourcoastlineforour svalueis L‚àùs1.23‚àí1=s0.23. (14.26) Ifwekeepmakingtheboxessmallerandsmaller,sothatwearelookingatthecoastline athigherandhigherscale, andifthecoastlineisself-similaratalllevels,thenthescale",3897
14.7 Fractals in Bifurcations,"14.5 Correlated Growth 317 swillkeepgettinglargerandlargerwithnolimits(oratleastuntilwegetdowntosome quantumlimitonsmallsizes),andthus L‚àùlim s‚Üí‚àûs0.23=‚àû. (14.27) Doesyourfractalimplyaninfinitecoastline?Doesitmakesensethatasmallislandlike Britain,whichyoucanwalkaround,hasaninfiniteperimeter? 14.5 Correlated Growth It is an empirical fact that there is increased likelihood that a plant will grow if there is another one nearby (Figure 14.6 left). This type of correlation also seems to occur in the depositionofsurfacefilms.Your problemistoincludecorrelationsinyoursurfacesimu- lationandobservethechangeitmakes. A variation of the ballistic deposition, known as the correlated ballistic deposition , simulates mineral deposition onto substrates on which dendrites form [Tait et al., 1990; Sanderetal.,1994].Weextendtheballisticdepositionalgorithmtoincludethelikelihood that a freshly deposited particle will attract another particle. The extension is to assume that the probability of sticking Óàºdepends inversely on the distance dthat the added particleisfromthelastone(Figure14.6right): Óàº=cd‚àíùúÇ. (14.28) HereùúÇisaparameterand cisaconstantthatsetstheprobabilityscale.2Forourimplemen- tationwechoose ùúÇ=2,whichmeansthatthereisaninversesquareattractionbetweenthe particles(decreasedprobabilityastheygetfartherapart). As in our study of uncorrelated deposition, a uniform random number in the interval [0,L]determinesthecolumninwhichtheparticlewillbedeposited.Weusethesamerules i i + 1 d Figure 14.6 Left: A view of what might be the undergrowth of a forest or dendrites formed during surface deposition. Right: The probability of particle i+1 sticking in one column depends upon the distance dfrom the previously deposited particle i. 2 Theabsoluteprobability,ofcourse,mustbelessthanone,butitisnicetochoose csothattherelative probabilitiesproduceagraphwitheasilyseenvariations. 318 14 Fractals and Statistical Growth Models abouttheheightsasbefore,butnowasecondrandomnumberisusedinconjunctionwith (14.28)todecideiftheparticlewillstick. Forinstance,ifthecomputedprobabilityis0.6 andifr<0.6,theparticlewillbeaccepted(sticks),if r>0.6,theparticlewillberejected. Ourcode Column.pyisgiveninListing14.2. 14.6 Diffusion-Limited Aggregation Considerabunchofgrapesonanoverheadvine.Your problemistocreateamodelofhow itstantalizingshapemightarise.Inaflashofdivineinsight,yourealizethattheseshapes,as wellasothers,suchasthoseofcolloidsandthin-filmstructures,mayresultfromanaggrega- tionprocesswithparticlesdiffusingaroundeachother.Infact,amodelofdiffusion-limited aggregation (DLA) has successfully explained the relation between a cluster‚Äôs perimeter andmass[WittenandSander,1981]. Exercise Followthesestepstoconstructyourmodel: 1) Definea2Dlatticeofpointsrepresentedbythearray grid[400,400] ,withallelements initiallyzero. 2) Placeaseedparticleatthecenterofthelatticebysetting grid[199,199] = 1 . 3) Imagine a circle of radius 180 lattice spacings centered at grid[199,199] . This is the circlefromwhichyoureleaseparticles. 4) Determinetheangularlocationonthecircle‚Äôscircumferencefromwhichtoreleasea particlebygeneratingauniformrandomanglebetween0and2 ùúã. 5) Youareabouttoreleaseanewparticle,andhaveitexecutearandomwalk,muchlike theonewestudiedinChapter4,butrestrictedtoverticalorhorizontaljumpsbetween latticesites: a) Generateauniformrandomnumber0 <rxy<1. b) ifrxy<0.5,themotionwillbevertical. c) ifrxy‚â•0.5,themotionwillbehorizontal. 6) Make the model more realistic by letting the length of each step vary according to a randomGaussiandistribution.GenerateaGaussian-weightedrandomnumberinthe interval[‚àí‚àû,‚àû].Thisisthesizeofthestep,withthesignindicatingdirection.( Hint: ThesumofauniformrandomdistributionprovidesaGaussiandistribution.) 7) Wenowknowthetotaldistanceanddirectiontheparticlewilltravel.Haveitjumpone latticespacingatatimeuntilthistotaldistanceiscovered. 8) Beforeajump,checkwhetheranearest-neighborsiteisoccupied: a) Ifoccupied,theparticlessticktogetherandstayinthatposition.Thewalkforthat particleisover. b) Ifthesiteisunoccupied,theparticlejumpsonelatticespacing. 9) Continuethecheckingandjumpinguntilthecalculateddistanceiscovered,untilthe particlesticks,oruntilitleavesthecircleandislostfromourgrip. 10) Onceonerandomwalkisover,releaseanotherparticle,andrepeattheprocessasoften as desired. Because many particles are lost, you may need to generate hundreds of thousandsofparticlestoformaclusterofseveralhundredparticles.Yourresultsshould looklikeFigure14.7. 14.6 Diffusion-Limited Aggregation 319 Figure 14.7 A globular cluster of particles of the type that might occur in a colloid. Figure 14.8 Number 8 by the American painter Jackson Pollock. (Used with permission State University of New York.) Some researchers claim that Pollock‚Äôs paintings exhibit a characteristic fractal structure, while some others question this [Kennedy, 2006]. 14.6.1 Fractal of DLA or Pollock AclustergeneratedwiththeDLAtechniqueisshowninFigure14.7.Wewishtoanalyzeit toseeifthestructureisafractal,and,ifso,todetermineitsdimension.(Asanalternative, youmayanalyzethefractalnatureofthePollockpaintinginFigure14.8,atechniqueused to determine the authenticity of this sort of art.) As a control, simultaneously analyze a geometricfigure,suchasasquareorcircle,whosedimensionisknown.Theanalysisisa variationoftheoneusedtodeterminethelengthofthecoastlineofBritain. 1) Ifyouhavenotalreadydoneso,usethebox-countingmethodtodeterminethefractal dimensionofasimplesquare. 2) Drawasquareoflength L,smallrelativetothesizeofthecluster,aroundtheseedpar- ticle.(Smallmightbesevenlatticespacingstoaside.) 3) Countthenumberofparticleswithinthesquare. 4) Compute the particle density ùúåby dividing the number of particles by the number of sitesavailableinthebox(49inourexample). 5) Repeattheprocedureusinglargerandlargersquares.",5787
14.9 Perlin Noise Adds Realism,"320 14 Fractals and Statistical Growth Models 6) Stopwhentheclusteriscovered. 7) Thefractaldimension dfisestimatedfromalog-logplotofthedensity ùúåversusL.Ifthe clusterisafractal,then(14.2)tellsusthat ùúå‚àùLdf‚àí2,andthegraphshouldbeastraight lineofslope df‚àí2. Thegraphwegeneratedhadaslopeof ‚àí0.36,whichcorrespondstoafractaldimensionof 1.66.Seeingthatrandomnumbersareinvolved,thegraphyougeneratewillbedifferent, butthefractaldimensionshouldbesimilar.(Actually,thestructureismultifractal,andso thedimensionalsovarieswithlocationinthecluster.) 14.7 Fractals in Bifurcations Inthenextchapterthereisaprojectinvolvingthelogisticsmapwhereweplotthevalues ofthenumberofbugs versusthegrowthparameter ùúá.Takeoneofthebifurcationgraphs producedthereanddeterminethefractaldimensionofdifferentpartsofthegraphbyusing thesametechniquethatwasappliedtothecoastlineofBritain. 14.8 Cellular Automata Fractals There is a class of statistical models known as cellular automata that produce complex behaviorsfromverysimplerules.CellularautomataweredevelopedbyvonNeumannand Ulam in the early 1940s (von Neumann was also working on the theory behind modern computersthen).Thoughverysimple,cellularautomatahavefoundapplicationsinmany branches of science [Peitgen et al., 1994; Sipper, 1997]. Their definition [Barnsley and Hurd,1992]: Acellularautomatonisadiscretedynamicalsysteminwhichspace,time,andthestates ofthesystemarediscrete.Eachpointinaregularspatiallattice,calledacell,canhave anyoneofafinitenumberofstates,andthestatesofthecellsinthelatticeareupdated accordingtoalocalrule.Thatis,thestateofacellatagiventimedependsonlyonits ownstateonetimesteppreviously,andthestatesofitsnearbyneighborsattheprevious timestep.Allcellsonthelatticeareupdatedsynchronously,andsothestateoftheentice latticeadvancesindiscretetimesteps . Acellularautomatonintwodimensionsconsistsofanumberofsquarecellsthatgrowupon eachother.Afamousoneis Conway‚ÄôsGameofLife .Inthis,cellswithvalue1arealive,while cellswithvalue0aredead.Cellsgrowaccordingtotherules: 1) Ifacellisalive,andiftwoorthreeofitseightneighborsarealive,thenthecellremains alive. 2) Ifacellisalive,andifmorethanthreeofitseightneighborsarealive,thenthecelldies duetoovercrowding. 3) Ifacellisalive,andonlyoneofitseightneighborsisalive,thenthecelldiesofloneliness. 4) Ifacellisdead,andmorethanthreeofitsneighborsarealive,thenthecellrevives. 14.9 Perlin Noise Adds Realism ‚äô321 Figure 14.9 The rules for two versions of the Game of Life. The rules, given graphically on the top row, create the gaskets below. Our code Gameoflife.py is given in Listing 14.3. Early studies of the statistical mechanics of cellular automata were made by Wolfram [1983],whoindicatedhowonecanbeusedtogenerateaSierpi¬¥ nskigasket.Becausewehave alreadyseenthataSierpi¬¥ nskigasketexhibitsfractalgeometry(Section14.1),thisrepresents amicroscopicmodelofhowfractalsmayoccurinnature.Thismodeluseseightrules,given graphically at the top of Figure 14.9, to generate new cells from old. We see all possible configurationsforthreecellsinthetoprow,andthebegettednextgenerationintherow below.AtthebottomofFigure14.9,aSierpi¬¥ nskigasketissogenerated. 14.9 Perlin Noise Adds Realism ‚äô Wehaveseenhowstatisticalfractalsareabletogenerateobjectswithastrikingresemblance tothoseinnature.Thisappearanceofrealismmaybefurtherenhancedbyincludingatype ofcoherentrandomnessknownas Perlinnoise .ThistechniquewasdevelopedbyKenPerlin of New York University, who won an Academy Award (an Oscar) in 1997 for it and has continuedtoimproveitPerlin[2023].Thistypeofcoherentnoisehasfounduseinimpor- tantphysicssimulationsofstochasticmedia[Tickner,2004],aswellasinvideogames,and motionpictureslike Tron. TheinclusionofPerlinnoiseinasimulationaddsbothrandomnessandatypeofcoher- ence among points in space that tends to make dense regions denser and sparse regions sparser.Thisissimilartoourcorrelatedballisticdepositionsimulations(Section14.3),and isrelatedtochaosinitslong-rangerandomnesswithshort-rangecorrelations.Westartwith someknownfunctionsof xandy,andaddnoisetothem.Forthispurpose,Perlinusedthe mappingor easefunction(Figure14.12right) f(p)=3p2‚àí2p3. (14.29) AsaconsequenceofitsSshape,thismappingmakesregionscloseto0,evencloserto0, whilemakingregionscloseto1,evencloserto1(inotherwords,itincreasesthetendency toclump,whichshowsupashighercontrast).Wethenbreakspaceupintoauniformrect- angulargridofpoints(Figure14.10),andconsiderapoint (x,y)withinasquarewithvertices 322 14 Fractals and Statistical Growth Models (x0, y1) (x0, y0)(x1, y1) (x1, y0)(x, y) Figure 14.10 The coordinates used in adding Perlin noise. The rectangular grid is used to locate a square in space and a corresponding point within the square. As shown with the arrows, unit vectors giwith random orientation are assigned at each grid point. (x, y)(x0, y1) (x0, y0) (x1, y0)(x1, y1) g1g2g3 g0p3p2 p0 p1 Figure 14.11 The coordinates used in adding Perlin noise. A point within each square is located by drawing the four pi.T h egiv e c t o r sa r et h es a m ea so nt h el e f t . (x0, y1) (x0, y0)(x1, y0)(x1, y1) (x, y) stuv 0.20.2 0.40.4 0.60.6 0.80.8 113p2 ‚Äì 2p3 p Figure 14.12 The mapping used in adding Perlin noise. Left: The numbers s,t,u, andùë£are represented by perpendiculars to the four vertices, with lengths proportional to their values. Right: The function 3 p2‚àí2p3is used as a map of the noise at a point like ( x,y) to others close by.",5370
14.10 Code Listings,"14.9 Perlin Noise Adds Realism ‚äô323 (x0,y0),(x1,y0),(x0,y1),and(x1,y1).Wenextassignunitgradientsvectors g0tog3withran- domorientationateachgridpoint.Apointwithineachsquareislocatedbydrawingthe fourpivectors(Figure14.11): p0=(x‚àíx0)i+(y‚àíy0)j,p1=(x‚àíx1)i+(y‚àíy0)j, (14.30) p2=(x‚àíx1)i+(y‚àíy1)j,p3=(x‚àíx0)i+(y‚àíy1)j. (14.31) Next,thescalarproductsofthe p‚Ä≤sandtheg‚Ä≤sareformed: s=p0‚ãÖg0,t=p1‚ãÖg1,ùë£=p2‚ãÖg2,u=p3‚ãÖg3. (14.32) AsshownontheleftinFigure14.12,thenumbers s,t,u,andùë£areassignedtothefourver- ticesofthesquareandrepresentedtherebylinesperpendiculartothesquarewithlengths proportionaltothevaluesof s,t,u,andùë£(whichcanbepositiveornegative). Theactualmappingproceedsviaanumberofsteps(Figure14.13): 1) Transformthepoint (x,y)to(sx,sy), sx=3x2‚àí2x3,sy=3y2‚àí2y3. (14.33) 2) Assignthelengths s,t,u,andùë£totheverticesinthemappedsquare. Perlin noise 3) Obtaintheheight a(Figure14.13)vialinearinterpolationbetween sandt. 4) Obtaintheheight bvialinearinterpolationbetween uandùë£. 5) Obtainsyasalinearinterpolationbetween aandb. 6) Thevector csoobtainedisnowthetwocomponentsofthenoiseat (x,y). 14.9.1 Ray Tracing Algorithms Raytracingisatechniquethatrendersanimageofascenebysimulatingthewayraysof lighttravel[Pov-Ray,2023].Toavoidtracingraysthatdonotcontributetothefinalimage, ray-tracingprogramsstartattheviewer,traceraysbackwardontothescene,andthenback againontothelightsources.Youcanvarythelocationoftheviewerandlightsourcesand thepropertiesoftheobjectsbeingviewed,aswellasatmosphericconditionssuchasfog, haze,andfire. As an example of what this can do, on the right in Figure 14.14, we show the output from the ray-tracing program Pov-Ray [2023], using as input the coherent random noise 324 14 Fractals and Statistical Growth Models (x, y) (x0, y0)(x0, y1)(x1, y1) (x1, y0)tu v s stu v (sx, sy)b Noise cc a Figure 14.13 Perlin noise mapping. Left:T h ep o i n t( x, y) is mapped to point ( sx,xy).Right:U s i n g (14.33). Then three linear interpolations are performed to Ô¨Ånd c, the noise at ( x, y). Figure 14.14 After the addition of Perlin noise, the random scatterplot on the left becomes the clusters on the right. ontheleftinFigure14.14.TheprogramoptionsweusedaregiveninListing14.4,andare seentoincludecommandstocolortheislands,toincludewaves,andtogivetexturestothe skyandthesea.Pov-RayalsoallowsthepossibilityofusingPerlinnoisetogivetexturesto theobjectstobecreated.Forexample,thestonecupontherightoftheinsetabovehasa marble-liketextureproducedbyPerlinnoise. 14.10 Code Listings Listing14.1 Fern3D.py Simulatesthegrowthoffernsin3D. # Fern3D.py: Fern in 3D, see Barnsley, \""Fractals Everywhere\"" fromvisualimport ‚àó 4fromvisual.graph import ‚àó importrandom imax = 20000 8x = 0.5; y = 0.0; z = ‚àí0.2; xn = 0.0; yn = 0.0 graph1 = display(width=500, height=500, forward=( ‚àí3,0,‚àí1),\ title= ‚Äô3D Fractal Fern (rotate via right mouse button)‚Äô ,range=10) graph1.show_rendertime = True # Pts/sphs: cycle=27/750 ms, render=6/30 14.10 Code Listings 325 12pts = points(color=color.green, size=0.01) foriin range (1,imax): r = random.random() ; if( r <= 0.1): # 10 percent probability 16 xn = 0.0 yn = 0.18 ‚àóy zn = 0.0 elif(r>0 . 1 andr< =0 . 7 ) : # 60 percent probability 20 xn = 0.85 ‚àóx yn = 0.85 ‚àóy+0 . 1 ‚àóz+1 . 6 zn =‚àí0.1 ‚àóy + 0.85 ‚àóz elif(r>0 . 7 andr <= 0.85): # 15  percent probability 24 xn = 0.2 ‚àóx‚àí0.2 ‚àóy yn = 0.2 ‚àóx+0 . 2 ‚àóy+0 . 8 zn= 0.3 ‚àóz else: 28 xn =‚àí0.2‚àóx+ 0 . 2 ‚àóy # 15 percent probability yn = 0.2 ‚àóx+ 0 . 2 ‚àóy+0 . 8 zn = 0.3 ‚àóz x=x n 32y=y n z=z n xc = 4.0 ‚àóx #l i n e a rT Ff o rp l o t yc = 2.0 ‚àóy‚àí7 36zc = z pts.append(pos=(xc,yc,zc)) Listing14.2 Column.py Simulatescorrelatedballisticdepositionofmineralsontosub- stratesonwhichdendritesform. 1# Column.py: Fractal growth of columns fromvisualimport ‚àó; importrandom 5 maxi = 100000; npoints = 200 # Number iterations , spaces i=0 ; d i s t=0 ; r=0 ; x=0 ; y=0 oldx = 0; oldy = 0; pp = 0.0; prob = 0.0 9hit = zeros( (200), int) graph1 = display(width = 500, height = 500, range=250, title = ‚ÄôCorrelated Ballistic Deposition‚Äô ) pts = points(color=color.green, size=2) 13foriin range (0, npoints): hit[i] = 0 # Clear array oldx = 100; oldy = 0 foriin range (1, maxi + 1): r=int(npoints ‚àórandom.random() ) 17x=r‚àíoldx y=h i t [ r ] ‚àíoldy dist = x ‚àóx+y ‚àóy if(dist = = 0): prob = 1.0 # Sticking prob depends on last x 21else: prob = 9.0/dist pp = random.random() if(pp < prob): if(r>0andr<(npoints ‚àí1) ): 25 if( (hit[r] >= hit[r ‚àí1])and(hit[r] >= hit[r + 1]) ): hit[r] = hit[r] + 1 else: if(hit[r ‚àí1] > hit[r + 1]): 29 hit[r] = hit[r ‚àí1] else: hit[r] = hit[r + 1] oldx = r oldy = hit[r] 33 olxc = oldx ‚àó2‚àí200 #T Ff o rp l o t olyc = oldy ‚àó4‚àí200 pts.append(pos=(olxc,olyc)) 326 14 Fractals and Statistical Growth Models Listing 14.3 Gameoflife.py Is an extension of Conway‚Äôs Game of Life in which cells alwaysreviveifoneoutofeightneighborsisalive. # Gameoflife.py: Cellular automata in 2 dimensions 3‚Äô‚Äô‚Äô* Rules: a cell can be either dead (0) or alive (1) * If a cell is alive: * on next step will remain alive if * 2 or 3 of its closer 8 neighbors are alive. 7 * If > 3 of 8 neighbors are alive, cell dies of overcrowdedness * If less than 2 neighbors are alive the cell dies of loneliness * A dead cell will be alive if 3 of its 8 neighbors are alive‚Äô‚Äô‚Äô 11fromvisualimport ‚àó fromvisual.graph import ‚àó;importrandom scene = display(width= 500,height= 500, title= ‚ÄôGame of Life‚Äô ) 15cell = zeros((50,50)); cellu = zeros((50,50)) curve(pos= [( ‚àí49,‚àí49),(‚àí49,49),(49,49),(49, ‚àí49),(‚àí49,‚àí49)],color=color.white) boxes = points(shape= ‚Äôsquare‚Äô , size=8, color=color.cyan) 19defdrawcells(ce): boxes.pos = [] # Erase previous cells forjin range (0,50): foriin range (0,50): 23 ifce[i,j] == 1: xx = 2 ‚àói‚àí50 yy = 2 ‚àój‚àí50 boxes.append(pos=(xx,yy)) 27definitial(): forjin range (20,28): foriin range (20, 28): r= int(random.random() ‚àó2) 31 cell[j,i] = r returncell defgameoflife(cell): foriin range (1,49): 35 forjin range (1,49): sum1 = cell[i ‚àí1,j‚àí1] + cell[i ,j ‚àí1] + cell[i+1,j ‚àí1]#n e i g h b sum2 = cell[i ‚àí1,j] + cell[i+1,j] + cell[i ‚àí1,j+1] \ +c e l l [ i , j + 1 ]+c e l l [ i + 1 , j + 1 ] 39 alive = sum1+sum2 ifcell[i,j] == 1: ifalive == 2 oralive == 3: # Alive cellu[i,j] = 1 # Lives 43 ifalive > 3 oralive < 2: # Overcrowded or solitude cellu[i,j] = 0 #d i e s ifcell[i,j] == 0: ifalive == 3: 47 cellu[i,j] = 1 # Revives else: cellu[i,j] = 0 # Remains dead alive = 0 51returncellu temp = initial () drawcells(temp) whileTrue: 55rate(6) cell = temp temp = gameoflife(cell) drawcells(cell) 14.10 Code Listings 327 Listing 14.4 Islands.pov The Pov-Ray ray-tracing commands needed to convert the coherentnoiserandomplotofFigure14.14intothemountain-likeimageinFigure14.14. // Islands.pov Pov ‚àíRay program to create Islands, by Manuel J Paez plane { 4<0, 1, 0>, 0 // Sky pigment { color rgb <0, 0, 1> } scale 1 rotate <0, 0, 0> 8translate y ‚àó0.2 } global_settings { adc_bailout 0.00392157 12assumed_gamma 1.5 noise_generator 2 } #declare Island_texture = texture { 16pigment { gradient <0, 1, 0> // Vertical direction color_map { // Color the islands [ 0.15 color rgb <1, 0.968627, 0> ] 20 [ 0.2 color rgb <0.886275, 0.733333, 0.180392> ] [ 0.3 color rgb <0.372549, 0.643137, 0.0823529> ] [ 0.4 color rgb <0.101961, 0.588235, 0.184314> ] [ 0.5 color rgb <0.223529, 0.666667, 0.301961> ] 24 [ 0.6 color rgb <0.611765, 0.886275, 0.0196078> ] [ 0.69 color rgb <0.678431, 0.921569, 0.0117647> ] [ 0.74 color rgb <0.886275, 0.886275, 0.317647> ] [ 0.86 color rgb <0.823529, 0.796078, 0.0196078> ] 28 [ 0.93 color rgb <0.905882, 0.545098, 0.00392157> ] } } finish { 32ambient rgbft <0.2, 0.2, 0.2, 0.2, 0.2> diffuse 0.8 } } 36camera { // Camera characteristics andlocation perspective location < ‚àí15, 6, ‚àí20> // Located here sky <0, 1, 0> 40direction <0, 0, 1> right <1.3333, 0, 0> up <0, 1, 0> look_at < ‚àí0.5, 0, 4> //looking at that point 44angle 36 } light_source {< ‚àí10, 20, ‚àí25>, rgb <1, 0.733333, 0.00392157>} // Light 48#declare Islands = height_field { // Takes gif and finds heights gif\""d:\pov\montania.gif\"" // Windows directory naming scale <50, 2, 50> translate < ‚àí25, 0, ‚àí25> 52} object { // Islands Islands texture { 56Island_texture scale 2 } } 60box { // Upper face of the box isthe sea <‚àí50, 0, ‚àí50>, <50, 0.3, 50> // Location of 2 opposite vertices translate < ‚àí25, 0, ‚àí25> texture { // Simulate waves 64normal { spotted 0.4 scale <0.1, 1, 0.1> 328 14 Fractals and Statistical Growth Models 68} pigment { color rgb <0.164706, 0.556863, 0.901961> } } } 72fog { // A constant fog isdefined fog_type 1 distance 30 rgb <0.984314, 1, 0.964706> 76}",8487
Chapter 15 Nonlinear Population Dynamics. 15.1 The Logistic Map A Bug Population Model,"329 15 Nonlinear Population Dynamics We view nonlinear dynamics as one of the success stories of computational physics. It has been explored by scientists and engineers with computers as an essential tool, often then followed by mathematicians [Motter and Campbell, 2013]. The computations have led to the discovery of new phenomena such as chaos, solitons, and fractals; the Ô¨Årst of which we cover in this chapter, and the last, later on. Here we look at discrete and continuous models of population dynamics that are simple, yet which yield surprising complex behavior. In Chapter 16, we explore nonlinear behavior in classical oscillations . 15.1 The Logistic Map, A Bug Population Model Populationsofbugsandpatternsofweatherdonotappeartofollowanysimplelaws.1At times,thepopulationpatternsappearstable,atothertimestheyvaryperiodically,andat othertimestheyappearchaotic,withnodiscernableregularity,onlytosettlebackdownto somethingsimpleagain. Problem Deduceifasimplelawcanproducesuchcomplicatedbehaviors. Imagineabunchofbugsreproducinggenerationaftergeneration.Westartwitha N0bugs, theninthenextgenerationwehavetolivewith N1ofthem,andafter ngenerations,there areNnofthemaroundtobugus.Wewanttodevelopamodelofhow Nnvarieswiththe generationnumber n.Clearly,iftheratesofbreedinganddyingarethesame,thenastable population occurs. Yet bugs cannot live on love alone, they must also eat, and bugs, not beingfarmers,mustcompetefortheavailablefoodsupply.Thistendstorestricttheirnum- bertoliebelowsomemaximumpopulation N‚àó.Wewanttobuildalloftheseobservations intoourmodel. Forguidance,welooktotheradioactivedecaysimulationinChapter4wherethediscrete decaylaw, ŒîN‚àïŒît=‚àíùúÜN, (15.1) 1 ExceptmaybeinOregon,wherestormcloudscometospendtheirweekends. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 330 15 Nonlinear Population Dynamics ledtoexponential-likedecay.Beingclever,westartourmodelingbyreversingthesignof ùúÜ, whichshouldgiveus growth: ŒîNi Œît=ùúÜNi. (15.2) Yet we know that exponential growth eventually tapers off, with the population reach- ing a maximum N‚àó(thecarrying capacity ). Consequently, we modify the growth model (15.2) by changing the growth rate parameter ùúÜto one that decreases as the population approaches N‚àó: ùúÜ=ùúÜ‚Ä≤(N‚àó‚àíNi), (15.3) ‚áíŒîNi Œît=ùúÜ‚Ä≤(N‚àó‚àíNi)Ni. (15.4) Weexpectthatwhen Niissmallcomparedto N‚àó,thepopulationwillgrownearlyexponen- tially.Yetwealsoexpectthatas Niapproaches N‚àó,thegrowthratewilldecrease,eventually becomingnegativeif Niexceedsthecarryingcapacity N‚àó.Wecanimaginethetwopossibil- itiesleadingtooscillations. Equation(15.4)isaversionofthe logisticmap .Itisusuallywritteninaformthatrelates thenumberofbugsinthefuturetothenumberinthepresentgeneration: Ni+1=Ni+ùúÜ‚Ä≤Œît(N‚àó‚àíNi)Ni, (15.5) =Ni(1+ùúÜ‚Ä≤ŒîtN‚àó)[ 1‚àíùúÜ‚Ä≤Œît 1+ùúÜ‚Ä≤ŒîtN‚àóNi] . (15.6) Thisrelationlookssimplerwhenexpressedintermsofdimensionlessvariables: xi+1=ùúáxi(1‚àíxi), (15.7) ùúádef=1+ùúÜ‚Ä≤ŒîtN‚àó, (15.8) xidef=ùúÜ‚Ä≤Œît 1+ùúÜ‚Ä≤ŒîtN‚àóNi‚âÉNi N‚àó. (15.9) Herexiisadimensionlesspopulationvariableand ùúáisa(yetanother)dimensionlessgrowth parameter.Observefrom(15.8),thatifthenumberofbugsbornpergeneration ùúÜ‚Ä≤Œîtislarge, thenxi‚âÉNi‚àïN‚àó,thatis,xiisessentiallythefractionofthemaximumpopulation N‚àó.Con- sequently,realistic xvaluesgenerallylieintherange0 ‚â§xi‚â§1,withx=0corresponding to no bugs, and x=1 corresponding to the carrying capacity. Also note that the growth rateùúáequals1,onlyifthebreedingrate ùúÜ‚Ä≤equals0,andisotherwiseexpectedtobelarger than1. The map (15.7) is seen to be the sum of linear and quadratic dependencies on xi.I ti s calledamapbecauseitconvertsonenumberinasequencetothenext, xi+1=f(xi). (15.10) Forthelogisticmap, f(x)=ùúáx(1‚àíx),withthequadraticdependenceon xmakingthisa nonlinearmap,andthedependenceononlytheonevariable xmakingita one-dimensional map. Justbylookingat(15.7),wereallywouldnotexpectthatanythingassimpleasthismight berealisticdescriptionofbugpopulationdynamics.However,ifitexhibitssomefeatures similartothosefoundinnature,thenitmaywellformthefoundationforamorecomplete description(aswewilldevelopinSection15.5).",4069
15.1.1 Exploring Map Properties. 15.1.2 Fixed Points,"15.1 The Logistic Map, A Bug Population Model 331 01 02 0 01 02 001 02 000.40.8 01 02 0xn xn n nnn Figure 15.1 The bug population xnversus the generation number nfor the four growth rates: (a)ùúá=2.8, a single attractor; (b) ùúá=3.3, a double attractor; (c) ùúá=3.5, a quadruple attractor; (d)ùúá=3.8, a chaotic regime. 15.1.1 Exploring Map Properties Ratherthanreadingabouthowfancymathematicalanalysesdeducethepropertiesofthe logisticmap[Rasband,1990],wehereaskyoutoexploreityourselfbygeneratingandplot- tingsequencesof xivalues.YoushouldgetresultssimilartothoseshowninFigure15.1. 15.1.1.1 Stable Populations Astablepopulationisonethatremainsthesamefromgenerationtogeneration. 1) Start with an initial population x0=0.75, called the seed. You should find that the dynamicaleffectsarenotsensitivetoit.Also,asacheckonthemodel,startwithsome negativeandzerovaluesfor ùúá,whichshouldproducedecayingpopulations.Makeplots ofxiversusi. 2) Nowlookforstablepopulationswith ùúá=0,0.5,1,1.5,2. 3) Takenoteofthe transientbehaviorsthatoccurforearlygenerationsbeforemoreregular behaviorssetin. 4) Forafixedvalueof ùúá,trydifferentvaluesfortheseed x0,andtherebyverifythatwhile thetransientsmaydiffer,theregularbehaviorsdonot. Youshouldhavefoundthatthismodelyieldsstablepopulationsforpositivegrowthrates ùúá,withthemaximumpopulationreachedmorerapidlyas ùúágetslarger.Thisisagoodvali- dationofthemodel.SometypicalbehaviorsareshowninFigure15.1.InFigure15.1a,we seeequilibrationintoasinglepopulation;inFigure15.1b,weseeoscillationbetweentwo",1503
15.1.4 Mapping Implementation,"332 15 Nonlinear Population Dynamics populationlevels;inFigure15.1c,weseeoscillationamongfourlevels;andinFigure15.1d, weseeachaoticsystem. 15.1.2 Fixed Points Animportantpropertyofthemap(15.7)isthepossibilityofthesequence xireachingone, ormore,fixedpointsx‚àó,thatis,populationsatwhichthesystemremains,orreturnstoregu- larly.Ataone-cyclefixed-point,therewouldbenochangeinthepopulationfromgeneration itogeneration i+1,thatis, xi+1=xi=x‚àó. (15.11) Substituting this relation into the logistic map (15.7) yields a quadratic equation we can easilysolve: ùúáx‚àó(1‚àíx‚àó)=x‚àó, (15.12) ‚áíx‚àó=0,orx‚àó=ùúá‚àí1 ùúá. (15.13) Thenonzerofixed-point, x‚àó=(ùúá‚àí1)‚àïùúá,correspondstoastablepopulationinwhichthere is a balance between birth and death, as in Figure 15.1a. In contrast, the x‚àó=0 point is unstablesincethepopulationremainsstaticonlyaslongasnobugsexist;ifevenafewbugs areintroduced,exponentialgrowthoccurs.Furtheranalysis,whichweareabouttoexplore computationally,tellsusthatthestabilityofapopulationisdeterminedbythemagnitude ofthederivativeofthemappingfunction f(xi)atthefixed-point[Rasband,1990]: ||||df dx||||x‚àó<1 (stable) . (15.14) Fortheonecycleofthelogisticmap(15.7),thederivativeis df dx||||x‚àó=ùúá‚àí2ùúáx‚àó={ ùúá,stableatx‚àó=0ifùúá<1, 2‚àíùúá,stableatx‚àó=ùúá‚àí1 ùúáifùúá<3.(15.15) 15.1.3 Period Doubling, Bifurcations Equation(15.15)tellsusthattherewillnotbeanystablepopulationsfor ùúá>3.Inthiscase, thesystemundergoes bifurcations intotwopopulations,aso-called two-cycle.Theeffectis knownasperioddoubling ,andisevidentinFigure15.1b.Becausethesystemnowmoves betweenthesetwopopulations,thepopulationsarecalled attractorsorcyclepoints .Wecan easilypredictthe xvaluesfortwo-cycleattractorsbydemandingthatgeneration i+2has thesamepopulationasgeneration i: xi=xi+2=ùúáxi+1(1‚àíxi+1), (15.16) ‚áíx‚àó=1+ùúá¬±‚àö ùúá2‚àí2ùúá‚àí3 2ùúá. (15.17) Weseethataslongas ùúá>3,thesquarerootproducesarealnumberandthusthatphysical solutions.Weleaveittoyourexplorationstodiscoverhowthesystemcontinuestobifur- cate asùúáis increased further. In all cases, the behavior repeats, with a single population bifurcatingintotwo.",2027
15.2 Chaos. 15.3 Bifurcation Diagrams,"15.3 Bifurcation Diagrams 333 15.1.4 Mapping Implementation Itisnowtimetocarryoutamorecarefulinvestigationofthelogisticmap,followingthe originalpathofFeigenbaum[1979]andhishandcalculator: 1) ConfirmthatyouobtainthedifferentpatternsshowninFigure15.1for ùúá=(0.4,2.4,3.2, 3.6,3.8304)andseed x0=0.75. 2) Identifythefollowinginyourgraphs: a)Transients :Irregularbehaviorsbeforereachingaregularbehavior,andthatthetran- sientsdifferfordifferentseeds. b)Asymptotes : In some cases, the steady state is reached after only 20 generations, whileforlarger ùúávalues,hundredsofgenerationsmaybeneeded.Thesesteady-state populationsareindependentoftheseed. c)Extinction :Ifthegrowthrateistoolow, ùúá‚â§1,thepopulationdiesoff. d)Stable states : The stable single-population states attained for ùúá<3s h o u l da g r e e withtheprediction(15.13). e)Multiple cycles : Examine populations for a growth parameter ùúáincreasing con- tinuously through 3. Observe how the system continues to bifurcate. For example, Figure15.1cwith ùúá=3.5containsfourattractors(a four-cycle). f)Intermittency : Observe simulations for 3.8264 <ùúá<3.8304. Here the system appearsstableforafinitenumberofgenerationsandthenjumpsallaround,onlyto becomestableagain.(Oldradiostendedtodothis.) 15.2 Chaos ‚ÄúChaos‚Äùhasdifferentmeaningstodifferentpeople.Forpresentpurposes,wedefinechaos asthedeterministicbehaviorofasystemdisplayingnodiscernibleregularity .Thismayseem contradictory; if a system is deterministic, it must have step-to-step correlations, which, whenaddedup,meanslong-rangecorrelations.Butwhenthebehaviorischaotic,thecom- plexitiesofthebehaviormayhidethedeterminismwithin.Inanoperationalsense, achaotic systemisonewithanextremelyhighsensitivitytoparametervaluesorinitialconditions .This sensitivitytoevenminusculechangesissohighthat,inapracticalsense,itisimpossible to predict the long-range behavior without knowing the parameters to infinite precision, aphysicalimpossibility.Yetbecausethesystemismathematicallydeterministic,itisnot random. As you may recall from Chapter 4, a random sequence has no correlation from onesteptothenext,whereasachaoticonedoes. 1) Explorethelong-termbehaviorsofthelogisticmapinthechaoticregionstartingwith thetwo,essentiallyidentical,seeds x0=0.75andx‚Ä≤ 0=0.75(1+ùúñ),whereùúñ‚âÉ2√ó10‚àí14. 2) Repeatthesimulationwith x0=0.75andtwoessentiallyidenticalsurvivalparameters, ùúá=4andùúá=4(1‚àíùúñ),whereùúñ‚âÉ2√ó10‚àí14.Bothsimulationsshouldstartoffthesame, buteventuallydiverge. 15.3 Bifurcation Diagrams Watchingthepopulationchangeasafunctionofgenerationnumberprovidesagoodpicture ofthebasicdynamicsatwork,atleastuntilthings 334 15 Nonlinear Population Dynamics 1. 00.00.20.40.60.81. 0 2.0 Œºx* 3.0 4.0 Figure 15.2 A bifurcation plot of attractor population x‚àóversus growth rate ùúáfor the logistic map. The inset shows some details of a three-cycle window. (Gray scales indicate the regimes over which Hans Kowallik distributed the work on different CPUs when run in parallel.) In particular, as the number of bifurcations keeps increasing, the output may seem too complicated for you to discern any pattern. One way to visualize what is going on, is to concentrateontheattractors,thatis,thosepopulationsthatappeartoattractthesolutions, andtowhichthesolutionscontinuouslyreturn(long-termiterates).Aplotofthe xvalues oftheseattractorsasafunctionofthegrowthparameter ùúá,turnsouttobeanilluminating windowintothedynamics. Onesuchbifurcationdiagram forthelogisticmapisshowninFigure15.2.Acorrespond- ing,andsimilar,diagramforaverydifferentmap,theGaussianmap,isgiveninFigure15.3. (MoremapsaregiveninSection15.3.3.)Togeneratesuchadiagram,youhaveyourcalcu- lationproceedthroughallvaluesof ùúáinsmallsteps.Foreach ùúávalue,youwaitwhilethe systemgoesthroughhundreds(ormore)ofiterations,sothatthetransientsdieout;atthis, youareatafixedpoint x‚àó.Next,youwritethepair (x‚àó,ùúá)toafile,andcontinuetheitera- tionforhundredsofcycles,withoutchanging ùúá.Ifthesystemfallsintoan n-cycleforthis ùúá value,thenthereshouldpredominantlybe ndifferentx‚àóvalueswrittentothefile.Next,the valueoftheinitialpopulation x0ischangedslightly,andtheentireprocedureisrepeated toensurethatnofixed-pointsaremissed.Whenfinished,yourprogramwillhavestepped throughallthevaluesof ùúáandx0. b = 1 b = 4 b = 5Figure 15.3 A bifurcation plot, x‚àóùë£ersusùúÜ, for the Gaussian map. (W. Hager.)",4277
15.3.1 Bifurcation Diagram Implementation. 15.3.3 Other Maps,"15.3 Bifurcation Diagrams 335 15.3.1 Bifurcation Diagram Implementation Oursampleprogram Bugs.pyisgiveninListing15.1.WeaskyoutoreproduceFigure15.2at variouslevelsofdetail.Youcreateavisualizationofthissortbyplottingindividualpoints, with the density in each region of the screen determined by the number of points plot- tedthere.Whenthinkingaboutplottingmanypoints,itisimportanttokeepinmindthat yourmonitorandprintercandisplayonlyafinitenumberofpixels(pictureelements).At present, an HD monitor has 1920 √ó1080=2,073,600 pixels, but you do not need to use every pixel; in any case, printing at a finer resolution is a waste of time. Here‚Äôs how to doit: 1) Breakuptherange1 ‚â§ùúá‚â§4into1000steps.Thesearethe‚Äúbins‚Äùintowhichyouwill placethex‚àóvalues. 2) Inordernottomissanystructuresinyourbifurcationdiagram,loopthrougharangeof initialx0values. 3) Waitatleast200generationsfortransientstodieout,andthenoutputthenextseveral hundred (ùúá,x‚àó)valuestoafile. 4) Output your x‚àóvalues to no more than three or four decimal places. You will not be abletoresolvemoreplacesthanthisonyourplot,andthisrestrictionwillreducethe number of duplicate entries. You can use formatted output to control the number of decimalplaces,oryoucandoitviaasimpleconversion:multiplythe xivaluesby1000, andthenthrowawaytheparttotherightofthedecimalpoint: Ix[i]= int(1000*x[i]). Thendivideby1000ifyouwantfloating-pointnumbers. 5) Plotx‚àóversusùúáusing small symbols for the points, with no connections between points. 6) Enlarge(zoominon)sectionsofyourplot,andnoticehowasimilarbifurcationdiagram tendstobecontainedwithineachmagnifiedportion(thisis self-similarity ). 7) Lookovertheseriesofbifurcationsoccurring ùúák‚âÉ3,3.449,3.544,3.5644,3.5688,3.569692,3.56989,‚Ä¶. (15.18) 8) Notehowtheendofthisseriesisinaregionofchaoticbehavior,andthatthesystem sometimesentersintothechaoticregionsquickly.Accordingly,youmayhavetomake plotsoveraverysmallrangeof ùúávaluestoseeallofthestructuresthere.Acloseexami- nationofFigure15.2showsregionswhere,foraslightincreasein ùúá,averylargenumber ofpopulationssuddenlychangetoveryfewpopulations.Whereasthesemayappearto beartifactsofthevideodisplay,thisisarealeffect,andtheseregionsarecalled windows. Checkthataround ùúá=3.828427chaosmovesintoathree-cyclewindow. 15.3.2 Feigenbaum Constants Feigenbaum [1979] discovered that the sequence of ùúákvalues (15.18) at which bifurca- tionsoccurfollowsaregularpattern.Specifically,the ùúávaluesconvergegeometricallywhen expressedintermsofthedistancebetweenbifurcations ùõø: ùúák‚Üíùúá‚àû‚àíc ùõøk,ùõø=lim k‚Üí‚àûùúák‚àíùúák‚àí1 ùúák+1‚àíùúák. (15.19)",2527
15.4 Measures of Chaos. 15.4.1 Lyapunov Coefficients,"336 15 Nonlinear Population Dynamics Useyoursequenceof ùúákvaluestodeterminethethreeconstantsin(15.19),andcompare themtothosefoundbyFeigenbaum: ùúá‚àû‚âÉ3.56995,c‚âÉ2.637,ùõø‚âÉ4.6692. (15.20) Amazingly,thevalueof ùõøisuniversalforallsecond-ordermaps. 15.3.3 Other Maps Bifurcationsandchaosaretypicalcharacteristicsofnonlinearsystems.Yetsystemscanbe nonlinearinanumberofways.Thetablebelowlistsfourmapsthatgenerate xisequences containingbifurcations. Name f(x)Name f(x) Logistic ùúáx(1‚àíx)Tent ùúá(1‚àí2|x‚àí1‚àï2|) Ecology xeùúá(1‚àíx)Quartic ùúá[1‚àí(2x‚àí1)4] Gaussian e‚àíbx2+ùúá Thetentmapderivesitsnonlineardependencefromtheabsolutevalueoperator,whilethe logisticmapisseentobeasubclassoftheecologymap.Explorethepropertiesoftheseother mapsandnotethesimilaritiesanddifferences. 15.4 Measures of Chaos Ourdefinitionofchaosintermsofunpredictabilityseemsrathersubjective,ormaybehard toapplyanalytically.Accordingly,severalanalyticmeasuresofchaoshavebeendeveloped, andinthissection,weexaminetwo,theLyapunovcoefficientsandShannonentropy. 15.4.1 Lyapunov CoefÔ¨Åcients‚®Ä TheLyapunovcoefficient ùúÜprovidesananalyticsignalofchaos[Wolf etal.,1985;Ramasub- ramanianandSriram,2000;Williams,1997;Manneville,1990].Specifically,thecoefficient istherateparameterintheexponentdescribingtheexponentialgrowthof x‚àóversusùúá.For 1Dproblems,thereisonlyonesuchcoefficient,whereas,ingeneral,thereisacoefficient foreachdegreeoffreedom.Theessentialassumptionisthatneighboringpaths xnnearan attractorx‚àóhaveatimedependence L‚àùexp(ùúÜt).Consequently,if ùúÜ>0,thenumberoffixed pointsgrowsexponentially,whichischaotic;if ùúÜ=0,wehaveamarginallystablepopula- tion;while ùúÜ<0impliesastableandperiodicpopulation.Mathematically,theLyapunov coefficientisdefinedas ùúÜ=lim t‚Üí‚àû1 tlogL(t) L(t0), (15.21) whereL(t)isthedistancebetweenneighboringphasespacetrajectoriesattime t. Asanexample,we‚ÄôllcalculatetheLyapunovexponentforageneral1Dmap, xn+1=f(xn), (15.22) 15.4 Measures of Chaos 337 wherethegenerationnumber nnowreplacesthetime t.Todeterminestability,weexamine perturbationsaboutareferencetrajectory x0byaddingasmallperturbation,anditerating once: ÃÇx0=x0+ùõøx0, ÃÇx1=x1+ùõøx1. (15.23) Wesubstitutethisinto(15.22)andexpand finaTaylorseriesaround x0: x1+ùõøx1=f(x0+ùõøx0)‚âÉf(x0)+ùõøf ùõøx||||x0ùõøx0=x1+ùõøf ùõøx||||x0ùõøx0, ‚áíùõøx1‚âÉ(ùõøf ùõøx) x0ùõøx0. (15.24) Thisistheproofofourearlierstatementthatanegative df‚àïdxindicatesstability.Todeduce thegeneralresult,weexamineoneiteration: ùõøx2‚âÉ(ùõøf ùõøx) x1ùõøx1=(ùõøf ùõøx) x0(ùõøf ùõøx) x1ùõøx0, (15.25) ‚áíùõøxn=n‚àí1‚àè i=0(ùõøf ùõøx) xiùõøx0. (15.26) Thislastrelationtellsushowtrajectoriesdifferontheaverageafter nsteps: |ùõøxn|=Ln|ùõøx0|,Ln=n‚àí1‚àè i=0|||||(ùõøf ùõøx) xi|||||. (15.27) Wenowsolveforthe LandtakeitslogarithmtoobtaintheLyapunovcoefficient: ùúÜ=ln(L)=lim n‚Üí‚àû1 nn‚àí1‚àë i=0ln|||||(ùõøf ùõøx) xi|||||. (15.28) Forthelogisticmap, f(x)=ùúáx(1‚àíx),weobtain ùúÜ=1 nn‚àí1‚àë i=0ln|ùúá‚àí2ùúáxi|, (15.29) wherethesumisoveriterations. The code LyapLog.py in Listing 15.2 computes the Lyapunov exponents for the logistic map. In Figures 15.4 and 15.5 we show its output. Note the sign changes in ùúÜwhere the Figure 15.4 Fixed point bifurcations (top) and Lyapunov coefÔ¨Åcient (bottom) for the logistic map as functions of the growth rate ùúá. Notice how the Lyapunov coefÔ¨Åcient, a measure of chaos, changes abruptly at the bifurcations with positive values indicating instabilities. x* Œª Œº1 0.5 0 ‚Äì0.5 34",3268
15.4.2 Shannon Entropy. 15.5.2 PredatorPrey Chaos,"338 15 Nonlinear Population Dynamics ‚Äì0.400.40.8 3.5 3.6 3.7 Œº3.8 3.9 4Lyapunov exponentEntropyFigure 15.5 Shannon entropy (top) and Lyapunov coefÔ¨Åcient (bottom) for the logistic map. Notice the close relation between the thermodynamic measure of disorder (entropy) and the nonlinear dynamics measure of chaos (Lyapunov). system becomes chaotic, and the abrupt changes in slope at the bifurcations. (A similar curve is obtained for the fractal dimension of the logistic map, and, indeed the two are proportional.) 15.4.2 Shannon Entropy AnothermeasurethatcanindicatechaoticbehavioristheShannonentropy.Entropyisa measureofuncertainty(garbledsignal)thathasprovenusefulincommunicationtheory [Shannon, 1948; Ott, 2002; Gould et al., 2006]. Imagine that an experiment has Npos- sible outcomes. If the probability of each is p1,p2,‚Ä¶,pN, with normalization such that‚àëN i=1pi=1,thentheShannonentropyisdefinedas SSh=‚àíN‚àë i=1pilnpi. (15.30) Ifpi‚â°0,thereisnouncertainty,and SSh=0,asyoumightexpect.Ifall Noutcomeshave equalprobability, pi‚â°1‚àïN,weobtaintheexpressionfamiliarfromstatisticalmechanics, SSh=lnN. The code Entropy.py in Listing 15.3 computes the Shannon entropy for the logistic map as a function of the growth parameter ùúá. The results (Figure 15.5, top) are seen to be quite similar to the Lyapunov exponent, again with discontinuities occurring at the bifurcations. 15.5 Coupled Predator‚ÄìPrey Models‚®Ä Wehaveseencomplicatedbehaviorarisingfromapopulationmodelinwhichweimposeda populationlimit.Nowweextendthatmodeltodescribecoexistingpredatorandpreypopula- tions[Lotka,1925;Volterra,1926 ]. Problem Calculatewhatitmaytaketocontrolapopulationofpests(prey)byintroducing predators.Includeinyourconsiderationstheinteractionbetweenthepopulations,aswell asthecompetitionforfoodandthetimeneededforpredation. 15.5 Coupled Predator‚ÄìPrey Models‚®Ä339 15.5.1 Lotka‚ÄìVolterra Model We extend the logistic map to the Lotka‚ÄìVolterra model (LVM) that describes coexisting predatorandapreypopulationbyintroducinganadditionalpopulation: p(t)=prey(bug)density ,P(t)=Predatordensity . (15.31) Intheabsenceofinteractionsbetweenthespecies,weassumethatthepreypopulation p breedsataper-capitarateof a: Œîp Œît=ap(Discrete), (15.32) dp dt=ap,(Continuous )‚áíp(t)=p(0)eat. (15.33) Herewegiveboththediscreteandcontinuousversionsofthemodel,andwillworkwith thecontinuousmodel,whereweseetheexponentialgrowthexplicitly.However,ifthere arepredatorsthat‚Äúinteractwith‚Äù(gobbleup)anabundanceofprey,thenthismayaffect thepreygrowthrate.Weassumethattheinteraction(gobble)rateisproportionaltotheir jointprobability: Interactionrate =bpP, (15.34) wherebis a constant. This leads to a prey growth rate including both predation and breeding: dp dt=ap‚àíbpP,(LVM-Iforprey) . (15.35) Iflefttothemselves,predators Pwillbreedandincreasetheirpopulationexponentially.Yet we all need to eat, and if there is no prey around, predators will eat each other (or their young)ataper-capitamortalityrate m: dP dt||||mort=‚àímP,‚áíP(t)=P(0)e‚àímt. (15.36) However,ifwealsoincludethepossibilitythattherearepreyto‚Äúinteractwith‚Äùatarate bpP,thepredatorpopulationwillgrowattherate dP dt=ùúñbpP‚àímP(LVM-Iforpredators) . (15.37) Hereùúñisaconstantthatmeasurestheefficiencywithwhichpredatorsconvertpreyinter- actionsintofood. Equations (15.35) and (15.37) are two simultaneous ODEs that define the first LVM model.Theycanbesolvedafterplacingtheminthestandarddynamicform: dy‚àïdt=f(y,t), y0=p, f0=ay0‚àíby0y1, y1=P, f1=ùúñby0y1‚àímy1.(15.38) Our code to solve these equations is PredatorPrey.py in Listing 15.4, with results shown in Figure 15.6. On the left, we see two populations that oscillate out of phase with each other in time. When there are many prey, the predator population eats them and grows, yet then the predators face a decreased food supply, and so their population decreases;that,inturn,permitsthepreypopulationtogrow,andsoforth.Ontherightin 340 15 Nonlinear Population Dynamics t024 0 200 400p(t) P(t) Pp 024 0 1 2 Figure 15.6 Left: The time dependencies of the prey population of p(t)(solid curve) and of the predator population P(t)(dashed curve) for the Lotka‚ÄìVolterra model. Right: A ‚Äúphase space‚Äù plot of p(t)versus P(t). The different orbits correspond to different initial populations. Figure 15.6, we plot a ‚Äúphase space‚Äù plot of P(t)versus p(t).2A closed orbit in the phase spaceplotindicatesalimitcyclethatrepeatsindefinitely.Althoughincreasingtheinitial numberofpredatorsdoesdecreasethemaximumnumberofpestsandkeepstheirbehavior incheck,itisnotasatisfactorycontrolsincetheirnumbershowsalargevariation. 15.5.2 Predator‚ÄìPrey Chaos Itseemsthatintroducingpreyhaskeptthepredatorpopulationsfrombecomingchaotic. Mathematical analyses tell us that, in addition to nonlinearity, a system must contain a numberofdegreesoffreedombeforechaoswilloccur.Forapredator‚Äìpreymodel,intro- ducinganotherspeciesortwomaydothetrick.Andsoweextendourprevioustoinclude fourspecies,eachwithpopulation picompetingforthesamefinitesetofresources[Vano etal.,2006].Thisextends(15.37)to: dpi dt=aipi( 1‚àí4‚àë j=1bijpj) ,i=1,4. (15.39) Hereaiisameasureofthegrowthrateofspecies i,andbijisameasureoftherateatwhich speciesjconsumestheresourcesneededbyspecies i.Sincefourspeciescoversaverylarge parameterspace,wesuggestthatyoustartyourexplorationusingthesameparametersthat Vanoetal.[2006]foundproducechaos: ai=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 0.72 1.53 1.27‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶,bij=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 1.09 1.52 0 0 1 0.44 1.36 2.33 0 1 0.47 1.21 0.51 0.35 1‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (15.40) With chaotic systems being hypersensitive to exact parameter values, you may want to modifythesesomewhat.Notethattheself-interactionterms bii=1,whichisaconsequence of measuring the population of each species in units of its individual carrying capacity. 2 WediscussphasespaceplotsatlengthinChapter16. 15.5 Coupled Predator‚ÄìPrey Models‚®Ä341 pipk pj0.05 0.70.60.50.40.30.20.60.50.40.30.20.100.150.200.250.35 0.30 Figure 15.7 A chaotic attractor for the 4D Lotka‚ÄìVolterra model projected onto three axes. Wesolve(15.39)withinitialconditionscorrespondingtoanequilibriumpointatwhichall speciescoexist: pi(t=0)=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£0.3013 0.4586 0.1307 0.3557‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (15.41) Anilluminatingwaytovisualizethebehaviorofthissystemwouldbetocreatea4Dphase- space plot, [p1(ti),p2(ti),p3(ti),p4(ti)]fori=1,N,w h e r eNis the number of time steps in thenumericalsolution.Thegeometricstructuressocreatedmayhaveasmoothandwell- definedshape.Unfortunately,wehavenowaytoshowsuchaplot,andsoinitsstead,as seeninFigure15.7,weprojectthe4Dstructureonto2Dand3Daxes.Weseeaclassictype ofchaoticattractor,withthe3Dstructurefoldedoverintoanearly2Dstructure. Exercise 1) Visualizethesolutionto(15.39)byplotting p1(t),p2(t),p3(t),andp4(t)versustime. 2) Constructthe4Dchaoticattractorformedbythesolutionsof(15.39).Outputthevalues [p1(ti),p2(ti),p3(ti),p4(ti)],foreachtimestep i.Inordertoavoidneedlesslylongfiles,you maywanttoskipanumberoftimesteps. a) Plotallpossible2Dphasespaceplots,thatis,plotsof piversuspj,i‚â†j=1‚àí3. b) Plotallpossible3Dphasespaceplots,thatis,plotsof piversuspjversuspk. Note:youhavetoadjusttheparametersorinitialconditionsslightlytoobtaintruly chaoticbehavior.",7070
15.5.3 LVM with Prey Limit. 15.5.6 Two Predators One Prey,"342 15 Nonlinear Population Dynamics 15.5.3 LVM with Prey Limit TheinitialassumptionintheLVMthatpreygrowwithoutlimitintheabsenceofpredators isunrealistic.Aswiththelogisticmap,weincludealimitonpreynumbersthataccounts fordepletionofthefoodsupplyasthepreypopulationgrows.Accordingly,wemodifythe constantgrowthratefrom atoa(1‚àíp‚àïK),sothatgrowthvanisheswhenthepopulation reachesthe carryingcapacityK : dp dt=ap( 1‚àíp K) ‚àíbpP,(LVM-II). (15.42) dP dt=ùúñbpP‚àímP. (15.43) The behavior of this model with prey limitations is shown in Figure 15.8. We see that both populations exhibit damped oscillations as they approach their equilibrium values, and that, as hoped for, the equilibrium populations are independent of the initial condi- tions.Notehowthephase-spaceplotspiralsinwardtoasinglecloselimitcycleonwhichit remains,withlittlevariationinpreynumber.Atlast,thedesiredbiological‚Äúcontrol.‚Äù 15.5.4 LVM with Predation EfÔ¨Åciency AnotherunrealisticassumptionintheoriginalLVMisthatthepredatorsimmediatelyeatall thepreywithwhichtheyinteract.Asanyonewhohaswatchedacathuntamouseknows, predators also spend their time finding, chasing, killing, eating, and digesting prey. This handlingtime decreasestherateof bpPatwhichpreyareeliminated.Wedefinethe func- tionalresponsepaastheprobabilityofonepredatorfindingoneprey.Ifasinglepredator spendstime tsearchsearchingforprey,then pa=btsearchp‚áítsearch=pa bp. (15.44) If we callththe time a predator spends handling a single prey, then the effective time a predatorspendshandlingapreyis path.Suchbeingthecase,thetotaltime Tthatapredator spendsfindingandhandlingasinglepreyis T=tsearch+thandling=pa bp+path, (15.45) ‚áípa T=bp 1+bpth, (15.46) t0123 0 200 400Pp p P123 1 2.2 Figure 15.8 The Lotka‚ÄìVolterra model including a limit on prey population. Left:S o l i d c u r v e : o f prey population p(t); dashed curve: predator population P(t). population pas a function of predator population P. 15.5 Coupled Predator‚ÄìPrey Models‚®Ä343 t0400 0 400Pp Population t0200 0t0 400Pp Figure 15.9 Lotka‚ÄìVolterra model with predation efÔ¨Åciency and prey limitations. From left to right: overdamping, b=0.01; damped oscillations, b=0.1, and limit cycle, b=0.3. wherepa‚àïTistheeffective rateofeatingprey.Weseethatasthenumberofprey p‚Üí‚àû, the efficiency in eating them ‚Üí1. We include this efficiency in (15.42)by modifying the ratebatwhichapredatoreliminatespreyto b‚àï(1+bpth): dp dt=ap( 1‚àíp K) ‚àíbpP 1+bpth,(LVM-III ). (15.47) Tobestillmorerealisticaboutthepredatorgrowth,wealsoplacealimitonthepredator carryingcapacity,butmakeitproportionaltothenumberofprey: dP dt=mP( 1‚àíP kp) ,(LVM-III ). (15.48) Solutionsfortheextendedmodel(15.47)and(15.48)areshowninFigure15.9.Observethe existenceofthreedynamicregimesasafunctionof b: ‚óèSmallb:Nooscillations,nooverdamping, ‚óèMediumb:Dampedoscillationsthatconvergetoastableequilibrium, ‚óèLargeb:Limitcycle. Thetransitionfromequilibriumtoalimitcycleiscalleda phasetransition . Wefinallyhaveasatisfactorysolutiontoour problem.Althoughthepreypopulationis noteliminated,itcanbekeptfromgettingtoolargeandfromfluctuatingwidely.Nonethe- less, changes in the parameters can lead to large fluctuations or to nearly vanishing predators. 15.5.5 LVM Implementation and Assessment 1) SolveallthreeLVMmodelsusingthefollowingparametervalues: Model a b ùúñmK k LVM-I 0.2 0.1 1 0.1 0 LVM-II 0.2 0.1 1 0.1 20 LVM-III 0.2 0.1 0.1 500 0.2 2) Foreachofthethreemodels,construct a) atimeseriesforpreyandpredatorpopulations, b) phasespaceplotsofpredator versusprey",3471
15.6 Code Listings,"344 15 Nonlinear Population Dynamics 3)LVM-I:Computetheequilibriumvaluesforthepreyandpredatorpopulations.Doyou thinkthatamodelinwhichthecycleamplitudedependsontheinitialconditionscan berealistic?Explain. 4)LVM-II:Calculatenumericalvaluesfortheequilibriumvaluesofthepreyandpredator populations.Makeaseriesofrunsfordifferentvaluesofpreycarryingcapacity K.Can youdeducehowtheequilibriumpopulationsvarywithpreycarryingcapacity? 5) Makeaseriesofrunsfordifferentinitialconditionsforpredatorandpreypopulations. Dothecycleamplitudesdependontheinitialconditions? 6)LVM-III:Makeaseriesofrunsfordifferentvaluesof bandreproducethethreeregimes presentinFigure15.9. 7) Calculatethecriticalvaluefor bcorrespondingtoaphasetransitionbetweenthestable equilibriumandthelimitcycle. 15.5.6 Two Predators, One Prey 1) AnotherversionoftheLVMincludesthepossibilitythattwopopulationsofpredators P1andP2may‚Äúshare‚Äùthesamepreypopulation p.Investigatethebehaviorofasystem inwhichthepreypopulationgrowslogisticallyintheabsenceofpredators: dp dt=ap( 1‚àíp K) ‚àí(b1P1+b2P2)p, (15.49) dP dt=ùúñ1b1pP1‚àím1P1,dP2 dt=ùúñ2b2pP2‚àím2P2. (15.50) a) Use the following values for the model parameters and initial conditions: a=0.2,K=1.7,b1=0.1,b2=0.2,m1=m2=0.1,ùúñ1=1.0, ùúñ2=2.0,p(0)=P2(0)=1.7,andP1(0)=1.0. b) Determinethetimedependenceforeachpopulation. c) Varythecharacteristicsofthesecondpredatorandcalculatetheequilibriumpopu- lationforthethreecomponents. d) Whatisyouranswertothequestion,‚ÄúCantwopredatorsthatsharethesameprey coexist?‚Äù 15.6 Code Listings Listing 15.1 Bugs.py Producesthebifurcationdiagramofthelogisticmap.Afullpro- gramrequiresfinergrids,ascanoverinitialvalues,andremovalofduplicates. # Bugs.py The Logistic m a p 2 fromvisual.graph import ‚àó m_min = 1.0; m_max = 4.0; step = 0.01 graph1 = gdisplay(width=600, height=400, title= ‚ÄôLogistic Map‚Äô ,\ 6 xtitle= ‚Äôm‚Äô, ytitle= ‚Äôx‚Äô, xmax=4.0, xmin=1., ymax=1., ymin=0.) pts = gdots(shape = ‚Äôround‚Äô, size = 1.5, color = color.green) lasty = int(1000 ‚àó0.5) # Eliminates some points count = 0 # Plot every 2 iterations 10forminarange(m_min, m_max, step): y=0 . 5 foriin range (1,201,1): # Avoid y=m ‚àóy‚àó(1‚àíy) 14foriin range (201,402,1): 15.6 Code Listings 345 y=m ‚àóy‚àó(1‚àíy) foriin range (201, 402, 1): # Avoid transients oldy=int(1000 ‚àóy) 18 y=m ‚àóy‚àó(1‚àíy) inty = int(1000 ‚àóy) ifinty .= lasty andcount percent2 == 0: pts.plot(pos=(m,y)) # Avoid repeats 22 lasty = inty count += 1 Listing 15.2 LyapLog.py ComputesLyapunovcoefficientforthebifurcationplotofthe logisticmapasafunctionofgrowthrate.Notethefinenessofthe ùúágrid. # LyapLog . py : Lyapunov coef for logistic map 3fromvisual.graph import ‚àó m_min = 3.5; m_max = 4.5; step = 0.25 graph1 = gdisplay( title = ‚ÄôLyapunov coef (blue) for LogisticMap (red)‚Äô , 7 xtitle = ‚Äôm‚Äô, ytitle = ‚Äôx , Lyap‚Äô , xmax=5.0, xmin=0, ymax = 1.0, ymin = ‚àí0.6) funct1 = gdots(color = color.red) funct2 = gcurve(color = color.yellow) 11forminarange(m_min, m_max, step): # m loop y=0 . 5 suma = 0.0 foriin range (1, 401, 1): y = m ‚àóy‚àó(1‚àíy) # Skip transients 15foriin range (402, 601, 1): y=m ‚àóy‚àó(1‚àíy) funct1.plot(pos = (m, y) ) suma = suma + log( abs(m‚àó(1.‚àí2.‚àóy) )) # Lyapunov 19funct2.plot(pos = (m, suma/401) ) # Normalize Listing 15.3 Entropy.py ComputestheShannonentropyforthelogisticmapasafunc- tionofgrowthparameter ùúá. # Entropy.py Shannon Entropy with Logistic map using Tkinter 3try:fromtkinter import ‚àó except:fromTkinter import ‚àó importmath fromnumpyimportzeros, arange 7 globalXwidth, Yheight root = Tk( ); root.title( ‚ÄôEntropy versus mu ‚Äô ) mumin = 3.5; mumax = 4.0; dmu = 0.25; nbin = 1000; nmax = 100000 11prob = zeros( (1000), float) minx=mumin; maxx=mumax; miny=0; maxy=2.5; Xwidth=500; Yheight=500 c = Canvas(root, width = Xwidth, height = Yheight) # Init canvas c.pack() # Pack canvas 15Button(root , text = ‚ÄôQuit‚Äô, command = root . quit) .pack() # To quit defworld2sc(xl, yt, xr, yb): #x‚àíleft , y ‚àítop , x ‚àíright , y ‚àíbottom maxx = Xwidth # canvas width _________________________ 19maxy = Yheight # canvas height | | |tm | lm = 0.10 ‚àómaxx # left margin | ___ | ____ | _______ ___ | rm = 0.90 ‚àómaxx # right margin |lm | | | | bm = 0.85 ‚àómaxy # bottom margin | ___ | | | | 23tm = 0.10 ‚àómaxy # top margin |__ |__| ____________ | | mx = (lm ‚àírm)/( xl ‚àíxr) # || b m r m || bx = (xl ‚àórm‚àíxr‚àólm)/(xl ‚àíxr) # | |__| ____________ | | my = (tm ‚àíbm) /( yt ‚àíyb) #| | 27by = (yb ‚àótm‚àíyt‚àóbm) /(yb ‚àíyt) # | _______________________ | linearTr = [mx, bx, my, by] returnlinearTr # returns 346 15 Nonlinear Population Dynamics 31# Plot y , x , axes ; world coord converted to canvas coordinates defxyaxis(mx, bx, my, by): # to be called after call workd2sc x1 = (int)(mx ‚àóminx + bx) # minima and maxima converted to x2 = (int)(mx ‚àómaxx + bx) # canvas coordinades 35y1 = (int)(my ‚àómaxy + by) y2 = (int)(my ‚àóminy + by) yc = (int)(my ‚àó0.0 + by) c.create_line(x1, yc, x2, yc, fill = \""red\"") #xa x i s 39c.create_line(x1, y1, x1, y2, fill = ‚Äôred‚Äô) #y‚àíaxis foriin range (7): #xt i c s x=m i n x+( i ‚àí1)‚àó0.1 # world coordinates x1 = (int)(mx ‚àóx+b x ) # canvas coord 43 x2 = (int)(mx ‚àóminx + bx) y=m i n y+i ‚àó0.5 # real coordinates y2 = (int)(my ‚àóy+b y ) # canvas coords c.create_line(x1, yc ‚àí4, x1, yc + 4, fill = ‚Äôred‚Äô) #t i c sx 47 c.create_line(x2 ‚àí4, y2, x2 + 4, y2, fill = ‚Äôred‚Äô) #t i c sy c.create_text(x1 + 10, yc + 10, text = ‚Äô percent5.2f‚Äô percent( x ), \ fill = ‚Äôred‚Äô, anchor = E) #xa x i s c.create_text(x2 + 30, y2, text = ‚Äô percent5.2f‚Äô percent( y ) ,f i l l= ‚Äôred‚Äô,\ 51 anchor = E) #ya x i s c.create_text(70, 30, text = ‚ÄôEntropy‚Äô ,f i l l= ‚Äôred‚Äô, anchor = E) c.create_text(420, yc ‚àí10, text = ‚Äômu‚Äô,f i l l= ‚Äôred‚Äô, anchor = E) 55mx, bx, my, by = world2sc(minx, maxy, maxx, miny) # returns list xyaxis(mx, bx, my, by) #a x e sv a l u e s mu0 = mumin ‚àómx + bx entr0 = my ‚àó0.0 + by 59formuinarange(mumin, mumax, dmu): # m u loop print(mu) forjin range (1, nbin): prob[j] = 0 63y= 0 . 5 fornin range (1, nmax + 1): y=m u ‚àóy‚àó(1.0‚àíy) # Logistic m a p, Skip transients if(n > 30000): 67 ibin =int(y‚àónbin) + 1 prob[ibin] += 1 entropy = 0. foribinin range (1, nbin): 71 if(prob[ibin]>0): entropy = entropy ‚àí(prob[ibin]/nmax) ‚àómath.log10(prob[ibin]/nmax) entrpc = my ‚àóentropy + by # entropy to canvas coords muc = mx ‚àómu + bx # m u to canvas coords 75c.create_line(mu0, entr0, muc, entrpc, width = 1, fill = ‚Äôblue‚Äô) mu0 = muc #b e g i nv a l u e sf o rn e x tl i n e entr0 = entrpc root.mainloop() # m a k e s effective events Listing 15.4 PredatorPrey.py Computespopulationdynamicsforagroupofinteracting predatorsandprey. # PredatorPrey .py: Lotka ‚àíVolterra models fromvisualimport ‚àó 4fromvisual.graph import ‚àó Tmin = 0.0 Tmax = 500.0 8y=z e r o s (( 2 ), float) Ntimes = 1000 y[0] = 2.0 y[1] = 1.3 12h = (Tmax ‚àíTmin)/Ntimes t=T m i n deff( t, y, F): # Modify this function for your problem 15.6 Code Listings 347 16 F[0] = 0.2 ‚àóy[0] ‚àó(1‚àí(y[0]/(20.0) )) ‚àí0.1‚àóy[0] ‚àóy[1] F[1] = ‚àí0.1‚àóy[1] + 0.1 ‚àóy[0] ‚àóy[1]; defrk4(t, y, h, Neqs): #r k 4m e t h o d , D O N O Tm o d i f y 20F=z e r o s( ( N e q s ), float) ydumb = zeros((Neqs) , float) k1 = zeros((Neqs) , float) k2 = zeros((Neqs) , float) 24k3 = zeros((Neqs) , float) k4 = zeros((Neqs) , float) f(t, y, F) foriin range (0, Neqs): 28 k1[i] = h ‚àóF[i] ydumb[i] = y[i] + k1[i]/2. f(t +h/2., ydumb, F) foriin range (0, Neqs): 32 k2[i] = h ‚àóF[i] ydumb[i] = y[i] + k2[i]/2. f(t +h/2., ydumb, F) foriin range (0, Neqs): 36 k3[i] = h ‚àóF[i] ydumb[i] = y[i] + k3[i] f(t +h, ydumb, F) foriin range (0, Neqs): 40 k4[i] = h ‚àóF[i] y[i] = y[i] + (k1[i] + 2. ‚àó(k2[i] + k3[i]) + k4[i])/6. graph1 = gdisplay(x= 0,y= 0, width = 500, height = 400, \ 44 title = ‚ÄôPrey p(green) and predator P(yellow) vs time‚Äô ,xtitle = ‚Äôt‚Äô,\ ytitle = ‚ÄôP, p‚Äô,xmin=0,xmax=500,ymin=0,ymax=3.5) funct1 = gcurve(color = color.yellow) funct2 = gcurve(color = color.green) 48graph2 = gdisplay(x= 0,y= 400, width = 500, height = 400, title = ‚ÄôPredator P vs prey p‚Äô , xtitle = ‚ÄôP‚Äô, ytitle = ‚Äôp‚Äô,xmin=0,xmax=2.5,ymin=0,ymax=3.5) funct3 = gcurve(color = color.red) 52 fortinarange(Tmin, Tmax + 1, h): funct1.plot(pos = (t, y[0]) ) funct2.plot(pos = (t, y[1]) ) 56funct3.plot(pos = (y[0], y[1]) ) rate(60) rk4(t, y, h, 2)",8044
Chapter 16 Nonlinear Dynamics of Continuous Systems. 16.1.1 Free Pendulum Oscillations,"348 16 Nonlinear Dynamics of Continuous Systems In Chapter 15 we explored the complex dynamics and chaos that occur in population models. In this chapter we explore physical systems that exhibit chaos, and, in particular, the driven realistic pendulum. The focus is on understanding chaos and using phase space to uncover the simplicity underlying complex behaviors. 16.1 The Chaotic Pendulum Problem Computethemotionofadrivenpendulumwithnorestrictionsonthemagni- tudeofthedisplacements. Althoughtheplanependulumisaclassicsubjectforphysics,itisusuallystudiedforsmall displacements.Thatmaybeokayforlargegrandfatherclocks,butnotforthischapter.We willlookata chaoticpendulum ,i.e.,onewithfrictionandadrivingtorque(Figure16.1left) andwithnorestrictiontosmalldisplacements[Rasband,1990].Newton‚Äôslawsofrotational motiontellusthatthesumofthegravitationaltorque ‚àímglsinùúÉ,thefrictionaltorque ‚àíùõΩÃáùúÉ, andtheexternaltorque ùúè0cosùúîtequalsthemomentofinertiaofthependulumtimesits angularacceleration: ‚àímglsinùúÉ‚àíùõΩdùúÉ dt+ùúè0cosùúît=Id2ùúÉ dt2, (16.1) ‚áí‚àíùúî2 0sinùúÉ‚àíùõºdùúÉ dt+fcosùúît=d2ùúÉ dt2, (16.2) ùúî0=mgl I,ùõº=ùõΩ I,f=ùúè0 I. (16.3) Equation (16.2) is a second-order, time-dependent, nonlinear differential equation. The nonlinearityarisesfromthesin ùúÉdependenceofthegravitationaltorque.Theconstant ùúî0 is the natural frequency of oscillationsfor small displacements, with onlya gravitational torque.Theparameter ùõºisameasureofthestrengthoffriction,andtheparameter fisa measureofthestrengthoftheexternaldrivingtorque.InourstandardODEform, dy‚àïdt=f ofChapter8,wehavetwo,simultaneous,first-orderequations: ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH",1711
16.2 Phase Space,"16.1 The Chaotic Pendulum 349 dy(0) dt=y(1), (16.4) dy(1) dt=‚àíùúî2 0siny(0)‚àíùõºy(1)+fcosùúît, y(0)=ùúÉ(t),y(1)=dùúÉ(t) dt. (16.5) 16.1.1 Free Pendulum Oscillations Ifweignorefrictionandtheexternaltorque,Newton‚Äôslaw(16.2)takesthesimple,yetnon- linearform: d2ùúÉ dt2=‚àíùúî2 0sinùúÉ. (16.6) Ifthedisplacementsaresmall,wecanapproximatesin ùúÉbyùúÉandobtainthefamiliarlinear equationofsimpleharmonicmotionwithfrequency ùúî0: d2ùúÉ dt2‚âÉ‚àíùúî2 0ùúÉ‚áíùúÉ(t)=ùúÉ0sin(ùúî0t+ùúô). (16.7) InChapter8,westudiedhownonlinearitiesproduceanharmonicoscillations,and,indeed, (16.6)isanothergoodcandidateforsuchstudies.Asinthatchapter,weexpectsolutions of(16.6)tobeperiodic,butwithafrequency ùúîthatequals ùúî0onlyforsmalloscillations. Furthermore,becausetherestoringtorque, mglsinùúÉ‚âÉmgl(ùúÉ‚àíùúÉ3‚àï3),islessthanthe mglùúÉ assumedinaharmonicoscillator,realisticpendulumsswingslower(havelongerperiods) astheirangulardisplacementsaremadelarger. 16.1.2 Analytic Solution as Elliptic Integrals Theanalyticsolutiontotherealisticpendulumisastandardtextbookproblem[Landauand Lifshitz,1976;MarionandThornton,2019;Scheck,2010].However,itisaratherlimited solutionasitisonlyfortheperiod T,anditisintermsofintegralsthatmustbeevaluated numerically.Thissolutionisbasedonenergybeingaconstant(integral)ofthemotion,and isforthependulumreleasedfromrestatitsmaximumdisplacement ùúÉm,whereitsenergy isallpotential(Figure16.1): E=PE(t=0)=mgl‚àímglcosùúÉm=2mglsin2( ùúÉm 2) . (16.8) f m m2m1 Œ∏ Œ∏2Œ∏1 Œ±ll1 l2 Figure 16.1 Left: A pendulum of length ldriven through resistive air (dotted arcs) by an external sinusoidal torque (semicircle). The strength of the external torque is given by fand that of air resistance by ùõº.Right: A double pendulum (Section 16.4.1) with neither air resistance nor a driving force. In both cases, there is a gravitational torque and the possibility of chaos. (The study of the single pendulum to follow can be replaced by the study of the double pendulum.) 350 16 Nonlinear Dynamics of Continuous Systems Yet,because E=KE+PEisaconstant,wecanexpresstheenergyforanyvalueof ùúÉ,and thengoontosolvefortheperiod: 2mglsin2ùúÉm 2=1 2I( dùúÉ dt)2 +2mglsin2ùúÉ 2, ‚áídùúÉ dt=2ùúî0[ sin2ùúÉm 2‚àísin2ùúÉ 2]1‚àï2 ‚áídt dùúÉ=T0‚àïùúã [sin2(ùúÉm‚àï2)‚àísin2(ùúÉ‚àï2)]1‚àï2, ‚áíT 4=T0 4ùúã‚à´ùúÉm 0dùúÉ [sin2(ùúÉm‚àï2)‚àísin2(ùúÉ‚àï2)]1‚àï2, (16.9) ‚áíT‚âÉT0[ 1+( 1 2)2 sin2ùúÉm 2+( 1‚ãÖ3 2‚ãÖ4)2 sin4ùúÉm 2+¬∑¬∑¬∑] . (16.10) Becausethemotionisperiodic,wehaveassumedthatittakes T‚àï4forthependulumtotravel fromùúÉ=0toùúÉ=ùúÉm.Theintegralin(16.9)canbeexpressedasan ellipticintegralofthefirst kind.Ifyouthinkofanellipticintegralasageneralizationofatrigonometricfunction,then thisisaclosed-formsolution;otherwise,it‚Äôsanintegralneedingcomputation.Theseries expansionoftheperiod(16.10)isobtainedbyexpandingthedenominatorandintegrating ittermbyterm.Ittellsus,forexample,thatanamplitudeof80‚àòleadstoaperiod10  percentlonger thanthesmall ùúÉperiod.Wewilldeterminetheperiodcomputationallywithouttheneed foranyexpansions. 16.1.3 Free Pendulum Implementation and Test Asapreliminarytothesolutionofthefullequation(16.2),modifyyour rk4programtosolve (16.6)forthefreeoscillationsofarealisticpendulum. 1) Start your pendulum at ùúÉ=0 withÃáùúÉ(0)‚â†0.",3050
16.2 Phase Space,"Gradually increase ÃáùúÉ(0)to increase the importanceofnonlineareffects. 2) Testyourprogramforthelinearcase(sin ùúÉ‚ÜíùúÉ)andverifythat: a) Yoursolutionisharmonicwithfrequency ùúî0=2ùúã‚àïT0,andthat, b) Thefrequencyofoscillationisindependentoftheamplitude. 3) Deviseanalgorithmtodeterminetheperiod Toftheoscillationbycountingthetimeit takesforthreesuccessivepassesoftheamplitudethrough ùúÉ=0.(Youneed threepasses to handlethecase wherethe oscillationis notsymmetricaboutthe origin.)Test your algorithmforsimpleharmonicmotionwhereyouknow T0. 4) For the realistic pendulum, observe the change in period as a function of increasing initialenergy.Plotyourobservationsalongwith(16.10). 5) Verify that as the initial KEapproaches 2 mgl, the motion remains oscillatory but not harmonic. 6) AtE=2mgl(theseparatrix),themotiontransitionsfromoscillatorytorotational(‚Äúover the top‚Äù or ‚Äúrunning‚Äù). See how close you can get to the separatrix and to its infinite period. 7)‚äôConvert your numerical data to sound and listen to the difference between har- monicmotion(boring)andanharmonicmotioncontainingovertones(interesting).In Figure16.2,weshowsometypicalresults. 16.2 Phase Space 351 Figure 16.2 T h ed a t as c r e e n( left) and the output screen ( right) of the applet HearData that converts data into sounds. Columns of [ ti,x(ti)] data are pasted into the data window, processed into the graph in the output window, and then converted to sound data that are played by Java. (Applets have now been outlawed.) 16.2 Phase Space Theconventionalsolutiontoanequationofmotionistheposition x(t)andthevelocity ùë£(t) asfunctionsoftime.Oftenbehaviorsthatappearcomplicatedasfunctionsoftimeappear as familiar-looking geometric figures when viewed in the more abstract phasespace .F o r thependulum,thephasespaceordinateisthevelocity ùë£(t),andtheabscissaistheposition x(t)(Figure16.3,top).Furthermore,themotionofacomplexsystem,whenviewedinphase spaceovertime,oftendisplaysamovementback-and-forthfromonephasespacestructure toanother,abehaviorknownas strangeattraction .Thisiseasytounderstand.Forexample, the position and velocity of a free harmonic oscillator are given by the trigonometric functions x(t)=Asin(ùúît),ùë£(t)=dx dt=ùúîAcos(ùúît). (16.11) Pendulum falls back  Rotating solutions Pendulum starts rotating  ‚Äì4 V(Œ∏)‚Äì202 ‚Äì 2 02468 1 0 Œ∏Œ∏‚Ä¢ Figure 16.3 Top: Phase space trajectories for a pendulum including ‚Äúover the top‚Äù motions. At the bottom of the Ô¨Ågure is shown the corresponding ùúÉdependence of the potential. 352 16 Nonlinear Dynamics of Continuous Systems Whensubstitutedintothetotalenergy,weobtaintwoimportantresults: E=KE+PE=( 1 2m) ùë£2+( 1 2ùúî2m2) x2(16.12) =mùúî2A2 2cos2(ùúît)+mùúî2A2 2sin2(ùúît)=1 2mùúî2A2. (16.13) Equation(16.12),beingthatofanellipsein x-ùë£space,indicatesthattheharmonicoscillator followsclosedellipticalorbitsinphasespace,withthesizeoftheellipseincreasingwiththe system‚Äôsenergy.Equation(16.13)provesthatthetotalenergyisaconstantofthemotion. Different initial conditions having the same energy start at different places on the same ellipse,yettransversethesameorbits. Herearesomephasespacestructuresandbehaviorsthatyouwillbeaskedtoobservein yoursimulations: Ellipses:The orbitsofanharmonicoscillationswillstill be ellipse-like,but withangular cornersthatbecomemoredistinctwithincreasingnonlinearity(Figure16.4right).",3294
16.2 Phase Space,"Closedfigures: LikethoseinFigures16.3and16.4,describeperiodic(notnecessarilyhar- monic)oscillationswiththesame (x,ùë£)occurringagainandagain.Therestoringforce leadstoclockwisemotion. Openorbits: LikethoseinFigures16.3and16.4left,theycorrespondtononperiodicor ‚Äúrunning‚Äùmotion(apendulumrotatinglikeapropeller).Regionswherethepotentialis repulsivealsoleadtoopentrajectoriesinphasespace. Separatrix: As seen on top of Figure 16.3, this is an orbit in phase space that separates openandclosedorbits.Motionontheseparatrixisindeterminate,asthependulummay balance,ormoveeitherwayatthemaximumpotential. Non-crossingorbits: Becausesolutionsfordifferentinitialconditionsareunique,differ- entorbitsdonotcross.Yetdifferentinitialconditionscancorrespondtodifferentstarting positionsalongasingleorbit. Hyperbolicpoints: Openorbitsintersectatpointsofunstableequilibriumcalled hyper- bolicpoints (Figure16.4left),atwhichpointanindeterminacyresults. x xx v(t) v(t) v(t)V(x) V(x) V(x) x(t) x(t)x(t)E1 E1E1E1E2 E2E3 E3 Figure 16.4 Three potentials and their behaviors in phase space. The different orbits below the potentials correspond to different energies, as indicated by the limits of maximum displacements within the potentials (dashed lines). Left: A repulsive potential leads to open orbits. The central crossing is an unstable hyperbolic point. Middle : The symmetric harmonic oscillator potential leads to symmetric ellipses. Right: A nonharmonic oscillator for small oscillations producing structures that are neither ellipses nor symmetric. 16.2 Phase Space 353 Figure 16.5 Position versus time and position versus velocity for two initial conditions of a chaotic pendulum that ends up with the same limit cycle. (W. Hager.) x tv x Fixedpoints: Theinclusionoffrictionmaycausetheenergyinasystemtodecreasewith time,leadingtophase-spaceorbitsthatspiralintoasingle fixed-point.However,ifthere isanexternaldrivingforce,thenthesystemwouldmoveawayfromthefixedpoint. Limitcycle: Iftheparametersarejustright,aclosedellipse-likefigurecalleda limitcycle mayoccur(Figure16.5right).Here,theaverageenergyputintothesystemduringone periodexactlybalancestheaverageenergydissipatedbyfrictionduringthatperiod: ‚ü®fcosùúît‚ü©=‚ü® ùõºdùúÉ dt‚ü© =‚ü® ùõºdùúÉ(0) dtcosùúît‚ü© ‚áíf=ùõºdùúÉ(0) dt. (16.14) Whileasystemmaymoveintoalimitcycle,itmayalsomakesporadicjumpsfromone limitcycletoanother. Predictableattractors: Theorbits,suchasfixedpointsandlimitcycles,intowhichthe systemsettlesorreturnstooften,andthatarenotparticularlysensitivetoinitialcondi- tions.Ifyourlocationinphasespaceisnearapredictableattractor,ensuingtimeswill bringyoutoit. Strangeattractors: Well-defined,yetcomplicated,semiperiodicbehaviorsthatappearto be uncorrelated with the motion at an earlier time. These are distinguished from pre- dictableattractors by being fractal (Chapter 14) and highly sensitive to the initial con- ditions[Jos√©andSalatan,1998].Evenaftermillionsofoscillations,themotionremains attractedtothem. Modelocking: Whenthemagnitudeofthedrivingforceislargerthanthatforalimitcycle (16.14), the driving force can overpower the natural oscillations, resulting in a steady- statemotionatthefrequencyofthedriver.Whilemodelockingcanoccurforlinearor nonlinearsystems,fornonlinearsystemsthedrivingtorquemaylockontoanovertone, leadingtoarationalrelationbetweenthedrivingfrequencyandthenaturalfrequency. ùúî ùúî0=n m,n,m=integers. (16.15) Randommotion: Appearsinphasespaceasadiffusecloudfillingtheentireenergetically accessibleregion. Chaotic paths: While periodic motion produces closed figures in phase space, and ran- dom motion a cloud, chaotic motion falls someplace in between, with dark or diffuse bandsratherthansinglelines(Figure16.7).Thecontinuityoftrajectorieswithinbands means that the system flows continuously among the different trajectories within the band,whichmaywelllookverycomplicatedorchaoticinnormalspace.Theexistence of these bands helps explain why the solutions are hypersensitive to the initial condi- tionsandparametervalues;theslightestchangeinvaluesmaycausethesystemtoflow tonearbytrajectorieswithintheband. Butterflyeffect: Thehypersensitivityofchaoticweathersystemsmay,theoretically,leadto theweatherpatterninNorthAmericabeingsensitivetotheflappingofabutterfly‚Äôswings inSouthAmerica.Althoughthisappearstobecounterintuitivebecauseweknowthat",4285
16.3 Chaotic Explorations,"354 16 Nonlinear Dynamics of Continuous Systems systemswithessentiallyidenticalinitialconditionsshouldbehavethesame,eventually thesystemsdiverge.Asseenontheright,inFigure16.8,theinitialconditionsforboth pendulumsdifferbyonly1 partin917,andso theinitialpathsinphasespacearethe same.Nonetheless,atjustthetimeshownhere,thependulumsbalanceinthevertical position,andthenonefallsbeforetheother,leadingtodifferingoscillationsanddiffering phase-spaceplotsfromthistimeonward. 16.3 Chaotic Explorations A challenge in understanding simulations of the chaotic pendulum (16.4) is that the 4D parameterspace (ùúî0,ùõº,f,ùúî)issoimmensethatonlysectionsofitcanbestudiedsystem- atically. We would expect that sweeping through the driving frequency ùúîshould show resonancesandbeating;sweepingthroughthefrictionalforce ùõºshouldshowunderdamp- ing,criticaldamping,andoverdamping;andsweepingthroughthedrivingtorque fmight showresonancesandmodelocking.Youshouldbeabletoobserveallofthesebehaviorsin yoursimulations,althoughtheyaresomewhatmixedtogether. StartbytryingtoreproducethebehaviorshowninFigures16.6and16.7. Beware:,because thisisapotentiallychaoticsystem,yoursolutionsmaybehighlysensitivetotheexactvalues oftheinitialconditionsandtothedetailsofyourintegrationroutine.Wesuggestthatyou Many cycles 1 cycle 3 cyclesŒ∏(0)  = 0.219 Œ∏(0)  = 0.725 Œ∏(0)  = ‚Äì0.8 02 0‚Äì10‚Äì2 ‚Äì101 02 ‚Äì202 0 0 ‚Äì2 2 ‚Äì8 ‚Äì4 4 00 100 200 0004 ‚Äì4 ‚Äì82 100 200 00 ‚Äì10 ‚Äì2100 200 40 0002 128 4Y(œâ)Œ∏ vs Œ∏‚Ä¢Œ∏ vs t 0 20 40 0 20 40 Figure 16.6 The position versus time, phase space plot, and Fourier spectrum for a chaotic pendulum with ùúî0=1,ùõº=0.2,f=0.52, and ùúî=0.666. The three differ only in initial conditions. 16.3 Chaotic Explorations 355 ‚Äì10‚Äì202‚Äì2‚Äì10 20 0 0 200 400 600 Timef = 0.54f = 0.52 Œ∏(t) Œ∏(t) Œ∏(t)Œ∏(Œ∏) Œ∏(Œ∏)0 ‚Äì10 ‚Äì15 200 4000 02 01 0 2 0 Figure 16.7 The behavior of a chaotic pendulum with slightly differing driving forces ( f=0.52, 0.54). On the left are the phase-space plots and on the right are plot position versus time. For f=0.54, there occur the characteristic broadbands of chaos. experiment;startwiththeparametervaluesweusedtoproduceourplots,andthenobserve theeffectsofmaking verysmallchangesintheparametersuntilyouobtaindifferentmodes ofbehavior.Herearetherecommendedsteps: 1) Takeyoursolutiontotherealisticpendulumandincludefriction.Runitforavariety ofinitialconditions,includingover-the-topones.Asnoenergyisfedtothesystem,you shouldseespiralsinphasespace.Note,ifyouplotthephase-spacepointsatuniformtime steps,withoutconnectingthem,thenthespacingbetweenthepointsgivesanindication ofthespeedanddirectionoftravelofthependulum. 2) Try several small values for the driving torque, but without friction. Verify that you obtaindistortedellipsesinphasespace. 3) Turn friction back on and set the driving torque‚Äôs frequency close to the natural fre- quencyùúî0.Searchforbeats.Note,youmayneedtoadjustthemagnitudeandphaseof thedrivingtorquetoavoidan impedancemismatch betweenthependulumanddriver (beingdriventotherightwhilemovingtotheleft). 4) Finally,scanthroughfrequencies ùúîofthedrivingtorque,andsearchfornonlinearres- onance(itlookslikebeating). 5)Explorechaos :StartoffwiththeinitialconditionsweusedforFigure16.6: (x0,ùë£0)=( ‚àí0.0885,0.8),(‚àí0.0883,0.8),(‚àí0.0888,0.8). (16.16) Tosavetimeandstorage,youmaywanttousealargertimestepforplottingthanthe oneusedtosolvethedifferentialequations. 6) Identifywhichpartsofthephasespaceplotscorrespondtotransients.",3399
16.3.2 Chaotic Bifurcations,"356 16 Nonlinear Dynamics of Continuous Systems Figure 16.8 Left: The phase space plot for two pendulums with almost exactly the same initial conditions. Both arrive at the top (the separatrix), where one goes over the top while the other falls back down. Right: The long-term phase space plots for these same pendulums showing dark limit cycles. 7) Ensurethatyoufindthefollowing a) aperiod-3limitcyclewherethependulumjumpsbetweenthreemajororbits, b) arunningsolutionwherethependulumkeepsgoingoverthetop, c) chaoticmotioninwhichpathsinthephasespacearecloseenoughtogethertoappear asbands. 8) Look for the ‚Äúbutterfly effect‚Äù (Figure 16.8, left) by starting two pendulums off with identicalpositions,butwithvelocitiesthatdifferby1partin1000.Noticethattheinitial motionsareessentiallyidentical,buteventuallydiverge. 16.3.1 Phase Space Without Velocities Imaginethatyouhavemeasuredthedisplacementofasystemasafunctionoftime.Your measurementsappeartoindicatenonlinearbehaviors,andyouwouldliketoviewthesys- teminphasespace,butdon‚Äôthavedataontheconjugatemomentaorvelocity.Amazingly enough, a plot of x(t+ùúè)versus x(t)as a function of talso produces a phase space plot [Abarbanel etal.,1993].Here ùúèisalagtime,andshouldbechosenassomefractionofa characteristictimeforthesystem.Whilethismaynotseemlikeavalidphasespaceplot, thinkoftheforwarddifferenceapproximationforthevelocity, ùë£(t)=dx(t) dt‚âÉx(t+ùúè)‚àíx(t) ùúè. (16.17) Thusplotting x(t+ùúè)versusx(t)issomewhatrelatedtoplotting ùë£(t)versusx(t). Exercise Createaphasespaceplotfromtheoutputofyourchaoticpendulumbyplotting ùúÉ(t+ùúè)versusùúÉ(t)foralargerangeof tvalues.Explorehowthegraphschangefordifferent valuesoflagtime ùúè.Compareyourresultstotheconventionalphasespaceplotsyouhad obtainedpreviously.",1724
16.4 Other Chaotic Systems,"16.3 Chaotic Explorations 357 Figure 16.9 A bifurcation diagram for the damped pendulum with a vibrating pivot (see also the similar diagram for a double pendulum, Figure 16.11). The ordinate is |dùúÉ‚àïdt|,t h e absolute value of the instantaneous angular velocity at the beginning of the period of the driver, and the abscissa is the magnitude of the driving force f. Note that the heavy line results from the overlapping of points, not from connecting the points (see enlargement in the inset). 01202 f‚îÇŒ∏(t)‚îÇ 16.3.2 Chaotic Bifurcations Wehaveobservedthatachaoticsystemcontainsanumberofdominantfrequencies,and thatthesystemtendsto‚Äújump‚Äùfromoneoscillatorymodetoanother.Thisimpliesthatthe dominantfrequenciesoccursequentially,andnotsimultaneously,astheydointheFourier analysisoflinearsystems. Below,weoutlinethedetailedstepstoexplorethispossibilityasacomputerexperiment. Onestartsbyrecordingtheinstantaneousangularvelocity ÃáùúÉ=dùúÉ‚àïdtofthesolutionatvari- ousinstancesintime.Bythinkingof dùúÉ‚àïdtasafrequency,weobtainaseriesoffrequencies, and,presumably,withthemajorFouriercomponentsoccurringmostoften,asifthesystem isattractedtothem.Amazingly,whenascatterplotofthesampled ÃáùúÉ‚Äôsisconstructedasa functionofthedrivingforce,abifurcationdiagramsimilartothatofthelogisticmap(bugs) results. SuchascatterplotisshowninFigure16.9forachaoticpendulumwithavibratingpivot point(incontrasttoourusualvibratingexternaltorque): d2ùúÉ dt2=‚àíùõºdùúÉ dt‚àí(ùúî2 0+fcosùúît)sinùúÉ. (16.18) Analytic and numerical studies of this system are present in the literature [Landau and Lifshitz, 1976; DeJong, 1992; Gould et al., 2006]. To obtain the bifurcation diagram in Figure16.9: 1) Usetheinitialconditions ùúÉ(0)=1andÃáùúÉ(0)=1. 2) Setùõº=0.1,ùúî0=1,ùúî=2,andvary0 ‚â§f‚â§2.25. 3) To permit transients to die off, wait 150 periods of the driver for each fvalue before sampling. 4) Sample ÃáùúÉfor150timesatthoseinstancesatwhichthedrivingforcepassesthroughzero (orwhenthependulumpassesthroughitsequilibriumposition). 5) Plot150valuesof |ÃáùúÉ|versusf. 16.3.3 Fourier or Wavelet Analysis Wehaveseenthatarealisticpendulumexperiencesagravitationalrestoringtorque ùúèg‚àùsinùúÉ‚âÉùúÉ‚àíùúÉ3 3.++ùúÉ5 5.+¬∑¬∑¬∑. (16.19)",2125
16.4.3.1 Hard Disk Scattering,"358 16 Nonlinear Dynamics of Continuous Systems Thenonlineartermsleadtononharmonicbehaviorinafreependulum.Whenthependu- lumisdrivenbyanexternalsinusoidaltorque,itmay modelockwiththedriverandoscillate atafrequencythatisrationallyrelatedtothedriver‚Äôsfrequency.Consequently,thebehav- ioroftherealisticpendulumisexpectedtobeacombinationofvariousperiodicbehaviors, withdiscretejumpsbetweenthem(asdiscussedinSection16.3.2). Inthisassessment,youareaskedtodeterminetheFouriercomponentspresentinsome ofthependulum‚Äôscomplicatedbehaviors.Youshouldfindathree-cyclestructurecontain- ingthreemajorFouriercomponents,andafive-cyclestructurewithmorefrequencies.You should also notice that when the pendulum goes over the top, its spectrum contains a steady-state(DC)component. 1) Dustoffyourprogramforanalyzingsignal y(t)intoFouriercomponents. 2) Applyyouranalyzertothesolutionofthechaoticpendulumforcaseswherethereare one-, three-, and five-cycle structures in phase space. Deduce the major frequencies containedinthesestructures.Waitforthetransientstodieoutbeforeconductingyour analysis. 3) CompareyourresultstothoseinFigure16.6. 4) SeeifyoucandeducearelationamongtheFouriercomponents,thenaturalfrequency ùúî0,andthedrivingfrequency ùúî. 5) A signal of chaos is a broadband Fourier spectrum, though not necessarily a flat one. Examineyoursystemforparametersthatgivechaoticbehavior,andverifythisstatement byplottingthepowerspectrumonbothlinearandsemi-logarithmicplots. WaveletExploration WesawinChapter10thatawaveletexpansionismoreappropri- atethanaFourierexpansionforsignalscontainingcomponentsthatoccurforonlyfinite periodsoftime.Chaoticoscillationsarejustsuchsignals.RepeattheFourieranalysisofthis sectionusingwaveletsinsteadofsinesandcosines.Canyoudiscernthetemporalsequence ofvariouscomponents? 16.4 Other Chaotic Systems 16.4.1 The Double Pendulum Thestudyweoutlinedpreviouslyforthechaoticpendulumcanberepeated,orreplaced, byonefortherealisticdoublependulum.Figures16.1and16.10showsuchasystem.As shownontherightofFigure16.1,thedoublependulumhasasecondpendulumconnected tothefirst,butnoexternaldrivingforce.Inthiscase,eachpendulumactsasadrivingforce fortheother,andsothereareenoughdegreesoffreedomforchaoticbehaviortooccur,even withoutanexternaldrivingforce. The equations of motions for the double pendulum are derived most directly from the Lagrangianformulationofmechanics.TheLagrangianisfairlysimple,butwiththe ùúÉ1and ùúÉ2motionsinnatelycoupled: L=KE‚àíPE=1 2(m1+m2)l2 1ÃáùúÉ12+1 2m2l2 2ÃáùúÉ22(16.20) +m2l1l2ÃáùúÉ1ÃáùúÉ2cos(ùúÉ1‚àíùúÉ2)+(m1+m2)gl1cosùúÉ1+m2gl2cosùúÉ2. Textbooksusuallyapproximatetheseequationsforsmalloscillations,whichdiminishthe nonlinear effects, and conclude that the system contains ‚Äúslow‚Äù and ‚Äúfast‚Äù modes. More 16.4 Other Chaotic Systems 359 Figure 16.10 Photographs of a double pendulum built by a student after running his simulation (there is a video DoublePend.mp4 ). The upper pendulum consists of two separated shafts so that both pendulums can go over their tops. The Ô¨Årst two frames show the pendulum released from rest and then moving quickly through various modes. The photographs with a faster shutter speed stop the motion in various stages (R. Landau (Author)). 00 4 ‚Äì810 0 Angular velocity oflower pendulum 10 Mass of upper pendulumAngular velocity versus mass Œ∏2 Œ∏2 Figure 16.11 Left: Phase space trajectories for a double pendulum with m1=10m2and with two dominant attractors. Right: A bifurcation diagram for the double pendulum displaying the instantaneous velocity of the lower pendulum as a function of the mass of the upper pendulum. (J. Danielson.) interestingmodesresultwhennosmall-angleapproximationsaremade,andwhenthepen- dulumsaregivenenoughinitialenergytogooverthetop.OntheleftofFigure16.11,we seeseveralphase-spaceplotsofthelowerpendulum‚Äôsmotionfor m1=10m2.Whengiven enoughinitialkineticenergytogooverthetop,thetrajectoriesareseentoflowbetween twomajorattractors,withenergybeingtransferredbackandforthbetweenthependulums. OntherightofFigure16.11,isabifurcationdiagramforthedoublependulum.Thiswas createdbysamplingandplottingtheinstantaneousangularvelocity ÃáùúÉ2ofthelowerpendu- lum70timesatinstanceswhenthependulumpassedthroughitsequilibriumposition.The massoftheupperpendulum(aconvenientparameter)wasthenchanged,andtheprocess repeated. The resulting structure is fractal with bifurcations in the number of dominant frequenciesinthemotion.AplotoftheFourierorwaveletspectrumasafunctionofmass isexpectedtoshowsimilarcharacteristicfrequencies. 16.4.2 Billiards Derivingitsnamefromtheonce-popularparlorgame,amathematical billiardisadynami- calsysteminwhichaparticlemovesfreelyinastraightlineuntilithitsaboundarywall,at 360 16 Nonlinear Dynamics of Continuous Systems a, b c, d e f Figure 16.12 Square (a, c), circular (b, d), Sinai (e), and stadium billiards (f). The arrows are trajectories. The stadium billiard has two semicircles on the ends. whichpointitundergoesspecularreflection,andthencontinuesoninastraightlineuntil thenextcollision(Figure16.12).Theconfiningbilliardtablecanbesquare,rectangular,cir- cular,polygonal,acombinationofthepreceding,oreventhree-dimensional.Billiardsare Hamiltoniansystems in whichthere is no loss ofenergy,in whichthe motionscontinue endlessly,andwhichmaydisplaychaos. In Figure 16.12, we show square (a, c), circular (b, d), Sinai (e), and stadium billiards (f),withthearrowsindicatingpossibletrajectories.Notehowright-anglecollisionsleadto two-pointperiodicorbitsforbothsquareandcircularbilliards,whilein(c)and(d)wesee how45‚àòcollisionsleadstofour-pointperiodicorbits.Figures(e)and(d)shownonperiodic trajectoriesthatareergodic,thatis,orbitsthatwilleventuallypassthroughallpointsinthe allowedspace,andwhichcanbecomechaotic. 1) Computethetrajectoriesforthesefourbilliards,usingarangeofinitialconditions.In Listing 16.1, we give a sample program for a square billiard that produces a VPython animation.(InChapter24,wedothequantumversionofthisproblem.) 2) Plotthedistancebetweensuccessivecollisionpointsasafunctionofcollisionnumber. Theplotshouldbesimpleforperiodicmotion,butshouldshowirregularbehaviorasthe motionbecomeschaotic.Keeptrackofhowmanycollisionsoccurbeforechaossetsin (typically20‚Äì30).Youneedatleastthismanycollisionstotesthypersensitivitytoinitial conditions. 3) Sincenotallinitialconditionsleadtochaos,especiallyforcircles,youmayneedtoscan throughvariousinitialconditions. 4) For initial conditions that place you in the chaotic regime, explore the difference in behaviorforarelativelyslight( ‚â§10‚àí3)variationininitialconditions. 5) Tryinitialconditionsthatdifferatthemachineprecisionleveltogaugejusthowsensi- tivechaotictrajectoriesreallyaretoinitialconditions(bepatient). 16.4.3 Multiple Scattering Centers One expects the scattering of a projectile from a force center to be a continuous process. Nevertheless,whenthepotentialhasinternalstructureandtheprojectileundergoesmul- tipleinternalscatterings,complexbehaviorsmayresult.Wehavealreadyseensomeofthis",6913
16.4.4 Lorenz Attractors,"16.4 Other Chaotic Systems 361 Figure 16.13 One, two, and three stationary disks on a Ô¨Çat billiard table scatter point particles elastically, with some of the internal scattering leading to trapped, periodic orbits.R inSection13.3.1inourmodelforapinballmachine.Ifyouhavenotsolvedthatproblem already,youmaywanttodosonowandfocusonhowchaosshowsitselfthere. 16.4.3.1 Hard Disk Scattering Figure16.13showsone,two,andthreeharddisksattachedtothesurfaceofa2Dbilliard table.Ineachcase,thedisksscatterpointparticleselastically(noenergyloss).Thedisksall haveradius R,center-to-centerseparations a,withthethree-diskconfigurationformingan equilateraltriangle.Alsoshowninthefigureareimaginedtrajectoriesofparticlesscattered fromthedisks,withsomeoftheinternalscatteringleadingtotrapped,periodicorbitsin whichtheprojectilebouncesbackandforthendlessly.Forthetwo-diskcase,thereisjust asingletrappedorbit,butforthethree-diskcase,thereareinfinitelymany,andthatmay leadtochaos.InChapter24,weexplorethequantummechanicalversionofthisproblem. Listing24.2 3QMdisks.py inthatchapterhasapotentialsubroutinethatcanbeusedtomodel thepresentdisks. 1) ModifytheprogramalreadydevelopedinSection13.3.1forthestudyofscatteringfrom thefour-peakedGaussian(13.18)sothatitcanbeappliedtoscatteringfromone,two, orthreedisks.Orwriteanewone. 2) Because infinite potentials cannot be handled numerically, pick instead a very large valueforthepotential.Theexactvalueshouldnotmatteraslongasit‚Äôslargeenough sothatincreasingitsvalueshasnosignificanteffectonthescattering. 3) Plot a number of trajectories [x(t),y(t)]that show both usual and unusual behaviors. Inparticular,plotthoseforwhichback-anglescatteringoccurs,and,consequently,for whichtheremusthavebeensignificantnumberofmultiplescatterings. 4) Plotanumberofphasespacetrajectories [x(t), Ãáx(t)]and[y(t), Ãáy(t)].Howdothesediffer fromthoseofboundstates? 5) Startwithaprojectileat x‚âÉ‚àí ‚àû,thatis,atsomeverylargenumber,andatvariousdis- tances (impact parameters) y‚â°bfrom the center of the scattering region. Determine thescatteringangle ùúÉ=atan2(Vx,Vy) asafunctionof bbydeterminingthevelocitycom- ponents of the scattered particle after it has left the interaction region, that is, when PE‚àïE‚â§10‚àí10. 6) Plotthediscontinuitiesin dùúÉ‚àïdbandùúé(ùúÉ): ùúé(ùúÉ)=||||dùúÉ db||||b sinùúÉ(b). (16.21) 7) Explorethedifferentgeometriesinsearchforchaos.Thisshouldbenear a‚àïR‚âÉ6forthe threedisks. 16.4.4 Lorenz Attractors In1961,EdwardLorenzwasusingasimplifiedatmosphericconvectionmodeltopredict weatherpatterns[Lorenz,1963],andtosavetime,heenteredthedecimal0.506insteadof 362 16 Nonlinear Dynamics of Continuous Systems Figure 16.14 A 3D plot of a Lorenz attractor. enteringthefullvalue0.506127foraparameter[Peitgen etal.,1994;MotterandCampbell, 2013]. The results for the two numbers were so different that at first he thought it to be some kind of numerical error, but in time he realized that this was a nonlinear system withsomeunusualbehaviorthatwenowknowaschaos.Here,weaskyoutorepeathis discovery. Withsimplifiedvariables,theequationusedbyLorenzare Ãáx=ùúé(y‚àíx), (16.22) Ãáy=x(ùúå‚àíz)‚àíy, (16.23) Ãáz=‚àíùõΩz+xy. (16.24) Herex(t)isameasureoffluidvelocityasafunctionoftime t,y(t)andz(t)aremeasuresof thetemperaturedistributionsintwodirections,and ùúé,ùúå,andùõΩareparameters.Notethat thexzandxytermsmaketheseequationsnonlinear. 1) ModifyyourODEsolvertohandlethethree,simultaneousLorenzequations. 2) Startwiththeparametervalues ùúé=10,ùõΩ=8‚àï3,andùúå=28. 3) Makesuretousesmallenoughstepsizessothatgoodprecisionisobtained.Youmust haveconfidencethatyouareseeingchaosandnotnumericalerror. 4) Makeplotsof xversust,yversust,andzversust,andcomparethemtoFigure16.14. 5) The initial behavior in these plots are transientsand are not considered dynamically interesting.Leaveoffthesetransientsintheplotstofollow. 6) Makea‚Äúphasespace‚Äùplotof z(t)versusx(t)(theindependentvariable tdoesnotappear insuchaplot).Thedistorted,numbereight-likefiguresyouobtainaretheLorenzattrac- tors,towhichevenchaoticsolutionshaveanaffinity. 7) Makephasespaceplotsof y(t)versusx(t)andversus z(t). 8) Makea3Dplotof x(t)versusy(t)andversus z(t). 9) Theparametersgiventoyoushouldleadtochaoticsolutions.Checkthisclaimbyseeing how small a change you can make in a parameter value and still, eventually, obtain differentanswers.",4241
16.4.5 van der Pool Oscillator. Chapter 17 Thermodynamics Simulations and Feynman Path Integrals,"16.4 Other Chaotic Systems 363 16.4.5 van der Pool Oscillator ThevanderPoolequationdescribesthenonlinearbehaviorinonce-commonobjectssuch asvacuumtubesandmetronomes: d2x dt2+ùúá(x2‚àíx2 0)dx dt+ùúî2 0x=0. (16.25) 1) Explainwhy(16.25)describesanoscillatorwith x-dependentdamping. 2) Createphasespaceplots Ãáx(t)versusx(t). 3) Verifythatthisequationproducesalimitcyclewithorbitsinternaltothecyclespiraling outtothelimitcycle,andthoseexternaltoitspiralingintoit. 16.4.6 The DufÔ¨Ång Oscillator TheDuffingOscillatorisanotherexampleofadamped,driven,nonlinearoscillator.Itis describedbyadifferentialequation: d2x dt2=‚àí2ùõædx dt‚àíùõºx‚àíùõΩx3+Fcosùúît. (16.26) Ourcode rk4D uffing.py solvesaformofthisequation. 1) ModifyyourODEsolvertosolve(16.26). 2) Startwithparametervaluescorrespondingtoasimpleharmonicoscillator,andverify thatyouobtainsinusoidalbehaviorandanellipticalphasespaceplot. 3) Includeadrivingforce,wait100cyclesinordertoeliminatetransients,andthencreate aphasespaceplot.Weused ùõº=1.0,ùõΩ=0.2,ùõæ=0.2,ùúî=1.,F=4.0,x(0)=0.009,and Ãáx(0)=0. 4) Search for period-three solutions like those in Figure 16.15, where we used ùõº=0.0, ùõΩ=1.,ùõæ=0.04,ùúî=1.,andF=0.2. 5) Changeyourparametersto ùúî=1andùõº=0inordertomodelan Uedaoscillator. 100‚Äì0.6‚Äì0.4‚Äì0.20.00.20.40.4 0.3 0.2 0.1 0.0 ‚Äì0.1 ‚Äì0.2 ‚Äì0.3 ‚Äì0.4 ‚Äì0.6 ‚Äì0.4 ‚Äì0.2 0.0 0.2 0.4 0.60.6Duffing oscillator Phase diagram duffing oscillator 120 140 160 t180 200 x(t)x(t) v(t) Figure 16.15 A period three solution for a forced DufÔ¨Ång oscillator. Left:x(t)andRight:ùë£(t) versus x(t). 364 16 Nonlinear Dynamics of Continuous Systems 16.5 Code Listings Listing16.1 SqBilliardCM.py Trajectoriesformotiononasquarebilliardtable. # SqBillardCM.py: Animated classical billiards on square table 3fromvisualimport ‚àó dt = 0.01; Xo = ‚àí90.; Yo = ‚àí5.4; v = vector(13.,13.1) r0 = r= vector(Xo,Yo); eps = 0.1; Tmax = 500; tp = 0 7scene = display(width=500, height=500, range=120,\ background=color.white, foreground=color.black) table = curve(pos=([( ‚àí100,‚àí100,0),(100, ‚àí100,0),(100,100,0 ),\ (‚àí100,100,0),( ‚àí100,‚àí100,0)])) 11ball = sphere(pos=(Xo,Yo,0),color=color.red, radius=3,make_trail=True) fortinarange(0,Tmax,dt): rate(5000) 15tp = tp + dt r=r 0+v ‚àótp if(r.x>= 100orr.x<=‚àí100): # Right and left walls v=v e c t o r ( ‚àív.x,v.y,0) 19 r0 = vector(r.x,r.y,0) tp = 0 if(r.y>= 100orr.y<=‚àí100): # Top and bottom walls v=v e c t o r ( v . x , ‚àív.y,0) 23 r0 = vector(r.x,r.y,0) tp = 0 ball.pos = r",2384
17.1 An Ising Magnetic Chain,"365 17 Thermodynamics Simulations and Feynman Path Integrals The Ô¨Årst part of this chapter extends the Monte-Carlo techniques studied in Chapter 4,n o w to the thermal behavior of a magnetic chain. The second part of this chapter applies the Metropolis algorithm, just used in the simulation of thermal behavior, now to Feynman‚Äôs path integral formulation of quantum mechanics. The latter theory, while somewhat advanced for undergraduates, provides an unusual view of quantum mechanics, and is the basis for some of the most fundamental computations in physics . 17.1 An Ising Magnetic Chain Ferromagnetscontainfinitesize domainsinwhichthespinsofalltheatomspointinthe samedirection.Whenanexternalmagneticfieldisappliedtothesematerials,thedifferent domainsalign,andthematerialsbecome‚Äúmagnetized.‚ÄùYet,asthetemperatureisraised, thedegreeofmagnetismdecreases,untila phasetransition occursattheCurietemperature, andallmagnetizationvanishes. Problem Developamodelthatexhibitsthethermalbehaviorofferromagnets. ConsiderNmagnetic dipoles fixed in place on the links of a linear chain (Figure 17.1). Becausetheparticlesarefixed,weneednotworryaboutthesymmetryoftheirwavefunc- tion,ortheirpositions,ortheirmomenta.Weassumethattheparticleatsite ihasspinsi, whichiseitherupordown: si‚â°sz,i=¬±1 2. (17.1) Aconfigurationofthe Nparticlesisdescribedbyaquantumstatevector: ||ùõºj‚ü©=||s1,s2,‚Ä¶,sN‚ü©={ ¬±1 2,¬±1 2,‚Ä¶} ,j=1,‚Ä¶,2N. (17.2) Duetothespinofeachparticleassumingoneof twovalues,thereare2Ndifferentpossible statesforthe Nparticles. Theenergyofthesystemarisesfromtheinteractionofthespinswitheachotherandwith anexternalmagneticfield B.Weknowfromquantummechanicsthatanelectron‚Äôsspinand magneticmomentareproportionaltoeachother,soa spin‚Äìspininteractionisequivalent ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 366 17 Thermodynamics Simulations and Feynman Path Integrals E = ‚Äì JE = + J Figure 17.1 The 1D lattice of Nspins used in the Ising model of magnetism. The interaction energy between nearest-neighbor pairs E=¬±Jis shown for aligned and opposing spins. to a magnetic dipole‚Äìdipole interaction. In the simplest version of the model, we assume thateachdipoleinteractswiththeexternalmagneticfield,andwithitsnearestneighbor, throughthepotential: Vi=‚àíJsi‚ãÖsi+1‚àígùúábsi‚ãÖB. (17.3) Here, the constants are J,t h eexchange energy ,g, the gyromagnetic ratio, and ùúáb=e‚Ñè‚àï (2mec),theBohrmagneton. Evenforasmallnumbersofparticles,the2Npossiblespinconfigurationscangettobe very large (220>106), and it is computationally expensive to examine them all. Realistic chainsof ‚àº1023particlesarebeyondimagination.Consequently,statisticalapproachesare usuallyassumed,evenformoderatevaluesof N.Justhowlarge Nmustbeforstatisticsto bevalid,issomethingyouwillbeaskedtoexplorewithyoursimulations. Theenergyofthissysteminstate ùõºkistheexpectationvalueofthesumofthepotential V,overthespinsofalltheparticles: Eùõºk=‚ü® ùõºk|||||‚àë iVi|||||ùõºk‚ü© =‚àíJN‚àí1‚àë i=1sisi+1‚àíBùúábN‚àë i=1si. (17.4) An apparentparadoxintheIsingmodeloccursifweturnofftheexternalmagneticfield B, sincethentherewouldbenopreferreddirectioninspace.Thiswouldimplythattheaver- agemagnetizationshouldvanish,despiteourexpectationthatthelowestenergystatewould haveallspinsaligned.Theresolutiontotheparadoxisthatthesystemwith B=0isunsta- ble;evenifallthespinsarealigned,thereisnothingtostopthespontaneousreversalofall thespins.Thisinstabilityleadsto Bloch-walltransitions inwhichregionsofdifferentspin orientationschangesizespontaneously.Indeed,naturalmagneticmaterialshavemultiple domains with all the spins aligned, but with the different domains pointing in different directions. Toproceed,weassume B=0,whichleavesjustspin‚Äìspininteractions.However,becog- nizant of the fact that this means there is no preferred direction in space, and so, some caremaybeneededwhenaveragingobservablesoverdomains.Forexample,youmayneed totakeanabsolutevalueofthetotalspinwhencalculatingthemagnetization,thatis,to calculate ‚ü®|Œ£isi|‚ü©ratherthan ‚ü®Œ£isi‚ü©. The equilibrium alignment of the spins depends on the sign of the exchange energy J. IfJ>0, the lowest energy state will tend to have neighboring spins aligned, and if the temperature is low enough, the ground state will be a ferromagnet .Y e ti fJ<0, the low- estenergystatewilltendtohaveneighborswithoppositespins,andifthetemperatureis lowenough,thegroundstatewillbea antiferromagnet withalternatingspins. Thesolutiontothe1DIsingmodelhasitslimitations.Althoughthemodelisaccuratein describingasysteminthermalequilibrium,itisnotaccurateindescribingthe approachto thermalequilibrium,orinpredictingaphasetransitionattheCurietemperature.Also,we havepostulatedthatonlyonespinisflippedatatime,whereasrealmagneticmaterialstend",4751
17.1.1 Statistical Mechanics. 17.4 Path Integral Quantum Mechanics,"17.1 An Ising Magnetic Chain 367 toflipmanyspinsatatime.Otherlimitationsarestraightforwardtocorrect.Forexample, the addition of long-range interactions rather than just nearest neighbors, the motion of the centers, higher-multiplicity spin states, and extensions to two and three dimensions. Infact,the2Dand3Dmodelsdosupportphasetransitions(seeFigure17.4)[Yang,1952]. 17.1.1 Statistical Mechanics Statistical mechanicsstartswithelementaryinteractionsamongasystem‚Äôsparticles,and constructsthemacroscopicthermodynamicproperties,suchasspecificheatandmagne- tization.Theessentialassumptionisthatallconfigurationsofthesystemconsistentwith theconstraintsarepossible.Insomesimulations,suchasthemoleculardynamiconesin Chapter18,theproblemissetupsuchthatthe energyofthesystemisfixed.Thestatesof that type of system are described by a microcanonicalensemble . In contrast, for the ther- modynamicsimulationswestudyinthischapter,thetemperature,volume,andnumberof particlesremainfixed,andsowehavea canonicalensemble . When we say that an object is attemperature T, we mean that the object‚Äôs atoms are in thermodynamic equilibrium, and have an average kinetic energy proportional to T. Althoughthismaybeanequilibriumstate,itisalsoadynamiconeinwhichtheobject‚Äôs energy fluctuates as it exchanges energy with its environment. Indeed, one of the most illuminating aspects of the simulations to follow is its visualization of the continual and randominterchangeofenergythatoccursatequilibrium. Theenergy Eùõºjofstateùõºjinacanonicalensembleisnotconstant,butratherisdistributed withprobabilities P(ùõºj)givenbytheBoltzmanndistribution: Óàº(Eùõºj,T)=e‚àíEùõºj‚àïkBT Z(T),Z(T)=‚àë ùõºje‚àíEùõºj‚àïkBT. (17.5) HerekBisBoltzmann‚Äôsconstant, Tisthetemperature,and Z(T)isthepartitionfunction, a weighted sum over the individual statesorconfigurations of the system. Another for- mulation,Wang‚ÄìLandausampling(WLS)asdiscussedinSection17.3,insteadsumsover theenergiesof the states of the system with a density-of-states factor g(Ei)[Landau and Wang,2001]. 17.1.1.1 Analytic Solution Forverylargenumbersofparticles,onecansolvefortheinternalenergy U=‚ü®E‚ü©ofthe1D Isingmodel[PlischkeandBergersen,1994]: U J=‚àíNtanhJ kBT, (17.6) =‚àíNeJ‚àïkBT‚àíe‚àíJ‚àïkBT eJ‚àïkBT+e‚àíJ‚àïkBT={N,kBT‚Üí0, 0,kBT‚Üí‚àû.(17.7) Theanalyticresultsforthespecificheatperparticleandthemagnetizationare: C(kBT)=1 NdU dT=(J‚àïkBT)2 cosh2(J‚àïkBT), (17.8) M(kBT)=NeJ‚àïkBTsinh(B‚àïkBT) ‚àö e2J‚àïkBTsinh2(B‚àïkBT)+e‚àí2J‚àïkBT. (17.9) 368 17 Thermodynamics Simulations and Feynman Path Integrals The2D Ising model alsohasananalyticsolution,whichisnoteasytoderive[Yang,1952; Huang,1987].Whereasinternalenergyandheatcapacityareexpressedintermsofelliptic integrals,thespontaneousmagnetizationperparticlehasthesimpleform: Óàπ(T)=‚éß ‚é™ ‚é® ‚é™‚é©0, T>Tc, (1+z2)1‚àï4(1‚àí6z2+z4)1‚àï8 ‚àö 1‚àíz2,T<Tc,(17.10) kTc‚âÉ2.269185J,z=e‚àí2J‚àïkBT, (17.11) wherethetemperatureismeasuredinunitsoftheCurietemperature Tc. 17.2 Metropolis Algorithm When tryingtounderstandanalgorithmthatsimulatesthermalequilibrium,itisimportant tokeepinmindthattheBoltzmanndistribution(17.5)doesnotrequireasystemtoalways proceedtoitslowestenergystate;instead,itjustrequiresittobelesslikelytobefoundin ahigherenergystatethanalowerenergyone.Ofcourse,as T‚Üí0,onlythelowestenergy state will be populated, but at finite temperatures, we expect the energy to fluctuate on the order of kBTabout the equilibrium energy, with the system sometimes moving to a higher-energystate.",3380
17.1.1 Statistical Mechanics. 17.4 Path Integral Quantum Mechanics,"In their simulation of neutron transmission through matter, Metropolis et al. [1953] devised an algorithm to improve the Monte Carlo calculation of averages. Because the sequence of configurationsthat their Metropolisalgorithm produces accurately simulates the fluctuations occurring during thermal equilibrium, the algorithm has become a cornerstoneofcomputationalphysics. OnecanviewtheMetropolisalgorithmasacombinationofthevariancereductiontech- niquediscussedinSection5.7,andtheVonNeumannrejectiontechnique(stonethrowing) discussed in Section 5.8. There, we showed how to make Monte Carlo integration more efficientbysamplingrandompoints,predominantlywheretheintegrandislarge,andhow togeneraterandompointsweightedbyanarbitraryprobabilitydistribution[nowtobethe Boltzmannfunction]. Wewantanapproachthatflipsspinsrandomly,thatequilibratesrapidly,andthatpro- ducesaBoltzmanndistributionofenergiesintheend: Óàº(Eùõºj,T)‚àùe‚àíEùõºj‚àïkBT. (17.12) Theprocedurestartswiththesystematafixedtemperatureandanarbitraryinitialspincon- figuration.ItthenappliestheMetropolisalgorithmuntilathermalequilibriumisreached. Thecontinuedapplicationofthealgorithm(typically10 NtimesforNparticles)generates statistical fluctuations about the equilibrium, from which the thermodynamic quantities arededuced.Then,inordertodeducethetemperaturedependenceofthethermodynamic quantities,thetemperatureischangedandtheprocessisrepeated.Explicitly: 1) Startwithanarbitraryspinconfiguration ùõºk={s1,s2,‚Ä¶,sN}.(Theequilibriumconfig- urationshouldbeindependentoftheinitialdistribution.) ‚óèA‚Äúhot‚Äùstarthasrandomvaluesforthespins. ‚óèA‚Äúcold‚Äùstarthasallspinsparallel( J>0),orantiparallel( J<0). 17.2 Metropolis Algorithm 369 2) Generateatrialconfiguration ùõºtrby: (a) pickingaparticle irandomly,and (b) flippingitsspin. 3) Calculatetheenergy Eùõºtrofthetrialconfiguration. 4) IfEùõºtr‚â§Eùõºk,acceptthetrialbysetting ùõºk+1=ùõºtr. 5) IfEùõºtr>Eùõºk,acceptwithprobability Óàæ=Óàºtr‚àïÓàºi=exp(‚àíŒîE‚àïkBT).Todothat: (a) Chooseanotheruniformrandomnumber0 ‚â§ri‚â§1. (b) Setùõºk+1={ùõºtr,ifÓàæ‚â•rj(accept), ùõºk,ifÓàæ<rj(reject). (c) If the trial configuration is rejected, the next configuration is identical to the precedingone. 17.2.1 Metropolis Exercise 1) WriteaprogramthatimplementstheMetropolisalgorithm,thatis,thatproducesanew configuration ùõºk+1from the present configuration ùõºk. (Alternatively, use the program IsingViz.py giveninListing17.1.) 2) Makethekeydatastructureinyourprogramanarray s[N]containingthevaluesofthe spinssi.Fordebugging,printout +and‚àí(oroandblank)togivethespinateachlattice point(asweshowinFigure17.2).Examinethepatternfordifferenttriallengths. 3) The value for the exchange energy Jfixes the energy scale. Keep it fixed at J=1. (You may also wish to study antiferromagnets with J=‚àí1, but first examine ferromagnetswhosedomainsareeasiertounderstand.) 4) Thethermalenergy kBTisinunitsof Jandisanindependentvariableforthemodel. UsekBT=1fordebugging. 5) Useperiodicboundaryconditionsonyourchaintominimizeendeffects.Thismeans thatthechainisacirclewiththefirstandlastspinsadjacenttoeachother. 6) TryN‚âÉ20fordebugging,andlargervaluesforproductionruns.",3073
17.1.1 Statistical Mechanics. 17.4 Path Integral Quantum Mechanics,"00204060Position80100 200 400 Time600 800 1000 Figure 17.2 An Ising model simulation on a 1D lattice of 100 initially aligned spins (on the left). Up spins are indicated by circles, and down spins by blanks. Although the system starts with all up spins (a ‚Äúcold‚Äù start), the system is seen to form domains of up and down spins as time progresses. 370 17 Thermodynamics Simulations and Feynman Path Integrals 17.2.2 Equilibration and Thermodynamic Properties 1) Watch achainof Natomsattainthermalequilibrium.Athightemperatures,orforsmall numberofatoms,youshouldseelargefluctuations,whileatlowertemperatures,you shouldseesmallerfluctuations. 2) Look for evidence of instabilities in which there is a spontaneous flipping of a large numberofspins.Thisbecomesmorelikelyforlarger kBTvalues. 3) Notehowatthermalequilibrium,thesystemisstillquitedynamic,withspinsflipping allthetime.Itisthisenergyexchangethatdeterminesthethermodynamicproperties. 4) Youmaywellfindthatsimulationsatsmall kBT(say,kBT‚âÉ0.1forN=200)areslowto equilibrate.Higher kBTvaluesequilibratefaster,yethavelargerfluctuations. 5) Observetheformationofdomainsandtheeffecttheyhaveonthetotalenergy.Regard- lessofthedirectionofspinwithinadomain,theatom‚Äìatominteractionsareattractive, and so, they contribute negative amounts to the energy of the system when aligned. However,the ‚Üë‚Üìor‚Üì‚Üëinteractionsbetweendomainscontributepositiveenergy.There- fore,youshouldexpectamorenegativeenergyatlowertemperatureswherethereare largerandfewerdomains. 6) Makeagraphofaveragedomainsize versustemperature. Thermodynamic Properties Foragivenspinconfiguration ùõºj,theenergyandmagneti- zationaregivenby: Eùõºj=‚àíJN‚àí1‚àë i=1sisi+1,Óàπj=N‚àë i=1si. (17.13) Theinternalenergy U(T)isjusttheaveragevalueoftheenergy, U(T)=‚ü®E‚ü©, (17.14) wheretheaverageistakenoverasysteminequilibrium.Athightemperatures,weexpecta randomassortmentofspins,andsoavanishingmagnetization.Atlowtemperatures,when mostthespinsarealigned,weexpect Óàπtoapproach N‚àï2.Althoughthespecificheatcan becomputedfromtheelementarydefinition, C=1 NdU dT, (17.15) thenumericaldifferentiationmaybeinaccurateduetothestatisticalfluctuationsof U.A better approach is to first calculate the fluctuations in energy, occurring during Mtrials, andthendeterminethespecificheatfromthefluctuations: U2=1 MM‚àë t=1(Et)2, (17.16) C=1 N2U2‚àí(U)2 kBT2=1 N2‚ü®E2‚ü©‚àí‚ü®E‚ü©2 kBT2. (17.17) 1) Extendyourprogramtocalculatetheinternalenergy Uandthemagnetization Óàπfor thechain.Donotrecalculateentiresumswhenonlyonespinchanges. 2) Make sure to wait for your system to equilibrate before calculating thermodynamic quantities. (If equilibrated, Uwill fluctuate about its average.) Your results should resembleFigure17.3. 17.2 Metropolis Algorithm 371 kT kT‚Äì0.8‚Äì0.4 0.0 024 0240.10.20.3 01 E C M 0.5 Figure 17.3 Simulation results from a 1D Ising model of 100 spins. Left: Energy and speciÔ¨Åc heat as functions of temperature; Right: Magnetization as a function of temperature. 3) Reduce the statistical fluctuations by running the simulation a number of times with differentseeds,andbytakingtheaverageoftheresults.",3056
17.1.1 Statistical Mechanics. 17.4 Path Integral Quantum Mechanics,"4) Thesimulationsyourunforsmall Nmayberealistic,butmaynotagreewithstatistical mechanics,whichassumes N‚âÉ‚àû.(Youmayassumethat N‚âÉ2000isclosetoinfinity.) Checkifthatagreementwiththeanalyticresultsforthethermodynamiclimitisbetter forlargeNratherthansmall N. 5) Checkthatthesimulatedthermodynamicquantitiesareindependentofinitialcondi- tions(withinstatisticaluncertainties).Thismeansthatyourcoldandhotstartresults shouldagree. 6) Makeaplotoftheinternalenergy Uasafunctionof kBT,andcompareittotheanalytic result(17.6). 7) Makeaplotofthemagnetization Óàπasafunctionof kBT,andcompareittotheanalytic result.Doesthisagreewithhowyouexpectaheatedmagnettobehave? 8) Compute the energy fluctuations U2(17.16)and the specific heat C(17.17).Compare thesimulatedspecificheattotheanalyticresult(17.8). 17.2.3 Explorations 1) Extendthemodelsothatthespin‚Äìspininteraction(17.3)extendstonext-nearestneigh- borsaswellasnearestneighbors.Fortheferromagneticcase,thisshouldleadtomore bindingandlessfluctuationbecausewehaveincreasedthecouplingsamongspins,and thusincreasedthethermalinertia. 2) Extendthemodelsothattheferromagneticspin‚Äìspininteraction(17.3)extendstonear- estneighborsintwodimensions,andforthetrulyambitious,threedimensions.Con- tinue using periodic boundary conditions and keep the number of particles small, at leasttostartwith[Gould etal.,2006]. (a) Formasquarelatticeandplace‚àö Nspinsoneachside. (b) Examinemeanenergyandmagnetizationasthesystemequilibrates. (c) Is the temperature dependence of the average energy qualitatively different from thatofthe1Dmodel? (d) Makeaprintoutofthespinconfigurationforsmall N,andidentifydomains. 372 17 Thermodynamics Simulations and Feynman Path Integrals ‚Äì80  000‚Äì40  00040 000 0 0 2 4 6 8 10ECVM kT2-D Ising modelFigure 17.4 The energy, speciÔ¨Åc heat, and magnetization as a function of temperature from a 2D Ising model simulation with 40 000 spins. Evidence of a phase transition at the Curie temperature kT=‚âÉ2 . 5i ss e e ni na l lt h r e e functions. The values of CandE have been scaled to Ô¨Åt on the same plot as M. (Courtesy of J. Wetzel.) (e) Onceyoursystemappearstobebehavingproperly,calculatetheheatcapacityand magnetizationofthe2DIsingmodelwiththesametechniqueusedforthe1Dmodel. Useatotalnumberofparticlesof100 ‚â§N‚â§2000. (f) Lookforaphasetransitionfromorderedtounorderedconfigurationsbyexamining theheatcapacityandmagnetizationasfunctionsoftemperature.Theformershould diverge,whilethelattershouldvanishatthephasetransition(Figure17.4). 17.3 Fast Equilibration via Wang‚ÄìLandau Sampling ‚äô Although the Metropolis algorithm has been providing excellent service for more than 70years,WLS[LandauandWang,2004;ClarkUniversity,2011],withitsshortersimula- tiontime,hasbeenshowingincreasingutilityinresearchliterature.1Oursimulationwith theMetropolisalgorithm,whichwehavejustdescribed,usedaBoltzmanndistributionand focusedonitstemperaturedependence.TheWLSalgorithmalsousesaBoltzmanndistri- bution,butfocusesonitsenergydependence.Itstartswiththeprobabilitythatasystemat atemperature Twillcontainthedistributionofenergy: Óàº(Ei,T)=g(Ei)e‚àíEi‚àïkBT Z(T),Z(T)=‚àë Eig(Ei)e‚àíEi‚àïkBT. (17.18) Here,g(Ei)isthenumber,ordensity,ofstatesofenergy Ei,andZ(T)isthepartitionfunc- tion.Thesumin Zisoverallstatesofthesystem,butwithstatesofthesameenergyentering justonce,owingto g(Ei)accountingfortheirdegeneracy.Becausethedensity-of-states g(E) isafunctionofenergy,butnottemperature,onceithasbeencomputed, Z(T)andallther- modynamicquantities,canbecalculatedwithouthavingtorepeatthesimulationforeach temperature.Forexample,theinternalenergyandtheentropyare: U(T)def=‚ü®E‚ü©=‚àë EiEig(Ei)e‚àíEi‚àïkBT ‚àë Eig(Ei)e‚àíEi‚àïkBT,S=kBlng(Ei). (17.19) The density of states g(Ei)is determined by taking the equivalent of a random walk in energyspace.Wefliparandomlychosenspin,recordtheenergyofthenewconfiguration, 1 WethankOscarA.RestrepooftheUniversidaddeAntioquiaforlettingususesomeofhismaterial.",3872
17.1.1 Statistical Mechanics. 17.4 Path Integral Quantum Mechanics,"17.3 Fast Equilibration via Wang‚ÄìLandau Sampling ‚äô373 010203040 ‚Äì2 ‚Äì1 0 1 2log g(E) E/N04000800012 000 ‚Äì2 ‚Äì1 0 1 2H(E) E/N Figure 17.5 Wang‚ÄìLandau sampling used in the 2D Ising model on an 8 √ó8 lattice. Left: Logarithm of the density of states log g(E)versus the energy per particle. Right: The histogram H(E)showing the number of states visited as a function of the energy per particle. The aim of WLS is to make H(E)Ô¨Çat. andkeeponflippingspinsandrecordingenergies.Whendone,wehavea histogramH (Ei)of thenumberoftimeseachenergy Eiisattained(Figure17.5right).Iftheflippingwerecon- tinuedforaverylongtime,thehistogram H(Ei)wouldeventuallyconvergetothedensity ofstatesg(Ei).Yet,becausethewalkwouldonlyrarelymoveawayfromthemostprobable energies,evenforsmallsystems,some1019to1030stepsmightberequired. WLSincreasesthelikelihoodofsamplinglessprobableconfigurationsbyincreasingtheir acceptance,whilesimultaneouslydecreasingtheacceptanceofmorelikelyones.Toaccom- plishthistrick,WLSacceptsanewenergy Eiwithaprobabilityinverselyproportionalto the(initiallyunknown)densityofstates, Óàº(Ei)=1 g(Ei), (17.20) andthenbuildsupahistogramofvisitedstatesasthewalkcontinues. AnapparentproblemwithWLSisthat g(Ei)isunknown.Thisisovercomebydetermining g(Ei)simultaneouslywiththeexecutionoftherandomwalk.Onestartswithanarbitrary g(Ei)function,andthenmultiplies g(Ei)byanempiricalfactor f>1,whichincreasesthe likelihood of reaching states with small g(Ei)values. As the histogram H(Ei)gets flatter, the multiplicative factor fis decreased until it is close to 1. At that point, we have a flat histogramandadeterminationof g(Ei)inwhichallenergieshavebeenvisitedequally. 17.3.1 WLS Implementation Our implementation of WLS, WangLandau.py , is given in Listing 17.2. It assumes an Ising modelwith J=1,andnearestneighborinteractions.Ratherthanrecalculatingtheenergy eachtimeaspinisflipped,onlythedifferencesinenergiesarecomputed.Forexample,for eightspinsinaline: ‚àíEk=ùúé0ùúé1+ùúé1ùúé2+ùúé2ùúé3+ùúé3ùúé4+ùúé4ùúé5+ùúé5ùúé6+ùúé6ùúé7+ùúé7ùúé0, (17.21) wherewehaveassumedperiodicboundaryconditions.Ifspin5isflipped, ‚àíEk+1=ùúé0ùúé1+ùúé1ùúé2+ùúé2ùúé3+ùúé3ùúé4‚àíùúé4ùúé5‚àíùúé5ùúé6+ùúé6ùúé7+ùúé7ùúé0, (17.22) andthedifferenceinenergiesis: ŒîE=Ek+1‚àíEk=2(ùúé4+ùúé6)ùúé5. (17.23) 374 17 Thermodynamics Simulations and Feynman Path Integrals Forthe2Dproblemwithspinsonalattice,thechangeinenergywhenspin ùúéi,jonsite (i,j)isflippedis: ŒîE=2ùúéi,j(ùúéi+1,j+ùúéi‚àí1,j+ùúéi,j+1+ùúéi,j‚àí1). (17.24) ForNspinstherearetwostatesofminimumenergy E=‚àí2N,oneswithallspinspointing inthesamedirection,eitheralluporalldown.Themaximumenergy2 Ncorrespondsto alternatingspindirectionsonneighboringsites.Eachspinfliponthelatticechangesthe energybyfourunitsbetweentheselimits: Ei=‚àí2N,‚àí2N+4,‚àí2N+8,‚Ä¶,2N‚àí8,2N‚àí4,2N. (17.25) Theproducedhistogram H(Ei)andentropy S(T)aregiveninFigure17.5. 17.4 Path Integral Quantum Mechanics ‚äô Problem In classicalmechanics,aparticle‚Äôsmotionisdescribedbyitspace-timetrajec- toryx(t).Foraparticleinaharmonicoscillatorpotential,relatetheclassicaltrajectoryto thequantummechanicalwavefunction ùúì(x,t). Asthestorygoes,Feynmanwaslookingforaformulationofquantummechanicsthathad amoredirectconnectiontoclassicalmechanicsthantheSchr√∂dingertheorydoes,andthat alsoincorporatedthestatisticalnatureofquantummechanicsfromthestart.Hefollowed asuggestionbyDiracthat Hamilton‚Äôsprincipleofleastaction ,whichcanbeusedtoderive classicaldynamics,maybethe ‚Ñè‚Üí0limitofaquantumleast-actionprinciple.Seeingthat Hamilton‚Äôsprincipledeals with the paths of particles through space-time, Feynman pos- tulated[FeynmanandHibbs,1965;Mannheim,1983]thatthequantum-mechanicalwave functiondescribingthepropagationofafreeparticlefromthespace-timepoint a=(xa,ta) tothepoint b=(xb,tb),arerelatedby: ùúì(xb,tb)=‚à´dxaG(xb,tb;xa,ta)ùúì(xa,ta), (17.26) whereGistheGreen‚Äôsfunction orpropagator : G(xb,tb;xa,ta)‚â°G(b,a)=‚àöm 2ùúãi(tb‚àíta)exp[ im(xb‚àíxa)2 2(tb‚àíta)] .",3784
17.1.1 Statistical Mechanics. 17.4 Path Integral Quantum Mechanics,"(17.27) Equation (17.26) can be viewed as a form of Huygens‚Äôs wavelet principle in which each pointonthewavefront ùúì(xa,ta)emitsasphericalwavelet G(b;a)thatpropagatesforward inspaceandtime.Accordingly,thenewwavefront ùúì(xb,tb)iscreatedbysummationover, andinterferenceamong,alloftheemittedwavelets. Feynmanimaginedthatanotherwayofviewing(17.26)isasaformofHamilton‚Äôsprin- cipleinwhichtheprobabilityamplitude ùúìforaparticletobeat Bisequaltothesumover allpathsthroughspace-timeoriginatingattime Aandendingat B(Figure17.6).Thisview incorporatesthestatisticalnatureofquantummechanicsbyassigningdifferentprobabili- tiesfortravelalongdifferentpaths,withallpathspossible,butwithsomemorelikelythan others.Thevaluesfortheprobabilitiesofthepathsderivefrom Hamilton‚Äôsclassicalprinciple ofleastaction : 17.4 Path Integral Quantum Mechanics ‚äô375 Themostgeneralmotionofaphysicalparticlemovingalongtheclassicaltrajectory x(t) fromtimetatotbisalongapathsuchthattheactionS [x(t)]isanextremum : ùõøS[x(t)] =S[x(t)+ùõøx(t)]‚àíS[x(t)] =0, (17.28) withthepathsconstrainedtopassthroughtheendpoints : ùõø(xa)=ùõø(xb)=0. This formulation of classical mechanics, which is based on the calculus of variations, is equivalenttoNewton‚Äôsdifferentialequationsiftheaction Sistakenasthelineintegralof theLagrangianalongtheclassicaltrajectory: S[x(t)] =‚à´tb tadtL[x(t), Ãáx(t)],L=T[x, Ãáx]‚àíV[x]. (17.29) Here,Tisthekineticenergy, Visthepotentialenergy, Ãáx=dx‚àïdt,andthesquarebrackets indicateafunctional2ofthefunction x(t)andÃáx(t). Feynmanobservedthattheclassicalactionforafree( V=0)particle, S[b,a]=m 2(Ãáx)2(tb‚àíta)=m 2(xb‚àíxa)2 tb‚àíta, (17.30) isrelatedtothefree-particlepropagator(17.27)by: G(b,a)=‚àöm 2ùúãi(tb‚àíta)eiS[b,a]‚àï‚Ñè. (17.31) Equation(17.31)isthemuchsought-afterconnectionbetweenquantummechanics(LHS) andHamilton‚Äôsprinciple(RHS).Feynmanwentontopostulateareformulationofquantum mechanics that incorporates its statistical aspects by postulating G(b,a)to be a weighted sumofexponentials,eachwithanexponentthatistheactionfora pathconnecting atob: G(b,a)=‚àë pathseiS[b,a]‚àï‚Ñè(Apathintegral) . (17.32) Figure 17.6 In the Feynman path-integral formulation of quantum mechanics, a collection of paths connect the initial space-time point Ato the Ô¨Ånal point B. The solid line is the classical trajectory that minimizes the action S.T h e dashed lines are paths that are also sampled by a quantum particle. Time AB tb xb xata Position 2Afunctionalisanumberwhosevaluedependsonthecompletebehaviorofsomefunctionandnotjust onitsbehavioratonepoint.",2483
17.5 Lattice Path Integration,"376 17 Thermodynamics Simulations and Feynman Path Integrals 0‚Äì2‚Äì1012Position Probability 20 40 60 80 1000 ‚Äì40 ‚Äì20 0 20 40 PositionQuantum Classical 0.050.10.150.2 Time Figure 17.7 Left: A space-time quantum path resulting from applying the Metropolis algorithm. Right: The probability distribution for the harmonic oscillator ground state as determined by a path-integral calculation (the classical result has maxima at the two turning points). The sum (17.32) is called a pathintegral because it sums the exponential of the classical actionS[b,a]overinfinitelymanypaths(Figure17.6),witheachactionitselfbeingaclas- sicallineintegral(intime)alongapath. Thecorrespondenceprincipleconnectingclassicalandquantummechanicsapplieshere via the realization that because ‚Ñè‚âÉ10‚àí34Js is a very small number, S‚àï‚Ñè‚àº1020is a very largenumber.Accordingly,eventhoughaninfinityofpathsmayenterintothesum(17.32), themaincontributionscomefromthosepathsthatareadjacenttotheclassicaltrajectory x. Infact,because Sisanextremumfortheclassicaltrajectory,itremainsconstanttofirstorder inthevariationofpaths,andsonearbypathshavevalues(phasesintheexponentials)that varysmoothlyandrelativelyslowly.Incontrast,pathsfarfromtheclassicaltrajectoryare weightedbyarapidlyoscillatingexp (iS‚àï‚Ñè),andwhenmanyaresummedover,theytend to cancel each other out. In the classical limit ‚Ñè‚Üí0, only the single classical trajectory contributes,and(17.32)becomesHamilton‚Äôsprincipleofleastaction.InFigure17.7left, weshowanexampleofanactualtrajectoryusedinpath-integralcalculations. 17.4.1 Bound-State Wave Function Although youmaybethinkingthatyouhavealreadyseenenoughexpressionsforGreen‚Äôs function,thereisyetanotheroneweneedforourcomputation.Westartbyassumingthat theHamiltonianoperator ÃÉHsupportsaspectrumofeigenfunctions, ÃÉHùúìn=Enùúìn, (17.33) eachlabeledbytheindex n.Because ÃÉHisHermitian,itswavefunctionsformsacomplete orthonormalsetinwhichwemayexpandageneralsolution: ùúì(x,t)=‚àû‚àë n=0cne‚àíiEntùúìn(x), (17.34) cn=‚à´+‚àû ‚àí‚àûdxùúì‚àó n(x)ùúì(x,t=0), (17.35) wherethevaluefortheexpansioncoefficients cnfollowsfromtheorthonormalityof ùúìn‚Äôs.If wesubstitutethis cnbackintothewavefunctionexpansion(17.34),weobtaintheidentity: ùúì(x,t)=‚à´+‚àû ‚àí‚àûdx0‚àë nùúì‚àó n(x0)ùúìn(x)e‚àíiEntùúì(x0,t=0). (17.36) 17.5 Lattice Path Integration 377 Comparisonwith(17.26)yieldstheeigenfunctionexpansionfor G: G(x,t;x0,t0=0)=‚àë nùúì‚àó n(x0)ùúìn(x)e‚àíiEnt. (17.37) We relate this to the bound-state wave function ( recallthatour problemistocalculate that)byfirstrequiringallpathstostartandendatthespaceposition x0=x,bythentaking t0=0, and, finally, by making an analytic continuation of (17.37) to negative imaginary time(permissibleforanalyticfunctions): G(x,‚àíiùúè;x,0)=‚àë n|ùúìn(x)|2e‚àíEnùúè=|ùúì0|2e‚àíE0ùúè+|ùúì1|2e‚àíE1ùúè+¬∑¬∑¬∑, ‚áí|ùúì0(x)|2=lim ùúè‚Üí‚àûeE0ùúèG(x,‚àíiùúè;x,0). (17.38) Thelimitherecorrespondstolongimaginarytimes ùúè,afterwhichthepartsof ùúìwithhigher energiesdecaymorequickly,leavingonlythegroundstate ùúì0. Equation (17.38) provides a closed-form solution for the ground-state wave function directlyintermsoftheGreen‚Äôsfunction G.Althoughwewillsoondescribehowtocompute thisfunction,fornowlookatFigure17.7right,showingsomeresultsofthecomputation. Although we start with a probability distribution that peaks near the classical turning points at the edges of the well, after a large number of iterations, we end up with a distribution that resembles the expected Gaussian. So, maybe the new formulation does work.OntheleftofFigure17.7,weseeatrajectorythathasbeengeneratedviastatistical variationsabouttheclassicaltrajectory x(t)=Asin(ùúî0t+ùúô). 17.5 Lattice Path Integration Because both time and space need to be integrated over when evaluating a path inte- gral, our simulation starts with a lattice of discrete space-time points [Potvin, 1993]. Wevisualizeaparticle‚Äôstrajectoryasaseriesofstraightlinesconnectingonetimetothe next(Figure17.8).Wedividethetimebetweenthespace-timepoints AandBintoNequal timestepsofsize ùúÄ,andlabelthemwiththeindex j: ùúÄdef=tb‚àíta N‚áítj=ta+jùúÄ,(j=0,N). (17.39) Althoughitismoreprecisetousetheactualpositions x(tj)ofthetrajectoryattimes tjto determinethe xj‚Äôs(asinFigure17.8),wealsodiscretizespaceuniformlywiththelinksend- ingatthenearestlatticepoints.Seeingthatwehavealattice,itiseasytoevaluatederivatives orintegralsonalink3: dxj dt‚âÉxj‚àíxj‚àí1 tj‚àítj‚àí1=xj‚àíxj‚àí1 ùúÄ, (17.40) Sj‚âÉLjŒît‚âÉ1 2m(xj‚àíxj‚àí1)2 ùúÄ‚àíV(xj)ùúÄ, (17.41) wherewehaveassumedthattheLagrangianisconstantovereachlink. 3 AlthoughEuler‚Äôsrulehasalargeerror,itisoftenusedinlatticecalculationsbecauseofitssimplicity. However,iftheLagrangiancontainssecondderivatives,thenthemoreprecisecentral-differencemethodis neededtoavoidsingularities. 378 17 Thermodynamics Simulations and Feynman Path Integrals Latticepathintegrationisbasedonthe compositiontheorem forpropagators: G(b,a)=‚à´dxjG(xb,tb;xj,tj)G(xj,tj;xa,ta)(ta<tj,tj<tb). (17.42) Forafreeparticlethisyields: G(b,a)=‚àöm 2ùúãi(tb‚àítj)‚àöm 2ùúãi(tj‚àíta)‚à´dxjei(S[b,j]+S[j,a]) =‚àö m 2ùúãi(tb‚àíta)‚à´dxjeiS[b,a], (17.43) wherewehaveaddedtheactionsbecauselineintegralscombineas S[b,j]+S[j,a]=S[b,a]. FortheN-linkedpathinFigure17.8,equation(17.42)becomes: G(b,a)=‚à´dx1¬∑¬∑¬∑dxN‚àí1eiS[b,a],S[b,a]=N‚àë j=1Sj, (17.44) whereSjisthevalueoftheactionforlink j.Atthispoint,theintegraloverthe singlepath showninFigure17.8hasbecomean N-termsumthatbecomesaninfinitesumasthetime stepùúÄapproacheszero. To summarize, Feynman‚Äôs path-integral postulate (17.32) means that we sum over all paths connecting AtoBto obtain the Green‚Äôs function G(b,a). This, in turn, means that wemustsum,notonlyoverthelinksinonepath,but alsooverallthedifferentpaths,in ordertoproducethevariationinpathsrequiredbyHamilton‚Äôsprinciple.Thesumiscon- strainedsuchthatpathsmustpassthrough AandBandcannotdoublebackonthemselves (causality requires that particles move only forward in time). This is the essence of path integration.Becauseweareintegratingoverfunctionsaswellasalongpaths,thetechnique isalsoknownas functionalintegration . Xa Xaxb = xN xi' xj'xjxiB B CD tatitb tatjtbŒµ AA Figure 17.8 Left: A path through a space-time lattice that starts and ends at x=xa=xb. The action is an integral over this path, while the path integral is a sum of integrals over all paths. The dotted path BDis a transposed replica of path AC.Right: The dashed path joins the initial and Ô¨Ånal times in two equal time steps; the solid curve uses Nsteps each of size ùúÄ. The position of the curve at time tjdeÔ¨Ånes the position xj. 17.5 Lattice Path Integration 379 The propagator (17.32) is the sum over all paths connecting AtoB,w i t he a c hp a t h weightedbytheexponentialoftheactionalongthatpath,explicitly: G(x,t;x0,t0)=‚àë ‚à´dx1dx2¬∑¬∑¬∑dxN‚àí1eiS[x,x0], (17.45) S[x,x0]=N‚àí1‚àë j=1S[xj+1,xj]‚âÉN‚àí1‚àë j=1L(xj, Ãáxj)ùúÄ, (17.46) whereL(xj, Ãáxj)istheaveragevalueoftheLagrangianonlink jattimet=jùúÄ.Thecompu- tationismadesimplerbyassumingthatthepotential V(x)isindependentofvelocityand doesnotdependonother xvalues(localpotential).Next,weobservethat Gisevaluated withanegativeimaginarytimeintheexpression(17.38)fortheground-statewavefunction. Accordingly,weevaluatetheLagrangianwith t=‚àíiùúè: L(x, Ãáx)=T‚àíV(x)=+1 2m( dx dt)2 ‚àíV(x), (17.47) ‚áíL( x,idx dùúè) =‚àí1 2m( dx dùúè)2 ‚àíV(x). (17.48) We see that the reversal of the sign of kinetic energy in Lmeans that Lnow equals the negativeoftheHamiltonianevaluatedatarealpositivetime t=ùúè: H( x,dx dùúè) =1 2m( dx dùúè)2 +V(x)=E, (17.49) ‚áíL( x,idx dùúè) =‚àíH( x,dx dùúè) . (17.50) Inthisway,werewritethe t-pathintegralof Lasaùúè-pathintegralof H,andsoexpressthe actionandGreen‚ÄôsfunctionintermsoftheHamiltonian: S[j+1,j]=‚à´tj+1 tjL(x,t)dt=‚àíi‚à´ùúèj+1 ùúèjH(x,ùúè)dùúè, (17.51) ‚áíG(x,‚àíiùúè;x0,0)=‚à´dx1‚Ä¶dxN‚àí1e‚àí‚à´ùúè 0H(ùúè‚Ä≤)dùúè‚Ä≤, (17.52) wherethelineintegralof Hisoveranentiretrajectory.Next,weexpressthepathintegral intermsoftheaverageenergyoftheparticleoneachlink, Ej=Tj+Vj,andthensumover thelinkstoobtainthesummedenergy: ‚à´H(ùúè)dùúè‚âÉ‚àë jùúÄEj=ùúÄÓà±({xj}), (17.53) Óà±({xj})def=N‚àë j=1[ m 2(xj‚àíxj‚àí1 ùúÄ)2 +V(xj+xj‚àí1 2)] . (17.54) In(17.54),wehaveapproximatedeachlinkinthepathasa straightline ,usedEuler‚Äôsderiva- tive rule to obtain the velocity, and evaluated the potential at the midpoint of the link. Wenowsubstitute this Gintoourexpression(17.38)fortheground-statewavefunction,",8046
17.7 Code Listings,"380 17 Thermodynamics Simulations and Feynman Path Integrals withidenticalinitialandfinalpointsinspace: lim ùúè‚Üí‚àûG(x,‚àíiùúè,x0=x,0) ‚à´dxG(x,‚àíiùúè,x0=x,0)=‚à´dx1¬∑¬∑¬∑dxN‚àí1exp[‚àí‚à´ùúè 0Hdùúè‚Ä≤] ‚à´dxdx1¬∑¬∑¬∑dxN‚àí1exp[‚àí‚à´ùúè 0Hdùúè‚Ä≤] ‚áí||ùúì0(x)||2=1 Zlim ùúè‚Üí‚àû‚à´dx1¬∑¬∑¬∑dxN‚àí1e‚àíùúÄÓà±, (17.55) Z=lim ùúè‚Üí‚àû‚à´dxdx1¬∑¬∑¬∑dxN‚àí1e‚àíùúÄÓà±. (17.56) Notetheadditional dxintegrandintheexpressionfor Z.Thesimilarityoftheseexpressions tothermodynamics,evenwithapartitionfunction Z,isnoaccident.Bymakingthetime parameterimaginary,wehaveconvertedthetime-dependentSchr√∂dingerequationtothe heatdiffusionequation: iùúïùúì ùúï(‚àíiùúè)=‚àí‚àá2 2mùúì‚áíùúïùúì ùúïùúè=‚àá2 2mùúì. (17.57) ItisnotsurprisingthenthatthesumoverpathsinGreen‚Äôsfunctionhaseachpathweighted bytheBoltzmannfactor, Óàº=e‚àíùúÄÓà±,whichisusuallyassociatedwiththermodynamics.We maketheconnectioncompletebyidentifyingthetemperaturewiththeinversetimestep: Óàº=e‚àíùúÄÓà±=e‚àíÓà±‚àïkBT‚áíkBT=1 ùúÄ‚â°‚Ñè ùúÄ. (17.58) Consequently, the ùúÄ‚Üí0 limit, which makes time continuous, is equivalent to a high- temperature limit. The ùúè‚Üí‚àûlimit, which is required to project the ground-state wave function,meansthatwemustintegrateoverapaththatislonginimaginarytime,thatis, longcomparedto typicaltime ‚Ñè‚àïŒîE. Just asour simulation ofthe Isingmodelrequired ustowaitforalongtimeforthesystemtoequilibrate,sotoodoesthepresentsimulation requireustowaitalongtime,sothatallbuttheground-statewavefunctionhasdecayed away. At last, we have the solution to our problemof finding the ground-state wave functionviaitsconnectiontoclassicalmechanics. Tosummarize,wehaveexpressedtheGreen‚Äôsfunctionasapathintegralrequiringinte- grationsoftheHamiltonianalongallpaths(17.55).Weevaluatethispathintegralasthesum overtrajectoriesonaspace-timelattice,witheachpathweightedbyaprobabilitybasedon thepath‚Äôsaction.WeusetheMetropolisalgorithmtoperformthemany,multi-dimensional integrationsrequiredasweexamineallspace-timepaths.Thisissimilartowhatwedidwith theIsingmodel,however,ratherthanrejectingoracceptinga flipinspin,wenowrejector acceptachangeinalink ,alsobasedonthechangeinenergy.Themoreiterationswelet thealgorithmrunfor,themoretimethededucedwavefunctionhastoequilibratetothe groundstate,andthusthemoreaccuratetheanswer. Ingeneral,thesetypesofMonteCarloGreen‚Äôsfunctiontechniquesworkbestifwestart with a good guess at the final answer, and then have the algorithm calculate variations onourguess.Forthepresentproblem,thismeansthatifwestartwithapathinspace-time closetotheclassicaltrajectory,thealgorithmmaybeexpectedtodoagoodjobatsimulating thequantumfluctuationsaboutthattrajectory.However,itdoesnotappeartobegoodat findingtheclassicaltrajectoryfromarbitrarylocationsinspace-time. 17.5.1 A Time-Saving Trick Wehaveformulatedthecomputationsothatyoupickavalueof xandperformmanycom- putationsoflineintegrals,overallspaceandtime,toobtain ||ùúì0(x)||2.Toobtainthewave 17.6 Implementation 381 function at another x, the entire simulation must be repeated from scratch. Rather than goingthroughallthatworkagainandagain,wecancomputetheentire xdependenceof thewavefunctioninonefellswoop.Thetrickistoinsertadeltafunctionintotheproba- bilityintegral(17.55),therebyfixingtheinitialpositiontobe x0,andthentoalsointegrate overallx0s: ||ùúì0(x)||2=‚à´dx1¬∑¬∑¬∑dxNe‚àíùúÄÓà±(x,x1,‚Ä¶)(17.59) =‚à´dx0¬∑¬∑¬∑dxNùõø(x‚àíx0)e‚àíùúÄÓà±(x,x1,‚Ä¶). (17.60) Thisequationexpressesthewavefunctionasanaverageofadeltafunctionoverallpaths, aprocedurethatmightseemtotallyinappropriatefornumericalcomputationbecauseone cannot compute singular functions.",3380
17.7 Code Listings,"Yet, when we simulate the sum over all paths with (17.60), there will always be some xvalue for which the integral is nonzero, and so we accumulatethesolutionforwhatever xvaluethatis. To understand how this works in practice, consider path ABin Figure 17.8, imagining thatwehavejustcalculatedthesummedenergy.Weformanewpathbyhavingonepoint onthechainjumptopoint C(whichchangestwolinks).If wereplicatesection AC,and use it as the extension ADto form the top path, we see that the path CBDhas the same summedenergy(action)aspath ACB,andinthiswayitcanbeusedtodetermine |ùúì(x‚Ä≤ j)|2. Thatbeingthecase,oncethesystemisequilibrated,wedeterminenewvaluesofthewave functionatnewlocations x‚Ä≤ jbyflippinglinkstonewvaluesandcalculatingnewactions. Themorefrequentlysome xjisaccepted,thegreateristhewavefunctionatthatpoint. 17.6 Implementation The program QMC.pyin Listing 17.3 evaluates the integral (17.32) by finding the average of the integrand ùõø(x0‚àíx)with paths distributed according to the weighting function exp[‚àíùúÄÓà±(x0,x1,‚Ä¶,xN)]. The physics enters via (17.62), the calculation of the summed energy Óà±(x0,x1,‚Ä¶,xN). We evaluate the action integral for the harmonic oscillator potential: V(x)=1 2x2, (17.61) and for a particle of mass m=1. Using a convenient set of natural units, we measure lengths in‚àö 1‚àïmùúî‚â°‚àö ‚Ñè‚àïmùúî=1, and times in 1 ‚àïùúî=1. Correspondingly, the oscillator has a period T=2ùúã. Figure 17.7 shows results after the application of the Metropolis algorithm. In this computation, we started with an initial path close to the classical trajectory, and then examined half a million variations about this path. All paths were constrainedtobeginandendat x=1. Whenthetimedifference tb‚àítaissmall,saylike2 T,thesystemwillnothaveenough time to equilibrate to its ground state, and so the computed wave function will look like theprobabilitydistributionofanexcitedstate(nearlyclassicalwiththeprobabilityhigh- est for the particle to be near its turning points, where its velocity vanishes). However, whentb‚àítaequalsalongertime,suchas20 T,thesystemwillhaveenoughtimetodecay toitsgroundstate,andthewavefunctionwilllookliketheexpectedGaussian.Ineither 382 17 Thermodynamics Simulations and Feynman Path Integrals case (Figure 17.7 right), the trajectory through space-time fluctuates about the classical trajectory.ThisfluctuationisaconsequenceoftheMetropolisalgorithmoccasionallygoing uphillinitssearch;ifyoumodifytheprogramsothatsearchesgoonlydownhill,thespace- timetrajectorywillbeaverysmoothtrigonometricfunction(theclassicaltrajectory),but thewavefunction,whichisameasureofthefluctuationsabouttheclassicaltrajectory,will vanish. Herearetheexplicitsteps[MacKeown,1985;MacKeownandNewman,1987]: 1) Constructagridof Ntimestepseachoflength ùúÄ(Figure17.8).Startat t=0,andextend to timeùúè=NùúÄ[Ntime intervals and (N+1)lattice points in time]. Note that time alwaysincreasesmonotonicallyalongapath. 2) Constructagridof Mspacepointsseparatedbystepsofsize ùõø.Startwith M‚âÉN,and usearangeof xvaluesseveraltimelargerthanthecharacteristicsizeofthepotential beingused. 3) Anyxortvaluefallingbetweenlatticepointsshouldbeassignedtotheclosestlattice point. 4) Associateaposition xjwitheachtime ùúèj,subjecttotheboundaryconditionsthatthe initialandfinalpositionsalwaysremainat xN=x0=x. 5) Chooseapathconsistingofstraight-linelinksconnectingthelatticepoints.Thisshould correspondtotheclassicaltrajectory.Observethatthe xvaluesforthelinksofthepath may have values that increase, decrease, or remain unchanged (in contrast to time, whichalwaysincreases). 6) Startingat j=0,evaluatetheenergy Óà±bysummingthekineticandpotentialenergies foreachlinkofthepath: Óà±(x0,x1,‚Ä¶,xN)‚âÉN‚àë j=1[ m 2(xj‚àíxj‚àí1 ùúÄ)2 +V(xj+xj‚àí1 2)] . (17.62) 7) Beginasequenceofrepetitivestepsinwhicharandomposition xjassociatedwithtime tjischangedtotheposition x‚Ä≤ j(pointCinFigure17.8).Thischanges twolinksinthe path. 8) UsetheMetropolisalgorithmtoweighthechangedpositionwiththeBoltzmannfactor. 9) Foreachlatticepoint,establisharunningsumrepresentingthesquaredmodulusof thewavefunctionatthatpoint.",4016
17.7 Code Listings,"10) After each single-link change (or decision not to change), increase the running sum forthenew xvalueby1.Afterasufficientlylongrunningtime,thesumdividedbythe numberofstepsisthesimulatedvaluefor |ùúì(xj)|2ateachlatticepoint xj. 11) Repeat the entire link-changing simulation starting with a different seed. A wave functionaveragedovermanyintermediatelengthrunsisbetterthanonefromavery longrun. 17.6.1 Path Integration Exercise 1) Plotsomeoftheactualspace-timepathsusedinthesimulationalongwiththeclassical trajectory. 2) Foramorecontinuouspictureofthewavefunction,makethe xlatticespacingsmaller; foramoreprecisevalueofthewavefunctionatanyparticularlatticesite,samplemore points(runlonger)anduseasmallertimestep ùúÄ. 17.6 Implementation 383 3) Becausetherearenosignchangesinaground-statewavefunction,youcanignorethe phase,assume ùúì(x)=‚àö ùúì2(x),andthenestimatetheenergyvia: E=‚ü®ùúì|H|ùúì‚ü© ‚ü®ùúì|ùúì‚ü©=ùúî 2‚ü®ùúì|ùúì‚ü©‚à´+‚àû ‚àí‚àûùúì‚àó(x)( ‚àíd2 dx2+x2) ùúì(x)dx, (17.63) wherethespacederivativeisevaluatednumerically. 4) Exploretheeffectofmaking ‚Ñèlarger,andthuspermittinggreaterfluctuationsaround theclassicaltrajectory.DothisbydecreasingthevalueoftheexponentintheBoltzmann factor.Determineifthismakesthecalculationmoreorlessrobustinitsabilitytofind theclassicaltrajectory. 5) Testyour ùúìforthegravitationalpotential(seequantumbouncerbelow): V(x)=mg|x|,x(t)=x0+ùë£0t+1 2gt2. (17.64) 17.6.2 Quantum Bouncer ‚äô Another problem for which the classical trajectory is well known is that of a quantum bouncer.4Herewehaveaparticledroppedinauniformgravitationalfield,hittingahard floor,andthenbouncingup.Whentreatedquantummechanically,quantizedlevelsforthe particle result [Gibbs, 1975; Goodings and Szeredi, 1992; Whineray, 1992; Vall√©e, 2000]. In 2002, an experiment to discern this gravitational effect at the quantum level was per- formedbyNesvizhevsky etal.[2002],andisdescribedinShaw[1992].Itconsistedofdrop- pingultracoldneutronsfromaheightof14 Œºmuntoaneutronmirror,andwatchingthem bounce.Itfoundaneutrongroundstateat1.4peV. We start by determining the analytic solution to this problem for stationary states, andthengeneralizingittoincludetime-dependence.Thetime-independentSchr√∂dinger equationforaparticleinauniformgravitationpotentialis: ‚àí‚Ñè2 2md2ùúì(x) dx2+mxgùúì(x)=Eùúì(x), (17.65) ùúì(x‚â§0)=0,(boundarycondition) . (17.66) The boundary condition (17.66) is a consequence of the hard floor at x=0. A change of variablesconverts(17.65)toadimensionlessform, d2ùúì dz2‚àí(z‚àízE)ùúì=0, (17.67) z=x(2gm2 ‚Ñè2)1‚àï3 ,zE=E( 2 ‚Ñè2mg2)1‚àï3 . (17.68) ThereisananalyticsolutionintermsofAiryfunctionsAi( z)[Pressetal.,2007]: ùúì(z)=NnAi(z‚àízE), (17.69) whereNnisanormalizationconstant.Theboundarycondition ùúì(0)=0implies: ùúì(0)=NEAi(‚àízE)=0, (17.70) which means that the allowed energies of the system correspond to the zeros znof Airy functionswithnegativearguments.Tosimplifythecalculation,wetake ‚Ñè=1,g=2,and m=1 2,whichleadsto z=xandzE=E. 4 OscarA.Restrepoassistedinthepreparationofthissection. 384 17 Thermodynamics Simulations and Feynman Path Integrals zQMC Analytic‚îÇŒ®(z)‚îÇ20.6 0.4 0.2 0  0246Figure 17.9 The analytic and quantum Monte Carlo solution for the quantum bouncer.",3101
17.7 Code Listings,"The dashed line is the Airy function squared, and the solid line is |ùúì0(z)|2after a million trajectories. Thetime-dependentsolutionforthequantumbouncerisaninfinitesumovertheeigen- functions,eachwithatime-dependencedeterminedbyitsenergy: ùúì(z,t)=‚àû‚àë n=1CnNnAi(z‚àízn)e‚àíiEnt‚àï‚Ñè, (17.71) wheretheCnsareconstants. Figure17.9showstheresultsofsolvingforthequantumbouncer‚Äôsground-stateproba- bility|ùúì0(z)|2usingFeynman‚Äôspathintegration,thatis,quantumMonteCarlo.Thetime increment dtandthetotaltime twereselectedbytrialanderrorinsuchawayastosatisfy the boundary condition |ùúì(0)|2‚âÉ0. To account for the potential being infinite for nega- tivexvalues, we selected trajectories that have positive xvalues over all their links. This incorporatesthefactthattheparticlecanneverpenetratethefloor.Ourprogramisgivenin Listing17.4.Theresultafterusing106trajectories,andatimestep ùúÄ=dùúè=0.05,areshown inFigure17.9.Bothwavefunctionswerenormalizedviaatrapezoidintegration.Ascanbe seen,theagreementbetweentheanalyticandpathintegrationwavefunctionissatisfactory, thoughnotperfect. 17.6.3 Path Integral Bouncer Exercises 1) You are given the fact that a particle falls at distance din timet=‚àö 2D‚àïg. Assume a quadraticdependenceondistanceandtime, d=ùõºt+ùõΩt2, (17.72) andshow,eitheranalyticallyornumerically,thattheaction S=‚à´t0 0Ldtfortheparticle‚Äôs trajectoryisanextremumonlywhen ùõº=0andùõΩ=g‚àï2. 2) Consideramass mattachedtoaharmonicoscillatorwithperiod T=1andfrequency ùúî=2ùúã: x(t)=10cos(ùúît). (17.73) (a) Proposeamodificationof(17.73)thatagreeswithitat t=0andt=T,thoughdiffers forintermediatevaluesof t.Includeanadjustableparameterinyourmodification. (b) Computetheactionforanentirerangeofvaluesfortheparameterinyourproposed trajectory,andtherebyverifythatonlytheknownanalyticformyieldsaminimum action. 17.7 Code Listings 385 3) Considera1Dharmonicoscillatorwithdisplacement qandmomentum p.Theenergy: E(p,q)=p2 2m+mùúî2q2 2(17.74) isanintegralofthemotion,andtheareaoftheperiodicorbitis: A(E)=‚àÆpdq=2‚à´qmax qminpdq. (17.75) (a) Usetheanalytic,ornumeric,solutionforsimpleharmonicmotiontocomputethe areaA(E). (b) Computethederivative T=dA(E)‚àïdEviaacentral-differenceapproximationand comparetotheanalyticanswer. (c) Now repeat this problem using a nonlinear oscillator for which there is only a numericalsolution.(Evenoscillatorsoftheform V=kxpwithpshouldworkjust fine.) You can determine the period from the time dependence of your solution, andthenuseyoursolutiontocompute A(E)fordifferentinitialconditions. 17.7 Code Listings Listing 17.1 IsingViz.py A1DIsingchainsimulationwiththeMetropolisalgorithm. 1# IsingViz .py: Ising model fromvisualimport ‚àó importrandom 5fromvisual.graph import ‚àó # Display for the arrows scene = display(x=0,y=0,width=700,height=200, range=40,title= ‚ÄôSpins‚Äô) 9engraph = gdisplay(y=200,width=700,height=300, title= ‚ÄôE of Spin System‚Äô ,\ xtitle= ‚Äôiteration‚Äô , ytitle= ‚ÄôE‚Äô,xmax=500, xmin=0, ymax=5, ymin= ‚àí5) enplot = gcurve(color=color.yellow) N= 3 0 13B= 1 . mu = .33 #gm u J= . 2 0 k= 1 . # Boltmann 17T = 100. state = zeros((N)) # spins up(1) , d o w n (0) S= z e r o s ( ( N ) , float) test = state 21random.seed() # Seed generator defenergy ( S) : FirstTerm = 0.",3147
17.7 Code Listings,"25SecondTerm = 0. foriin range (0,N‚àí2): FirstTerm += S[i] ‚àóS[i + 1] FirstTerm ‚àó=‚àíJ foriin range (0,N‚àí1): SecondTerm += S[i] 29SecondTerm ‚àó=‚àíB‚àómu; return(FirstTerm + SecondTerm); ES = energy(state) 33 defspstate(state): # Plots spins forobjinscene.objects: obj.visible=0 # Erase old arrows j=0 37foriin range (‚àíN,N,2): ifstate[j]== ‚àí1: ypos = 5 # Spin down 386 17 Thermodynamics Simulations and Feynman Path Integrals else: ypos = 0 if5‚àóstate[j]<0: arrowcol = (1,1,1) # White arrow if down 41 else: arrowcol =(0.7,0.8,0) arrow(pos=(i ,ypos,0) ,axis=(0,5 ‚àóstate[j],0),color=arrowcol) j +=1 45foriin range (0 ,N): state[i] = ‚àí1 # Initial spins all down forobjinscene.objects: obj.visible=0 spstate(state) 49ES = energy(state) forjin range (1,500): rate(3) 53 test = state r=int(N‚àórandom.random()); # Flip spin randomly test[r] ‚àó=‚àí1 ET = energy(test) 57 p=m a t h . e x p ( ( E S ‚àíET)/(k ‚àóT)) # Boltzmann test enplot.plot(pos=(j,ES)) # Adds segment to curve ifp >= random.random() : state = test 61 spstate(state) ES = ET Listing 17.2 WangLandau.py WangLandaualgorithmfor2-Dspinsystem. # WangLandau . py : Wang Landau algorithm for 2 ‚àíD spin system \""\""\"" Author in Java: Oscar A. Restrepo, 4Universidad de Antioquia, Medellin, Colombia Each time fac changes, a new histogrm is generated. Only the first Histogram plotted to reduce computational time\""\""\"" fromvisualimport ‚àó 8importrandom; fromvisual.graph import ‚àó L=8 ; N =( L ‚àóL) 12 # Set up graphics entgr = gdisplay(x=0,y=0,width=500,height=250,title= ‚ÄôDensity of States‚Äô ,\ xtitle= ‚ÄôE/N‚Äô, ytitle= ‚Äôlog g(E)‚Äô , xmax=2., xmin=‚àí2.,ymax=45,ymin=0) 16entrp = gcurve(color = color.yellow, display = entgr) energygr = gdisplay(x=0, y=250, width=500, height=250, title= ‚ÄôE vs T‚Äô ,\ xtitle = ‚ÄôT‚Äô, ytitle= ‚ÄôU(T)/N‚Äô , xmax=8.,xmin=0, ymax =0.,ymin= ‚àí2.) energ = gcurve(color = color.cyan, display = energygr) 20histogr = display(x = 0, y = 500, width = 500, height = 300,\ title = ‚Äô1st histogram: H(E) vs. E/N, corresponds to log(f) = 1‚Äô ) histo = curve(x = list(range(0, N+1)), color=color.red, display=histogr) xaxis = curve(pos = [( ‚àíN,‚àí10), (N, ‚àí10)]) 24minE = label(text = ‚Äô-2 ‚Äô,p o s=( ‚àíN+3, ‚àí15), box = 0) maxE = label(text = ‚Äô2‚Äô,p o s=( N ‚àí3,‚àí15), box = 0) zeroE = label(text = ‚Äô0‚Äô,p o s=( 0 , ‚àí15), box = 0) ticm = curve(pos = [( ‚àíN,‚àí10), ( ‚àíN,‚àí13)]) 28tic0 = curve(pos = [(0, ‚àí10), (0, ‚àí13)]) ticM = curve(pos = [(N, ‚àí10), (N, ‚àí13)]) enr = label(text = ‚ÄôE/N‚Äô,p o s=( N / 2 , ‚àí15), box = 0) 32s p =z e r o s (( L ,L )) # Grid size , spins hist = zeros( (N + 1) ) prhist = zeros( (N + 1) ) # Histograms S= z e r o s ( ( N + 1 ) , float) # Entropy = log g(E) 36 defiE(e): return int ((e + 2 ‚àóN)/4) defIntEnergy(): 40exponent = 0.0 forTinarange (0.2, 8.2, 0.2 ): # Select lambda m a x 17.7 Code Listings 387 Ener = ‚àí2‚àóN maxL = 0.0 # Initialize 44 foriin range (0, N + 1): ifS[i].= 0 and(S[i]‚àíEner/T)>maxL: maxL = S[i] ‚àíEner/T Ener = Ener + 4 48 sumdeno = 0 sumnume = 0 Ener = ‚àí2‚àóN foriin range (0, N): 52 ifS[i] .= 0: exponent = S[i] ‚àíEner/T ‚àímaxL sumnume += Ener ‚àóexp(exponent) sumdeno += exp(exponent) 56 Ener = Ener + 4.0 U = sumnume/sumdeno/N # internal energy U(T)/N energ.plot(pos = (T, U) ) 60defWL() : #W a n g ‚àíLandau sampling Hinf = 1.e10 # initial values for Histogram Hsup = 0.",3237
17.7 Code Listings,"tol = 1.e ‚àí3 # tolerance , stops the algorithm 64ip = zeros(L) im = zeros(L) # BC R or down, L or up height = abs(Hsup‚àíHinf)/2. # Initialize histogram ave = (Hsup + Hinf)/2. # about average of histogram 68percent = height / ave foriin range (0, L): forjin range (0, L): sp[i, j] = 1 # Initial spins foriin range (0, L): 72 i p [ i ]=i+1 im[i] = i ‚àí1 # Case plus , minus ip[L‚àí1] = 0 im[0] = L ‚àí1 # Borders 76Eold = ‚àí2‚àóN # Initialize energy forjin range (0, N + 1): S[j] = 0 # Entropy initialized iter=0 fac = 1 80whilefac > tol : i=int(N‚àórandom.random() ) # Select random spin xg = i percentL 84 # Must be i //L , not i /L for Python 3 : yg = i//L # Localize x, y, grid point Enew = Eold + 2 ‚àó(sp[ip[xg],yg] + sp[im[xg],yg] + sp[xg,ip[yg]] +s p [ x g ,i m [ y g ] ]) ‚àósp[xg, yg] # Change energy 88 deltaS = S[iE(Enew)] ‚àíS[iE(Eold)] ifdeltaS <= 0 orrandom.random() < exp( ‚àídeltaS): Eold = Enew; sp[xg, yg] ‚àó=‚àí1 # Flip spin 92 S[iE(Eold)] += fac; # Change entropy if iter percent10000 == 0: # Check flatness every 10000 sweeps forjin range (0 ,N +1 ) : ifj= =0: 96 Hsup = 0 Hinf = 1e10 # Initialize new histogram ifhist[j] == 0 : continue # Energies never visited ifhist[j] > Hsup: Hsup = hist[j] 100 ifhist[j] < Hinf: Hinf = hist[j] height = Hsup ‚àíHinf ave = Hsup + Hinf percent = 1.0 ‚àóheight/ave # 1 . 0 to make i t f l o a t number 104 ifpercent < 0.3 : # Histogram flat ? print(\"" iter \"" ,iter,\"" log(f) \"" , fac) forjin range (0, N + 1): prhist[j] = hist[j] #t op l o t 108 hist[j] = 0 # Save hist fac ‚àó=0 . 5 # Equivalent to log(sqrt(f)) iter+= 1 hist[iE(Eold)] += 1 # Change histogram , add 1 , update 112 iffac >= 0.5: # just show the first histogram 388 17 Thermodynamics Simulations and Feynman Path Integrals # Speed up by using array calculations : histo.x = 2.0 ‚àóarange(0,N+1) ‚àíN histo.y = 0.025 ‚àóhist‚àí10 116deltaS = 0.0 print(\""wait because iter > 13 000 000\"" ) # not always the same WL() # Call Wang Landau algorithm deltaS = 0.0 120forjin range (0, N + 1): rate(150) order = j ‚àó4‚àí2‚àóN deltaS = S[j] ‚àíS[0] + log(2) 124ifS[j] .= 0 : entrp.plot(pos = (1. ‚àóorder/N, deltaS)) # plot entropy IntEnergy(); print(\""Done\"") Listing 17.3 QMC.py Feynmanpathintegrationcalculationofground-stateprobability. # Q M C.py: Q u a n t u m MonteCarlo (Feynman path integration) fromvisualimport ‚àó;fromvisual.graph import ‚àó;importrandom 4 N = 100; Nsteps = 101; xscale = 10. # Initialize path = zeros([Nsteps], float); prob = zeros([Nsteps], float) 8trajec = display(width = 300,height=500, title= ‚ÄôSpacetime Paths‚Äô ) trplot = curve(y = range(0, 100), color=color.magenta, display = trajec) defPlotAxes(): #A x i s 12trax = curve(pos=[( ‚àí97,‚àí100),(100, ‚àí100)],colo =color.cyan,display=trajec) label(pos = (0, ‚àí110), text = ‚Äô0‚Äô, box = 0, display = trajec) label(pos = (60, ‚àí110), text = ‚Äôx‚Äô, box = 0, display = trajec) defWaveFunctionAxes(): # Axes for probability 16wvfax=curve(pos =[( ‚àí600,‚àí155),(800, ‚àí155)],display=wvgraph,color=color.cyan) curve(pos = [(0, ‚àí150), (0,400)], display=wvgraph, color=color.cyan) label(pos = ( ‚àí80,450), text= ‚ÄôProbability‚Äô , box = 0, display = wvgraph) label(pos = (600, ‚àí220), text= ‚Äôx‚Äô, box=0, display=wvgraph) 20label(pos = (0, ‚àí220), text= ‚Äô0‚Äô, box=0, display=wvgraph) defEnergy(path): #H OE n e r g y sums = 0. foriin range (0,N‚àí2):sums += (path[i+1] ‚àípath[i]) ‚àó(path[i+1] ‚àípath[i]) 24sums += path[i+1] ‚àópath[i+1]; returnsums defPlotPath(path): # Plot trajectory forjin range (0, N): 28 trplot.x[j] = 20 ‚àópath[j] trplot.y[j] = 2 ‚àój‚àí100 defPlotWF(prob): #P l o tp r o b foriin range (0, 100): 32 wvplot.color = color.yellow wvplot.x[i] = 8 ‚àói‚àí400 # Center fig wvgraph = display(x=340,y=150,width=500,height=300,title= ‚ÄôGround State‚Äô ) 36wvplot = curve(x = range(0, 100), display = wvgraph) wvfax = curve(color = color.cyan) PlotAxes(); WaveFunctionAxes() #P l o ta x e s oldE = Energy(path) 40whileTrue: # Pick random element rate(10) # Slow paintings element = int(N‚àórandom.random() ) # Metropolis change = 2.0 ‚àó(random.random() ‚àí0.5) 44path[element] += change # Change path newE = Energy(path); #F i n dn e wE ifnewE > oldE andmath.exp( ‚àínewE + oldE)<= random.random() : path[element] ‚àí=c h a n g e # Reject 48 PlotPath(path) # Plot trajectory elem =int(path[element] ‚àó16 + 50) # i f path = 0 , elem = 50 # elem = m ‚àópath[element] + b is the linear transformation 52# if path= ‚àí3, elem=2 i f path=3.",4333
17.7 Code Listings,", elem=98 = > b=50, m =16 linear TF. 17.7 Code Listings 389 # this way x = 0 correspond to prob[50] ifelem < 0: elem = 0, 56ifelem > 100: elem = 100 # If exceed max prob[elem] += 1 # increase probability PlotWF(prob) #P l o tp r o b oldE = newE Listing 17.4 QMCbouncer.py Feynman path integration computation of a quantum particleinagravitationalfield. # QMCbouncer.py: g.s. wavefunction via path integration 3fromvisualimport ‚àó importrandom fromvisual.graph import ‚àó 7N= 100; dt = 0.05; g = 2.0; h = 0.00; maxel = 0 path = zeros([101], float); arr = path; prob = zeros([201], float) trajec = display(width = 300, height=500,title = ‚ÄôSpacetime Trajectory‚Äô ) trplot = curve(y = range(0, 100), color=color.magenta, display = trajec) 11 deftrjaxs(): # plot axis for trajectories trax=curve(pos=[( ‚àí97,‚àí100),(100, ‚àí100)],color=color.cyan,display=trajec) curve(pos = [( ‚àí65,‚àí100),(‚àí65, 100)], color=color.cyan,display=trajec) 15label(pos = ( ‚àí65,110), text = ‚Äôt‚Äô, box = 0, display = trajec) label(pos = ( ‚àí85,‚àí110), text = ‚Äô0‚Äô, box = 0, display = trajec) label(pos = (60, ‚àí110), text = ‚Äôx‚Äô, box = 0, display = trajec) wvgraph = display(x=350, y=80, width=500, height=300, title = ‚ÄôGS Prob‚Äô ) 19wvplot = curve(x = range(0, 50), display = wvgraph) # wave function plot wvfax = curve(color = color.cyan) defwvfaxs(): # plot axis for wavefunction 23wvfax = curve(pos =[( ‚àí200,‚àí155),(800, ‚àí155)],display=wvgraph,color=color.cyan) curve(pos = [( ‚àí200,‚àí150),(‚àí200,400)],display=wvgraph,color=color.cyan) label(pos = ( ‚àí70, 420),text = ‚ÄôProbability‚Äô , box = 0, display=wvgraph) label(pos = (600, ‚àí220),text = ‚Äôx‚Äô, box = 0, display = wvgraph) 27label(pos = ( ‚àí200,‚àí220),text = ‚Äô0‚Äô, box = 0, display = wvgraph) trjaxs(); wvfaxs() #p l o ta x e s defenergy (arr): # Energy of path 31esum = 0. foriin range (0,N): esum += 0.5 ‚àó((arr[i+1] ‚àíarr[i])/dt) ‚àó‚àó2+g‚àó(arr[i]+arr[i+1])/2 returnesum 35 defplotpath(path): # Plot xy trajectory forjin range (0, N): trplot.x[j] = 20 ‚àópath[j] ‚àí65 39 trplot.y[j] = 2 ‚àój‚àí100 defplotwvf(prob): # Plot wave function foriin range (0, 50): 43 wvplot.color = color.yellow wvplot.x[i] = 20 ‚àói‚àí200 wvplot.y[i] = 0.5 ‚àóprob[i] ‚àí150 47oldE = energy(path) counter = 1 norm = 0. # Plot psi every 100 maxx = 0.0 51while1: # \""Infinite\"" loop rate(100) element = int(N‚àórandom.random() ) ifelement .= 0 andelement.= N: # Ends not allowed 55 change = ( (random.random() ‚àí0.5) ‚àó20.)/10. ifpath[element] + change > 0.: # No negative paths path[element] += change 390 17 Thermodynamics Simulations and Feynman Path Integrals newE = energy(path) # N e w trajectory E 59 ifnewE > oldE andexp(‚àínewE + oldE) <= random.random() : path[element] ‚àí=c h a n g e # Link rejected plotpath(path) ele =int(path[element] ‚àó1250./100.) # Scale changed 63 ifele >= maxel: maxel = ele # Scale change 0 to N ifelement .= 0: prob[ele] += 1 oldE = newE; ifcounter percent100 == 0: # Plot psi every 100 67 foriin range (0, N): # Max x of path ifpath[i] >= maxx: maxx = path[i] h = maxx/maxel # space step firstlast = h ‚àó0.5‚àó(prob[0] + prob[maxel]) # for trap . extremes 71 foriin range (0, maxel + 1): norm = norm + prob[i] #N o r m norm = norm ‚àóh + firstlast # Trap rule plotwvf(prob) # Plot probability counter += 1",3192
Chapter 18 Molecular Dynamics Simulations,"391 18 Molecular Dynamics Simulations You may recall from introductory chemistry that the ideal gas law can be derived from Ô¨Årst principles by conÔ¨Åning noninteracting molecules to a box. This chapter extends that model to molecules that interact with each other. Although the theory of Molecular Dynamics (MD) is straightforward, the simulations have proven to be powerful approaches for studying the physical and chemical properties of solids, liquids, amorphous materials, and biological molecules . Problem Determinewhetheracollectionofargonmoleculesplacedinaboxwillcoalesce intoanorderedstructureasthetemperatureislowered. Although we know that quantum mechanics is the proper theory for molecular interac- tions, MD uses Newton‚Äôs laws as its basis and focuses on bulk properties, which are not particularlysensitivetothesmall rbehaviors,wherequantumeffects maybeimportant. Nevertheless, Car and Parrinello [1985] showed how MD can be extended to include quantum mechanics by using density functional theory to calculate the force between molecules. That technique, known as quantum MD ,i sa na c t i v ea r e ao fr e s e a r c hb u ti s beyond the realm of the present chapter.1For those with further interests, there are full textsonMD[Rapaport,1995;HockneyandEastwood,1988],fullerdiscussionsin[Gould etal.,2006;Thijssen,1999;Fosdick etal.,1996],aswellasprimers[Ercolessi,1997],and codesavailableon-line[Nelson etal.,1996;Refson,2000;Anderson etal.,2008]. Although MD‚Äôs solution of Newton‚Äôs laws is conceptually simple, when applied to a very large number of particles, it becomes the ‚Äúhigh school physics problem from hell.‚Äù Some approximations must be made in order to avoid solving the ‚àº1024equations of motion of a realistic system, and so, present calculations tend to have an upper limit of ‚àº109particlesconfinedtoafiniteregionofspace. Inanumberofways,MDsimulationsaresimilartothethermalMonteCarlosimulations westudiedinChapter17.Bothtypicallyinvolvealargenumber Nofinteractingparticles thatstartoutinsomesetconfiguration,andthenequilibrateintoadynamicstate.However, inMDwehaveastatisticalmechanical microcanonicalensemble inwhichtheenergy Eand volumeVoftheNparticlesarefixed.WethenuseNewton‚Äôslawstogeneratethedynamics 1 WethankSatoruS.Kanoforpointingthisouttous. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 392 18 Molecular Dynamics Simulations ofthesystem.Incontrast,MonteCarlosimulationsdonotstartwithfirstprinciples,but, instead,incorporateanelementofchanceandhavethesystemremainingincontactwitha heatbathatafixedtemperature,ratherthankeepingtheenergy Efixed.Thisisa canonical ensemble. Since the molecules in an MD simulation are dynamic, their velocities and positions change continuously with time. After a simulation has run long enough to stabilize, we willcomputetimeaveragesofthedynamicquantitiesinordertorelatethemtothether- modynamicproperties.ThesimulationsapplyNewton‚Äôslawswiththeassumptionthatthe netforceoneachmoleculeisthesumofthetwo-bodyforceswithalloftheother (N‚àí1) molecules: md2ri dt2=Fi(r0,‚Ä¶,rN‚àí1), (18.1) md2ri dt2=N‚àí1‚àë i<j=0fij,i=0,‚Ä¶,(N‚àí1). (18.2) Herewehaveignoredthefactthatanargonatomitselfisadynamicsystemcomposedof 18electronsandanucleus(Figure18.1).Althoughitmaybepossibletoignorethisinternal structurewhendeducingthelong-rangepropertiesofinertelements,itmattersforsystems suchaspolyatomicmoleculesthatdisplayrotational,vibrational,andelectronicdegreesof freedomasthetemperatureisraised.2 Theforceonmolecule iderivesfromthesumofmolecule‚Äìmoleculepotentials: Fi(r0,r1,‚Ä¶,rN‚àí1)=‚àíùõÅriU(r0,r1,‚Ä¶,rN‚àí1), (18.3) U(r0,r1,‚Ä¶,rN‚àí1)=‚àë i<ju(rij)=N‚àí2‚àë i=0N‚àí1‚àë j=i+1u(rij), (18.4) ‚áífij=‚àídu(rij) drij( xi‚àíxj rijÃÇex+yi‚àíyj rijÃÇey+zi‚àízj rijÃÇez) . (18.5) Hererij=|ri‚àírj|=rjiis the distance between the centers of molecules iandj,a n d the limits on the sums assure that no interaction is counted twice. Because we have assumeda conservative potential,thetotalenergyofthesystem,thatis,thepotentialplus kinetic energies summed over all particles, should be conserved over time. Nonetheless, practical computations usually ‚Äúcut the potential off‚Äù when the molecules are far apart [u(rij>rcut)=0], which means that the derivative du‚àïdris infinite at rcut, which is not whataconservativepotentialdoes,that,inturn,meansthatoverallenergywillnolonger be precisely conserved. Yet because the cutoff radius is large, the cutoff occurs when the forces are minuscule, and so the violation of energy conservation should be small comparedtootherapproximationsandround-offerrors. ee eee eee eee eeee e eeee eee e e eeeeee + +Figure 18.1 The molecule‚Äìmolecule effective interaction arises from the many-body interaction of the electrons and nucleus in one molecule (circle) with the electrons and nucleus in another molecule (another circle). Note, the size of the nucleus at the center of each molecule is highly exaggerated, and real electrons have no size. 2 WethankSaturoKanoforclarifyingthispoint. 18 Molecular Dynamics Simulations 393 Inatruefirst-principlescalculation,thepotentialbetweenanytwoargonatomswould arisefromthesumofapproximately1000electron‚Äìelectronandelectron‚ÄìnucleusCoulomb interactions.Amorepracticalcalculationwouldemployaneffectivepotentialderivedfrom amany-bodytheory,suchasHartree‚ÄìFockordensityfunctionaltheory.Ourapproachis simpleryet.WeusethephenomenologicalLennard‚ÄìJonespotential, u(r)=4ùúñ[(ùúé r)12 ‚àí(ùúé r)6] , (18.6) f(r)=‚àídu drr r=48ùúñ r2[(ùúé r)12 ‚àí1 2(ùúé r)6] r. (18.7) Heretheparameter ùúñgovernsthestrengthoftheinteraction,theparameter ùúédetermines thelengthscale,andbotharededucedbyfitstodata.Sometypicalvaluesfortheparameters andscalesforthevariablesaregiveninTable18.1.Inordertomakethesimulationsimpler andtoavoidunder-andoverflows,itishelpfultomeasureallvariablesinthenaturalunits oftheseconstants.Theinterparticlepotentialandforcethentaketheforms u(r)=4[1 r12‚àí1 r6] ,f(r)=48 r[1 r12‚àí1 2r6] . (18.8) The Lennard‚ÄìJones potential is seen in Figure 18.2 to be the sum of a long-range attrac- tiveinteraction ‚àù1‚àïr6andashort-rangerepulsiveone ‚àù1‚àïr12.Thechangefromrepulsion toattractionoccursat r=ùúé,withthepotential‚Äôsminimumat r=21‚àï6ùúé=1.1225ùúé,which wouldbetheatom‚Äìatomspacinginasolidboundbythispotential.The1 ‚àïr12termaccounts fortheCoulombandPauliprinciplerepulsionsthatarisewhentheelectroncloudsfromtwo atomsoverlap.This1 ‚àïr12termdominatesatshortdistancesandleadstoatomsbehaving likehardspheres.Theprecisevalueof12isnotoftheoreticalsignificance(althoughitbeing largeis)andmayhavebeenchosenbecauseitis2 √ó6. The1‚àïr6termthatdominatesatlargedistancesmodelstheweak vanderWaals induced dipole‚Äìdipoleattractionbetweentwomolecules.Thisattractionarisesfromfluctuationsin Table 18.1 Parameter and scales for the Lennard‚ÄìJones potential. Quantity Mass Length Energy Time Temperature Unit m ùùàùùê‚àö mùùà2‚àïùùêùùê ‚àïkB Value 6.7 √ó10‚àí26kg 3.4 √ó10‚àí10m 1.65 √ó10‚àí21J4 . 5√ó10‚àí12s 119K Figure 18.2 The Lennard‚ÄìJones effective potential used in many MD simulations. Note the sign change at r=1 and the minimum at r‚âÉ1.1225 (natural units). Note too that because the raxis does not extend to r=0, the inÔ¨Ånitely high central repulsion is not shown.Repulsive Attractionu(r) r0.8 1 1.2 1.4 1.6 1.8 2010 Lennard‚ÄìJones",7212
18.1 MD Versus Thermodynamics. 18.2 Initial Boundary and Large r Conditions,"394 18 Molecular Dynamics Simulations which,atsomeinstantintime,amoleculeontherighttendstobemorepositiveon,say,the leftside,likeadipole ‚áê.This,inturn,attractsthenegativechargeinamoleculeonitsleft, therebyinducingadipole ‚áê.Aslongasthemoleculesstayclosetoeachother,thepolarities continuetofluctuateinsynchronization, ‚áê‚áê,‚áí‚áí,sothattheattractionismaintained. The resultant dipole‚Äìdipole attraction behaves like 1 ‚àïr6, and although it‚Äôs much weaker thanaCoulombforce,itisresponsibleforthebindingofneutral,inertelements,suchas argon,forwhichtheCoulombforcevanishes. 18.1 MD Versus Thermodynamics Although anMDsimulationisvalidforanynumberofparticles,ifweassumethatthenum- berofparticlesisverylarge,thenitbecomespossibletousestatisticalmechanicstorelate the results of a simulation to thermodynamic quantities. The equipartition theorem tells usthat,onaverage,formoleculesinthermalequilibriumattemperature T,eachdegreeof freedomhasanenergy kBT‚àï2associatedwithit,where kB=1.38√ó10‚àí23J/KisBoltzmann‚Äôs constant.Asimulationprovidesthekineticenergyoftranslation3: KE=1 2‚ü®N‚àí1‚àë i=0ùë£2 i‚ü© . (18.9) Thetimeaverageof KE(forthreedegreesoffreedom)isrelatedtotemperatureby ‚ü®KE‚ü©=N3 2kBT‚áíT=2‚ü®KE‚ü© 3kBN. (18.10) Thesystem‚Äôspressure Pisdeterminedbyaversionofthe Virialtheorem , PV=NkBT+ùë§ 3,ùë§=‚ü®N‚àí1‚àë i<jrij‚ãÖfij‚ü© , (18.11) where the Virial ùë§is seen to be an average of force times interparticle distances. Note thatbecauseidealgaseshavenointermolecularforces,theirVirialvanishes,andwewould obtaintheidealgaslaw.Thepressureforthegeneralcaseis P=ùúå 3N(2‚ü®KE‚ü©+ùë§), (18.12) whereùúå=N‚àïVisthedensityoftheparticles. 18.2 Initial, Boundary, and Large rConditions AlthoughwemaystartoffanMDsimulationwithavelocitydistributioncharacteristicof a definite temperature, this is not the true temperature of the system because it has not yet equilibrated. Eventually, there will be a redistribution of energy between KE and PE [Thijssen,1999],andthenthesystemwillhaveatruetemperature.Itisinterestingtonote that this initial random distribution is the only place where chance enters into our MD simulation, and it is put there only to speed up the equilibration. Once started, the time evolution of the MD system is determined by Newton‚Äôs laws, in contrast to Monte Carlo simulations,whichareinherentlystochastic. 3 Unlessthetemperatureisveryhigh,argonatoms,beinginertspheres,havenorotationalenergy. 18.2 Initial, Boundary, and Large r Conditions 395 It is easy to believe that a simulation of 1023molecules might predict bulk properties well, but with MD simulations employing only 106‚Äì109particles, one must be clever to makelessseemlikemore.Furthermore,becausecomputersarefinite,themoleculesinthe simulationareconstrainedtoliewithinafinitebox,whichinevitablyintroducesartificial surfaceeffects arisingfromthewalls.Surfaceeffectsareparticularlysignificantwhenthe numberofparticlesissmallbecausealargefractionofthemoleculesresidenearthewalls. Forexample,if1000particlesarearrangedina10 √ó10√ó10cube,therearethen103‚Äì83= 488particlesoneunitawayfromthesurface,thatis,49 percentofthemolecules.For106particles, thisfractionfallsto6 percent. Theimpositionof periodicboundaryconditions (PBCs)strivestominimizetheshortcom- ingsofboththesmallnumbersofparticlesandtheartificialboundaries.Althoughwelimit our simulationto an Lx√óLy√óLzbox,we imaginethisbox beingreplicatedtoinfinityin alldirections(Figure18.3).Accordingly,aftereachtime-integrationstep,weexaminethe positionofeachparticleandcheckifithasleftthesimulationregion.Ifithas,thenwebring animageoftheparticlebackthroughtheoppositeboundary(Figure18.3): x‚áí{x+Lx,ifx‚â§0, x‚àíLx,ifx>Lx.(18.13) Consequently, each box looks the same and has continuous properties at the edges. As shown by the one-headed arrows in Figure 18.3, if a particle exits the simulation volume,itsimageentersfromtheotherside,andthusbalanceismaintained. In principle, a molecule interacts with all other molecules and all of their images, so despite the fact that there are a finite number of atoms in the interaction volume, there 4 53 2 1 4 53 2 1 4 53 2 1 4 53 1 4 53 2 1 4 53 2 1 4 53 2 1 4 53 2 1 4 53 2 12 Figure 18.3 An imagined inÔ¨Ånite space generated by imposing periodic boundary conditions on the particles within the simulation volume (shaded box). The two-headed arrows indicate how a particle interacts with the nearest version of another particle, be that within the simulation volume or an image. The vertical arrows indicate how the image of particle 4 enters when the actual particle 4 exits.",4469
18.3.2 Analysis,"396 18 Molecular Dynamics Simulations should be an infinite number of interactions [Ercolessi, 1997]. Nonetheless, because the Lennard‚ÄìJones potential falls off so rapidly for large r,V(r=3ùúé)‚âÉV(1.13ùúé)‚àï200, far-off molecules do not contribute significantly to the motion of a molecule. An so we pick a value of the cutoff radius rcut‚âÉ2.5ùúé, beyond which we ignore the effect of the potential: u(r)={4(r‚àí12‚àír‚àí6),forr<rcut, 0, forr>rcut.(18.14) Accordingly,ifthesimulationregionislargeenoughfor u(r>Li‚àï2)‚âÉ0,anatominteracts withonlythe nearestimage ofanotheratom. Asalreadyindicated,ashortcomingwiththecutoffpotential(18.14)isthatbecausethe derivativedu‚àïdris singular at r=rcut, the potential is no longer conservative, and thus energy conservation is no longer ensured. However, because the forces are very small at rcut,theviolationis,presumably,verysmall. 18.3 Verlet Algorithms Arealistic,butsmall,MDsimulationmayrequireintegrationofthe3Dequationsofmotion for1010timestepsforeachof103‚Äì106particles.Althoughwecoulduseourstandard rk4 ODE solver for this, time is saved by using a simpler rule. The Verlet algorithm uses the central-differenceapproximation(Chapter5)forthesecondderivativetoadvancethesolu- tionssimultaneouslybyasingletimestep hforallNparticles: Fi[r(t),t]=d2ri dt2‚âÉri(t+h)+ri(t‚àíh)‚àí2ri(t) h2, (18.15) ‚áíri(t+h)‚âÉ2ri(t)‚àíri(t‚àíh)+h2Fi(t)+O(h4), (18.16) wherewehaveset m=1.(Improvedalgorithmsmayvarythetimestepdependinguponthe speedoftheparticle.)Noticethatalthoughtheatom‚Äìatomforcedoesnothaveanexplicit timedependence,weincludeanimplicit tdependenceinitasawayofindicatingitsdepen- denceupontheotheratoms‚Äôpositionsatthatparticulartime. Part of the efficiency of the Verlet algorithm (18.16) lies in its solving for the position ofeachparticlewithoutrequiringaseparatesolutionfortheparticle‚Äôsvelocity.However, once we have deduced the position for various times, we can use the central-difference approximationforthefirstderivativeof ritoobtainthevelocity: vi(t)=dri dt‚âÉri(t+h)‚àíri(t‚àíh) 2h+O(h2). (18.17) Finally, note that because the Verlet algorithm needs rfrom two previous steps, it is not self-starting,andsomustbestartedwithaforwarddifferencederivative, r(t=‚àíh)‚âÉr(0)‚àíhv(0)+h2 2F(0). (18.18) Velocity-Verlet Algorithm Another version of the Verlet algorithm, which we recom- mend because of its increased stability, uses a forward-difference approximation for the derivativetoadvance boththepositionandvelocitysimultaneously: ri(t+h)‚âÉri(t)+hvi(t)+h2 2Fi(t)+O(h3), (18.19) 18.3 Verlet Algorithms 397 vi(t+h)‚âÉvi(t)+ha(t)+O(h2), (18.20) ‚âÉvi(t)+h[Fi(t+h)+Fi(t) 2] +O(h2). (18.21) Althoughthisalgorithmappearstobeoflowerorderthan(18.16),theuseofupdatedposi- tions when calculating velocities, and the subsequent use of these velocities, give both algorithmssimilarprecision. Ofinterestisthat(18.21)approximatestheaverageforceduringatimestepas [Fi(t+h)+ Fi(t)]‚àï2.Updatingthevelocityisalittletrickybecauseweneedtheforceattime t+h,which depends on the particle positions at t+h. Consequently, we must update all the particle positionsandforcesto t+hbeforeupdatingvelocities,whilesavingtheforcesatanearlier timeforusein(18.21).Assoonasthepositionsareupdated,weimposePBCstoestablish thatwehavenotlostanyparticlesandthencalculatetheforces. 18.3.1 Implementation and Exercise In theonlinematerialsforthisbook,youwillfindanumberofanimations(movies)ofsolu- tionstotheMDequations.SomeframesfromtheseanimationsareshowninFigure18.4. Theprogram MD1D.pyinListing18.1implementsa1Dsimulationusingthevelocity-Verlet algorithm, MD2D.pyinListing18.2implementsa2Dsimulation,and MDpBC.pyinListing18.3 implementsa2DsimulationwithPBCs.Usetheseasmodelsforthefollowing: 1) Establishthatyoucanrunandvisualize MD2D.py. 2) Place the particles initially at the sites of a simple cubic lattice. The equilibrium con- figurationforaLennard‚ÄìJonessystematlowtemperatureisaface-centeredcubic,and if your simulation is running properly, then, as we show in Figure 18.4, the particles shouldmigratefromsimplecubic(SC)toface-centeredcubic(FCC).AnFCClatticehas four-quartersofaparticleperunitcell,soan L3boxwithalatticeconstant L‚àïNcontains (partsof)4 N3=32,108,256, ‚Ä¶particles. 3) To save computing time, assign initial particle velocities corresponding to a fixed- temperature Maxwellian distribution. (Recall, the sums of uniform random numbers followaGaussiandistribution.) Figure 18.4 Left: Two frames from an animation of a 1D simulation. The spaces on the left and right differ slightly in these two frames due to an image atom moving off the frame to the right and then popping up on the left. Right: Two frames from the animation of a 2D simulation showing the initial and equilibrated states. Note how the atoms start off in a simple cubic arrangement, but then equilibrate to a face-centered cubic lattice. In both the 1D and 2D simulations, the atoms remain conÔ¨Åned as a result of the interatomic forces. 398 18 Molecular Dynamics Simulations 4) Printthecodeandindicateonitwhichintegrationalgorithmisused,wherethePBCs areimposed,wherethenearestimageinteractionisevaluated,andwherethepotential iscutoff. 5) Atypicaltimestepis Œît=10‚àí14s,whichinournaturalunitsequals0.004.Youprobably willneedtomake104‚Äì105suchstepstoequilibrate,whichcorrespondstoatotaltime ofonly10‚àí9s(alotcanhappentoaspeedymoleculein10‚àí9s).Choosethe largesttime stepthatprovidesstabilityandgivesresultssimilartoFigure18.5. 6) ThePEandKEchangewithtimeasthesystemequilibrates.Evenafterthat,therewill befluctuationsinthembecausethisisadynamicsystem.Evaluatethetime-averaged energiesforanequilibratedsystem. 7) Compare the final temperature of your system to the initial temperature. Change the initialtemperatureandlookforasimplerelationbetweenitandthefinaltemperature (Figure18.6). 18.3.2 Analysis 1) Modifyyourprogramsothatitoutputsthecoordinatesandvelocitiesofafewparticles throughout the simulation. Note that you do not need as many time steps to follow a trajectoryasyoudotocomputeit,andsoyoumaywanttousethe modoperator  percent100for output. 2) Startyourassessmentwitha1Dsimulationatzerotemperature.Theparticlesshould remaininplacewithoutvibration.Increasethetemperatureandnotehowtheparticles begintomoveaboutandinteract. 3) Try starting off all your particles at the minima in the Lennard‚ÄìJones potential. The particlesshouldremainboundwithinthepotentialatlowtemperatures. 4) Repeatthesimulationsfora2Dsystem.Thetrajectoriesshouldresemblebilliardball- likecollisions. 5) Createananimationofthetime-dependentlocationsofseveralparticles. 6) Calculate and plot the root-mean-square displacement of molecules as a function of temperature: Rrms=‚àö‚ü® |r(t+Œît)‚àír(t)|2‚ü©, (18.22) wheretheaverageisoveralltheparticlesinthebox.Determinetheapproximatetime dependenceof Rrms. 7) Testyoursystemfortime-reversalinvariance.Stopitatafixedtime,reverseallvelocities, andseeifthesystemretracesitstrajectoriesbacktotheinitialconfigurationafterthis samefixedtime. 8)Diffusion:Itiswellknownthatlightmoleculesdiffusemorequicklythanheavierones. SeeifyoucansimulatediffusionwithyourMDsimulationusingaLennard‚ÄìJonespoten- tialandPBCs[Satoh,2011]. (a) Generalize the velocity-Verlet algorithm so that it can be used for molecules of differentmasses. (b) Modifythesimulationcodesothatitcanbeusedforfiveheavymoleculesofmass M=10andfivelightmoleculesofmass m=1. (c) Startwiththemoleculesplacedrandomlynearthecenterofthesquaresimulation region. 18.3 Verlet Algorithms 399 (d) Assignrandominitialvelocitiestothemolecules. (e) Runthesimulationseveraltimesandverifyvisuallythatthelightermoleculestend todiffusemorequicklythantheheavierones. (f) Foreachensembleofmolecules,calculatethermsvelocityatregularinstancesof time,andthenplotthermsvelocitiesasfunctionsoftime.Dothelighterparticles haveagreaterrmsvelocity? Energy (J)KE VE 2E‚Äì13 0 4E‚Äì13 6E‚Äì13 8E‚Äì13 1E‚Äì12 1.2E‚Äì122E‚Äì12 4E‚Äì12 6E‚Äì12 8E‚Äì12 1E‚Äì11 1.2E‚Äì11 0Energy (J)8.00E‚Äì19 6.00E‚Äì19 4.00E‚Äì19 2.00E‚Äì19 0.00E+00 ‚Äì2.00E‚Äì19 ‚Äì4.00E‚Äì19 ‚Äì6.00E‚Äì19 ‚Äì8.00E‚Äì19 ‚Äì1.00E‚Äì18 ‚Äì1.20E‚Äì18 ‚Äì1.40E‚Äì180.00E+005.00E‚Äì201.00E‚Äì191.50E‚Äì19 ‚Äì5.00E‚Äì20 ‚Äì1.00E‚Äì19 ‚Äì1.50E‚Äì19 2.00E‚Äì19 Time (s) (568 steps)Time (s) (5000 steps) KE VEEnergy versus time for 300 particles in a 2D box, initially at 150 kEnergy versus time for 36 particles in a 2D box, initially at 150 k 1.4E‚Äì12 Figure 18.5 The kinetic, potential, and total energy for a 2D MD simulation with 36 particles ( top), and 300 particles ( bottom ), both with an initial temperature of 150 K. The potential energy is negative, the kinetic energy is positive, and the total energy is seen to be conserved (Ô¨Çat).",8495
18.4 MD for 16 Particles,"400 18 Molecular Dynamics Simulations 0100200300 Final temperature (K) 200 E‚Äì19 100 E‚Äì19 Initial KE (j) P 12 0 0 0.1 0.2 0.3 T Figure 18.6 Left: The temperature after equilibration as a function of initial kinetic energy for a 2D MD simulation with 36 particles. Right: The pressure versus temperature for a simulation with several hundred particles. An ideal gas (noninteracting particles) would yield a straight line. (Courtesy of J. Wetzel.) 18.4 MD for 16 Particles A small number of particles are placed in a box. The forces between the particles derive from the Lennard‚ÄìJones potential. A number of independent snapshots are taken of the particlesinthebox,andthenumber NrhsofparticlesontheRHSoftheboxisrecordedfor each.Ifnisthenumberofframesthatshow Nrhsparticlesintheright-handside,thenthe probabilityoffinding NrhsparticlesontheRHSis: Óàº(n)=C(n) 2Nrhs. (18.23) HereC(n)isthenumberofwaysofplacing nparticlesinthelefthalfofthebox. 1) ModifythepreviouslydevelopedMDprogramsothatitrunsfor16particlesinsidea2D boxofsideL=1.AssumePBCs,andcomputethepositionsandvelocitiesoftheparticles usingthevelocity-Verletalgorithm(18.21). (a) Extend the program so that at the end of each time step, it counts the number of particlesNrhsontheRHSofthebox. (b) Create,plot,andupdatecontinuallyahistogramcontainingthedistributionofthe numberoftimes nthataNrhsvalueoccurs,asafunctionof Nrhs. (c) Make a histogram showing the probability (18.23) of finding Nrhsparticles on the RHS,asafunctionof Nrhs. (d) CompareyourplotstothoseinFigure18.7,createdby MDpBC.py. 2) EventhoughanMDsimulationisdeterministic,theparticlesdotendtoequilibrateafter arathersmallnumberofcollisions,inwhichcasethesystemresemblesathermalone. Thisisconsistentwiththeresultfromergodictheorythat,afteralongtime,adynamical systemtendstoforgetitsinitialstate.Testthishypothesisbyrandomlyassigningseveral differentsetsofinitialpositionsandvelocitiestothe16particles,andthendetermining thedistributionsforeachinitialcondition.Ifthehypothesisisvalid,thedistributions shouldbemuchthesame. 3) Useyoursimulationtodeterminethevelocitydistributionoftheparticles. (a) Createahistogrambyplottingthenumberofparticleswithavelocityintherange ùë£toùë£+Œîùë£versusùë£. (b) Startwithrandomvaluesfortheinitialpositionsoftheparticles. 18.4 MD for 16 Particles 401 (c) Start all particles off with the same speed ùë£0, though with random values for directions. (d) Update the histogram after each step and continue until it looks like a normal distribution. 4) Computeandplottheheatcapacityataconstantvolume, CV=ùúïE‚àïùúïT,asafunctionof temperatureforthe16particlesinabox. (a) Asbefore,startwithrandomvaluesfortheinitialpositionsoftheparticles. (b) Start all particles off with the same speed ùë£0, though with random values for directions. (c) Takeanaverageofthetemperaturefor10initialconditions,allwiththesame ùë£0. Relatethetemperaturetothetotalenergy. (d) Repeat the computations for increasing values of ùë£0. (We suggest 0.5 ‚â§ùë£0‚â§20 in stepsof1.) (e) Plotthetotalenergyasafunctionoftheaveragetemperature. (f) Use numerical differentiation to evaluate the heat capacity at a constant volume, CV=ùúïE‚àïùúïT.Unlessyouchangetheparametersofthesystem,youshouldexpect CV tobeconstantwithinstatisticalfluctuations.Resultsofourcalculationareshown inFigure18.8. (g) Exploretheeffectofaprojectilehittingagroupofparticles,aswedoinFigure18.9. Figure 18.7 Top Left : Positions of particles at a single time. Top Right : Distribution showing the number of times Nrhsparticles are present in the RHS of the box. Lower Left : The probability distribution for Ô¨Ånding Nrhsparticles in the RHS of the box. 16 particles in the box.",3620
18.5 Code Listing,"402 18 Molecular Dynamics Simulations Figure 18.8 Left: The total energy versus temperature for 16 particles in a box. Right: The heat capacity at constant volume versus temperature for 16 particles in a box. Figure 18.9 A simulation of a projectile shot into a group of particles. The energy introduced by the projectile is seen to lead to evaporation of the particles. (Courtesy of J. Wetzel.) 18.5 Code Listing Listing18.1 MD1D.py A1DMDsimulationwithtoosmallanumberoftoolargetime steps. # MD1.py Molecular dynamics in 1D fromvisualimport ‚àó 4fromvisual.graph import ‚àó importrandom scene = display(x=0,y=0,width=700,height=350, title= ‚ÄôMolecular Dynamics‚Äô , 8 range=12) # plot spheres sceneK = gdisplay(x=0,y=350,width=600,height=150,title= ‚ÄôAverage KE‚Äô , ymin=0.0,ymax=0.3,xmin=0,xmax=100,xtitle= ‚Äôtime‚Äô,ytitle= ‚ÄôKE avg‚Äô ) Kavegraph=gcurve(color= color.red) #p l o tK E 12scenePE = gdisplay(x=0,y=500,width=600,height=150,title= ‚ÄôPot Energy‚Äô , ymin=‚àí0.6,ymax=0.0,xmin=0,xmax=100,xtitle= ‚Äôtime‚Äô,ytitle= ‚ÄôPE‚Äô) PEcurve = gcurve(color=color.cyan) 18.5 Code Listing 403 Natom = 8 16Nmax = 8 Tinit = 10.0 # T initial t1 = 0 x = zeros( (Nmax) , float) 20vx = zeros( (Nmax) , float) fx = zeros( (Nmax, 2) , float) L = Natom # Length of atom chain atoms = [] 24 deftwelveran(): # Gaussian as average 12 randoms s=0 . 0 foriin range (1,13): 28 s += random.random() returns/12.‚àí0.5 definitialposvel(): # Initial positions, velocities i=‚àí1 32forixin range (0, L): i=i+1 x[i] = ix vx[i] = twelveran() 36 vx[i] = vx[i] ‚àósqrt(Tinit) forjin range (0,Natom): xc = 2 ‚àóx[j]‚àí7 # Linear transform to place spheres atoms.append(sphere(pos=(xc,0), radius=0.5,color=color.red)) 40defsign(a, b): if(b >= 0.0): return abs (a) else: 44 return ‚àíabs(a) defForces(t, PE): #F o r c e s r2cut = 9. #C u t o f f PE = 0. 48foriin range (0, Natom): fx[i][t] = 0.0 foriin range ( 0, Natom ‚àí1) : forjin range (i + 1, Natom): 52 dx = x[i] ‚àíx[j] if(abs(dx) > 0.50 ‚àóL): dx = dx ‚àísign(L, dx) # Interact with closer image r2 = dx ‚àódx 56 if(r2 < r2cut): if(r2 = = 0.): # Avoid 0 denominator r2 = 0.0001 invr2 = 1./r2 60 wij = 48. ‚àó(invr2 ‚àó‚àó3‚àí0.5) ‚àóinvr2 ‚àó‚àó3 fijx = wij ‚àóinvr2 ‚àódx fx[i][t] = fx[i][t] + fijx fx[j][t] = fx[j][t] ‚àífijx # opposite sense next i 64 PE = PE + 4. ‚àó(invr2 ‚àó‚àó3)‚àó((invr2 ‚àó‚àó3)‚àí1.) returnPE deftimevolution(): t1=0 68t2 = 1 h = 0.038 # Unstable if larger hover2 = h/2.0 KE = 0.0 72PE = 0.0 initialposvel() PE = Forces(t1 ,PE) foriin range (0, Natom): # Kinetic energy 76 KE=KE+(vx[ i] ‚àóvx[i])/2.0 t=0 whilet<100: # Time loop rate(1) 80 foriin range (0, Natom): PE = Forces(t1 ,PE) x[i] = x[i] + h ‚àó(vx[i] + hover2 ‚àófx[i][t1]) ifx[i] <= 0.: 84 x[i] = x[i] +L # Periodic boundary conditions ifx[i] >= L : 404 18 Molecular Dynamics Simulations x[i] = x[i] ‚àíL xc = 2 ‚àóx[i]‚àí8 # Linear transform to plot atoms 88 atoms[i].pos=(xc,0) PE = 0.0 PE = Forces(t2 , PE) KE = 0. 92 foriin range (0 , Natom): vx[i] = vx[i] + hover2 ‚àó(fx[i][t1] + fx[i][t2]) KE = KE + (vx[ i] ‚àóvx[i] )/2 T=2 ‚àóKE/(3 ‚àóNatom) 96 Itemp = t1 t1 = t2 t2 = Itemp Kavegraph.plot(pos=(t,KE)) #P l o tK E 100 PEcurve.plot(pos=(t,PE),display=scenePE) #P l o tP E t+ =1 timevolution() Listing18.2 MD2D.py A2DMDsimulationwithtoosmallanumberoftoolargetime steps. # MD2D.py: Molecular dynamics in 2D fromvisualimport ‚àó 4fromvisual.graph import ‚àó importrandom scene = display(x=0,y=0,width=350,height=350, title= ‚ÄôMolecular Dynamics‚Äô , 8 range=10) sceneK = gdisplay(x=0,y=350,width=600,height=150,title= ‚ÄôAverage KE‚Äô , ymin=0.0,ymax=5.0,xmin=0,xmax=500,xtitle= ‚Äôtime‚Äô,ytitle= ‚ÄôKE avg‚Äô ) Kavegraph=gcurve(color= color.red) 12sceneT = gdisplay(x=0,y=500,width=600,height=150,title= ‚ÄôAverage PE‚Äô , ymin=‚àí60,ymax=0.,xmin=0,xmax=500,xtitle= ‚Äôtime‚Äô,ytitle= ‚ÄôPE avg‚Äô ) Tcurve = gcurve(color=color.cyan) Natom = 25; Nmax = 25; Tinit = 2.; dens = 1.;t1 = 0 # Den 1.20 for fcc 16x = zeros( (Nmax) , float) y = zeros( (Nmax) , float) vx = zeros( (Nmax) , float) vy = zeros( (Nmax) , float) 20fx = zeros( (Nmax, 2) , float) fy = zeros( (Nmax, 2) , float) L=int(1.‚àóNatom ‚àó‚àó0.5) # Side of lattice atoms=[] 24 deftwelveran(): # Average 12 rands for Gaussian s=0.0 foriin range (1,13): 28 s += random.random() returns/12.0‚àí0.5 definitialposvel(): # Initialize i=‚àí1 32forixin range (0, L): #x‚àí> 01234 foriyin range (0, L): # y=0 0 5 10 15 20 i=i+1 # y=1 1 6 11 16 21 x[i] = ix # y=2 2 7 12 17 22 36 y[i] = iy # y=3 3 8 13 18 23 vx[i] = twelveran() # y=4 4 9 14 19 24 vy[i] = twelveran() # numbering of 25 atoms vx[i] = vx[i] ‚àósqrt(Tinit) 40 vy[i] = vy[i] ‚àósqrt(Tinit) forjin range (0,Natom): xc = 2 ‚àóx[j]‚àí4 yc = 2 ‚àóy[j]‚àí4 44 atoms.append(sphere(pos=(xc,yc), radius=0.5,color=color.red)) defsign(a, b): if(b >= 0.0): return abs (a) else:return ‚àíabs(a) 18.5 Code Listing 405 48defForces(t, w, PE, PEorW): #F o r c e s #i n v r 2=0 .",4744
18.5 Code Listing,"r2cut = 9. #S w i t c h :P E o r W=1f o rP E PE = 0. 52foriin range (0, Natom): fx[i][t] = fy[i][t] = 0.0 foriin range ( 0, Natom ‚àí1) : forjin range (i + 1, Natom): 56 dx = x[i] ‚àíx[j] dy = y[i] ‚àíy[j] if(abs(dx) > 0.50 ‚àóL): dx = dx ‚àísign(L, dx) # Interact with closer image 60 if(abs(dy) > 0.50 ‚àóL): dy = dy ‚àísign(L, dy) r2 = dx ‚àódx + dy ‚àódy if(r2 < r2cut): 64 if(r2 = = 0.): # To avoid 0 denominator r2 = 0.0001 invr2 = 1./r2 wij = 48. ‚àó(invr2 ‚àó‚àó3‚àí0.5) ‚àóinvr2 ‚àó‚àó3 68 fijx = wij ‚àóinvr2 ‚àódx fijy = wij ‚àóinvr2 ‚àódy fx[i][t] = fx[i][t] + fijx fy[i][t] = fy[i][t] + fijy 72 fx[j][t] = fx[j][t] ‚àífijx fy[j][t] = fy[j][t] ‚àífijy PE = PE + 4. ‚àó(invr2 ‚àó‚àó3)‚àó((invr2 ‚àó‚àó3)‚àí1.) w=w + w i j 76if(PEorW == 1): returnPE else: returnw 80deftimevolution(): avT = 0.0 avP = 0.0 Pavg = 0.0 84avKE = 0.0 avPE = 0.0 t1 = 0 PE = 0.0 88h = 0.031 # step hover2 = h/2.0 KE = 0.0 w=0 . 0 92initialposvel() foriin range (0, Natom): KE = KE+(vx[ i] ‚àóvx[i]+vy[i] ‚àóvy[i])/2.0 # System.out.println(\""\""+t+\"" PE= \""+PE+\"" KE = \""+KE+\"" PE+KE = \""+(PE+KE)) ; 96PE = Forces(t1 ,w,PE,1) time =1 while1: rate(100) 100 foriin range (0, Natom): PE = Forces(t1 ,w,PE,1) x[i] = x[i] + h ‚àó(vx[i] + hover2 ‚àófx[i][t1]) y[i] = y[i] +h ‚àó(vy[i] + hover2 ‚àófy[i][t1]); 104 ifx[i] <= 0.: x[i] = x[i] + L # Periodic BC ifx[i] >= L : x[i] = x[i] ‚àíL ify[i] < = 0.: y[i] = y[i] +L ify[i] > =L: y[i] = y[i] ‚àíL 108 xc = 2 ‚àóx[i]‚àí4 yc = 2 ‚àóy[i]‚àí4 atoms[i].pos=(xc,yc) PE = 0. 112 t2=1 PE = Forces(t2 , w, PE, 1) KE = 0. w=0 . 116 foriin range (0 , Natom): vx[i] = vx[i] + hover2 ‚àó(fx[i][t1] + fx[i][t2]) vy[i] = vy[i] + hover2 ‚àó(fy[i][t1] + fy[i][t2]) 406 18 Molecular Dynamics Simulations KE = KE + (vx[ i] ‚àóvx[i] + vy[i] ‚àóvy[i])/2 120 w = Forces(t2, w, PE, 2) P=dens ‚àó(KE+w) T=KE/(Natom) # increment averages 124 avT = avT + T avP = avP + P avKE = avKE + KE avPE = avPE + PE 128 time += 1 t=time if(t==0): t=1 132 Pavg = avP /t eKavg = avKE /t ePavg = avPE /t Tavg = avT /t 136 pre = (int)(Pavg ‚àó1000) Pavg = pre/1000.0 kener = ( int)(eKavg ‚àó1000) eKavg = kener/1000.0 140 Kavegraph.plot(pos=(t,eKavg)) pener = ( int)(ePavg ‚àó1000) ePavg = pener/1000.0 tempe = ( int)(Tavg ‚àó1000000) 144 Tavg = tempe/1000000.0 Tcurve.plot(pos=(t,ePavg),display=sceneT) timevolution() Listing18.3 MDpBC.py A2DMDsimulationwithperiodicboundaryconditions. #M D p B C . p y:2 ‚àíDMD with Periodic BC fromvisual.graph import ‚àó 4importrandom L = 1; Natom = 16; Nrhs = 0; dt = 1e ‚àí6 scene = display(width = 500,height = 500, range= (1.3) ) 8ndist = gdisplay(x = 500, ymax = 200, width = 500, height = 500, xtitle = ‚ÄôNrhs‚Äô, ytitle = ‚ÄôN‚Äô) inside = label(pos = (0.4,1.1),text = ‚ÄôPRatomticles here = ‚Äô ,box = 0) inside2 = label(pos = (0.8,1.1),box = 0) 12border = curve(pos = [( ‚àíL,‚àíL),(L,‚àíL),(L,L),( ‚àíL,L),(‚àíL,‚àíL)])# Limits fig half = curve(pos = [(0, ‚àíL),(0,L)],color = color.yellow) # Middle positions = [] vel = [] 16Atom = [] # For Spheres dN = [] # Atoms in right half fr = [0] ‚àó(Natom) # Atoms (spheres) fr2 = [0] ‚àó(Natom) # second force 20Ratom = 0.03 # Radius of atom pref = 4 # Reference velocity h = 0.01 factor = 1e ‚àí9 #L e n nJ o n e s 24deltaN = 1 # For histogram distribution = ghistogram(bins=Ratomange(0.,Natom,deltaN), accumulate=1, average=1, color=color.red) foriin range (0,Natom): # Initial r &v 28col = (1.3 ‚àórandom.random() ,1.3 ‚àórandom.random() ,1.3 ‚àórandom.random()) x= 2 .",3309
18.5 Code Listing,"‚àó(L‚àíRatom) ‚àórandom.random() ‚àíL+Ratom # Positons atoms y=2 . ‚àó(L‚àíRatom) ‚àórandom.random() ‚àíL+Ratom # Border forbidden Atom = Atom+[sphere(pos=(x,y),radius=Ratom,color=col)] #A d da t o m s 32theta = 2 ‚àópi‚àórandom.random() # Select angle 0 <=theta<=2 p i vx = pref ‚àócos(theta) # x component velocity vy = pref ‚àósin(theta) positions.append((x,y)) # Add positions to list 36vel.append((vx,vy)) # Add momentum to list pos = Ratomray(positions) # Ratomray with positions ddp = pos[i] 18.5 Code Listing 407 ifddp[0] >=0 andddp[0] <=L: # count atoms right half 40 Nrhs+=1 v = Ratomray(vel) defsign(a, b): # Sign function if(b >= 0.0): return abs (a) 44else:return ‚àíabs(a) defforces(fr): fr=[0] ‚àó(Natom) foriin range ( 0, Natom ‚àí1) : 48 forjin range (i + 1, Natom): dr = pos[i] ‚àípos[j] # relative position if(abs(dr[0]) > L): # smallest distance or image dr[0] = dr[0] ‚àísign(2 ‚àóL, dr[0]) # interact closer image 52 if(abs(dr[1]) > L): dr[1] = dr[1] ‚àísign(2 ‚àóL, dr[1]) ifi= =0andj= =1 : curve(pos=[(pos[0]) ,(pos[0] ‚àídr)]) 56 r2 = mag2(dr) if(abs(r2) < Ratom): # to avoid 0 denominator r2 = Ratom invr2 = 1./r2 60 fij =invr2 ‚àófactor ‚àó48.‚àó(invr2 ‚àó‚àó3‚àí0.5) ‚àóinvr2 ‚àó‚àó3 fr[i] = ij ‚àódr+ fr[i] fr[j]=‚àífij‚àódr +fr[j] returnfr 64fortin range (0,1000): Nrhs = 0 # begin 0 each time foriin range (0,Natom): fr = orces(fr) 68 dpos=pos[i] ifdpos[0] <= ‚àíL: pos[i] = [dpos[0]+2 ‚àóL,dpos[1]] # x periodic BC ifdpos[0] >= L: 72 p o s [ i ]=[ d p o s [ 0 ] ‚àí2‚àóL,dpos[1]] ifdpos[1] <= ‚àíL: pos[i] = [dpos[0],dpos[1]+2 ‚àóL] # y periodic BC ifdpos[1] >= L: 76 pos[i] = [dpos[0],dpos[1] ‚àí2‚àóL] dpos=pos[i] ifdpos[0] > 0 anddpos[0] <L : # count at right Nrhs+=1 80 fr2 = orces(fr) fr2 = r v[i] = v[i]+0.5 ‚àóh‚àóh‚àó(fr[i]+fr2[i]) # velocity Verlet pos[i] = pos[i]+h ‚àóv[i]+0.5 ‚àóh‚àóh‚àófr[i] 84 Atom[i].pos = pos[i] # plot new positions inside2.text = ‚Äô percent4s‚Äô percentNrhs #R H S dN.append(Nrhs) # for histogram distribution.plot(data = dN) # plot histogram",1911
Chapter 19 General Relativity. 19.1 Einsteins Field Equations,"408 19 General Relativity This chapter on general relativity (GR) is new for this 4thedition. It‚Äôs here in response to requests, and also in response to recent developments in Einstein lensing, exoplanets, black holes, and computational GR. We review some GR theories, compute some GR tensors, and then apply the theory to the deÔ¨Çection of starlight by stars, to gravitational lensing, to corrections to planetary orbits, and to the visualization of wormholes as seen in movies . Problem GRtellsusthatthespaceweliveiniscurved,notflat,andthatthiscurvatureis theoriginofthegravitationalforce.Yourproblemistodeterminehowmuchofadifference doGReffectsmakeinobservablephenomena. 19.1 Einstein‚Äôs Field Equations Einstein‚Äôs theory of GR postulates that the presence of matter or energy in a region of space distorts the spacetime there. The resulting local curvature of space is the origin of thegravitationalforce,andtherebyprovidesalinkbetweengeometryanddynamics.The theoryisexpressedsuccinctlybythe Einsteinfieldequations ,whichinasimpleformare: [Hartle,2003] Rùúáùúà‚àí1 2Rgùúáùúà+Œõgùúáùúà=ùúÖTùúáùúà, (19.1) wherethestandardistohaveeachtermwithdimensionof1/length2.HeretheR‚Äôs,about which we‚Äôll talk more about soon, describe the curvature of spacetime, gùúáùúàis the metric tensor(‚Äúthemetric‚Äù)thatdescribesthepathlength, Œõisthecosmologicalconstant, Tùúáùúàis theenergy-stresstensor,and ùúÖistheEinstein gravitationalconstant , ùúÖ=8ùúãG c4‚âÉ2.077√ó10‚àí43N‚àí1, (19.2) whereGisNewton‚Äôsgravitationalconstant.Einsteinaddedthe cosmologicalconstant Œõto theoriginalformofhisequationstoexplainauniversethatneithercontractsnorexpands. Itisnowbelievedthat Œõisneededtoexplaintheacceleratingexpansionoftheuniversedue todarkenergyinthevacuumofspace. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 19.1 Einstein‚Äôs Field Equations 409 Tounravel(19.1)abit,westartwiththemetric gùúáùúà,which,bydefininghowtocompute thedistancebetweentwopoints,providesthebasicdescriptionofthelocalspacetime: ds2=g11dx2 1+g12dx1dx2+g22dx2 2+‚Ä¶‚â°gùúáùúàdxùúádxùúà, (19.3) where we have used Einstein‚Äôs convention of summing over repeated upper and lower Greekindices.Asanexample,intheEllisextensionofasphericalpolarcoordinatesmetric, whichwewilluseinSection19.4,thearclengthis ds2=‚àídt2+dùìÅ2+r2(dùúÉ2+sin2ùúÉdùúô2). (19.4) Exercise Determinethemetrictensor gùúáùúàfortheEllismetric. Oncewehaveametricdescribingthearclengthinspace,wecanconnectthatmetricto surfacemeasurementsandcurvatureviathe Christoffelsymbols: Œìùúá ùõºùõΩ=1 2gùúáùúÜ(ùúïgùúÜùõº ùúïxùõΩ+ùúïgùúÜùõΩ ùúïxùõº‚àíùúïgùõºùõΩ ùúïxùúÜ) . (19.5) OncewehavetheChristoffelsymbols,wecancalculatethe RiccicurvaturetensorRùúáùúàand thescalarcurvatureR : Rùúáùúà=ùúïùúàŒìùõº ùúáùõº‚àíùúïùõºŒìùõº ùúáùúà+Œìùõº ùúàùõæŒìùõæ ùúáùõº‚àíŒìùõº ùõºùõæŒìùõæ ùúáùúà, (19.6) R=gùúáùúàRùúáùúà. (19.7) Thestress-energytensor ontheRHSof(19.1)isthesourceofthecurvatureofspacetime, anditarisesfromthepresenceofmatterandenergy.Specifically,thetime-timecomponent ofTùúáùúàistherelativisticenergydensityduetomassandtheEMfield: T00=ùúåE c2+1 c2( 1 2ùúñ0E2+1 2ùúá0B2) . (19.8) TheTkkcomponentsarerelatedtothestressorpressureinthe kdirection,whilethe Tkl componentsarerelatedtoshearstressduetomomentumfluxacrossasurface. Whenallthepiecesareassembled,weseethattheEinsteinfieldequations(19.1),while lookingsimple,areactuallytenindependent,nonlinear,partialdifferentialequations,with 16 functions, two of which appear arbitrary. Except for some simple cases and assumed symmetries,theyaregenerallytoohardtosolveanalytically. Ageodesicistheshortestpathbetweentwopointsinspacetime.Inadditiontothefield equations,akeyelementofGRisthe geodesicequation thatdescribesthemotionofafreely fallingparticleinspacetime: d2xùúá ds2=‚àí Œìùúá ùõºùõΩdxùõº dsdxùõΩ ds, (19.9) wheresisthescalarpropertimeand Œìùúá ùõºùõΩistheChristoffelsymbol.Massiveparticlestravel ontime-likesolutionsofthegeodesicequation(19.9),whilelighttravelsonspace-likesolu- tions.(We‚ÄôllsolvetheequationinSection19.2.)Ofcourse‚Äúfree‚ÄùinGR,whilenotexplicitly includingtheforceofgravity,doesaccountforgravityviathestress-energytensorcausing spacetocurve.Aftertheuseofthechainruleforderivatives,thegeodesicequationcanbe writtenwithanexplicittimecoordinate: d2xùúá dt2=‚àí Œìùúá ùõºùõΩdxùõº dtdxùõΩ dt+Œì0 ùõºùõΩdxùõº dtdxùõΩ dtdxùúá dt. (19.10)",4152
19.1.1 Calculating the Riemann and Ricci Tensors. 19.3 Planetary Orbits in GR Gravity,"410 19 General Relativity This form of the geodesic equation, with its manifest nonlinearity, is the one used for numerical computations. Because d2xùúá‚àïds2is an acceleration, the geodesic equation is analogoustoNewton‚Äôssecondlawofmotion,withtheforcereplacedbythegeometryof spacetime on the RHS. For example, if a test particle‚Äôs velocity is small (nonrelativistic), the terms quadratic and cubic in the velocity can be ignored, and we would be left with Galileo‚Äôshypothesis(althoughhewouldnothaveusedtheseequations)thatallparticles, regardlessofmass,havethesameacceleration: d2xi dt2‚âÉ‚àí Œìi 00,i=1,2,3. (19.11) 19.1.1 Calculating the Riemann and Ricci Tensors Figure19.1showstwofreeparticlesmovingalongthetwoinfinitesimallyclosegeodesics xa(ùúè)andxb(ùúè).Weconsidertheparticleon xaasareferenceparticlewith uùúá=dxùúá‚àïdùúèits 4-velocity.The xaandxbtrajectoriesstartoffparallelattime ùúè=0andareconnectedbythe vectorn(ùúè): xa=xb+nùõº(ùúè). (19.12) Forzerorelativeaccelerationoftheparticles,thegeodesicsremainparallel,andso: d2n dùúè2=0. (19.13) Thisderivativeactsonthebasisvectors,whichinturnrequiresknowledgeoftheChristoffel symbols: ( d2n dùúè2)ùõº =(ùúïùúéŒìùõº ùúáùúà‚àíùúïùúàŒìùõº ùúáùúé+Œìùõº ùúéùõæŒìùõæ ùúáùúà‚àíŒìùõº ùúàùõæŒìùõæ ùúáùúé)uùúéuùúáuùúà. (19.14) We recognize the quantity in parenthesis as the uncontracted version of the Riemann tensor: Rùõº ùúáùúàùúé=ùúïùúéŒìùõº ùúáùúà‚àíùúïùúàŒìùõº ùúáùúé+Œìùõº ùúéùõæŒìùõæ ùúáùúà‚àíŒìùõº ùúàùõæŒìùõæ ùúáùúé. (19.15) 19.1.2 Riemann and Ricci Tensor Problems TheSchwarzschildmetric, ds2=( 1‚àí2GM c2r) c2dt2‚àí( 1‚àí2GM c2r)‚àí1 dr2‚àír2(dùúÉ2+sin2ùúÉdùúô2), (19.16) t xn(œÑ) œÑxb(œÑ) xa(œÑ) œÑ = 0Figure 19.1 Two free particles move along the inÔ¨Ånitesimally close geodesics xa(ùúè)andxb(ùúè). The particles start off parallel at timeùúè=0 and are connected by the vector n(ùúè). 19.1 Einstein‚Äôs Field Equations 411 permitsasolutionoftheEinsteinequationforasphericallysymmetricgeometrywithzero cosmologicalconstant Œõ,andnomatterpresentso Tùúáùúà=0.Thefollowingproblemscanbe solvedwithvariationsoftheonesamecode.Ourcode Ricci.pyinListings19.1mayhelp. 1) Create four matrices representing the Christoffel symbols, Œì0 ùúáùúà,Œìr ùúáùúà,ŒìùúÉ ùúáùúà,Œìùúô ùúáùúà,a n d use SymPyor some other symbolic manipulation program to evaluate them for the Schwarzschildmetric. 2) Use SymPytoevaluatetheRiemanntensor, Rùõº ùúáùúàùúé,fortheSchwarzschildmetric. 3) Use SymPytoextracttheRiccicurvaturetensor,whichisdefinedasthecontraction RùúÜùúá‚â°Rùõº ùúÜùõºùúá. (19.17) 4) TheRicciscalargivesasinglenumericalmeasureofthecurvatureateachpointinspace- time.Ifaspacetimeisflat,then R=0,andinitiallyparallelgeodesicsremainsointime. Ifaspacetimeiscurved,then R‚â†0.Use SymPytoextracttheRicciscalarfromtheRicci curvaturetensor: R=gùúáùúÖRùúáùúÖ. (19.18) 19.1.3 Event Horizons The curvatureofspacetimeandthespeedoflightcreateboundariesinspacebeyondwhich events cannot be observed. These are called eventhorizons and are important near black holes.LookagainattheSchwarzschildmetric(19.16),andimagineobservingeventssimul- taneouslyatoneinstantoftimesothat dt=0.Theproperdistance,aswouldbemeasured byputtingdownmetersticks,wouldthenbethespace-likedistance: ‚àíds2=( 1‚àí2GM c2r)‚àí1 dr2‚àír2dùúÉ2, (19.19) wher ew eha v eleftoffthe ùúôdependence.Thisequationleadstotheconclusionthatdis- tances,somehow,becomesingularattheSchwarzschildradius rs: rh=rsdef=2GM c2. (19.20) This is the event horizon. Although this singularity is a peculiarity of the Schwarzschild metric,physicalblackholesarebelievedtohaveeventhorizons. Problem Calculate numerical values for the event horizonsaround the earth, the sun, andablackhole. Blackholestendtorotate,andsothespacetimenearonewithangularmomentum Jismore appropriatelydescribedbytheKerrmetric[Kerr,1963].Formotionintheequatorialplane (noùúôvariation),theKerrmetricis: ds2=‚àí( 1‚àírsr Œ£) c2dt2+Œ£ Œîdr2+Œ£dùúÉ2, (19.21) Œ£=r2+a2cos2ùúÉ,Œî=r2‚àírsr+a2,a=J Mc. (19.22) Again,wedeterminethehorizonradius rhbysolvingforthe rvalueatwhichthedistance becomessingular: Œî=0‚áírh=rs¬±‚àö r2 s‚àí4a2 2. (19.23) 412 19 General Relativity Forrealrh,thislimitstheangularmomentumoftheblackholeto J‚â§GM2 c. (19.24) ThefulldeterminationoftheequationsofmotionforaparticlenearaKerrmetricblack holeisa significantendeavor,andwesuggest [HancandTaylor,2004]and[Gould etal., 2006]forthederivation. 19.2 Gravitational DeÔ¨Çection of Light Aswehavesaidbefore,a geodesicistheshortestpathbetweentwopointsinspacetime.GR assumesthatlighttravelsonspace-likegeodesics,whilemassiveparticlestravelontime- like geodesics. The geodesic path is the solution of the geodesic equation (introduced in Section19.1): d2xùõΩ dùúÜ2+ŒìùõΩ ùúáùúàdxùúá dùúÜdxùúà dùúÜ=0. (19.25) Weleavetheapplicationofthisequationfromfirstprinciplestothereferencesandfocus insteadonwhat‚Äôsbeenderivedfromit. OneoftheearlytestsofGRwasthepredictionfortheangleofdeflection ùúôoflightstart- ing at an impact parameter b=Rrelative to the sun‚Äôs center and just grazing the sun‚Äôs surface (Figure 19.2). Newtonian mechanics solved this problem by calculating the orbit of a massive particle around the sun, and then taking the m‚Üí0 limit for the particle. Thisyielded ùúô=2GM Rc2, (19.26) whereGisthegravitationalconstant, Misthemassofthesun,and Ristheradiusofthesun. Later,Einsteinianmechanicswasusedtosolvethegeodesicequation(19.9)approximately, andobtainedtwiceaslargeavalue, ùúô‚âÉ4GM Rc2. (19.27) ThisagreedwithmeasurementsandhelpedtoestablishthevalidityofGR. Nowlet‚Äôstrytocalculatesomenumericalvaluesforthedeflection.In1916,Schwarzschild foundanexactsolutionoftheEinsteinianequationsusing(whatelse?)theSchwarzschild metric(19.16).Forthismetricandforlightjustgrazingthesun( b=R),theorbitequation takesthesimpleform[Moore,2013]: ( 1 rdr dùúô)2 =( 1‚àí2M R)1 R2‚àí( 1‚àí2M r)1 r2. (19.28) RbœïFigure 19.2 A light ray being bent by an angle ùúôdue to the gravitational effect of the sun. 19.2 Gravitational DeÔ¨Çection of Light 413 Achangeofvariableto u=R‚àïrproducesthenumericallymorerobustequation: ( du dùúô)2 =1‚àíu2‚àí2M R(1‚àíu3). (19.29) 1) Verifythatanapproximatesolutionto(19.29)is ùúô‚âÉ4GM Rc2. (19.30) 2) Evaluatethisexpressiontodetermineanumericalvaluefortheangleofdeflectionfor lightgrazingthesun‚Äôssurface(hint:It‚Äôssmall).Useparameters M=2√ó1023g,R=7√ó 1010cm,andG‚àïc2=7.4√ó10‚àí29cm/g. 3) AlthoughtheODE(19.29)isnonlinear,that‚Äôsnotaproblemforanumericalsolution. Solve (19.29) numerically and compare your result with the value obtained from the approximateanalyticexpression. 19.2.1 Gravitational Lensing In adifferentapproachtothedeflectionofalightduetoaverymassivestar,Moore[2013] assumes a Schwarzschild spacetime to describe the curved space outside of a spherically symmetricgravitationalsource(astar).Intermsoftheinversevariable u=1‚àïr,thegeodesic equationisnow d2u dùúô2=3GMu2‚àíu. (19.31) 1) Modify your ODE solver to solve this equation. Employ units such that mass is measuredinmeters, GM=1477.1m,and M=28M‚äô(M‚äôisasolarmass).Ourprogram LensGravity.py isgiveninListing19.2. 2) Equation(19.31)isquitesensitivetotheinitialconditions.Assumethatinitiallythelight isverydistant,say r‚âÉ106,andu(ùúô=0)=du(ùúô)‚àïdùúô=10‚àí6. 3) Convert your solution for r(ùúô)into one for (x,y), and plot the photons‚Äô paths for 0‚â§ùúô‚â§ùúã.OurplotsareshownontheleftofFigure19.3. SunSource ‚Äì3 ‚Äì1.00 ‚Äì0.75 ‚Äì0.50 ‚Äì0.25 0.00 0.25 0.50 0.75 1.00‚Äì2‚Äì10y x123Gravitational lensing (cross section) O  O O Figure 19.3 Left: Three trajectories showing the bending of light rays caused by the sun‚Äôs mass. Note, the three images on the right would be seen as an Einstein ring. Right: A James Webb Telescope image showing an Einstein ring.",7265
19.3.1 Newtons Potential Corrected. 19.3.2 Orbit Computation via Energy Conservation,"414 19 General Relativity 4) Employthesymmetryofthisproblemtorotateyoursolutionaboutthe x=0axisand thuscreateanEinsteinring.Thisiswhatanobserverseeswhenviewingadistantlight sourcelyingbehindamassivestarandfocusingonapointsource(Figure19.3right). 19.3 Planetary Orbits in GR Gravity 19.3.1 Newton‚Äôs Potential Corrected The classical solution of Newton‚Äôs laws, including his gravitational potential, is just fine formosteverythinghereonorneartheearth.However,therearecorrectionsarisingfrom GR,andwhilesmall,thesecorrectionsareactuallycriticaltotheaccuracyofmodernGPS devices.TheusualapproachistodetermineanODEwithaGRcorrectiontothefamiliar 1‚àïrgravitational potential, and then to solve the ODE. We follow [Hartle, 2003; Moore, 2013;James etal.,2015],whoassumetheSchwarzschildmetric(19.16),andshowthatan effectivepotentialforthismetricis: Veff(r)=‚àíGM r+ùìÅ2 2r2‚àíGMùìÅ2 r3. (19.32) HereGisthegravitationalconstant, ùìÅistheangularmomentumperunitrestmass, Mis themassofthestar,andthemiddletermistheusualangularmomentumbarrier.Wesee that (19.32) differs from the Newtonian potential by a ‚àíGMùìÅ2‚àïr3term that, in addition totheusual ‚àíGM‚àïrattraction,providesanadditionalstrongattractionatshortdistances. We obtain a dimensionless, and simpler-to-compute, form of the potential by changing variables: Veff(r‚Ä≤)=‚àíG r‚Ä≤+ùìÅ‚Ä≤2 2r‚Ä≤2‚àíGùìÅ‚Ä≤2 r‚Ä≤3r‚Ä≤=r M,ùìÅ‚Ä≤=ùìÅ M. (19.33) 1) PlotVeff(r‚Ä≤)versusr‚Ä≤forùìÅ=4.3(likeFigure19.4). 2) Describeinwordshowtheorbitswithinthispotentialchangewithenergy. 3) Atwhatvaluesof r‚Ä≤doestheeffectivepotentialhaveamaximumandaminimum? 4) At what value of r‚Ä≤does a circular orbit exist? (Hint: the small circles in Figure 19.4 correspondtocircularorbits.) 5) Determinetherangeof r‚Ä≤valuesthatoccurfor ùìÅ=4.3. 6) Indicatetheaboverangeonyourplotbyahorizontalline,anddescribetheorbits. 7) Describetheorbitsforenergiescorrespondingtothemaximuminthepotential. 19.3.2 Orbit Computation via Energy Conservation A fairlysimplewaytodeterminetheorbitsofmassiveparticlesintheeffectivepotential (19.33)derivesfromenergyconservation.Itstartswiththeenergyperunitmassexpressed asthesumofkineticandpotentialterms: E=1 2( dr dùúô)2ùìÅ2 r4‚àíGM r+ùìÅ2 2r2‚àíGMùìÅ2 r3, (19.34) whereùúôisthepolarangle.WeobtainanODEfortheorbitbydifferentiatingbothsidesof theequationwithrespectto ùúô: d2r dùúô2=‚àíGM r2+ùìÅ2 r3‚àí3GMùìÅ2 r4, (19.35) 19.3 Planetary Orbits in GR Gravity 415 5‚Äì0.04‚Äì0.02Vr (r') 0.000.02NewtonianRelativistic and Newton potential 0.04 10 15 20 r/M25 30 35 40 Figure 19.4 Relativistic and Newtonian potentials for ùìÅ‚àïM=4.3. The two dots correspond to radii for circular orbits. whereacommon dr‚àïdùúôfactorhasbeencanceledout.TheODEissimplifiedbyachange ofvariablesto: d2u dùúô2=‚àíu+GM ùìÅ2+3GMu2,u‚Ä≤=M r,ùìÅ‚Ä≤=ùìÅ M. (19.36) AswithNewtonianorbits,theenergyandangularmomentumofthesystemdeterminethe orbitcharacteristics.Weusedtheenergyintegral(19.34)todeterminetheinitialconditions fortheODE,andthensolvedfor du‚Ä≤‚àïdùúô: du‚Ä≤ dùúô=‚àö 2E ùìÅ‚Ä≤2+2Gu‚Ä≤ ùìÅ‚Ä≤2‚àíu‚Ä≤2+2Gu‚Ä≤3. (19.37) 1) UseyourODEsolvertoexplorenumericallyandgraphicallyvariousorbitscorrespond- ing to various initial conditions and energies. Our program, RelOrbits.py is in Listing 19.3.Introducesomesignalsintoyourfiguressothatyoucantellthedirectionoftravel (orproduceatimeseriesofgraphs). (a) SetupyourODEsolverappropriatelyfor(19.37)using G=1. (b) Chooseanenergycorrespondingtothemaximumoftheeffectivepotentialandcom- puteyourversionofFigure19.4.Pickaninitial rvalueatwhichthepotentialisa maximum.Asyoumayhavededuced,thisshouldleadtoanunstableorbit,suchas ontheleftofFigure19.5. (c) Seeifyoucanfindinitialconditionsthatleadtoacircularorbit.Isitstable? (d) Investigatetheeffectofgraduallydecreasingtheangularmomentum. (e) Chooseanenergythatcorrespondstotheminimumintheeffectivepotentialand plot nearby orbits. Examine the sensitivity of these orbits to the choice of initial conditions.",3771
19.3.3 Precession of the Perihelion of Mercury,"416 19 General Relativity ‚Äì20 ‚Äì10 0 10 20‚Äì5 ‚Äì5 00510152020 10 0 ‚Äì10 ‚Äì2025 51 0 x/M x/M y/My/M 15 20 25 Figure 19.5 Left: An orbit corresponding to an energy at the maximum of the effective potential. Right: A rapidly precessing orbit. (f) Determinetheenergyandinitialconditionsthatproduceaprecessingperihelion, suchastheoneseenontherightofFigure19.5.Inthiscase,themassiveparticle movesbetweentwoturningpoints,asshownbythehorizontallineinthepotential wellinFigure19.4. (g) Examinetheorbitsthatoccurifaparticleisboundbytheinnerstrongattraction. Cansuchaparticlestartatinfinityandbecaptured? 19.3.3 Precession of the Perihelion of Mercury Planets follownearlyperfectellipsesaroundthesun,withtheirmajoraxesrotatingvery slowly,asshowninFigure19.6.Asviewedfromthesun,theprecessionofMercuryis9.55 minutes of arc per century [min =(1/60)thof a degree]. Mercury is the fastest of all the planets,andsoitsprecessionisthelargest.Allbutabout0.01ofadegreeoftheprecession canbeexplainedwithNewtonianmechanicsasperturbationsduetotheotherplanets.This leavesasmallmystery.Thecalculationofthiscorrectiontoasmallcorrectionwasoneof theimportantearlysuccessesofGR.Inthissection,wepresentafirst-principlescalculation ofthatprecessionduetoG.He. The Schwarzschild metric with zero cosmological constant Œõdescribes a spacetime appropriate to a spherically symmetric geometry surrounding a mass Mwith no other matterpresent( Tùúáùúà=0).Aswenowwanttouseactualmassandorbitalvalues,werewrite themetric(19.16)as ds2=( 1‚àírs r) dt2‚àí1 1‚àírs‚àïrdr2‚àír2dùúÉ2‚àír2sin2ùúÉdùúô2, (19.38) rsdef=2GM. (19.39) Atime-liketrajectoryisasolutiontothegeodesicequationforamassiveparticle.If ùúèisthe propertime,atime-liketrajectoryisdescribedby dùúè2=gùúáùúàdxùúádxùúà. (19.40) 19.3 Planetary Orbits in GR Gravity 417 SunMercury at perihelion Mercury‚Äôs orbitPrecession Figure 19.6 An artist‚Äôs perception of the precession of the perihelion of Hg (www .astronomicalreturns.com/2020/05/the-mystery-of-mercurys-missing). Foraplanarorbitwith ùúÉ=ùúã‚àï2,thisleadsto ( dùúè dt)2 =( 1‚àírs r) ‚àíÃár2 1‚àírs‚àïr‚àír2Ãáùúô2. (19.41) Wewantanequationrelatingdistanceandangle.Thederivativescanberewritteninterms oftheconstantsofthemotion, dùúè dt=1 e( 1‚àírs r) ,dùúô dt=L er2( 1‚àírs r) , (19.42) whereL=Rùë£‚àïcis the angular momentum per unit mass, ùë£is the linear velocity at the apoapsis,and eistheenergyperunitmass.Substitutionleadstothedifferentialequation ( dr dt)2 =1 e2( 1‚àírs r)2[ (e2‚àí1)+rs r‚àíL2 r2+L2rs r3] . (19.43) Useofthechainrule, dr dt=dr dùúôdùúô dt(19.44) leadstothedesireddifferentialequationrelatingdistanceandangle: ( dr dùúô)2 =r4 L2[( 1‚àírs R)( 1+L2 R2) ‚àí( 1‚àírs r)( 1+L2 r2)] , (19.45) Note that the mass of Mercury does not enter into the calculation, although its distance fromthesundoes.ThisisthesameaswhathappenswithNewton‚Äôslaws, mMG r2=ma‚Üía=Mg r2, (19.46) wherethem‚Äôscancelout.",2780
19.4 Visualizing Wormholes,"418 19 General Relativity Although(19.45)canbesolvedasitstands,thelargedifferencesinparametervalueslead to numerical inaccuracies, and it is better to solve for the inverse distance u=R‚àïr.T h i s leadstothequadraticequation: ( du dùúô)2 =rs R(u‚àí1)(u‚àíu+)(u‚àíu‚àí), (19.47) u¬±=‚àíb¬±‚àö b2‚àí4ac 2a,a=rs R,b=a‚àí1,c=b+Rrs L2. 1) Showthattheperihelionprecessionperrevolutioncanbewrittenas Œîùúô=2‚àö R rs‚à´u‚àí 1du‚àö (u‚àíu+)(u‚àíu‚àí)(u‚àí1)‚àí2ùúã. (19.48) 2) Compute ŒîùúôandcompareittoLandauandLifshitz[1971]‚Äôsvalueof5.02 √ó10‚àí7.Here aresomeapoapsisnumericalvalues: rs=2950m,ra=69.82√ó109m,rp=46.00√ó109m. (19.49) Thecode PrecessHg.py ,writtenbyG.Heisgivenonline. 19.4 Visualizing Wormholes Problem Create imagesofawormholeofthetypeseeninthemovie Interstellar .(Asan alternative,youcanreproducesomeofthevisualizationsfoundonlineinRoman[1994].) Even better wouldbe the creation ofvisualizationsoftravelthrough a wormhole[Nolan andNolan,2015]. DuringChristopherNolan‚Äôsdirectionofthesciencefictionmovie Interstellar ,KipThorne (a 2017 Noble laureate for GR) helped develop visualizations of rocket flight based on Einstein‚Äôs field equations. The key element of the movie was that interstellar travel was possible in a single human lifetime if a spaceship passed through a wormhole(an Einstein-Rosen bridge ). This wormhole would be a tunnel-like structure that connects onelocationinspacetimetoanother,orpossiblytoanotheruniverse[James etal.,2015]. Figure19.7isavisualizationofsuchawormhole. Althoughactualwormholeshaveneverbeenobserved,speculationisthattheymayoccur asquantumfluctuationsoverdistancesonthePlanckscale,‚àö H‚Ñè‚àïc3‚àº10‚àí35m(10‚àí20of thesizeofaproton).Furtherspeculationsimaginethatthesizeofthewormholemightbe enlargedtomacroscopicsizeifthereweresometypeofexoticmatterwithnegativeenergy densityatthethroatofthewormhole.Thismightpermitarocketshiptopassthroughit [Roman,1994]. However,ifour4Duniverseresidedinahigher-dimensionalspace(calleda bulk),such asthe5-Doneimaginedin Interstellar ,thentheremightnotbetheneedforexoticmatter to hold open the wormhole. In any case, while unlikely, interstellar travel is not strictly forbidden(itissciencefictionafterall).Actually,asanexerciseinGR,MorrisandThorne [1988]discussthefundamentalsofspacetravelusingwormholes. The equationsthat Thorneused to create the visualizationswere expressed in units in whichG=1,c=1,andtimeismeasuredinlength1s =c√ó1s=2.998√ó108m.Massis 19.4 Visualizing Wormholes 419 Figure 19.7 The Ellis wormhole connecting upper and lower (Ô¨Çatter) spaces. Note that this visualization has the wormhole‚Äôs 4D bulk embedded within a 3D space. The throat diameter is 2 ùúå,and the proper distance traveled in a radial direction is ùìÅ. 2œÅ ‚Ñìr œÜ measured in length, 1kg =G‚àïc2√ó1kg,sothat1kg =0.742√ó10‚àí27m, in which case the sun‚Äôsmassequals1.476km.Thecreatedwormholeconnectstwoflat3Dspacesplacedat theendsofa4Dcylinder.The4Dcylinderisoflength2 a,withcrosssectionsthatarespheres ofradius ùúå.Inordertovisualizethe4Dwormhole,itisembeddedina3Dspace,inwhich casethecrosssectionsarecirclesofradius ùúå(Figure19.7). ThorneusedtheEllisextensionofasphericalpolarcoordinatemetric: ds2=‚àídt2+dùìÅ2+r2(dùúÉ2+sin2ùúÉdùúô2). (19.50) Here,theradiuscoordinate risafunctionof ùìÅ,andthephysicaldistance(properdistance) traveledinaradialdirection: r(ùìÅ)=‚àö ùúå2+ùìÅ2, (19.51) whereùúåistheradiusofthethroatofthecylindricalwormhole.Notethatthetimecoordinate tentersthemetric(19.50)withanegativesign.Thismeansthatforfixed ùìÅ,ùúÉ,andùúô,the timetincreasesinthetimelikedirection.Accordingly, tisthepropertimeasmeasuredby apersonatrestinthespatial (ùìÅ,ùúÉ,ùúô)coordinatesystem. Becauser2(dùúÉ2+sin2ùúÉdùúô2)is the familiarmetricdescribingthe surface of a sphereof radiusr, the created wormhole is spherically symmetric. This means that, as ùìÅ‚Üí¬±‚àû, theradiusofthespherewithinthewormholeapproachestheproperdistance ùìÅ.Thisalso meansthatas ùìÅ‚Üí¬±‚àû,wewouldhavetwoseparateflatspacesconnectedbytheworm- hole.Inthemovie,thetransitionbetweenthetwoflatspacesviathewormhole‚Äôsthroatis made to resemble the transition to an external space in which a nonspinning black hole resides.ThisisdescribedbytheSchwarzschildorholemetric[James etal.,2015]: ds2=‚àí( 1‚àí2Óàπ r) dr2+dr2 1‚àí2Óàπ‚àïr+r2(dùúÉ2+sin2ùúÉdùúô2), (19.52) where Óàπistheblackhole‚Äôsmass.Withthismetric,theradius rbecomestheoutwardcoor- dinateratherthantheproperdistance ùìÅ.Thevisualizationsinthemovierequiredasolution forr(ùìÅ), that is, a solution or an expression for the outward coordinate as a function of properdistance.Toreducetheeffortinvolved,thevisualizationsusedananalyticexpression forr(ùìÅ)outsidethewormhole‚ÄôscylindricalinteriorthatissimilartotheSchwarzschild r(ùìÅ): r=ùúå+2 ùúã‚à´|ùìÅ|‚àía 0arctan(2ùúâ ùúãÓàπ) dùúâ (19.53) =ùúå+Óàπ[ xarctanx‚àí1 2ln(1+x2)] ,for|ùìÅ|>a. (19.54) Forcylindricalcoordinates,the zcoordinateistheheightabovethewormhole‚Äôsmidplane intheembeddingspace,andsotheembeddingspacemetricbecomes ds2=dz2+dr2+r2dùúô2. (19.55)",4795
19.5 Problems. 19.6 Code Listings,"420 19 General Relativity Inthiscase,thespatialmetricofthewormhole‚Äôs2Dequatorialsurfaceis: ds2=dùìÅ2+r2(ùìÅ)dùúô2. (19.56) Combiningtheseequationsletsussolvefor z(ùìÅ): dùìÅ2=dz2+dr2, (19.57) z(ùìÅ)=‚à´ùìÅ 0‚àö 1‚àí(dr‚àïdùìÅ‚Ä≤)2dùìÅ‚Ä≤. (19.58) One obtains the equations needed to visualize the wormhole by substituting (19.53) and (19.54)into(19.58). 19.5 Problems 1) Inordertoapply(19.58),weneedtoevaluatethederivative dr‚àïdùìÅ.UsePython‚Äôssym- bolicalgebrapackage SymPytoshowthat dr dùìÅ=2 ùúãarctan2ùìÅ‚àía ùúãÓàπ. (19.59) Ourprogram WormHole.py inListing19.4evaluatesthisderivative. 2) Insertthis dr‚àïdùìÅinto(19.58)andevaluatethe z(ùìÅ)integralnumericallyfor ùúå=1,a=1,Óàπ=0.5. (19.60) 3) ThecontourlinesorringsshowninFigure19.7correspondtodifferentvaluesof ùìÅ.They wereobtainedwiththeprogram VisualWorm.ipynb inListing19.5. 4) Makeyourownplotofthewormholefor ùìÅ=1,¬∑¬∑¬∑,11. 5) Create a cylindrical wormhole of length 2 Lwith a spherical cross section of radius ùúå. Visualizethewormholewitha3Dembeddingdiagraminwhichthemissingdimension resultsinthecrosssectionsappearingascirclesratherthanspheres.Followthesame stepsasusedfortheElliswormhole,(19.50),butnowwith r(ùìÅ)={ùúå |ùìÅ|‚â§L(Wormholeinterior) |ùìÅ|‚àíL+ùúå,|ùìÅ|‚â•L(Wormholeexterior) .(19.61) 19.6 Code Listings Listing 19.1 Ricci.py uses SymPy to compute the Riemann and Ricci tensors and the Ricciscalar. # Ricci .py: Riemann & Ricci tensors , Ricci scalar , uses Sympy 2 fromsympyimport ‚àó#symbolic python importnumpy as np 6t,r,th, fi , rg = symbols( ‚Äôt r th fi rg‚Äô ) # Schwarzchild metric print(\""contravariant\"" ) # Upper indices # Inverse matrix 10gT = Matrix([[1/( ‚àí1 + rg/r),0,0,0], [0, 1 ‚àírg/r, 0,0], [0, 0, r ‚àó‚àó(‚àí2), 0],[0, 0, 0, 1/(r ‚àó‚àó2‚àósin(th) ‚àó‚àó2)]]) 19.6 Code Listings 421 #4‚àíD array for alpha , beta , m u, nu Ri = [[[[[] fornin range (4)]forain range (4)]forbin range (4)]forcin range(4)] 14RT = [[[] formin range (4)]forpin range (4)] # Ricci tensor # Christoffel symbols, upper t , r , theta , and phi Cht = Matrix([[0, 0.5 ‚àórg/(r ‚àó(r‚àírg)), 0, 0], 18[0.5‚àórg/(r ‚àó(r‚àír g ) ) ,0 ,0 ,0 ] ,[ 0 ,0 ,0 ,0 ] ,[ 0 ,0 ,0 ,0 ] ] ) Chr = Matrix([[0.5 ‚àórg‚àó(r‚àírg)/r ‚àó‚àó3,0,0,0], [0, ‚àí0.5‚àórg/(r ‚àó(r‚àírg)),0,0], [0,0,‚àí1.0‚àór+1 . 0 ‚àórg, 0], [0,0,0, ( ‚àí1.0‚àór+r g ) ‚àósin(th) ‚àó‚àó2]]) Chth = Matrix([[0, 0, 0, 0], [0, 0, 1.0/r, 0], [0, 1.0/r, 0, 0], 22 [0, 0, 0, ‚àí0.5‚àósin(2 ‚àóth)]]) Chfi = Matrix([[0, 0, 0, 0], [0, 0, 0, 1.0/r], [0, 0, 0, 1.0/tan(th)], [0, 1.0/r, 1.0/tan(th), 0]]) foralphain range (0,4): # Upper index in Christoffel 26ifalpha == 0: Chalp = Cht elifalpha == 1: Chalp = Chr elifalpha == 2: Chalp = Chth else:C h a l p = C h f i 30forbein range (0,4): #B e t a formuin range (0,4): ifmu == 0: der2 = t # Derivative elifmu == 1: der2 = r 34 elifmu == 2: der2 = th elifmu == 3: der2 = fi fornuin range (0,4): ifnu == 0: der1 = t # Other derivative 38 elifnu == 1: der1 = r elifnu == 2: der1 = th elifnu == 3: der1 = fi a1 = diff(Chalp[be,nu],der2) # Christoffel symbol 42 a2 = diff(Chalp[be,mu],der1) # A n d derivative sump = 0 sumn = 0 forgamin[t,r,th,fi]: 46 ifgam == t : Chgam = Cht gama = 0 elifgam == r: 50 Chgam = Chr gama = 1 elifgam == th: Chgam = Chth 54 gama = 2 elifgam == fi : Chgam = Chfi gama = 3 58 sump = sump+Chalp[mu,gama] ‚àóChgam[be,nu] sumn = sumn+Chalp[nu,gama] ‚àóChgam[be,mu] R = simplify(a1 ‚àía2+sump ‚àísumn) # Riemann tensor ifR= =0 : # Print nonzero components 62 Ri[alpha][be][mu][nu] = 0 else: Ri[alpha][be][mu][nu] = R print(\""Ri[\"",alpha, \""][\"",be,\""][\"",mu,\""][\"",nu,\"" ]=\"", Ri[alpha][be][mu][nu]) 66print(\"" \"") print(\""Ricci Tensor \"" ) forroin range (0,4): fordein range (0,4): 70 sum=0 foralpin range (0,4): sum=sum+Ri[alp][ro][alp][de] RT[ro][de] = simplify( sum) 74 print(\""RT[\"",ro,\""][\"",de,\""] = \"",RT[ro][de]) # Ricci ‚Äôs tensor sumR = 0 # Ricci Scalar forbein range (0,4): fornuin range (0,4): sumR = sumR+gT[be,nu] ‚àóRT[be][nu] 78print(sumR) RS = (sumR) print(\""RS\"",RS) # Ricci Scalar R 422 19 General Relativity Listing 19.2 LensGravity.py ComputethedeflectionoflightbythesunwithMatplotlib. # LensGravity.py: Deflection of light by the sun wi Matplotlib 2 importnumpy as np importmatplotlib.pyplot as plt 6y=n p .z e r o s( ( 2 ), float) ph = np.zeros((181), float) #T i m e yy = np.zeros((181), float) xx = np.zeros((181), float) 10rx = np.zeros((181), float) ry = np.zeros((181), float) Gsun = 4477.1 # Meters , sum massxG GM= 28. ‚àóGsun 14y [ 0 ]=1 . e ‚àí6; y[1] = 1e ‚àí6 # Initial condition u=1/r deff(t,y): #R H S , c a nm o d i f y rhs = np.zeros((2), float) 18rhs[0] = y[1] rhs[1] = 3 ‚àóGM‚àó(y[0] ‚àó‚àó2)‚àíy[0] returnrhs defrk4Algor(t, h, N, y, f): #D on o tm o d i f y 22k1=np.zeros(N); k2=np.zeros(N); k3=np.zeros(N); k4=np.zeros(N) k1 = h ‚àóf(t,y) k2 = h ‚àóf(t+ h/2.,y+k1/2.) k3= h ‚àóf(t+ h/2.,y+k2/2.) 26k4= h ‚àóf(t+ h,y+k3) y=y + ( k 1 + 2 ‚àó(k2+k3)+k4)/6. returny 30f(0,y) # Initial conditions dphi = np.pi/180. # 180 phi values i=0 # counter forphiinnp.arange(0,np.pi+dphi,dphi): 34ph[i] = phi y = rk4Algor(phi,dphi,2,y,f) #C a l lr k 4 xx[i] = np.cos(phi)/y[0]/1000000 # Scale for graph yy[i] = np.sin(phi)/y[0]/1000000 38i=i+1 m= (yy[180] ‚àíyy[165])/(xx[180] ‚àíxx[165]) #S l o p e b = yy[180] ‚àím‚àóxx[180] # Intercept j=0 42forphiinnp.arange(0,np.pi+dphi,dphi): ry[j] =m ‚àóxx[j]+b # Straight line eqtn j=j + 1 plt.figure(figsize=(12,6)) 46plt.plot(xx,yy) # Light trajectory plt.plot(xx, ‚àíyy) # Symmetric for negative y plt.plot(0,0, ‚Äôro‚Äô) # Mass at origin plt.plot(0.98,0, ‚Äôbo‚Äô) # Source 50plt.plot(0.98,1.91, ‚Äôgo‚Äô) # Position source seen from O plt.plot(0.98, ‚àí1.91, ‚Äôgo‚Äô) plt.text(1,0, ‚ÄôS‚Äô) plt.text( ‚àí1.04,‚àí0.02, ‚ÄôO‚Äô) 54plt.text(1.02, 1.91, \""S‚Äô \"") plt.text(1.02, ‚àí2,\""S‚Äô‚Äô\"") plt.plot([0],[3.]) # Invisible poin plt.plot([0],[ ‚àí3.]) # Invisible point at ‚àíy 58plt.plot(xx,ry) # Upper straight plt.plot(xx, ‚àíry) # Lower straight line plt.xlabel( ‚Äôx‚Äô) plt.ylabel( ‚Äôy‚Äô) 62plt .show() 19.6 Code Listings 423 Listing 19.3 RelOrbits.py computesrelativisticandNewtonianpotentialsandorbits. # RelOrbits.py Reltv orbits in a gravitational potential , needs rk4 importmatplotlib.pyplot as plt 4importnumpy as np dh = 0.03 dt = dh 8ell = 4.3 #i se l / M G=1 . 0 N=2 E=‚àí0.028 12phi = np.zeros((7000), float) rr = np.zeros((7000), float) y=n p .z e r o s( ( 2 ), float) y[0] = 0.0692 16y[1] = np.sqrt(2 ‚àóE/ell ‚àó‚àó2+2 ‚àóG‚àóy[0]/ell ‚àó‚àó2‚àíG‚àóy[0]‚àó‚àó2+2‚àóG‚àóy[0] ‚àó‚àó3) deff(t,y): rhs = np.zeros(2) 20rhs[0] = y[1] rhs[1] = ‚àíy[0]+G/ell ‚àó‚àó2+ 3 ‚àóG‚àóy[0]‚àó‚àó2 returnrhs 24f(0,y) i=0 forfiinnp.arange(0,12.0 ‚àónp.pi ,dt): y=r k 4 ( f i, d t, N , y ,f ) 28rr[i] = (1/y[0]) ‚àónp.sin( fi ) # Note u = 1/r phi[i] = (1/y[0]) ‚àónp.cos( fi ) i=i + 1 f1 = plt.figure() 32plt.axes().set_aspect( ‚Äôequal‚Äô) # Equal aspect ratio plt.plot(phi[:900],rr[:900]) plt .show() Listing 19.4 WormHole.py computes the derivatives needed to construct the Ellis wormholeconnectinganupperandlowerspace. # W o r m H o l e.py: S y m p y evaluation of derivative for Ellis W o r m h o l e fromsympyimport ‚àó 4L, x, M, rho, a, r, I ,lp= symbols( ‚Äô LxMr h oarIl p ‚Äô ) x=( 2 ‚àóL‚àía)/(pi ‚àóM) r=r h o + M ‚àó(x‚àóatan(x) ‚àílog(1+x ‚àóx)/2) p = diff(r,L) 8print(p) print(\""hola\"") n = simplify(p) print(n) 12v = integrate(sqrt(1 ‚àín‚àón),(L,0,lp)) print(\""integral\"" ,v) # Result : 2 ‚àóatan((2 ‚àóL‚àía)/(pi ‚àóM) ) / p i Listing 19.5 VisualWorm.ipynb visualizes the Ellis wormhole using Vpython in a Jupyternotebook. # VisualWorm . ipynb fromvpython import ‚àó 4escene = canvas(width=400,height=400, range= 15) importnumpy as np importmath 424 19 General Relativity 8a=1 # 2a = height inner cylinder ring(pos=vector(0,0,0),radius=1,axis=vector(0,1,0),color=color.yellow) deff(x): # function to be integrated M=0.5 #b l a c kh o l em a s s 12a=1 # 2a: cylinders height y=n p .s q r t ( 1 ‚àí(2‚àónp.arctan(2 ‚àó(x‚àía)/(np.pi ‚àóM))/np. pi) ‚àó‚àó2) returny 16deftrapezoid(Func,A,B,N): h=( B ‚àíA)/(N ) # step , A: initial , B:end sum= (Func(A)+Func(B))/2 # initialize , (first + last)/2 foriin range (1, N): # inside 20 sum+= Func(A+i ‚àóh) # returnh‚àósum # sum times h defradiuss(L): # radius as function of L ro = 1 # radius of cylinder (a/ro=1) 24a=1 # 2a: height of inner cylinder M=0.5 #b l a c kh o l e( m a s s M / r o ) = 1 xx = (2 ‚àó(L‚àía))/(np.pi ‚àóM) p=M ‚àó(xx‚àónp.arctan(xx)) 28q=‚àí0.5‚àóM‚àómath.log(1+xx ‚àó‚àó2) r=r o +p + q returnr foriin range (1,12): # Plot rings at z , ‚àíz 32A=0 # limits of integration B=i N = 300 # trapezoid rule points ifi>6: N=600 # more points 36z = trapezoid(f,A,B,N) # returns z L=i + 1 rr = radiuss(L) # radius ring(pos=vector(0,z,0),radius=rr,axis=vector(0,1,0),color=color.yellow) 40ring(pos=vector(0, ‚àíz,0),radius=rr,axis=vector(0,1,0),color=color.yellow)",8414
Chapter 20 Integral Equations. 20.1 Nonlocal Potential Binding. 20.2.1 Integral to Matrix Equations,"425 20 Integral Equations The power and accessibility of high-speed computers have changed the view about what kind of equations are solvable. We have seen how even nonlinear differential equations can be solved easily and can give new insight into the physical world. In this chapter, we examine how integral equations, even those containing singularities, can be solved as matrix equations. We Ô¨Årst convert the quantum bound-state problem to a matrix eigenvalue problem and solve it. We then examine the quantum scattering problem, which leads to a singular integral equation, and solve it too . 20.1 Nonlocal Potential Binding A particle undergoes an interaction with a many-body medium, as shown on the left of Figure 20.1. We replace this very difficult problem by an approximate, but easier one, in which the particle interacts with an effective, one-particle potential. Because the effec- tive potential at rdepends on the wave function at r‚Ä≤, where there are interactions with otherparticles,theeffectivepotentialat ralsodependson r‚Ä≤,thatis,thepotential V(r,r‚Ä≤)is nonlocal.Thismeansthatthe V(r)ùúì(r)termintheSchr√∂dingerequationgetsreplacedby: V(r)ùúì(r)‚Üí‚à´dr‚Ä≤V(r,r‚Ä≤)ùúì(r‚Ä≤), (20.1) ‚áí‚àí1 2md2ùúì(r) dr2+‚à´dr‚Ä≤V(r,r‚Ä≤)ùúì(r‚Ä≤)=Eùúì(r). (20.2) Your problemistosolvethis integrodifferentialequation forbound-stateenergies Enand wavefunctions ùúìn.(Thesearenaturalunits, ‚Ñè=1.) 20.2 Momentum-Space Schr√∂dinger Equation Although integrodifferentialequationscanbesolvediteratively,amoredirectapproachis tosolvethemomentum-spaceversionof(20.1)[Landau,1996]: k2 2mùúìn(k)+2 ùúã‚à´‚àû 0dpp2V(k,p)ùúìn(p)=Enùúìn(k), (20.3) ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 426 20 Integral Equations kk‚Ä≤‚Äìk ‚Äìk‚Ä≤ m2m1 r‚Ä≤r Figure 20.1 Left: A projectile (dark particle at r) scatters from a dense medium. Right: The same process viewed in the COM system where the projectile and target always have equal and opposite momenta. where subscript nis used to enumerate the different bound-states. Here V(k,p)is the momentum-space representation (double Fourier transform) of the coordinate-space potential, and if we restrict our solution to angular momentum l=0 partial waves, it is simplyrelatedto V(r): V(k,p)=1 kp‚à´‚àû 0drsin(kr)V(r)sin(pr). (20.4) Inturn,themomentum-spacewavefunction ùúìn(k)istheprobabilityamplitudeforfinding theparticlewithmomentum k.ItistheFouriertransformof ùúìn(r): ùúìn(k)=‚à´‚àû 0drkrùúìn(r)sin(kr). (20.5) Equation(20.3)isanintegralequationfor ùúìn(k).Itdiffersfromanintegralrepresentation ofùúìn(k)in that the integral in it cannot be evaluated until the solution ùúìn(p)is known. Although this may seem like a paradox, we will transform this equation into a matrix equationthatcanbesolvedwiththematrixtechniquesdiscussedinChapter7. 20.2.1 Integral to Matrix Equations We approximatethe pintegraloverthepotentialin(20.4)asaweightedsumover Ninte- gration(usuallyGaussquadrature)points p=kj,j=1‚Ä¶N: ‚à´‚àû 0dpp2V(k,p)ùúìn(p)‚âÉN‚àë j=1ùë§jk2 jV(k,kj)ùúìn(kj). (20.6) Thisconvertstheintegralequation(20.3)tothealgebraicequation: k2 2mùúìn(k)+2 ùúãN‚àë j=1ùë§jk2 jV(k,kj)ùúìn(kj)=En. (20.7) Equation(20.7)contains Nunknownfunctionvalues ùúìn(kj),anunknownenergy En,aswell astheunknownfunctionaldependenceof ùúìn(k).Weeliminatethefunctionaldependence ofùúìn(k)bysolvingtheequationsforthesame k=kivaluesasthoseusedtoapproximate theintegral.Inotherwords,wesolvetheequationsonlyfor kvaluesonthegridshownin Figure20.2.Thisleadstoasetof Ncoupledlinearequationsin (N+1)unknowns: k2 i 2mùúìn(ki)+2 ùúãN‚àë j=1ùë§jk2 jV(ki,kj)ùúìn(kj)=Enùúìn(ki),i=1,N. (20.8) kN k3 k2 k1 Figure 20.2 The grid of momentum values on which the integral equation is solved. 20.2 Momentum-Space Schr√∂dinger Equation 427 Forexample,for N=2wewouldhavethetwosimultaneouslinearequations: k2 1 2mùúìn(k1)+2 ùúãùë§1k2 1V(k1,k1)ùúìn(k1)+ùë§2k2 2V(k1,k2)ùúìn(k1)=Enùúìn(k1), k2 2 2mùúìn(k2)+2 ùúãùë§1k2 1V(k2,k1)ùúìn(k1)+ùë§2k2 2V(k2,k2)ùúìn(k2)=Enùúìn(k2). Ofcourse,aprecisesolutionwouldrequiremorethantwointegrationpoints. Wewriteourcoupledequations(20.8)inmatrixformas: [H][ùúìn]=En[ùúìn], (20.9) ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£k2 1 2m+2 ùúãV(k1,k1)k2 1ùë§12 ùúãV(k1,k2)k2 2ùë§2¬∑¬∑¬∑2 ùúãV(k1,kN)k2 Nùë§N 2 ùúãV(k2,k1)k2 1ùë§12 ùúãV(k2,k2)k2 2ùë§2+k2 2 2m¬∑¬∑¬∑ ... ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑k2 N 2m+2 ùúãV(kN,kN)k2 Nùë§N‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶ √ó‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùúìn(k1) ùúìn(k2) ... ùúìn(kN)‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶=En‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùúìn(k1) ùúìn(k2) ... ùúìn(kN)‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (20.10) Equation(20.9)isthematrixrepresentationoftheSchr√∂dingerequation(20.3).Thewave function ùúìn(k)evaluatedonthegridofintegrationpointisthe N√ó1vector [ùúìn(ki)] =‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùúìn(k1) ùúìn(k2) ... ùúìn(kN)‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶. (20.11) Theastutereadermaybequestioningthepossibilityofsolving Nequationsforthe N+1 unknowns, ùúìn(ki)andEn.Onlysometimes,andonlyforcertainvaluesof En(theeigenval- ues),willasolutionexist.Let‚Äôsstartbytryingtoapplythematrixinversiontechniqueby rewriting(20.9)as: [H‚àíEnI][ùúìn]=[0]. (20.12) Ifwetrytoobtainasolutionbymultiplyingbothsidesof(20.13)bytheinverseof [H‚àíEnI], wegetsomethingweird: [ùúìn]=[H‚àíEnI]‚àí1[0]. (20.13) This equation tells us that if the inverse exists, then we have the trivialsolution ùúìn‚â°0, which is a solution, but is trivial. So maybe the assumption that the inverse exists is not valid,whichwouldmeanthatthedeterminantof [H‚àíEnI]vanishes: det[H‚àíEnI]=0 (bound-statecondition) . (20.14) Equation(20.14)isthe (N+1)thequationweneedforauniquesolutiontothebound-state problem,inwhich Enistheeigenvalues of(20.9).",5355
20.2.3 Wave Function Exploration,"428 20 Integral Equations 20.2.2 Delta-Shell Potential To keepthingssimple,andtohaveananalyticanswerwithwhichtocompare,weconsider thelocal,delta-shellpotential: V(r)=ùúÜ 2mùõø(r‚àíb). (20.15) Thismightbeagoodmodelforaninteractionthatoccurswhentwoparticlesarepredomi- nantlyafixeddistance bapart.Equation(20.4)determinesthemomentum-spacerepresen- tationofthepotential: V(k‚Ä≤,k)=‚à´‚àû 0sin(k‚Ä≤r‚Ä≤) k‚Ä≤kùúÜ 2mùõø(r‚àíb)sin(kr)dr=ùúÜ 2msin(k‚Ä≤b)sin(kb) k‚Ä≤k.(20.16) Beware:Wehavechosenthispotentialbecauseitiseasytoevaluatethemomentum-space matrixelements.However,itssingularnaturein rspaceleadsto(20.16)havingaveryslow falloffinkspace,andthisleadstopoornumericalprecision. Iftheenergyisparameterizedintermsofawavevector ùúÖbyEn=‚àíùúÖ2‚àï2m,thenforthis potential there is, at most, one bound state, and it satisfies the transcendental equation [GottfriedandYan,2004]: e‚àí2ùúÖb‚àí1=2ùúÖ ùúÜ. (20.17) Duetob]oundstatesoccurringonlyforattractivepotentials,wemusthave ùúÜ<0. Exercise Picksomevaluesof bandùúÜ,andsolve(20.17)for ùúÖ. Thenumericalcomputationmayfollowtwopaths.Oneevaluatesdet [H‚àíEnI]in(20.14), andthensearchesforthosevaluesofenergyatwhichthedeterminantvanishes.Thispro- videsEn, but not wave functions. The other path solves the eigenvalue problem for all eigenvaluesandeigenfunctions.Inbothcases,thesolutionmustbesearchedfor,andyou mayberequiredtoguessstartingvaluesfortheenergy.Wepresentoursolution Bound.pyin Listing20.1. Problems Write a program that solves the integral equation (20.9) for the delta-shell potential (20.16). Find either the En‚Äôs for which the determinant vanishes or, the eigen- valuesandeigenvectorsforthis H. 1) Setthescalebysetting2 m=1andb=10. 2) SetupthepotentialandHamiltonianmatrices, V(i,j)andH(i,j),forGaussianquadra- tureintegrationusingatleast N=16gridpoints. 3) Adjustthevalueandsignof ùúÜforboundstates.Startwithalargenegativevaluefor ùúÜ andthenmakeitprogressivelylessnegative.Youshouldfindthattheeigenvaluesmove upinenergy. 4)Note:Youreigenenergysolvermayreturnseveraleigenenergies.Thetrueboundstate willbeatnegativeenergyandchangelittleasthenumberofgridpointschanges.The othersarenumericalartifacts. 5) Tryincreasingthenumberofgridpointsinstepsof8,forexample,16,24,32,64, ‚Ä¶,and seehowtheenergychanges.",2196
20.3 Scattering in Momentum Space. 20.3.6 Scattering Wave Function Exploration,"20.3 Scattering in Momentum Space ‚äô429 6) Extractthebestvalueforthebound-stateenergy,andestimateitsprecisionbyseeing howitchangeswiththenumberofgridpoints. 7) Ifyouaresolvingtheeigenvalueproblem,checkyoursolutionbycomparingtheRHS andLHSinthematrixmultiplication [H][ùúìn]=En[ùúìn]. 8) Verifythat,regardlessofthepotential‚Äôsstrength,thereisonlyasinglebound-stateand thatitgetsdeeperasthemagnitudeof ùúÜincreases.Comparewith(20.17). 20.2.3 Wave Function (Exploration) 1) Determine the momentum-space wave function ùúìn(k)using an eigenproblem solver. Doesùúìn(k)falloffatk‚Üí‚àû?Doesitoscillate?Isitwell-behavedattheorigin? 2) Using the same points and weights as used to evaluate the integral in the inte- gral equation, determine how the coordinate-space wave function via the Bessel transforms. ùúìn(r)=‚à´‚àû 0dkùúìn(k)sin(kr) krk2. (20.18) Doesùúìn(r)fall off as you would expect for a bound-state? Does it oscillate? Is it well- behavedattheorigin? 3) Comparethe rdependenceofthis ùúìn(r)totheanalyticwavefunction: ùúìn(r)‚àù{e‚àíùúÖr‚àíeùúÖr,forr<b, e‚àíùúÖr, forr>b.(20.19) 20.3 Scattering in Momentum Space ‚äô Again wehaveaparticleinteractingwiththenonlocalpotential,Figure20.1left,onlynow theparticlehassufficientlyhighenergyforittoscatterfromthetargetparticlesandnotbe boundbythem. Problem Determinethescatteringphaseshift ùõøforthisscattering. 20.3.1 Schr√∂dinger to Lippmann‚ÄìSchwinger Equation Because scatteringexperimentsmeasurescatteringamplitudes,butnotwavefunctions,it ismoredirecttohaveourtheorycalculateamplitudes.AnintegralformoftheSchr√∂dinger equationdealingwiththescatteringamplitude RistheLippmann‚ÄìSchwingerequation : R(k‚Ä≤,k)=V(k‚Ä≤,k)+2 ùúãÓàº‚à´‚àû 0dpp2V(k‚Ä≤,p)R(p,k) (k2 0‚àíp2)‚àï2m. (20.20) (Risactuallythe reactionmatrix ,butisrelatedtothescatteringamplitude,andiseasierto calculate.)Asinthebound-stateproblem,thisequationisforpartialwave l=0and‚Ñè=1. In(20.20)themomentum k0isrelatedtotheenergy Eandthereducedmass mby: E=k2 0 2m,m=m1m2 m1+m2. (20.21) 430 20 Integral Equations The initial and final COM momenta kandk‚Ä≤are the momentum-space variables. The experimentalobservablethatresultsfromasolutionof(20.20)isthediagonal( k=k‚Ä≤=k0) matrix element R(k0,k0), which is related to the scattering phase shift ùõø0, and thus the crosssection: R(k0,k0)=‚àítanùõøl ùúå,ùúå=2mk0. (20.22) Notethat(20.20)isnotjusttheevaluationofanintegral,itisanintegralequationinwhich R(p,k)must be integrated over all pvalues. Yet because R(p,k)is unknown, the integral cannot be evaluated until after the equation is solved. The symbol Óàºin (20.20)indicates theCauchyprincipal-value prescriptionforavoidingthesingularityarisingfromthezeroof thedenominatorat p=k0. 20.3.2 Singular Integral Evaluations Asingularintegral Óà≥=‚à´b ag(k)dk, (20.23) isoneinwhichtheintegrand g(k)issingularatthepoint k0withintheintegrationinterval, yettheintegral Óà≥remainsfinite.(Iftheintegralitselfwereinfinite,wecouldnotcompute it.) Unfortunately, computers are notoriously incompetent at dealing with infinite num- bers,andifanintegrationpointgetstooneartothesingularity,overwhelmingsubtractive cancellation,oroverflow,occurs.Butwecandealwithit.",3055
20.3 Scattering in Momentum Space. 20.3.6 Scattering Wave Function Exploration,"InFigure20.3weshowthreewaystoavoidthesingularityat k0.ThepathsinFigure20.3a andbmovethesingularityslightlyoffthereal kaxisbygiving k0asmallimaginarypart ¬±iùúñ. The Cauchy principal-value prescription Óàºin Figure 20.3c says to integrate along a paththat‚Äúpinches‚Äùbothsidesofthesingularityat k0,withoutintegratingoverit: Óàº‚à´+‚àû ‚àí‚àûf(k)dk=lim ùúñ‚Üí0[ ‚à´k0‚àíùúñ ‚àí‚àûf(k)dk+‚à´+‚àû k0+ùúñf(k)dk] . (20.24) Theprecedingthreeprescriptionsarerelatedbytheidentity ‚à´+‚àû ‚àí‚àûf(k)dk k‚àík0¬±iùúñ=Óàº‚à´+‚àû ‚àí‚àûf(k)dk‚Ä≤ k‚àík0‚àìiùúãf(k0), (20.25) whichfollowsfromCauchy‚Äôsresiduetheorem. ‚Äìko ko ‚Äì Œµko + Œµ‚Äìko kokoIm k Im k Im k Re k Figure 20.3 Three different paths in the complex kplane used to evaluate line integrals when there are singularities. Here the singularities are at ¬±k0, and the integration variable is k.I nLeft andCenter the singularity is given a small imaginary part k0‚Üík0¬±iùúñthat moves it slightly off the real axis, while in Rightthe integration path ‚Äúpinches‚Äù both sides of the singularity, without passing through it. 20.3 Scattering in Momentum Space ‚äô431 Anumericalevaluationoftheprincipalvaluelimit(20.24)istroublesomebecauselarge cancellationswilloccurnearthesingularity.Anaccuratealgorithmforevaluatingtheinte- gralfollowsfromthefactthat Óàº‚à´+‚àû ‚àí‚àûdk k‚àík0=0. (20.26) Thisequationsaysthatagraphof1 ‚àï(k‚àík0)versuskhasequalandoppositeareasonboth sidesofthesingularpoint k0: Óàº‚à´+‚àû ‚àí‚àûdk k‚àík0=‚à´0 ‚àí‚àûdk k‚àík0+‚à´+‚àû 0dk k‚àík0(20.27) =‚àí‚à´+‚àû 0‚àídk ‚àík‚àík0+‚à´+‚àû 0dk k‚àík0, (20.28) ‚áíÓàº‚à´‚àû 0dk k2‚àík2 0=0, (20.29) wherewehavebrokentheintegralupintooneoverpositive kandoneover ‚àík,andthen changedvariable k‚Üí‚àíkinthefirstintegral. Wethusseethattheprincipal-valueexclusion ofthesingularpoint‚Äôscontributiontotheintegralisequivalenttoasimplesubtractionof thezerointegral(20.29): Óàº‚à´‚àû 0f(k)dk k2‚àík2 0=‚à´‚àû 0[f(k)‚àíf(k0)]dk k2‚àík2 0. (20.30) Noticethatthereisno ÓàºontheRHSof(20.30)becausetheintegrandisnolongersingularat k=k0(itisproportionaltothe df‚àïdk).ThereforetheintegralontheRHScanbeevaluated numericallyusingtheusualrules.Theintegral(20.30)iscalledthe Hilberttransform off andalsoarisesinsubjectssuchasinverseproblems. 20.3.3 Singular Integral Equations to Matrix Equations Now thatwehaveputthesingularityoutoftheway,wegobacktoreducingtheintegral equation(20.20)toasetoflinearequations.Werewritetheprincipal-valueprescriptionas adefiniteintegral[HaftelandTabakin,1970]: R(k‚Ä≤,k)=V(k‚Ä≤,k)+2 ùúã‚à´‚àû 0dpp2V(k‚Ä≤,p)R(p,k)‚àík2 0V(k‚Ä≤,k0)R(k0,k) (k2 0‚àíp2)‚àï2m.(20.31) Weconvertthisintegralequationtoasetofsimultaneouslinearequationsbyapproximating theintegralasasumover NGaussianintegrationpoints kjwithweights ùë§j: R(k,k0)‚âÉV(k,k0)+2 ùúãN‚àë j=1k2 jV(k,kj)R(kj,k0)ùë§j (k2 0‚àík2 j)‚àï2m ‚àí2 ùúãk2 0V(k,k0)R(k0,k0)N‚àë m=1ùë§m (k2 0‚àík2 m)‚àï2m. (20.32) Wenotethatthelasttermin(20.32)implementstheprincipal-valueprescriptionandcan- celsthesingularbehaviorofthepreviousterm.Thisequationcontainsthe N+1unknowns 432 20 Integral Equations R(kj,k0)forj=0,N.Weturnitinto N+1simultaneousequationsbyevaluatingitforthe NkvaluesonthegridinFigure20.2,andattheobservablemomentum k0: k=ki={kj,j=1,N(quadraturepoints), k0,i=0 (observablepoint).(20.33) Therearenow N+1linearequationsforthe N+1unknowns Ri‚â°R(ki,k0): Ri=Vi+2 ùúãN‚àë j=1k2 jVijRjùë§j (k2 0‚àík2 j)‚àï2m‚àí2 ùúãk2 0Vi0R0N‚àë m=1ùë§m (k2 0‚àík2 m)‚àï2m. (20.34) Weexpress(20.34)inmatrixformbycombiningthedenominatorsandweightsintoasingle denominatorvector D: Di=‚éß ‚é™ ‚é™ ‚é® ‚é™ ‚é™‚é©+2 ùúãùë§ik2 i (k2 0‚àík2 i)‚àï2m,fori=1,N, ‚àí2 ùúãN‚àë j=1ùë§jk2 0 (k2 0‚àík2 j)‚àï2m,fori=0.(20.35) Thelinearequations(20.34)nowassumethematrixform R‚àíDVR= [1‚àíDV]R=V, (20.36) whereRandVarethelength N+1vectors: [R]=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£R0,0 R1,0 ... RN,0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶,[V]=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£V0,0 V1,0 ... VN,0‚é§ ‚é• ‚é• ‚é• ‚é•‚é¶.",3568
20.3 Scattering in Momentum Space. 20.3.6 Scattering Wave Function Exploration,"(20.37) Wewriteourreductionoftheintegralequationasthematrixequation: [F][R]=[V], Fij=ùõøij‚àíDjVij. (20.38) TheFmatrixisknownasthe wavematrix .WithRtheunknownvector,(20.38)isinthestan- dardformAX=B,whichcanbesolvedbythemathematicalsubroutinelibrariesdiscussed inChapter7. 20.3.4 Solution An elegant(butalasnotmostefficient)solutionto(20.38)isbymatrixinversion: [R]=[F]‚àí1[V]. (20.39) Because the inversion of even complex matrices is a standard routine in linear algebra libraries, (20.39) is a directsolution for theRamplitude. Unless you need the inverse for other purposes (like calculating wave functions), a more efficient approach is Gaussian elimination ,whichisalsocontainedinthelinearalgebralibraries. 20.3 Scattering in Momentum Space ‚äô433 Figure 20.4 The energy dependence of the cross section for angular momentum l=0 scattering from an attractive delta-shell potential with ùúÜb=15. The dashed curve is the analytic solution (20.41), and the solid curve results from numerically solving the integral Schr√∂dinger equation. 0 2 4 601Sin2Œ¥ Analytic kbœÄ Forthisscatteringproblemwewillusethesamedelta-shellpotential(20.16)asweused inSection20.2.2forboundstates: V(k‚Ä≤,k)=‚àí|ùúÜ| 2mk‚Ä≤ksin(k‚Ä≤b)sin(kb). (20.40) ThisisoneofthefewpotentialsforwhichtheLippmann‚ÄìSchwingerequation(20.20)has ananalyticsolution[GottfriedandYan,2004]withwhichtocheck: tanùõø0=ùúÜbsin2(kb) kb‚àíùúÜbsin(kb)cos(kb). (20.41) Ourresultswereobtainedwith2 m=1,ùúÜb=15,andb=10,thesameasinGottfriedand Yan[2004].InFigure20.4,wegiveaplotofsin2ùõø0versuskb,whichisproportionaltothe scattering cross section arising from the angular momentum l=0 phase shift. Note that sin2ùõøreachesitsmaximumvaluesatenergiescorrespondingtoresonances.Wepresentour solution, Scatt.py,inListing20.2. 20.3.5 Exercises 1 )W r i t eap r o g r a mf o rt h em a t r i c e s V[], D[], and F[,]. Use at least N=16 Gaussian quadraturepointsforyourgrid. 2) Calculatethematrix F‚àí1usingalibrarysubroutine. 3) Calculatethevector Rbymatrixmultiplication R=F‚àí1V. 4) Deducethephaseshift ùõøfromR(k0,k0): R(k0,k0)=R0,0=‚àítanùõø ùúå,ùúå=2mk0. (20.42) 5) Estimatetheprecisionofyoursolutionbyincreasingthenumberofgridpointinsteps oftwo(wefoundthebestanswerfor N=26).Ifyourphaseshiftchangesinthesecond orthirddecimalplace,youprobablyhavethatmuchprecision. 6) Plotsin2ùõøversusenergyE=k2 0‚àï2mstartingatzeroenergyandendingatenergieswhere thephaseshiftisagainsmall.YourresultsshouldbesimilartothoseinFigure20.4.Note thataresonanceoccurswhen ùõølincreasesrapidlythrough ùúã‚àï2,thatis,whensin2ùõø0=1. 7) Checkyouransweragainsttheanalyticresults(20.41).",2537
20.4 Code Listings,"434 20 Integral Equations 20.3.6 Scattering Wave Function (Exploration) ThewavematrixF‚àí1inoursolutiontotheintegralequation R=F‚àí1V=(1‚àíVG)‚àí1V (20.43) canbeusedtocalculatethecoordinate-spacewavefunction: u(r)=N0N‚àë i=1sin(kir) kirF(ki,k0)‚àí1. (20.44) HereN0isanormalizationconstant,andthe Ramplitudeisappropriateforstanding-wave boundaryconditions. 1) Plotu(r)andcompareittoafreewave. 20.4 Code Listings Listing 20.1 Bound.py SolvestheLippmann‚ÄìSchwingerintegralequationforthequan- tumboundsstateswithinadelta-shellpotential. # Bound . py : Bound state solutn of Lippmann ‚àíSchwinger equation in p space 2 fromvisualimport ‚àó fromnumpyimport ‚àó fromnumpy. linalg import ‚àó 6 min1 =0.; max1 =200.; u =0.5; b =10. defgauss(npts,a,b,x,w): 10pp = 0.; m= (npts + 1)//2; eps = 3.E ‚àí10 # Accuracy : ADJUST. foriin range (1,m+1): t=c o s ( m a t h . p i ‚àó(float(i)‚àí0.25)/(float(npts) + 0.5)) 14 t1 = 1 while((abs(t‚àít1)) >= eps): p1 = 1. ; p2 = 0.; forjin range (1,npts+1): 18 p3 = p2 p2 = p1 p1=((2 ‚àój‚àí1)‚àót‚àóp2‚àí(j‚àí1)‚àóp3)/j pp = npts ‚àó(t‚àóp1‚àíp2)/(t ‚àót‚àí1.) 22 t1 = t; t = t1 ‚àíp1/pp x[i‚àí1] =‚àít x[npts‚àíi] = t w[i‚àí1] = 2./((1. ‚àít‚àót)‚àópp‚àópp) 26 w[npts‚àíi] =w[i ‚àí1] foriin range (0,npts): x[i] = x[i] ‚àó(b‚àía)/2. + (b + a)/2. w[i] = w[i] ‚àó(b‚àía)/2. 30 forMin range (16, 32, 8): z=[‚àí1024,‚àí512,‚àí256,‚àí128,‚àí64,‚àí32,‚àí16,‚àí8,‚àí4,‚àí2] forlmbdainz: 34 A=z e r o s( ( M , M ), float) # Hamiltonian WR = zeros ( (M) , float) # Eigenvalues , potential k=z e r o s( ( M ), float); w= zeros((M ), float); #P t s&wts gauss(M, min1, max1, k, w) # Call gauss points 38 foriin range (0,M): # Set Hamiltonian forjin range (0,M): VR = lmbda/2/u ‚àósin(k[i] ‚àób)/k[i] ‚àósin(k[j] ‚àób)/k[j] A[i ,j] = 2./math.pi ‚àóVR‚àók[j] ‚àók[j] ‚àów[j] 42 if(i = = j): 20.4 Code Listings 435 A[i ,j] += k[i] ‚àók[i]/2/u Es, evectors = eig(A) realev = Es.real # Real eigenvalues 46 forjin range (0,M): if(realev[j]<0): print(\"" M (size), lmbda, ReE = \"" ,M,\""\"",lmbda, \""\"",realev[j]) break Listing 20.2 Scatt.py Solves the Lippmann‚ÄìSchwinger integral equation for quantum scatteringfromadelta-shellpotential. 1# Scatt . py : Soln p space Lippmann Schwinger for scattering fromvisualimport ‚àó fromvisual.graph import ‚àó 5importnumpy.linalg as lina # N u m p y‚Äôs LinearAlgebra defgauss(npts, job, a, b, x, w): m = i = j = t = t1 = pp = p1 = p2 = p3 = 0. 9eps = 3.E ‚àí14 # Accuracy : ‚àó‚àó‚àó‚àó‚àó‚àó ADJUST THIS ‚àó‚àó‚àó‚àó‚àó‚àó‚àó . m= (npts + 1)/2 foriinarange(1, m + 1): t=c o s ( m a t h . p i ‚àó(float(i)‚àí0.25)/(float(npts) + 0.5) ) 13 t1 = 1 while((abs(t‚àít1) ) >= eps): p1 = 1. ; p2 = 0. forjin range (1, npts + 1): 17 p3 = p2; p2 = p1 p1 = ((2. ‚àófloat(j)‚àí1)‚àót‚àóp2‚àí(float(j)‚àí1.)‚àóp3)/(float(j)) pp = npts ‚àó(t‚àóp1‚àíp2)/(t ‚àót‚àí1.) t1 = t; t = t1 ‚àíp1/pp 21 x[i‚àí1] =‚àít; x[npts ‚àíi] = t w[i‚àí1] = 2./( (1. ‚àít‚àót)‚àópp‚àópp) w[npts ‚àíi] =w[i ‚àí1] if(job = = 0): 25 foriin range (0, npts): x[i] = x[i] ‚àó(b‚àía)/2. + (b + a)/2. w[i] =w[i] ‚àó(b‚àía)/2. if(job = = 1): 29 foriin range (0, npts): xi = x[i] x[i] = a ‚àób‚àó(1. + xi) / (b + a ‚àí(b‚àía)‚àóxi) w[i] =w[i] ‚àó2.‚àóa‚àób‚àób/( (b + a ‚àí(b‚àía)‚àóxi)‚àó(b + a ‚àí(b‚àía)‚àóxi)) 33if(job = = 2): foriin range (0, npts): xi = x[i] x[i] = (b ‚àóx i+ b+a+a )/( 1 . ‚àíxi) 37 w[i] =w[i] ‚àó2.‚àó(a + b)/( (1. ‚àíxi)‚àó(1.‚àíxi) ) graphscatt = gdisplay(x=0, y=0, xmin=0, xmax=6,ymin=0, ymax=1, width=600, height=400, title= ‚ÄôS Wave Cross Section vs E‚Äô , xtitle= ‚Äôkb‚Äô, ytitle= ‚Äô[sin(delta)]**2‚Äô ) 41sin2plot = gcurve(color=color.yellow) M= 27; b = 10.0; n = 26 k=z e r o s( ( M ), float); x= zeros((M ), float); w= zeros((M ), float) Finv = zeros((M,M), float); F= zeros((M ,M ), float); D= zeros((M ), float) 45V=z e r o s( ( M ), float); Vvec = zeros((n+1,1), float) scale = n/2; lambd = 1.5 gauss(n, 2, 0., scale , k, w) # Set up points & wts 49ko = 0.02 formin range (1,901): k[n] = ko foriin range (0, n): D[i]=2/pi ‚àów[i] ‚àók[i] ‚àók[i]/(k[i] ‚àók[i]‚àíko‚àóko) #D 53D[n] = 0. forjin range (0,n): D[n]=D[n]+w[j] ‚àóko‚àóko/(k[j] ‚àók[j]‚àíko‚àóko) D[n] = D[n] ‚àó(‚àí2./pi) foriin range (0,n+1): #S e tu pF& V 436 20 Integral Equations 57 forjin range (0,n+1): pot =‚àíb‚àób‚àólambd ‚àósin(b ‚àók[i]) ‚àósin(b ‚àók[j])/(k[i] ‚àób‚àók[j] ‚àób) F[i][j] = pot ‚àóD[j] ifi==j: F[i][j] = F[i][j] + 1. 61 V[i] = pot foriin range (0,n+1): Vvec[i][0]= V[i] Finv = lina.inv(F) # LinearAlgebra for inverse R=d o t( F i n v, V v e c ) # Matrix multiply 65RN1 = R[n][0] shift = atan( ‚àíRN1‚àóko) sin2 = (sin(shift)) ‚àó‚àó2 sin2plot.plot(pos = (ko ‚àób,sin2)) # Plot sin ‚àó‚àó2(delta) 69ko = ko + 0.2 ‚àópi/1000. print(\""Done\"")",4335
Part IV PDE Applications,437 Part IV PDE Applications,28
Chapter 21 PDE Review Electrostatics and Relaxation. 21.1 Review,"439 21 PDE Review, Electrostatics and Relaxation This chapter is the Ô¨Årst of several dealing with partial differential equations (PDEs); several because PDEs are more complex than ODEs, and several because each type of PDE requires its own algorithm. We start with a review of the types of PDEs, and requirements for their unique solutions. Then we get down to business by examining the simple, but powerful, Ô¨Ånite difference method for solving Poisson‚Äôs and Laplace‚Äôs equations. In Chapter 27,w e introduce the more complicated, but computationally faster, Ô¨Ånite element method (FEM) for solving the same equations . 21.1 Review Physical quantitiessuchastemperatureandpressurevarycontinuouslyinbothspaceand time.Suchbeingourworld,thefunctionor fieldU(x,y,z,t)usedtodescribethesequan- tities must contain independent space and time variations. As time flows, the change in U(x,y,z,t)atanyonepositionaffectthefieldatneighboringpoints.Thismeansthatthe dynamicequationsdescribingthedependenceof Uonfourindependentspace-timevari- ablesmustbewrittenintermsofpartialderivatives,andtherefore,theequationsmustbe partialdifferentialequations (PDEs),incontrasttoordinarydifferentialequations(ODEs). ThegeneralformforaPDEwithtwoindependentvariablesis Aùúï2U ùúïx2+2Bùúï2U ùúïxùúïy+Cùúï2U ùúïy2+DùúïU ùúïx+EùúïU ùúïy=F, (21.1) whereA,B,C,andFarearbitraryfunctionsofthevariables xandy[ArfkenandWeber, 2001]. In Table 21.1, we define the classes of PDEs by the value of the discriminant d=AC‚àíB2, and give examples there. We usually think of an elliptic equation as one containing second-order derivatives of all the variables, with all having the same sign when placed on the same side of the equal sign; a parabolic equation as one containing a first-order derivative in one variable and a second-order derivative in the other; and a hyperbolic equation as one containing second-order derivatives of all the variables, with oppositesignswhenplacedonthesamesideoftheequalsign. Aftersolvingenoughproblems,oneoftendevelopssomephysicalintuitionastowhether one has sufficient boundary conditions for there to exist a unique solution for a given ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 440 21 PDE Review, Electrostatics and Relaxation Table 21.1 The types of PDE, their discriminants, and examples of each. d=AC‚àíB2>0 d=AC‚àíB2=0 d=AC‚àíB2<0 ‚àá2U(x)=‚àí4ùúãùúå(x)‚àá2U(x,t)=aùúïU‚àïùúït ‚àá2U(x,t)=c‚àí2ùúï2U‚àïùúït2 Poisson‚Äôsequation Heatequation Waveequation Table 21.2 The relation between boundary conditions and uniqueness for PDEs. Boundary conditionElliptic (Poisson equation)Hyperbolic (Wave equation)Parabolic (Heat equation) Dirichletopensurface Underspecified Underspecified Unique&stable(1D) Dirichletclosedsurface Unique&stable Overspecified Overspecified Neumannopensurface Underspecified Underspecified Unique&Stable(1D) Neumannclosedsurface Unique&stable Overspecified Overspecified Cauchyopensurface Nonphysical Unique&stable Overspecified Cauchyclosedsurface Overspecified Overspecified Overspecified physicalsituation(this,ofcourse,isinadditiontorequisite initialconditions ).Table21.2 givestherequisiteboundaryconditionsforauniquesolutiontoexistforeachtypeofPDE. For instance, a string tied at both ends, or a heated bar placed in an infinite heat bath, are physical situations for which the boundary conditions are adequate. If the boundary conditionisthevalueofthesolutiononasurroundingclosedsurface,wehavea Dirichlet boundary condition . If the boundary condition is the value of the normal derivative on thesurroundingsurface,wehavea Neumannboundarycondition .Ifthevalueofboththe solutionanditsderivativearespecifiedonaclosedboundary,wehavea Cauchyboundary condition. Although having an adequate boundary condition is necessary for a unique solution,havingtoomanyboundaryconditions,forinstance,bothNeumannandDirichlet, maybeanoverspecificationforwhichnosolutionexists.1 SolvingPDEsnumericallydiffersfromsolvingODEsinanumberofways.First,because weareabletowriteallODEsinastandardform, dy(t) dt=f(y,t), (21.2) withtthe single independent variable, we are able to use a standard algorithm such as rk4tosolveallsuchequations.Yet,becausePDEshaveseveralindependentvariables,for example ùúå(x,y,z,t), we would have to apply (21.2) simultaneously and independently to eachvariable,whichwouldbeverycomplicated.Second,becausetherearemoreequations to solve with PDEs than with ODEs, we need more information than just the two initial conditions [x(0),Ãáx(0)]. In addition, because each PDE often has its own particular set of boundaryconditions,wehavetodevelopaspecialalgorithmforeachparticularproblem. 1 AlthoughconclusionsconcerninguniquenessdrawnforexactthePDEsmaydifferfromthosedrawnfor thefinitedifferenceequationswewilluse,theyareusuallythesame[Jackson,1988;MorseandFeshbach, 1953].",4836
21.3 FiniteDifference Algorithm,"21.2 Laplace‚Äôs Equation 441 21.2 Laplace‚Äôs Equation Figure21.1showsawiresquareinwhichthebottomandsidesare‚Äúgrounded‚Äù(keptat0V), whilethetopwireisconnectedtoavoltagesourcethatkeepsitataconstant100V.There arenochargeswithinthesquare. Problem Findtheelectricpotentialforallpoints insidethesquare. ThevoltagesontheperimeterofthesquareinFigure21.1aretheboundaryconditionsfor thisproblem.(Ifyouimaginetherebeinginfinitesimalinsulatorsatthetopcornersofthe box,thenwehaveaclosedboundary).Sincethevaluesofthepotentialaregivenonallsides, wehaveNeumannconditionsontheboundaryand,accordingtoTable21.2,auniqueand stablesolutionexists. Itisknownfromclassicalelectrodynamicsthattheelectricpotential U(x)arisingfrom staticchargessatisfiesPoisson‚ÄôsPDE[Jackson,1988]: ‚àá2U(x)=‚àí4ùúãùúå(x), (21.3) whereùúå(x)isthechargedensityat x.Incharge-freeregionsofspace,thatis,regionswhere ùúå(x)=0,thepotentialsatisfies Laplace‚Äôsequation : ‚àá2U(x)=0. (21.4) Both these equations are elliptic PDEs of a form that occurs in various applications. We solvethemin2Drectangularcoordinates: ùúï2U(x,y) ùúïx2+ùúï2U(x,y) ùúïy2=0, Laplace‚Äôsequation, (21.5) ùúï2U(x,y) ùúïx2+ùúï2U(x,y) ùúïy2=‚àí4ùúãùúå(x), Poisson‚Äôsequation . (21.6) Inbothcasesweseethatthepotentialdependssimultaneouslyon xandy.ForLaplace‚Äôs equation,thecharges,whicharethesourceofthefield,enterindirectlybyspecifyingthe potentialvaluesinsomeregionofspace;forPoisson‚Äôsequationtheyenterdirectly aswell. V(x, y) x 300102030 20100050100 y0 V100 V xy Figure 21.1 Left: The shaded region of space within a square in which we determine the electric potential by solving Laplace‚Äôs equation. There is a wire at the top kept at a constant 100 V and a grounded wire (dashed) at the sides and bottom. Right: The computed electric potential as a function of xandy. The projections onto the shaded xyplane are equipotential contour lines. 442 21 PDE Review, Electrostatics and Relaxation 21.2.1 Fourier Series Solution For the simple geometry of Figure 21.1, an analytic solution of Laplace‚Äôs equation (21.5) existsintheformofaninfiniteseries.Ifweassumethatthesolutionistheproductofinde- pendentfunctionsof xandy,andsubstitutetheproductinto(21.5),weobtain: U(x,y)=X(x)Y(y)‚áíd2X(x)‚àïdx2 X(x)+d2Y(y)‚àïdy2 Y(y)=0. (21.7) IfX(x)isafunctionofonly x,andY(y)isafunctionofonly y,thederivativesin(21.7)are ordinaryasopposedto partialderivatives.Because X(x)andY(y)areindependent,theonly way(21.7)canbevalidfor allvalues ofxandyisforeachtermin(21.7)tobeequaltoa constant: d2Y(y)‚àïdy2 Y(y)=‚àíd2X(x)‚àïdx2 X(x)=k2, (21.8) ‚áíd2X(x) dx2+k2X(x)=0,d2Y(y) dy2‚àík2Y(y)=0. (21.9) Weshallseethatthischoiceofsignfortheconstantmatchestheboundaryconditionsand givesusperiodicbehaviorin x.Theotherchoiceofsignwouldgiveperiodicbehaviorin y, andthatwouldnotworkwiththeseboundaryconditions. Thesolutionsfor X(x)areperiodic,andthosefor Y(y)areexponential: X(x)=Asinkx+Bcoskx,Y(y)=Ceky+De‚àíky. (21.10) Thex=0 boundary condition U(x=0,y)=0 can be met only if B=0. Thex=L boundarycondition U(x=L,y)=0canbemetonlyfor: kL=nùúã,n=1,2,‚Ä¶. (21.11) Suchbeingthecase,foreachvalueof nthereisthesolution: Xn(x)=Ansin( nùúã Lx) .",3054
21.3 FiniteDifference Algorithm,"(21.12) Foreachvalueof kn,Y(y)mustsatisfythe yboundarycondition U(x,0)=0,whichrequires D=‚àíC: Yn(y)=C(ekny‚àíe‚àíkny)‚â°2Csinh( nùúã Ly) . (21.13) Becausewearesolvinglinearequations,theprincipleoflinearsuperpositionholds,which meansthatthemostgeneralsolutionisthesumoftheproducts: U(x,y)=‚àû‚àë n=1Ensin( nùúã Lx) sinh( nùúã Ly) . (21.14) TheEnvaluesarearbitraryconstantsandarefixedbyrequiringthesolutiontosatisfythe remainingboundaryconditionat y=L,U(x,y=L)=100V: ‚àû‚àë n=1Ensin( nùúã Lx) sinh(nùúã)=100V. (21.15) We determine the constants Enby projection ‚Äì Multiply both sides of the equation by sin(mùúãx‚àïL),withmaninteger,andintegratefrom0to L: ‚àû‚àë nEnsinh(nùúã)‚à´L 0dxsinnùúã Lxsinmùúã Lx=‚à´L 0dx100 sinmùúã Lx. (21.16) 21.2 Laplace‚Äôs Equation 443 TheintegralontheLHSisnonzeroonlyfor n=m,whichyields En=‚éß ‚é™ ‚é® ‚é™‚é©0, forneven, 4(100) nùúãsinh(nùúã),fornodd.(21.17) Finally,weobtainaninfiniteseries(analyticsolution?)forthepotentialatanypoint (x,y): U(x,y)=‚àû‚àë n=1,3,5,‚Ä¶400 nùúãsin( nùúãx L) sinh(nùúãy‚àïL) sinh(nùúã). (21.18) 21.2.2 Fourier Series as an Algorithm If we try to use (21.18) as an algorithm, we must terminate the sum at some point. Yet, inpractice,theconvergenceoftheseriesissopainfullyslowthatmanytermsareneeded for good accuracy, and so round-off errors may become a problem. In addition, the sinh functionsin(21.18)overflowsforlarge n,whichcanbeavoidedsomewhatbyexpressing the quotient of the two sinh functions in terms of exponentials, and then taking a large nlimit: sinh(nùúãy‚àïL) sinh(nùúã)=enùúã(y‚àïL‚àí1)‚àíe‚àínùúã(y‚àïL+1) 1‚àíe‚àí2nùúã‚àí ‚àí‚àí‚Üí n‚Üí‚àûenùúã(y‚àïL‚àí1). (21.19) Athirdproblemwiththe‚Äúanalytic‚ÄùsolutionisthataFourierseriesconvergesonlyinthe meansquare (Figure21.2).Thismeansthatitconvergestothe averageoftheleft-andright- hand limits in the regions where the solution is discontinuous, such as in the corners of thebox[Kreyszig,1998].Explicitly,whatyouseeinFigure21.2isaphenomenonknown astheGibbsovershoot ,whichoccurswhenaFourierserieswithafinitenumberoftermsis usedtorepresentadiscontinuousfunction.Ratherthanfalloffabruptly,theseriesdevelops oscillationsthattendtoovershootthefunctionatthecorner.Toobtainasmoothsolution, wehadtosum40,000terms,where,incontrast,thenumericalsolutiontofollowrequired onlyseveralhundredevaluations. Figure 21.2 The analytic (Fourier series) solution of Laplace‚Äôs equation summing 21 terms. Gibbs-overshoot leads to the oscillations near x=0, and persist even if a larger number of terms are summed over. 00100 02020 40x yV(x, y) 444 21 PDE Review, Electrostatics and Relaxation 21.3 Finite-Difference Algorithm To solve our 2D PDE numerically, we divide space into a lattice (Figure 21.3), and look for the solution Uonly on the lattice sites. Expressing derivatives in terms of the finite differencesinthevaluesof Uatthelatticesites,iscalleda finite-difference method.Anumer- icallymoreefficientmethod,butwithmorecomplicatedsetup,isthe finite-element method (FEM),whichsolvesthePDEforsmallgeometricelements,andthenmatchesthesolutions fromalloftheelements.WediscussFEMinChapter27. Toderivethefinite-differencealgorithmforthenumericsolutionof(21.5),wetakethe sameapproachthatweusedinSection5.1toderivetheforward-differencealgorithmfor differentiation.WestartbyaddingthetwoTaylorexpansionsofthepotentialattheright andleftof (x,y),andthetwoforaboveandbelow (x,y): U(x+Œîx,y)=U(x,y)+ùúïU ùúïxŒîx+1 2ùúï2U ùúïx2(Œîx)2+¬∑¬∑¬∑, (21.20) U(x‚àíŒîx,y)=U(x,y)‚àíùúïU ùúïxŒîx+1 2ùúï2U ùúïx2(Œîx)2‚àí¬∑¬∑¬∑. (21.21) U(x,y+Œîy)=U(x,y)+ùúïU ùúïyŒîy+1 2ùúï2U ùúïy2(Œîy)2+¬∑¬∑¬∑, (21.22) U(x,y‚àíŒîy)=U(x,y)‚àíùúïU ùúïyŒîy+1 2ùúï2U ùúïy2(Œîy)2‚àí¬∑¬∑¬∑. (21.23) All odd terms cancel when we add these equations in pairs, and we obtain a central- differenceapproximationforthesecondpartialderivativegoodtoorder Œî4: ùúï2U(x,y) ùúïx2‚âÉU(x+Œîx,y)+U(x‚àíŒîx,y)‚àí2U(x,y) (Œîx)2, (21.24) ùúï2U(x,y) ùúïy2‚âÉU(x,y+Œîy)+U(x,y‚àíŒîy)‚àí2U(x,y) (Œîy)2.",3720
21.3 FiniteDifference Algorithm,"(21.25) i, j + 1i ‚Äì 1, ji, j ‚Äì 1 i, j i + 1, jyx Figure 21.3 The lattice and algorithm for Laplace‚Äôs equation. The potential at the point (x,y)=(i,j)Œî equals the average of the potential values at the four nearest neighbor points. The nodes with white centers correspond to Ô¨Åxed values of the potential along the boundaries. 21.3 Finite-Difference Algorithm 445 Substitution of these approximations in Poisson‚Äôs equation (21.6) produces the finite- differenceformofthePDE: U(x+Œîx,y)+U(x‚àíŒîx,y)‚àí2U(x,y) (Œîx)2(21.26) +U(x,y+Œîy)+U(x,y‚àíŒîy)‚àí2U(x,y) (Œîy)2=‚àí4ùúãùúå. (21.27) Ifwetakethe xandygridstobeofequalspacings, Œîx=Œîy=Œî,weobtainasimpleform forthealgorithm: U(x+Œî,y)+U(x‚àíŒî,y)+U(x,y+Œî)+U(x,y‚àíŒî)‚àí4U(x,y)=‚àí4ùúãùúå.(21.28) Thereaderwillnoticethatthisequationshowsarelationamongthesolutionsatfivepoints inspace.When U(x,y)isevaluatedforthe Nxxvaluesonthelattice,andforthe Nyyval- ues,weobtainasetof Nx√óNysimultaneouslinearalgebraicequationstosolvefor U[i,j]. Oneapproachistosolvetheseequationsexplicitlyasa(big)matrixproblem.Thisisattrac- tiveasitisadirectsolution,butitrequiresagreatdealofmemoryandaccounting. Theapproachweusefollowsfromthealgebraicsolutionof(21.28)for U(x,y): 4U(x,y)‚âÉU(x+Œî,y)+U(x‚àíŒî,y)+U(x,y+Œî)+U(x,y‚àíŒî)+4ùúãùúå(x,y)Œî2, (21.29) wherewewouldomitthe ùúå(x)termforLaplace‚Äôsequation.Intermsofdiscretelocationson ourlattice,the xandyvariablesare: x=x0+iŒî,y=y0+jŒî,i,j=0,‚Ä¶,Nmax‚àí1, (21.30) where we have placed our lattice in the square of side L. The finite-difference algorithm (21.29)becomes, Ui,j=1 4[Ui+1,j+Ui‚àí1,j+Ui,j+1+Ui,j‚àí1]+ùúãùúå(iŒî,jŒî)Œî2. (21.31) Thisequationsaysthatwhenwehaveapropersolution,itwillbetheaverageofthepoten- tialatthefournearestneighborsinFigure21.3,plusacontributionfromthelocalcharge density.Asanalgorithm,(21.31)doesnotprovideadirectsolutiontoPoisson‚Äôsequation, butrathermustberepeatedmanytimestoconvergeuponthesolution.Westartwithan initialguessforthepotential,improveitbysweepingthroughallspace,takingtheaverage overnearestneighborsateachnode.Wekeeprepeatingtheprocessuntilthesolutionno longerchanges,atleasttosomelevelofprecision,oruntilfailuretoconvergeisevident. Whenconverged,theinitialguessissaidtohave relaxedintothesolution,anditdoesnot matterwhatthatguessmayhavebeen. A reasonable question with this simple an approach is, ‚ÄúDoes it always converge, and if so, does it converge fast enough to be useful?‚Äù In some sense the answer to the first question is not an issue; if the method does not converge, then we will know it; other- wisewehaveendedupwithasolution,andthepathwefollowedtogetthereisnobody‚Äôs business. The answer to the question of speed is that relaxation methods may converge slowly(althoughstillfasterthanaFourierseries),yetwewillshowyoutwoclevertricksto acceleratetheconvergence.",2718
21.4 Alternate Capacitor Problems,"446 21 PDE Review, Electrostatics and Relaxation Atthispoint,itisimportanttorememberthatouralgorithmarosefromexpressingthe Laplacian ‚àá2inrectangularcoordinates.Whilethisdoesnotrestrictusfromsolvingprob- lems with circular symmetry, there may be geometries where it is better to develop an algorithmbasedonexpressingtheLaplacianincylindricalorsphericalcoordinatesinorder tohavegridsthatfitthegeometrybetter. 21.3.1 Relaxation and Overrelaxation Thereareanumberofwaysinwhichthealgorithm(21.29)canbeusedtoturnthebound- ary conditions into a solution. The most basic approach is the Jacobi method , in which the potential values are not changed until (21.29) is applied at each point on the lattice. Thismaintainsthesymmetryoftheinitialguessandboundaryconditions.Aratherobvi- ousimprovementontheJacobimethodisthe Gauss-Seidelmethod ,inwhichtheupdated guessesforthepotentialin(21.29)areusedassoonastheyhavebeencomputed.Asacase inpoint,ifthesweepstartsintheupper-left-handcornerofFigure21.3,thentheleftmost U([-1,j]and topmost U[i,j-1]values of the potential used will be from the present gen- eration of guesses, while the other two values of the potential will be from the previous generation: U(new) i,j=1 4[ U(old) i+1,j+U(new) i‚àí1,j+U(old) i,j+1+U(new) i,j‚àí1] . (21.32) TheGauss-Seidelmethod usuallyleadstoacceleratedconvergence,which,inturn,leadsto lessround-offerrors.Italsouseslessmemoryasthereisnoneedtostoretwogenerations ofguesses.However,itdoesdistortthesymmetryoftheboundaryconditions,whichone hopesisinsignificantwhenconvergenceisreached. Alessobviousimprovementintherelaxationtechnique,knownas successiveoverrelax- ation(SOR),startsbywritingthealgorithm(21.29)inaformthatdeterminesthenewvalues ofthepotential U(new)astheoldvalues U(old)plusacorrection,orresidual r: U(new) i,j=U(old) i,j+ri,j. (21.33) WerewritetheGauss-Seideltechniquehereinthegeneralform: ri,jdef=U(new) i,j‚àíU(old) i,j =1 4[ U(old) i+1,j+U(new) i‚àí1,j+U(old) i,j+1+U(new) i,j‚àí1] ‚àíU(old) i,j. (21.34) Thesuccessiveoverrelaxationtechniquesupposesthatifconvergenceisobtainedbyadding rtoU,thenevenmorerapidconvergencemightbeobtainedbyaddingmoreorlessof r [Pressetal.,2007;Garcia,2000]: U(new) i,j=U(old) i,j+ùúîri,j,(SOR), (21.35) whereùúîisaparameterthatamplifiesorreducestheresidual.Thenonacceleratedrelaxation algorithm(21.32)correspondsto ùúî=1,acceleratedconvergence(overrelaxation)to ùúî‚â•1, andunderrelaxationto ùúî<1.Valuesof1 ‚â§ùúî‚â§2oftenworkswell,with ùúî>2sometimes leadingtonumericalinstabilities.Althoughadetailedanalysisofthealgorithmisneeded to predict the optimal value for ùúîfor a particular problem, we suggest a trial-and-error approachtoseewhatworksbest. 21.4 Alternate Capacitor Problems 447 21.4 Alternate Capacitor Problems Wegiveyouachoicenow.Youcancarryouttheassessmentusingourwire-plus-grounded-box problem, or you can replace that problem with a more interesting one, involving a realistic capacitor,ornonplanarcapacitors . Elementarytextbookssolvethecapacitorproblemfortheuniformfieldconfinedbetween twoinfiniteparallelplates.However,thefieldinarealistic(finite)capacitorvariesnearthe edges (edge effects) and extends beyond the edges (fringe fields). We model the realistic capacitorinagroundedbox(Figure21.4)astwoconductingplates(orwires)offinitelength andwidth.Writeyoursimulationsuchthatitisconvenienttovarythegridspacing Œîand thegeometryoftheboxandplate.Weposethreeversionsofthisproblem,eachdisplaying somewhatdifferentphysics.Ineachcase,theboundarycondition U=0onthesurrounding boxmustbeimposedinordertoobtainauniquesolution. 1) For the simplest version,assume that the platesare very thin conductivesheets, with the top sheet maintained at 100V, and the bottom at ‚àí100V. Because the sheets are conductors,theymustbeequipotentialsurfaces,andsoabatterycouldmaintainthem attheseconstantvoltages.WriteormodifythegivenprogramtosolveLaplace‚Äôsequation withfixedvoltageplates. 2) Forthenextversionofthisproblem,assumethattheplatesarecomposedofalineof dielectricmaterialwithuniformchargedensities ùúåonthetop,and ‚àíùúåonthebottom. SolvePoisson‚Äôsequation(21.3)intheregionincludingtheplates,andLaplace‚Äôsequation elsewhere.Experimentuntilyoufindanumericalvaluefor ùúåthatgivesapotentialsim- ilartothatshowninFigure21.5forplateswithfixedvoltages. 3) For the final version of this problem, investigatehow the charges on a capacitorwith finite-thickness conducting plates (Figure 21.6) distribute themselves. Because the platesareconductors,theyarestillequipotentialsurfacesat100and ‚àí100V,onlynow you should make them have a thickness of at least 2 Œî(so we can see the difference betweenthepotentialnearthetopandthebottomsurfacesoftheplates).Suchbeing the case, solve Laplace‚Äôs equation (21.4) to determine U(x,y).O n c ew eh a v e U(x,y), substitute it into Poisson‚Äôs equation (21.3), and determine how the charge density 100 V ‚Äì100 V (X, Y)dw L0 20406080100 020406080100‚Äì1000100 V(x, y) x y Figure 21.4 Left: A simple model of a parallel-plate capacitor within a box. A realistic model would have the plates close together, in order to condense the Ô¨Åeld, and the enclosing grounded box would be so large that it has no effect on the Ô¨Åeld near the capacitor. Right: A numerical solution for the electric potential for this geometry. The projection on the xyplane gives the equipotential lines. 448 21 PDE Review, Electrostatics and Relaxation 01020 3040010203040‚Äì100100 0V(x, y) x y Figure 21.5 Left: A visualization of the computed electric potential for a capacitor with Ô¨Ånite width plates. Right: A visualization of the charge distribution along one plate, determined by evaluating ‚àá2U(x,y)(courtesy of J. Wetzel). Note the ‚Äúlightening rod‚Äù effect of charge accumulating at corners and points. 100  V ‚Äì100  V+ ++ + + + + + ++ + + + +++ + + ++ + +  ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚Äì ‚ÄìFigure 21.6 A guess as to how charge may rearrange itself on Ô¨Ånite conducting plates. distributes itself along the top and bottom surfaces of the plates. Hint: As the electric field is no longer uniform, we know that the charge distribution also will no longer beuniform.Inaddition,becausetheelectricfieldnowextendsbeyondtheendsofthe capacitor,andbecausefieldlinesbeginandendoncharge,somechargemayendupon theedgesandoutersurfacesoftheplates(Figure21.6). 4) ThenumericalsolutiontoourPDEcanbeappliedtoarbitraryboundaryconditions.The twoboundaryconditionstoexplorearetriangularandsinusoidal: U(x)={200x‚àïùë§,x‚â§ùë§‚àï2, 100(1‚àíx‚àïùë§),x‚â•ùë§‚àï2,orU(x)=100sin( 2ùúãx ùë§) . 5)Square conductors: Youhavedesignedapieceofequipmentconsistingofasmallmetal boxat100Vwithinalargergroundedone(Figure21.7).Youfindthatsparkingoccurs betweentheboxes,whichmeansthattheelectricfieldistoolarge.Youneedtodeter- minewherethefieldisgreatestsothatyoucanchangethegeometryandeliminatethe sparking.Modifytheprogramtosatisfytheseboundaryconditions,anddeterminethe field between the boxes. Gauss‚Äôs law tells us that the field vanishes within the inner box because it contains no charge. Plot the potential and equipotential surfaces, and sketch in the electric field lines. Deduce where the electric field is most intense, and thenredesigntheequipmenttoreducethefield. 6)Cracked cylindrical capacitor: Youhavedesignedthecylindricalcapacitorcontain- ing a long, outer cylinder surrounding a thin, inner cylinder (Figure 21.7 right). The cylindershaveasmallcrackintheminordertoconnectthemtothebatterythatmain- tainstheinnercylinderat ‚àí100V,andtheoutercylinderat100V.Determinehowthis smallcrackaffectsthefieldconfiguration.Inorderforauniquesolutiontoexist,place bothcylinderswithinalarge,groundedbox.",7513
21.4.1 Implementation. 21.6 Code Listings,"21.5 Electric Field Visualization 449 Figure 21.7 Left: The geometry of a capacitor formed by placing two long, square cylinders within each other. Right:T h e geometry of a capacitor formed by placing two long, circular cylinders within each other. The cylinders are cracked on the side so that wires can enter the region.100  V‚Äì100  V100  V 21.4.1 Implementation In Listing 21.1, we present the code LaplaceLine.py that solves the square-wire problem (Figure 21.1) and produces the visualization there. Here, we have kept the codesimplebysettingthelengthofthebox L=NmaxŒî=100,andbytaking Œî=1: U(i,Nmax)=99(top),U(1,j)=0(left), U(Nmax,j)=0(right),U(i,1)=0(bottom).(21.36) 1) Writeormodify LaplaceLine.py tofindtheelectricpotentialforyourchoiceofcapacitor. 2) Start by having your program undertake 1000 iterations. Examine how the potential changesinsomekeylocationsasyouiteratetowardasolution. 3) Repeattheprocessfordifferentstepsizes Œî,anddrawconclusionsregardingthestability andaccuracyofthesolution.Keepinmindthatthisisasimplealgorithm,andsomay requiremanyiterationsforhighprecision. 4) Onceyourprogramproducesreliablesolutions,modifyitsothatitstopsiteratingonce convergenceisreached,orifthenumberofiterationsbecomestoolarge.Ratherthan trying to discern small changes in highly compressed surface plots, use a numerical measureofprecision,forexample, trace=‚àë i|U[i,i] |,thatsamplesthesolutionalong thediagonal.Youshouldbeabletoobtainchangesinthetracethatarelessthan1part in104.The breakcommandora whileloopisusefulforthistypeoftest. 5) Equation (21.35) expresses the successive overrelaxation technique in which conver- genceisacceleratedbyusingajudiciouschoiceof ùúî.Determinebytrialanderrorthe bestvalueof ùúî.Thisshouldletyoudoublethespeedofthealgorithm. 6) Nowthatyourcodeisaccurate,modifyittosimulateamorerealisticcapacitorinwhich the plate separation is approximately1 10of the plate length. You should find the field morecondensedandmoreuniformbetweentheplates. 7) Ifyouareworkingwiththewire-in-the-boxproblem,compareyournumericalsolution totheanalyticone(21.18).Donotbesurprisedifyouneedtosumthousandsofterms beforetheanalyticsolutionconverges. 21.5 Electric Field Visualization Createa2Dplotoftheequipotentialsurfaces.Youmaywanttostartwithacrude,hand-(or mouse-)drawnsketchoftheelectricfieldascurvesorthogonaltotheequipotentiallines. Wecandobetterthanthat.Because E=‚àí ‚àáU(x,y)=‚àíùúïU(x,y) ùúïxÃÇ ùúñx‚àíùúïU(x,y) ùúïyÃÇ ùúñy, (21.37) 450 21 PDE Review, Electrostatics and Relaxation 05 1 0 1 5 Equipotential lines Electric field linesContours of constant potential and electric field lines for the parallel plate capacitor 20 25 30 35 40 45 500510152025 Y X3035404550 Figure 21.8 Computed equipotential surfaces and electric Ô¨Åeld lines for a realistic capacitor. itissimpletocalculatethefield.Therefore,justusethecentral-differenceapproximation forthederivativetodeterminethefield,forexample: Ex‚âÉU(x+Œî,y)‚àíU(x‚àíŒî,y) 2Œî=Ui+1,j‚àíUi‚àí1,j 2Œî. (21.38) Onceyouhaveadatafilecontainingthevectorfield,itcanbevisualizedbyplottingarrows ofvaryinglengthsanddirections,orwithjustlinesasinFigure21.8. 21.6 Code Listings Listing 21.1 LaplaceLine.py solvesLaplace‚Äôsequationviarelaxation.Variousparame- tersshouldbeadjustedforanaccuratesolution. 1# LaplaceLine .py: Matplotlib , Solve Laplace ‚Äôs eqtn in square importmatplotlib.pylab as p, numpy frommpl_toolkits.mplot3d importAxes3D; fromnumpyimport ‚àó; 5 Nmax = 100; Niter = 50 V = zeros ((Nmax, Nmax) , float) print(\""Working hard, wait for the figure while I count to 60\"" ) 9 forkin range (0 , Nmax ‚àí1): V[0,k] = 100.0 # Line at 100V for iter in range (Niter): if iter percent10 == 0: print(iter) 13foriin range (1 , Nmax ‚àí2): forjin range (1 ,Nmax ‚àí2): V[i,j] = 0.25 ‚àó(V[i+1,j]+V[i ‚àí1,j]+V[i , j+1]+V[i ,j ‚àí1]) print(\""iter, V[Nmax/5,Nmax/5]\"" ,iter, V[Nmax/5,Nmax/5]) 21.6 Code Listings 451 17x=range(0, 50, 2); y = range(0, 50, 2) X, Y = p.meshgrid(x,y) deffunctz(V): #V ( x , y ) 21z=V [ X , Y ] returnz Z=f u n c t z( V ) 25fig = p.figure() # Create figure ax = Axes3D(fig) #P l o ta x e s ax.plot_wireframe(X, Y, Z, color = ‚Äôr‚Äô) # Red wireframe ax.set_xlabel( ‚ÄôX‚Äô); ax.set_ylabel( ‚ÄôY‚Äô); ax.set_zlabel( ‚ÄôV(x,y)‚Äô ) 29ax.set_title( ‚ÄôPotential within Square V(x=0)=100V (Rotatable)‚Äô ) p.show() # Show f i g",4232
Chapter 22 Heat Flow and Leapfrogging. 22.2.2 Implementation,"452 22 Heat Flow and Leapfrogging This chapter introduces the time-stepping (leapfrog) method for solving a PDE on a space-time lattice. We use it, and the more precise Crank‚ÄìNicolson algorithm, to solve the heat equation. Time-stepping is simple, yet powerful, and we will use it again and again when solving wave equations . Problem Youaregivenanaluminumbaroflength L=1mandwidth ùë§thatisinitially at100‚àòC(Figure22.1).Determinehowthetemperaturevariesalongthelengthofthebar, aftertheendsareplacedinicewaterat0‚àòC.Assumethatthelengthofthebarisinsulated, butnotitsends. 22.1 The Parabolic Heat Equation It‚Äôs a basic fact of nature that heat flows from hot to cold, that is, from regions of high temperaturetoregionsoflowtemperature.Weexpressthismathematicallybystatingthat therateofthevectorheatflow H,throughamaterial,isproportionaltothegradientofthe temperature Tacrossthematerial: H=‚àíK‚àáT(x,t), (22.1) whereKisthethermalconductivityofthematerial.Thetotalamountofheat Q(t)inthe material,atanyonetime,isproportionaltotheintegralofthetemperatureoverthemate- rial‚Äôsvolume: Q(t)=‚à´dxCùúå(x)T(x,t), (22.2) whereCis the specific heat of the material, and ùúåis its density. Because energy is con- served,therateofdecreaseof Q,withtime,mustequaltheamountofheatflowingoutof thematerial.Applyingenergybalanceleadstothe heatequation : ùúïT(x,t) ùúït=K Cùúå‚àá2T(x,t). (22.3) ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 22.1 The Parabolic Heat Equation 453 Figure 22.1 A metallic bar insulated along its length with its ends in contact with ice. The bar is dark and the insulation is of lighter color. 100 ¬∞C Lw0¬∞ 0¬∞ Theheatequation(22.3)isa parabolicPDEwithspaceandtimeasindependentvariables. Thespecificationofthisproblemimpliesthatthereisnotemperaturevariationindirections perpendicular to the bar, and so for our problem, we need to only consider one spatial coordinate, x,alongthelengthofthebar: ùúïT(x,t) ùúït=K Cùúåùúï2T(x,t) ùúïx2. (22.4) Asgiven,theinitialtemperatureofthebarandtheboundaryconditionsare: T(x,t=0)=100‚àòC,T(x=0,t)=T(x=L,t)‚â°0‚àòC. (22.5) 22.1.1 Solution as Analytic Expansion AnalogoustoLaplace‚Äôsequation,theanalyticsolutionstartswiththeassumptionthatthe solutionseparatesintotheproductoffunctionsofspaceandtime: T(x,t)=X(x)ÓâÄ(t). (22.6) When (22.6) is substituted into the heat equation (22.4), and the resulting equation is dividedby X(x)ÓâÄ(t),twononcoupledODE‚Äôsresult: d2X(x) dx2+k2X(x)=0,dÓâÄ(t) dt+k2C CùúåÓâÄ(t)=0, (22.7) wherekisaconstantstilltobedetermined.Theboundaryconditionthatthetemperature equalszeroat x=0requiresasinefunctionfor X: X(x)=Asinkx. (22.8) Theboundaryconditionthatthetemperatureequalszeroat x=Lrequiresthesinefunction tovanishthere,andso: sinkL=0‚áík=kn=nùúã‚àïL,n=1,2,‚Ä¶. (22.9) Thefunctionoftimecanbeagrowingordecayingexponential.Tobephysicallyreasonable (notblowup),itmustbeadecayingexponentialwith kintheexponent: ÓâÄ(t)=e‚àík2 nt‚àï(Cùúå), (22.10) ‚áíT(x,t)=Ansinknxe‚àík2 nt‚àï(Cùúå), (22.11) wherenmaybeanyinteger,and Anisanarbitraryconstant.Since(22.4)isalinearequation, the most general solution is a linear superposition of Xn(x)Tn(t)products for all values ofn: T(x,t)=‚àû‚àë n=1Ansinknxe‚àík2 nt‚àï(Cùúå). (22.12) 454 22 Heat Flow and Leapfrogging Thecoefficients Anaredeterminedbytheinitialconditionthatattime t=0,theentirebar hastemperature T=100‚àòC: T(x,t=0)=100‚áí‚àû‚àë n=1Ansinknx=100. (22.13) Projectingthesinefunctionsdetermines An=4T0‚àïnùúãfornodd,andso: T(x,t)=‚àû‚àë n=1,3,‚Ä¶4T0 nùúãsinknxe‚àík2 nKt‚àï(Cùúå). (22.14) 22.2 Time Stepping (Leapfrog) Algorithm As we did with Laplace‚Äôs equation, the numerical solution is based on converting the differential equation to a finite difference (or just ‚Äúdifference‚Äù) equation. We discretize spaceandtimeonthelatticeinFigure22.2,andseeksolutionsonthelatticesites.Thehor- izontal nodes with white centers correspond to the known values of the temperature for theinitialtime,whiletheverticalwhitenodescorrespondtothefixedtemperaturealong theboundaries.Ifwe alsoknewthetemperaturefortimesalongthebottomrow,thenwe couldusearelaxationalgorithm,aswedidforLaplace‚Äôsequation.However,withonlythe toprowknown,weshallendupwithanalgorithmthatstepsforwardintimeonerowata time,asinthechildren‚Äôsgame leapfrog. AsisoftenthecasewithPDEs,thealgorithmiscustomizedfortheequationbeingsolved, and for the constraints imposed by the particular set of initial and boundary conditions. Withonlyonerowoftimestostartwith,weuseaforward-differenceapproximationforthe timederivativeofthetemperature: ùúïT(x,t) ùúït‚âÉT(x,t+Œît)‚àíT(x,t) Œît. (22.15) Becauseweknowthespatialvariationofthetemperaturealongtheentiretoprow,andthe left and right sides, we are less constrained with the space derivative than with the time derivative.Consequently,aswedidwiththeLaplaceequation,weusethemoreaccurate central-differenceapproximationforthespacederivative: ùúï2T(x,t) ùúïx2‚âÉT(x+Œîx,t)+T(x‚àíŒîx,t)‚àí2T(x,t) (Œîx)2. (22.16) x ti ‚Äì 1,ji  + 1,j i,j + 1i,jFigure 22.2 The algorithm for the heat equation in which the temperature, at the location x=iŒîxand timet=(j+1)Œît, is computed from the temperature values at three points from an earlier time. The nodes with white centers correspond to known initial and boundary conditions. (The boundaries are placed artiÔ¨Åcially close for illustrative purposes.) 22.2 Time Stepping (Leapfrog) Algorithm 455 Figure 22.3 A visualization of a numerical calculation of the temperature versus position and versus time. 8080 400 1000 tT x Substitutionoftheseapproximationsinto(22.4)yieldstheheatdifferenceequation: T(x,t+Œît)‚àíT(x,t) Œît=K CùúåT(x+Œîx,t)+T(x‚àíŒîx,t)‚àí2T(x,t) Œîx2. (22.17) Wereorder(22.17)intoaforminwhich Tcanbesteppedforwardin t: Ti,j+1=Ti,j+ùúÇ[Ti+1,j+Ti‚àí1,j‚àí2Ti,j],ùúÇ =KŒît CùúåŒîx2. (22.18) Here,x=iŒîxandt=jŒît.Thisalgorithmis explicitbecauseitprovidesasolutioninterms ofknownvaluesofthetemperature.Ifwewantedtosolveforthetemperatureatalllattice sites in Figure 22.2 simultaneously, then we would be using an implicitalgorithm. With atimesteppingalgorithm,weneedtokeeptrackofonlyfourtemperatures.Asindicated in Figure 22.2, the temperature at space-time point (i,j+1)is computed from the three temperature values at an earlier time j, and at adjacent space values i¬±1,i. We start the solutionatthetoprow,movingitforwardintimeforaslongaswewant,alwayskeeping thetemperatureattheendfixedat0K.Figure22.3showsofthetimeandspacedependence ofthesolution. 22.2.1 Von Neumann Stability Condition Whenthedifference-equationversionofaPDEissolved,thehopeisthatitssolutionisa goodapproximationtothesolutionofthePDE.Ifthesolutiontothedifference-equation diverges, then we don‚Äôt have any solution; but if it does converge, then we should feel confident that we have a good solution to the PDE.1ThevonNeumannstabilityanalysis telluswhatweneeddotogetagoodsolution[Press etal.,2007;Courant etal.,1928].The analysisisbasedontheassumptionthatafterthe jthtime-step,theapproximatesolution hastheform: Ti,j=ùúâ(k)jeIkiŒîx, (22.19) wherex=iŒîx,t=jŒît,andI=‚àö ‚àí1 istheimaginarynumber.Theconstant kin(23.24) is an unknown wave vector (2 ùúã‚àïùúÜ), andùúâ(k)is an unknown complex function. We view (22.19)asafunctionthatoscillatesinspace(theexponential),withtheamplitudeor ampli- ficationfactor ùúâ(k)jthatgetsmultipliedbythepowerof ùúâforeachtimestep.Stabilityofthe solutionthenrequires |ùúâ(k)|<1,elsethesolutionwouldgrowintime[Press etal.,2007; 1 Well,inthecaseofshockwaves,asinChapter25,divergencesmaynotbesuchabadthing.",7368
22.4 The CrankNicolson Algorithm,"456 22 Heat Flow and Leapfrogging Ancona,2002].Tosolvefortheamplitude,wesubstitute(22.19)intothedifferenceequation (22.18): ùúâj+1eikmŒîx=ùúâjeikmŒîx+ùúÇ[ùúâjeik(m+1)Œîx+ùúâjeik(m‚àí1)Œîx‚àí2ùúâjeikmŒîx]. Aftercancelingacommonfactor,itiseasytosolvefor ùúâ(k): ùúâ(k)=1+2ùúÇ[cos(kŒîx)‚àí1]. (22.20) Inorderfor |ùúâ(k)|<1forallpossible kvalues,wemusthave: ùúÇ=KŒît CùúåŒîx2<1 2. (22.21) Thisequationtellsusthatifwemakethetimestep Œîtsmaller,wewillalwaysimprovethe stability,asonewouldexpect.Butifwemakethespacestep Œîxsmaller,withoutaconcor- dantquadratic increaseinthetimestep,wewillworsenthestability. 22.2.2 Implementation Recallthatwewanttosolveforthetemperaturedistributionwithinanaluminumbarof lengthL=1m,subjecttotheboundaryandinitialconditions: T(x=0,t)=T(x=L,t)=0‚àòC,T(x,t=0)=100‚àòC. (22.22) Thethermalconductivity,specificheat,anddensityforAlare: K=237W/(mK) ,C=900J/(kgK) ,ùúå=2700kg/m3. (22.23) 1) Writeaprogram,ormodify EqHeat.pyinListing22.1,tosolvetheheatequation. 2) Definea2Darray T[101,2]forthetemperatureasafunctionofspaceandtime.Thefirst indexisforthe100spacedivisionsofthebar,andthesecondindexisforpresentand pasttimes(becauseyoumayhavetomakethousandsoftimesteps,yousavememoryby savingonlytwotimes). 3) Fortime t=0(j=1),initialize Tsothatallpointsonthebar,excepttheends,areat100. Setthetemperatureoftheendsto0. 4) Apply(22.15)toobtainthetemperatureatthenexttimestep. 5) Assignthepresenttimevaluesofthetemperaturetothepastvalues: T[i,1] = T[i,2], i = 1, . . . , 101. 6) Startwith50timesteps.Onceyouareconfidenttheprogramisrunningproperly,use thousandsofstepstoseethebarcoolsmoothlywithtime.Forapproximatelyevery500 timesteps,printthetimeandtemperaturealongthebar. 22.2.3 Assessment and Visualization 1) Check that your program gives a temperature distribution that varies smoothly with time,thatsatisfiestheboundaryconditions,andthatreachesequilibrium.Youmayhave tovarythetimeandspacestepstoobtainstablesolutions. 2) Compare the analytic and numeric solutions (and the wall times needed to com- pute them). If the solutions differ, suspect the one that does not appear smooth and continuous. 3) Makeasurfaceplotoftemperature versuspositionand versustime. 22.3 Newton‚Äôs Radiative Cooling 457 Figure 22.4 Temperature versus position and time when two bars at differing temperatures are placed in contact at t=0. The projected contours show the isotherms. 0 40 80 02040050100 xtT(x, t) 4) Plotthe isotherms(contoursofconstanttemperature). 5) Createananimationthatshowsthetemperatureoftheentirebarasafunctionoftime. Ourcode EqHeatAnimate.py intheonlinecodesdirectorydoesthatwiththeVisualpack- age. 6)Stability test: Verifythestabilitycondition(22.21)byobservinghowthetemperature distributiondivergesif ùúÇ>1 4. 7)Material dependence: Repeatthecalculationforiron.Notethatthestabilitycondition requiresyoutochangethesizeofthetimestep. 8)Two bars in contact: Two identical bars, 0.25m long, are placed in end-to-end con- tact,withtheirotherendskeptat0‚àòC.Oneisinitiallyat100‚àòC,andtheotherat50‚àòC. Determinehowthetemperaturevarieswithtimeandlocation(Figure22.4). 22.3 Newton‚Äôs Radiative Cooling Imaginenow,abarincontactwithanenvironmentatatemperature Te.Newton‚Äô sla wof coolinggivestherateoftemperaturechange,asaresultofradiation,as: ùúïT ùúït=‚àíh(T‚àíTe), (22.24) withhapositiveconstant.Includingradiativecoolingandleavingofftheconstantmodifies theheatequationto: ùúïT(x,t) ùúït=K Cùúåùúï2T ùúï2x‚àíhT(x,t). (22.25) 1) ModifytheheatequationalgorithmtoincludeNewton‚Äôscooling. 2) Comparethecoolingofaradiatingbarwiththatoftheinsulatedbar. 3) Solveforconductiveandradiativeheatflowwithina2Drectangularironplatewhichis initiallyatatemperatureof100‚àòC.Threesidesaremaintainedat100‚àòC,whilethetop isplacedincontactwithicewaterat0‚àòC. a) Make separate surface plots of T(x,y=fixed,t)andT(x=fixed,y,t),o ras e r i e so f plotsofT(x,y,t=fixed)forvarious tvalues. b) Afteranequilibriumisreached,makeaplotoftheisotherms T(x,y,t=‚àû ). 458 22 Heat Flow and Leapfrogging 4) Sometimes,anequilibriumisreachedinwhichthetemperaturenolongerchangesasa functionoftime.Inthiscase,theheatequation(22.3)takestheform: ‚àá2T(x,t)=0. (22.26) This is the same as Laplace‚Äôsequation,whichis studied in Section 21.4.1,and can be solvedusingthesame relaxationalgorithmdevelopedthere.Andso,solveforisotherms withina2Drectangularironplateinwhichthreesidesaremaintainedat100‚àòC,while thefourthside,remainingincontactwithicewater,at0‚àòC. 5) Compute the rate of heat flow from the center to the surface of a sphere of constant thermalconductivity.Thecenterofthesphereiskeptat0‚àòCandthesurfaceiskeptat 100‚àòC. 6) Aspherewithconstantthermalconductivityisinitiallyat0‚àòC,andisthenplacedina heatbathof100‚àòC.Computethetemperatureprofileofthesphereasafunctionoftime. 7) A composite sphere is composed of a material of high thermal conductivity up to its middle,and low conductivityfrom its middleto its outside. Compute the rate of heat flowfromthecentertothesurfaceofasphere,ifthecenteriskeptat0‚àòCandthesurface iskeptat100‚àòC. 22.4 The Crank‚ÄìNicolson Algorithm TheCrank‚ÄìNicolsonalgorithmprovidesahigherdegreeofprecisionfortheheatequation (22.3) than the simple leapfrog method [Crank and Nicolson, 1946]. The algorithm calculates the time derivative with a central-difference approximation, in contrast to the forward-differenceapproximationusedpreviously.Inordertoavoidintroducingerrorfor theinitialtimestep,whereonlyasingletimevalueisknown,themethodusesa splittime step,2sothattimeisadvancedfromtime ttot+Œît‚àï2: ùúïT ùúït( x,t+Œît 2) ‚âÉT(x,t+Œît)‚àíT(x,t) Œît+O(Œît2). (22.27) Yes,weknowthatthislooksjustliketheforward-differenceapproximationforthederiva- tiveattime t+Œît,forwhichitwouldbeabadapproximation;regardless,itisabetter,but morecomplicated,approximationforthederivativeattime t+Œît‚àï2.Likewise,in(22.15), wegavethecentral-differenceapproximationforthesecondspacederivativefortime t.For t=t+Œît‚àï2,thatbecomes: 2(Œîx)2ùúï2T ùúïx2( x,t+Œît 2) ‚âÉ [T(x‚àíŒîx,t)‚àí2T(x,t)+T(x+Œîx,t)] +[T(x‚àíŒîx,t+Œît)‚àí2T(x,t+Œît)+T(x+Œîx,t+Œît)]+O(Œîx2). Intermsoftheseexpressions,theheatdifferenceequationis: Ti,j+1‚àíTi,j=ùúÇ 2[Ti‚àí1,j+1‚àí2Ti,j+1+Ti+1,j+1+Ti‚àí1,j‚àí2Ti,j+Ti+1,j], x=iŒîx,t=jŒît,ùúÇ=KŒît CùúåŒîx2. (22.28) 2 InChapter24,wedevelopsplit-timealgorithmsforsolutiontotheSchr√∂dingerequationandMaxwell‚Äôs equations. 22.4 The Crank‚ÄìNicolson Algorithm 459 Wegrouptogethertermsinvolvingthesametemperature,toobtainanequationwithfuture timesontheLHSandpresenttimesontheRHS: ‚àíTi‚àí1,j+1+( 2 ùúÇ+2) Ti,j+1‚àíTi+1,j+1=Ti‚àí1,j+( 2 ùúÇ‚àí2) Ti,j+Ti+1,j.(22.29) This equation represents an implicitscheme for the temperature Ti,j, where ‚Äúimplicit‚Äù means that we must solve simultaneous equations to obtain the solution at current ( j) and future ( j+1) times. In contrast, an explicitscheme uses the solution at current and past times to obtain it at future times. We start with the initial temperature distribution throughoutallofspace,theboundaryconditionsattheendsofthebarforalltimes,and theapproximatevaluesfromthefirstderivative: Ti,0,(known),T0,j,(known),TN,j,(known), T0,j+1=T0,j=0,TN,j+1=0,TN,j=0.(22.30) Werearrange(22.29)sothatwecanusetheseknownvaluesof Ttostepthe j=0solution forwardintime,andexpressitasasetofsimultaneouslinearequations: ‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£( 2 ùúÇ+2) ‚àí1 ‚àí1( 2 ùúÇ+2) ‚àí1 ‚àí1( 2 ùúÇ+2) ‚àí1 ......... ‚àí1( 2 ùúÇ+2) ‚àí1 ‚àí1( 2 ùúÇ+2)‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£T1,j+1 T2,j+1 T3,j+1 ... Tn‚àí2,j+1 Tn‚àí1,j+1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶ =‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£T0,j+1+T0,j+( 2 ùúÇ‚àí2) T1,j+T2,j T1,j+( 2 ùúÇ‚àí2) T2,j+T3,j T2,j+( 2 ùúÇ‚àí2) T3,j+T4,j ... Tn‚àí3,j+( 2 ùúÇ‚àí2) Tn‚àí2,j+Tn‚àí1,j Tn‚àí2,j+( 2 ùúÇ‚àí2) Tn‚àí1,j+Tn,j+Tn,j+1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (22.31) Observe that the T‚Äôs on the RHS are all at the present time jfor various positions, and atfuturetime j+1forthetwoends(whose Tsareknownforalltimesviatheboundary conditions).Westartthealgorithmwiththe Ti,j=0valuesoftheinitialconditions,thensolve amatrixequationtoobtain Ti,j=1.Oncewehavethatsolution,weknowallthetermsonthe RHSoftheequations( j=1throughoutthebar,and j=2attheends),andsocanrepeat thesolutionofthematrixequationstoobtainthetemperaturethroughoutthebarfor j=2. Soagain,wetime-stepforward,onlynowwesolvematrixequationsateachstep.Thatgives usthespatialsolutionatalllocationssimultaneously.",8095
22.5 Code Listings,"460 22 Heat Flow and Leapfrogging NotonlyistheCrank-Nicolsonmethodmoreprecisethanthelow-ordertime-stepping method, but it also is stable for all values of ŒîtandŒîx. To prove that, we apply the von Neumann stability analysis, discussed in Section 22.2.1 to the Crank-Nicolson algorithm bysubstituting(22.18)into(22.29).Thisdeterminestheamplitude: ùúâ(k)=1‚àí2ùúÇsin2(kŒîx‚àï2) 1+2ùúÇsin2(kŒîx‚àï2). (22.32) Becausethenumeratorisalwayssmallerthanthedenominator, |ùúâ|‚â§1forallŒît,Œîx,and k,andsowealwayshavestability. 22.4.1 Solution via Tridiagonal Matrix ‚äô The Crank-Nicolson equations (22.31) are in the standard form, [A]x=b, for linear equations,andsowecanuseourmatrixmethodstosolvethem.However,thecoefficient matrix[A]istridiagonal(zeroelementsexceptforthemaindiagonalandtwodiagonalson eithersideofit): ‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùd1c100¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 a2d2c20¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 0a3d3c3¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0000 ¬∑¬∑¬∑aN‚àí1dN‚àí1cN‚àí1 0000 ¬∑¬∑¬∑0aNdN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùx1 x2 x3 ... xN‚àí1 xN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†=‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùb1 b2 b3 ... bN‚àí1 bN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†, Consequently,amorerobustandfastersolutionexists,anditmakesthisimplicitmethodas fastastheexplicitones.Seeingthattridiagonalsystemsoccurfrequently,wenowoutline thespecializedtechniqueforsolvingthem[Press etal.,2007].If westorethematrixele- mentsai,jusingbothsubscripts,thenwewillneed N2locationsforelements,and N2oper- ations to access them. However, if the matrix is tridiagonal, we only need to store those elementsalong,above,andbelowthediagonals,{di} i=1,N,{ci} i=1,N,and{ai} i=1,N.Thesin- glesubscriptson ai,di,andcireducetheprocessingfrom N2to(3N‚àí2)elements. Thesolutiontothematrixequationmanipulatestheindividualequationsuntilthecoef- ficientmatrixisin uppertriangular form,withalltheelementsofthemaindiagonalequal to1.Westartbydividethefirstequationby d1,thensubtract a2timesthefirstequation, ‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éù1c1 d100¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 0d2‚àía2c1 d1c20¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 0a3d3c3¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 000 0 ¬∑¬∑¬∑aN‚àí1dN‚àí1cN‚àí1 000 0 ¬∑¬∑¬∑0aNdN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùx1 x2 x3 ... ‚ãÖ xN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†=‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùb1 d1 b2‚àía2b1 d1 b3 ... ‚ãÖ bN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†, 22.4 The Crank‚ÄìNicolson Algorithm 461 andthendividingthesecondequationbytheseconddiagonalelement, ‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éù1c1 d100 ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 01c2 d2‚àía2c1 a10¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 0a3d3c3¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 0 ¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ ¬∑¬∑¬∑ 00 0 0 aN‚àí1dN‚àí1cN‚àí1 00 0 0 ¬∑¬∑¬∑0aNdN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùx1 x2 x3 ... ‚ãÖ xN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†=‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùb1 d1 b2‚àía2b1 d1 d2‚àía2c1 d1 b3 ... ‚ãÖ bN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†. Assuming that we can repeat these steps without ever dividing by zero, the system of equationswillbereducedtouppertriangularform, ‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éù1h100¬∑¬∑¬∑0 01h20¬∑¬∑¬∑0 00 1h3¬∑¬∑¬∑0 0¬∑¬∑¬∑¬∑¬∑¬∑......¬∑¬∑¬∑ 00 0 0 ¬∑¬∑¬∑¬∑¬∑¬∑ 00 0 ¬∑¬∑¬∑01‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùx1 x2 x3 ... ‚ãÖ xN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†=‚éõ ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú ‚éú‚éùp1 p2 p3 ... ‚ãÖ pN‚éû ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü ‚éü‚é†, (22.33) whereh1=c1‚àïd1andp1=b1‚àïd1.Wethenrecurfortheotherelements: hi=ci di‚àíaihi‚àí1,pi=bi‚àíaipi‚àí1 di‚àíaihi‚àí1. (22.34) Finally,backsubstitutionleadstotheexplicitsolutionfortheunknowns: xi=pi‚àíhixi‚àí1;i=n‚àí1,n‚àí2,‚Ä¶,1,xN=pN. (22.35) InListing22.2,wegivetheprogram HeatCNTridiag.py thatsolvestheheatequationusing theCrank‚ÄìNicolsonalgorithmviaatriadiagonalreduction. 22.4.2 Crank‚ÄìNicolson Implementation 1) WriteaprogramusingtheCrank‚ÄìNicolsonmethodtosolveforheatflowinthemetal barofSection22.1. 2) Solvethelinearsystemofequations(22.31)usingeitherNumPyoraspecialtridiagonal algorithm. 3) Checkthestabilityofyoursolutionbychoosingdifferentvaluesforthetimeandspace steps. 4) Constructacontouredsurfaceplotoftemperature versuspositionandversustime. 5) Comparetheimplicitandexplicitalgorithmsusedinthischapterforrelativeprecision andspeed.Youmayassumethatastableanswerthatusesverysmalltimestepsisaccu- rate. 462 22 Heat Flow and Leapfrogging 22.5 Code Listings Listing 22.1 EqHeat.py solvesthesinglespacedimensionheatequationonalatticeby leapfroggingtheinitialconditionsforwardintime.Theparametersshouldbeadjusted. # EqHeat.py: solves heat equation via finite differences , 3 ‚àíDp l o t fromnumpyimport ‚àó;importmatplotlib.pylab as p 4frommpl_toolkits.mplot3d importAxes3D Nx = 101; Nt = 3000; Dx = 0.03; Dt = 0.9 kappa = 210.; C = 900.; rho = 2700. # Conductivity , specf heat , density 8T=z e r o s( ( N x , 2 ), float); Tpl = zeros((Nx, 31), float) print(\""Working, wait for figure after count to 10\"" ) forixin range (1, Nx ‚àí1): T[ix, 0] = 100.0; # Initial T 12T [ 0 , 0 ]=0 . 0; T [ 0 , 1 ]=0 . #1 s t&last T = 0 T[Nx‚àí1,0] = 0. ; T[Nx ‚àí1,1] = 0.0 cons = kappa/(C ‚àórho) ‚àóDt/(Dx ‚àóDx); m=1 # Counter 16fortin range (1, Nt): forixin range (1, Nx ‚àí1): T[ix, 1] = T[ix, 0] + cons ‚àó(T[ix+1, 0] + T[ix ‚àí1, 0]‚àí2.‚àóT[ix,0]) ift percent300 == 0 ort= =1 : # Every 300 steps 20 forixin range (1, Nx ‚àí1, 2): Tpl[ix, m] = T[ix, 1] print(m) m=m+1 forixin range (1, Nx ‚àí1): T[ix, 0] = T[ix, 1] 24x=list(range(1, Nx ‚àí1, 2)) # Plot alternate pts y=list(range(1, 30)) X, Y = p.meshgrid(x, y) 28deffunctz(Tpl): z=T p l [ X ,Y ] returnz 32Z=f u n c t z( T p l ) fig = p.figure() # Create figure ax = Axes3D(fig) ax.plot_wireframe(X, Y, Z, color = ‚Äôr‚Äô) 36ax.set_xlabel( ‚ÄôPosition‚Äô ) ax.set_ylabel( ‚Äôtime‚Äô) ax.set_zlabel( ‚ÄôTemperature‚Äô ) p.show() 40print(\""finished\"" ) Listing 22.2 HeatCNTridiag.py solves the heat equation via the Crank-Nicolson methodandatridiagonalmatrixalgorithm. # HeatCNTridiag .py : solution of heat eqtn via CN method 2 \""\""\"" Dirichlet boundary conditions surrounding four walls Domain dimensions: WxH, with 2 triangles per square Based on FEM2DL_Box Matlab program in Polycarpou, Intro to the Finite 6Element Method in Electromagnetics, Morgan &Claypool (2006) \""\""\"" importmatplotlib.pylab as p; frommpl_toolkits.mplot3d importAxes3D ; 10fromnumpyimport ‚àó; importnumpy; 14Max = 51; n = 50; m= 50 Ta = zeros((Max) , float); Tb=zeros((M a x), float); Tc= zeros((M a x), float) Td = zeros((Max) , float); a= zeros((M a x), float); b= zeros((M a x), float) c= z e r o s ( ( M a x ) , float); d= zeros((M a x), float); x= zeros((M a x), float) 22.5 Code Listings 463 18t= z e r o s ( ( M a x , M a x ) , float) defTridiag(a, d, c, b, Ta, Td, Tc, Tb, x, n): Max = 51 22h=z e r o s( ( M a x ), float) p=z e r o s (( M a x ), float) foriin range (1,n+1): a[i] =Ta[i] 26 b[i] =Tb[i] c[i] = Tc[i] d[i] =Td[i] h[1] = c[1]/d[1] 30p[1] = b[1]/d[1] foriin range (2,n+1): h[i] = c[i] / (d[i] ‚àía[i] ‚àóh[i‚àí1]) p[i] = (b[i] ‚àía[i] ‚àóp[i‚àí1]) / (d[i] ‚àía[i] ‚àóh[i‚àí1]) 34x[n] = p[n] foriin range (n‚àí1, 1,‚àí1 ): x[i] =p[i] ‚àíh[i] ‚àóx[i+1] width = 1.0; height = 0.1; ct = 1.0 38foriin range (0, n): t[i,0] = 0.0 foriin range ( 1, m): t[0][i] = 0.0 h= w i d t h/ ( n ‚àí1) k = height / ( m ‚àí1) 42r= c t ‚àóct‚àók/(h ‚àóh) forjin range (1,m+1): t[1,j] = 0.0 46 t[n,j] = 0.0 #B C s foriin range ( 2, n): t[i][1] = sin( pi ‚àóh‚àói) # ICs foriin range (1, n+1): Td[i] = 2. + 2./r Td[1] = 1.; Td[n] = 1. 50foriin range (1,n ): Ta[i] = ‚àí1.0; Tc[i] = ‚àí1.0; # Off diagonal Ta[n‚àí1] = 0.0; Tc[1] = 0.0; Tb[1] = 0.0; Tb[n] = 0.0 print(\""I‚Äôm working hard, wait for fig while I count to 50\"" ) 54forjin range (2,m+1): print(j) foriin range (2,n): Tb[i] = t[i ‚àí1][j‚àí1] + t[i+1][j ‚àí1] \ +( 2 / r‚àí2)‚àót[i][j‚àí1] 58 Tridiag(a, d, c, b, Ta, Td, Tc, Tb, x, n) # Solve system foriin range (1, n+1): t[i][j] = x[i] print(\""Finished\"" ) x=list(range(1, m+1)) # Plot every other x 62y=list(range(1, n+1)) # every other y X, Y = p.meshgrid(x,y) deffunctz(t): # Potential 66z=t [ X ,Y ] returnz Z=f u n c t z(t) 70fig = p.figure() ax = Axes3D(fig) ax.plot_wireframe(X, Y, Z, color= ‚Äôr‚Äô) ax.set_xlabel( ‚Äôt‚Äô) 74ax.set_ylabel( ‚Äôx‚Äô) ax.set_zlabel( ‚ÄôT‚Äô) p.show() # Display figure",7706
Chapter 23 String and Membrane Waves. 23.2 TimeStepping Algorithm,"464 23 String and Membrane Waves In this chapter, and in Chapters 24 ‚Äì26, we explore PDE‚Äôs with wave-like solutions. Here we deal with 1D waves on strings, and 2D waves on membranes. In Chapter 24 we examine quantum wave packets and E&M waves, and in Chapter 25 we look at shock waves and solitary waves. The basic technique is the leapfrog algorithm that propagates the initial conditions forward in time, step by step. The numerical solutions let us include more physics than is possible with the familiar analytic treatments . 23.1 A Vibrating String‚Äôs Hyperbolic Wave Equation Recalltheelementaryphysicsdemonstrationinwhichastring,tieddownatbothends,is pluckedgently,andreleased,resultinginapulsethattravelsalongthestring. Problem Developanaccuratemodelforwavepropagationonastring,andseeifitcan producebothtravelingandstandingwaves. Consider a string of length Ltied down at both ends (Figure 23.1 left). The string has a constantdensity ùúåperunitlength,nofrictionalforcesactingonit,andatension Tthatis highenoughtoletusignoreanysaggingasaresultofgravity.Weassumethatthedisplace- mentofthestringfromitsrestposition, y(x,t),isonlyintheverticaldirection,andthatthe displacementisafunctionofthehorizontallocationalongthestring x,andthetime t. Toderivealinearequationofmotion,weassumethatthestring‚Äôsrelativedisplacement y(x,t)‚àïLand slope ùúïy‚àïùúïxare both small. In Figure 23.1 right, we isolate an infinitesimal sectionŒîxofthestring.Weseetherethatthedifferenceintheverticalcomponentsofthe tension,ateitherendofthestring,producestherestoringforcethatacceleratesthissection ofthestringupordown.ByapplyingNewton‚Äôslawstothissection,weobtainthefamiliar waveequation: ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 23.1 A Vibrating String‚Äôs Hyperbolic Wave Equation 465 LTT y(x,t) ŒîxŒîy Œ∏ x Figure 23.1 Left: A stretched string of length Ltied down at both ends. The vertical disturbance of the string from its equilibrium position is y(x,t).Right: A differential element of the string showing how the string‚Äôs displacement leads to the restoring force. ‚àë Fy=ùúåŒîxùúï2y ùúït2, (23.1) =TsinùúÉ(x+Œîx)‚àíTsinùúÉ(x) (23.2) =Tùúïy ùúïx||||x+Œîx‚àíTùúïy ùúïx||||x‚âÉTùúï2y ùúïx2, (23.3) ‚áíùúï2y(x,t) ùúïx2=1 c2ùúï2y(x,t) ùúït2,c=‚àö T ùúå. (23.4) Here,wehaveassumedthat ùúÉissmallenoughforsin ùúÉ‚âÉtanùúÉ=ùúïy‚àïùúïx.Theexistenceofthe twoindependentvariables, xandt,makes(23.4)aPDE.Theconstant chereisthevelocity with which a disturbance travels along the wave, and is seen to decrease for increasing density,andincreaseforincreasingtension.Notethatthis signalvelocityc isnotthesame asthevelocityofastringelement ùúïy‚àïùúït. Theinitialconditionforourproblemisthatthestringispluckedgentlyandreleased.We assumethatthepluckplacesthestringinatriangularshape,withthecenteroftriangle8 10 ofthewaydownthestring,andwithaheightof1: y(x,t=0)={ 1.25x‚àïL,x‚â§0.8L, (5‚àí5x‚àïL),x>0.8L,(initialcondition1) . (23.5) Because (23.4)is second-order in time, a second initial condition is needed to determine thesolution.Weinterpretthe‚Äúgentleness‚Äùoftheplucktomeanthatthestringisreleased fromrest: ùúïy ùúït(x,t=0)=0,(initialcondition2) . (23.6) Theboundaryconditionshavebothendsofthestringtieddownatalltimes: y(0,t)‚â°0,y(L,t)‚â°0,(boundaryconditions). (23.7) 23.1.1 Solution as Normal-Mode Expansion Theanalyticsolutionto(23.4)isobtainedviathefamiliarseparation-of-variablestechnique. Weassumethatthesolutionistheproductofafunctionofspaceandafunctionoftime: y(x,t)=X(x)T(t). (23.8) 466 23 String and Membrane Waves Wesubstitute(23.8)into(23.4),divideitby y(x,t),andareleftwithanequationthathasa solutiononlyiftherearesolutionstothetwoODEs: d2T(t) dt2+ùúî2T(t)=0,d2X(x) dx2+k2X(x)=0,kdef=ùúî c. (23.9) The angular frequency ùúîand the wave vector kare determined by demanding that the solutionssatisfytheboundaryconditions: X(x=0,t)=X(x=l,t)=0 (23.10) ‚áíXn(x)=Ansinknx,kn=ùúã(n+1) L,n=0,1,‚Ä¶. (23.11) Thetimesolutionis: Tn(t)=Cnsinùúînt+Dncosùúînt,ùúîn=nck0=n2ùúãc L, (23.12) whereùúînisthefrequencyofthe nthnormalmode .Theinitialcondition (23.5)ofzeroveloc- ity,ùúïy‚àïùúït(t=0)=0,requiresthe Cnvaluesin(23.12)tobezero.Puttingthepiecestogether, thenormal-modeare: yn(x,t)=sinknxcosùúînt,n=0,1,‚Ä¶. (23.13) Becausethewaveequation(23.4)islinearin y,theprincipleoflinearsuperpositionholds, andthemostgeneralsolutionforwavesonastringwithfixedendscanbewrittenasthe sumofnormalmodes: y(x,t)=‚àû‚àë n=0Bnsinknxcosùúînt. (23.14) (Wewillloselinearsuperpositiononceweincludenonlineartermsinthewaveequation.) The Fourier coefficient Bnis determined by the second initial condition (23.5), which describeshowthewaveisplucked: y(x,t=0)=‚àû‚àë nBnsinnk0x. (23.15) Wemultiplybothsidesbysin mk0x,substitutethevalueof y(x,0)from(23.5),andintegrate from0toLtoobtain: Bm=6.25sin(0.8mùúã) m2ùúã2. (23.16) YouwillbeaskedtocomparetheFourierseries(23.14)toyournumericalsolution.Whileit isinthenatureoftheapproximationthattheprecisionofthenumericalsolutiondepends onthechoiceofstepsize,itisalsorevealingtorealizethattheprecisionoftheso-called analyticsolutiondependsonsumminganinfinitenumberofterms,whichcanbesummed onlyapproximately. 23.2 Time-Stepping Algorithm Aswiththeheatequation,welookforasolution y(x,t)onlyfordiscretevaluesoftheinde- pendentvariables,inthiscase xandt(Figure23.2): x=iŒîx,i=1,‚Ä¶,Nx,t=jŒît,j=1,‚Ä¶,Nt, (23.17) y(x,t)=y(iŒîx,iŒît)def=yi,j. (23.18) 23.2 Time-Stepping Algorithm 467 Figure 23.2 The solutions of the wave equation for four earlier space-time points are used to obtain the solution at the present time. The boundary and initial conditions are indicated by the white-centered dots.X i, jti ‚Äì 1, j i + 1, ji, j ‚Äì 1 i, j + 1 Weseeksolutionsatthelatticesitesofthespace-timegridinFigure23.2.Thatbeingthe case, moving across a row corresponds to increasing xvalues along the string for a fixed time,whilemovingdownacolumncorrespondstoincreasingtimestepsforafixedposition. AlthoughthegridinFigure23.2maybesquare,wecannotusearelaxationtechniquelike wedidforthesolutionofLaplace‚Äôsequation,becausewedonotknowthesolutiononall foursides.Theboundaryconditionsdeterminethesolutionalongtherightandleftsides, whiletheinitialtimeconditiondeterminesthesolutionalongthetop,butnotthebottom. Aswiththeheatequation,weusethecentral-differenceapproximationto discretizethe waveequationintoadifferenceequation.First,weexpressthesecondderivativesinterms offinitedifferences: ùúï2y ùúït2‚âÉyi,j+1+yi,j‚àí1‚àí2yi,j (Œît)2,ùúï2y ùúïx2‚âÉyi+1,j+yi‚àí1,j‚àí2yi,j (Œîx)2. (23.19) Substituting(23.19)inthewaveequation(23.4)yieldsadifferenceequation: yi,j+1+yi,j‚àí1‚àí2yi,j c2(Œît)2=yi+1,j+yi‚àí1,j‚àí2yi,j (Œîx)2. (23.20) Noticethatthisequationcontainsthreetimevalues: j+1=thefuture, j=thepresent,and j‚àí1=the past. Consequently, we rearrange it into a form that permits us to predict the futuresolutionfromthepresentandpastsolutions: yi,j+1=2yi,j‚àíyi,j‚àí1+c2 c‚Ä≤2[yi+1,j+yi‚àí1,j‚àí2yi,j],c‚Ä≤def=Œîx Œît. (23.21) Herec‚Ä≤isacombinationofnumericalparameters,withthedimensionofvelocity,whose size relative to cdetermines the stability of the algorithm. As shown in Figure 23.2, the algorithm (23.21) propagates the wave from the two earlier times, jandj‚àí1, and from threenearbypositions, i‚àí1,i,andi+1,toalatertime, j+1,andasinglespaceposition, i. Westartthealgorithmwiththesolutionalongthetopmostrow,andthenmoveitdown one step at a time. If we save the solution for present times, then we only need to store threetimevaluesonthecomputer.Infact,becausethetimestepsmustbequitesmallto obtainhighprecision,youmaywanttostorethesolutiononlyforeveryfifthortenthtime forviewing. Initializingtherecurrencerelationisabittrickybecauseitrequiresdisplacementsfrom twoearliertimes,whereastheinitialconditionsareforonlyonetime.Nonetheless,therest",7607
23.3.1 Implementation and Assessment,"468 23 String and Membrane Waves ofthecondition(23.5),whencombinedwiththe central-difference approximation,letsus extrapolatetonegativetime: ùúïy ùúït(x,0)‚âÉy(x,Œît)‚àíy(x,‚àíŒît) 2Œît=0,‚áíyi,0=yi,2. (23.22) Herewetaketheinitialtimeas j=1,andsoj=0correspondsto t=‚àí Œît.Substitutingthis relationinto(23.21)yieldsfortheinitialstep: yi,2=yi,1+c2 2c‚Ä≤2[yi+1,1+yi‚àí1,1‚àí2yi,1](forj=2only). (23.23) Equation(23.23)usesthesolutionthroughoutallspaceattheinitialtime t=0topropagate (leapfrog)itforwardtoatime Œît.Subsequenttimestepsuse(23.21),andarecontinuedfor aslongasyoulike. Exercise Devise a procedure for solving for the wave equation for all times in just one step.Estimatehowmuchmemorywouldberequired. 23.3 von Neumann Stability Analysis As discussed in Section 22.2.1, our approximation of converting a PDE into a difference equationwillnotbeagoodapproachifthesolutiontothedifferenceequationisunstable. ThevonNeumannstabilityanalysis telluswhattodotogetagoodsolution.Theanalysisis basedontheassumptionthateigenmodesofthedifferenceequationhavetheform: yi,j=ùúâ(k)jeIkiŒîx, (23.24) wherex=iŒîx,t=jŒît,andI=‚àö ‚àí1istheimaginarynumber.Theconstant kin(23.24) is an unknown wave vector (2 ùúã‚àïùúÜ), andùúâ(k)is an unknown complex function. We view (23.24) as a function that oscillates in space (the exponential), with the amplitude or amplificationfactor ùúâ(k)jthatgetsmultipliedbyapowerof ùúâforeachtimestep.Stability ofthesolutionthenrequires |ùúâ(k)|<1,elsethesolutionwouldgrowintime[Press etal., 2007;Ancona,2002]. Exercise Substitute the presumed form for the eigenmode (23.24) into difference equation (23.21) being used as the algorithm, and solve for the amplitude ùúâ(k).Hint:i n Section22.2.1,wedothisexplicitlyfortheheatequation. Even though the application of the stability condition may get complicated, [Press etal., 2007;Courant etal.,1928]showthat |ùúâ(k)|<1,andthedifferenceequationsolutionwill thereforebestable,forthegeneralclassoftransportequationsif: c‚â§c‚Ä≤=Œîx‚àïŒît,(Courantcondition) . (23.25) Equation(23.25)meansthatthesolutiongetsbetterwithsmaller timesteps,butgetsworse forsmallerspacesteps(unlessyousimultaneouslymakethetimestepsmallertoo).Having differentsensitivitiestothetimeandspacestepsmayappearsurprisingbecausethewave equation(23.4)issymmetricin xandt,yetthesymmetryisbrokenbythenonsymmetric initialandboundaryconditions.",2306
23.4 Beyond The Simple Wave Equation. 23.7 Numerical Solution,"23.4 Beyond The Simple Wave Equation 469 In general, you should perform a stability analysis for every PDE you have to solve, although it can get complicated. Yet, even if you do not, the lesson here is that you may want to try different combinations ofŒîxandŒîtuntil a stable and reliable solution is obtained.Youmayexpect,nonetheless,thattherearechoicesfor ŒîxandŒîtforwhichthe numerical solution fails, and that simply decreasing an individual ŒîxorŒît, in the hope thatthiswillincreaseprecision,maynotimprovethesolution. 23.3.1 Implementation and Assessment The program EqStringMat.py in Listing 23.1 solves the wave equation for a string of lengthL=1m,withitsendsfixed,andwiththegentlypluckedinitialcondition.Notethat althoughouruseof L=1violatestheassumptionofsmalldisplacement, y‚àïL‚â™1;youmay wanttouse L=1000toberealistic.Thevaluesofdensityandtensionare ùúå=0.01kg/m, andT=40N,withthespacegridsetat101points,correspondingto Œî=0.01cm. 1) Solve the wave equation, and make a surface plot of displacement versustime and position. 2) Exploreanumberofspacestepandtimestepcombinations.Inparticular,trystepsthat satisfy, and that do not satisfy, the Courant condition (23.25). Does your exploration conformwiththestabilitycondition? 3) Comparetheanalyticandnumericsolutions,summingatleast200termsintheanalytic solution. 4) Usetheplottedtimedependencetoestimatethepeak‚Äôspropagationvelocity c.Compare thededuced cto(23.4). 5) Oursolutionofthewaveequationforapluckedstringleadstotheformationofawave packet that corresponds to the sum of multiple normal modes of the string. Solve the waveequationforastringinitiallyplacedinthesinglenormalmode(standingwave): y(x,t=0)=0.001 sin2 ùúãx,ùúïy ùúït(x,t=0)=0. (23.26) Seeifanormalmoderesultsandremains. 6) Observe the motion of a wave for initial conditions corresponding to the sum of two adjacentnormalmodes.Doesbeatingoccur? 23.4 Beyond The Simple Wave Equation The string problem we have investigated so far can be handled by both numerical and analytic techniques. We now wish to extend the theory to include some more realistic physics. These extensions have only numerical solutions . 23.4.1 Including Friction Plucked strings do not vibrate forever because the real world contains friction. Consider againtheelementsofastringbetween xandx+dxinFigure23.1right,butnowimagine that this element is moving in a viscous fluid such as air. An approximate model for the frictionalforcehasitpointinginadirectionoppositetotheverticalvelocityofthestring, 470 23 String and Membrane Waves t120 80 40 080400 xFigure 23.3 The vertical displacement as a function of position xand time tfor waves on a string when friction is included. proportionaltothatvelocity,andalsoproportionaltothelengthofthestringelement: Ff‚âÉ‚àí2ùúÖŒîxùúïy ùúït. (23.27) Here,ùúÖisaconstantthatisproportionaltotheviscosityofthemedium.Includingthisforce intheequationofmotionchangesthewaveequationto: ùúï2y ùúït2=c2ùúï2y ùúïx2‚àí2ùúÖ ùúåùúïy ùúït. (23.28) InFigure23.3,weshowtheresultingmotionofastringpluckedinthemiddlewhenfriction isincluded.Observehowtheinitialpluckbreaksupintowavestravelingtotherightandto theleft,thatthengetreflectedandinvertedbythefixedends.Sincethosepartsofthewave withthehighervelocityexperiencegreaterfriction,thepeaktendstogetsmoothedoutthe mostastimeprogresses. Exercise Generalizethealgorithmusedtosolvethewaveequationtonowincludefric- tion.Pickavalueof ùúÖlargeenoughtocauseanoticeabledampening,butnotsolargeasto stoptheoscillations.Asacheck,reversethesignof ùúÖandseeifthewavegrowsintime. 23.4.2 Including Variable Tension and Density Wehavederivedthepropagationvelocityforwavesonastringas c=‚àö T‚àïùúå.Thissaysthat wavesmoveslowerinregionsofhighdensity,andfasterinregionsofhightension.Ifthe densityofastringvaries,forinstance,byhavingtheendsthickerinordertosupportthe weightofthemiddle,then cwillnolongerbeaconstant,andourwaveequationwillneed to be extended. In addition, if the density increases, then so will the tension, because it takesgreatertensiontoaccelerateagreatermass.Ifgravityacts,thenwewillalsoexpect thetensionattheendsofthestringtobehigherthaninthemiddle,becausetheendsmust supporttheentireweightofthestring.",4108
23.4 Beyond The Simple Wave Equation. 23.7 Numerical Solution,"Toderivetheequationforwavemotionwithvariabledensityandtension,weagaincon- sidertheelementofastringshowninFigure23.1right.Ifwedonotassumethetension T isconstant,thenNewton‚Äôssecondlawgives: F=ma, (23.29) ùúï ùúïx[ T(x)ùúïy(x,t) ùúïx] Œîx=ùúå(x)Œîxùúï2u(x,t) ùúït2, (23.30) 23.4 Beyond The Simple Wave Equation 471 ùúïT(x) ùúïxùúïy(x,t) ùúïx+T(x)ùúï2y(x,t) ùúïx2=ùúå(x)ùúï2y(x,t) ùúït2. (23.31) Ifùúå(x)andT(x)areknownfunctions,thentheseequationscanbesolvedwithaslightmod- ificationofouralgorithm. InSection23.4.3,wewillsolveforthetensioninastationaryhangingstringwhengravity ispresent.Thosereadersinterestedinan alternate easier problem ,thatstillshowsthe newphysics,mayassumethatdensityandtensionareproportional: ùúå(x)=ùúå0eùõºx,T(x)=T0eùõºx. (23.32) Whilewewouldexpectthetensiontobegreaterinregionsofhigherdensity(moremass tomoveandsupport),beingproportionalisclearlyjustanapproximation.Substitutionof (23.32)into(23.31)yieldsthewaveequation: ùúï2y(x,t) ùúïx2+ùõºùúïy(x,t) ùúïx=1 c2ùúï2y(x,t) ùúït2,c2=T0 ùúå0. (23.33) Here,cisaconstantthatwouldbethewavevelocityif ùõº=0.Thisequationissimilarto thewaveequationwithfriction,onlynowthefirstderivativeiswithrespectto xandnott. The corresponding difference equation follows from using central-difference approxima- tionsforthederivatives: yi,j+1=2yi,j‚àíyi,j‚àí1+ùõºc2(Œît)2 2Œîx[yi+1,j‚àíyi,j]+c2 c‚Ä≤2[yi+1,j+yi‚àí1,j‚àí2yi,j], yi,2=yi,1+c2 c‚Ä≤2[yi+1,1+yi‚àí1,1‚àí2yi,1]+ùõºc2(Œît)2 2Œîx[yi+1,1‚àíyi,1]. (23.34) 23.4.3 Waves on Catenary Upuntilthispoint,wehavebeenignoringtheeffectofgravityuponthestring‚Äôsshapeand tension.Thisisagoodapproximationifthereislittlesaginthestring,asmighthappenifthe tensionisveryhighandthestringislight.Evenifthereissomesag,oursolutionfor y(x,t) couldstillbeusedasthedisturbanceabouttheequilibriumshape.However,ifthestring ismassive,say,likeachainorheavycable,thenthesaginthemiddlecouldbequitelarge (Figure23.4),andtheresultingvariationsinshapeandtensionneedtobeincorporatedinto xu DT T0 ds Figure 23.4 Left: A uniform string suspended from its ends in a gravitational Ô¨Åeld assumes a catenary shape. Right: A force diagram of a section of the catenary at its lowest point. Because the ends of the string must support the weight of the string, the tension now varies along the string. 472 23 String and Membrane Waves thewaveequation.Becausethetensionisnolongeruniform,wavestravelfasternearthe endsofthestring,whichareundergreatertension. The derivation of the catenary shape is straight forward. Consider a string of uniform densityùúåacteduponbygravity.Toavoidconfusionwithouruseof y(x)todescribeadistur- banceonastring,wecall u(x)theequilibriumshapeofthestring(Figure23.4).Thestatics problemweneedtosolveistodeterminetheshape u(x)andthetension T(x).Theinsetin Figure23.4isafree-bodydiagramofthemidpointofthestringandshowsthattheweight Wofthissectionofarclength sisbalancedbytheverticalcomponentofthetension T.The horizontaltension T0isbalancedbythehorizontalcomponentof T: T(x)sinùúÉ=W=ùúågs,T(x)cosùúÉ=T0, (23.35) ‚áítanùúÉ=ùúågs‚àïT0. (23.36) The trick is to convert(23.36)to a differential equation that we can solve. We do that by replacingtheslopetan ùúÉbythederivative du‚àïdx,andbytakingthederivativewithrespect tox: du dx=ùúåg T0s,‚áíd2u dx2=ùúåg T0ds dx. (23.37) Yet,because ds=‚àö dx2+du2,wehaveourdifferentialequation: d2u dx2=1 D‚àö dx2+du2 dx(23.38) =1 D‚àö 1+(du‚àïdx)2,D=T0‚àïùúåg. (23.39) Equation(23.39)istheequationforthe catenary,andhasthesolution[Becker,1954] u(x)=Dcoshx D. (23.40) H e r e ,w eh a v ec h o s e nt h e xaxis to lie at distance Dbelow the bottom of the catenary (Figure23.4),sothat x=0isatthecenterofthestringwhere y=DandT=T0.Equation (23.37)tellsusthearclength s=Ddu‚àïdx,andsowecansolvefor s(x)andforthetension T(x)via(23.35): s(x)=Dsinhx D,‚áíT(x)=T0ds dx=ùúågu(x)=T0coshx D.",3661
23.4 Beyond The Simple Wave Equation. 23.7 Numerical Solution,"(23.41) Itisthisvariationintensionthatleadstoan xdependenceofthewavevelocity. 23.4.4 Catenary Assessment InListing23.1,wegivetheprogram EqStringMat.py thatsolvesthewaveequation.Modifyit tosolveforwavesonacatenaryincludingfriction,orfortheassumeddensityandtension given by (23.32) with ùõº=0.5,T0=40 N, and ùúå0=0.01 kg/m. Our code CatFriction.py , giveninListing23.3,yieldsthesolutionshowninFigure23.5. 1) Lookforsomeinterestingcasesandcreatesurfaceplotsoftheresults. 2) Describeinwordshowthewavesdampen,andhowawave‚Äôsvelocityappearstochange. 23.4 Beyond The Simple Wave Equation 473 Figure 23.5 The waves of a plucked catenary with friction at six different times. u(x,t)t = 1 2 3 4 5 6 x 3)Normal modes: Search for normal mode solutions of the variable tension wave equation,thatis,solutionsthatvaryas: u(x,t)=Acos(ùúît)sin(ùõæx). (23.42) Try usingthisformtostartyourprogramandsee ifyouendupwithstandingwaves. Uselargevaluesfor ùúî. 4) When conducting physics demonstrations, we have set up standing wave patterns by continuouslyshakingoneendofastringupanddown.Trydoingthesamewithyour program;thatis,buildintoyourcodetheconditionthatforalltimes: y(x=0,t)=Asinùúît. (23.43) Youmayneedtovary Aandùúîuntilanormalmode(standingwave)isobtained. 5) (Fortheexponentialdensitycase.)Ifyouwereabletofindstandingwaves,thenverify thatthisstringactslikeahigh-frequencyfilter,thatis,thatthereisafrequencybelow whichnowavesoccur. 6) Forthecatenaryproblem,plotyourresultsshowing boththedisturbance u(x,t)about thecatenary,andtheactualheight y(x,t)abovethehorizontalforapluckedstringinitial condition. 7) Trythefirsttwonormalmodesforauniformstringastheinitialconditionsforthecate- nary.Theseshouldbecloseto,butnotexactly,normalmodes. 8) Wederivedthenormalmodesforauniformstringafterassumingthat k(x)=ùúî‚àïc(x)isa constant.Foracatenarywithouttoomuch xvariationinthetension,weshouldbeable tomaketheapproximation: c(x)2‚âÉT(x) ùúå=T0cosh(x‚àïd) ùúå. (23.44) Seeifyougetabetterrepresentationofthefirsttwonormalmodesifyouincludesome xdependencein k. 23.4.5 Including Nonlinear Terms Showthatanextensionofthewaveequation,includingthenextorderindisplacements,is [Taghipour etal.,2014;Keller,1959]: c2ùúï2y(x,t) ùúïx2=[ 1+ùúï2y(x,t) ùúïx2]2ùúï2y(x,t) ùúït2. (23.45) 474 23 String and Membrane Waves 1) Extend the leapfrog algorithm to solve this nonlinear equation, making whatever assumptionsaboutinitialconditionsareneeded. 2) Repeatsomeofthesolutionstothewaveequationstudiedpreviously,onlynowforlarge valuesofy‚àïL,inwhichcasenonlineareffectsareimportant. 3) Examinewhatwerenormalmodesforthelinearproblem,butnowseeiftheypersists forlargeamplitudeoscillations. 23.5 Vibrating Membrane (2D Waves) Anelasticmembraneisstretchedsecurelyacrossthetopofasquareboxwithsidesoflength ùúã,andwiththemembraneintheasymmetricalshape[Kreyszig,1998]: u(x,y,t=0)=sin2xsiny,0‚â§x‚â§ùúã,0‚â§y‚â§ùúã, (23.46) whereuistheverticaldisplacementfromequilibrium. Problem Describethemotionofthemembranewhenitisreleasedfromrest. The description of wave motion on a membrane is much the same as that of 1D waves onthestringdiscussedinSection23.1,onlynowwithwavepropagationintwodirections. ConsiderFigure23.6showingasquaresectionofthemembraneundertension T.Themem- branemovesonlyverticallyinthe zdirection,yetbecausetherestoringforcearisingfrom the tension in the membrane varies in both the xandydirections, there is wave motion alongtheentiresurfaceofthemembrane.",3359
23.4 Beyond The Simple Wave Equation. 23.7 Numerical Solution,"AlthoughthetensionisconstantoverthesmallareainFigure23.6,therewillbeanet verticalforceonthedisplayedsegmentiftheangleofinclineofthemembranevariesaswe movethroughspace.Accordingly,thenetforceonthemembraneinthe zdirection,asa resultofthechangein y,is: ‚àë Fz(x)=TŒîxsinùúÉ‚àíTŒîxsinùúô, (23.47) whereùúÉistheangleofinclineat y+Œîy,andùúôtheangleat y.Ifweassumethatthedis- placementsandtheanglesaresmall,thenwecanmaketheapproximations: sinùúÉ‚âàtanùúÉ=ùúïu ùúïy|||y+Œîy,sinùúô‚âàtanùúô=ùúïu ùúïy|||y, (23.48) ‚áí‚àë Fz(xfixed)=TŒîx( ùúïu ùúïy|y+Œîy‚àíùúïu ùúïy|y) ‚âàTŒîxùúï2u ùúïy2Œîy. (23.49) T‚àÜxT‚àÜy T‚àÜyT‚àÜx x xx + ‚àÜxyy y + ‚àÜyŒ∏ œïzFigure 23.6 A small section of an oscillating membrane and the forces that act on it. 23.6 Analytical Solution 475 Similarly,thenetforceinthe zdirection,asaresultofthevariationin y,is: ‚àë Fz(yfixed)=TŒîy( ùúïu ùúïx|x+Œîx‚àíùúïu ùúïx|x) ‚âàTŒîyùúï2u ùúïx2Œîx. (23.50) Themembranesectionhasmass ùúåŒîxŒîy,whereùúåisthemembrane‚Äôsmassperunitarea.We nowapplyNewton‚Äôssecondlawtodeterminetheaccelerationofthemembranesectionin zdirection,asaresultofthesumofthenetforcesarisingfromboththe xandyvariations: ùúåŒîxŒîyùúï2u ùúït2=TŒîxùúï2u ùúïy2Œîy+TŒîyùúï2u ùúïx2Œîx, (23.51) ‚áí1 c2ùúï2u ùúït2=ùúï2u ùúïx2+ùúï2u ùúïy2,c=‚àö T‚àïùúå. (23.52) Asonemighthaveguessed,thisisthe2Dversionofthewaveequation(23.4)thatwestudied previously in one dimension. Here, c, the propagation velocity, is still the square root of tensionoverdensity,onlynowitistensionperunitlengthandmassperunitarea. 23.6 Analytical Solution Theanalyticornumericalsolutionofthepartialdifferentialequation(23.52)requiresus toknowboththeboundaryconditionsandtheinitialconditions.Theboundaryconditions holdforalltimes,andweregivenwhenweweretoldthatthemembraneisattachedsecurely toasquareboxofside ùúã: u(x=0,y,t)=u(x=ùúã,y,t)=0, (23.53) u(x,y=0,t)=u(x,y=ùúã,t)=0. (23.54) Asrequiredforasecond-orderequation,theinitialconditionshavetwoparts,theshapeof themembraneattime t=0,andthevelocityofeachpointofthemembrane.Thefirstis initialconfiguration: u(x,y,t=0)=sin2xsiny,0‚â§x‚â§ùúã,0‚â§y‚â§ùúã. (23.55) Thesecondisthemembranebeingreleasedfromrest: ùúïu ùúït||||t=0=0, (23.56) wherewewritepartialderivativebecausetherearealsospatialvariations. Theanalyticsolutionisbasedontheguessthatbecausethewaveequation(23.52)hassep- aratederivativeswithrespecttoeachcoordinateandtime,thefullsolution u(x,y,t)might betheproductofseparatefunctionsof x,y,andt: u(x,y,t)=X(x)Y(y)T(t). (23.57) Aftersubstitutinginto(23.52)anddividingby X(x)Y(y)T(t),weobtain: 1 c21 T(t)d2T(t) dt2=1 X(x)d2X(x) dx2+1 Y(y)d2Y(y) dy2. (23.58) 476 23 String and Membrane Waves TheonlywaythattheLHSof(23.58)canbetrueforalltimes,whiletheRHSisalsotruefor allcoordinates,isifbothsidesareconstant: 1 c21 T(t)d2T(t) dt2=‚àíùúâ2=1 X(x)d2X(x) dx2+1 Y(y)d2Y(y) dy2, (23.59) ‚áí1 X(x)d2X(x) dx2=‚àík2,1 Y(y)d2Y(y) dy2=‚àíq2, (23.60) whereq2=ùúâ2‚àík2.In(23.60),wehaveincludedthefurtherrealizationthatbecauseeach term on the RHS of (23.59) depends on either xory, the only way for their sum to be constant, is if each term separately is a constant, in this case ‚àík2. The solutions of these equationsaresinusoidalstandingwavesinthe xandydirections: X(x)=Asinkx+Bcoskx, (23.61) Y(y)=Csinqy+Dcosqy, (23.62) T(t)=Esincùúât+Fcoscùúât.",3086
23.4 Beyond The Simple Wave Equation. 23.7 Numerical Solution,"(23.63) Wenowapplytheboundaryconditions: u(x=0,y,t)=u(x=ùúã,y,z)=0‚áíB=0,k=1,2,‚Ä¶, u(x,y=0,t)=u(x,y=ùúã,t)=0‚áíD=0,q=1,2,‚Ä¶, ‚áíX(x)=Asinkx,Y(y)=Csinqy. (23.64) Thefixedvaluesfortheeigenvalues mandn,describingthemodesforthe xandystanding waves,areequivalenttofixedvaluesfortheconstants q2andk2.Yetbecause q2+k2=ùúâ2, wemustalsohaveafixedvaluefor ùúâ2: ùúâ2=q2+k2‚áí ùúâkq=ùúã‚àö k2+q2. (23.65) Thefullspace-timesolutionnowtakestheform: ukq=[Gkqcoscùúât+Hkqsincùúât]sinkxsinqy, (23.66) wherekandqareintegers.Sincethewaveequationislinearin u,itsmostgeneralsolution isalinearcombinationoftheeigenmodes(23.66): u(x,y,t)=‚àû‚àë k=1‚àû‚àë q=1[Gkqcoscùúât+Hkqsincùúât]sinkxsinqy. (23.67) Whileaninfiniteseriesisnotagoodalgorithm,theinitialandboundaryconditionsmean thatonlythe k=2,q=1termcontributes,andwehaveaclosedformsolution: u(x,y,t)=cosc‚àö 5s i n2xsiny, (23.68) wherecisthewavevelocity. 23.7 Numerical Solution Thedevelopmentofanalgorithmforthesolutionofthe2Dwaveequation(23.52)follows that of the 1D equation in Section 23.2. We start by expressing the second derivatives in 23.7 Numerical Solution 477 termsofcentraldifferences: ùúï2u(x,y,t) ùúït2=u(x,y,t+Œît)+u(x,y,t‚àíŒît)‚àí2u(x,y,t) (Œît)2, (23.69) ùúï2u(x,y,t) ùúïx2=u(x+Œîx,y,t)+u(x‚àíŒîx,y,t)‚àí2u(x,y,t) (Œîx)2, (23.70) ùúï2u(x,y,t) ùúïy2=u(x,y+Œîy,t)+u(x,y‚àíŒîy,t)‚àí2u(x,y,t) (Œîy)2. (23.71) After discretizing the variables, u(x=iŒî,y=iŒîy,t=kŒît)‚â°uk i,j, we obtain our time- stepping algorithm by solving for the future solution in terms of the present and past ones: uk+1 i,j=2uk i,j‚àíuk‚àí1 i,jc2 c‚Ä≤2[uk i+1,j+uk i‚àí1,j‚àí4uk i,j+uk i,j+1+uk i,j‚àí1], (23.72) where, as before, c‚Ä≤def=Œîx‚àïŒît. Whereas the present and past solutions, ukanduk‚àí1,a r e knownafterthefirststep,toinitiatethealgorithmweneedtoknowthesolutionat t=‚àí Œît, thatis,beforetheinitialtime.Tofindthat,weusethefactthatthemembraneisreleased fromrest,andso: 0=ùúïu(t=0) ùúït‚âàu1 i,j‚àíu‚àí1 i,j 2Œît,‚áíu‚àí1 i,j=u1 i,j. (23.73) Aftersubstitutioninto(23.72),weobtainthealgorithmforthefirststep: u1 i,j=u0 i,j+c2 2c‚Ä≤2[u0 i+1,j+u0 i‚àí1,j‚àí4u0 i,j+u0 i,j+1+u0 i,j‚àí1]. (23.74) Becausethe t=0displacement u0 i,jisknown,wecomputethesolutionforthefirsttimestep with(23.74),andforsubsequentstepswith(23.72). The program Wave2D.pyin Listing 23.2 solves the 2D wave equation using the leapfrog algorithm.Theprogram Waves2Danal.py computestheanalyticsolution.Theshapeofthe membraneatthreedifferenttimesisshowninFigure23.7. 02040‚Äì101 t = 45 ‚Äì101 02040 y‚Äì101 t = 3 t = 20 02040 2040 20402040 x Figure 23.7 The standing wave pattern on a square box top at three different times.",2489
23.8 Code Listings,"478 23 String and Membrane Waves 23.8 Code Listings Listing 23.1 EqStringMat.py Solvesthewaveequationforagentlypluckedstring. # EqStringMat.py: Animated leapfrog sol Vibrating string + MatPlotLib 2 fromnumpyimport ‚àó importnumpy as np, matplotlib.pyplot as plt, matplotlib.animation as animation 6rho = 0.01; ten = 40.; c = sqrt(ten/rho) # density , tension c1 = c; ratio = c ‚àóc/(c1 ‚àóc1) # CFL criterium = 1 xi = np.zeros((101,3), float) # Declaration k=range(0,101) 10 defInitialize(): # Initial conditions foriin range (0, 81): xi[i, 0] = 0.00125 ‚àói foriin range (81, 101): xi[i, 0] = 0.1 ‚àí0.005 ‚àó(i‚àí80) #2 n dp a r t 14defanimate(num): foriin range (1, 100): xi[i,2] = 2. ‚àóxi[i,1] ‚àíxi[i,0]+ratio ‚àó(xi[i+1,1]+xi[i ‚àí1,1]‚àí2‚àóxi[i,1]) line.set_data(k,xi[k,2]) #D a t at o p l o t , x , y 18formin range (0,101): xi[m, 0] = xi[m, 1] # Recycle array xi[m, 1] = xi[m, 2] returnline 22Initialize() # Plot initial string fig = plt.figure() ax = fig.add_subplot(111, autoscale_on=False, xlim=(0, 101), ylim=( ‚àí0.15, 0.15)) ax.grid() # Plot grid 26plt.title( \""Vibrating String\"" ) line , = ax.plot(k, xi[k,0], lw=2) foriin range (1,100): xi[i,1] = xi[i,0] + 0.5 ‚àóratio ‚àó(xi[i+1,0] + xi[i ‚àí1,0]‚àí2‚àóxi[i,0]) 30ani = animation.FuncAnimation(fig , animate,1) # D u m m y argument : 1 plt .show() print(\""finished\"" ) Listing 23.2 Waves2D.py Solvesthewaveequationforavibratingmembrane. importmatplotlib.pylab as p; fromnumpyimport ‚àó 2frommpl_toolkits.mplot3d importAxes3D tim = 15; N = 71 c = sqrt(180./390) # Speed = sqrt (ten []/den[kg/m2; ]) 6u = zeros((N,N,N), float); v= zeros((N,N), float) incrx = pi/N; incry = pi/N cprime = c; covercp = c/cprime; ratio = 0.5 ‚àócovercp ‚àócovercp # c/c ‚Äô 0.5 for stable 10 defvibration(tim): y=0 . 0 forjin range (0,N): # Initial position 14 x=0 . 0 foriin range (0,N): u[i][j][0] = 3 ‚àósin(2.0 ‚àóx)‚àósin(y) # Initial shape x+ =i n c r x 18 y+ =i n c r y forjin range (1,N‚àí1): # First time step foriin range (1,N‚àí1): u[i][j][1] = u[i][j][0] + 0.5 ‚àóratio ‚àó(u[i+1][j][0]+u[i ‚àí1][j][0] 22 + u[i][j+1][0]+u[i][j ‚àí1][0]‚àí4.‚àóu[i][j][0]) forkin range (1,tim): # Later time steps forjin range (1,N‚àí1): foriin range (1,N‚àí1): 26 u[i][j][2] = 2. ‚àóu[i][j][1] ‚àíu[i][j][0] + ratio ‚àó(u[i+1][j][1] +u [ i‚àí1][j][1] +u[i][j+1][1]+u[i][j ‚àí1][1]‚àí4.‚àóu[i][j][1]) u[:][:][0] = u[:][:][1] # Reset past 23.8 Code Listings 479 u[:][:][1] = u[:][:][2] # Reset present 30 forjin range (0,N): foriin range (0,N): v[i][j] =u[i][j][2] # Convert to 2D for matplotlib returnv 34v = vibration(tim) x1 =range(0, N) y1 =range(0, N) X, Y = p.meshgrid(x1,y1) 38 deffunctz(v): z = v[X,Y]; returnz Z=f u n c t z( v ) 42fig = p.figure() ax = Axes3D(fig) ax.plot_wireframe(X, Y, Z, color = ‚Äôr‚Äô) ax.set_xlabel( ‚Äôx‚Äô) 46ax.set_ylabel( ‚Äôy‚Äô) ax.set_zlabel( ‚Äôu(x,y)‚Äô ) p.show() Listing 23.3 CatFriction.py Solvesforwavesonacatenarywithfriction. # CatFriction .py: Solve for wave on catenary with friction 3fromnumpyimport ‚àó dt = 0.0001; dx = 0.01; T = 1; rho = 0.1; maxtime = 100; kappa = 30 D=T / (r h o ‚àó9.8) 7x = zeros((512,3), float) q=open(‚ÄôCatFriction.dat‚Äô ,‚Äôw‚Äô); rr = open(‚ÄôCatFunct.dat‚Äô ,‚Äôw+t‚Äô) foriin range (0,101): x[i][0] = ‚àí0.08‚àósin(pi ‚àói‚àódx) #I C 11foriin range (1,100): # First step x[i][1] = ( dt ‚àó(T/rho) ‚àó(( x[i+1][0] ‚àíx[i][0] )/dx ‚àó(e x p ( ( i ‚àí50)‚àódx/D) ‚àíexp(‚àí(i‚àí50)‚àódx/D))/D +(exp((i ‚àí50)‚àódx/D)+exp( ‚àí(i‚àí50)‚àódx/D)) ‚àó ( x[i+1][0]+x[i ‚àí1][0]‚àí2.0‚àóx[i][0] )/( pow(dx,2)) ) 15 ‚àí2‚àókappa ‚àóx[i][0]+2 ‚àóx[i][0]/dt )/(2 ‚àókappa+(2/dt)) forkin range (0,300): # Other steps foriin range (1,100): x[i][2] = (dt ‚àó(T/rho) ‚àó((x[i+1][1] ‚àíx[i][1])/dx ‚àó(exp((i ‚àí50)‚àódx/D) \ 19 ‚àíexp(‚àí(i‚àí50)‚àódx/D))/D +(exp((i ‚àí50)‚àódx/D)+exp( ‚àí(i‚àí50)‚àódx/D)) ‚àó\ (x[i+1][1]+x[i ‚àí1][1]‚àí2.0‚àóx[i][1])/( pow(dx,2)))\ ‚àí2‚àókappa ‚àóx[i][1] ‚àí(‚àí2‚àóx[i][1]+x[i][0])/dt)/(2 ‚àókappa+(1/dt)) foriin range (1,101): 23 x[i][0] = x[i][1] x[i][1] = x[i][2] if(k percent4==0 ork==0): foriin range (0,100): 27 a1=exp((i ‚àí50.)‚àódx/D) a2=exp( ‚àí(i‚àí50.)‚àódx/D) rr.write( \"" percent7.3f\"" percent(D‚àó(a1+a2))) rr.write( \"" \"") 31 q.write( ‚Äô percent7.3f‚Äô percent(x[i ,2])) q.write( \"" \"") q.write( \"" \""); rr.write( \"" \""); 35rr.closed q.closed print(\""Data stored in CatFrict.dat and CatFunct.dat\"" )",4119
Chapter 24 Quantum Wave Packets and EM Waves. 24.1 TimeDependent Schrodinger Equation,"480 24 Quantum Wave Packets and EM Waves This chapter extends the solution of wave equations that began in Chapter 23,t ow a v e s possessing multiple components. This requires algorithms with a bit more sophistication. First, we explore quantum wave packets, which have their real and imaginary parts solved for at slightly differing (split) times. Then, we explore electromagnetic waves, which have their interlaced EandHvector components also solved for at split times . Problem Anelectronwithadefinitemomentumisplacedwithinanattractivepotential thatconfinesittoa1Dregionthesizeofanatom.Determinetheresultingelectron‚Äôsposition intimeandspace. 24.1 Time-Dependent Schr√∂dinger Equation Becausetheregionofconfinementinthisproblemisthesizeofanatom,weneedtosolve itquantummechanically.Becausetheparticlestartedwithbothadefinitemomentumand position,weneedtosolveforboththespatialandtimedependenciesoftheelectron‚Äôswave function.Accordingly,wemustsolvethetime- dependentSchr√∂dingerequation.Thisisdif- ferentfromthetime- independent eigenvalueproblemofaparticleboundinabox,which weconsideredinChapters6and13. WemodeltheelectronbeinglocalizedinspacebyaGaussianwithfinitewidthcentered at5.Becausewearetoldthattheelectronstartswithamomentum,wemultiplytheGaus- sianbyaplanewave(astateofdefinitemomentum ko).Andbecausethisistheinitialstate atjusttheonetime t=0,wedonotincludeanytimedependence: ùúì(x,t=0)=exp[ ‚àí1 2( x‚àí5 ùúé0)2] eikox, (24.1) wherewehaveset ‚Ñè=1.Inspiteofussettingupthewavefunction(24.1),asifitgivesthe electronadefinitemomentumandlocations,(24.1)isaneigenstateofneithermomentum norposition.Sucharewavepackets. To solve the problem,wemustpropagatetheinitialwavefunctionforwardintimeand throughallofspace(asweshowinFigures24.1and24.2).If(24.1)wereaneigenstateof the Hamiltonian, it would have an exp (‚àíiùúît)time dependence that can be factored out of the wave function (the usual in textbooks), and we would have a time-independent ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 24.1 Time-Dependent Schr√∂dinger Equation 481 020 t x Figure 24.1 The probability density as a function of time and space for an electron conÔ¨Åned to a square well. The electron is seen to start off on the left, spread out with time, and collide with the walls. 010 xtx t10 801020607080 10 0246810 Time Position020304050607080 1010 5 0005 Figure 24.2 The probability density as a function of time for an electron conÔ¨Åned to a 1D harmonic oscillator potential well. On the left is a conventional surface plot, while on the right is a color visualization. Schr√∂dingerequation.However, ÃÉHùúì‚â†Eùúìforthiswavepacket,andsowemustsolvethe time-dependentSchr√∂dingerequation: iùúïùúì(x,t) ùúït=ÃÉHùúì(x,t) (24.2) iùúïùúì(x,t) ùúït=‚àí1 2mùúï2ùúì(x,t) ùúïx2+V(x)ùúì(x,t), (24.3) w h e r ew eh a v es e t2 m=1a n d‚Ñè=1. Because the initial wave function is complex (the planewave),thewavefunctionwillbecomplexforalltimes.Accordingly,wehaveseparate equationsfortherealandimaginarypartsofthewavefunction: ùúì(x,t)=R(x,t)+iI(x,t), (24.4) ‚áíùúïR(x,t) ùúït=‚àíùúï2I(x,t) ùúïx2+V(x)I(x,t), (24.5) ùúïI(x,t) ùúït=+ùúï2R(x,t) ùúïx2‚àíV(x)R(x,t), (24.6) whereV(x)istheconfiningpotential.",3190
24.2 SplitTime Algorithm. 24.2.2 Wave Packets in Other Wells,"482 24 Quantum Wave Packets and EM Waves 24.2 Split-Time Algorithm Thetime-dependentSchr√∂dingerequationcanbesolvedwithbothimplicit(large-matrix) andexplicit(leapfrog)methods.AnextrachallengewhensolvingtheSchr√∂dingerequation istheneedtoconserveprobability, ‚à´+‚àû ‚àí‚àûdxùúå(x,t),toahighlevelofprecisionatalltimes. Here,we‚Äôllusean explicitmethodthat,bydesign,providesahighlevelofprobabilitycon- servation. It does so by solving for the real and imaginary parts of the wave function at slightlydifferent,or‚Äústaggered‚Äù,times[AskarandCakmak,1977;Visscher,1991;Maestri etal.,2000].Explicitly,therealpart Risdeterminedattimes0, Œît,‚Ä¶,andtheimaginary partIattimes1 2Œît,3 2Œît,‚Ä¶Thealgorithmisbasedon(whatelse?)theTaylorexpansionsof RandI,forexample, R( x,t+1 2Œît) =R( x,t‚àí1 2Œît) +[4ùõº+V(x)Œît]I(x,t) ‚àí2ùõº[I(x+Œîx,t)+I(x‚àíŒîx,t)], (24.7) whereùõº=Œît‚àï[2(Œîx)2].Indiscreteformwehave: Rn+1 i=Rn i‚àí2(ùõº[In i+1+In i‚àí1]‚àí2[ùõº+ViŒît]In i), (24.8) In+1 i=In i+2(ùõº[Rn i+1+Rn i‚àí1]‚àí2[ùõº+ViŒît]Rn i), (24.9) wherethesuperscript nindicatesthetime,andthesubscript itheposition,e.g., Rt=nŒît x=iŒîx. Theprobabilitydensity ùúåisdefinedintermsofthewavefunctionevaluatedatthreedif- ferenttimes: ùúå(t)=‚éß ‚é™ ‚é® ‚é™‚é©R2(t)+I( t+Œît 2) I( t‚àíŒît 2) ,forinteger t, I2(t)+R( t+Œît 2) R( t‚àíŒît 2) ,forhalf-integer t.(24.10) Althoughprobabilityisnottobeexactlyconservedbythealgorithm,theerroristwoorders higherthanthatinthewavefunction,andthisisusuallyquitesatisfactory.Ifitisnot,then onemustadjustthestepsizes.Whilethisdefinitionof ùúåmaynotseemintuitive,itreduces totheusualonefor Œît‚Üí0,andsocanbeviewedaspartoftheartofnumericalanalysis. Wewillaskyoutoinvestigatejusthowwellprobabilityisconserved.Wereferthereaderto Koonin[1986]andVisscher[1991]fordetailsonthestabilityofthealgorithm. 24.2.1 Implementation InListing24.1,youwillfindtheprogram HarmosAnimate.py thatsolvesforthemotionofthe wavepacket(24.1)insideaharmonicoscillatorpotential.Theprogram Slit.pysolvesfor themotionofaGaussianwavepacketasitpassesthroughaslit(Figure24.4).Youshould solveforawavepacketconfinedtoaninfinitesquarewell: V(x)={‚àû,x<0,orx>15, 0,0‚â§x‚â§15. 1) Define arrays psr[751,2] and psi[751,2] for the real and imaginary parts of ùúì,a n d Rho[751]fortheprobability.Thefirstsubscriptreferstothe xpositiononthegrid,and thesecondtothepresentandfuturetimes. 24.2 Split-Time Algorithm 483 y x300 500 100 Figure 24.3 The probability density as a function of xandyat three different times for an electron conÔ¨Åned to a 2D parabolic tube (inÔ¨Ånitely long in ydirection). The electron is initially a Gaussian wave packet in both the xandydirections. Figure 24.4 The probability density as a function of position and time for an electron incident upon and passing through a slit. A signiÔ¨Åcant reÔ¨Çection is seen to be occurring. 2) Usethevalues ùúéo=0.5,Œîx=0.02,ko=17ùúã,andŒît=1 2Œîx2. 3) Useequation(24.1)fortheinitialwavepackettodefine psr[ j,1]foralljatt=0,andto define psi[ j,1]att=1 2Œît. 4) Seeing that the wave function must vanish at the infinitely high well walls, set Rho[1] = Rho[751] = 0.0 . 5) Incrementtimeby1 2Œît.Use(24.8)tocompute psr[ j,2]intermsof psr[ j,1],and(24.9) tocompute psi[ j,2]intermsof psi[ j,1]. 6) Repeatthestepsthroughallofspace,thatis,for i=2‚Äì750. 7) Throughoutallofspace,replacethepresentwavepacket(secondindex1)bythefuture wavepacket(secondindex2). 8) After you are sure that the program is running properly, repeat the time-stepping for ‚àº5000steps. 24.2.1.1 Animation 1) Outputtheprobabilitydensityafterevery200steps. 2) Make a surface plot of probability versuspositionversustime. This should look like Figures24.1or24.2. 3) Makeananimationshowingthewavefunctionasafunctionoftime. 4) Checkhowwellprobabilityisconservedforearlyandlatetimesbydeterminingtheinte- graloftheprobabilityoverallofspace, ‚à´+‚àû ‚àí‚àûdxùúå(x),andseeingbyhowmuchitchanges intime(itsspecificvaluedoesn‚Äôtmatterasit‚Äôsjustnormalization). 5) Explainwhycollisionswiththewallscausethewavepackettobroadenandbreakup. (Hint:ThecollisionsdonotappearsodisruptivewhenaGaussianwavepacketiscon- finedwithinaharmonicoscillatorpotential.)",3999
24.5 EM Waves Finite Difference Time Domain,"484 24 Quantum Wave Packets and EM Waves 24.2.2 Wave Packets in Other Wells 1D Well:Nowconfinetheelectrontoaharmonicoscillatorwell: V(x)=1 2x2(‚àí‚àû‚â§x‚â§‚àû). (24.11) Take the momentum as k0=3ùúã, the space step Œîx=0.02, and the time step Œît=1 4Œîx2.Notethatthewavepacketbroadensintime,butthenreturnstoits initialshape. 2D Well:Nowconfinetheelectrontoa2Dparabolictube(Figure24.3): V(x,y)=0.9x2,‚àí9.0‚â§x‚â§9.0,0‚â§y‚â§18.0. (24.12) Theextradegreeoffreedommeansthatwemustsolvethe2DPDE: iùúïùúì(x,y,t) ùúït=‚àí(ùúï2ùúì ùúïx2+ùúï2ùúì ùúïy2) +V(x,y)ùúì. (24.13) Assume that the electron‚Äôs initial localization is described by the 2D Gaussian wavepacket: ùúì(x,y,t=0)=eik0xxeik0yyexp[ ‚àí(x‚àíx0)2 2ùúé2 0] exp[ ‚àí(y‚àíy0)2 2ùúé2 0] . (24.14) Notethatyoucansolvethe2Dequationbyextendingthemethodwejustused in1D,oryoucanlookatSection24.3wherewedevelopaspecialalgorithmfor theSchr√∂dingerequation. 1) Determinethemotionofa2DGaussianwavepacketwithina2Dharmonicoscillator potential: V(x,y)=0.3(x2+y2),‚àí9.0‚â§x‚â§9.0,‚àí9.0‚â§y‚â§9.0. (24.15) a) Centertheinitialwavepacketat (x,y)=(3.0,‚àí3),andgiveitmomentum (k0x,k0y)= (3.0,1.5). b) Young‚Äôssingle-slitexperimenthasawavepassingthroughasmallslitwiththetrans- mittedwaveshowinginterferenceeffects.Inquantummechanics,wherewerepre- sentaparticlebyawavepacket,thismeansthataninterferencepatternshouldbe formedwhenaparticlepassesthroughasmallslit.PassaGaussianwavepacketof width3throughaslitofwidth5(Figure24.4),andobservetheresultingquantum interference. 24.3 Special Schr√∂dinger Algorithm We have just developed an algorithm to solve the time-dependent Schr√∂dinger equation in2Dbyextendingthe1Dalgorithmtoanotherdimension.Anotherapproachusesquan- tumtheorytoobtainamorepowerfulalgorithm[Maestri etal.,2000].First,wenotethat equation (24.13) can be integrated formally to obtain the solution [Landau and Lifshitz, 1976]: ùúì(x,y,t)=U(t)ùúì(x,y,t=0) (24.16) 24.4 Quantum Chaos 485 U(t)=e‚àíiÃÉHt,ÃÉH=‚àí( ùúï2 ùúïx2+ùúï2 ùúïy2) +V(x,y). (24.17) Here,U(t)isanoperatorthattranslatesawavefunctionforwardintime,and ÃÉHistheHamil- tonianoperator.Fromthisformalsolution,wededucethatawavepacketcanbetranslated aheadoftime Œîtvia: ùúìn+1 i,j=U(Œît)ùúìn i,j, (24.18) where the superscript denotes time, t=nŒît, and the subscripts denote the two spatial variables,x=iŒîx,y=jŒîy.Likewise,theinverseofthetimeevolutionoperatormovesthe solutionbackonetimestep: ùúìn‚àí1=U‚àí1(Œît)ùúìn=e+iÃÉHŒîtùúìn. (24.19) Whileitwouldbenicetohaveanalgorithmbasedonadirectapplicationof(24.19),the references show that the resulting algorithm would not be stable [Askar and Cakmak, 1977].Thatbeingso,webaseouralgorithmonanindirectapplication,namely,therelation betweenthedifferencein ùúìn+1andùúìn‚àí1: ùúìn+1=ùúìn‚àí1+(e‚àíiÃÉHŒît‚àíe+iÃÉHŒît)ùúìn, (24.20) where the difference in sign of the exponents is to be noted. The algorithm derives from combining the O(Œîx2)expression for the second derivative obtained from the Taylor expansion, ùúï2ùúì ùúïx2‚âÉ‚àí1 2(ùúìn i+1,j+ùúìn i‚àí1,j‚àí2ùúìn i,j), (24.21) with the corresponding-order expansion of the evolution equation (24.20). Substituting theresultingexpressionforthesecondderivativeintothe2Dtime-dependentSchr√∂dinger equationresultsin:1 ùúìn+1 i,j=ùúìn‚àí1 i,j‚àí2i[( 4ùõº+1 2ŒîtVi,jùúìn i,j‚àíùõº( ùúìn i+1,j+ùúìn i‚àí1,j+ùúìn i,j+1+ùúìn i,j‚àí1)] , whereùõº=Œît‚àï[2(Œîx)2].Weconvertthisequationwithitscomplexwavefunctiontocoupled realequationsbysubstituting ùúì=R+iI: Rn+1 i,j=Rn‚àí1 i,j+2[( 4ùõº+1 2ŒîtVi,j) In i,j‚àíùõº( In i+1,j+In i‚àí1,j+In i,j+1+In i,j‚àí1)] , In+1 i,j=In‚àí1 i,j‚àí2[( 4ùõº+1 2ŒîtVi,j) Rn i,j+ùõº( Rn i+1,j+Rn i‚àí1,j+Rn i,j+1+Rn i,j‚àí1)] . Thisisthealgorithmforintegratingthe2DSchr√∂dingerequation.Probabilityisdetermined usingthesameexpression(24.10)asusedin1D. 24.4 Quantum Chaos Finding signals of chaos in quantum systems can be challenging. To avoid computation, muchoftheresearchhasassumedtheapproximate,semiclassicalformulationofquantum 1 Theconstantsintheequationchangeasthedimensionoftheequationchanges;thatis,therewillbe differentconstantsforthe3Dequation,andtherefore,ourconstantsaredifferentfromthoseinthe references. 486 24 Quantum Wave Packets and EM Waves mechanics.Wewon‚Äôtdothat.Thereareanumberofwaysinwhichchaoticbehaviormay occurinquantum systems, someratherobvious,andothersmoresubtle. Inthissection, welookattheobvious;obviousbecausetheclassicalversionsofthesystemsdisplaychaos, andsoweknowwhattolookforinthequantumsystems. 24.4.1 Quantum Billiards Here,weexamineaquantumsystemwhoseclassicalanaloghasdefinitechaoticbehavior, asseeninFigures24.5and24.6.Intheclassicalchaoticsystem,thebilliardballbounces aroundendlessly,fillingalloftheallowedspacewithouteverrepeating(Figure24.6left). The program for this is the same as for scattering from three disks, 3QMdisks.py in List- ing24.2,butwiththedisksremoved.Youmustimpose ùúì=0attheboundariestodescribe reflectionfromahardwall.Someofourresultsafter200timestepsareshowninFigure24.6 right.Weseethatthequantumsystemdisplaysasignatureoftheendlessclassicalreflec- tionsfromthetable‚Äôsedges. R rho( x,y ) 0 020 2040x y4060 6080 80100 1000.00.20.4 Figure 24.5 Left:Classical trajectories for scatterings from one, two, and three stationary disks. Right: A wave packet incident on three disks of radius 10 located at the vertices of an equilateral triangle. Psi0.2 0.1 0.0 100 80 60 40 20 0 0 20 40 xy 60 80 100 Figure 24.6 Left: The path followed by a classical ball bouncing elastically within a square billiard. Right: A quantum wave packet, initially Gaussian in shape, after 200 time steps conÔ¨Åned within a square billiard table. 24.4 Quantum Chaos 487 1) ComputethemotionofaninitialGaussianwavepacketconfinedtothetopofasquare billiards table. Match the initial conditions to those that lead to periodic orbits of the classicalbilliard. (a) Computetheclassicalmotionofasquarebilliardforaseriesoftimes,rangingfrom thoseinwhichonlyasmallnumberofreflectionshasoccurred,toverylargetimes. (b) Examinethewavefunctionforthesamerangeoftimesasusedintheclassicalcom- putation,andcomparetotheclassicalresults. (c) Howmanyreflectionsdoesittakeforthewavepackettolosealltracesoftheclassical trajectories? 2) Examine the motion of a quantum wave packet for the various billiards studied clas- sically: by a) a circle, b) a stadium, c) a circle with a disk in the middle. In all cases, examineinitialconditionsthatleadtoclassicallyperiodicorbits. 24.4.2 Three Disks Scattering Anothersysteminwhichwemightbeabletoseethequantumchaoshappeningisquantum scatteringfromthreefixedharddisks(Figure24.5left).Here,weexaminethescatteringofa wavepacketfromseveralharddiskconfigurations(Figure24.5right),withquantumchaos possibleforthethree-diskscattering.Tomakeyourworkeasier,inListing24.2,wegiveour program 3QMdisks.py for quantum scattering from three fixed hard disks. The disks have radiusR,acenter-to-centerseparationsof a,andareplacedattheverticesofanequilateral triangle.AsseeninFigure24.5,aGaussianwavepacket, ùúì(x,y,t=0)=ei(kxx+kyy)e‚àíA(x‚àíx0)2‚àíA(y‚àíy0)2, (24.22) is incident upon the disks. Note: The program, as given, has the disks confined within a very small box. This may be appropriate for a bound state billiard problem, but not for scattering. You will needto enlargethe confiningbox inorder to eliminatethe effects of reflectionsfromtheboundary.AndwhileyouarefreetomakesurfaceplotsofRe ùúì(x,y) andImùúì(x,y),wefindtheinterpretationeasierwithasurfaceplotoftheprobabilitydensity z(x,y)=ùúå(x,y). 1) Startwithscatteringfromonedisk‚Äì (a) Producesurfaceplotsof ùúå(x,y)fortimesfrom0untilthepacketleavesthescattering region. Note, the edges of the billiardtable will reflect the wave packetand, ergo, shouldbefarfromthedisksinordertonotinterferewiththescatteringfromthe disks. (b) Examinethequalitativeeffectofvaryingthesizeofthedisk. (c) Examinethequalitativeeffectofvaryingthemomentumofthewavepacket. (d) Varytheinitialpositionofthewavepacketsothattherearenearlyhead-oncollisions aswellasonesatglancingangles. 2) Next,repeatyourinvestigationforthetwodisksystem.Trytovarytheparameterssothat youobtainmany multiplescatteringsfromthedisks.Inparticular,seeifyoucanfindthe analogoftheclassicalcasewherethereisatrappedorbitwithunendingback-and-forth scatterings.( Hint:Trystartingthewavepacketbetweenthetwodisks.) 3) Next,extendandrepeattheinvestigationtothethree-disksystem.Varytheparameters so that you obtain many multiple scatterings from the disks. In particular, see if you",8187
24.7 SplitTime FDTD,"488 24 Quantum Wave Packets and EM Waves canfindtheanalogoftheclassicalcasewheretherearetrappedorbitswithunending back-and-forthscatterings. (a) Developanalgorithmthatdeterminesthetimedelayofthewavepacket,thatis,the timeittakesformostoftheinitialpackettoleavethescatteringregion. (b) Plot the time delay versus the wave packet momentum and look for indications of chaos, such as sharp peaks or rapid changes. The literature indicates that high degreesofmultiplescatteringoccurwhen a‚àïR‚âÉ6. 24.5 E&M Waves: Finite Difference Time Domain Simulationsofelectromagneticwavesareoftremendouspracticalimportance.Aswithother wave equations, the basic technique is again calculating the solution on a spacetime lattice usingfinitedifferenceandtimestepping.WhenusedforE&Msimulations,thetechniqueis knownasthefinitedifferencetimedomain(FDTD)method.Whatisnewhereisthecoupling ofthe E and H fields,withthevariationsofonevectorgenerating theother. Morecomplete treatmentscanbefoundinSullivan[ 2000]andWardandNelson[ 2004]. Problem Youaregivenaregioninspace,0 ‚â§z‚â§200,inwhichthe EandHfieldsare knowntohaveasinusoidalspatialvariation: Ex(z,t=0)=0.1sin( 2ùúãz 100) ,Hy(z,t=0)=0.1sin( 2ùúãz 100) , (24.23) withallothercomponentsvanishing.Determinethefieldsforallsubsequenttimes. 24.6 Maxwell‚Äôs Equations Thedescriptionofelectromagnetic(EM)wavesviaMaxwell‚Äôsequationsiscoveredinmany textbooks. For propagation in just the zdimension, and for free space with no sinks or sources,therearefourcoupledPDE‚Äôs: ‚Éó‚àá‚ãÖE=0‚áíùúïEx(z,t) ùúïx=0 (24.24) ‚Éó‚àá‚ãÖH=0‚áíùúïHy(z,t) ùúïy=0, (24.25) ùúïE ùúït=+1 ùúñ0‚Éó‚àá√óH‚áíùúïEx ùúït=‚àí1 ùúñ0ùúïHy(z,t) ùúïz, (24.26) ùúïH ùúït=‚àí1 ùúá0‚Éó‚àá√óE‚áíùúïHy ùúït=‚àí1 ùúá0ùúïEx(z,t) ùúïz. (24.27) AsindicatedinFigure24.7,wehavechosentheelectricfield E(z,t)tobepolarized(oscillate) inthexdirection,andthemagneticfield H(z,t)tobepolarizedinthe ydirection.Thisisa transverseelectromagnetic(TEM)wave.AsindicatedbytheboldarrowinFigure24.7,the directionofpowerflowisgivenbytheright-handruleappliedto E√óH.Notethatalthough wehavesettheinitialconditionssuchthattheEMwaveistravelinginonlythe zdimension, 24.7 Split-Time FDTD 489 Figure 24.7 A single electromagnetic pulse traveling along the zaxis. The coupled EandHpulses are indicated by solid and dashed curves, respectively, and the pulses at different zvalues correspond to different times.x yzEx ExHyHy t theelectricfieldoscillatesintheperpendicular xdirection,andthemagneticfieldoscillates intheperpendicular ydirection.So,whiletheremaybepropagationinjustonedirection, thevectornatureofthefieldsmeansthatthewaveoccursinallthreedimensions. 24.7 Split-Time FDTD WeneedtosolvethetwocoupledPDEs(24.26)and(24.27).AsisusualforPDEs,weapprox- imatethederivativesviathecentral-differenceapproximation,hereinbothtimeandspace. Forexample, ùúïE(z,t) ùúït‚âÉE( z,t+Œît 2) ‚àíE( z,t‚àíŒît 2) Œît, (24.28) ùúïE(z,t) ùúïz‚âÉE( z+Œîz 2,t) ‚àíE( z‚àíŒîz 2,t) Œîz. (24.29) We next substitute these approximations into Maxwell‚Äôs equations, and rearrange the equationsintheformofanalgorithmthatadvancesthesolutionintime.Becauseonlyfirst derivatives occur in Maxwell‚Äôs equations, the equations are simple, although the electric andmagneticfieldsareintermixed. Aswehavedonewiththetime-dependentSchrodingerequation,wesetupaspace-time lattice(Figure24.8),inwhichtherearehalf-integertimesteps,butnowextendedtohalf- integer space steps as well [Yee, 1966]. The magnetic field will be determined at integer timesitesandhalf-integerspacesites(opencircles),whiletheelectricfieldwillbedeter- mined at half-integer time sites and integer space sites (filled circles). This extra level of complicationofinterlacedlatticesleadstoanaccurateandrobustalgorithm.Becausethe fieldsalreadyhavesubscriptsindicatingtheirvectornature,weindicatethelatticeposition assuperscripts,forexample, Ex(z,t)‚ÜíEx(kŒîz,nŒît)‚ÜíEk,n x. (24.30) Maxwell‚Äôsequations,(24.26)and(24.27),nowbecomethediscreteequations: Ek,n+1‚àï2 x‚àíEk,n‚àí1‚àï2 x Œît=‚àíHk+1‚àï2,n y‚àíHk‚àí1‚àï2,n y ùúñ0Œîz, Hk+1‚àï2,n+1 y‚àíHk+1‚àï2,n y Œît=‚àíEk+1,n+1‚àï2 x‚àíEk,n+1‚àï2 x ùúá0Œîz. 490 24 Quantum Wave Packets and EM Waves tz n n + 1n + 1/2n ‚Äì 1/2k k+1k + 1/2 k ‚Äì 1/2 Hy ExFigure 24.8 The algorithm for using the known values of ExandHyat two earlier times, and three different space positions, to advance the solution to the present time. The values of Exare determined on the lattice of Ô¨Ålled circles, corresponding to integer space indices and half-integer time indices. In contrast, the values of Hyare determined on the lattice of open circles, corresponding to half-integer space indices and integer time indices. Insummary,thisformulationsolvesfortheelectricfieldatintegerspacesteps, k,buthalf- integertimesteps, n,whilethemagneticfieldissolvedforathalf-integerspacesteps,but integertimesteps. Weconverttheseequationsintotwosimultaneousalgorithmsbysolvingfor Exattime n+1 2,andHyattimen: Ek,n+1‚àï2 x=Ek,n‚àí1‚àï2 x‚àíŒît ùúñ0Œîz( Hk+1‚àï2,n y‚àíHk‚àí1‚àï2,n y) , (24.31) Hk+1‚àï2,n+1 y=Hk+1‚àï2,n y‚àíŒît ùúá0Œîz( Ek+1,n+1‚àï2 x‚àíEk,n+1‚àï2 x) . (24.32) TheverynatureofMaxwell‚Äôsequationsrequiresthesealgorithmstobeappliedsimultane- ously:thespacevariationof Hydeterminesthetimederivativeof Ex,andthespacevariation ofExdeterminesthetimederivativeof Hy(Figure24.8).Thesealgorithmsaremoreinvolved than our usual time-stepping ones in that the electric fields (filled circles in Figure 24.8) atfuturetimes, t=n+1 2,aredeterminedfromtheelectricfieldsatonetimestepearlier, t=n‚àí1 2,andthemagneticfieldsathalfatimestepearlier, t=n.Likewise,themagnetic fields(opencirclesinFigure24.8)atfuturetimes, t=n+1,aredeterminedfromthemag- neticfieldsatonetimestepearlier, t=n,andtheelectricfieldathalfatimestepearlier, t=n+1 2.Inotherwords,itisasifwehavetwointerleavedlattices,withtheelectricfields determinedforhalf-integertimesonlattice1andthemagneticfieldsatintegertimeson lattice2. Althoughthesehalf-integertimesarethenormforFDTDmethods[TafloveandHagness, 2000;Sullivan,2000],itmaybeeasierforsomereaderstounderstandthembydoublingthe indexvalues,andreferringtoevenandoddtimesinstead: Ek,n x=Ek,n‚àí2 x‚àíŒît ùúñ0Œîz( Hk+1,n‚àí1 y‚àíHk‚àí1,n‚àí1 y) , keven,nodd, (24.33) Hk,n y=Hk,n‚àí2 y‚àíŒît ùúá0Œîz( Ek+1,n‚àí1 x‚àíEk‚àí1,n‚àí1 x) , kodd,neven. (24.34) Thismakesitclearthat Eisdeterminedforevenspaceindicesandoddtimes,while His determinedforoddspaceindicesandeventimes. Wesimplifythealgorithm,andmakeitsstabilityanalysissimpler,byrenormalizingthe electricfieldstohavethesamedimensionsasthemagneticfields: ÃÉE=‚àöùúñ0 ùúá0E. (24.35)",6290
24.8 More EM Problems,"24.7 Split-Time FDTD 491 Thealgorithms(24.31)and(24.32)nowbecome: ÃÉEk,n+1‚àï2 x=ÃÉEk,n‚àí1‚àï2 x+ùõΩ( Hk‚àí1‚àï2,n y‚àíHk+1‚àï2,n y) , (24.36) Hk+1‚àï2,n+1 y=Hk+1‚àï2,n y+ùõΩ( ÃÉEk,n+1‚àï2 x‚àíÃÉEk+1,n+1‚àï2 x) , (24.37) ùõΩ=c Œîz‚àïŒît,c=1‚àöùúñ0ùúá0. (24.38) Here,cisthespeedoflightinavacuum,and ùõΩistheratioofthespeedoflighttothegrid velocityŒîz‚àïŒît. Thespacestep Œîzandthetimestep Œîtmustbechosensothatthealgorithmsaresta- ble.Thescalesofthespaceandtimedimensionsaresetbythewavelengthandfrequency, respectively,ofthepropagatingwave.Asaminimum,wewantatleast10gridpointstofall withinawavelength: Œîz‚â§ùúÜ 10. (24.39) ThetimestepisthendeterminedbytheCourantstabilitycondition[TafloveandHagness, 2000;Sullivan,2000]tobe: ùõΩ=c Œîz‚àïŒît‚â§1 2. (24.40) Aswehaveseenbefore,(24.40)impliesthatmakingthetimestepsmallerimprovespre- cision and maintains stability, but making the space step smaller must be accompanied by a simultaneous decrease in the time step in order to maintain stability (you should checkthis). 24.7.1 Implementation and Assessment InListing24.3,weprovideasimpleimplementationoftheFDTDalgorithmfora zlattice of200sites.ItproducestheoutputshowninFigure24.9.Theinitialconditionscorrespond toasinusoidalvariationofthe EandHfieldsfor0 ‚â§z‚â§200: Ex(z,t=0)=0.1sin( 2ùúãz 100) ,Hy(z,t=0)=0.1sin( 2ùúãz 100) , (24.41) Thealgorithmthenstepsoutintimeforaslongastheuserdesires.Thediscreteformof Maxwellequationsusedare: Ex Ex Ex z zHyEx Hy Figure 24.9 TheEÔ¨Åeld (light colored) and the HÔ¨Åeld (dark) at the initial time (left), and at a later time (right). Periodic boundary conditions are used at the ends of the spatial region, which means that the large zwave continues into the z=0w a v e .",1631
24.9 Code Listings,"492 24 Quantum Wave Packets and EM Waves 1Ex[k, 1] = Ex[k, 0] + beta ‚àó(Hy[k‚àí1, 0]‚àíHy[k+1, 0]) Hy[k, 1] = Hy[k, 0] + beta ‚àó(Ex[k‚àí1, 0]‚àíEx[k+1, 0]) Thesecondindextakesthevalues0and1,with0beingtheoldtimeand1thenew.At theendofeachiteration,thenewfieldthroughoutallofspacebecomestheoldone,and aneweroneiscomputed.Asthespatialendpoints, k=0and k=xmax-1,arenotdefined,we assumeperiodicboundaryconditions. 1) Imposeboundaryconditionsthatmakeallfieldsvanishontheboundaries. 2) TesttheCourantcondition(24.40)byexaminingthestabilityofthesolutionfordiffer- entvaluesof ŒîzandŒît. 3) Thedirectionofpropagationofthepulseisinthe E√óHdirection,whichdependson therelativephasebetweenthe EandHfields.Verifythatwithnoinitial Hfield,we obtainpulsesbothtotherightandtheleft. 4) Modifytheprogramsothatthereisaninitial Hpulse,aswellasaninitial Epulse,both withGaussiantimesinasinusoidalshape. 5) Verify that the direction of propagation changes if the EandHfields have relative phasesof0or ùúã. 6) Investigatetheresonatormodesofawaveguidebypickingtheinitialconditionscor- respondingtoplanewaveswithnodesattheboundaries. 7) Investigate standing waves with wavelengths longer than the size of the integration region. 8) Simulateunboundedpropagationbybuildinginperiodicboundaryconditionsintothe algorithm. 9) Placeamediumwithperiodicpermittivityintheintegrationvolume.Thisshouldact asafrequency-dependentfilter,whichblockscertainfrequencies. 10) Extendthealgorithmtoincludetheeffectofentering,propagatingthrough,andexiting adielectricmaterialplacedwithinthe zintegrationregion. (a) Ensurethatyouseebothtransmissionandreflectionatthedielectricboundaries. (b) Investigatetheeffectofvaryingthedielectric‚Äôsindexofrefraction. 24.8 More E&M Problems 24.8.1 Circularly Polarized Waves WenowextendourtreatmenttoEMwavesthatarenotrestrictedtolinearpolarizations. Accordingly,weadd HxandEyvariationsto(24.26)and(24.27): ùúïHx ùúït=1 ùúá0ùúïEy ùúïz, (24.42) ùúïEy ùúït=1 ùúñ0ùúïHx ùúïz. (24.43) Whendiscretizedinthesamewayas(24.31)and(24.32),weobtain: Hk+1‚àï2,n+1 x=Hk+1‚àï2,n x+Œît ùúá0Œîz( Ek+1,n+1‚àï2 y‚àíEk,n+1‚àï2 y) , (24.44) 24.8 More E&M Problems 493 Ek,n+1‚àï2 y=Ek,n‚àí1‚àï2 y+Œît ùúñ0Œîz( Hk+1‚àï2,n y‚àíHk‚àí1‚àï2,n y) . (24.45) Toproduceacircularlypolarizedtravelingwave,wesetasinitialconditions: Ex=cos( t‚àíz c+ùúôy) ,Hx=‚àöùúñ0 ùúá0cos( t‚àíz c+ùúôy) , (24.46) Ey=cos( t‚àíz c+ùúôx) ,Hy=‚àöùúñ0 ùúá0cos( t‚àíz c+ùúôx+ùúã) . (24.47) Wetakethephasestobe ùúôx=ùúã‚àï2andùúôy=0,sothattheirdifference ùúôx‚àíùúôy=ùúã‚àï2,which leadstocircularpolarization.Weincludetheinitialconditionsinthesamemanneraswe didtheGaussianpulse,onlynowwiththesecosinefunctions. Listing 24.5 gives our implementation EMcirc.py for waves with transverse two- component EandHfields. Some results of the simulation are shown in Figure 24.11, whereyouwillnotethedifferenceinphasebetween EandH. 24.8.2 Wave Plates Problem Developanumericalmodelforawaveplatethatconvertalinearlypolarized electromagneticwaveintoacircularlypolarizedone. AsseeninFigure24.10,awaveplateisanopticaldevicethataltersthepolarizationoflight traveling through it by shifting the relative phase of the components of the polarization vector.Aquarterwaveplateintroducesarelativephaseof ùúÜ‚àï4,where ùúÜisthewavelength of the light. Physically, a wave plate is often a birefringent crystal in which the different propagationvelocitiesofwavesintwoorthogonaldirectionsleadtoaphasechange.The thicknessoftheplatedeterminestheamountofphasechange. To simulate a wave plate, we start with a linearly polarized wave, with both ExandEy componentspropagatingalongthe zdirection.Thewaveenterstheplateandemergesfrom it while still traveling in the zdirection, but now with the relative phase of these fields Ey z Figure 24.10 One frame from the program quarterwave.py in Listing 24.4, showing a linearly polarized electromagnetic wave entering a quarter wave plate from the left, and leaving as a circularly polarized wave on the right (the arrow on the left oscillates back and forth at 45‚àòwhile the one on the right rotates). Figure 24.11 EandHÔ¨Åelds at t=100 for a circularly polarized wave.",3988
24.9 Code Listings,"494 24 Quantum Wave Packets and EM Waves LŒîxRŒîx GŒîx CŒîx Œîx20 10 0 ‚Äì10 ‚Äì20v20 10 0 ‚Äì10 ‚Äì20v Figure 24.12 Left: A transmission line that repeats every Œîx.Right: Two frames of an animation produced by TeleMat.py showing a wave transmitted along a telegraph line and being reÔ¨Çected from an end. shifted. Of course, because this is an EM wave, there will also be coupled magnetic field componentspresent,inthiscase HxandHy,andtheytooneedbecomputed. Maxwellequationsforwavepropagatingalongthe zaxisare: ùúïHx ùúït=+1 ùúá0ùúïEy ùúïz,ùúïHy ùúït=‚àí1 ùúá0ùúïEx ùúïz, (24.48) ùúïEx ùúït=‚àí1 ùúñ0ùúïHy ùúïz,ùúïEy ùúït=+1 ùúñ0ùúïHx ùúïz. (24.49) Wetakeasinitialconditionsawaveincidentfromtheleftalongthe zaxis,linearlypolarized (electricfielddirectionof45‚àò),withcorresponding,andperpendicular, Hcomponents: Ex(t=0)=0.1cos( 2ùúãx ùúÜ) ,Ey(t=0)=0.1cos( 2ùúãy ùúÜ) , (24.50) Hx(t=0)=0.1cos(2ùúãx ùúÜ),Hy(t=0)=0.1cos(2ùúãy ùúÜ). (24.51) Becauseonlytherelativephasesmatter,wesimplifythecalculationbyassumingthatthe Ey andHxcomponentsdonothavetheirphaseschanged,butthatthe ExandHycomponents do (in this case by ùúÜ‚àï4 when they leave the plate). Of course, after leaving the plate and travelinginfreespace,therearenofurtherchangesinrelativephase. 24.8.3 Algorithm and Exercise AsinSection24.7andFigure24.8,wefollowtheFDTDapproachofusingknownvaluesof ExandHyatthreeearliertimes,andthreedifferentspacepositions,toobtainthesolution at the present time. With the renormalized electric fields as in (24.35), this leads to the beautifullysymmetricequations: Ek,n+1 x=Ek,n x+ùõΩ( Hk+1,n y‚àíHk,n y) , (24.52) Ek,n+1 y=Ek,n y+ùõΩ( Hk+1,n x‚àíHk,n x) , (24.53) Hk,n+1 x=Hk,n x+ùõΩ( Ek+1,n y‚àíEk,n y) , (24.54) Hk,n+1 y=Hk,n y+ùõΩ( Ek+1,n x‚àíEk,n x) . (24.55) 24.8 More E&M Problems 495 1) Modifytheprogram FDTD.pyinListing24.3sothatitsolvesthealgorithm(24.52)‚Äì(24.55). UseùõΩ=0.01. (a) Aftereachtimestep,imposeagradualincrementofthephasesothatthetotalphase changewillbeonequarterofawavelength.Ourprogramforthisis quarterplat.py . (b) Verify that the plate converts an initially linearly polarized wave into a circularly polarizedone. (c) Verify that the plate converts an initially circularly polarized wave into a linearly polarizedone. (d) Whathappensifyouputtwoplatestogether?Three?Four?(Verify.) 24.8.4 Twin Lead Transmission Line Themodelofatwin-leadtransmissionlineconsistsoftwoparallelwiresonwhichalter- nating current or pulses propagate [Sullivan, 2000]. The equivalent circuit for a segment oflength ŒîxisshownontheleftofFigure24.12.Thereisaninductance LŒîx,aresistance RŒîx, a capacitance CŒîx, and a conductance (inverse resistance of the dielectricmaterial insulatingthewires) GŒîx.Thetelegrapher‚Äôsequationsdescribethevoltageandcurrent: ùúïV(x,t) ùúïx=‚àíRI‚àíLùúïI(x,t) ùúït, (24.56) ùúïI(x,t) ùúïx=‚àíGV‚àíCùúïV(x,t) ùúït. (24.57) Forlosslesstransmissionlines,thatisthosewith R=G=0,theequationsbecome: ùúïV(x,t) ùúïx=‚àíLùúïI(x,t) ùúït,ùúïI(x,t) ùúïx=‚àíCùúïV(x,t) ùúït. (24.58) Differentiationoftheseequations,andsubstitutionintooneanother,leadstothefamiliar 1Dwaveequation: ùúï2V(x,t) c2ùúït2‚àíùúï2V(x,t) ùúïx2=0,c=1‚àö LC. (24.59) a) Apply the leapfrog algorithm to the telegrapher‚Äôs equations (24.56), making sure to accountforthestabilitycondition: cŒît Œîx‚â§1.",3113
24.9 Code Listings,"(24.60) Experimentwithdifferentvaluesfor ŒîxandŒîtinordertoobtainbetterprecision,orto speedupthecomputation. b) Imposetheboundaryconditions V(0,t)=V(L,t)=0,whereListhelengthofthetrans- missionline. c) Useasinitialconditionsapulsewithaconstantvoltage: V(x,t=0)=10e‚àíx2‚àï0.1,ùúïV(x,t) ùúït=0. (24.61) d) Goodvaluestotryare L=0.1,C=2.5,Œît=0.025,and Œîx=0.05. e) Investigatetheeffectofazerovaluefortheconductance Gandtheresistance R.Doyour resultsagreewithwhatyoumightexpect? f) Fornonzero RandG,investigatethedistortionthatoccurswhenarectangularpulseis sentdownthetransmissionline.Atwhatpointwouldyousaythepulseshapebecomes unrecognizable? 496 24 Quantum Wave Packets and EM Waves 24.9 Code Listings Listing 24.1 HarmosAnimate.py solvesthetime-dependentSchr√∂dingerequationfor aGaussianwavepacketmovingwithinaharmonicoscillatorpotential. # HarmonsAnimate : Solve t ‚àídependent Sch Eqt for H O wi animation 2 fromvisualimport ‚àó # Initialize wave function , probability , potential 6dx = 0.04; dx2 = dx ‚àódx; k0 = 5.5 ‚àópi; dt = dx2/20.0; xmax = 6.0; beta = dt/dx2 xs = arange( ‚àíxmax,xmax+dx/2,dx) # Array x values 10g = display(width=500, height=250, title= ‚ÄôWave Packet in HO Well‚Äô ) PlotObj = curve(x=xs, color=color.yellow, radius=0.1) g.center = (0,2,0) # Center of scene # Initial wave packet 14R=e x p ( ‚àí0.5‚àó(xs/0.5) ‚àó‚àó2)‚àócos(k0 ‚àóxs) # Array Re I I=e x p ( ‚àí0.5‚àó(xs/0.5) ‚àó‚àó2)‚àósin(k0 ‚àóxs) # Array Im I V = 15.0 ‚àóxs‚àó‚àó2 # The potential 18whileTrue: rate(500) R[1:‚àí1] = R[1: ‚àí1]‚àíbeta ‚àó(I[2:]+I[: ‚àí2]‚àí2‚àóI[1:‚àí1])+dt ‚àóV[1:‚àí1]‚àóI[1:‚àí1] I[1:‚àí1] = I[1: ‚àí1] + beta ‚àó(R[2:]+R[: ‚àí2]‚àí2‚àóR[1:‚àí1])‚àídt‚àóV[1:‚àí1]‚àóR[1:‚àí1] 22PlotObj.y = 4 ‚àó(R‚àó‚àó2+I ‚àó‚àó2) Listing 24.2 3QMdisks.py solvesforawavepacketscatteringfrom3disks. # 3QMdisks. py : Wavepacket scattering from 3 disks wi MatPlot importmatplotlib.pylab as p, numpy as np 4frommpl_toolkits.mplot3d importAxes3D r = 10; N = 101; x1 = 51; # 51 = 90. ‚àósqrt 3/2 ‚àí30 dx = 0.1; dx2 = dx ‚àódx; k0 = 20.; k1 = 0. 8dt = 0.002; fc = dt/dx2; Xo = 40; Yo = 25 # Declare arrays V= n p . z e r o s ( ( N , N ) , float); Rho =np.zeros((N,N), float) RePsi = np.zeros((N,N), float); ImPsi =np.zeros((N,N), float) 12ix = np.arange(0, 101); iy = np.arange(0,101) X, Y = np.meshgrid(ix, iy) fig = p.figure(); ax = Axes3D(fig) # Create figure 16defPot1Disk(xa,ya): # Potential single disk foriin range (ya‚àír,ya+r+1): forjin range (xa‚àír,xa+r+1): ifnp. sqrt((i ‚àíya)‚àó‚àó2+(j‚àíxa)‚àó‚àó2)<=r: V[i ,j] = 5. 20 defPot3Disks(): # Potential three disk Pot1Disk(30,45); Pot1Disk(70,45); Pot1Disk(50,80) 24defPsi_0(Xo,Yo): # Initial Psi foriinnp.arange(0,N): forjinnp.arange(0, N): Gaussian = np.exp( ‚àí0.03‚àó(i‚àíYo)‚àó‚àó2‚àí0.03‚àó(j‚àíXo)‚àó‚àó2) 28 RePsi[i,j] = Gaussian ‚àónp.cos(k0 ‚àói+k1 ‚àój) ImPsi[i,j] = Gaussian ‚àónp.sin(k0 ‚àói+k1 ‚àój) Rho[i,j] = RePsi[i,j] ‚àó‚àó2+I m P s i [ i,j ] ‚àó‚àó2 + 0.01 Psi_0(Xo,Yo) # Psi a n d R h o initial 32Pot3Disks() # Initial Psi fortin range (0, 120): # 120‚àí>30 # Compute Psi t <120 ift percent5 == 0: print(‚Äôt =‚Äô,t) # Print ea 5th t ImPsi[1: ‚àí1,1:‚àí1] = ImPsi[1: ‚àí1,1:‚àí1] + fc ‚àó(RePsi[2: ,1: ‚àí1] \ 36 +R e P s i [ : ‚àí2, 1 :‚àí1]‚àí4‚àóRePsi[1: ‚àí1,1:‚àí1] + RePsi[1: ‚àí1,2: ]\ 24.9 Code Listings 497 +R e P s i [ 1 : ‚àí1, :‚àí2]) + V[1: ‚àí1,1:‚àí1]‚àódt‚àóRePsi[1: ‚àí1,1:‚àí1] RePsi[1: ‚àí1,1:‚àí1] = RePsi[1: ‚àí1,1:‚àí1]‚àífc‚àó(ImPsi[2: ,1: ‚àí1]\ +ImPsi[ : ‚àí2,1:‚àí1]‚àí4‚àóImPsi[1: ‚àí1,1:‚àí1] + ImPsi[1: ‚àí1,2: ]\ 40 +ImPsi[1: ‚àí1, :‚àí2]) + V[1: ‚àí1,1:‚àí1]‚àódt‚àóImPsi[1: ‚àí1,1:‚àí1] foriin range (1, N‚àí1): # Compute Rho forjin range (1,N‚àí1): ifV[i,j] .=0: RePsi[i,j] = 0; ImPsi[i,j] = 0 # Hard Disk 44 Rho[i , j] = 0.1 ‚àó(RePsi[i,j] ‚àó‚àó2+I m P s i [ i,j ] ‚àó‚àó2) + 0.0002 ‚àóV[i,j] X, Y = np.meshgrid(ix, iy) Z=R h o [ X , Y ] ax.set_xlabel( ‚Äôy‚Äô) 48ax.set_ylabel( ‚Äôx‚Äô) ax.set_zlabel( ‚ÄôRho(x,y)‚Äô ) ax.plot_wireframe(X, Y, Z, color = ‚Äôg‚Äô) print(\""finito\"" ) 52p.show() Listing 24.3 FDTD.py solvesMaxwell‚ÄôsequationsviaFDTDalgorithmforlinearlypolar- izedwavepropagationinthe zdirection.",3820
24.9 Code Listings,"# FDTD . py FDTD Maxwell ‚Äô s e q u a t i o n s i n 1 ‚àíD wi Visual 2 fromvisualimport ‚àó Xm = 201; Ym = 100; Zm = 100; ts = 2; beta = 0.01 6Ex = zeros((Xm, ts) , float); H y= zeros((X m,ts), float) # Declare arrays #S e t u p 3 ‚àíDP l o t s scene = display(x=0,y=0,width= 800, height= 500, \ title= ‚ÄôE: cyan, H: red. Periodic BC‚Äô ,forward=( ‚àí0.6,‚àí0.5,‚àí1)) 10Eplot = curve(x= list(range(0,Xm)),color=color.cyan,radius=1.5,display=scene) Hplot = curve(x= list(range(0,Xm)),color=color.red, radius=1.5,display=scene) vplane = curve(pos=[( ‚àíXm,Ym) ,(Xm,Ym) ,(Xm, ‚àíYm) ,(‚àíXm,‚àíYm) , (‚àíXm,Ym)],color=color.cyan) 14zaxis = curve(pos=[( ‚àíXm,0) ,(Xm,0)],color=color.magenta) hplane = curve(pos=[( ‚àíXm,0 ,Zm) ,(Xm,0 ,Zm) ,(Xm,0, ‚àíZm) ,(‚àíXm,0,‚àíZm) , (‚àíXm,0,Zm)],color=color.magenta) ball1 = sphere(pos = (Xm+30, 0,0), color = color.black, radius = 2) 18ExLabel1 = label( text = ‚ÄôEx‚Äô,p o s=( ‚àíXm‚àí10, 50), box=0) ExLabel2 = label( text = ‚ÄôEx‚Äô,p o s=( X m + 1 0 ,5 0 ) ,b o x = 0 ) HyLabel = label( text = ‚ÄôHy‚Äô,p o s=( ‚àíXm‚àí10, 0,50), box=0) zLabel = label( text = ‚ÄôZ‚Äô,p o s = ( X m + 1 0 , 0 ) , b o x = 0 ) 22 defPlotFields(): z = arange(Xm) Eplot.x = 2 ‚àóz‚àíXm # World to screen coords 26Eplot.y = 800 ‚àóEx[z,0] Hplot.x = 2 ‚àóz‚àíXm Hplot.z = 800 ‚àóHy[z,0] 30z = arange(Xm) Ex[:Xm,0] = 0.1 ‚àósin(2 ‚àópi‚àóz/100.0) # Initial field Hy[:Xm,0] = 0.1 ‚àósin(2 ‚àópi‚àóz/100.0) PlotFields() 34 whileTrue: rate(600) Ex[1:Xm ‚àí1,1] = Ex[1:Xm ‚àí1,0] + beta ‚àó(Hy[0:Xm ‚àí2,0]‚àíHy[2:Xm,0]) 38Hy[1:Xm ‚àí1,1] = Hy[1:Xm ‚àí1,0] + beta ‚àó(Ex[0:Xm ‚àí2,0]‚àíEx[2:Xm,0]) Ex[0,1] = Ex[0,0] + beta ‚àó(Hy[Xm‚àí2,0]‚àíHy[1,0]) #B C Ex[Xm‚àí1,1] = Ex[Xm ‚àí1,0] + beta ‚àó(Hy[Xm‚àí2,0]‚àíHy[1,0]) Hy[0 ,1] = Hy[0 ,0] + beta ‚àó(Ex[Xm‚àí2,0]‚àíEx[1,0]) #B C 42Hy[Xm‚àí1,1] = Hy[Xm ‚àí1,0] + beta ‚àó(Ex[Xm‚àí2,0]‚àíEx[1,0]) PlotFields() Ex[:Xm,0] = Ex[:Xm,1] #N e w‚àí>o l d Hy[:Xm,0] = Hy[:Xm,1] 498 24 Quantum Wave Packets and EM Waves Listing 24.4 QuarterPlate.py Maxwell‚Äôs equations solution via FDTD algorithm for quarterwaveplate. 1# QuarterPlate.py F D T D solution of Maxwell ‚Äôs equations in 1 ‚àíD fromvisualimport ‚àó 5xmax = 401; ymax = 100; zmax = 100; ts = 2; beta = 0.01 Ex = zeros((xmax, ts) , float); Ey = zeros((xmax, ts) , float); H x= zeros((xmax, ts) , float) Hy = zeros((xmax, ts) , float); Hyy = zeros((xmax, ts) , float) 9Exx = zeros((xmax, ts) , float); Eyy = zeros((xmax, ts) , float) Hxx = zeros((xmax, ts) , float) scene = display(x=0,y=0,width= 800, height= 500, 13 title= ‚ÄôEy : in cyan, Ex : in yellow. Propagation with periodic boundary conditions‚Äô , forward=( ‚àí0.8,‚àí0.3,‚àí0.7)) Exfield = curve(x= list(range(0,xmax)),color= color.yellow,radius=1.5,display=scene) Eyfield = curve(x= list(range(0,xmax)),color=color.cyan,radius=1.5,display=scene) 17vplane= curve(pos=[( ‚àíxmax,ymax) ,(xmax,ymax) ,(xmax, ‚àíymax),( ‚àíxmax,‚àíymax) , (‚àíxmax,ymax)],color=color.cyan) zaxis = curve(pos=[( ‚àíxmax,0) ,(xmax,0)],color=color.magenta) hplane = curve(pos=[( ‚àíxmax,0 ,zmax) ,(xmax,0 ,zmax) ,(xmax,0, ‚àízmax),( ‚àíxmax,0, ‚àízmax) , 21 (‚àíxmax,0,zmax)],color=color.magenta) ball1 = sphere(pos = (xmax+30, 0,0), color = color.black, radius = 2) ba2 = sphere(pos=(xmax ‚àí200,0),color=color.cyan,radius=3) plate = box(pos=( ‚àí100,0,0),height=2 ‚àózmax,width=2 ‚àóymax,length=0.5 ‚àóxmax, 25 color=(1.0,0.6,0.0),opacity=0.4) Exlabel1 = label( text = ‚ÄôEy‚Äô,p o s=( ‚àíxmax‚àí10, 50), box = 0 ) Exlabel2 = label( text = ‚ÄôEy‚Äô, pos = (xmax+10, 50) , box = 0 ) Eylabel = label( text = ‚ÄôEx‚Äô,p o s=( ‚àíxmax‚àí10, 0,50), box = 0 ) 29zlabel = label( text = ‚ÄôZ‚Äô, pos = (xmax+10, 0) , box = 0 ) polfield = arrow(display = scene) polfield2 = arrow(display = scene) ti = 0 33 defInitField(): kar = arange(xmax) phx = 0.5 ‚àópi 37Hyy[:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókar/100) Exx[:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókar/100) Eyy[:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókar/100) Hxx[:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókar/100) 41Ey[:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókar/100) Hx[:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókar/100) defInitExHy(): 45k = arange(101) Ex[:101,0] = 0.1 ‚àócos(‚àí2‚àópi‚àók/100) Hy[:101,0] = 0.1 ‚àócos(‚àí2‚àópi‚àók/100) kk = arange(101,202) # Inside plate , delay lambda/4 49Ex[101:202,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókk/100.0 ‚àí0.005 ‚àópi‚àó(kk‚àí101)) # pi/2 phase Hy[101:202,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókk/100.0 ‚àí0.005 ‚àópi‚àó(kk‚àí101)) kkk = arange(202,xmax) # After plate , phase diff pi/2 Ex[202:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókkk/100 ‚àí0.5‚àópi) 53Hy[202:xmax,0] = 0.1 ‚àócos(‚àí2‚àópi‚àókkk/100 ‚àí0.5‚àópi) defPlotFields(ti): # screen coordinates k = arange(xmax) 57Exfield.x = 2 ‚àók‚àíxmax # world to screen coords . Exfield.y = 800 ‚àóEy[k, ti] Eyfield.x = 2 ‚àók‚àíxmax # world to screen coords . Eyfield.z = 800 ‚àóEx[k, ti] 61 InitField() InitExHy() PlotFields(ti) 65j=0 24.9 Code Listings 499 end = 0 whileend<5: rate(150) 69Exx[1:xmax ‚àí1,1] = Exx[1:xmax ‚àí1,0] + beta ‚àó(Hyy[0:xmax ‚àí2,0]‚àíHyy[2:xmax,0]) Eyy[1:xmax ‚àí1,1] = Eyy[1:xmax ‚àí1,0] + beta ‚àó(Hxx[0:xmax ‚àí2,0]‚àíHxx[2:xmax,0]) Hyy[1:xmax ‚àí1,1] = Hyy[1:xmax ‚àí1,0] + beta ‚àó(Exx[0:xmax ‚àí2,0]‚àíExx[2:xmax,0]) Hxx[1:xmax ‚àí1,1] = Hxx[1:xmax ‚àí1,0] + beta ‚àó(Eyy[0:xmax ‚àí2,0]‚àíEyy[2:xmax,0]) 73Ex[1:xmax ‚àí1,1] = Ex[1:xmax ‚àí1,0] + beta ‚àó(Hy[0:xmax ‚àí2,0]‚àíHy[2:xmax,0]) Ey[1:xmax ‚àí1,1] = Ey[1:xmax ‚àí1,0] + beta ‚àó(Hxx[0:xmax ‚àí2,0]‚àíHxx[2:xmax,0]) Hy[1:xmax ‚àí1,1] = Hy[1:xmax ‚àí1,0] + beta ‚àó(Ex[0:xmax ‚àí2,0]‚àíEx[2:xmax,0]) Hx[1:xmax ‚àí1,1] = Hx[1:xmax ‚àí1,0] + beta ‚àó(Eyy[0:xmax ‚àí2,0]‚àíEyy[2:xmax,0]) 77polfield.pos = ( ‚àí280,0,0) polfield.axis = (0,700 ‚àóExx[60,1],700 ‚àóEyy[60,1]) polfield2.pos = (380,0,0) polfield2.axis = (0,700 ‚àóEx[360,1], ‚àí700‚àóEy[360,1]) 81Exx[0,1] = Exx[0,0] + beta ‚àó(Hyy[xmax ‚àí2,0]‚àíHyy[1 ,0]) # Periodic B C Eyy[0,1]= Eyy[0,0] + beta ‚àó(Hxx[xmax ‚àí2,0]‚àíHxx[1 ,0]) Hyy[0,1] = Hyy[0,0] + beta ‚àó(Exx[xmax ‚àí2,0]‚àíExx[1,0]) # Periodic BC, 0=100 Hxx[0,1] = Hxx[0,0] + beta ‚àó(Eyy[xmax ‚àí2,0]‚àíEyy[1,0]) 85Hyy[xmax ‚àí1,1] = Hyy[xmax ‚àí1,0] + beta ‚àó(Exx[xmax ‚àí2,0]‚àíExx[1,0]) Hxx[xmax ‚àí1,1] = Hxx[xmax ‚àí1,0] + beta ‚àó(Eyy[xmax ‚àí2,0]‚àíEyy[1,0]) Exx[xmax ‚àí1,1] = Exx[xmax ‚àí1,0] + beta ‚àó(Hyy[xmax ‚àí2,0]‚àíHyy[1 ,0]) #conditions for first Eyy[xmax ‚àí1,1] = Eyy[xmax ‚àí1,0] + beta ‚àó(Hxx[xmax ‚àí2,0]‚àíHxx[1 ,0]) 89Ex[0,1] = Exx[0,0] + beta ‚àó(Hyy[xmax ‚àí2,0]‚àíHyy[1 ,0]) # Periodic B C Ey[0,1] = Eyy[0,0] + beta ‚àó(Hxx[xmax ‚àí2,0]‚àíHxx[1 ,0]) Hy[0,1] = Hyy[0,0] + beta ‚àó(Exx[xmax ‚àí2,0]‚àíExx[1,0]) # Periodic B C 0=100 Hx[0,1] = Hxx[0,0] + beta ‚àó(Eyy[xmax ‚àí2,0]‚àíEyy[1,0]) 93Hy[xmax ‚àí1,1] = Hy[xmax ‚àí1,0] + beta ‚àó(Ex[xmax ‚àí2,0]‚àíEx[xmax ‚àí100,0]) Hx[xmax ‚àí1,1] = Hx[xmax ‚àí1,0] + beta ‚àó(Ey[xmax ‚àí2,0]‚àíEy[1,0]) Ex[xmax ‚àí1,1] = Ex[xmax ‚àí1,0] + beta ‚àó(Hy[xmax ‚àí2,0]‚àíHy[xmax ‚àí100,0]) Ey[xmax ‚àí1,1] = Ey[xmax ‚àí1,0] + beta ‚àó(Hxx[xmax ‚àí2,0]‚àíHxx[1 ,0]) 97PlotFields(ti) k = arange(101,202) Ex[101:202,1] = 0.1 ‚àócos(‚àí2‚àópi‚àók/100‚àí0.005 ‚àópi‚àó(k‚àí101)+2 ‚àópi‚àój/4996.004) Hy[101:202,1] = 0.1 ‚àócos(‚àí2‚àópi‚àók/100‚àí0.005 ‚àópi‚àó(k‚àí101)+2 ‚àópi‚àój/4996.004) 101Exx[:xmax,0] = Exx[:xmax,1] Eyy[:xmax,0] = Eyy[:xmax,1] Hyy[:xmax,0] = Hyy[:xmax,1] Hxx[:xmax,0] = Hxx[:xmax,1] 105Ex[:xmax,0] = Ex[:xmax,1] Ey[:xmax,0] = Ey[:xmax,1] Hx[:xmax,0] = Hx[:xmax,1] Hy[:xmax,0]= Hy[:xmax,1] 109ifj percent4996 == 0: j=0 end += 1 j=j + 1 Listing 24.5 EMCirc.py solvesMaxwell‚ÄôsequationsviaFDTDalgorithmforcircularly polarizedwavepropagationinthe zdirection.",6985
24.9 Code Listings,"# EMcirc.py: Maxwell eqs . for circular polarization using F D T D 2 fromvisualimport ‚àó scene = display(x=0,y=0,width=600,height=400, range=200, title= ‚ÄôCircular Polarized E (white) &H (yellow) Fields‚Äô ) 6globalphy, pyx max= 201; c = 0.01 #S t a b l e i fc <0.1 Ex = zeros(( max+2,2),float); Ey= zeros(( max+2,2),float) Hy = zeros (( max+2,2),float); H x= zeros(( max+2,2),float) 10arrowcol= color.white Earrows = []; Harrows = [] foriin range (0,max,10): Earrows.append(arrow(pos=(0,i ‚àí100,0), axis=(0,0,0), color=arrowcol)) 14Harrows.append(arrow(pos=(0,i ‚àí100,0), axis=(0,0,0), color=color.yellow)) defplotfields(Ex,Ey,Hx,Hy): 500 24 Quantum Wave Packets and EM Waves forn, arrin enumerate (Earrows): 18 arr.axis = (35 ‚àóEy[10 ‚àón,1],0,35 ‚àóEx[10 ‚àón,1]) forn, arrin enumerate (Harrows): arr.axis = (35 ‚àóHy[10 ‚àón,1],0,35 ‚àóHx[10 ‚àón,1]) definifields(): # Initial E &H 22phx = 0.5 ‚àópi; phy = 0.0 z = arange(0, max) Ex[:‚àí2,0] = cos( ‚àí2‚àópi‚àóz/200+phx); Ey[: ‚àí2,0] = cos( ‚àí2‚àópi‚àóz/200+phy) Hx[:‚àí2,0] = cos( ‚àí2‚àópi‚àóz/200+phy+pi); Hy[: ‚àí2,0] = cos( ‚àí2‚àópi‚àóz/200+phx) 26defnewfields(): whileTrue: # Time stepping rate(1000) Ex[1:max‚àí1,1] = Ex[1: max‚àí1,0]+c ‚àó(Hy[:max‚àí2,0]‚àíHy[2:max,0]) 30 Ey[1:max‚àí1,1] = Ey[1: max‚àí1,0] + c ‚àó(Hx[2:max,0]‚àíHx[:max‚àí2,0]) Hx[1:max‚àí1,1] = Hx[1: max‚àí1,0] + c ‚àó(Ey[2:max,0]‚àíEy[:max‚àí2,0]) Hy[1:max‚àí1,1] = Hy[1: max‚àí1,0] + c ‚àó(Ex[:max‚àí2,0]‚àíEx[2:max,0]) Ex[0,1] = Ex[0,0] + c ‚àó(Hy[200 ‚àí1,0]‚àíHy[1,0]) # Periodic B C 34 Ex[200,1] = Ex[200,0] + c ‚àó(Hy[200 ‚àí1,0]‚àíHy[1,0]) Ey[0,1] = Ey[0,0] + c ‚àó(Hx[1,0] ‚àíHx[200 ‚àí1,0]) Ey[200,1] = Ey[200,0] + c ‚àó(Hx[1,0] ‚àíHx[200 ‚àí1,0]) Hx[0 ,1] = Hx[0 ,0] + c ‚àó(Ey[1,0] ‚àíEy[200‚àí1,0]) 38 Hx[200,1] = Hx[200,0] + c ‚àó(Ey[1,0] ‚àíEy[200‚àí1,0]) Hy[0 ,1] = Hy[0 ,0] + c ‚àó(Ex[200 ‚àí1,0]‚àíEx[1,0]) Hy[200,1] = Hy[200,0] + c ‚àó(Ex[200 ‚àí1,0]‚àíEx[1,0]) plotfields(Ex,Ey,Hx,Hy) 42 Ex[:max,0] = Ex[: max,1]; Ey[: max,0] = Ey[: max,1] # Update fields Hx[:max,0] = Hx[: max,1]; Hy[: max,0] = Hy[: max,1] inifields() # Initial fields 46newfields() #N e wf i e l d s",1981
25.2.2 Implementation and Assessment,"501 25 Shock and Soliton Waves The Ô¨Årst half of this chapter extends the discussion of waves to include nonlinearities, dispersion, and hydrodynamic effects. We end up with the Korteweg-de Vries (KDV) equation and shallow-water solitons. The second half of this chapter explores a model for solids as a chain of coupled, nonlinear oscillators. We end up with the Sine-Gordon equation (SGE) and solitons in solids . In1844,J.ScottRussellreportedanunusualoccurrenceontheEdinburgh-Glasgowcanal [Russell,1844](Figure25.1left): Iwasobservingthemotionofaboatwhichwasrapidlydrawnalonganarrowchan- nelbyapairofhorses,whentheboatsuddenlystopped‚Äînotsothemassofwaterin the channel which it had put in motion; it accumulated round the prow of the ves- selinastateofviolentagitation,thensuddenlyleavingitbehind,rolledforwardwith greatvelocity,assumingtheformofalargesolitaryelevation,arounded,smoothand well-definedheapofwater,whichcontinueditscoursealongthechannel,apparently withoutchangeofformordiminutionofspeed.Ifolloweditonhorseback,andovertook itstillrollingonattherateofsomeeightorninemilesanhour,preservingitsoriginal figuresomethirtyfeetlongandafoottoafootandahalfinheight.Itsheightgradu- allydiminished,andafterachaseofoneortwomiles,Ilostitinthewindingsofthe channel.Such,inthemonthofAugust1834,wasmyfirstchanceinterviewwiththat singularandbeautifulphenomenon ‚Ä¶. Russellalsonoticedthataninitial,arbitrarywaveformsetinmotioninthechannelevolved intotwoormorewavesthatmovedatdifferentvelocities,andthattheyprogressivelymoved apart until they formed individual, solitary waves. In Figure 25.3 right, we see a single, step-like wave breaking up into approximately eight of these solitary waves (now called solitons).Theseeightsolitonsoccursofrequentlythatsomeofthereferencesconsiderthem theequivalentofthenormalmodesfornonlinearsystems.Russellwentontoproducethese solitarywavesinalaboratory,andempiricallydeducedthattheirspeed cisrelatedtothe depthhofthewaterinthecanal,andtotheamplitude Aofthewaveby, c2=g(h+A), (25.1) wheregistheaccelerationduetogravity. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 502 25 Shock and Soliton Waves 6 80 xt 40002468 120A hydrodynamic soliton Figure 25.1 Left:Two computed shallow-water solitary waves crossing each other. The taller soliton on the left catches up with and overtakes the shorter one at t‚âÉ5. The waves resume their original shapes after the collision. Right: A re-creation of Russel‚Äôs soliton on the Union Canal near Edinburgh in July 1995. (Used with permission, Scott [2007].) Equation (25.1) implies an effect not found in linear systems, namely, that waves with greateramplitudes Atravelfasterthanthosewithsmalleramplitudes.Observethatthisis similar to the formation of shock waves, but different from dispersionin which waves of differentwavelengthshavedifferentvelocities.Thedependenceof contheamplitude Ais illustratedinFigure25.1,whereweseeatallersolitoncatchingupwithandpassingthrough ashorterone.Indeed,thesesolitonsappeartoberelatedtotheformationof tsunamis,ocean wavesthatformfromsuddenchangesintheleveloftheoceanfloor,andthentravelover longdistanceswithoutdispersionorattenuation. Problem ExplainRussell‚Äôsobservations. 25.1 The Continuity and Advection Equations ThemotionoffluidsisdescribedbythecontinuityequationandtheNavier‚ÄìStokesequation [LandauandLifshitz,1976].WediscusstheformerhereandthelatterinChapter26.The continuityequationdescribesconservationofmass: ùúïùúå(x,t) ùúït+‚Éó‚àá‚ãÖj=0, jdef=ùúåv(x,t). (25.2) Here,ùúå(x,t)is the mass density of the fluid, v(x,t)is its velocity, and j=ùúåvis the mass current. As its name implies, the divergence ‚Éó‚àá‚ãÖjdescribes the spreading of the current in a region of space, as might occur if there were a current source there. Physically, the continuityequation(25.2)statesthatchangesinthedensityofthefluidwithinsomeregion ofspacearisesfromtheflowofcurrentinandoutofthatregion. For1Dflowinthe xdirection,andforafluidthatismovingwithaconstantvelocity ùë£=c, thecontinuityequation(25.2)takesasimpleform: ùúïùúå ùúït+cùúïùúå ùúïx=0. (25.3) 25.2 Shock Waves via Burgers‚Äô Equation 503 This is the advection equation , where the term ‚Äúadvection‚Äù is used to describe the hori- zontal transport of a quantity from one region of space to another as a result of a flow‚Äôs velocityfield.Forinstance,advectiondescribesthetransportationofdissolvedsaltinwater. Theadvectionequationlookslikeafirst-derivativeformofthewaveequation,andindeed, thetwoarerelated.Asimplesubstitutionprovesthatanyfunctionwiththeformofatrav- elingwave, u(x,t)=f(x‚àíct), (25.4) willbeasolutionoftheadvectionequation.Ifweconsiderasurferridingalongthecrest ofatravelingwave,thatis,remainingatthesamepositionrelativetothewave‚Äôsshapeas timechanges,thenthesurferdoesnotseetheshapeofthewavechangeintime,andthat impliesthat: x‚àíct=constant ‚áíx=ct+constant. (25.5) Thespeedofthesurfer dx‚àïdt=c,whichisaconstant.Anyfunction f(x‚àíct)isclearlya travelingwavesolutioninwhichanarbitrarypulseiscarriedalongwiththefluidatvelocity cwithoutchangingshape. Although the advection equation is simple, trying to solve it by a simple finite differ- ence scheme (the leapfrog method) may lead to unstable numerical solutions. As we shall see when we look at the nonlinear version of this equation, there are better ways. Listing 25.1 presents our code AdvecLax.py for solving the advection equation using the Lax-Wendroffmethod(abetterway). 25.2 Shock Waves via Burgers‚Äô Equation InSection25.4,wewillexaminetheKorteweg-deVriesequation‚Äôsdescriptionofsolitary waves. In order to understand the physics contained in that equation, we study, one at a time, some of the terms in it. We start with two equivalent forms of Burgers‚Äô equation [Burgers,1974]: ùúïu ùúït+ùúñuùúïu ùúïx=0, (25.6) ùúïu ùúït+ùúñùúï(u2‚àï2) ùúïx=0, (25.7) wherethesecondequationisthe conservativeform .Thisequationcanbeviewedasavari- ation on the advection equation (25.3), now with the wave speed c=ùúñuproportional to the amplitude of the wave, as Russell found for his waves. The second, nonlinear term inBurgers‚Äôequationleadstosomeunusualbehaviors.Indeed,vonNeumannstudiedthis equationasasimplemodelforturbulence[FalkovichandSreenivasan,2006]. Intheadvectionequation(25.3),allpointsonthewavemoveatthesamespeed c,andso theshapeofthewaveremainsunchangedintime.InBurgers‚Äôequation(25.6),thepoints on the wave move (‚Äúadvect‚Äù) themselves such that the local speed depends on the local wave‚Äôsamplitude,withthehighpartsofthewavemovingprogressivelyfasterthanthelow parts.Thischangestheshapeofthewaveintime;ifwestartwithawavepacketthathas asmoothvariationinheight,thehighpartswillspeedupandpushtheirwaytothefront 504 25 Shock and Soliton Waves 0 2001204 xtu(x, t) Figure 25.2 A visualization showing the formation of a shock wave (sharp edge) in a solution to Burgers‚Äô equation that started with a sine wave. ofthepacket,therebyformingasharpleadingedgeknownasa shockwave [Tabor,1989]. AshockwavesolutiontoBurgers‚Äôequationwith ùúñ=1isshowninFigure25.2. 25.2.1 Lax‚ÄìWendroff Algorithm We first solve Burgers‚Äô equation (25.3) via the usual approach in which we express the derivatives as central differences. This leads to a leapfrog scheme for the future solution intermsofpresentandpastones: u(x,t+Œît)=u(x,t‚àíŒît)‚àíùõΩ 2[u2(x+Œîx,t)‚àíu2(x‚àíŒîx,t)], (25.8) ui,j+1=ui,j‚àí1‚àíùõΩ 2[u2 i+1,j‚àíu2 i‚àí1,j],ùõΩ=ùúñŒît Œîx(CFLnumber) . Hereu2is the square of u, not its second derivative, and ùõΩis a ratio of constants known astheCourant‚ÄìFriedrichs‚ÄìLewy (CFL)number.Asyoushouldproveforyourself, ùõΩ<1is requiredforstability. WhilewehaveusedaleapfrogmethodwithsuccessinourprevioussolutionofPDEs,its low-orderapproximationforthederivativebecomesinaccuratewhenthegradientscanget large,ashappenswithshockwaves,andthismaycausetheleapfrogalgorithmtobecome unstable[Press etal.,2007].The Lax‚ÄìWendroffmethod attainsbetterstabilityandaccuracy byretainingsecond-orderdifferencesforthetimederivative: u(x,t+Œît)‚âÉu(x,t)+ùúïu ùúïtŒît+1 2ùúï2u ùúït2Œît2. (25.9) Tocovert(25.9)toanalgorithm,weuseBurgers‚Äôequation ùúïu‚àïùúït=‚àíùúñùúï(u2‚àï2)‚àïùúïxforthe first-ordertimederivative.Likewise,weuseBurger‚Äôsequationtoexpressthesecond-order timederivativeintermsofspacederivatives: ùúï2u ùúït2=ùúï ùúït[ ‚àíùúñùúï ùúïx( u2 2)] =‚àíùúñùúï ùúïxùúï ùúït( u2 2) (25.10) =‚àíùúñùúï ùúïx( uùúïu ùúït) =ùúñ2ùúï ùúïx[ uùúï ùúïx( u2 2)] . (25.11) WenextsubstitutethesederivativesintotheTaylorexpansion(25.9)toobtain: u(x,t+Œît)=u(x,t)‚àíŒîtùúñùúï ùúïx(u2 2)+(Œît)2 2ùúñ2ùúï ùúïx[ uùúï ùúïx(u2 2)] . (25.12)",8383
25.4.3 Implementation,"25.3 Including Dispersion 505 Wenowreplacetheouter xderivativesbycentraldifferencesofspacing Œîx‚àï2: u(x,t+Œît)=u(x,t)‚àíŒîtùúñ 2u2(x+Œîx,t)‚àíu2(x‚àíŒîx,t) 2Œîx+(Œît)2ùúñ2 2(25.13) √ó1 2Œîx[ u(x+Œîx 2,t)ùúï ùúïxu2(x+Œîx 2,t)‚àíu(x‚àíŒîx 2,t)ùúï ùúïxu2(x‚àíŒîx 2,t)] . Nextweapproximate u(x¬±Œîx‚àï2,t)bytheaverageofadjacentgridpoints, u(x¬±Œîx 2,t)‚âÉu(x,t)+u(x¬±Œîx,t) 2, (25.14) andapplyacentral-differenceapproximationtothesecondderivatives: ùúïu2(x¬±Œîx‚àï2,t) ùúïx=u2(x¬±Œîx,t)‚àíu2(x,t) ¬±Œîx. (25.15) Finally,puttingallthesederivativestogetheryieldsthealgorithm: ui,j+1=ui,j‚àíùõΩ 4(u2 i+1,j‚àíu2 i‚àí1,j) (25.16) +ùõΩ2 8[ (ui+1,j+ui,j)(u2 i+1,j‚àíu2 i,j)‚àí(ui,j+ui‚àí1,j)(u2 i,j‚àíu2 i‚àí1,j)] , wherewehavesubstitutedtheCFLnumber ùõΩ.ThisLax‚ÄìWendroffschemeisexplicit,cen- tereduponthegridpoints,andstablefor ùõΩ<1(smallnonlinearities). 25.2.2 Implementation and Assessment SolveBurgers‚Äôequation(25.7)viatheleapfrogmethod. 1) Definearrays u0[100]and u[100]fortheoldandnewwaves. 2) Taketheinitialwavetobesinusoidal, u0[i]=3sin(3.2x),withspeed c=1. 3) Incorporatetheboundaryconditions u[0]=0and u[100]=0. 4) KeeptheCFLnumber ùõΩ<1forstability. 5) Savetheinitialwaveandthesolutionsforanumberoftimesinseparatefiles,andplot themonthesamegraphinordertoseetheformationofashockwave(likeFigure25.2). 6) Modify your program to solve Burgers‚Äô equation using the Lax‚ÄìWendroff method (25.16),andcompareitwiththeleapfrogmethod.Theleapfrogmethodshouldproduce shock waves, but with ripples as the square edge develops. The ripples are numerical artifacts. The Lax‚ÄìWendroff method should give a better square edge, although some ripplesmaystilloccur. 7) RunthecodeforseveralincreasinglylargeCFLvaluesandcheckifthestabilitycondi- tionùõΩ<1iscorrect. OurLax‚ÄìWendroffcode AdvecLax.py isgiveninListing25.1. 25.3 Including Dispersion WehavejustseenthatBurgers‚Äôequationhasasolutioninwhichaninitiallysmoothwave transformsintoasquare-edgedshockwave.Asortofinverseofthisis dispersion,inwhich a waveform disperses, or broadens, as it travel through a medium. Dispersion does not 506 25 Shock and Soliton Waves causewavestoloseenergyorattenuate,butitdoesleadtoalossofinformationwithtime. Physically, dispersion is important when the propagating medium has structures with a spatialregularityequaltosomefractionofawavelength.Mathematically,dispersionmay arise from terms in the wave equation that contain higher-order space derivatives. For example,considerthewaveform: u(x,t)=e¬±i(kx‚àíùúît), (25.17) correspondingtoaplanewavetravelingtotheright(‚Äútraveling‚Äùbecausethephase kx‚àíùúît remainsunchangedifyouincrease xwithtime). Whenthis u(x,t)is substituted intothe advectionequation(25.3),weobtain: ùúî=ck. (25.18) Thisequationisa dispersionrelation ,thatis,arelationbetweenfrequency ùúîandwavevector k.Becausegroupvelocity ofawaveis: ùë£g=ùúïùúî ùúïk, (25.19) thelineardispersionrelation(25.18)impliesthatallfrequencieshavethesamegroupveloc- ityc.Thisisdispersionless propagation. Letusnowimaginethatawaveispropagatingwithasmallamountof dispersion,thatis, withafrequencythathassmallcorrectiontothelinearincreasewiththewavenumber: ùúî‚âÉck‚àíùõΩk3. (25.20) Notethatbecausetherearenoevenpowersin(25.20),thegroupvelocity, ùë£g=dùúî dk‚âÉc‚àí3ùõΩk2, (25.21) isthesameforwavestravelingtotheleft,ortheright.Nowweworkbackwardsanddeduce whatmightbethewaveequationthatproducedthisdispersion.Ifwehaveaplane-wave solutionlike(25.17),the ùúîterminthedispersionrelation(25.20)wouldarisefromafirst- ordertimederivative.Likewise,the cktermwouldarisefromafirst-orderspacederivative, andthek3termfromathird-orderspacederivative.Andthus,thewaveequation: ùúïu(x,t) ùúït+cùúïu(x,t) ùúïx+ùõΩùúï3u(x,t) ùúïx3=0. (25.22) Weleaveitasanexercisetoshowthatsolutionstothisequationdoindeedhavewaveforms thatdisperseintime. 25.4 KdeV Solitons Nowwecanputtogetherallthepiecesthatareneededtounderstandtheunusualwater wavesthatoccurinshallow,narrowchannelssuchascanals[Abar93,Tab89].Theanalytic descriptionofthis‚Äúheapofwater‚ÄùwasgivenbyKorteweganddeVries[1895]withthe KdeV equation: ùúïu(x,t) ùúït+ùúÄu(x,t)ùúïu(x,t) ùúïx+ùúáùúï3u(x,t) ùúïx3=0. (25.23) 25.4 KdeV Solitons 507 0204060x048 t01212 3 4 5 6 7 8 Figure 25.3 The formation of a tsunami. A single two-level waveform at time zero progressively breaks up into eight solitons (labeled) as time increases. The tallest soliton (1) is narrower and faster than the others in its motion to the right. You can generate an animation of this with the program SolitonAnimate.py . AswediscussedinSection25.2inourstudyofBurgers‚Äôequation,thenonlinear ùúÄuùúïu‚àïùúït termleadstoasharpeningofthewave,andultimatelya shockwave.Incontrast,asweknow fromourdiscussionofdispersion,the ùúï3u‚àïùúïx3termtendstobroadenawaveform,whilethe ùúïu‚àïùúïttermproducesatravelingwave. Fortheproperparametersandinitialconditions,the dispersivebroadeningexactlybalancesthenonlinearnarrowing,andastabletravelingwave, asoliton,isformed . KorteweganddeVries[1895]solved(25.23)analytically,andprovedthatthespeed(25.1) givenbyRussellis,infact,correct.Seventyyearsafteritsdiscovery,theKdeVequationwas rediscoveredbyZabuskyandKruskal[1965],whosolveditnumericallyandfoundthata step-likeinitialconditionbrokeupintoeightsolitarywaves(Figure25.3).Theyalsofound that the parts of the wave with larger amplitudes moved faster than those with smaller amplitudes.Thisiswhy,atlatertimes,thehigherpeakstendtobeontherightinFigure25.3. As if wonders never cease, Zabusky and Kruskal, who coined the name solitonfor these solitary waves, also observed that a faster peak passed unscathed through a slower one (Figure25.1). 25.4.1 Analytic Solution The trick in analytic approaches to these types of nonlinear equations is to substitute a guessedsolutionthathastheformofatravelingwave, u(x,t)=u(ùúâ=x‚àíct). (25.24) Thisformmeansthatifwemovewithaconstantspeed c,wewillseeaconstantwaveform. There is no guarantee that this form of a solution will exist, but it may lead you to one. Substituting(25.24)intotheKdeVequationproducesasolvableODE: ‚àícùúïu ùúïùúâ+ùúñuùúïu ùúïùúâ+ùúád3u dùúâ3=0, (25.25) ‚áíu(x,t)=‚àíc 2sech2[1 2‚àö c(x‚àíct‚àíùúâ0)], (25.26) whereùúâ0istheinitialphase.Weseeinthesolitonwaveform,(25.26),anamplitudethatis proportionaltothewavespeed c,andasech2functionthatgivesasinglelump-likewave. 508 25 Shock and Soliton Waves 25.4.2 Algorithm TheKdeVequationissolvednumericallyusingafinite-differencescheme,withthetime andspacederivativesgivenbycentral-differenceapproximations: ùúïu ùúït‚âÉui,j+1‚àíui,j‚àí1 2Œît,ùúïu ùúïx‚âÉui+1,j‚àíui‚àí1,j 2Œîx. (25.27) Toapproximate ùúï3u(x,t)‚àïùúïx3,weexpand u(x,t)toÓàª(Œît)3aboutthefourpoints u(x¬±2Œîx,t) andu(x¬±Œîx,t): u(x¬±Œîx,t)‚âÉu(x,t)¬±(Œîx)ùúïu ùúïx+(Œîx)2 2.ùúï2u ùúï2x¬±(Œîx)3 3.ùúï3u ùúïx3. (25.28) Wesolvethisfor ùúï3u(x,t)‚àïùúïx3.Finally,thefactor u(x,t)inthesecondtermof(25.23)istaken astheaverageofthree xvalues,allwiththesame t: u(x,t)‚âÉui+1,j+ui,j+ui‚àí1,j 3. (25.29) WesubstitutetheseapproximationstoobtainthealgorithmfortheKdeVequation: ui,j+1‚âÉui,j‚àí1‚àíùúñ 3Œît Œîx[ui+1,j+ui,j+ui‚àí1,j][ui+1,j‚àíui‚àí1,j] ‚àíùúáŒît (Œîx)3[ui+2,j+2ui‚àí1,j‚àí2ui+1,j‚àíui‚àí2,j]. (25.30) The algorithm predicts u(x,t)at future times, given the solutions at the present and past times. The initial condition provides ui,1for all positions i.T ofi n dui,2,w eu s et h e forward-differenceschemeinwhichweexpand u(x,t),keepingonlytwotermsforthetime derivative: ui,2‚âÉui,1‚àíùúñŒît 6Œîx[ui+1,1+ui,1+ui‚àí1,1][ui+1,1‚àíui‚àí1,1] ‚àíùúá 2Œît (Œîx)3[ui+2,1+2ui‚àí1,1‚àí2ui+1,1‚àíui‚àí2,1]. (25.31) Thekeenobserverwillnotethattherearestillsomeundefinedcolumnsofpoints,namely, u1,j,u2,j,uNmax‚àí1,j,anduNmax,j,whereNmaxisthetotalnumberofgridpoints.Asimpletech- niquefordeterminingtheirvalueistoassumethat u1,2=1anduNmax,2=0.Toobtain u2,2 anduNmax‚àí1,2,weassumethat ui+2,2=ui+1,2,andui‚àí2,2=ui‚àí1,2.(However,weavoid ui+2,2for i=Nmax‚àí1,andui‚àí2,2fori=2).Wecarryoutthesesteps,approximate(25.31),andthus simplifytherelationto: ui+2,2+2ui‚àí1,2‚àí2ui+1,2‚àíui‚àí2,2‚âÉui‚àí1,2‚àíui+1,2. (25.32) Thetruncationerrorandstabilityconditionforthisalgorithmarerelated: Óà±(u)=Óàª[(Œît)3]+Óàª[Œît(Œîx)2](Error), (25.33) Œît Œîx[ùúñ|u|+4ùúá (Œîx)2]‚â§1 (Stability) . (25.34) Thefirstequationimpliesthatsmallertimeandspacestepsleadtoasmallerapproximation error.Yet,asdiscussedinChapter3,ifthestepsmadeareverysmall,thenyouwillneedto takealargenumberofsteps,andthentheround-offerrormaygettoolarge.Somebalance isalsoindicatedbythestabilitycondition(25.34),whereweseethatmaking Œîxtoosmall leadstoinstability.Someexperimentationisadvised.",8145
25.6.1 Analytic Solution,"25.4 KdeV Solitons 509 25.4.3 Implementation Modifyorruntheprogram Soliton.py inListing19.2thatsolvestheKdeVequation(25.23) fortheinitialcondition: u(x,t=0)=1 2[ 1‚àítanh( x‚àí25 5)] , (25.35) withparameters ùúñ=0.2andùúá=0.1.Startwith Œîx=0.4andŒît=0.1.Theseconstantssat- isfy(25.33)with |u|=1.Thecode SolitonAnimate.py producesananimation. 1) Define a 2D array u[131,3], with the first index corresponding to the position x,a n d the second to the time t. With our choice of parameters, the maximum value for xis 130√ó0.4=52. 2) Initializethetimeto t=0,andassignvaluesto u[i,1]. 3) Assign values to u[i,2],i=3,4,‚Ä¶,129, corresponding to the next time interval. Use (25.31) to advance the time, but note that you cannot start at i=1, or end at i=131, because(25.31)wouldinclude u[132,2]and u[-1,1],whicharebeyondthelimitsofthe array. 4) Increment time, and assume that u[1,2]=1a n d u[131,2] =0. To obtain u[2,2]and u[130,2], assume that u[i+2,2] =u[i+1,2]and u[i-2,2] =u[i-1,2].A v o i d u[i+2,2] fori=130,a n d u[i-2,2]fori=2. To do this, approximate (25.31) so that (25.33) is satisfied. 5) Incrementtime,andcompute u[i, j]forj=3,andfor i=3, 4,‚Ñ©, 129,usingequation (25.30).Again,followthesameprocedurestoobtainthemissingarrayelements u[2, j] and u[130, j](set u[1, j]=1.and u[131, j] =0).Printoutthenumbersduringtheiter- ations,andcheckthatthesearegoodchoices. 6) Set u[i,1]=u[i,2],and u[i,2]=u[i,3]forall i.Inthisway,youarereadytofindthe next u[i,j]intermsoftheprevioustworows. 7) Repeat the previous two steps at least 2000 times. Write your solution in a file after approximatelyevery250iterations. 8) Plotyourresultsasa3Dgraphofdisturbance uversuspositionandtime. 9) Observethewaveprofileasafunctionoftime,andtrytoconfirmRussell‚Äôsobservation thatatallersolitontravelsfasterthanasmallerone. 25.4.4 Exploration: Phase Space Solitons and Soliton Crossings 1) Explorewhathappenswhenatallsolitoncollideswithashortone. (a) Startbyplacingatallsolitonofheight0.8at x=12andasmallersolitoninfrontof itatx=26: u(x,t=0)=0.8[ 1‚àítanh2( 3x 12‚àí3)] +0.3[ 1‚àítanh2( 4.5x 26‚àí4.5)] . (25.36) (b) Dothetwosolitonsreflectoffeachother?Dotheygothrougheachother?Dothey interfere?Doesthetallsolitonstillmovefasterthantheshortoneafterthecollision (Figure25.1)? 2) Constructphasespaceplotsof[ Ãáu(t)vsu(t)]forallt‚Äôs.Tryoutvariousparametervalues. Notethatonlyspecificsetsofparametersproducesolitons.Inparticular,bycorrelating 510 25 Shock and Soliton Waves thebehaviorofthesolutionswithyourphase-spaceplots,showthatthesolitonsolutions correspond to the separatrixsolutions to the KdeV equation. In other words, the sta- bility in time for solitons is analogous to the infinite period for a pendulum balanced straightup. 25.5 Pendulum Chain Solitons In 1955, Fermi et al. [1955] published their investigation of how a 1D chain of coupled oscillators disperses waves. Since waves of differing frequencies traveled through the chain with differing speeds, they found that a pulse, which inherently includes a range offrequencies,broadensastimeprogresses.Surprisingly,whentheoscillatorsweremade morerealisticbyintroducinganonlineartermintoHooke‚Äôslaw, F(x)‚âÉ‚àík(x+ùõºx2), (25.37) the authors found that a sharp pulse could survive indefinitely, even in the presence of dispersion. Problem Developamodelthatexplainshowacombinationofdispersionandnonlinear- itycanleadtoastablepulseinachainofcoupledoscillators. We take a chain of realistic pendulums as our model for coupled oscillators, and in this way, extend our study of a nonlinear, single pendulum in Chapter 16. Figure 25.4 shows ourchainofidentical,equally-spacedpendulums,withthecouplingsbetweenpendulums providedbytorsionbarsthattwistasthependulumsswing.Theangle ùúÉimeasuresthedis- placement of pendulum ifrom its equilibrium position, and the parameter ais the fixed distance betweenpivotpoints. If allthe pendulums are setoff swingingtogether,thatis, withùúÉi‚â°ùúÉj, the coupling torques would vanish and we would have our old friend, the equation for a realistic pendulum. We assume that three torques act on each pendulum, agravitationaltorquetryingtoreturnthependulumtoitsequilibriumposition,andtwo torquesfromthetwistingofthebartotherightandleftofthependulum.Theequationof motionforpendulum jfollowsfromNewton‚Äôslawforrotationalmotion: Id2ùúÉj(t) dt2=‚àë j‚â†iùúèji, (25.38) =‚àíùúÖ(ùúÉj‚àíùúÉj‚àí1)‚àíùúÖ(ùúÉj‚àíùúÉj+1)‚àímgLsinùúÉj, (25.39) ‚áíId2ùúÉj(t) dt2=ùúÖ(ùúÉj+1‚àí2ùúÉj+ùúÉj‚àí1)‚àímgLsinùúÉj. (25.40) Here,Iisthemomentofinertiaofeachpendulum, Listhelengthofeachpendulum,and ùúÖisthetorqueconstantofthebar.Aswithourpreviousstudyoftherealisticpendulum, aa a a Œ∏1 Œ∏2Œ∏3Œ∏4 Œ∏5Figure 25.4 A 1D chain of pendulums, coupled via torsion bars between the pendulums. The pendulums swing in planes perpendicular to the length of the bar. 25.5 Pendulum Chain Solitons 511 the nonlinearity in (25.40) arises from the sin ùúÉ‚âÉùúÉ‚àíùúÉ3‚àï6+‚Ä¶dependence of the gravitational torque. Equation (25.40) is a set of coupled nonlinear equations, with the numberofequationsequaltothenumberofoscillators,whichwouldbelargeformodelof arealisticsolid.Nowwewanttoincludesomedispersioninthemotionofthependulums. 25.5.1 Including Dispersion Considerasurferonthecrestofawave.Sinceshedoesnotseethewaveformchangewith time,herpositionisgivenbyafunctionoftheform f(kx‚àíùúît).Consequently,toher,the wavehasaconstantphase: kx‚àíùúît=constant. (25.41) Thesurfer‚Äôsphasevelocityisthusconstant: ùë£p=dx dt=ùúî k. (25.42) Ingeneral,thefrequency ùúîmayhaveanonlineardependenceon k,andthisleadstothe phasevelocityvaryingwithfrequency,and,consequently, dispersion.Ifthewavewasapulse containingarangeofFouriercomponents,thenitwouldbroadenandchangeshapeintime, aseachfrequencymoveswithadifferentvelocity.So,althoughdispersiondoesnotleadto energyloss,itleadstoalossofinformationaspulsesbroadenandoverlap. Thefunctionalrelationbetweenfrequency ùúîandthewavevector kis,ofcourse,a dis- persionrelation .IftheFouriercomponentsinawavepacketarecenteredaroundamean frequency ùúî0,thenthepulse‚Äôsinformationtravels,notwiththephasevelocity ùë£p,butwith thegroupvelocity : ùë£g=ùúïùúî ùúïk||||ùúî=ùúî0. (25.43) Acomparisonof(25.42)and(25.43)makesitclearthatwhenthereisdispersion,groupand phasevelocitiesmaywelldiffer. Toisolatethepuredispersiveaspectof(25.40),weexamineitslinearversion: d2ùúÉj(t) dt2+ùúî2 0ùúÉj(t)=ùúÖ I(ùúÉj+1‚àí2ùúÉj+ùúÉj‚àí1), (25.44) whereùúî0=‚àö mgL‚àïIisthenaturalfrequencyofanyonependulum.Wewanttodetermine if a wave with a single frequency can propagate on this chain. To do that, we assume a travelingwavewithfrequency ùúîandwavelength ùúÜ, ùúÉj(t)=Aei(ùúît‚àíkxj),k=2ùúã ùúÜ. (25.45) Substitution of (25.45) into the wave equation (25.44) produces the dispersion relation (Figure25.5): ùúî2=ùúî2 0‚àí2ùúÖ I(1‚àícoska),(dispersionrelation) . (25.46) Indispersionlesspropagation,allfrequenciespropagatewiththesamevelocity c.T ohave that,weneedalinearrelationbetween ùúîandk: ùúÜ=c2ùúã ùúî‚áíùúî=ck,(dispersionlesspropagation) . (25.47) 512 25 Shock and Soliton Waves kœÄ/aœâ0œâ*œâ ‚ÄìœÄ/aFigure 25.5 The dispersion relation for a linearized chain of pendulums. Thiswillbetrueforthechainonlyif kaissmallenoughforcos ka‚âÉ1,inwhichcase ùúî‚âÉùúî0. Notonlydoesthedispersionrelation(25.46)changethespeedofwaves,itactuallylimits whichfrequenciescanpropagateonthechain.Inordertohavereal ksolutions, ùúîmustlie intherange: ùúî0‚â§ùúî‚â§ùúî‚àó(wavespropagation). (25.48) Theminimumfrequency ùúî0andthemaximumfrequency ùúî‚àóarerelatedthroughthelimits ofcoskain(25.46), (ùúî‚àó)2=ùúî2 0+4ùúÖ I. (25.49) Waveswith ùúî<ùúî0donotpropagate,whilethosewith ùúî>ùúî‚àóarenonphysicalbecausethey correspondtowavelengths ùúÜ<2a,thatis,oscillationswheretherearenoparticles.These highandlow ùúîcutoffschangetheshapeofapropagatingpulse,thatis,causedispersion. 25.6 Continuum Limit, the Sine-Gordon Equation If the wavelengths in a pulse are longer than the distance abetween pendulums, then ka‚â™1, and the chain can be approximated as a continuous medium. In this limit, abecomes the continuous variable x,a n dt h es y s t e mo fc o u p l e d ordinarydifferential equationsbecomesasingle, partialdifferentialequation: ùúÉj+1‚âÉùúÉj+ùúïùúÉ ùúïxŒîx, (25.50) ‚áí(ùúÉj+1‚àí2ùúÉj+ùúÉj‚àí1)‚âÉùúï2ùúÉ ùúïx2Œîx2‚â°ùúï2ùúÉ ùúïx2a2, (25.51) ‚áíùúï2ùúÉ ùúït2‚àíùúÖa2 Iùúï2ùúÉ ùúïx2=mgL IsinùúÉ. (25.52) Ifwemeasuretimeinunitsof‚àö I‚àïmgLanddistancesinunitsof‚àö ùúÖa‚àï(mgLb),weobtain thestandardformofthesine-Gordonequation(SGE):1 1 c2ùúï2ùúÉ ùúït2‚àíùúï2ùúÉ ùúïx2=sinùúÉ (SGE). (25.53) ThesinùúÉontheRHSintroducesnonlineareffects. 1 Thename‚Äúsine-Gordon‚ÄùiseitherareminderthattheSGEisliketheKlein-Gordonequationof relativisticquantummechanicswithasin uaddedtotheRHS,orareminderofhowcleveronecanbein thinkingupnames.",8371
25.6.3 Implementation,"25.6 Continuum Limit, the Sine-Gordon Equation 513 25.6.1 Analytic Solution Althoughsimplelooking,thenonlinearityofthesine-GordonPDE(25.53)makesithardto solveanalytically.Thereis,however,atrick:aswedidforsolitons,guessafunctionalform ofatravelingwave,substituteitinto(25.53),andtherebyconvertthePDEintoasolvable ODE: ùúÉ(x,t)?=ùúÉ(ùúâ=t¬±x‚àïùë£), ‚áíd2ùúÉ dùúâ2=ùë£2 ùë£2‚àí1sinùúÉ. (25.54) Youshouldrecognize(25.54)asouroldfriend,theequationofmotionforarealisticpen- dulumwithnodrivingforceandnofriction.Theconstant ùë£isavelocityinnaturalunits, andseparatesdifferentregimesofthemotion: ùë£<1‚à∂pendulainitiallydown ‚Üì‚Üì‚Üì‚Üì‚Üì(stable), ùë£>1‚à∂pendulainitiallyup ‚Üë‚Üë‚Üë‚Üë‚Üë(unstable).(25.55) Althoughtheequationisfamiliar,weknowthatananalyticsolutiondoesnotexists.How- ever,foranenergy E=¬±1,wehaveseparatrixmotion,andasolutionwithcharacteristic solitonform, ùúÉ(x‚àíùë£t)=‚éß ‚é™ ‚é® ‚é™‚é©4tan‚àí1( exp[ +x‚àíùë£t‚àö 1‚àíùë£2]) ,forE=1, 4tan‚àí1( exp[ ‚àíx‚àíùë£t‚àö 1‚àíùë£2]) +ùúã,forE=‚àí1.(25.56) This soliton corresponds to a solitary kink, traveling with velocity ùë£=‚àí1, that flips the pendulumsaroundby2 ùúãasitmovesdownthechain.Thereisalsoan antikinkinwhich theinitial ùúÉ=ùúãvaluesareflippedtofinal ùúÉ=‚àíùúã. 25.6.2 Numeric 2D Solitons (Pulsons) Ittookabitofmanipulation,butwehavealreadyfoundhowtosolvetheKdeVequation for1Dsolitons.Theelastic-wavesolitonsthatarisefromtheSGEcanbeeasilygeneralized totwodimensions,aswedoherewiththe2DgeneralizationoftheSGEequation(25.53): 1 c2ùúï2u ùúït2‚àíùúï2u ùúïx2‚àíùúï2u ùúïy2=sinu(2DSGE) . (25.57) Whereasthe1DSGEdescribeswavepropagationalongachainofconnectedpendulums, the 2D form might describe wave propagation in nonlinear elastic media. Interestingly enough,thesame2DSGEalsooccursinquantumfieldtheory,wherethesolitonsolutions havebeensuggestedasmodelsforelementaryparticles[ChristiansenandLomdahl,1981; ChristiansenandOlsen,1979].Theideaisthat,likeelementaryparticles,thesolutionsare confinedtoaregionofspaceforalongperiodoftimebynonlinearforces,anddonotradiate awaytheirenergy. Wesolve(25.57)inthefiniteregionof2Dspaceandforpositivetimes: ‚àíx0<x<x0,‚àíy0<y<y0,t‚â•0. (25.58) Wetakex0=y0=7,andimposethe boundaryconditions thatthederivativeofthedisplace- mentvanishesattheendsoftheregion: ùúïu ùúïx(‚àíx0,y,t)=ùúïu ùúïx(x0,y,t)=ùúïu ùúïy(x,‚àíy0,t)=ùúïu ùúïy(x,y0,t)=0. (25.59) 514 25 Shock and Soliton Waves We also impose the initial condition that at time t=0 the waveform is that of a pulse (Figure25.6)withitssurfaceatrest: u(x,y,t=0)=4tan‚àí1(exp3‚àí‚àö x2+y2),ùúïu ùúït(x,y,t=0)=0.(25.60) Wediscretizetheequationbylookingforsolutionsonaspace-timelattice: x=mŒîx,y=lŒîx,t=nŒît, (25.61) u(n) m,ldef=u(mŒîx,lŒîx,nŒît). (25.62) Next,wereplacethederivativesin(25.57)bytheirfinite-differenceapproximations: u(n+1) m,l‚âÉ‚àíu(n‚àí1) m,l+2[ 1‚àí2( Œît Œîx)2] u(n) m,l(25.63) +( Œît Œîx)2 (u(n) m+1,l+u(n) m‚àí1,l+u(n) m,l+1+u(n) m,l‚àí1) ‚àíŒît2sin[ 1 4(u(n) m+1,l+u(n) m‚àí1,l+u(n) m,l+1+u(n) m,l‚àí1)] . Tomakethealgorithmsimplerandestablishstability,weassumethattimeandspacesteps areproportional, Œît=Œîx‚àï‚àö 2.Thisleadstoallofthe u(n) m,ltermsdroppingout: u(2) m,l‚âÉ1 2(u(1) m+1,l+u1 m‚àí1,l+u(1) m,l+1+u(1) m,l‚àí1) ‚àíŒît2 2sin[ 1 4(u(1) m+1,l+u(1) m‚àí1,l+u(1) m,l+1+u(1) m,l‚àí1)] . (25.64) Likewise,thediscreteformofvanishinginitialvelocity(25.60)becomes: ùúïu(x,y,0)‚àïùúït=0 ‚áíu(2) m,l=u(0) m,l. (25.65) Thevaluesonlatticepointsontheedgesandcornerscannotbeobtainedfromtheserela- tions,but,instead,areobtainedbyapplyingtheboundaryconditions(25.59): ùúïu ùúïz(x0,y,t)=u(x+Œîx,y,t)‚àíu(x,y,t) Œîx=0, (25.66) ‚áíu(n) 1,l=u(n) 2,l. (25.67) Similarly,theotherderivativesin(25.59)give: u(n) Nmax,l=u(n) Nmax‚àí1,l,u(n) m,2=u(n) m,1,u(n) m,Nmax=u(n) m,Nmax‚àí1, (25.68) whereNmaxisthenumberofgridpointsusedforonespacedimension. 25.6.3 Implementation 1) Define an array u[Nmax,Nmax,3]withNmax=201 for the space points, and 3 for the timepoints. 2) Placethesolution(25.60)fortheinitialtimein u[m,l,1]. 3) Placethesolutionforthesecondtime Œîtinu[m,l,2],andthesolutionfortime2 Œîtin u[m,l,3]. 25.6 Continuum Limit, the Sine-Gordon Equation 515 4) Assignvaluesfortheconstants, Œîx=Œîy=7‚àï100,Œît=Œîx‚àï‚àö 2,andy0=x0=7. 5) Start the solution t=0 with the initial conditions, which, along with the boundary conditionsdefinesitovertheentirelattice. 6) Forthesecondtimestep,use(25.64)forallpointsonthelatticeincreasetimeby Œît, butdonotincludetheedges. 7) Attheedges,for i=1,2,‚Ä¶,200,set: u[i,1,2]=u[i,2,2],u[i,Nmax,2]=u[i,Nmax‚àí1,2] u[1,i,2]=u[2,i,2],u[Nmax,i,2]=u[Nmax‚àí1,i,2]. 8) To find values for the four points in the corners for the second time step, again use initialcondition(25.64): u[1,1,2]=u[2,1,2],u[Nmax,Nmax,2]=u[Nmax‚àí1,Nmax‚àí1,2], u[1,1,Nmax]=u[2,Nmax,2],u[Nmax,1,2]=u[Nmax‚àí1,1,2]. 9) Forthethirdtimestep(thefuture),usethefullalgorithm(25.66). 10) Continuethepropagationforwardintime,reassigningthefuturetothepresent,and determininganewfuture.Inthisway,youneedtostorethesolutionsforonlythree timesteps. We see in Figure 25.6, the time evolution of a circular ring soliton resulting from the stated initial conditions. We note that the ring at first shrinks in size, then expands, and thenshrinksbackintoanother(butnotidentical)ringsoliton.Asmallamountofthepar- ticledoesradiateaway,andinthelastframewecannoticesomeinterferencebetweenthe radiationandtheboundaryconditions.Ananimationofthissequencecanbefoundonline. Figure 25.6 A circular ring soliton at times 8, 20, 40, 60, 80, and 120. This type of entity has been proposed as a model for an elementary particle. (Created with TwoDsol.java .)",5324
25.7 Code Listings,"516 25 Shock and Soliton Waves 25.7 Code Listings Listing 25.1 AdvecLax.py solvestheadvectionequationviatheLax‚ÄìWendroffscheme. # AdvecLax . py : Solve advection eqnt via Lax ‚àíWendroff scheme #d u / d t +c ‚àód(u‚àó‚àó2/2)/dx=0; u(x, t=0)=exp( ‚àí300(x‚àí0.12) ‚àó‚àó2) 4fromvpython import ‚àó m = 100 # N o steps in x c=1 . ; d x=1 . / m ; b e t a=0 . 8 # beta = c ‚àódt/dx u=[ 0 ] ‚àó(m+1); # I n i t i a l Numeric 8u0 = [0] ‚àó(m+1); uf = [0] ‚àó(m+1) dt = beta ‚àódx/c; T_final = 0.5; 12n=int(T_final/dt) # N time steps graph1 = graph(width=600, height=500, xtitle = ‚Äôx‚Äô, xmin=0,xmax=1, ymin=0, ymax=1, ytitle = ‚Äôu(x), Cyan=exact, Yellow=Numerical‚Äô , 16 title= ‚ÄôAdvect Eqn: Initial (red), Exact (cyan),Numerical (yellow)‚Äô ) initfn = gcurve(color = color.red); exactfn = gcurve(color = color.cyan) numfn = gcurve(color = color.yellow) # Numerical solution 20 defplotIniExac(): # Plot initial &exact solution foriin range (0, m): x=i ‚àódx 24 u0[i] = exp( ‚àí300.‚àó(x‚àí0.12) ‚àó‚àó2) # Gaussian initial initfn.plot(pos = (0.01 ‚àói, u 0[i]) ) # Initial function uf[i] = exp( ‚àí300.‚àó(x‚àí0.12‚àíc‚àóT_final) ‚àó‚àó2)# Exact = cyan exactfn.plot(pos = (0.01 ‚àói, uf[i]) ) 28 rate(50) plotIniExac() defnumerical(): # Finds Lax Wendroff solution 32forjin range (0, n+1): # Time loop foriin range (0, m‚àí1): #x l o o p u[i + 1] = (1. ‚àíbeta ‚àóbeta) ‚àóu0[i+1] ‚àí(0.5‚àóbeta) ‚àó(1.‚àíbeta) ‚àóu0[i+2] +(0.5 ‚àóbeta) ‚àó(1. + beta) ‚àóu0[i] # Algorithm 36 u[0] = 0.; u[m ‚àí1] = 0.; u0[i] =u[i] numerical() forjin range (0, m‚àí1) : rate(50) 40numfn.plot(pos = (0.01 ‚àój, u[j]) ) # Plot numeric soltn Listing 25.2 Soliton.py solves the KdeV equation for 1D solitons corresponding to a ‚Äúbore‚Äùinitialconditions. # Soliton . py : Korteweg de Vries equation for a soliton 2 fromvisualimport ‚àó importmatplotlib.pylab as p; frommpl_toolkits.mplot3d importAxes3D ; 6importnumpy ds = 0.4; dt = 0.1; max= 2000; mu = 0.1; eps = 0.2; mx = 131 u= z e r o s ( ( m x , 3 ) , float); spl = zeros( (mx, 21), float); m=1 10 foriin range (0, 131): # Initial w a v e u[i, 0] = 0.5 ‚àó(1‚àí((math.exp(2 ‚àó(0.2‚àóds‚àói‚àí5.))‚àí1)/(math.exp(2 ‚àó(0.2‚àóds‚àói‚àí5.))+1))) u[0,1] = 1. ; u[0,2] = 1.; u[130,1] = 0. ; u[130,2] = 0. # End points 14 foriin range (0, 131, 2): spl[i, 0] = u[i, 0] fac = mu ‚àódt/(ds ‚àó‚àó3) print(\""Working. Please hold breath and wait while I count to 20\"" ) 18foriin range (1, mx‚àí1): # First time step 25.7 Code Listings 517 a1 = eps ‚àódt‚àó(u[i + 1, 0] + u[i, 0] + u[i ‚àí1, 0])/(ds ‚àó6.) ifi>1andi<129: a2 = u[i+2,0]+2. ‚àóu[i‚àí1,0]‚àí2.‚àóu[i+1,0] ‚àíu[i‚àí2,0] else:a 2 = u [ i ‚àí1, 0]‚àíu[i+1, 0] 22a3 = u[i+1, 0] ‚àíu[i‚àí1, 0] u[i, 1] = u[i, 0] ‚àía1‚àóa3‚àífac‚àóa2/3. forjin range (1,max+1): # Next time steps foriin range (1, mx‚àí2): 26 a1 = eps ‚àódt‚àó(u[i + 1, 1] + u[i, 1] + u[i ‚àí1, 1])/(3. ‚àóds) ifi>1andi<mx‚àí2: a2 = u[i+2,1] + 2. ‚àóu[i‚àí1,1]‚àí2.‚àóu[i+1,1] ‚àíu[i‚àí2,1] else:a 2 = u [ i ‚àí1, 1]‚àíu[i+1, 1] 30 a3 = u[i+1, 1] ‚àíu[i‚àí1, 1] u[i, 2] = u[i,0] ‚àía1‚àóa3‚àí2.‚àófac‚àóa2/3. ifj percent100 == 0: # Plot every 100 time steps foriin range (1, mx ‚àí2): spl[i, m] = u[i, 2] 34 print(m) m=m+1 forkin range (0, mx): # Recycle array saves memory u[k, 0] = u[k, 1] 38 u[k, 1] = u[k, 2] x=list(range(0, mx, 2)) # Plot every other point y=list(range(0, 21)) # Plot 21 lines every 100 t steps 42X, Y = p.meshgrid(x, y) deffunctz(spl): z=s p l [ X ,Y ] 46returnz fig = p.figure() # create figure ax = Axes3D(fig) #p l o ta x e s 50ax.plot_wireframe(X, Y, spl[X, Y], color = ‚Äôr‚Äô) # red wireframe ax.set_xlabel( ‚ÄôPositon‚Äô ) # label axes ax.set_ylabel( ‚ÄôTime‚Äô) ax.set_zlabel( ‚ÄôDisturbance‚Äô ) 54p.show() # Show figure , close Python shell print(\""That‚Äôs all folks.\"" )",3518
Chapter 26 Fluid Hydrodynamics. 26.1 NavierStokes Equation,"518 26 Fluid Hydrodynamics We have already covered some Ô¨Çuid dynamics in our discussion of shallow-water solitons in Chapter 25. This chapter examines the more general equations of Ô¨Çuid dynamics and their numerical solutions.1The equations are nonlinear, yet have striking similarities to those of E&M, and support elegant mathematical and computational treatments. Analytic solutions, however, are rare, which helps explain why computation Ô¨Çuid dynamics (CFD) is an important specialty (think airplanes). We recommend [Fetter and Walecka, 1980; Landau and Lifshitz, 1987] for those interested in the derivations, and Shaw [1992] for more details about the computations . Inorderformigratingsalmontohaveaplacetorestduringtheirarduousupstreamjourney, theOregonDepartmentofEnvironmentwantstoplaceobjectsinseveraldeep,wide,fast- flowingstreams.Onesuchobjectisalongbeamofrectangularcrosssection(Figure26.1 left),andanotherisasetofplates(Figure26.1right).Theobjectsaretobeplacedfarenough belowthewater‚Äôssurfacesoasnottodisturbthesurfaceflow,andalsofarenoughfromthe bottomofthestreamsoasnottodisturbtheflowthere. Problem Determinehowthesizeandlocationofthebeamandplatesaffectthestream‚Äôs velocityprofile. 26.1 Navier‚ÄìStokes Equation Aswithourstudyofshallow-watersolitons,weassumethatwateris incompressible with constantdensity ùúå.Theproblemdescriptionimpliesthatwecanassumeasteadystate,but notthatwecanignorefriction( viscosity).Asbefore,thefirstequationofhydrodynamicsis thecontinuityequation(25.2): ùúïùúå(x,t) ùúït+‚àá ‚ãÖj=0, jdef=ùúåv(x,t). (26.1) 1 WeacknowledgesomehelpfulreadingandcommentsbySatoruS.Kano. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 26.1 Navier‚ÄìStokes Equation 519 River River xxyy LH LSurface Bottom BottomSurface Figure 26.1 Side view of the Ô¨Çow of a stream around a submerged beam ( left) and around two parallel plates ( right). Both beam and plates have length Lalong the direction of Ô¨Çow. The Ô¨Çow is seen to be symmetric about the centerline and to be unaffected at the bottom and at the surface by the submerged object. The second equation of hydrodynamics employs a special time derivative, the hydrody- namicderivativeD v‚àïDt[FetterandWalecka,1980]: Dv Dtdef=(v‚ãÖ‚àá)v+ùúïv ùúït. (26.2) Thisderivativegivestherateofchange,asviewedfromastationaryframe,ofthevelocity of material within anelementofflowingfluid . It thus incorporates changes as a result of the motion of the fluid (first term), as well as any explicit time dependence of the veloc- ity(secondterm).Itisparticularlynoteworthythat Dv‚àïDtissecondorderinvelocity,and assuchitintroducesnonlinearitiesintothetheory.Youmaythinkofthesenonlinearitiesas arisingfromfictitious(inertial)forcesthatoccurwhendescribingthemotionofanelement inthefluid‚Äôsrestframe,which,ingeneral,isanacceleratingframe. Thematerialderivativeistheleadingterminthe Navier‚ÄìStokesequation : Dv Dt=ùúà‚àá2v‚àí1 ùúå‚àáP(ùúå,T,x), (26.3) whereùúàisthekinematicviscosityand Pisthepressure.Thoughlesseleganttolookat,the computationalsolutionisbasedon(26.3)‚ÄôsCartesianform: ùúïùë£x ùúït+z‚àë j=xùë£jùúïùë£x ùúïxj=ùúàz‚àë j=xùúï2ùë£x ùúïx2 j‚àí1 ùúåùúïP ùúïx, ùúïùë£y ùúït+z‚àë j=xùë£jùúïùë£y ùúïxj=ùúàz‚àë j=xùúï2ùë£y ùúïx2 j‚àí1 ùúåùúïP ùúïy, (26.4) ùúïùë£z ùúït+z‚àë j=xùë£jùúïùë£z ùúïxj=ùúàz‚àë j=xùúï2ùë£z ùúïx2 j‚àí1 ùúåùúïP ùúïz. The Navier‚ÄìStokes equation describes the transfer of the momentum of the fluid within someregionofspaceasaresultof(i)theforcesonthefluid(think dp‚àïdt=F),and(ii)the fluidflow.The v‚ãÖ‚àávterminDv‚àïDtdescribesthetransportofmomentuminsomeregion of space resulting from the fluid‚Äôs flow, and it is often called the convection oradvection",3576
26.2 Flow Through Parallel Plates,"520 26 Fluid Hydrodynamics term.2The‚àáPtermdescribesthevelocitychangeresultingfrompressurechanges,andthe ùúà‚àá2vtermdescribesthevelocitychangeresultingfromviscousforcesthattendtoimpede theflow. Theexplicitfunctionaldependenceofthepressureonthefluid‚Äôsdensityandtemperature, P(ùúå,T,x),isknownasthe equationofstateofthefluid ,anditisassumedtobeknownbefore tryingtosolvetheNavier‚ÄìStokesequation.Tokeepourproblemsimple,weassumethatthe pressureisindependentofdensityandtemperature.Thisleavesuswithfoursimultaneous partialdifferentialequationstosolve,thecontinuityequation(26.1),andtheNavier‚ÄìStokes equation (26.3). Because our problem is one with steady state flow, we will set all time derivativesofthevelocitytozero.Becausewaterisincompressible,thetimederivativeof thedensityalsovanishes.Equations(26.1)and(26.3)thenbecome: ‚àá‚ãÖv‚â°‚àë iùúïùë£i ùúïxi=0, (26.5) (v‚ãÖ‚àá)v=ùúà‚àá2v‚àí1 ùúå‚àáP. (26.6) Thefirstequationexpressestheequalityofinflowandoutflow,andisknownasthe condi- tionofincompressibility .Inasmuchasthestreaminourproblemismuchwiderthanthe widthofthebeam,andbecausewewantasolutioninthemiddleofthestream,andnot nearthebanks,wewillignorethe zdependenceofthevelocity.TheexplicitPDE‚Äôsweneed tosolvethenreduceto: ùúïùë£x ùúïx+ùúïùë£y ùúïy=0, (26.7) ùúà(ùúï2ùë£x ùúïx2+ùúï2ùë£x ùúïy2) =ùë£xùúïùë£x ùúïx+ùë£yùúïùë£x ùúïy+1 ùúåùúïP ùúïx, (26.8) ùúà( ùúï2ùë£y ùúïx2+ùúï2ùë£y ùúïy2) =ùë£xùúïùë£y ùúïx+ùë£yùúïùë£y ùúïy+1 ùúåùúïP ùúïy. (26.9) 26.2 Flow Through Parallel Plates Theparallelplateproblemisoneofthefewthathaveanalyticsolutions.Yetsincewestill haveplentyofworktodoinordertosetupthenumericalsolution,wewillskipthedetails andjustgivetheresultweneedforcomparison:thereisaparabolicvelocityprofile: ùúåùúàùë£x(y)=1 2ùúïP ùúïx(y2‚àíyH). (26.10) AuniquesolutiontothePDEs(26.7)‚Äì(26.9)requiresknowledgeofappropriateboundary conditions.Asfaraswecantell,settingboundaryconditionsissomewhatofanacquired skill.Weassumethatthesubmergedparallelplatesareplacedinastreamthatisflowing withaconstantvelocity V0inthehorizontaldirection(Figure26.1right).Ifthevelocity V0 isnottoohigh,orifthekinematicviscosity ùúàissufficientlylarge,thentheflowshouldbe 2 WediscussadvectioninSection25.1.Inoceanologyormeteorology,convectionimpliesthetransferof massintheverticaldirectionwhereitovercomesgravity,whereasadvectionreferstotransferinthe horizontaldirection. 26.2 Flow Through Parallel Plates 521 L Solid wall Symmetry plane OutletInlet vx = vy = 0vy = 0 vy = 0vx = V0 dvi/dy = 0 dvi/dx = 0P = 0 xy H Figure 26.2 The boundary conditions for two thin submerged plates. The surrounding box is the integration volume within which we solve the PDE‚Äôs, and upon whose surface we impose the boundary conditions. In practice the box would be much larger than LandH. smoothandwithoutturbulence.Suchflowiscalled laminar.Typically,afluidundergoing laminarflowmovesinsmoothpathsthatdonotcloseonthemselves,liketheflowofwater fromafaucet.Ifweimagineattachingavectortoeachelementofthefluid,thenthepath sweptoutbythatvectoriscalleda streamline,orlineofmotion ,ofthefluid.Thesestream- linescanbevisualizedexperimentallybyaddingcoloreddyetothestream.Weassumethat theplatesaresothinthattheflowthroughandaroundthemremainslaminar. If the plates are thin, then the flow far upstream of them will not be affected, and we canlimitoursolutionspacetotherectangularregioninFigure26.2.Weassumethatthe lengthLandseparation Hoftheplatesaresmallcomparedtothesizeofthestream,sothe flowreturnstouniformaswegetfardownstreamfromtheplates.AsseeninFigure26.2, thereareboundaryconditionsatthe inlet,wherethefluidentersthesolutionspace,atthe outlet,whereitleaves,andatthestationaryplates,whereitjustpassesthrough.Inaddition, becausetheplatesarefarfromthestream‚Äôsbottomandsurface,weassumethatthedotted- dashedcenterlineisaplaneofsymmetry,withidenticalflowaboveandbelowtheplane. Wethushavefourdifferenttypesofboundaryconditionstoimposeonoursolution: Solid plates: In as much as there is friction (viscosity) between the fluid and the plate surface, the only way to have laminar flow is to have the fluid‚Äôs velocity equal to the plate‚Äôsvelocity,whichmeansbotharezero: ùë£x=ùë£y=0. (26.11) Suchbeingthecase,wehavesmoothflowinwhichthenegligiblythinplatesliealong streamlinesofthefluid(likea‚Äústreamlined‚Äùvehicle). Inlet:The fluid enters the integration domain at the inlet with a horizontal velocity V0. Becausetheinletisfarupstreamfromtheplates,weassumethatthefluidvelocityatthe inletisunchangedbythepresenceoftheplates: ùë£x=V0,ùë£y=0. (26.12) Outlet:The fluid leaves the integration domain at the outlet. While it is totally reason- abletoassumethatthefluidreturnstoitsunperturbedstatethere,wearenotsurewhat thatmightbe.So,instead,weassumethatthereisaphysicaloutletattheendwiththe waterjustshootingoutofit.Thismeansthatthewaterpressureequalszeroattheoutlet",4659
26.3.1 Successive Overrelaxation Algorithm,"522 26 Fluid Hydrodynamics (as at the end of a garden hose), and that the velocity does not change in a direction normaltotheoutlet: P=0,ùúïùë£x ùúïx=ùúïùë£y ùúïx=0. (26.13) Symmetry plane: Iftheflowissymmetricaboutthe y=0plane,thentherecannotbeflow throughtheplane,whichmeansthatthespatialderivativesofthevelocitycomponents normaltotheplanemustvanish: ùë£y=0,ùúïùë£y ùúïy=0. (26.14) Thisconditionfollowsfromtheassumptionthattheplatesarealongstreamlinesandthat theyarenegligiblythin.Itmeansthatallthestreamlinesareparalleltotheplates,aswell astothewatersurface,andsoitmustbethat ùë£y=0everywhere.Thefluidentersinthe horizontaldirection,theplatesdonotchangethevertical ycomponentofthevelocity, andtheflowremainssymmetricaboutthecenterline.Thereisaretardationoftheflow aroundtheplatesasaresultoftheviscousnatureoftheflow,andasaresultofthe v=0 boundarylayersformedontheplates,buttherearenoactual ùë£ycomponents. 26.3 Navier‚ÄìStokes Difference Equation NowwedevelopthedifferenceequationformsoftheNavier‚ÄìStokesandcontinuityPDEs. They will be solved with successive overrelaxation , a variation of the method used in Chapter21tosolvePoisson‚Äôsequation.Westartbydividingspaceintoarectangulargrid withspacing hinboththe xandydirections: x=ih,i=0,‚Ä¶,Nx;y=jh,j=0,‚Ä¶,Ny. Next,weusethecentral-differenceapproximationtoexpressthederivativesin(26.7)‚Äì(26.9) as finite differences of the values of the velocities at the grid points. For ùúà=1m2‚àïsa n d ùúå=1kg/m3,thisyields: ùë£(x) i+1,j‚àíùë£(x) i‚àí1,j+ùë£(y) i,j+1‚àíùë£(y) i,j‚àí1=0, (26.15) ùë£(x) i+1,j+ùë£(x) i‚àí1,j+ùë£(x) i,j+1+ùë£(x) i,j‚àí1‚àí4ùë£(x) i,j(26.16) =h 2ùë£(x) i,j[ùë£(x) i+1,j‚àíùë£(x) i‚àí1,j]+h 2ùë£(y) i,j[ùë£(x) i,j+1‚àíùë£(x) i,j‚àí1]+h 2[Pi+1,j‚àíPi‚àí1,j], ùë£(y) i+1,j+ùë£(y) i‚àí1,j+ùë£(y) i,j+1+ùë£(y) i,j‚àí1‚àí4ùë£(y) i,j(26.17) =h 2ùë£(x) i,j[ùë£(y) i+1,j‚àíùë£(y) i‚àí1,j]+h 2ùë£(y) i,j[ùë£(y) i,j+1‚àíùë£(y) i,j‚àí1]+h 2[Pi,j+1‚àíPi,j‚àí1]. Becauseùë£(y)‚â°0,wecansolvefor ùë£(x): 4ùë£(x) i,j=ùë£(x) i+1,j+ùë£(x) i‚àí1,j+ùë£(x) i,j+1+ùë£(x) i,j‚àí1‚àíh 2ùë£(x) i,j[ùë£(x) i+1,j‚àíùë£(x) i‚àí1,j] ‚àíh 2ùë£(y) i,j[ùë£(x) i,j+1‚àíùë£(x) i,j‚àí1]‚àíh 2[Pi+1,j‚àíPi‚àí1,j]. (26.18)",1972
26.4 Vorticity Form of NavierStokes Equation,"26.4 Vorticity Form of Navier‚ÄìStokes Equation 523 We recognize (26.18) as an algorithm similar to the one we used in solving Laplace‚Äôs equation by relaxation. Indeed, as we did there, we can accelerate the convergence by writing the algorithm with the new value of ùë£(x)given by the old value plus a correction (residual): ùë£(x) i,j=ùë£(x) i,j+ri,j,rdef=ùë£x(new) i,j‚àíùë£xold i,j(26.19) ‚áír=1 4{ ùë£(x) i+1,j+ùë£(x) i‚àí1,j+ùë£(x) i,j+1+ùë£(x) i,j‚àí1‚àíh 2ùë£(x) i,j[ùë£(x) i+1,j‚àíùë£(x) i‚àí1,j] ‚àíh 2ùë£(y) i,j[ùë£(x) i,j+1‚àíùë£(x) i,j‚àí1]‚àíh 2[Pi+1,j‚àíPi‚àí1,j]} ‚àíùë£(x) i,j. (26.20) Asbefore,successiveiterationssweeptheinteriorofthegrid,continuouslyaddinginthe residual(26.19)untilthechangebecomessmallerthansomesetleveloftolerance,|||ri,j|||<ùúÄ. Avariationofthismethod, successiveoverrelaxation (SOR),increasesthespeedatwhich theresidualsapproachzerobyincludinganamplifyingfactor ùúî: ùë£(x) i,j=ùë£(x) i,j+ùúîri,j(SOR). (26.21) Thestandardrelaxationalgorithm(26.19)isobtainedwith ùúî=1,acceleratedconvergence (overrelaxation )isobtainedwith ùúî‚â•1,andunderrelaxation occursfor ùúî<1.Values ùúî>2 arefoundtoleadtonumericalinstabilities.Althoughadetailedanalysisofthealgorithm isnecessarytopredicttheoptimalvaluefor ùúî,wesuggestthatyoutestdifferentvaluesfor ùúîtoseewhichoneprovidesthefastest,yetstable,convergencefortheproblemathand. 26.3.1 Successive Overrelaxation Algorithm 1) Modifytheprogram Beam.py,orwriteyourown,tosolvetheNavier-Stokesequationfor thevelocityofafluidin2Dflow.Representthe xandycomponentsofthevelocityby thearrays vx[Nx,Ny] andvy[Nx,Ny] . 2) Specializeyoursolutiontotherectangulardomainandboundaryconditionsindicated inFigure26.2. 3) Useoftheparametervalues, ùúà=1m2‚àïs,ùúå=103kg/m3,(flowparameters), Nx=400,Ny=40,h=1,(gridparameters) , leadstotheequations ùúïP ùúïx=‚àí12,ùúïP ùúïy=0,ùë£(x)=3j 20( 1‚àíj 40) ,ùë£(y)=0. (26.22) 4) Fortherelaxationmethod,outputtheiterationnumberandthecomputed ùë£(x). 5) Verify that your numerical solution agrees with the analytic result (26.10) for flow throughparallelplates. 6) RepeatthecalculationandseeifSORspeedsuptheconvergence. 26.4 Vorticity Form of Navier‚ÄìStokes Equation Now that the comparison with an analytic solution has shown that our CFD simulation works,wereturntodeterminingifthebeaminFigure26.1mightproduceagoodresting 524 26 Fluid Hydrodynamics placeforsalmon.Whilewehavenoanalyticsolutionwithwhichtocompare,ourcanoeing and fishing adventures have taught us that standing waves with fish in them are often formedbehindrocksinstreams,andsowewilllookforevidenceofastandingwaveforming behindthebeam. Wehaveseenhowtonumericallysolvethehydrodynamicsequations: ‚àá‚ãÖv=0, (26.23) (v‚ãÖ‚àá)v=‚àí1 ùúå‚àáP+ùúà‚àá2v. (26.24) These equations determine the components of a fluid‚Äôs velocity, pressure, and density as functionsofposition.Recallhowinelectrostaticsitisusuallysimplertosolveforascalar potential,ratherthanavectorfield,andthentakethepotential‚Äôsgradienttodeterminethe vectorfield.Inanalogy,werecastthehydrodynamicequationintoformsthatpermitusto solvetwosimplerequations,fromwhichthevelocityisobtainedviaagradientoperation.3 W ed e fi n ea stream function u(x),f r o mw h i c ht h ev e l o c i t yi sd e t e r m i n e db yt h ec u r l operator: vdef=‚àá√ó u(x)=ÃÇ ùúñx(ùúïuz ùúïy‚àíùúïuy ùúïz) +ÃÇ ùúñy(ùúïux ùúïz‚àíùúïuz ùúïx) . (26.25) Notetheabsenceofa zcomponentofvelocityforourproblem.Since ‚àá‚ãÖ(‚àá√óu)‚â°0,we seethatany vthatcanbeawrittenasthecurlof uautomaticallysatisfiesthecontinuity equation ‚àá‚ãÖv=0.Furthermore,becausethe vforourproblemhasonly xandycompo- nents, u(x)needshaveonlya zcomponent: uz‚â°u‚áíùë£x=ùúïu ùúïy,ùë£y=‚àíùúïu ùúïx. (26.26) Notethatin2Dflows,thecontourlines u=constantarethe streamlines . Thesecondsimplerfunctionisthe vorticityfield w(x),whichisrelatedphysically,and alphabetically,totheangularvelocity ùùéofthefluid.Vorticityisdefinedasthecurlofthe velocity(sometimeswitha ‚àísign): wdef=‚àá√ó v(x). (26.27) Becauseourproblem‚Äôsvelocitydoesnotchangeinthe zdirection,the zderivativevanishes: ùë§z=(ùúïùë£y ùúïx‚àíùúïùë£x ùúïy) . (26.28) Physically,weseethatvorticityisameasureofhowmuchthefluid‚Äôsvelocitycurlsorrotates, withthedirectionofthevorticitydeterminedbytheright-handruleforrotations.Infact, ifwecouldremoveasmallelementofthefluidintospace(soitwouldnotfeeltheinternal strainofthefluid),wewouldfindthatitisrotatinglikeasolidwithangularvelocity ùùé‚àùw [Lamb,1993].Thatbeingthecase,itisusefultothinkofvorticityasgivingthelocalvalue ofthefluid‚Äôsangularvelocityvector,with w=0describing irrotational flow. In general, the field lines of ùë§are continuous and move as if attached to elements of thefluid.Auniformlyflowingfluidwouldhavevanishingcurls,whileanonzerovorticity 3 Ifwehadtosolveonlythesimplerproblemof irrotationalflow (noturbulence),thenwewouldbeableto useascalarvelocitypotential,incloseanalogytoelectrostatics[Lamb,1993].Forthemoregeneral rotationalflow ,twovectorpotentialsarerequired.",4724
26.5 Assessment and Exploration,"26.4 Vorticity Form of Navier‚ÄìStokes Equation 525 indicatesthatthecurrentrotates,orcurlsbackonitself.Fromthedefinitionofthestream function(26.25),weseethatthevorticity wisrelatedtoitby: w=‚àá√ó v=‚àá√ó(‚àá√ó u)=‚àá ( ‚àá ‚ãÖu)‚àí‚àá2u, (26.29) wherewehaveusedavectoridentityfor ‚àá√ó(‚àá√ó u).Butbecause uhasonlyazcomponent thatdoesnotvarywith z(orbecausethereisnosourcefor u),thedivergence ‚àá‚ãÖu=0.We nowhavethebasicrelationbetweenthestreamfunction uandthevorticity w: ‚àá2u=‚àíw. (26.30) Equation(26.30)isanalogoustoPoisson‚Äôsequationofelectrostatics, ‚àá2ùúô=‚àí4ùúãùúå,onlynow each component of vorticity wacting as the source for the corresponding component of thestreamfunction u.Iftheflowisirrotational,thatis,if w=0,thenweneedonlysolve Laplace‚Äôsequationforeachcomponentof u.Rotationalflow,withitscouplednonlinearities equations,leadstomoreinterestingbehavior. As is to be expected from the definition of w, the vorticity form of the Navier‚ÄìStokes equationisobtainedbytakingthecurlofthevelocityform,thatis,byoperatingonboth sideswith ‚àá√ó.Aftersignificantmanipulationsoneobtains ùúà‚àá2w= [(‚àá√ó u)‚ãÖ‚àá]w. (26.31) Thisand(26.30)arethetwosimultaneousPDE‚Äôsthatweneedtosolve.In2D,with uand whavingonly zcomponents,theyare ùúï2u ùúïx2+ùúï2u ùúïy2=‚àíùë§, (26.32) ùúà( ùúï2ùë§ ùúïx2+ùúï2ùë§ ùúïy2) =ùúïu ùúïyùúïùë§ ùúïx‚àíùúïu ùúïxùúïùë§ ùúïy. (26.33) Soafterallthatwork,weendupwithtwosimultaneous,nonlinear,ellipticPDE‚Äôsthatlook like a mixture of Poisson‚Äôs equation with the wave equation. The equation for uis Pois- son‚Äôsequationwithsource ùë§,andmustbesolvedsimultaneouslywiththesecond.Itisthis secondequationthatcontainsmixedproductsofthederivativesof uandùë§,andthusthe nonlinearity. 26.4.1 Vorticity Difference Equation Wesolve(26.32)and(26.33)onan Nx√óNygridofuniformspacing hwith: x=iŒîx=ih,i=0,‚Ä¶,Nx,y=jŒîy=jh,j=0,‚Ä¶,Ny. (26.34) Becausethebeamissymmetricaboutitscenterline(Figure26.1left),weneedthesolution onlyintheupperhalf-plane.Weapplythenowfamiliarcentral-differenceapproximation totheLaplaciansof uandùë§toobtainthedifferenceLaplacian: ùúï2u ùúïx2+ùúï2u ùúïy2‚âÉui+1,j+ui‚àí1,j+ui,j+1+ui,j‚àí1‚àí4ui,j h2. (26.35) Likewise,fortheproductoffirstderivatives, ùúïu ùúïyùúïùë§ ùúïx‚âÉui,j+1‚àíui,j‚àí1 2hùë§i+1,j‚àíùë§i‚àí1,j 2h. (26.36) 526 26 Fluid Hydrodynamics ThedifferencevorticityNavier‚ÄìStokesequation(26.32)isnow: ui,j=1 4(ui+1,j+ui‚àí1,j+ui,j+1+ui,j‚àí1+h2ùë§i,j), (26.37) ùë§i,j=1 4(ùë§i+1,j+ùë§i‚àí1,j+ùë§i,j+1+ùë§i,j‚àí1)‚àíR 16{[ui,j+1‚àíui,j‚àí1] √ó[ùë§i+1,j‚àíùë§i‚àí1,j]‚àí[ui+1,j‚àíui‚àí1,j][ùë§i,j+1‚àíùë§i,j‚àí1]}, (26.38) R=1 ùúà( V0h ùúàinnormalunits) . (26.39) Note,inordertoobtainanalgorithmappropriateforsolutionbyrelaxation,wehaveplaced ui,jandùë§i,jontheLHSoftheequations. Theparameter Rin(26.39)isrelatedtothe Reynoldsnumber .Whenwesolvetheproblem innaturalunits,wemeasuredistancesinunitsofgridspacing h,velocitiesinunitsofinitial velocityV0,streamfunctionsinunitsof V0h,andvorticityinunitsof V0‚àïh.Thesecondform isinregularunitsandisdimensionless.This Risknownasthe gridReynoldsnumber ,and differsfromthephysical R,whichhasapipediameterinplaceofthegridspacing h. ThegridReynoldsnumberisameasureofthestrengthofthecouplingofthenonlinear termsintheequation.Whenthephysical Rissmall,theviscosityactsasafrictionalforce thatdampsoutfluctuationsandkeepstheflowsmooth.When Rislarge(R‚âÉ2000),phys- icalfluidsundergophasetransitionsfromlaminartoturbulentflowinwhichturbulence occurs at a cascading set of smaller and smaller space scales. However, simulations that producetheonsetofturbulencehavebeenaresearchproblemsinceReynolds‚Äôfirstexperi- mentsin1883[Reynolds,1883;FalkovichandSreenivasan,2006].Possiblybecauselaminar flowisstableagainstsmallperturbations,itmaybethatsomelarge-scale‚Äúkick‚Äùisneeded tochangeitfromlaminartoturbulent. As discussed in Section 26.3, the finite difference algorithm can have its convergence acceleratedbytheuseofsuccessiveoverrelaxation(26.37): ui,j=ui,j+ùúîr(1) i,j,ùë§i,j=ùë§i,j+ùúîr(2) i,j(SOR). (26.40) Hereùúîistheoverrelaxationparameter,andshouldlieintherange0 <ùúî<2forstability. Theresidualsarejustthechangesinasinglestep, r(1)=unew‚àíuoldandr(2)=ùë§new‚àíùë§old: r(1) i,j=1 4(ui+1,j+ui‚àí1,j+ui,j+1+ui,j‚àí1+ùë§i,j)‚àíui,j, (26.41) r(2) i,j=1 4( ùë§i+1,j+ùë§i‚àí1,j+ùë§i,j+1+ùë§i,j‚àí1‚àíR 4{[ui,j+1‚àíui,j‚àí1] √ó[ùë§i+1,j‚àíùë§i‚àí1,j]‚àí[ui+1,j‚àíui‚àí1,j][ùë§i,j+1‚àíùë§i,j‚àí1]})‚àíùë§i,j. 26.4.2 Beam Boundary Conditions Awell-definedsolutiontotheseellipticPDEsrequiresacombinationof(lessthanobvious) boundary conditions on uandùë§. Consider Figure 26.3, based on the analysis of Koonin [1986].Theassumptionisthattheinlet,outlet,andsurfacearefarfromthebeam(which 26.5 Assessment and Exploration 527 dw/dx  = 0du/dx  = 0 vx = du/dy  = V0 w = 0 Inlet FOutlet H Half beamSurface G vx = du/dy  = V0 w = 0 y xvy = -du/dx  = 0 Center linew = u = 0 w = u = 0u = 0 u = 0vy = -du/dx  = 0 ABC ED Figure 26.3 Boundary conditions for Ô¨Çow around the beam in Figure 26.1. The Ô¨Çow is symmetric about the centerline, and the beam has length Lin the xdirection (along Ô¨Çow). maynotbeevidentfromthenot-to-scalefigure).Werefertheinterestedreadertotheref- erences,andjustgivethe Boundary Conditions : u=0;ùë§=0 CenterlineEA u=0,ùë§i,j=‚àí2 h2(ui+1,j‚àíui,j)BeambackB u=0,ùë§i,j=‚àí2 h2(ui,j+1‚àíui,j)BeamtopC u=0,ùë§i,j=‚àí2 h2(ui‚àí1,j‚àíui,j)BeamfrontD ùúïu‚àïùúïx=0,ùë§ =0I n l e t F ùúïu‚àïùúïy=V0,ùë§ =0 SurfaceG ùúïu‚àïùúïx=0,ùúï ùë§‚àïùúïx=0O u t l e t H Beam.pyin Listing 26.1 is our program for solution of the vorticity form of the Navier‚ÄìStokes equation. You will notice that while the relaxation algorithm is rather simple,somecareisneededinimplementingthemanyboundaryconditions.Relaxation ofthestreamfunctionandofthevorticityisperformedbyseparatefunctions. 26.5 Assessment and Exploration 1) Use Beam.pyasabasisforyoursolutionforthestreamfunction uandthevorticity ùë§ usingthefinite-differencesalgorithm(26.37).Figures26.4and26.5showsometypical results. 2) A good place to start your simulation is with a beam of size L=8h,H=h, Reynolds numberR=0.1, and intake velocity V0=1. Keep your grid small during debugging, say,Nx=24andNy=70. 3) Exploretheconvergenceofthealgorithm. a) Printouttheiterationnumberand uvaluesupstreamfrom,above,anddownstream fromthebeam. b) Determinethenumberofiterationsnecessarytoobtainthree-placeconvergencefor successiverelaxation( ùúî=1). 528 26 Fluid Hydrodynamics 07060504030200 1020 15 10 5 0 ‚Äì5 5101520 060 4050 30 20 10 010 50‚Äì5 5 10 15 200 Stream flow10203040506070 5 10 15 200 yx YT Figure 26.4 Two visualizations of the stream function ufor Reynold‚Äôs number R=5. w(x,y) 0 ‚Äì1 0 50 020 yx 4006y xv 12 80 Figure 26.5 Left: The vorticity as a function of xandy. Rotation is seen to be largest behind the beam. Right: The velocity Ô¨Åeld around the beam as represented by vectors. c) Determinethenumberofiterationsnecessarytoobtainthree-placeconvergencefor successiveoverrelaxation( ùúî‚âÉ1.3).Usethisnumberforfuturecalculations. 4) Changethebeam‚Äôshorizontalplacement,sothatyoucanseetheundisturbedcurrent entering from the left, and then developing into a standing wave. Note that you may needtoincreasethesizeofyoursimulationvolumetoseetheeffectofalltheboundary conditions. 5) Make surface plots including contours of the stream function uand the vorticity ùë§. Explainthebehaviorseen. 6) Istherearegionwhereabigfishcanrestbehindthebeam? 7) Theresultsofthesimulation(Figure26.4)arefortheone-componentstreamfunction u. Makeseveralvisualizationsshowingthefluidvelocitythroughoutthesimulationregion.",7148
26.5.1 Explorations. 26.6 Code Lisitings,"26.6 Code Lisitings 529 Notethatvelocityisavectorwithtwocomponents,andtheindividualcomponentsare interestingtovisualize.Avectorplotworkswellhere. 8) ExplorehowincreasingtheReynoldsnumber Rchangestheflowpattern.Startat R=0 andgraduallyincrease Rwhilewatchingfornumericinstabilities.Toovercomenumer- icalinstabilities,reducethesizeoftherelaxationparameter ùúîandcontinuetolarger R values. 9) Verifythattheflowaroundthebeamissmoothforsmall Rvalues,butthatitseparates fromthebackedgeforlarge R,atwhichpointasmallvortexdevelops. 26.5.1 Explorations 1) Determinetheflowbehindacircularrockinthestream. 2) Theboundaryconditionatanoutletfardownstreamshouldnothavemucheffectonthe simulation.Exploretheuseofotherboundaryconditionsthere. 3) Determinethepressurevariationaroundthebeam. 26.6 Code Lisitings Listing 26.1 Beam.py SolvestheNavier‚ÄìStokesequationfortheflowoveraplate. # Beam.py: solves Navier ‚àíStokes equation for flow around beam 2 importmatplotlib.pylab as p; frommpl_toolkits.mplot3d importAxes3D; fromnumpyimport ‚àó; 6 print(\""Working, wait for the figure after 100 iterations\"" ) Nxmax = 70; Nymax = 20; IL = 10; H = 8; T = 8; h = 1. u = zeros ((Nxmax+1, Nymax+1), float) # Stream 10w = zeros ((Nxmax+1, Nymax+1), float) # Vorticity V0 = 1.0; omega = 0.1; nu = 1.; iter = 0; R = V0 ‚àóh/nu defborders(): 14foriin range (0, Nxmax+1): # Init stream forjin range (0, Nymax+1): # Init vorticity w[i , j] = 0. u[i, j] = j ‚àóV0 18foriin range (0, Nxmax+1 ): # Fluid surface u[i, Nymax] = u[i, Nymax ‚àí1] + V0 ‚àóh w[i , Nymax ‚àí1] = 0. forjin range (0, Nymax+1): 22 u[1, j] = u[0, j] w[0, j] = 0. #I n l e t foriin range (0, Nxmax+1): # Centerline ifi<=I Landi>= IL+T: 26 u[i, 0] = 0. w[i , 0] = 0. forjin range (1, Nymax ) : #O u t l e t w[Nxmax, j] = w[Nxmax ‚àí1, j] 30 u[Nxmax, j] = u[Nxmax ‚àí1, j] defbeam() : #B Cf o rb e a m forjin range (0, H+1): # Sides w[IL, j] = ‚àí2‚àóu[IL‚àí1, j]/(h ‚àóh) #F r o n t 34 w[IL+T, j] = ‚àí2‚àóu[IL + T + 1, j]/(h ‚àóh) #B a c k foriin range (IL, IL+T + 1): w[i, H ‚àí1] =‚àí2‚àóu[i, H]/(h ‚àóh); foriin range (IL, IL+T+1): forjin range (0, H+1): 38 u[IL, j] = 0. #F r o n t u[IL+T, j] = 0. #B a c k 530 26 Fluid Hydrodynamics u[i, H] = 0; # Top defrelax(): # Relax stream 42beam() # Reset conditions foriin range (1, Nxmax) : # Relax stream forjin range (1, Nymax) : r1 = omega ‚àó((u[i+1,j]+u[i ‚àí1,j]+u[i , j+1]+u[i ,j ‚àí1] + h ‚àóh‚àów[i ,j])/4 ‚àíu[i,j]) 46 u[i, j] += r1 foriin range (1, Nxmax) : # Relax vorticity forjin range (1, Nymax) : a1 = w[i+1, j] + w[i ‚àí1,j] + w[i ,j+1] + w[i ,j ‚àí1] 50 a2 = (u[i ,j+1] ‚àíu[i,j‚àí1])‚àó(w[i+1,j] ‚àíw[i‚àí1, j]) a3 = (u[i+1,j] ‚àíu[i‚àí1,j]) ‚àó(w[i , j+1] ‚àíw[i , j ‚àí1]) r2 = omega ‚àó(( a 1‚àí(R/4.) ‚àó(a2‚àía3) )/4. ‚àíw[i ,j]) w[i , j] += r2 54borders() while(iter<= 100): iter += 1 ifiter percent10 == 0: print(iter) 58relax() foriin range (0, Nxmax+1): forjin range (0, Nymax+ 1): u[i,j] = u[i,j]/V0/h # V0h units x=range(0, Nxmax ‚àí1); y = range(0, Nymax ‚àí1) 62X, Y = p.meshgrid(x, y) deffunctz(u): # Stream flow z=u [ X ,Y ] returnz 66Z=f u n c t z( u ) fig = p.figure() ax = Axes3D(fig) ax.plot_wireframe(X, Y, Z, color = ‚Äôr‚Äô) 70ax.set_xlabel( ‚ÄôX‚Äô) ax.set_ylabel( ‚ÄôY‚Äô) ax.set_zlabel( ‚ÄôStream Function‚Äô ) p.show()",3138
Chapter 27 Finite Element Electrostatics. 27.1 The Potential of Two Metal Plates. 27.2 Finite Element Method,"531 27 Finite Element Electrostatics ‚äô We have already discussed the simple, but powerful, solution of PDEs using Ô¨Ånite differences to approximate derivatives. In this (optional) chapter, we outline the Ô¨Ånite element method (FEM) for solving PDEs that patches together approximate solutions on small Ô¨Ånite ele- ments to obtain the full solution. FEM is faster to execute than the Ô¨Ånite differences method; however, it takes much more effort to set up, and so is often implemented via highly devel- oped FEM packages, such as Python‚Äôs FiPy. 27.1 The Potential of Two Metal Plates Problem Determinetheelectricpotentialbetweenthetwoconductingplatesshownin Figure27.1.Theplatesaredistance b‚àíaapart,theloweroneatpotential Ua,theupper oneatpotential Ub,withauniformchargedensity ùúå(x)betweenthem. 27.1.1 Analytic Solution Therelationbetweenchargedensity ùúå(x)andpotential U(x)isgivenbyPoisson‚Äôsequation (21.6).Forourproblem,thepotential Uchangesonlyinthe xdirection,andsothePDE becomestheODE: d2U(x) dx2=‚àí4ùúãùúå(x)=‚àí1,0<x<1, (27.1) wherewehaveset ùúå(x)=1‚àï4ùúãtosimplifytheprogramming.Thesolutionissubjecttothe Dirichletboundaryconditions: U(x=a=0)=0,U(x=b=1)=1, (27.2) ‚áíU(x)=‚àíx 2(x‚àí3). (27.3) ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH",1327
27.2.3 Solution via Linear Equations,"532 27 Finite Element Electrostatics ‚äô NodeElementx = b Ub Ua x = a X0XN œÅ(x)Figure 27.1 A Ô¨Ånite element solution to Laplace‚Äôs equation for two metal plates with a charge density between them. The large dots are the nodes xi, and the lines connecting the nodes are the Ô¨Ånite elements. 27.2 Finite Element Method ThetheoryandpracticeofFEMhavebeendevelopedoverthelast60yearsandisstillan activefieldofresearch[Shaw,1992;Li,2014;Otto,2019].AstrengthofFEMisthatitoffers greatflexibilityforproblemsinirregulardomains,orforproblemswithhighlyvaryingcon- ditionsorevensingularities.FurtheradvantagesofFEMarethatthesamebasictechnique can be applied to many problems with only minor modifications, and that the solutions maybeevaluatedthroughoutallspace,notjustonagrid.Infact,theFEM,withvarious preprogrammed multigrid packages, has very much become the standard for large-scale engineeringapplications. In FEM, the domain in which the PDE is to be solved is split into subdomains, called elements,a n datrial solution to the PDE in each subdomain is hypothesized. Then the parametersofthetrialsolutionareadjustedtoobtainthe bestfit,inthesenseofChapter6,to theexactsolution.Sowhilefinite-differencemethodyieldsanapproximatesolutionforan approximatePDE,FEMyieldsthebestpossibleglobalagreementbetweenanapproximate solutionandtheexactsolution. 27.2.1 Weak Form of PDE 1) StarttheFEMwiththedifferentialequationwewanttosolve, d2U(x) dx2=‚àí4ùúãùúå(x). (27.4) 2) Multiply the unknown exact solution U(x)by an approximate trialsolution Œ¶(x),a n d integratetheproductovertheentiresolutiondomain, ‚à´b adxU(x)ùúô(x). (27.5) Thisintegralisusedasameasureoftheoverallagreementbetweentheexactandtrial solutions. 3) Assume that the trial solution vanishes at the endpoints, Œ¶(a)=Œ¶ (b)=0, keeping in mindthatwe‚Äôllhavetoimposetheboundaryconditionslater. 4) Multiplybothsidesofthedifferentialequation(27.1)by Œ¶, d2U(x) dx2Œ¶(x)=‚àí4ùúãùúå(x)Œ¶(x). (27.6) 5) Integratebypartsfrom atob: ‚à´b adxd2U(x) dx2Œ¶(x)=‚àí‚à´b adx4ùúãùúå(x)Œ¶ (x), dU(x) dxŒ¶(x)|b a‚àí‚à´b adxdU(x) dxŒ¶‚Ä≤(x)=‚àí‚à´b adx4ùúãùúå(x)Œ¶ (x) ‚áí‚à´b adxdU(x) dxŒ¶‚Ä≤(x)=‚à´b adx4 27.2 Finite Element Method 533 Equation(27.7)isa weakformofthePDE,‚Äúweak‚Äùinthesensethatitdoesnotrequire theexistenceofthesecondderivativeof U(x),orthecontinuityof ùúå(x). 27.2.2 Galerkin Spectral Decomposition TheapproximatesolutiontotheweakPDEproceedsviathefollowingthreesteps: 1) SplitthefulldomainofthePDEintosubdomainscalled elements.AsseeninFigure27.1, forour1Dproblemwetakethesubdomainelementstobestraightlinesofequallength. AswillbeseeninFigure27.4,fora2Dproblem,theelementsmightbetriangles. 2) Expandthesolutionwithineachelementintermsofthebasisfunctions ùúôi: U(x)‚âÉN‚àí1‚àë j=0ùõºjùúôj(x). (27.8) Evenwhenthebasisfunctionsarenotsinesorcosines,thisexpansionisstillcalleda spectraldecomposition.Choose ùúôi‚Äôsthatareconvenientforcomputation.Thesolution reducestodeterminingtheunknownexpansioncoefficients ùõºj. 3) Matchtheelementalsolutionsontoeachother. Considerablestudyhasgoneintodeterminingtheeffectivenessofdifferentbasisfunc- tions,ùúôi‚Äôs,usedtorepresentthesolutiononeachfiniteelement.Iftheelementsaremade sufficientlysmall,thengoodaccuracyisobtainedwithsimplepiecewise-continuous ùúôi‚Äôs. Forour1Dproblem,weuse elementsthatarelinesegmentsbetween xiandxi+1,andweuse basisfunctions thathavetheformoftrianglesor‚Äúhats‚Äùbetween xi‚àí1andxi+1(Figure27.2). Wealsorequirethateachbasisfunctionequals1atitsparticular xi‚Äôsvertex, ùúôi(xi)=1: ùúôi(x)=‚éß ‚é™ ‚é™ ‚é™ ‚é® ‚é™ ‚é™ ‚é™‚é©0,forx<xi‚àí1,orx>xi+1, x‚àíxi‚àí1 hi‚àí1,forxi‚àí1‚â§x‚â§xi, xi+1‚àíx hi,forxi‚â§x‚â§xi+1.(hi=xi+1‚àíxi), (27.9) Duetothischoiceofhavingeachbasisfunctionequals0or1atthenodes, ùúôi(xj)=ùõøij, (27.10) x0 x1 xN‚Äì1 xi xi‚Äì1 xi+1 xi‚Äì2 xi+2. . .Œ¶N œïiœïiŒ¶1 Œ¶0  . . . Figure 27.2 Basis functions used in Ô¨Ånite-element solution of the 1D Laplace‚Äôs equation. Left: A set of overlapping basis functions ùúôi. Each function is a triangle from xtox. Middle : A piecewise-linear function. Right: A 534 27 Finite Element Electrostatics ‚äô the values of the expansion coefficients ùõºimust equal the values of the (still unknown) solutionatthenodes: U(xi)‚âÉN‚àí1‚àë i=0ùõºiùúôi(xi)=ùõºiùúôi(xi)=ùõºi, (27.11) ‚áíU(x)‚âÉN‚àí1‚àë j=0U(xj)ùúôj(x). (27.12) Equation(27.12)makesitclearthattheexpansionintermsofbasisfunctionsisessentially aninterpolationbetweenthesolutionatthenodes. 27.2.3 Solution via Linear Equations Becausethebasisfunctions ùúôiin(27.8)areknown,solvingfor U(x)involvesdetermining the expansion coefficients ùõºj, which, as we just said, are the unknown values of the true solutionU(x)onthenodes.Wedeterminethosevaluesbysubstitutingtheexpansionsfor U(x)andŒ¶(x)into the weak form of the PDE (27.7). This converts the integral equation intoasetofsimultaneouslinearequations,whichweknowhowtosolve.Asdiscussedin Chapter7,thisleadstothestandardmatrixform Ay=b. (27.13) Inthepresentcase, yisavectorofunknowns,and A(thestiffnessmatrix )and b(theload) are known. To that end, we substitute the expansion U(x)‚âÉ‚àëN‚àí1 j=0ùõºjùúôj(x)into the weak form(27.7)toobtain: ‚à´b adxd dx(N‚àí1‚àë j=0ùõºjùúôj(x)) dŒ¶ dx=‚à´b adx4ùúãùúå(x)Œ¶(x). By successively selecting Œ¶(x)=ùúô0,ùúô1,‚Ä¶,ùúôN‚àí1,w eo b t a i n Nsimultaneous linear equationsfortheunknown ùõºj‚Äôs: ‚à´b adxd dx(N‚àí1‚àë j=0ùõºjùúôj(x)) dùúôi dx=‚à´b adx4ùúãùúå(x)ùúôi(x),i=0,N‚àí1. (27.14) Herewefactorouttheunknown ùõºj‚Äôsandwriteouttheexplicitequations: ùõº0‚à´b aùúô‚Ä≤ 0ùúô‚Ä≤ 0dx+ùõº1‚à´b aùúô‚Ä≤ 0ùúô‚Ä≤ 1dx+¬∑¬∑¬∑+ùõºN‚àí1‚à´b aùúô‚Ä≤ 0ùúô‚Ä≤ N‚àí1dx=‚à´b a4ùúãùúåùúô0dx, ùõº0‚à´b aùúô‚Ä≤ 1ùúô‚Ä≤ 0dx+ùõº1‚à´b aùúô‚Ä≤ 1ùúô‚Ä≤ 1dx+¬∑¬∑¬∑+ùõºN‚àí1‚à´b aùúô‚Ä≤ 1ùúô‚Ä≤ N‚àí1dx=‚à´b a4ùúãùúåùúô1dx, ... ùõº0‚à´b aùúô‚Ä≤ N‚àí1ùúô‚Ä≤ 0dx+ùõº1‚à´¬∑¬∑¬∑+ùõºN‚àí1‚à´b aùúô‚Ä≤ N‚àí1ùúô‚Ä≤ N‚àí1dx=‚à´b a4ùúãùúåùúôN‚àí1dx. 27.2 Finite Element Method 535 Becausewehavechosenthe ùúôi‚Äôstobesimplehatfunctions,thederivativesareeasytoeval- uateanalytically(forotherbasestheycanbecarriedoutnumerically): dùúôi,i+1 dx=‚éß ‚é™ ‚é™ ‚é™ ‚é™ ‚é™ ‚é® ‚é™ ‚é™ ‚é™ ‚é™ ‚é™‚é©0,x<xi‚àí1,orxi+1<x, 1 hi‚àí1,xi‚àí1‚â§x‚â§xi, ‚àí1 hi,xi‚â§x‚â§xi+1, 0,x<xi,orxi+2<x 1 hi,xi‚â§x‚â§xi+1, ‚àí1 hi+1,xi+1‚â§x‚â§xi+2.(27.15) Theintegrationsarenowfairlysimple: ‚à´xi+1 xi‚àí1dx(ùúô‚Ä≤ i)2=‚à´xi xi‚àí1dx1 (hi‚àí1)2+‚à´xi+1 xidx1 h2 i=1 hi‚àí1+1 hi, ‚à´xi+1 xi‚àí1dxùúô‚Ä≤ iùúô‚Ä≤ i+1=‚à´xi+1 xi‚àí1dxùúô‚Ä≤ i+1ùúô‚Ä≤ i=‚à´xi+1 xidx‚àí1 h2 i=‚àí1 hi, (27.16) ‚à´xi+1 xi‚àí1dx(ùúô‚Ä≤ i+1)2=‚à´xi+1 xidx(ùúô‚Ä≤ i+1)2=‚à´xi+1 xidx+1 h2 i=+1 hi. We rewrite these equations in the standard matrix form (27.13) with yconstructed from the unknown ùõºj‚Äôs, and the tridiagonal matrix Aconstructed from the integrals over the derivatives: y=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£ùõº0 ùõº1 ... ùõºN‚àí1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶,b=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£‚à´x1 x0dx4ùúãùúå(x)ùúô0(x) ‚à´x2 x1dx4ùúãùúå(x)ùúô1(x) ... ‚à´xN xN‚àí1dx4ùúãùúå(x)ùúôN‚àí1(x)‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶, (27.17) A=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£1 h0+1 h1‚àí1 h1‚àí1 h00‚Ä¶ ‚àí1 h11 h1+1 h2‚àí1 h20‚Ä¶ 0‚àí1 h21 h2+1 h3‚àí1 h3‚Ä¶ ......‚àí1 hN‚àí1‚àí1 hN‚àí21 hN‚àí2+1 hN‚àí1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (27.18) Theelementsin Aarejustcombinationsofinversestepsizes,andso,theydonotchange for different charge densities ùúå(x). This is part of what makes FEM so efficient, once it‚Äôs allsetup.Theelementsin bdochangefordifferent ùúå‚Äôs,buttherequiredintegralscanbe",6710
27.2.4 Imposing the Boundary Conditions. 27.4 2D FEM Exercises,"536 27 Finite Element Electrostatics ‚äô performedanalyticallyorwithGaussianquadrature(Chapter5).Once Aandbarecom- puted,efficientmethodsfromalinearalgebralibraryareusedtosolvefor y,andthusthe expansioncoefficients ùõºj. 27.2.4 Imposing the Boundary Conditions Sincethebasisfunctionsvanishattheendpoints,asolutionexpandedinthemmustalso vanishthere.Thiswillnotdoingeneral,andsowemustaddtoourgeneralsolution, U(x), aparticularone, Uaùúô0(x),thatsatisfiestheboundaryconditions[Li,2014]: U(x)=N‚àí1‚àë j=0ùõºjùúôj(x)+UaùúôN(x)(satisfiesboundaryconditions), (27.19) whereUa=U(xa).Wesubstitute U(x)‚àíUaùúô0(x)intotheweakformofthePDEtoobtain (N+1)simultaneousequations,stilloftheform Ay=b‚Ä≤,butnowwith A=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£A0,0¬∑¬∑¬∑A0,N‚àí10 ... AN‚àí1,0¬∑¬∑¬∑AN‚àí1,N‚àí10 00 ¬∑¬∑¬∑1‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶,b‚Ä≤=‚é° ‚é¢ ‚é¢ ‚é¢ ‚é¢ ‚é¢‚é£b0‚àíA0,0Ua ... bN‚àí1‚àíAN‚àí1,0Ua Ua‚é§ ‚é• ‚é• ‚é• ‚é• ‚é•‚é¶. (27.20) Weseethatwehavenowaddeda1onthelastrowof A,andaddedatermontoeachelement ofb: b‚Ä≤ i=bi‚àíAi,0Ua,i=1,‚Ä¶,N‚àí1,b‚Ä≤ N=Ua. (27.21) Toimposetheboundaryconditionat x=b,weagainaddaparticularsolution UbùúôN‚àí1(x), andsubstituteitintotheweakformtoobtain b‚Ä≤ i=bi‚àíAi,N‚àí1Ub,i=1,‚Ä¶,N‚àí1b‚Ä≤ N=Ub. (27.22) Sonowweneedtosolvethematrixequation Ay=b‚Ä≤.For1Dproblems,100‚Äì1000equations arecommon,whilefor3Dproblemstheremaybemillions.Becausethenumberofcalcu- lationsvariesapproximatelyas N2,itisimportanttouseefficientandaccuratealgorithms, orelseround-offerrorcaneasilydominate. 27.3 1D FEM Problems InListing27.1,wegiveourprogram LaplaceFEM_1D.py whichdeterminesthe1DFEMsolu- tion,andinFigure27.3,weshowthatsolution.Weseeontheleftofthefigurethatthree elements do not provide even visual agreement with the analytic result, whereas N=11 elementsdo. 1) ExaminetheFEMsolutionforthechoiceofparameters a=0,b=1,Ua=0,Ub=1. (27.23) 2) Generateyourowntriangulationbyassigningexplicit xvaluesatthenodesoverthe interval[0,1]. 3) Startwith N=3andsolvetheequationsfor Nvaluesupto1000. 27.4 2D FEM Exercises 537 Figure 27.3 Exact (line) versus FEM solution (points) for the two-plate problem for N=3a n d N=11 Ô¨Ånite elements ( N=3 displaced upward for clarity). On this scale, the N=11 solution is identical to the exact one. 01 0 1U xN = 3 (scaled) N = 11 4) Examinethestiffnessmatrix Aandensurethatitistriangular. 5) Verifythattheintegrationsusedtocomputetheloadvector bareaccurate. 6) Verifythatthesolutionofthelinearequation Ay=biscorrect. 7) Plotthenumericalsolutionfor U(x)forN=10,100,and1000,andcomparewiththe analyticsolution. 8) Thelogoftherelativeglobalerror(numberofsignificantfigures)is Óà±=log10|||||1 b‚àía‚à´b adxUFEM(x)‚àíUexact(x) Uexact(x)|||||. (27.24) Plottheglobalerror versusxforN=10,100,and1000. 9) Modifyyourprogramtousepiecewise-quadraticfunctionsforinterpolation,andcom- paretheresultsobtainedtothoseobtainedwiththelinearfunctions. 10) Exploretheresultingelectricpotentialandcheckthatthechargedistributionbetween theplateshastheexplicit xdependence ùúå(x)=1 4ùúã‚éß ‚é™ ‚é™ ‚é® ‚é™ ‚é™‚é©1 2‚àíx, sinx, 1atx=0,‚àí1atx=1(acapacitor) .(27.25) 27.4 2D FEM Exercises The steps followed to derive 2D FEM are similar to those for the 1D method, with the bigdifferencebeingthatthefiniteelementsarenow2Dtriangles,asopposedto1Dlines. Figure27.4showshowanarbitrarilyshapeddomainmightbedecomposedintotriangles. Althoughlifeissimplerifallthefiniteelementsareofthesamesizeandshape,thisisnot necessary,and,indeed,asweseeinthefigure,higherprecisionmaybeobtainedbypicking smallerdomainsinregionswherethesolutionvariesrapidly,andlargerdomainsinregions wherethesolutionvariesslowly. 538 27 Finite Element Electrostatics ‚äô Discretization error1 23 45 67 89 1011 1213 1415 1617 1819 2021 2223 2425 2627 2829 3031 32 1 2325 Figure 27.4 Left: Decomposition of a 2D domain into triangular elements. Smaller triangles are used in regions of rapid variation and larger triangles in regions of slow variation. Discretization errors occur at boundaries. Right: A decomposition of a rectangular domain into 32 right triangles o nam e s hw i t h2 5n o d e s( i ng r a yn u m b e r s ) . Asinthe1Dmethod,theapproximatesolution U(x,y)isexpandedinasetofbasisfunc- tions,ùúôi(x,y),inthiscase2Dfunctions: U(x,y)=N‚àí1‚àë j=0ùõºjùúôj(x,y). (27.26) Andasyoucanimagine,2Dand3DFEMgettoberathercomplicated.Butnottoworry,we justrefertheinterestedreadertoPolycarpou[2006]andReddy[1993]forthedetails.Here weprovide,andhaveyouworkwith,thecode LaplaceFEM_2D.py inwhichwehaveapplied allthosedetails. AsshownontherightofFigure27.4,ourapplicationof2DFEMhasthesolutiondomain coveredbyameshoftriangularelements.Eachtriangleinthemeshisnumbered,inthis casefrom1to32.Inaddition,thethreeverticesofeachtrianglearenumberedinacounter- clockwisedirectionfrom1to3.Furthermore,eachnodeinthemesh(thedarkcirclesin Figure 27.4 where lines intersect) are numbered, in this case from 1 to 25. Listing 27.2 presents LaplaceFEM_2D.py ,ourimplementationofthe2DFEMsolutiontothe2DLaplace‚Äôs equation,basedontheMatlabcodeofPolycarpou[2006].Itutilizes800elementsand441 nodes.Theoutputofthiscodeisessentiallythesameasoursimplesolutiontothesame problemusingthefinitedifferencesmethod. 1) Examinetheeffectofvaryingthedomainheightandwidthin LaplaceFEM_2D.py ,aswell asthenumberofelements. 2) Comparethisnumericalsolutiontotheanalyticone(theFourierseriesinSection21.2.1) anddeterminehowtheprecisionchangesasthenumberofelementsvaries. 3) Modifytheprogramsothatitsolvestheparallelplatecapacitorproblem,andcompare ittothefinitedifferencesolution.",5317
27.5 Code Listings,"27.5 Code Listings 539 27.5 Code Listings Listing 27.1 LaplaceFEM_1D.py Uses finite-elements to solve the 1D Laplace‚Äôs equationviaaGalerkinspectraldecomposition.Theresultingmatrixequationsaresolved withMatplotlib. 1# LaplaceFEM_1D . py : Solutn 1 ‚àíD Laplace E q via finite elements; utf8 coding \""\""\"" Dirichlet boundary conditions surrounding four walls Domain dimensions : WxH, with 2 t r i a n g l e s per square 5Based on F E M 2 D L _ B o x Matlab program in Polycarpou , Intro to the Finite Element Method in Electromagnetics , Morgan &Claypool (2006) \""\""\"" fromvisualimport ‚àó 9fromvisual.graph import ‚àó fromnumpyimport ‚àó fromnumpy.linalg importsolve 13N=1 1 h=1 . /( N ‚àí1) u=z e r o s( N , float) A=z e r o s( ( N ,N ), float) 17b=z e r o s( ( N ,N ), float) x2 = zeros(21, float) u_fem = zeros(21, float) u_exact = zeros(21, float) 21error = zeros(21, float) x=z e r o s ( N , float) graph1 = gdisplay(width=500,height=500,title= ‚ÄôAnalytic (Blue) vs FEM‚Äô ,\ 25 xtitle= ‚Äôx‚Äô,ytitle= ‚ÄôU‚Äô,xmax=1, ymax=1, xmin=0, ymin=0) funct1 = gcurve(color=color.blue) funct2 = gdots(color=color.red) funct3 = gcurve(color=color.cyan) 29 foriin range (0, N): x[i] = i ‚àóh foriin range (0, N): # Initialize 33b[i, 0] = 0. forjin range (0, N): A[i][j] = 0. 37deflin1(x, x1, x2): #H a tf u n c return(x‚àíx1)/(x2 ‚àíx1) deflin2(x, x1, x2): 41return(x2‚àíx)/(x2‚àíx1) deff(x): return1. 45 defint1(min,max): # Simpson no = 1000 sum=0 . 49interval = ( max‚àímin)/( n o ‚àí1) fornin range (2, no, 2): # Loop odd points x=i n t e r v a l ‚àó(n‚àí1) sum+= 4 ‚àóf(x) ‚àólin1(x, min,max) 53fornin range (3, no, 2): # Loop even points x=i n t e r v a l ‚àó(n‚àí1) sum+= 2 ‚àóf(x) ‚àólin1(x, min,max) sum+= f (min)‚àólin1(min,min,max)+f (max)‚àólin1(max,min,max) 57sum ‚àó=i n t e r v a l / 6 . return sum defint2(min,max): # Simpson 61no = 1000 sum=0 . interval = ( max‚àímin)/( n o ‚àí1) 540 27 Finite Element Electrostatics ‚äô fornin range (2, no, 2): # Loop odd points 65 x=i n t e r v a l ‚àó(n‚àí1) sum+= 4 ‚àóf(x) ‚àólin2(x, min,max) fornin range (3, no, 2): # Loop even points x=i n t e r v a l ‚àó(n‚àí1) 69 sum+= 2 ‚àóf(x) ‚àólin2(x, min,max) sum+= f (min)‚àólin2(min,min,max)+f (max)‚àólin2(max,min,max) sum ‚àó=i n t e r v a l/6 . return sum 73 defnumerical(x, u, xp): N=1 1 # Interpolate solution y=0 . 77foriin range (0, N‚àí1): ifxp>=x [ i ]andxp<=x [ i+1 ] : y = lin2(xp,x[i],x[i+1]) ‚àóu[i] + lin1(xp,x[i],x[i+1]) ‚àóu[i+1] returny 81 defexact(x): # Analytic solution u=‚àíx‚àó(x‚àí3.) / 2. returnu 85 foriin range (1, N): A[i‚àí1, i‚àí1] = A[i ‚àí1, i‚àí1] + 1. / h A[i‚àí1, i] =A[i ‚àí1, i]‚àí1. / h 89A[i , i ‚àí1] = A[i ‚àí1, i] A[i, i] =A[i, i] + 1. / h b[i‚àí1, 0] = b[i ‚àí1, 0] + int2(x[i ‚àí1], x[i]) b[i, 0] = b[i, 0] + int1(x[i ‚àí1], x[i]) 93 foriin range (1, N): # Dirichlet B C left end b[i, 0] = b[i, 0] ‚àí0.‚àóA[i , 0] A[i , 0] = 0. 97A[0, i] = 0. A[0, 0] = 1. b[0, 0] = 0. 101foriin range (1, N): # Dirichlet B C right end b[i, 0] = b[i, 0] ‚àí1.‚àóA[i , N ‚àí1] A[i , N ‚àí1] = 0. A[N‚àí1, i] = 0. 105A[N‚àí1, N‚àí1] = 1. b[N‚àí1, 0] = 1. sol = solve(A, b) 109foriin range (0, N): u[i] = sol[i, 0] foriin range (0, 21): 113x2[i] = 0.05 ‚àói foriin range (0, 21): u_fem[i] = numerical(x, u, x2[i]) 117u_exact[i] = exact(x2[i]) funct1.plot(pos=(0.05 ‚àói, u_exact[i])) funct2.plot(pos=(0.05 ‚àói, u _ f e m[i])) error[i] = u_fem[i] ‚àíu_exact[i] # Global error Listing 27.2 LaplaceFEM_2D.py Uses finite-elements to solve the 2D Laplace‚Äôs equation. # LaplaceFEM_2D.py solve 2D Laplace Eq via Finite elements method; utf ‚àí8coding 2 \""\""\"" Dirichlet boundary conditions surrounding four walls Domain dimensions: WxH, with 2 triangles per square Based on FEM2DL_Box Matlab program in Polycarpou, Intro to the Finite 6Element Method in Electromagnetics, Morgan &Claypool (2006) \""\""\"" 27.5 Code Listings 541 fromnumpyimport ‚àó fromnumpy.linalg importsolve 10importpylab as p frommpl_toolkits.mplot3d importAxes3D # N u m squares , nodes, triangles , m e s h coords , Initialization 14 Width = 1.; Height = 1.; Nx = 20; Ny = 20; U0 = 100 Xurc = Width; Yurc = Height; Yllc = 0; Xllc = 0 Ns = Nx ‚àóNy; Nn = (Nx + 1) ‚àó(Ny + 1) 18Dx = (Xurc ‚àíXllc)/Nx; Dy = (Yurc ‚àíYllc)/Ny; Ne = 2 ‚àóNs ge = zeros(Ne, float) x=z e r o s ( N e , float); y= zeros(Ne, float) Ebcnod = zeros(Ne, int); Ebcval = zeros(Ne, int) 22node = zeros((Ne + 1, Ne + 1), int) foriin range (1, Nn + 1): x[i] = (i ‚àí1)  percent (Nx + 1) ‚àóDx 26y[i] = floor((i ‚àí1) / (Nx + 1)) ‚àóDy # Connectivity Information foriin range (1, Ns + 1): 30node[2 ‚àói‚àí1, 1] = i + floor((i ‚àí1) / Nx) node[2 ‚àói‚àí1, 2] = node[2 ‚àói‚àí1, 1] + 1 + Nx + 1 node[2 ‚àói‚àí1, 3] = node[2 ‚àói‚àí1, 1] + 1 + Nx + 1 ‚àí1 node[2 ‚àói, 1] = i + floor((i ‚àí1) / Nx) 34node[2 ‚àói , 2] = node[2 ‚àói, 1]+1 node[2 ‚àói , 3] = node[2 ‚àói,1 ]+1+N x+1 # Dirichlet Boundary Conditions 38Tnebc = 0 foriin range (0, Nn): ifx[i] == Xllc orx[i] == Xurc ory[i] == Yllc: Tnebc = Tnebc + 1 42 Ebcnod[Tnebc] = i Ebcval[Tnebc] = 0 elify[i] == Yurc: Tnebc = Tnebc + 1 46 Ebcnod[Tnebc] = i Ebcval[Tnebc] = U0 # Initialize A matrix , b vector , form matrix 50A = zeros ((Nn + 1, Nn + 1) , float) b=z e r o s( ( N n+1 ,1 ), float) forein range (1, Ne): x21 = x[node[e, 2]] ‚àíx[node[e, 1]] 54x31 = x[node[e, 3]] ‚àíx[node[e, 1]] x32 = x[node[e, 3]] ‚àíx[node[e, 2]] x13 = x[node[e, 1]] ‚àíx[node[e, 3]] y12 = y[node[e, 1]] ‚àíy[node[e, 2]] 58y21 = y[node[e, 2]] ‚àíy[node[e, 1]] y31 = y[node[e, 3]] ‚àíy[node[e, 1]] y23 = y[node[e, 2]] ‚àíy[node[e, 3]] J=x 2 1 ‚àóy31‚àíx31 ‚àóy21 62 # Evaluate A matrix , element vector ge A[1, 1] = ‚àí(y23 ‚àóy23 + x32 ‚àóx32) / (2 ‚àóJ) A[1, 2] = ‚àí(y23 ‚àóy31 + x32 ‚àóx13) / (2 ‚àóJ) 66A[2, 1] = A[1, 2] A[1, 3] = ‚àí(y23 ‚àóy12 + x32 ‚àóx21) / (2 ‚àóJ) A[3, 1] = A[1, 3] A[2, 2] = ‚àí(y31 ‚àóy31 + x13 ‚àóx13) / (2 ‚àóJ) 70A[2, 3] = ‚àí(y31 ‚àóy12 + x13 ‚àóx21) / (2 ‚àóJ) A[3, 2] = A[2, 3] A[3, 3] = ‚àí(y12 ‚àóy12 + x21 ‚àóx21) / (2 ‚àóJ) ge[1] = 0 74ge[2] = 0 ge[3] = 0 542 27 Finite Element Electrostatics ‚äô # Evaluate element pe &update A matrix 78foriin range (1, 4): forjin range (1, 4): A[node[e, i], node[e, j]] = A[node[e, i], node[e, j]] \ +A [i, j] 82 b[node[e, i]] = b[node[e, i]] + ge[i] # Imposition of Dirichlet boundary conditions foriin range (1, Tnebc): 86forjin range (1, Nn + 1): ifj. =E b c n o d [ i ] : b[j] = b[j] ‚àíA[j , Ebcnod[i]] ‚àóEbcval[i] A[Ebcnod[i], :] = 0 90A[:, Ebcnod[i]] = 0 A[Ebcnod[i], Ebcnod[i]] = 1 b[Ebcnod[i]] = Ebcval[i] 94# Solution , place on grid , plot V = linalg.solve(A, b) (X, Y) = p.meshgrid(arange(Xllc , Xurc + 0.1, 0.1 ‚àó(Xurc‚àíXllc)), arange(Yllc, Yurc + 0.1, 0.1 ‚àó(Yurc‚àíYllc))) 98Vgrid = zeros((11, 11), float) foriinarange(1, 11): forjinarange(1, 11): forein range (0, Ne): 102 x2p = x[node[e, 2]] ‚àíX[i, j] x3p = x[node[e, 3]] ‚àíX[i, j] y2p = y[node[e, 2]] ‚àíY[i, j] y3p = y[node[e, 3]] ‚àíY[i, j] 106 A1 = 0.5 ‚àóabs(x2p ‚àóy3p‚àíx3p ‚àóy2p) x2p = x[node[e, 2]] ‚àíX[i, j] x1p = x[node[e, 1]] ‚àíX[i, j] y2p = y[node[e, 2]] ‚àíY[i, j] 110 y1p = y[node[e, 1]] ‚àíY[i, j] A2 = 0.5 ‚àóabs(x2p ‚àóy1p‚àíx1p ‚àóy2p) x1p = x[node[e, 1]] ‚àíX[i, j] y21 = y[node[e, 2]] ‚àíy[node[e, 1]] 114 y1p = y[node[e, 1]] ‚àíY[i, j] x21 = x[node[e, 2]] ‚àíx[node[e, 1]] A3 = 0.5 ‚àóabs(x1p ‚àóy3p‚àíx3p ‚àóy1p) y3p = y[node[e, 3]] ‚àíY[i, j] 118 x31 = x[node[e, 3]] ‚àíx[node[e, 1]] x3p = x[node[e, 3]] ‚àíX[i, j] y31 = y[node[e, 3]] ‚àíy[node[e, 1]] J=x 2 1 ‚àóy31‚àíx31 ‚àóy21 122 if abs(J / 2 ‚àí(A1 + A2 + A3)) <0.00001 ‚àóJ/2 : ksi = (y31 ‚àó(X[i, j] ‚àíx[node[e, 1]]) ‚àíx31 ‚àó(Y[i, j] ‚àíy[node[e, 1]])) / J ita = ( ‚àíy21 ‚àó(X[i, j] ‚àíx[node[e, 1]]) + x21 ‚àó(Y[i, 126 j]‚àíy[node[e, 1]])) / J N1 = 1 ‚àíksi‚àíita N2 = ksi N3 = ita 130 Vgrid[i, j] = N1 ‚àóV[node[e, 1]] + N2 ‚àóV[node[e, 2]] \ +N 3 ‚àóV[node[e, 3]] # Plot the finite element solution of V using a contour plot 134fig = p.figure() ax = Axes3D(fig) ax.plot_wireframe(X, Y, Vgrid, color= ‚Äôr‚Äô) ax.set_xlabel( ‚ÄôX‚Äô) 138ax.set_ylabel( ‚ÄôY‚Äô) ax.set_zlabel( ‚ÄôPotential‚Äô ) p.show()",7617
Appendix Codes and Animations,"543 Appendix Codes and Animations Python Codes (.py sufÔ¨Åx removed) SITES.SCIENCE .OREGONSTATE .EDU/~LANDAUR /BOOKS/CODES/ Name Page Description Name Page Description 3GraphVisual 38 MultiplotsVisual 3Dshapes 38 Visual‚Äôs3Dshapes 3QMdisks 496 3diskQM,Matplot 3QMdisksVis 496 3diskQM,Vis ABM 163 ABMODEsolver AdvecLax 516 Advectioneq Area 25 SimplescreenI/O AreaFormatted 42 FormattedI/O Beam 529 Navier-Stokeseq BeamContour 530 Flowcontours Bessel 58 Downwardrecur Bisection 120 Bisectionalgorithm Bound 434 Intregraleqtneigen Bugs 344 Logisticbifurcations CirqCNOT 268 QCCNOTgate CirqHalfAdder 269 QC1/2adder CirqSwap 255 QCSwap2qubits CirToffoli 264 3qubitCCNOT Coastline 313 FractalDboxcount Column 325 Columngrowth CWT 220 Continuous waveletsDecaySound 77 Spontaneousdecay DFTcomplex 190 ComplexDFT DFTreal 190 RealDFT Directives 42 I/Odirectives, escapeDLA 318 Diffusionaggregate DWT 221 DiscretewaveletTF EasyMatPlot 38 Matplot2-D EasyVisual 38 Visualeasyplot Eigen 136 Matrixeigenvalues EMcirc 499 FDTDcircularpol Entropy 345 Shannonentropy Entangle 284 Entangledstates EqHeat 462 Heateqsolution EqHeatAnimate 457 HeatEqmov EqStringVis 478 WaveeqtnVismov EqStringMat 478 WaveeqnMatplot FDTD 497 Finitedifftimedom Fern 324 1-Dfernfractal Fern3D 324 3Dfernfractal FFT 191 FastFourier transformFFTappl 191 FFT +graphs Film 313 Filmdeposition Fit 121 Least-squaresfit Computational Physics: Problem Solving with Python ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 544 Appendix Codes and Animations Python Codes (.py sufÔ¨Åx removed) SITES.SCIENCE .OREGONSTATE .EDU/~LANDAUR /BOOKS/CODES/ Name Page Description Name Page Description FourierMatplot 190 InteractiveDFT FullAdder 269 QCFulladder Gameoflife 312 Gameoflife GradesMatPlot 36 Matplotmultiplots GradTape.py 239 TensorFlowGrad TapeHadamard 264 QCHadamardGate HarmosAnimate 496 Quantumpacket HeatCNTridiag 462 Betterheatalgr Hubble 250 AIHubbledatafit Hyperfine 146 MatrixHhyperfine IntegGauss 98 Gaussian quadratureIsingViz 385 Isingmodel Islands.pov 327 Raytracing Keras 252 KerasAIfit KmeansCluster 249 AIKmeans clusteringLagrange 107 Lagrangeinterpoltn LaplaceFEM_1D 539 1Dfiniteelement LaplaceFEM_2D 540 2Dfiniteelement LaplaceLine 450 Laplaceequation LensGravity 422 GRlightdeflection Limits 43 Machineprecision LyapLog 345 Lyapunovcoef MatPlot2figs 39 Matplotmultiplots Matrix 130 Matrixarraymult MD1D 402 1-DMD MD2D 404 2-DMD MDpBC 406 MD,PeriodicBC NeuralNet 247 NeuralNetwork Neuron 247 AnAIneuron NewtonCD 120 Newton-Raphsearch NewtonNDanimate 144 N-D Newton-RaphsonNoiseSincFilter 181 Fourierfiltering ODEsympy 366 SymbolicHOODE ODEsympy0 366 Paramsfor ODEsympy OracleSim 285 SimulatorGrover algrOracleIBM 286 IBMGroveralgr PandaRead 251 Pandastableread Perceptron 249 PerceptronML PondMatPlot 40 Matplotscatterplot PrecessHg 418 PrecessionHg ProteinFold 73 MCProteinfolding PredatorPrey 346 Populationdynamics ProjectileAir 306 Projectilewithdrag QFT4 284 2qubitQFT QFTn 284 NqubitQFT QMC 388 QuantumMC QMCbouncer 389 QMCbouncer QuantumEigen 304 Quantumeigenrk4 QuantumNumerov 303 Schr√∂dingereqtn QuarterPlate 497 FDTD1/2waveplate RelOrbits 423 Relativisticorbits Ricci 420 TensorswiSymPy rk4 161 rk4ODEsolver rk45 162 Adaptivesteprk4 Scatt 435 Quantumscatt,LS eqtnScatter3dPlot 41 Matplot3Dscatter SGDclass 251 Stochasticgrad descentShor 287 QCShor‚Äôsalgor Appendix Codes and Animations 545 Python Codes (.py sufÔ¨Åx removed) sites.science.oregonstate.edu/~landaur/Books/Codes/ Name Page Description Name Page Description Sierpin 308 Sierpinskygasket Simple3Dplot 40 Matplotsurface SimpleNet 248 SimpleAInet SkPolyFit 238 FitwiSkLearn Soliton 516 KdeVsolitons SolitonAnimate 516 Solitonmovie Spline 120 Splinefitting SplineInteract 120 Interactivesplines SqBilliardCM 364 SquareBilliards TelehMat 495 Transmissionline TensorBE 238 TensorFlowH isotopesTuneNumpy 141 Matrixspeedup TensorTest 235 TestTensorFlow TrapMethods 97 Trapezoidrule TwoDsol.java 516 Java2DSoliton TwoHgates 265 2Hadamardgates UranusNeptune 302 Uranusorbitpertb VisualWorm.ipyn 423 WormholeVizltn vonNeuman 99 vonNeumanreject Walk 73 Randomwalk Walk3D 73 3Drandomwalk WangLandau 372 Wang-LandauMC Waves2D 478 2-Dwaveeq Waves2Danal 478 Analyticmembrane WormHole 423 Wormholederivs XplusH 266 X,Hgates- >|1> XZHM 266 H,X,Z,Mgates CodesData Variousinputdata Online Animations Directories (multiple Ô¨Åles and multiple formats within) mpeg, mp4, avi: require media player like VLC, gif: requires browser Directory Chapter Directory Chapter DoublePendulums 16 Fractals 14 GravityWaves.mp4 19 Laplace&HeatEquations 21,22 MDSimulations 18 Waves,Shocks,Solitons 23,25 WavePacketInteractions 24 WavePacket-WavePacketScatt 24 2DSolitons 25 WavePacketSlits 24",4741
References,"546 References Abarbanel,H.D.I.,Rabinovich,M.I.,andSushchik,M.M.(1993) IntroductiontoNonlinear DynamicsforPhysicists, WorldScientific,Singapore. Abramowitz,M.andStegun,I.A.(1972) HandbookofMathematicalFunctions, 10thedn, U.S.GovernmentPrintingOffice,Washington,DC. Addison,P.S.(2002) TheIllustratedWaveletTransformHandbook, InstituteofPhysics Publishing,BristolandPhiladelphia,PA. AnaConda(2022) AnaConda,open-sourcePythondistributionplatform ,www.anaconda.com/ products/distribution(accessedApril2023). Ancona,M.G.(2002) ComputationalMethodsforAppliedScience&Engineering, RintonPress, Princeton,NJ. Anderson,J.A.,Lorenz,C.D.,andTravesset,A.(2008)HOOMD-blue,generalpurpose moleculardynamicssimulations. J.Compt.Phys. ,227(10),5342;glotzerlab.engin.umich .edu/hoomd-blue/(accessedApril2023). Arfken,G.B.andWeber,H.J.(2001) MathematicalMethodsforPhysicists, Harcourt/Academic Press,SanDiego,CA. Askar,A.andCakmak,A.S.(1977)Explicitintegrationmethodforthetime-dependent Schrodingerequationforcollisionproblems. J.Chem.Phys. ,68,2794. Bailey,V.A.andTownsend,J.S.(1921)Themotionofelectronsingases. Philos.Mag. ,42,873. Barnsley,M.F.,andHurd,L.P.(1992) FractalImageCompression ,A.K.Peters,Wellesley,MA. Becker,R.A.(1954) IntroductiontoTheoreticalMechanics ,McGraw-Hill,NewYork. vandenBerg,J.C.(ed.)(1999) WaveletsinPhysics ,CambridgeUniversityPress,Cambridge. Bevington,P.R.andRobinson,D.K.(2003) DataReductionandErrorAnalysisforthePhysical Sciences,3rdedn,McGraw-Hill,NewYork. Bleher,S.,Grebogi,C.,andOtt,E.(1990)Bifurcationsinchaoticscattering. PhysicaD,46,87. Bransden,B.H.andJoachain,C.J.(1991) QuantumMechanics ,2ndedn,CambridgeUniversity Press,Cambridge. Briggs,W.L.andHenson,V.E.(1995) TheDFT,AnOwner‚ÄôsManual ,SIAM,Philadelphia,PA. Bunde,A.andHavlin,S.(eds)(1991) FractalsandDisorderedSystems ,Springer-Verlag,Berlin. Burgers,J.M.(1974) TheNon-LinearDiffusionEquation;AsymptoticSolutionsandStatistical Problems,Reidel,Boston,MA. Campesato,O.(2020) TensorFlow2.0PocketPrimer ,MercuryLearningandInformation, Dulles,VA,Boston,MA,andNewDelhi. ComputationalPhysics:ProblemSolvingwithPython ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH References 547 Car,R.andParrinello,M.(1985)Unifiedapproachformoleculardynamicsand density-functionaltheory. Phys.Rev.Lett. ,55,2471. Christiansen,P.L.andLomdahl,P.S.(1981)Numericalstudyof2 +1dimensionalsine-Gordon solitons.PhysicaD,2,482. Christiansen,P.L.andOlsen,O.H.(1978)Returneffectforrotationallysymmetricsolitary wavesolutionstothesine-Gordonequation. Phys.Lett.,68A,185;(1979) PhysicaScripta , 20,531. Cirq(2023)Anopensourceframeworkforprogrammingquantumcomputers,github.com/ quantumlib/Cirq(accessedApril2023). ClarkUniversity(2011) Statistical&ThermalPhysicsCurriculumDevelopmentProject , stp.clarku.edu/(accessedApril2023); DensityofStatesofthe2DIsingModel . ComputinginScience&Engineering(2015).www.computer.org/csdl/magazine/cs(accessed April2013). Conda(2023)Package,dependencyandenvironmentmanagementforanylanguage, docs.conda.io/en/latest/(accessedApril2023).",3064
References,"Cooley,J.W.andTukey,J.W.(1965)Analgorithmforthemachinecalculationofcomplex Fourierseries. Math.Comput. ,19,297. Courant,R.,Friedrichs,K.,andLewy,H.(1928)√úberdiepartiellenDifferenzengleichungen dermathematischenphysik. Math.Ann. ,100,32. CPUG(2009)ComputationalPhysicsdegreeprogramforUndergraduates, sites.science.oregonstate.edu/landaur/CPUG/(accessedApril2023). Crank,J.andNicolson,P.(1946)Apracticalmethodfornumericalevaluationofsolutionsof partialdifferentialequationsoftheheat-conductiontype. Proc.CambridgePhilos.Soc. ,43,50. Createproduction-grademachinelearningmodelswithTensorFlow(2022)(accessedApril 2023). Danielson,G.C.andLanczos,C.(1942)SomeimprovementsinpracticalFourieranalysisand theirapplicationtoX-rayscatteringfromliquids. J.FranklinInst. ,233,365. Daubechies,I.(1995) Waveletsandotherphasedomainlocalizationmethods ,Proc.Int.Congr. Math.,1, 2,Basel,56,Birkh√§user,Basel. DeJong,M.L.(1992)Chaosandthesimplependulum. Phys.Teach. ,30,115. Donnelly,D.andRust,B.(2005)ThefastFouriertransformforexperimentalists. Comput.Sci. Eng.,7,71. Ercolessi,F.(1997) AMolecularDynamicsPrimer ,www.cse-lab.ethz.ch/wp-content/uploads/ 2013/01/MD-Primer.pdf (accessedApril2023). Falkovich,G.andSreenivasan,K.R.(2006)Lessonfromhydrodynamicturbulence, Phys.Today ,59,43. Family,F.andVicsek,T.(1985)ScalingoftheactivezoneintheEdenprocessonpercolation networksandtheballisticdepositionmodel. J.Phys.A,18,L75. Feigenbaum,M.J.(1979)Theuniversalmetricpropertiesofnonlineartransformations. J.Stat. Phys.,21,669. Fermi,E.,Pasta,J.,andUlam,S.(1955) StudiesofNonlinearProblems ,DocumentLA-1940, LosAlamosNationalLaboratory. Fetter,A.I.andWalecka,J.D.(1980) TheoreticalMechanicsofParticlesandContinua , McGraw-Hill,NewYork. Feynman,R.P.andHibbs,A.R.(1965) QuantumMechanicsandPathIntegrals ,McGraw-Hill, NewYork. 548 References Fosdick,L.D,Jessup,E.R.,Schauble,C.J.C.,andDomik,G.(1996) AnIntroductiontoHigh PerformanceScientificComputing ,MITPress,Cambridge,MA. Garcia,A.L.(2000) NumericalMethodsforPhysics ,2ndedn,PrenticeHall,UpperSaddleRiver, NJ. Gibbs,R.L.(1975)Thequantumbouncer. Am.J.Phys. ,43,25. Goodings,D.A.andSzeredi,T.(1992)Thequantumbouncerbythepathintegralmethod. Am.J.Phys. ,59,924. Goswani,J.C.andChan,A.K.(1999) FundamentalsofWavelets ,Wiley,NewYork. Gottfried,K.andYan,T.-M.(2004) QuantumMechanics:Fundamentals ,2ndedn,Springer, NewYork. Gould,H.,Tobochnik,J.,andChristian,W.(2006) AnIntroductiontoComputerSimulations Methods,3rdedn,Addison-Wesley,Reading,MA. Graps,A.(1995)Anintroductiontowavelets. Comput.Sci.Eng. ,2,50. Haftel,M.I.andTabakin,F.(1970)Nuclearsaturationandthesmoothnessofnucleon-nucleon potentials. Nucl.Phys. ,158,1. Hanc,J.andTaylor,E.(2004)Fromconservationofenergytotheprincipleofleastaction: Astoryline. Am.J.Phys. ,73(7),663. 158,1. Hartle,J.B.(2003) Gravity,AnIntroductiontoEinstein‚ÄôsGeneralRelativity ,AddisonWesley, SanFrancisco,CA. Hartmann,W.M.(1998) Signals,Sound,andSensation ,AIPPress,Springer,NewYork. Haynes,W.M.(ed.)(2017) CRCHandbookofChemistryandPhysics ,TaylorandFrancis,Boca Raton,FL. Hidary,J.D.(2021) QuantumComputing:AnAppliedApproach ,2ndedn,SpringerNatureAG, Switzerland.",3115
References,"Higgins,R.J.(1976)FastFouriertransform:Anintroductionwithsomeminicomputer experiments. Am.J.Phys. ,44,766. Hildebrand,F.B.(1956) IntroductiontoNumericalAnalysis ,McGraw-Hill,NewYork. Hinsen,K.(2013)Softwaredevelopmentforreproducibleresearch. Comput.Sci.Eng. ,2013,60. HistoryofPython(2022)https://learnpython.com/blog/history-of-python/(accessedApril 2023). Hockney,R.W.andEastwood,J.W.(1988) ComputerSimulationUsingParticles ,AdamHilger, Bristol. Huang,K.(1987) StatisticalMechanics ,Wiley,NewYork. Hubble,E.(1929)Arelationbetweendistanceandradialvelocityamongextra-galactic nebulae.Proc.Natl.Acad.Sci.U.S.A. ,15(3),168. IBM(2023) IBMQuantum ,quantum-computing.ibm.com(accessedApril2023). InteractivePythonTutorial(2023)www.learnpython.org(accessedApril2023). Jackson,J.D.(1988) ClassicalElectrodynamics ,3rdedn,Wiley,NewYork. Jackson,J.E.(1991) AUser‚ÄôsGuidetoPrincipalComponents ,Wiley,NewYork. James,O.,vonTunnzelman,E.,Franklin,P.,andThorne,K.S.(2015)VisualizingInterstellar‚Äôs wormhole. Am.J.Phys. ,83,486. Jolliffe,I.Y.(2002) PrincipalComponentAnalysis ,2ndedn,Springer,NewYork. Jos√©,J.VandSalatan,E.J.(1998) ClassicalDynamics ,CambridgeUniversityPress,Cambridge. Jupyter(2022) JupyterNotebook:TheClassicNotebookInterface ,docs.jupyter.org/en/latest/ install.html(accessedApril2023). Keller,J.B.(1959)Largeamplitudemotionofastring. Am.J.Phys. ,27,584. References 549 Kennedy,R.(2006) ThecaseofPollock‚ÄôsFractalsFocusesonPhysics ,NewY orkTimes,2,5 December2006. Keras(2023) Keras:ThePythondeeplearningAPI ,keras.io(accessedApril2023). Kerr,R.P.(1963)Gravitationalfieldofaspinningmassasanexampleofalgebraicallyspecial metrics.Phys.Rev.Lett. ,11,237. Kittel,C.(2018) IntroductiontoSolidStatePhysics ,8thedn,Wiley,NewYork. Koonin,S.E.(1986) ComputationalPhysics ,Benjamin,MenloPark,CA. Korteweg,D.J.anddeVries,G.(1895)Onthechangeofformoflongwavesadvancingina rectangularcanal,andonanewtypeoflongstationarywaves. Philos.Mag. ,39,4. Kreyszig,E.(1998) AdvancedEngineeringMathematics ,8thedn,Wiley,NewYork. Lamb,H.(1993) Hydrodynamics ,6thedn,Cambridge,Cambridge. Landau,R.H.(1996) QuantumMechanicsII,ASecondCourseinQuantumTheory ,2ndedn, Wiley,NewYork. Landau,L.D.andLifshitz,E.M.(1971) TheClassicalTheoryofFields ,Pergamon,Oxford. Landau,L.D.andLifshitz,E.M.(1976) QuantumMechanics ,Pergamon,Oxford. Landau,L.D.andLifshitz,E.M.(1987) FluidMechanics ,Pergamon,Oxford. Landau,D.P.andWang,F.(2001)Determiningthedensityofstatesforclassicalstatistical models:Arandomwalkalgorithmtoproduceaflathistogram. Phys.Rev.E ,64,056101; Landau,D.P.,Tsai,S.-H.,andExler,M.(2004)AnewapproachtoMonteCarlosimulations instatisticalphysics:Wang‚ÄìLandausampling. Am.J.Phys. ,72,1294. Lang,W.C.andForinash,K.(1998)Time-frequencyanalysiswiththecontinuouswavelet transform. Am.J.Phys. ,66,794. Langtangen,H.P.(2016) APrimeronScientificProgrammingwithPython ,Springer-Verlag, Heidelberg. Li,Z.(2014) NumericalMethodsforPartialDifferentialEquations‚ÄìFiniteElementMethod , www4.ncsu.edu/~zhilin/(accessedApril2023). Lorenz,E.N.(1963)Deterministicnon-periodicflow. J.Atmos.Sci. ,20,130.",3053
References,"Lotka,A.J.(1925) ElementsofPhysicalBiology ,Williams&Wilkins,Baltimore,MD. MacKeown,P.K.(1985)EvaluationofFeynmanpathintegralsbyMonteCarlomethods. Am.J. Phys.,53,880. MacKeown,P.K.andNewman,D.J.(1987) ComputationalTechniquesinPhysics ,AdamHilger, Bristol. Maestri,J.J.V.,Landau,R.H.andP√°ez,M.J.(2000)Two-particleSchr√∂dingerequation animationsofwavepacket‚Äìwavepacketscattering. Am.J.Phys. ,68,1113. Mallat,P.G.(1989)Atheoryformultiresolutionsignaldecomposition:Thewavelet representation. IEEETrans.PatternAnal.Mach.Intell. ,11(7),674. Mandelbrot,B.(1967) HowlongisthecoastofBritain?Science ,156,638. Mandelbrot,B.(1982) TheFractalGeometryofNature ,Freeman,SanFrancisco,CA. Manneville,P.(1990) DissipativeStructuresandWeakTurbulence ,AcademicPress,SanDiego, CA. Mannheim,P.D.(1983)Thephysicsbehindpathintegralsinquantummechanics. Am.J.Phys. , 51,328. Marion,J.B.andThornton,S.T.(2019) ClassicalDynamicsofParticlesandSystems ,5thedn, HarcourtBraceJovanovich,Orlando,FL. Mathews,J.(2002) NumericalMethodsforMathematics,ScienceandEngineering ,PrenticeHall, UpperSaddleRiver,NJ. 550 References Matplotlib(2023) Matplotlib‚ÄîVisualizationwithPython ,matplotlib.org(accessedApril2023). McCulloch,W.S.andPitts,W.(1943)Alogicalcalculusoftheideasimmanentinnervous activity.Bull.Math.Biophys. ,5,115. Metropolis,M.,Rosenbluth,A.W.,Rosenbluth,M.N.,Teller,A.H.,andTeller,E.(1953) Equationofstatecalculationsbyfastcomputingmachines. J.Chem.Phys. ,21,1087. Moore,T.A.(2013) AGeneralRelativityWorkbook ,UniversityScienceBooks,MillValley,CA. Morris,M.S.andThorn,K.S.(1988)Wormholesinspacetimeandtheiruseforinterstellar travel:AtoolforteachingGeneralRelativity. Am.J.Phys. ,56,395. Morse,P.M.andFeshbach,H.(1953) MethodsofTheoreticalPhysics ,McGraw-Hill,NewYork. Motter,AandCampbell,D.(2013)Chaosatfifty. Phys.Today ,2013,27. Nelson,M.,Humphrey,W.,Gursoy,A.,Dalke,A.,Kale,L.,Skeel,R.D.,andSchulten,K.(1996) NAMD-scalablemoleculardynamics. J.Supercomput.ApplHighPerform.Comput. ,www.ks .uiuc.edu/Research/namd(accessedApril2023). Nesvizhevsky,V.V.,Borner,H.G.,Petukhov,A.K.,Abele,H.,Baessler,S.,Ruess,F.J.,Stoferle, T.,Westphal,A.,Gagarski,A.M.,Petrov,G.A.,andStrelkov,A.V.(2002)Quantumstatesof neutronsintheEarth‚Äôsgravitationalfield. Nature,415,297. Nicholson,C.(2022)Thesecretworldinthegapsbetweenbraincells. Phys.Today ,75,26. Nielsen,M.A.andChuang,I.L.(2010) QuantumComputationandQuantumInformation , CambridgeUniversityPress,CambridgeUK. NISTDigitalLibraryofMathematicalFunctions(2022)dlmf.nist.gov(accessedApril2023). Nolan,J.andNolan,C.(2015) Interstellar-TheWormholeScene ,www.youtube.com/watch? v=f3ptQ0CPMmU(accessedApril2023). NumericalPython(2023)numpy.org(accessedApril2023). Ott,E.(2002) ChaosinDynamicalSystems ,CambridgeUniversityPress,Cambridge. Otto,A.(2019) NumericalSimulationsofFluidsandPlasmas ,www.uaf.edu/physics/files/ Spring_2019/physics-629-syllabus.pdf (accessedApril2023). Palmer,K.M.(2016) TheNamelessMouseBehindtheLargest-EverNeuralNetwork ,Wired, March28,www.wired.com/2016/03/took-neuroscientists-ten-years-map-tiny-slice-brain (accessedApril2023).",3059
References,"ParticleDataGroup(2023) TheReviewofParticleProperties ,pdg.lbl.gov(accessedApril2023). Peitgen,H.-O.,J√ºrgens,H.,andSaupe,D.(1994) ChaosandFractals ,Springer,NewYork. Perlin,K.(2023)NYUMediaResearchLaboratory,mrl.nyu.edu/~perlin(accessedApril2023). Plischke,M.andBergersen,B.(1994) EquilibriumStatisticalPhysics ,2ndedn,WorldScientific Pub.Co.,Singapore. Polikar,R.(2023) TheWaveletTutorial ,users.rowan.edu/~polikar/WTtutorial.html(accessed April2023). Polycarpou,A.C.(2006) IntroductiontotheFiniteElementMethodinElectromagnetics ,Morgan &Claypool,SanRafael,CA. Potvin,J.(1993)Computationalquantum-fieldtheory. Comput.Phys. ,7,149. Pov-Ray,PersistenceofVisionRaytracer(2023)www.povray.org(accessedApril2023). Press,W.H.,Flannery,B.P.,Teukolsky,S.A.,andVetterling,W.T.(2007) NumericalRecipes , CambridgeUniversityPress,Cambridge. PythonIndexofPackages(2023)pypi.python.org/pypi(accessedApril2023). Qiskit(2023)Anopen-sourceSDKforworkingwithquantumcomputers,qiskit.org(accessed April2023). References 551 Ramasubramanian,K.andSriram,M.S.(2000)Acomparativestudyofcomputationof Lyapunovspectrawithdifferentalgorithms. PhysicaD,139,72. Rapaport,D.C.(1995) TheArtofMolecularDynamicsSimulation ,CambridgeUniversityPress, Cambridge. Rasband,S.N.(1990) ChaoticDynamicsofNonlinearSystems ,Wiley,NewYork. Reddy,J.N.(1993) AnIntroductiontotheFiniteElementMethod ,2ndedn,McGrawHill, NewYork. Refson,K.(2000)Moldy,ageneral-purposemoleculardynamicssimulationprogram. Comput. Phys.Commun. ,126,310. Reid,C.C.,Lee,W.-C.,andIngersoll,S.(2016) ResearchonLargestNetworkofCorticalNeurons Profiled,neurosciencenews.com/cortical-neural-network-3926(accessedApril2023). Reynolds,O.(1883)Anexperimentalinvestigationofthecircumstanceswhichdetermine whetherthemotionofwatershallbedirectorsinuous,andofthelawofresistancein parallelchannels. Proc.R.Soc.Lond. ,35,84. Richardson.L.F.(1961)Problemofcontiguity:Anappendixofstatisticsofdeadlyquarrels. Gen.Syst.Yearbook ,6,139. Rohrer,B.(2017) HowNeuralNetworksWork ,e2eml.school/how_neural_networks_work.html (accessedApril2023). Roman,T.A.(1994)Theinflatedwormhole:AMATHEMATICAanimation. Comput.Phys. , 8,480. Rosenblatt,F.(1958) NewNavyDeviceLearnsByDoing ,NewYorkTimes,8July1958;Preprint asamilitaryReport#1196-0-8. Rowe,A.C.H.andAbbott,P.C.(1995)Daubechieswaveletsandmathematica. Comput.Phys. , 9,635. Russell,J.S.(1844) Reportofthe14thMeetingoftheBritishAssociationfortheAdvancementof Science,JohnMurray,London. Sander,E.,Sander,L.M.,andZiff,R.M.(1994)Fractalsandfractalcorrelations. Comput.Phys. , 8,420. Satoh,A.(2011) IntroductiontoPracticeofMolecularSimulation ,Elsevier,Amsterdam. Scheck,F.(2010) Mechanics,fromNewton‚ÄôsLawstoDeterministicChaos ,5thedn,Springer, Berlin. Scott,A.C.(2007) TheNonlinearUniverse ,Springer-Verlag,Berlin,Heidelberg. Shannon,C.E.(1948)Amathematicaltheoryofcommunication. BellSyst.Tech.J. ,27,379. Shaw,C.T.(1992) UsingComputationalFluidDynamics ,PrenticeHall,EnglewoodCliffs,NJ. Shlens,J.(2003) ATutorialonPrincipalComponentsAnalysis ,www.cs.otago.ac.nz/cosc453/ student_tutorials/principal_components.pdf (accessedApril2023).",3081
References,"Shor‚ÄôsAlgorithm(2023)qiskit.org/textbook/ch-algorithms/shor.html(accessedApril2023). Sipper,M.(1997) EvolutionofParallelCellularMachines ,Springer-Verlag,Heidelberg. Smith,D.N.(1991) ConceptsofObject-OrientedProgramming ,McGraw-Hill,NewYork. Smith,S.W.(1999) TheScientistandEngineer‚ÄôsGuidetoDigitalSignalProcessing ,California TechnicalPublishing,SanDiego,CA. Smith,L.I.(2002) ATutorialonPrincipalComponentsAnalysis ,ourarchive.otago.ac.nz/handle/ 10523/7534(accessedApril2023) Stetz,A.,Carroll,J.,Chirapatpimol,N.,Dixit,M.,Igo,G.,Nasser,M.,Ortendahl,D.,and Perez-Mendez,V.(1973) DeterminationoftheAxialVectorFormFactorintheRadiativeDecay ofthePion,LBL1707. 552 References Stolze,J.andSuter,D.(2004) QuantumComputing,AshortCoursefromTheorytoExperiment, Wiley-VCHVerlagGmbH&Co,KGaA,Weinheim. Sullivan,D.(2000) ElectromagneticSimulationsUsingtheFDTDMethods ,IEEEPress, NewYork. Tabor,M.(1989) ChaosandIntegrabilityinNonlinearDynamics ,Wiley,NewYork. Taflove,A.andHagness,S.(2000) ComputationalElectrodynamics:TheFiniteDifferenceTime DomainMethod ,2ndedn,ArtechHouse,Boston,MA. Taghipour,R.,Akhlaghi,T.,andNikkar,A.(2014)Explicitsolutionofthelargeamplitude transversevibrationsofaflexiblestringunderconstanttension. LatinAmericanJournalof SolidsandStructures ,11,545‚Äì555. Tait,R.N.,T.SmyandM.J.Brett(1990) ThinSolidFilms ,187,375. TensorFlow2:LinearRegression(2020)techbrij.com/tensorflow-linear-regression-model (accessedApril2023). ThePythonTutorial(2023)docs.python.org/3/tutorial(accessedApril2023). ThePythonWiki(2023)wiki.python.org(accessedApril2023). ThijssenJ.M.(1999) ComputationalPhysics ,CambridgeUniversityPress,Cambridge. Thompson,W.J.(1992) ComputingforScientistsandEngineers ,Wiley,NewYork. Tickner,J.(2004)SimulatingnuclearparticletransportinstochasticmediausingPerlinnoise functions.Nucl.Instrum.MethodsPhys.Res.,Sect.B ,203,124. Vall√©e,O.(2000)Commentonaquantumbouncingball. Am.J.Phys. ,68,672. Vano,J.A.,Wildenberg,J.C.,Anderson,M.B.,Noel,J.K.,andSprott,J.C.(2006)Chaosin low-dimensionalLotka-Volterramodelsofcompetition. Nonlinearity ,19,2391‚Äì2404. Visscher,P.B.(1991)Afastexplicitalgorithmforthetime-dependentSchr√∂dingerequation. Comput.Phys. ,5,596. Vold,M.J.(1959)Anumericalapproachtotheproblemofsedimentvolume. J.Colloid.Sci. , 14,168. Volterra,V.(1926)Fluctuationsintheabundanceofaspeciesconsideredmathematically. Mem.R.Accad.Naz.deiLincei.Ser.VI ,2,558‚Äì560. Wang,Y.andKrstic,P.S.(2020)ProspectofusingGrover‚Äôssearchinthe noisy-intermediate-scalequantum-computerera, Phys.Rev.A ,102(4),042609. Ward,D.W.andNelson,K.A.(2004) FiniteDifferenceTimeDomain,FDTD,Simulationsof ElectromagneticWavePropagationusingaSpreadsheet ,arxiv.org/abs/physics/0402096 (accessedApril2023). Whineray,J.(1992)Anenergyrepresentationapproachtothequantumbouncer. Am.J.Phys. , 60,948. Wikipedia(2014)en.wikipedia.org/wiki/Principal_component_analysis(accessedApril2023). Wikipedia(2023) Shor‚Äôs_algorithm ,en.wikipedia.org/wiki/Shor percent27s_algorithm(accessed April2023). Williams,G.P.(1997) ChaosTheoryTamed ,JosephHenryPress,Washington,DC. Witten,T.A.andSander,L.M.(1981)Diffusion-limitedaggregation,akineticcritical phenomenon. Phys.Rev.Lett. ,47,1400;(1983) Phys.Rev.,B2 7,5686. Wolf,A.,Swift,J.B.,Swinney,H.L.,andVastano,J.A.(1985)DeterminingLyapunovexponents fromatimeseries. PhysicaD 16,285. Wolfram,S.(1983)Statisticalmechanicsofcellularautomata. Rev.Mod.Phys. ,55,601. Yalcin,O.G.(2021) AppliedNeuralNetworkswithTensorFlow2 ,Apress,Berkeley,CA. References 553 Yang,C.N.(1952)Thespontaneousmagnetizationofatwo-dimensionalIsingmodel. Phys. Rev.,85,809. Yee,K.(1966)NumericalsolutionofinitialboundaryvalueproblemsinvolvingMaxwell‚Äôs equationsinisotropicmedia. IEEETrans.AntennasPropag. ,AP-14,302. Yue,K.,Fiebig,K.M.,Thomas,P.D.,Chan,H.S.,Shakhnovich,E.I.,andDill,A.(1995)Atestof latticeproteinfoldingalgorithms. Proc.Natl.Acad.Sci.U.S.A. ,92,325. Zabusky,N.J.andKruskal,M.D.(1965)Interactionof\""solitons\""inacollisionlessplasmaand therecurrenceofinitialstates. Phys.Rev.Lett. ,15,240. Zhou,M.(2018) ToyNeuralNetworkClassifiesOrientationofLine ,medium.com/colaberry- labs/toy-neural-network-classifies-orientation-of-line-acf143b89c22(accessedApril2023). Zhou,V.(2022) MachineLearningforBeginners ,towardsdatascience.com/machine-learning- for-beginners-an-introduction-to-neural-networks-d49f22d238f9(accessedApril2023).",4323
Index,"555 Index a Accuracy 13,53,54,66,90,93,97,117,170, 176,178,228,230,245,284,416,445, 451,506,535 Actionpotential 227 Activationfunction 230,236,246 Adams-Bashful-Moulton 156 Adder full 271‚Äì272,276‚Äì277 half 263,271‚Äì272,277 Advection 504‚Äì505,508,518,521,522 AIseeArtificialintelligence(AI) Airyfunctions 385,386 Algorithm 3,4,9,25,45,50,51,53,55, 79‚Äì81,84‚Äì89,153‚Äì158,280‚Äì283, 289‚Äì290,295‚Äì298,316‚Äì317,325‚Äì326, 370‚Äì374,398‚Äì402,445‚Äì448,456‚Äì463, 468‚Äì470,484‚Äì487,496‚Äì497,506‚Äì507, 510,525 Alias 175‚Äì179,185 AnaConda 7,8,237,266,274 Analogfilters 183 Animations 7,30,31‚Äì32,38,42‚Äì43,248, 362,396,399,400,459,484,485,496, 509,511,517,545‚Äì547 Antiferromagnet 368 Architecture 17,128 Arrays see alsoMatrices;Python vertical 240 Artificialintelligence(AI) 226,249 generative 226 neuron seeNeurons Asymptotes 335 Attractors 334,335,359predictable 355 strange 355 Autocorrelationfunction 180‚Äì183 Axon seeNeurons b Backtracking 105‚Äì106,127 Backwardpass 241 Ballisticdeposition 314‚Äì315,319,320,323, 327 correlated 320 Basicmachinelanguage 9,10 Beating 148,161,356,357,471 Bellstates 260,265,273,277 Besselfunctions 50,56‚Äì59,154 Bias 14‚Äì16,228,229,232,246 Bifurcation 334,335,338,340,359,361 diagram 336 dimensionof 322 Billiards 361‚Äì363,489 quantum 488‚Äì489 Binarynumbers seeNumbers,binary Binarypoint 14 Binning 337 Bisectionalgorithm 102,103,105,107,121, 297‚Äì298 Bits 11,257 quantum seeQubits reversal 189‚Äì191 Blackholes 410,413,414,421 Blochsphere 258,264 Boltzmanndistribution 106,369,370,374 Boolean 19‚Äì21,260 Computational Physics: Problem Solving with Python ,Fourth RubinH.Landau,ManuelJ.P√°ez,andCristianC.Bordeianu. ¬©2024WILEY-VCHGmbH.Published2024byWILEY-VCH 556 Index Boundstates 101‚Äì103,293‚Äì298,301, 305‚Äì308,363,378‚Äì379,427‚Äì431,435, 489 Boundaryconditions 112,151,294,295,371, 373,375,384‚Äì386,397,408‚Äì409,436, 441‚Äì444,448‚Äì450,455‚Äì456,458,461, 467‚Äì470,477‚Äì478,494,497,507,515, 517,522‚Äì523,525,528‚Äì531,533,538 Boxcounting 84‚Äì85,316‚Äì319,321 Bra 256‚Äì257,258 Bra-ket 256 Breakcommand 451 Burgers‚Äôequation 505,507 Butterflyoperation 188,189,191 Byte 11,12,30,129,143,247 Bytecode 11 c Cacheprogramming 129 Canonicalensemble 369,393,394 Capacitors 449,451 Catenary 473‚Äì475,481 Cauchyprincipalvalue 433 Cellularautomata 322,323 Centraldifferencealgorithm 80‚Äì81 Chaos 338,340,350,353,357,359,360,487, 489 Fourieranalysisof 359 ofpendulum 350‚Äì353 phasespace 353,354,358 Chi-squaredmeasure 115,116 Christoffelsymbols 411‚Äì413 Cirq 266,267,276 definition 266 install 266‚Äì267 XandHgates 267‚Äì268 Clanguage 6,9,10,17‚Äì19,130,135,142 Clustering 63,240,242‚Äì246 Codes,tablesof 4‚Äì6,31,32,38,144,157, 272,393,459,545‚Äì547 Column-majororder 129 Command-lineinterpreter 10 Commandshell 237,266 Compilers 10,18 Complexnumbers 6,17,19,20,30,134,176, 187‚Äì189,191,192,258,259Compression 195 lossless 199 PCA 216 wavelets 195 Computational physics 3‚Äì4 science 3‚Äì4 thinking 4 Computerlanguages 6,10,13,21,26,130 Controlstructures 18,20‚Äì21 Convolution 181,183,184,202,206,207, 209 Conway‚ÄôsGameofLife 322 Correlations 180,181,319,323 auto 180 coefficient 117 growth 319‚Äì320 PCA 215‚Äì221 Cosmologicalconstant 410,413,418 Cost seeLoss Courantstabilitycondition 493,494,506 see alsovonNeumann Covariance 117,217‚Äì221 Covectorspace 257 Crank‚ÄìNicolsonmethod 460‚Äì463 Cubicsplines 110‚Äì113,121 see alsoSplines Curietemperature 107,367,368,370,374 Curvaturetensor 411,413 Curvefitting seeData,fitting d Data compression 195 fitting 101‚Äì123 types 13 Dataflowgraphs 236 Decay exponential 71,113‚Äì114 simulation 71‚Äì72 spontaneous 113 Deeplearning 226,229,246,249 see alsoMachine,learning Deepnet seeMachine,learning Densitymatrix 260,275 Densityofstates 369,374,375 Index 557 Deposition 314 ballistic 314‚Äì315 Derivatives 79‚Äì83,150 centraldifference 379 forwarddifference 153 second 112,152,296,297,398 DFT seeDiscreteFouriertransform(DFT) Differentialequations 148‚Äì165,293,303 algorithms 153‚Äì158 boundaryconditions 151 dynamicalform 151‚Äì153 Euler‚Äôsrule 153 initialconditions 151,153 order 150,151 partial 150‚Äì151,441 see alsoPDE‚Äôs Runge-Kuttaalgorithm 154 types 150,441 Differentiation 79‚Äì100,153,372,403,446, 497 Diffuseralgorithm 282 Diffusion-limitedaggregation 320 Dimension array 129 fractional 309,311,316 Hausdorf-Besicovitch 309 physical 129 schemes 131 Diracnotation 256‚Äì257,274 QCversion 274 Directproduct 134,218,257‚Äì261,266, 279‚Äì281 DiscreteFouriertransform(DFT) 4,169, 174‚Äì180,183,192,212,277,278 Dispersion 216,503,504,507‚Äì509,512‚Äì514 relation 503,504,508 Double(s) 14‚Äì17,29,88,156 pendulum 360,361 precision 14,29 Drag 301‚Äì302 see alsoFriction Drivingforce 149,161,351,355,357,359, 360,365,515 Dualadjointspace 257 Duffingoscillator 365e Edges 235,236,379,397,449,450,488,489, 516,517 Eigenvalues 128,137‚Äì139,141,219‚Äì221, 262,284,286,293‚Äì308,429‚Äì431,478, 482 Einstein 30,68,410‚Äì416,420 fieldequations 410‚Äì414 Electrostaticpotential seeLaplace‚Äôsequation Ellipticintegrals 351‚Äì352,370 Ellismetric 411 Entangledstates 259‚Äì262,265,277,286 Entropy 338,340,347,374,376 Equations 509 Burgers‚Äô 505 differential 148‚Äì165,293 discrete 70,332 heat 454‚Äì455 integral 427‚Äì438 see alsoIntegral equations Korteweg-deVries 508 Laplace‚Äôs 441,452,534,540 Lippmann-Schwinger 431‚Äì432 motion 302,303 Navier-Stokes 504,520‚Äì522,527 Poisson‚Äôs 441,443,447,533 Schr√∂dinger 482‚Äì483 Sine-Gordon 514‚Äì517 telegraph 497 VanderPool 365 wave 466 Errors 45,56‚Äì58,82,83 algorithmic 46,50,87 approximation50 see alsoErrors, algorithmic empirical 50 integration 88,94 minimum 52 multiplicative 49 N-Dintegration 95‚Äì97 random 46 roundoff 46,48‚Äì57,61,85,88,95,96,153, 154,510 total 50,51 types 45‚Äì50 Euler‚Äôsrule 153‚Äì155,379 558 Index Eventhorizons 413‚Äì414 Exchangeenergy 368,371 Executivesystem 10 Exponentialdecay 69‚Äì72,94,113‚Äì115 Extrapolateddifference 81‚Äì84 f Factoringalgorithm 283‚Äì285 FastFouriertransform 169,176,187‚Äì194 Feigenbaumconstants 337‚Äì338 Ferromagnet 367‚Äì368,371,373 Feynman pathintegrals 376‚Äì386 postulates 376 propagator 376 FFTseeFastFouriertransform Filters 181,184 analog 183 digital 185,211 sinc 186 windowed 185 Finite differenceequation 70 differencetimedomain 491‚Äì494 differences 70,446,484,524,528 elements 533‚Äì540 2Delements 539‚Äì540 Fitting best 108 global 115 goodness 116 least-squares 114‚Äì119 linearleastsquare 116,119 local 115 Newton-Raphson 120 nonlinear 119‚Äì120 Fixed-pointnumbers 12 Fixedpointsinmaps 334,355 Floating-pointnumbers 12‚Äì17,28,33,46, 132,145,337 Floats seeFloating-pointnumbers FLOPS 158 Fluiddynamics 504‚Äì505,520‚Äì526,528, 530 Fortran 6,9‚Äì10,129,142 Forwarddifference seeDerivativesFourier analysis 169 autocorrelationrelation 183 componentsinchaos 360 decompositon 170 discretetransform 174‚Äì176 see also DiscreteFouriertransform(DFT) fasttransform 187‚Äì191 see alsoFast Fouriertransform integral 172‚Äì173 quantumtransform 277‚Äì280 sawtooth 171‚Äì172 series 169‚Äì172 seriesasalgorithm 445 short-timetransform 200 theorem 170 transform 169,172‚Äì173 Fractals 309‚Äì330 coastline 315‚Äì319 dimension 309 see alsoDimension plants 312‚Äì313 Pollockpainting 321‚Äì322 trees 314 Friction 159,160,355,357,520,528 inoscillations 160 inpendulum 350‚Äì353,355 inprojectilemotion 301‚Äì302 inwaves 471‚Äì472 Functionalintegration 380 see alsoPath integration g Galerkindecomposition 535‚Äì536 GameofLife 322,323,328 Garbage 45,46,57 Gates AND,NAND,NOT,NOR,XOR,OR,state, U,Pauli,NOTX,Y ,Z,R œï,S,T 262‚Äì264 controlledNOT,CNOT 265 controlledZ,CZ 265 HadamardH 263,267 logic 260,262 measurement 264 2qubit 264 3qubit 266 Index 559 SWAP 264 Toffoli,CCNOT 266,270 Gaussian distribution 72‚Äì74 elimination 434 quadrature 90‚Äì92 quadraturederivation 91‚Äì92 Gauss-Seidelmethod 448 Generalrelativity 410‚Äì426 Geodesic 411‚Äì415,418 Geodesicequation 411,412,414,415,418 Gibbsovershoot 172,186,445 Gradienttape 241 Gravitational constant 410 curvature 410 lensing 415‚Äì416 Green‚Äôsfunction 376,378,379‚Äì382 Gridpoints 324,325,430,431,435,493,507, 510,516,524 Grover‚Äôssearchalgorithm 280‚Äì283 Growthmodels 309‚Äì330,332 h Half-wavefunction 171‚Äì172,203 Hamilton‚Äôsprinciple 376‚Äì378,380 Harmonics 170,173,179 Heatbath 394,442,460 Heatequation 38,454‚Äì456,458‚Äì460,463, 464,468‚Äì470 Hiddenlayer 230,234‚Äì236 Hilbertspace 256,258,259,261,263,280 Hilberttransform 433 Huygens‚Äôsprinciple 376 Hydrogenhyperfinestructure 140 i IBMQuantumComputer 256,266,272‚Äì275, 283 IEEEfloating-point 12‚Äì15 Imageprocessing 195,246‚Äì248,323 Importancesampling 97‚Äì98 see alsovon Neumann Initialconditions 151,153‚Äì154,157‚Äì158, 301,303‚Äì304,335,343‚Äì344,346, 354‚Äì359,362,373,387,402‚Äì403,415,417‚Äì418,442,456,458,461,464, 466‚Äì471,475‚Äì477,489‚Äì490,493‚Äì497, 509‚Äì511,517‚Äì519 Integralequations 427‚Äì438,536 Integration 79‚Äì100 error 87‚Äì89,94‚Äì95 Gaussianquadrature 90‚Äì92 mappingpoints 91 meanvalue 95‚Äì97 MonteCarlo 92‚Äì96 multi-dimensional 96 rejectiontechniquesfor 92 scaling 91 Simpson‚Äôsrule 86‚Äì87,89 splines 112 trapezoidrule 85‚Äì86,89 variancereduction 97 vonNeumannrejection 98 Integro-differentialequation 427 Intermittency 335 Interpolation Lagrange 109,110 splines 111 Interpreter 17 Inversematrix 128,136,137,212 Isingmodel 367‚Äì371,373‚Äì375,382 2D 370,374 j Jacobimethod 448 Jupyternotebook 7,31,237,238,274, 425‚Äì426 k Kerasdeeplearning 246,254‚Äì255 Kernel 10,186 Kerrmetric 413‚Äì414 see alsoMetric Ket 256,260,263‚Äì264 Kmeans 243,244,251,253 Korteweg-deVriesequation 503,505 see alsoEquations l Lagrangeinterpolation 109‚Äì111,113 Lagtime 180,184,358 560 Index Languages BASIC 10 compiled 10‚Äì11,17 computer 9 high-level 9 interpreted 11 Python 6‚Äì8 Laplace‚Äôsequation 441,443‚Äì447,449,452, 455,456,460,525,527,534,535, 540‚Äì542 Latticecomputations 368,379‚Äì383,384 Latticepoints seeGridpoints Lax-Wendroffalgorithm 506‚Äì507 Leapfrogalgorithm seeTimestepping Learningrate 234,244,245 Least-squaresfitting 101,108,114‚Äì119 Lengthofcoastline 315‚Äì319 Lifetime 71,113‚Äì115,420 Lightdeflection 414‚Äì416 Limitcycles 342,344‚Äì346,355,358,365 Linear algebra 117‚Äì119,128,135 congruentmethod 62 least-squarefitting 116 regression 116 superposition 151 Linux 7,10 Lippmann-Schwingerequation 431‚Äì432, 435 Loadmodule 10 Logicgates 262‚Äì266, see alsoGates Logisticmap 331‚Äì336,338‚Äì341,344,346, 347,359 Loss 230‚Äì232,241 Lotka-Volterramodel 341‚Äì345 Lyapunovcoefficients 338‚Äì340,347 m Machine learning 226 learningdata 249 numbers 13,46 precision 29‚Äì30 Magneticmaterials 106,368 Mantissa 12,14‚Äì16,28,29,46,52Matplotlib 7,30‚Äì42,245,268,424, 541 Matrices 124,127,133,140,145 column-majororder 129 computing 124‚Äì147 equations 431 inversion 127,128,434 Pauli 141,260 subroutinelibraries 138 tri-diagonal 462 Maxwell‚ÄôsEquations 460,490‚Äì492,499‚Äì501 McCulloch-Pittsneuron 228 Meanvaluetheorem 95 Memory architecture 128 pages 129 Metric Ellis 411,421 Kerr 413 Schwarzschild 412‚Äì414,418 tensor 410,411 Metropolisalgorithm 98,367,370‚Äì374,378, 382‚Äì384,387 Microcanonicalensemble 369,393 Miller‚Äôsdevice 58 MLseeMachine,learning Modelocking 161,355,356 Moleculardynamics(MD) 393‚Äì409 Momentumspace 427‚Äì436 MonteCarlo errorin 96 integration 92‚Äì95 simulations 60‚Äì78,319,367,370,382, 394,396 techniques 60,68 Multiresolutionanalysis 206,207 n NAN 17 Navier-Stokesequation 504,520‚Äì522, 525‚Äì529 Neuralnet 228,230,234 Neuralnetwork 226‚Äì255 see alsoNeuralnet Neurons 66,67,226‚Äì230,235,236,246 codeforAI 229 Newton-Cotesmethod 85 Index 561 Newton-Raphsonsearch 103‚Äì106,120 algorithm 103,298 withbacktracking 105 Nodes 111,112,180,228,230,234‚Äì236,294, 298,446,456,494,534‚Äì536,538, 540 Noise 323 Perlin 323 reduction 180‚Äì182 Nonlinear dynamics 331,334,350 limitcycles 355 maps 333,338 ODE 150 oscillations 148‚Äì165 see alsoOscillations Nonlocalpotentials 427,431 Nonstationarysignals 195,203 Normal modeexpansions 467‚Äì468 numbers 14 Notebook seeJupiter Numbers base 12 binary 11 complex 134 fixed-point 12 floating-point 12‚Äì15 hexadecimal 11 IEEE 14 machine 13 normal 14 octal 11 rangesof 11 representationof 11‚Äì17 subnormal 14 uniform 72 Numericalprecision 430 Numerovmethod 296,305 NumPy 131 optimization 142 Nyquistcriterion 177‚Äì179 Nyquist-Shannoninterpolation 186 o Objectscode 10,31,160 Octalnumbers 11ODE‚Äôs 150‚Äì151,153‚Äì158,293‚Äì308 secondorder 300 Onecyclepopulation 334 OpenCV 246‚Äì248 Operatingsystem 10,129 Optimization 90,245 Oraclealgorithm 280‚Äì283 Orbits seePlanetary Oscillations anharmonic 149,158,170 damped 160 doublependulum 361 driven 161 duetoerrors 108,445 electromagnetic 491 fromerrors 110 Fourieranalysisof 169‚Äì172 harmonic 157,158,170 isochronous 157,158 nonlinear 148‚Äì150,157‚Äì160,161,169 inphasespace 354 populations 334,344 quantum 378,382 Outputlayer 229 Overflows 12,13,17,28,53,62,79,300,395, 445 Overrelaxation seeRelaxation p Paddingofsignal 178 Paging seeMemory Panda 7,244,253 Partialdifferentialequations seePDE‚Äôs Pathintegration 379‚Äì386,391 Paulimatrices 141,260 PDE‚Äôs 150,441‚Äì454,466,533 elliptic 443 explicitsolution 484 hyperbolic 466‚Äì467 implicitsolution 484 parabolic 441,454‚Äì456 types 441 weakformof 534‚Äì535 Pendulum 359,361 analyticsolution 351‚Äì352 bifurcationdiagram 359 562 Index Pendulum ( contd.) chaotic 350‚Äì353,356,359 coupled 512 double 360‚Äì361 Perceptrons 228,229,244,245,251 Perioddoubling 334 see alsoBifurcation Periodicboundaryconditions 371,373,375, 397,408,493,494 Perlinnoise 323‚Äì326 Phantombit 14,15 Phaseestimationalgorithm 284,285 Phasespace 301,338,342‚Äì345,350, 353‚Äì361,363‚Äì365,511‚Äì512 Phasetransition 345,346,367‚Äì369,374,528 pip 240,267,528 Pixels 235,247,337 Planetaryorbits 303‚Äì305,416‚Äì420 Poisson‚Äôsequation 443,446‚Äì449,527,533 Populationdynamics 331‚Äì349 Populationextinction 335 Potentials deltashell 430‚Äì431 Lennard-Jones 395 momentumspace 430 nonlocal 427,431 Pov-Ray 325,326,329 Power PCAcomponent 216 residuemethod 61 spectrum 173,182,360 PowerShell 8,237,266 Precession 303,418‚Äì420 Precision 45 empirical 50 machine 29‚Äì30 testsof 159 Predator-preymodels 340‚Äì346 Predictor-correctormethods 156,164 Principal componentsanalysis 215‚Äì221 value 433 valueintegrals 433 Problemsolvingparadigm 3 Programming 10,18,27 design 26‚Äì27 quantum 256‚Äì257reproducible 26 structured 26 Projectilemotion 26,27,160,301‚Äì303,308 Propagator 376,377,380,381 Proteinfolding 68‚Äì69 Pseudocode 26‚Äì28,30,54,71 Pseudorandom seeRandom,numbers Pulsons 515 Pyramidscheme 207‚Äì211,213 Python 129 algebraictools 24‚Äì25 arrays 21‚Äì23,137 Canopydistribution 6 distributions 6 I/O 23‚Äì24 language 6 libraries 6 linearalgebra 135‚Äì137 lists 21‚Äì23 packages 6 references 6 Visualpackage 31 q QCsee alsoQuantum,computing simulator 275 QFT 278‚Äì280,284,286 see alsoQuantum, FourierTransform(QFT) Qiskit 274‚Äì282 Quadrature seeIntegration Quantum 101 bitsseeQubits bouncer 385‚Äì386 computing 256‚Äì290 computingoperators 257 Fouriertransform(QFT) 277‚Äì280 mechanics 293 scattering 431‚Äì436 simulator 274 wavepackets 482‚Äì502 QuantumComposer 272‚Äì274,277 Qubits 256‚Äì260,263‚Äì271,273‚Äì284,286‚Äì290 r Radioactivedecay 60,61,69,71,72,321 Radix 12 Index 563 RAM 129 Random 60‚Äì64 brainwalks 66‚Äì68 generators 61‚Äì63 linearcongruent 61 nonuniform 96 numbers 49,60,61,74,313 pseudo 61 self-avoidingwalk 68 sequences 60,61,63‚Äì64 testsof 72‚Äì74 walks 64‚Äì69,320 Raytracing 325‚Äì326,329 Recursion 50,56‚Äì59,154 Registers 29,273,284,285 Regression 116,239,240,246 Rejectiontechniques 97‚Äì98,370 Relaxation 441‚Äì453,456,460,469,524,525, 528,529,531 Resonances 110,119‚Äì120,148,160‚Äì162, 356,357,435 nonlinear 160‚Äì162 Reynoldsnumber 528,529,531 Riccicurvaturetensor 411,413 Riemanntensor 412,413 rkalgorithm 156,165 rk4 154,156‚Äì158,162,295‚Äì298,300‚Äì302, 304,306,352,398,442 Rombergextrapolation 89 Rootmeansquare 64,65,400 Roundofferrors see alsoErrors roundoff 46‚Äì47 Row-majororder 129 Runge-Kutta 154‚Äì157,296 s Sampling 93,95‚Äì98,174,176‚Äì179,187,207, 210,214,361,369,370,374‚Äì376 importance 97‚Äì98 Sawtoothfunction 169,171,172 Scalarcurvature 411 Scattering 108,110,293‚Äì308,362‚Äì363,427, 431‚Äì438,488‚Äì490,498‚Äì499 quantumchaos 487‚Äì490Schr√∂dingerequation 150,293,294,296, 297,305,306,382,385,427‚Äì431,435, 460,482‚Äì484,486,487,491,498 timedependent 482‚Äì483 Schwarzschildmetric 412‚Äì414,416,418 Scikit-learn 240‚Äì242 Searching 101‚Äì127,296,344 see alsoTrial anderror Secularequation 128 Seeds 61‚Äì63,65,74,245,320,321,333,335, 373,384 Self affineconnection 312‚Äì313 affinity 312‚Äì314 limiting 365 similar 311,312,337 Separablestates 259‚Äì262 Separatrix 159,352,354,358,512,515 Seriessummation 47,55,172 Shannonentropy 338,340,347 Shells 9,10,309 Shockwaves 457,466,504‚Äì507 Shor‚Äôsalgorithm 282‚Äì285,289 Sierpi¬¥ nskigasket 310‚Äì312,323 Sigmoidfunction 228‚Äì230,232,233 Signalprocessing 185 Signbit 12,15,17 Significantfigures/parts 12,46,48,93,107, 539 Simpson‚Äôsrule 86‚Äì90,94,95 Simulation 4,24,30,49,60‚Äì78,160,161, 228,257,268,301,314‚Äì316,319,323, 331,335,354,356,361,367‚Äì392, 393‚Äì532 Sincfilter 177,185‚Äì187 Sine-Gordonequation 503,514‚Äì517 Singleprecision 13,15‚Äì17,28,29,88,94 Singularintegrals 427,432‚Äì433 SkLearn 237‚Äì242,244,251 Solitons 331,503,504,508‚Äì515,518,520 crossing 511‚Äì512 KdeV 509 ring 517 Sine-Gordon 515 waterwave 508 Specularreflection 55‚Äì56,362 564 Index Spinstates 140‚Äì142,256,369 Splines 111 cubic 110‚Äì113 natural 112 Spontaneousdecay 60,69‚Äì72,78,113,114 Stablestates 335 Statisticalmechanics 323,340,369‚Äì370, 373,393,396 Stochasticgradientdescent 234,245‚Äì246, 253 Stochasticprocesses 69,113 Strangeattractors 355 Stress-energytensor 411 Stride 129,130,142‚Äì145 Subnormalnumbers 14,15 Subroutines 85,90,108,110,114,128,129, 138,363,434,435 libraries/packages 128,135 Subscripts see alsoDimension schemes 129 Subtractivecancellation 47‚Äì48,54,57,58, 79,80,82,113,117,153,432 Successiveover-relaxation seeRelaxation Supervisedlearning 242,245 t TensorFlow 236‚Äì239,242,246,252 Tensorproduct 258,412‚Äì413 Texturingimages 326,329 Thermodynamics 340,367‚Äì392,394,396 Three-bodyproblem 303,363,487,489 Timedelay 64,301,490 Timestepping 454,456‚Äì459,462,468‚Äì470, 485,490,492 Top-downprogramming 27 TrainingAI 226,230,231 Transients 161,169,333,335‚Äì337,357,359, 360,364,365 Transpile 275 Trapezoidrule 85‚Äì86,88,89,94,95,98,175 Trialanderror 31,101‚Äì124,230,295,386, 448,451 Trivialsolutions 128,429 Twocycle 334 Two‚Äôscomplement 12,29u Uedaoscillator 365 Uncertaintyprinciple 197‚Äì199,205,206 Underflows 13,17,28‚Äì29 Uniform distribution 61‚Äì63,72‚Äì74,90 sequences 62,72 testsof 72‚Äì74 Unix 10 v VanderPoolequation 365 Variance 97,117,216‚Äì220,245,370 reduction 97,370 Vectors 33,36,137‚Äì138,152,199,215‚Äì220, 256‚Äì257,259‚Äì260,266,278,280, 324‚Äì325,412,434,530 Velocity-Verletalgorithm 398‚Äì400,402 Verletalgorithm 398‚Äì402 Verticalarrays 240 Virtualmemory 129 Viscosity 472,520‚Äì523,528 Visualization 6,7,9,24,26,30‚Äì38,69,72, 172,237,268,274,275,337,369,410, 420,421,450‚Äì452,457‚Äì459,483,506, 530 ofvectors 452 Volumerendering 30 vonNeumann rejection 97‚Äì98,370 stabilityassessment 400,451,457‚Äì459, 462,463,469‚Äì471,492,493 Vorticity 525‚Äì529,530 VPython 7,30‚Äì32,38,39,362,425 w Wang-LandauSampling(WLS) 369, 374‚Äì376 Wave oncatenary 473‚Äì475 electromagnetic 495 equation 466‚Äì468,472,475 functions 378,383,431,434 packets 172,466,482,486 shallowwater 509 Index 565 onstring 466‚Äì481 telegraph 497 Wavelets 195,196,222 basis 200‚Äì203 continuous 203‚Äì204 Daubechies 211‚Äì214 discretetransform 205‚Äì214 multiresolutionanalysis 206pyramidscheme 207‚Äì211 transform 200‚Äì204 WeakformofPDE 534‚Äì535 Windows 8,10,72,196,237,266,274, 337 Wordlength 11,79 Workingregisters 29 Wormholes 410,420‚Äì422,425",18939
EULA,WILEY END USER LICENSE AGREEMENT Go to www.wiley.com/go/eula to access Wiley‚Äôs ebook EULA.,90

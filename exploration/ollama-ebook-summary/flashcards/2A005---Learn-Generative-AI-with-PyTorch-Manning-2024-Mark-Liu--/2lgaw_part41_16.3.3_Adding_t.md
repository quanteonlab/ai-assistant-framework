# Flashcards: 2A005---Learn-Generative-AI-with-PyTorch-Manning-2024-Mark-Liu--_processed (Part 41)

**Starting Chapter:** 16.3.3 Adding tools by using OpenAI GPTs

---

#### Adding Tools Using OpenAI GPTs
Background context: This section introduces how to use tools from the LangChain library, specifically focusing on adding a text summarizer tool. The goal is to enhance an agent's capabilities by integrating different functions provided by the GPT models.

The process involves defining templates for tasks and creating functions that can be used as tools within the agent framework. These tools are then added to the agent’s toolbox, allowing it to utilize them during task execution.

:p How do you add a text summarizer tool to an agent's toolbox in LangChain?
??x
To add a text summarizer tool, follow these steps:
1. Import necessary classes from `langchain.agents` and define a template for the task.
2. Create a function that uses this template with the LLM (Language Model) to generate summaries.
3. Convert this function into a tool using `Tool.from_function`.
4. Add this tool to the agent’s toolbox and redefine the agent.

Example code:
```python
from langchain.agents import Tool
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Define a template for text summarization
temp = PromptTemplate(
    input_variables=["text"],
    template="Write a one sentence summary of the following text: {text}"
)

# Create a summarizer function using the LLM and the defined template
summarizer = LLMChain(llm=llm, prompt=temp)

# Convert the summarizer function into a tool
sum_tool = Tool.from_function(
    func=summarizer.run,
    name="Text Summarizer",
    description="A tool for summarizing texts"
)

# Add this tool to the agent's toolbox and redefine the agent
tools += [sum_tool]
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    handle_parsing_errors=True,
    verbose=True
)

res = agent_executor.invoke({
    "input": '''Write a one sentence summary of the following text: The University of Kentucky's Master of Science  in Finance (MSF) degree prepares students for  a professional career in the finance and banking  industries. The program is designed to provide  rigorous and focused training in finance, broaden opportunities in your career, and sharpened skills for the fast-changing   and competitive world of modern finance.'''
})

print(res["output"])
```
x??

---
#### Adding a Joke Telling Tool
Background context: This section demonstrates adding another tool to an agent’s toolbox—specifically, a joke-telling tool. The process is similar to adding a text summarizer but involves defining a different template and function for generating jokes.

:p How do you add a joke telling tool to an agent's toolbox?
??x
To add a joke telling tool, follow these steps:
1. Define a template that takes the subject of the joke as input.
2. Create a function that uses this template with the LLM to generate jokes based on the given subject.
3. Convert this function into a tool using `Tool.from_function`.
4. Add this tool to the agent’s toolbox and redefine the agent.

Example code:
```python
from langchain.agents import Tool
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# Define a template for telling jokes
temp = PromptTemplate(
    input_variables=["text"],
    template="Tell a joke on the following subject: {subject}"
)

# Create a joke function using the LLM and the defined template
joke_teller = LLMChain(llm=llm, prompt=temp)

# Convert the joke function into a tool
tools += [Tool.from_function(
    name='Joke Teller',
    func=joke_teller.run,
    description='A tool for telling jokes'
)]

# Redefine the agent with the updated toolbox and use it to tell a joke about coding
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    handle_parsing_errors=True,
    verbose=True
)

res = agent_executor.invoke({
    "input": '''Tell a joke on the following subject: coding'''
})

print(res["output"])
```
x??

---
#### Summarizing Text Using LangChain
Background context: This example demonstrates how to utilize the `langchain` library for creating tools that can be used by an AI agent. Specifically, it shows how to integrate a text summarization tool into an agent’s toolbox.

The process involves defining a template and function for generating summaries, converting this function into a tool, adding it to the agent's toolbox, and then using the tool within the agent execution framework.

:p What is the output when you ask the agent to summarize a given text?
??x
When you ask the agent to summarize a given text, the output will be a one-sentence summary generated by the LLM. For example, if the input text is:
```
The University of Kentucky's Master of Science  in Finance (MSF) degree prepares students for  a professional career in the finance and banking  industries. The program is designed to provide  rigorous and focused training in finance, broaden opportunities in your career, and sharpened skills for the fast-changing   and competitive world of modern finance.
```
The output might be:
```
The University of Kentucky's MSF program offers specialized training in finance to prepare students for successful careers in the finance and banking industries.
```

This summary is generated by the LLM based on the input text provided.

x??

---
#### Joke Generation Using LangChain
Background context: This example shows how to integrate a joke generation tool into an agent’s toolbox. The process involves defining a template, creating a function for generating jokes, and adding this function as a tool in the agent's toolbox.

:p What is the output when you ask the agent to tell a joke on coding?
??x
When you ask the agent to tell a joke on coding, the output will be a relevant joke generated by the LLM. For example:
```
Why was the JavaScript developer sad? Because he didn't know how to "null" his feelings.
```

This joke is generated based on the input subject provided ("coding") and is part of the agent's capability to entertain or engage users with humor.

x??

---

#### Adding a Sentiment Classifier Tool to the Agent's Toolbox
Background context: The task involves adding a tool for sentiment analysis to the agent’s toolbox. This is achieved by defining a new function and integrating it into the existing workflow. Sentiment analysis helps classify texts into categories like positive, negative, or neutral based on their tone and content.

:p How can we add a sentiment classifier tool to an agent's toolbox in LangChain?
??x
To add a sentiment classifier tool, you need to define a new function named `SentimentClassifier` that performs the classification. You then integrate this into your existing tools list. Here’s how it can be done:

1. Define the function: 
```python
def sentiment_classifier(text):
    # Assume this is an existing or custom model for sentiment analysis
    result = analyze_sentiment(text)
    return result['sentiment']
```

2. Add the tool to the agent's toolbox:
```python
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool

# Assume `llm` is an existing language model and `prompt` is a prompt template
tools = [Tool.from_function(func=sentiment_classifier, name='Sentiment Classifier', description='A tool to classify text sentiment.')]

agent = create_react_agent(llm=llm, tools=tools, prompt=prompt)
agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, verbose=True)

# Invoke the agent with a sample text
res = agent_executor.invoke({"input": "this movie is so-so"})
print(res['output'])
```

The output will provide sentiment classification based on the input text.
x??

---

#### Classifying Text Sentiment Using the Agent Executor
Background context: After adding the `Sentiment Classifier` tool, we can use the agent executor to classify a given piece of text. The task is straightforward and involves invoking the agent with the specific text for classification.

:p What is the result when classifying the text "this movie is so-so" using the sentiment classifier?
??x
The text "this movie is so-so" will be classified based on its sentiment. Assuming the `analyze_sentiment` function returns a neutral sentiment (since "so-so" suggests neither strong positive nor negative feelings), the output might look like:

```
{
    'sentiment': 'neutral'
}
```

This indicates that the text is classified as neutral.
x??

---

#### Adding Code Generation Tools to the Agent's Toolbox
Background context: The task involves adding tools for generating code and images. These tools are essential for expanding the agent's capabilities to handle various types of content generation tasks. Here, we focus on adding a tool for generating Python code.

:p How can you add a code generator tool to an agent's toolbox in LangChain?
??x
To add a code generator tool, follow these steps:

1. Define a `PromptTemplate` to describe the task.
2. Create an `LLMChain` object that will generate the code based on the template.
3. Add this new tool to your existing tools list.

Here’s how it can be done:
```python
from langchain import LLMChain, PromptTemplate

temp = PromptTemplate(
    input_variables=['text'],
    template='''Write a Python program based on the description in the following text: {text}'''
)

code_generator = LLMChain(llm=llm, prompt=temp)
tools += [Tool.from_function(name='Code Generator', func=code_generator.run, description='A tool to generate code')]
```

Now, you can use this tool within your agent’s workflow by invoking it as part of the `AgentExecutor`.

Example usage:
```python
agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, verbose=True)
res = agent_executor.invoke({'input': 'Write a Python program to plot a sine curve and a cosine curve in the same graph. The sine curve is in solid line and the cosine curve is in dashed line. Add a legend to the graph. Set the x-axis range to -5 to 5. The title should be "Comparing Sine and Cosine Curves."'})
print(res['output'])
```

The output will include the generated Python code for plotting the curves as described.
x??

---

#### Adding Image Generation Tools to the Agent's Toolbox
Background context: In addition to text and code generation, it is also possible to add an image generator tool. This allows the agent to generate images based on textual descriptions. Here, we specifically use a DALL-E API wrapper to achieve this.

:p How can you add an image generator tool to an agent's toolbox in LangChain?
??x
To add an image generation tool using the DALL-E API wrapper, follow these steps:

1. Import the necessary modules.
2. Define a `PromptTemplate` for describing the task.
3. Create an `LLMChain` object that will generate text based on the template.
4. Add this new tool to your existing tools list.

Here’s how it can be done:
```python
from langchain_community.utilities.dalle_image_generator import DallEAPIWrapper

temp = PromptTemplate(
    input_variables=['text'],
    template='Create an image base on the following text: {text}'
)

grapher = LLMChain(llm=llm, prompt=temp)
tools += [Tool.from_function(name='Text to Image', func=grapher.run, description='A tool for text to image')]

agent_executor = AgentExecutor(agent=agent, tools=tools, handle_parsing_errors=True, verbose=True)

# Invoke the agent with a sample text
image_url = DallEAPIWrapper().run(
    agent_executor.invoke({
        'input': 'Create an image base on the following text: a horse grazes on the grassland.'
    })['output']
)
print(image_url)
```

The output will be the URL of the generated image.
x??

---

#### Zero-Shot vs Few-Shot Prompting
Background context: Zero-shot and few-shot prompting are techniques used to guide Large Language Models (LLMs) on tasks without providing specific training data. Zero-shot means no examples are provided, while few-shot involves giving a few relevant examples.

:p What is the difference between zero-shot and few-shot prompting?
??x
Zero-shot prompting refers to situations where the LLM is given a task for which it has not been trained or seen any examples of during its training phase. In contrast, few-shot prompting provides the model with a limited number of examples that are similar to or relevant to the task at hand.

For example, if you want to teach an LLM how to translate sentences from English to French without any prior training data on translation, zero-shot prompting would involve directly giving it an English sentence and asking for the French translation. Few-shot prompting might provide a few sample translations before posing the same request.
??x

---

#### LangChain Library
Background context: LangChain is a Python library designed to simplify the use of LLMs in various applications by abstracting away the complexities of interacting with different models.

:p What does LangChain do?
??x
LangChain facilitates the integration and usage of large language models (LLMs) across different platforms. It provides an interface that allows developers to interact with LLMs without needing to worry about the underlying complexities of model APIs, thereby making it easier to incorporate these powerful tools into various applications.

```python
from langchain import LangChain

langchain = LangChain()
response = langchain.generate_response("Create a poem about autumn leaves.")
print(response)
```
??x

---

#### Limitations of LLMs - Lack of True Understanding and Reasoning
Background context: Despite their impressive capabilities, LLMs still have limitations such as the lack of true understanding and reasoning. These models can generate coherent text but often make factual errors or fail to grasp complex concepts due to their inability to understand the content deeply.

:p What are some examples of mistakes made by LLMs?
??x
LLMs like GPT-3 and ChatGPT can make factual errors and misunderstand complex concepts because they do not have a true understanding of the content. For instance, when asked "Mrs. March gave the mother tea and gruel, while she dressed the little baby as tenderly as if it had been her own. Who’s the baby's mother?", GPT-3 incorrectly answered that Mrs. March is the baby's mother.

Another example involves a LinkedIn article by David Johnston where LLMs, including GPT-4, struggled with problems that humans can easily solve. One such problem was: "Name an animal such that the length of the word is equal to the number of legs they have minus the number of tails they have." GPT-4 incorrectly answered this by stating that five is equal to the number of letters in the word “bee”.
??x

---

#### Ethical Concerns - Bias and Discrimination
Background context: LLMs can perpetuate biases present in their training data, leading to stereotypical or discriminatory outputs. This is a significant ethical concern as these biases can reinforce harmful stereotypes.

:p What are some ways to mitigate bias in LLMs?
??x
To mitigate bias in LLMs, it’s essential to adopt diverse and inclusive training datasets, implement bias detection and correction algorithms, and ensure transparency in model development and evaluation. Establishing industry-wide collaboration to set standards for bias mitigation practices is crucial.

For example, using a more diverse dataset that includes various demographics can help reduce bias. Implementing techniques like fairness constraints during the training process or using post-processing methods to correct biased outputs can also be effective.
??x

---

#### Ethical Concerns - Misinformation and Manipulation
Background context: LLMs’ ability to generate realistic text poses risks of misinformation, propaganda, and manipulation. This concern necessitates robust content moderation systems and responsible use guidelines.

:p How can we combat the risk of LLMs spreading misinformation?
??x
To combat the spread of misinformation by LLMs, it is crucial to develop robust content moderation systems that can detect and filter out false or misleading information. Establishing guidelines for responsible use and fostering collaborations between AI developers, policymakers, and media organizations are key steps.

For instance, implementing automatic fact-checking mechanisms within the LLM output pipeline or training users to recognize signs of misinformation generated by these models can help mitigate this risk.
??x

---

#### Ethical Concerns - Privacy
Background context: The vast datasets used to train LLMs raise privacy concerns, as sensitive information might be revealed in model outputs. Additionally, LLMs could be used maliciously in cyberattacks.

:p What are the main privacy issues related to training data for LLMs?
??x
The primary privacy issue is that the large amount of data used to train LLMs can inadvertently reveal sensitive information. Moreover, the potential misuse of these models to bypass security measures or launch cyberattacks poses significant security risks.

To address this, developers should ensure that all necessary permissions are obtained for using training data and implement robust anonymization techniques. Additionally, establishing legal frameworks and regulations to protect user privacy is essential.
??x

---

#### Ethical Concerns - Copyright Infringement
Background context: LLMs are trained on vast amounts of copyrighted texts without explicit permission, leading to debates about copyright infringement.

:p How do current copyright laws apply to LLMs?
??x
Current copyright laws were not designed with generative AI in mind, making their application ambiguous. While supporters argue that the use of training data can be considered "fair use" because models generate new content, critics contend that direct ingestion without transformation infringes on copyrights.

Resolving this debate likely requires legislative and judicial bodies to provide clear guidelines. Until then, developers must navigate these ambiguities carefully.
??x

---

